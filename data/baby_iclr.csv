submission_id,year,full_decision,arxiv_first,title,authors,keywords,tldr,arxiv_id,primary_category,published_time,updated_time
--GJkm7nt0,2021,Reject,False,Enhancing Visual Representations for Efficient Object Recognition during Online Distillation,"[""Shashanka Venkataramanan"", ""Bruce W McIntosh"", ""Abhijit Mahalanobis""]",[],,,,,
--gvHfE3Xf5,2021,Accept (Poster),False,Meta-Learning of Structured Task Distributions in Humans and Machines,"[""Sreejan Kumar"", ""Ishita Dasgupta"", ""Jonathan Cohen"", ""Nathaniel Daw"", ""Thomas Griffiths""]","[""meta-learning"", ""human cognition"", ""reinforcement learning"", ""compositionality""]","We developed a novel meta-learning task with a structured task distribution and statistically equivalent ""null"" task distribution to show humans are more adept at the former whereas current meta-learning agents are more adept at the latter. ",,,,
--rcOeCKRh,2021,Reject,False,CROSS-SUPERVISED OBJECT DETECTION,"[""Zitian Chen"", ""Zhiqiang Shen"", ""Jiahui Yu"", ""Erik Learned-Miller""]","[""Object detection"", ""weakly supervised"", ""transfer leaning""]", We show how to build better object detectors from weakly labeled images of new categories by leveraging knowledge learned from fully labeled base categories.,,,,
-0Cjhnl-dhK,2022,Reject,False,Towards Uncertainties in Deep Learning that Are Accurate and Calibrated,"['Volodymyr Kuleshov', 'Shachi Deshpande']",[],,,,,
-0LuSWi6j4,2022,Reject,False,Mind Your Bits and Errors: Prioritizing the Bits that Matter in Variational Autoencoders,"['Rui Shu', 'Stefano Ermon']","[""deep generative models"", ""variational autoencoders""]",We prioritize the modeling of visually perceptible bits,,,,
-29uFS4FiDZ,2022,Reject,False,Word Sense Induction with Knowledge Distillation from BERT,"['Anik Saha', 'Alex Gittens', 'Bulent Yener']","[""word embeddings"", ""sense embeddings"", ""word sense induction""]",Effective approach to distil word meaning from contextual embeddings to word sense embeddings.,,,,
-2FCwDKRREu,2021,Accept (Oral),False,Learning Invariant Representations for Reinforcement Learning without Reconstruction,"[""Amy Zhang"", ""Rowan Thomas McAllister"", ""Roberto Calandra"", ""Yarin Gal"", ""Sergey Levine""]","[""rich observations"", ""bisimulation metrics"", ""representation learning"", ""state abstractions""]",,,,,
-3Qj7Jl6UP5,2022,Reject,False,The magnitude vector of images,"['Michael F Adamer', ""Leslie O'Bray"", 'Edward De Brouwer', 'Bastian Rieck', 'Karsten Borgwardt']","[""magnitude"", ""magnitude vector"", ""edge detection"", ""adversarial robustness"", ""metric space"", ""algebraic topology""]",We study the magnitude vector of images and highlight potential applications,,,,
-3yxxvDis3L,2022,Reject,False,How to Improve Sample Complexity of SGD over Highly Dependent Data?,"['Shaocong Ma', 'Ziyi Chen', 'Yi Zhou', 'Kaiyi Ji', 'Yingbin Liang']","[""Dependent data sampling"", ""SGD"", ""sample complexity""]",This paper shows that both SGD with periodic data-subsampling and mini-batch SGD can improve the sample complexity of vanilla SGD under dependent data.,,,,
-5VpoDCExrU,2021,Reject,False,Log representation as an interface for log processing applications,"[""Mohammad Amin Sadeghi"", ""Shameem Parambath"", ""Ji Lucas"", ""Youssef Meguebli"", ""Maguette Toure"", ""Fawaz Al Qahtani"", ""Ting Yu"", ""Sanjay Chawla""]","[""Vector embedding"", ""Logs"", ""Search"", ""Causal Analysis"", ""Anomaly Detection""]",We present a variant of transformer network to represent logs at different levels of abstraction. These representations can be directly used for downstream applications.,,,,
-5W5OBfFlwX,2021,Reject,True,Regret Bounds and Reinforcement Learning Exploration of EXP-based Algorithms,"[""Mengfan Xu"", ""Diego Klabjan""]",[],,2009.09538,cs.LG,2020-09-20 22:31:37+00:00,2020-09-20 22:31:37+00:00
-6me0AsJVdu,2022,Reject,False,Model Validation Using Mutated Training Labels: An Exploratory Study,"['Jie Zhang', 'Mark Harman', 'Benjamin Guedj', 'Earl Barr', 'John Shawe-Taylor']",[],Mutation Validation (MV) is a new model validation measurement using the relationship between mutated labels and training performance changes.,,,,
-6vS_4Kfz0,2021,Accept (Poster),False,Optimizing Memory Placement using Evolutionary Graph Reinforcement Learning,"[""Shauharda Khadka"", ""Estelle Aflalo"", ""Mattias Mardar"", ""Avrech Ben-David"", ""Santiago Miret"", ""Shie Mannor"", ""Tamir Hazan"", ""Hanlin Tang"", ""Somdeb Majumdar""]","[""Reinforcement Learning"", ""Memory Mapping"", ""Device Placement"", ""Evolutionary Algorithms""]","We combine evolutionary and gradient-based reinforcement learning to tackle the large search spaces needed to map tensors to memory, yielding up to 78% speedup on BERT and ResNet on a deep learning inference chip.",,,,
-70L8lpp9DF,2022,Accept (Oral),True,Hyperparameter Tuning with Renyi Differential Privacy,"['Nicolas Papernot', 'Thomas Steinke']","[""differential privacy"", ""hyperparameter tuning""]","We provide privacy guarantees for hyperparameter search procedures, showing that tuning hyperparameters leaks private information, but that, under certain assumptions, this leakage is modest.",2110.03620,cs.LG,2021-10-07 16:58:46+00:00,2021-10-07 16:58:46+00:00
-757TnNDwIn,2021,Reject,False,Generative Adversarial Neural Architecture Search with Importance Sampling,"[""SEYED SAEED CHANGIZ REZAEI"", ""Fred X. Han"", ""Di Niu"", ""Mohammad Salameh"", ""Keith G Mills"", ""Shangling Jui""]","[""Nueral Architecture Search"", ""Deep Learning"", ""Generative Adversarial Network"", ""Graph Neural Network"", ""Computer Vision""]","We propose Generative Adversarial NAS (GA-NAS), as a search strategy for NAS problems, based on a generative adversarial learning framework and importance sampling for rare event simulation.",,,,
-7UeX2KPqs,2022,Reject,False,State-Action Joint Regularized Implicit Policy for Offline Reinforcement Learning,"['Shentao Yang', 'Zhendong Wang', 'Huangjie Zheng', 'Mingyuan Zhou']","[""Implicit Policy"", ""State-action Visitation"", ""Distribution Matching"", ""Generative Adversarial Networks""]",An offline reinforcement learning framework that supports the learning of a flexible and well-regularized policy.,,,,
-8sBpe7rDiV,2022,Accept (Poster),False,NETWORK INSENSITIVITY TO PARAMETER NOISE VIA PARAMETER ATTACK DURING TRAINING,"['Julian BÃ¼chel', 'Fynn Firouz Faber', 'Dylan Richard Muir']","[""parameter attack"", ""adversarial attack"", ""neural network"", ""deep learning"", ""optimisation"", ""neuromorphic processor""]",We flatten the weight loss-landscape by introducing a parameter attack term in the loss function and demonstrate improved network insensitivity to noise common in analog neuromorphic hardware.,,,,
-9ffJ9NQmal,2022,Reject,False,VICE: Variational Inference for Concept Embeddings,"['Lukas Muttenthaler', 'Charles Yang Zheng', 'Patrick McClure', 'Martin N Hebart', 'Francisco Pereira']","[""cognitive science"", ""variational Bayes"", ""category representation"", ""sparse coding"", ""representation learning"", ""interpretable representations""]","A variational inference approach for learning sparse, non-negative object concept embeddings, from human behavior in an odd-one-out task.",,,,
-9uy3c7b_ks,2022,Reject,False,Learning Controllable Elements Oriented Representations for Reinforcement Learning ,"['Qi Yi', 'Jiaming Guo', 'Rui Zhang', 'Shaohui Peng', 'Xing Hu', 'Xishan Zhang', 'Ke Tang', 'Zidong Du', 'Qi Guo', 'Yunji Chen']","[""reinforcement learning"", ""representation learning"", ""mutual information""]",We train representations for RL by encoding the controllable elements of the environment.,,,,
-AOEi-5VTU8,2022,Accept (Poster),False,Fast Differentiable Matrix Square Root,"['Yue Song', 'Nicu Sebe', 'Wei Wang']","[""Differentiabl Matrix Square Root"", ""Differentiable Matrix Decomposition"", ""Vision Transformers""]",We develop two fast methods to compute the differentiable matrix square root.,,,,
-AW3SFO63GO,2022,Reject,False,Dissecting Local Properties of Adversarial Examples,"['Lu Chen', 'Renjie Chen', 'Hang Guo', 'Yuan Luo', 'Quanshi Zhang', 'Yisen Wang']",[],,,,,
-ApAkox5mp,2022,Accept (Spotlight),True,SHINE: SHaring the INverse Estimate from the forward pass for bi-level optimization and implicit models,"['Zaccharie Ramzi', 'Florian Mannel', 'Shaojie Bai', 'Jean-Luc Starck', 'Philippe Ciuciu', 'Thomas Moreau']","[""implicit models"", ""bi-level optimization"", ""quasi-newton methods""]",Use the approximate Jacobian matrix computed in quasi-Newton methods to perform the inversion needed in the training of implicit models.,2106.00553,cs.LG,2021-06-01 15:07:34+00:00,2022-01-30 18:05:10+00:00
-BA38x6Cf2,2021,Reject,False,Can Kernel Transfer Operators Help Flow based Generative Models?,"[""Zhichun Huang"", ""Rudrasis Chakraborty"", ""Xingjian Zhen"", ""Vikas Singh""]",[],(almost) training-free generative model,,,,
-BTmxCddppP,2022,Reject,False,Revisiting Out-of-Distribution Detection: A Simple Baseline is Surprisingly Effective,"['Julian Bitterwolf', 'Alexander Meinke', 'Maximilian Augustin', 'Matthias Hein']","[""out-of-distribution detection"", ""robustness"", ""OOD""]",We analyze different training methods and scoring functions for out-of-distribution detection and identify a binary discriminator as a critical implicit component in different OOD detection approaches.,,,,
-DRft_lKDqo,2021,Reject,False,Generalized Universal Approximation for Certified Networks,"[""Zi Wang"", ""Aws Albarghouthi"", ""Somesh Jha""]","[""adversarial deep learning"", ""neural network verification"", ""interval analysis""]",We have extended the universal approximation theorem for certified neural networks and demonstrated how interval analysis can be used to certify the robustness of neural networks.,,,,
-FP1-bBxOzv,2022,Reject,False,Self Reward Design with Fine-grained Interpretability,"['Erico Tjoa', 'Cuntai Guan']","[""Reinforcement Learning"", ""Interpretability"", ""Explainable Artificial Intelligence"", ""Neural Networks""]",Reinforcement Learning with fine-grained Interpretable Neural Network Designs and Self Reward Design,,,,
-GLNZeVDuik,2021,Accept (Poster),True,Categorical Normalizing Flows via Continuous Transformations,"[""Phillip Lippe"", ""Efstratios Gavves""]","[""Normalizing Flows"", ""Density Estimation"", ""Graph Generation""]","We explore the application of normalizing flows on categorical data and propose a permutation-invariant generative model on graphs, called GraphCNF.",2006.09790,cs.LG,2020-06-17 11:37:01+00:00,2021-01-21 12:06:59+00:00
-Gk_IPJWvk,2022,Accept (Poster),True,Top-N: Equivariant Set and Graph Generation without Exchangeability,"['Clement Vignac', 'Pascal Frossard']","[""set generation"", ""graph generation"", ""permutation equivariance"", ""generative models"", ""Top-N""]",We propose the Top-N method for one-shot set and graph probabilistic decoders as a replacement for i.i.d. generation in the first layer.,2110.02096,cs.LG,2021-10-05 14:51:19+00:00,2021-11-23 08:18:50+00:00
-H48S9ePSUC,2022,Reject,False,Fundamental Limits of Transfer Learning in Binary Classifications,"['Mohammadreza Mousavi Kalan', 'Salman Avestimehr', 'Mahdi Soltanolkotabi']",[],,,,,
-HSOjDPfhBJ,2022,Accept (Poster),True,PER-ETD: A Polynomially Efficient Emphatic Temporal Difference Learning Method,"['Ziwei Guan', 'Tengyu Xu', 'Yingbin Liang']","[""emphatic temporal difference"", ""finite-time analysis"", ""off-policy evaluation"", ""reinforcement learning""]","We propose a new off-policy evaluation algorithm called PER-ETD (i.e., PEriodically Restarted Emphatic TD), which improves upon its precursor ETD with reduced variance and polynomial sample efficiency.",2110.06906,cs.LG,2021-10-13 17:40:12+00:00,2021-10-13 17:40:12+00:00
-Hs_otp2RB,2021,Accept (Poster),False,Improving VAEs' Robustness to Adversarial Attack,"[""Matthew JF Willetts"", ""Alexander Camuto"", ""Tom Rainforth"", ""S Roberts"", ""Christopher C Holmes""]","[""deep generative models"", ""variational autoencoders"", ""robustness"", ""adversarial attack""]",We show that regularisation methods first developed to obtain 'disentangled' VAEs increase the robustness of VAEs to adversarial attack; leveraging this insight we propose an even-more-robust hierarchical VAE.,,,,
-IXhmY16R3M,2021,Accept (Poster),True,Universal approximation power of deep residual neural networks via nonlinear control theory,"[""Paulo Tabuada"", ""Bahman Gharesifard""]","[""Deep residual neural networks"", ""universal approximation"", ""nonlinear control theory""]","Using nonlinear control theory, it is shown that deep residual neural networks have the power of universal approximation with respect to the supremum norm.",2007.06007,cs.LG,2020-07-12 14:53:30+00:00,2020-12-16 19:44:38+00:00
-J9xYzP2HD,2021,Reject,True,Chameleon: Learning Model Initializations Across Tasks With Different Schemas,"[""Lukas Brinkmeyer"", ""Rafael Rego Drumond"", ""Randolf Scholz"", ""Josif Grabocka"", ""Lars Schmidt-Thieme""]","[""Meta-Learning"", ""Initialization"", ""Few-shot classification""]",Chameleon projects different schemas to a fixed input space while keeping features from different tasks but ofthe same type or distribution in the same position,1909.13576,cs.LG,2019-09-30 10:42:44+00:00,2020-06-11 16:34:37+00:00
-Lr-u0b42he,2021,Accept (Poster),True,Disentangling 3D Prototypical Networks for Few-Shot Concept Learning,"[""Mihir Prabhudesai"", ""Shamit Lal"", ""Darshan Patil"", ""Hsiao-Yu Tung"", ""Adam W Harley"", ""Katerina Fragkiadaki""]","[""Disentanglement"", ""Few Shot Learning"", ""3D Vision"", ""VQA""]","We present neural architectures that disentangle RGB-D images into objectsâ shapes and styles and a map of the background scene, and explore their applications for few-shot 3D object detection and few-shot concept classification.",2011.03367,cs.CV,2020-11-06 14:08:27+00:00,2021-07-20 19:07:01+00:00
-M0QkvBGTTq,2021,Accept (Poster),False,SaliencyMix: A Saliency Guided Data Augmentation Strategy for Better Regularization,"[""A F M Shahab Uddin"", ""Mst. Sirazam Monira"", ""Wheemyung Shin"", ""TaeChoong Chung"", ""Sung-Ho Bae""]","[""SaliencyMix"", ""Saliency Guided Data Augmentation"", ""Data Augmentation"", ""Regularization""]",The proposed method carefully selects a representative image patch with the help of a saliency map and mixes that indicative patch with the target image that leads the model to learn more appropriate feature representation,,,,
-N7PBXqOUJZ,2021,Accept (Poster),True,Lipschitz Recurrent Neural Networks,"[""N. Benjamin Erichson"", ""Omri Azencot"", ""Alejandro Queiruga"", ""Liam Hodgkinson"", ""Michael W. Mahoney""]","[""recurrent neural networks"", ""dynamical systems"", ""differential equations""]","We develop a provably stable parameterization for continuous-time Lipschitz Recurrent Neural Networks that can employ high order integration schemes and outperform existing RNNs in performance, robustness, and conditioning.",2006.12070,cs.LG,2020-06-22 08:44:52+00:00,2021-04-24 03:31:59+00:00
-NEXDKk8gZ,2021,Reject,False,Improved Denoising Diffusion Probabilistic Models,"[""Alexander Quinn Nichol"", ""Prafulla Dhariwal""]","[""neural networks"", ""generative models"", ""log-likelihood"", ""diffusion models"", ""denoising diffusion probabilistic models"", ""image generation""]",We show that denoising diffusion probabilistic models can achieve competitive log-likelihoods and efficient sampling.,,,,
-Nf6TikpjQ,2022,Reject,False,Multi-agent Performative Prediction: From Global Stability and Optimality to Chaos,"['Georgios Piliouras', 'Fang-Yi Yu']",[],,2201.10483,cs.LG,2022-01-25 17:26:12+00:00,2022-01-25 17:26:12+00:00
-ODN6SbiUU,2021,Accept (Poster),False,In Defense of Pseudo-Labeling: An Uncertainty-Aware Pseudo-label Selection Framework for Semi-Supervised Learning,"[""Mamshad Nayeem Rizve"", ""Kevin Duarte"", ""Yogesh S Rawat"", ""Mubarak Shah""]","[""Semi-Supervised Learning"", ""Pseudo-Labeling"", ""Uncertainty"", ""Calibration"", ""Deep Learning""]",We present an uncertainty-aware pseudo-label selection framework for semi-supervised learning which greatly reduces the noise introduced by the pseudo-labeling process.,,,,
-Qaj4_O3cO,2021,Reject,True,DCT-SNN: Using DCT to Distribute Spatial Information over Time for Learning Low-Latency Spiking Neural Networks,"[""Isha Garg"", ""Sayeed Shafayet Chowdhury"", ""Kaushik Roy""]","[""Spiking Neural Networks"", ""Input Encoding"", ""Low Latency"", ""Discrete Cosine Transform"", ""Temporal Information"", ""Frequency Domain""]","We propose a new scheme that utilizes DCT to encode pixel information across timesteps, enabling us to learn deep spiking neural networks that can perform inference with lower number of timesteps compared to other state-of-the-art SNNs.",2010.01795,cs.LG,2020-10-05 05:55:34+00:00,2020-10-05 05:55:34+00:00
-QxT4mJdijq,2021,Accept (Poster),False,Meta-learning Symmetries by Reparameterization,"[""Allan Zhou"", ""Tom Knowles"", ""Chelsea Finn""]","[""meta-learning"", ""equivariance"", ""convolution"", ""symmetry""]",A method for automatically meta-learning and encoding equivariances into neural networks.,,,,
-RAFyM-YPj,2022,Reject,True,Counting Substructures with Higher-Order Graph Neural Networks:  Possibility and Impossibility Results,"['Behrooz Tahmasebi', 'Derek Lim', 'Stefanie Jegelka']","[""graph neural networks"", ""expressive power"", ""complexity""]",We study the expressive power and complexity for a novel graph learning architecture as well as general pooling and GNN architectures that count subgraphs.,2012.03174,cs.LG,2020-12-06 03:42:54+00:00,2021-10-11 03:36:32+00:00
-RQVWPX73VP,2021,Reject,False,Interpretable Meta-Reinforcement Learning with Actor-Critic Method,"[""Xingyuan Liang"", ""Xu-Ying Liu""]","[""meta-reinforcement learning"", ""actor-critic"", ""deep learning"", ""interpretable""]",a new meta-RL algorithm that can reduce the variance and bias of the meta-gradient estimation and perform few-shot task data sampling,,,,
-TSe5o7STVR,2022,Accept (Poster),False,Non-Parallel Text Style Transfer with Self-Parallel Supervision,"['Ruibo Liu', 'Chongyang Gao', 'Chenyan Jia', 'Guangxuan Xu', 'Soroush Vosoughi']","[""style transfer"", ""non-parallel corpus"", ""imitation learning"", ""language models"", ""political stance transfer""]",We propose a new text style transfer model for non-parallel corpus with supervision from intrinsic parallelism.,,,,
-TwO99rbVRu,2021,Accept (Poster),True,PseudoSeg: Designing Pseudo Labels for Semantic Segmentation,"[""Yuliang Zou"", ""Zizhao Zhang"", ""Han Zhang"", ""Chun-Liang Li"", ""Xiao Bian"", ""Jia-Bin Huang"", ""Tomas Pfister""]","[""pseudo-labeling"", ""semi-supervised"", ""semantic-segmentation""]",This paper presents a new method that first demonstrates how well-calibrated soft pseudo labels obtained through wise fusion of predictions from diverse sources greatly improve consistency training for semantic segmentation.,2010.09713,cs.CV,2020-10-19 17:59:30+00:00,2021-03-30 17:54:47+00:00
-Txy_1wHJ4f,2022,Reject,False,Safe Deep RL in 3D Environments using Human Feedback,"['Matthew Rahtz', 'Vikrant Varma', 'Ramana Kumar', 'Zachary Kenton', 'Shane Legg', 'Jan Leike']",[],,2201.08102,cs.LG,2022-01-20 10:26:34+00:00,2022-01-21 16:10:14+00:00
-WwaX9vKKt,2021,Reject,False,Ask Question with Double Hints:  Visual Question Generation with Answer-awareness and Region-reference,"[""Shen Kai"", ""Lingfei Wu"", ""Siliang Tang"", ""Fangli Xu"", ""Zhu Zhang"", ""Yu Qiang"", ""Yueting Zhuang""]","[""Semi-supervised Learning"", ""graph neural network"", ""vision and language"", ""question generation""]","For visual question generation task, we propose a new learning paradigm and a novel a double-hints guided graph-to-sequence learning framework to address the one-to-many mapping and object modeling with side information problems.",,,,
-YAqAIsxr7v,2022,Reject,False,OVD-Explorer: A General Information-theoretic Exploration Approach for Reinforcement Learning,"['Jinyi Liu', 'Zhi Wang', 'YAN ZHENG', 'Jianye HAO', 'Junjie Ye', 'Chenjia Bai', 'Pengyi Li']","[""Exploration"", ""Uncertainty"", ""Reinforcement Learning""]","We propose an information-theoretic exploration method OVD-Explorer following the OFU principle, and more importantly, it avoids exploring the areas with high aleatoric uncertainty.",,,,
-YCAwPdyPKw,2021,Reject,False,A Bayesian-Symbolic Approach to Learning and Reasoning for Intuitive Physics,"[""Kai Xu"", ""Akash Srivastava"", ""Dan Gutfreund"", ""Felix Sosa"", ""Tomer Ullman"", ""Joshua B. Tenenbaum"", ""Charles Sutton""]","[""physics learning"", ""symbolic regression"", ""intuitive physics""]",A novel computational framework to perform joint learning-reasoning of physics by combining symbolic regression and Bayesian inference.,,,,
-_Zp7r2-cGK,2021,Accept (Poster),True,A Discriminative Gaussian Mixture Model with Sparsity,"[""Hideaki Hayashi"", ""Seiichi Uchida""]","[""classification"", ""sparse Bayesian learning"", ""Gaussian mixture model""]","A sparse classifier based on a discriminative Gaussian mixture model, which can also be embedded into a neural network.",1911.06028,cs.LG,2019-11-14 10:42:41+00:00,2021-05-07 08:23:12+00:00
-aThAo4b1zn,2021,Reject,False,A Theory of Self-Supervised Framework for Few-Shot Learning,"[""Zhong Cao"", ""Jiang Lu"", ""Jian Liang"", ""Changshui Zhang""]",[],,,,,
-bdp_8Itjwp,2021,Accept (Poster),False,Self-supervised Learning from a Multi-view Perspective,"[""Yao-Hung Hubert Tsai"", ""Yue Wu"", ""Ruslan Salakhutdinov"", ""Louis-Philippe Morency""]","[""Self-supervised Learning"", ""Unsupervised Learning"", ""Multi-view Representation Learning""]","From a multi-view learning perspective, this paper provides both theoretical and empirical analysis on self-supervised learning.",,,,
-bxf89v3Nx,2021,Accept (Poster),False,Calibration tests beyond classification,"[""David Widmann"", ""Fredrik Lindsten"", ""Dave Zachariah""]","[""calibration"", ""uncertainty quantification"", ""framework"", ""integral probability metric"", ""maximum mean discrepancy""]",Unifying framework for calibration evaluations and tests of probabilistic predictive models,,,,
-cII-Vju5C,2022,Reject,False,Orthogonalising gradients to speedup neural network optimisation,"['Mark Tuddenham', 'Adam Prugel-Bennett', 'Jonathon Hare']","[""machine learning"", ""deep learning"", ""orthogonalisation"", ""optmisation"", ""optimization""]",The optimisation of neural networks can be sped up by orthogonalising the gradients before the optimiser step.,,,,
-csYGiUuGlt,2021,Reject,False,Convergent Adaptive Gradient Methods in Decentralized Optimization,"[""Xiangyi Chen"", ""Belhal Karimi"", ""Weijie Zhao"", ""Ping Li""]","[""Adam"", ""decentralized optimization"", ""adaptive gradient methods""]",We analyzed a framework to decentralize adaptive gradient methods and proposed a convergent decentralized adaptive gradient method using the framework.,2109.03194,cs.LG,2021-09-07 16:58:11+00:00,2021-09-07 16:58:11+00:00
-dzXGe2FyW6,2022,Reject,False,Equalized Robustness: Towards Sustainable Fairness Under Distributional Shifts,"['Haotao Wang', 'Junyuan Hong', 'Jiayu Zhou', 'Zhangyang Wang']",[],,,,,
-e4EXDWXnSn,2022,Accept (Poster),False,Invariant Causal Representation Learning for Out-of-Distribution Generalization,"['Chaochao Lu', 'Yuhuai Wu', 'JosÃ© Miguel HernÃ¡ndez-Lobato', 'Bernhard SchÃ¶lkopf']",[],,,,,
-e7awdzWsOc,2022,Reject,False,Towards Structured Dynamic Sparse Pre-Training of BERT,"['Anastasia S. D. Dietrich', 'Frithjof Gressmann', 'Douglas Orr', 'Ivan Chelombiev', 'Daniel Justus', 'Carlo Luschi']","[""sparsity"", ""natural language processing"", ""pre-training"", ""computational efficiency""]",We present a dynamic sparse pre-training approach for BERT and demonstrate its superior FLOP-efficiency when compared to the dense baseline.,,,,
-fORBF5k2ZB,2022,Reject,False,Gating Mechanisms Underlying Sequence-to-Sequence Working Memory,"['Ian D Jordan', 'Piotr A Sokol', 'Il Memming Park']","[""Working Memory"", ""RNN"", ""Dynamical Systems"", ""Slow Manifold"", ""Gating""]","A synthetic RNN solution to a sequence-to-sequence working memory task, inspired from analysis on a trained network, is constructed and extrapolated from.",,,,
-gabSeMKO4H,2021,Reject,False,Translation Memory Guided Neural Machine Translation,"[""Shaohui Kuang"", ""Heng Yu"", ""Weihua Luo"", ""Qiang Wang""]","[""neural machine translation"", ""translation memory"", ""pre-train language model""]",,,,,
-geBFMKGlkq,2022,Reject,True,Density-based Clustering with Kernel Diffusion,"['Chao Zheng', 'Yingjie Chen', 'Chong Chen', 'Jianqiang Huang', 'Xian-Sheng Hua']","[""density-based clustering"", ""diffusion process"", ""density function"", ""face clustering""]"," We propose a new kernel diffusion density function that can be used in density-based clustering algorithms, which results in a significant superior practical performance especially for large-scale and complex datasets.",2110.05096,cs.LG,2021-10-11 09:00:33+00:00,2021-10-14 04:41:31+00:00
-gfhS00XfKj,2021,Accept (Poster),False,Learning advanced mathematical computations from examples,"[""Francois Charton"", ""Amaury Hayat"", ""Guillaume Lample""]","[""differential equations"", ""computation"", ""transformers"", ""deep learning""]",We train transformers to predict qualitative and numerical properties of differential equations,,,,
-h5rboREox7,2022,Reject,True,Double Descent in Adversarial Training: An Implicit Label Noise Perspective,"['Chengyu Dong', 'Liyuan Liu', 'Jingbo Shang']","[""Adversarial training"", ""Robust overfitting"", ""Double descent"", ""Label noise""]","We update the understanding of robust overfitting by showing that it is the early part of a epoch-wise double descent, and design effective algorithm to mitigate it.",2110.03135,cs.LG,2021-10-07 01:15:06+00:00,2021-10-07 01:15:06+00:00
-kfLEqppEm_,2021,Reject,False,Convex Regularization in Monte-Carlo Tree Search,"[""Tuan Quang Dam"", ""Carlo D'Eramo"", ""Jan Peters"", ""Joni Pajarinen""]","[""Monte-Carlo Tree Search"", ""Entropy regularization"", ""Reinforcement Learning""]",A theoretical and empirical study on the use of convex regularization in Monte-Carlo Tree Search.,,,,
-kigPjfTIGd,2021,Reject,False,SSW-GAN: Scalable Stage-wise Training of Video GANs,"[""Lluis Castrejon"", ""Nicolas Ballas"", ""Aaron Courville""]","[""video generation"", ""GANs"", ""scalable methods""]","We propose a scalable methods to generate videos by training a GAN to produce a low resolution and temporally subsampled version of a video, which is then upsampled by one or more local upsampling stages.",,,,
-llS6TiOew,2022,Accept (Spotlight),False,Fairness in Representation for Multilingual NLP: Insights from Controlled Experiments on Conditional Language Modeling,['Ada Wan'],"[""fairness"", ""evaluation"", ""multilingual NLP / multilinguality"", ""representation learning for language data"", ""statistical comparisons"", ""Double Descent"", ""conditional language modeling"", ""data-centric approach"", ""diversity in AI"", ""morphology"", ""Transformer"", ""meta evaluation"", ""visualization or interpretation of learned representations"", ""character encoding"", ""internationalization and localization"", ""robustness"", ""statistical science for NLP"", ""science in the era of AI/DL (AIxScience)"", ""transdisciplinarity""]","We investigate performance disparity in multilingual NLP with Transformer conditional LMs, and find, in the context of computing, morphological complexity to be a byproduct of word segmentation and disparity arising therefrom unwarranted. ",,,,
-mWcQVLPSPy,2021,Accept (Poster),False,Isometric Propagation Network for Generalized Zero-shot Learning,"[""Lu Liu"", ""Tianyi Zhou"", ""Guodong Long"", ""Jing Jiang"", ""Xuanyi Dong"", ""Chengqi Zhang""]","[""Zero-shot learning"", ""isometric"", ""prototype propagation"", ""alignment of semantic and visual space""]",We improve the current zero-shot learning performance by a dynamic alignment between the semantic space and visual space that encourages the isometry of the class-prototype propagation procedures in the two spaces. ,2102.02038,cs.CV,2021-02-03 12:45:38+00:00,2021-02-03 12:45:38+00:00
-ngwPqanCEZ,2022,Accept (Poster),False,Representation-Agnostic Shape Fields,"['Xiaoyang Huang', 'Jiancheng Yang', 'Yanjun Wang', 'Ziyu Chen', 'Linguo Li', 'Teng Li', 'Bingbing Ni', 'Wenjun Zhang']","[""shape embedding"", ""3D deep learning"", ""shape classification and segmentation""]","We propose a  generalizable and computation-efficient shape embedding layer for 3D deep learning, named Representation-Agnostic Shape Fields (RASF), to improve performance across different representations, backbones and down-stream tasks",,,,
-oeKiM9lD9h,2021,Reject,False,Rethinking Convolution: Towards an Optimal Efficiency,"[""Tao Wei"", ""Yonghong Tian"", ""Chang Wen Chen""]",[],,,,,
-p6rexF3qdQ,2021,Reject,False,Learn Robust Features via Orthogonal Multi-Path,"[""Kun Fang"", ""Xiaolin Huang"", ""Yingwen Wu"", ""Tao Li"", ""Jie Yang""]","[""adversarial robustness"", ""orthogonal multi-path""]",We propose a novel defence method via embedding orthogonal multi-path into a neural network to enhance the robustness.,,,,
-qB7ZgRNRq,2021,Reject,False,Towards Data Distillation for End-to-end Spoken Conversational Question Answering,"[""Chenyu You"", ""Nuo Chen"", ""Fenglin Liu"", ""Dongchao Yang"", ""Zhiyang Xu"", ""Yuexian Zou""]","[""spoken question answering"", ""natural language processing"", ""speech and language processing"", ""knowledge distillation""]",,,,,
-qg9k1ftTc,2022,Reject,False,S$^3$ADNet: Sequential Anomaly Detection with Pessimistic Contrastive Learning,"['Quexuan Zhang', 'Yukio Ohsawa']","[""deep learning"", ""anomaly detection"", ""unsupervised learning"", ""sequential data""]","This paper proposed a flexible and straightforward framework S$^3$ADNet, for detecting anomalies on sequential data by using contrastive learning under the pessimistic assumptions.",,,,
-qh0M9XWxnv,2021,Accept (Poster),False,Analyzing the Expressive Power of Graph Neural Networks in a Spectral Perspective,"[""Muhammet Balcilar"", ""Guillaume Renton"", ""Pierre H\u00e9roux"", ""Benoit Ga\u00fcz\u00e8re"", ""S\u00e9bastien Adam"", ""Paul Honeine""]","[""Graph Neural Networks"", ""Spectral Graph Filter"", ""Spectral Analysis""]",This paper aims to analyse of the expressive power of Graph Neural Network in spectral domain.,,,,
-spj8FZD4y2,2022,Reject,False,Contextual Multi-Armed Bandit with Communication Constraints,"['Francesco Pase', 'Deniz Gunduz', 'Michele Zorzi']","[""Machine Learning"", ""Information Theory"", ""Multi-Armed Bandits""]","We study the problem of Contextual Multi-Armed Bandit in which a decision maker can observes the context and the reward, while the actions have to be communicated over a rate-limited communication channel.",,,,
-u4j4dHeWQi,2021,Reject,False,Explore with Dynamic Map: Graph Structured Reinforcement Learning,"[""Jiarui Jin"", ""Sijin Zhou"", ""Weinan Zhang"", ""Rasool Fakoor"", ""David Wipf"", ""Tong He"", ""Yong Yu"", ""Zheng Zhang"", ""Alex Smola""]","[""Deep Reinforcement Learning"", ""Graph Structured Reinforcement Learning"", ""Exploration""]","In this paper, we propose to construct a dynamic graph on top of state transitions in replay buffer and leverage graph structure for learning and planning.",,,,
-u8EliRNW8k,2022,Reject,False,Speech-MLP: a simple MLP architecture for speech processing,"['Chao Xing', 'Dong Wang', 'Lirong Dai', 'Qun Liu', 'Anderson Avila']","[""MLP"", ""transformers"", ""speech signal processing""]",A pure MLP architecture with new feature partition methods by simple training methods outperforms elaborate designed transformer-based models in speech signal processing tasks.,,,,
-uPIaaZdMLF,2022,Reject,False,Attentional meta-learners for few-shot polythetic classification,"['Ben Day', 'Ramon ViÃ±as TornÃ©', 'Nikola Simidjievski', 'Pietro Lio']","[""Meta-learning"", ""self-attention"", ""feature-selection""]",Attentional meta-learners are well-suited to recognising classes based on patterns of traits and benefit from feature-selection.,,,,
-uZp67PZ7p,2022,Reject,False,Multi-Agent Reinforcement Learning with Shared Resource in Inventory Management,"['Mingxiao Feng', 'Guozi Liu', 'Li Zhao', 'Lei Song', 'Jiang Bian', 'Tao Qin', 'Wengang Zhou', 'Houqiang Li', 'Tie-Yan Liu']","[""Multi-Agent Reinforcement Learning"", ""Inventory Management"", ""Shared Resource"", ""Decentralized Training Paradigm"", ""Model-based RL""]",We propose shared-resource stochastic game to capture the problem structure in IM and propose a novel algorithm that leverages the shared-resource structure to solve IM problem efficiently.,,,,
-w2oomO6qgc,2022,Accept (Poster),True,GeneDisco: A Benchmark for Experimental Design in Drug Discovery,"['Arash Mehrjou', 'Ashkan Soleymani', 'Andrew Jesson', 'Pascal Notin', 'Yarin Gal', 'Stefan Bauer', 'Patrick Schwab']","[""batch active learning"", ""drug discovery"", ""benchmark""]",A comprehensive benchmark for batch active learning in drug discovery. ,2110.11875,cs.LG,2021-10-22 16:01:39+00:00,2021-10-22 16:01:39+00:00
-xhk0O7iAc0,2022,Reject,True,A Topological View of Rule Learning in Knowledge Graphs,"['Zuoyu Yan', 'Tengfei Ma', 'Liangcai Gao', 'Zhi Tang', 'Chao Chen']","[""Inductive Relation Prediction"", ""Topological Data Analysis"", ""Cycle Basis"", ""Homology""]",,2110.02510,cs.LG,2021-10-06 05:18:18+00:00,2022-01-28 10:50:52+00:00
-ybZRQktdgc,2022,Reject,False,LRN: Limitless Routing Networks for Effective Multi-task Learning,"['Ryan Wickman', 'Xiaofei Zhang', 'Weizi Li']","[""multi-task learning"", ""MTL"", ""reinforcement learning"", ""machine learning"", ""routing networks"", ""modular networks""]",A new multi-task learning framework that builds upon routing networks.,,,,
-yo2vfTt_Cg,2021,Reject,False,Adaptive norms for deep learning with regularized Newton methods,"[""Jonas K Kohler"", ""Leonard Adolphs"", ""Aurelien Lucchi""]","[""Stochastic Optimization"", ""Non-convex Optimization"", ""Deep Learning"", ""Adaptive methods"", ""Newton methods"", ""Second-order optimization""]",This paper proposes second-order variants of adaptive gradient methods such as RMSProp.,,,,
0-EYBhgw80y,2021,Accept (Poster),False,MoPro: Webly Supervised Learning with Momentum Prototypes,"[""Junnan Li"", ""Caiming Xiong"", ""Steven Hoi""]","[""webly-supervised learning"", ""weakly-supervised learning"", ""contrastive learning"", ""representation learning""]",MoPro is a new webly-supervised learning framework which advances representation learning using freely-available Web images.,,,,
0-uUGPbIjD,2021,Accept (Oral),True,Human-Level Performance in No-Press Diplomacy via Equilibrium Search,"[""Jonathan Gray"", ""Adam Lerer"", ""Anton Bakhtin"", ""Noam Brown""]","[""multi-agent systems"", ""regret minimization"", ""no-regret learning"", ""game theory"", ""reinforcement learning""]",We present an agent that approximates a one-step equilibrium in no-press Diplomacy using no-regret learning and show that it exceeds human-level performance,2010.02923,cs.AI,2020-10-06 01:28:34+00:00,2021-05-03 14:00:12+00:00
01AMRlen9wJ,2022,Accept (Spotlight),False,Online Hyperparameter Meta-Learning with Hypergradient Distillation,"['Hae Beom Lee', 'Hayeon Lee', 'JaeWoong Shin', 'Eunho Yang', 'Timothy Hospedales', 'Sung Ju Hwang']","[""Hyperparameter Optimization"", ""Meta-learning""]","We propose a gradient-based hyperparameter optimization method based on the idea of knowledge distillation, which is fully online and applicable to high-dimensional hyperparameters.",,,,
01olnfLIbD,2021,Accept (Poster),False,Witches' Brew: Industrial Scale Data Poisoning via Gradient Matching,"[""Jonas Geiping"", ""Liam H Fowl"", ""W. Ronny Huang"", ""Wojciech Czaja"", ""Gavin Taylor"", ""Michael Moeller"", ""Tom Goldstein""]","[""Data Poisoning"", ""ImageNet"", ""Large-scale"", ""Gradient Alignment"", ""Security"", ""Backdoor Attacks"", ""from-scratch"", ""clean-label""]","Data poisoning attacks that successfully poison neural networks trained from scratch, even on large-scale datasets like ImageNet.",,,,
03RLpj-tc_,2022,Accept (Poster),False,Crystal Diffusion Variational Autoencoder for Periodic Material Generation,"['Tian Xie', 'Xiang Fu', 'Octavian-Eugen Ganea', 'Regina Barzilay', 'Tommi S. Jaakkola']","[""materials"", ""graph neural networks"", ""periodic"", ""diffusion models"", ""score matching"", ""molecule"", ""3D"", ""generative""]",A generative model for the 3D periodic structure of materials,,,,
04ArenGOz3,2021,Accept (Poster),False,Set Prediction without Imposing Structure as Conditional Density Estimation,"[""David W Zhang"", ""Gertjan J. Burghouts"", ""Cees G. M. Snoek""]","[""set prediction"", ""energy based models""]",A set prediction training and prediction framework that addresses tasks with ambiguous target sets.,,,,
04LZCAxMSco,2021,Accept (Spotlight),False,Learning a Latent Simplex in Input Sparsity Time,"[""Ainesh Bakshi"", ""Chiranjib Bhattacharyya"", ""Ravi Kannan"", ""David Woodruff"", ""Samson Zhou""]","[""Latent Simplex"", ""numerical linear algebra"", ""low-rank approximation""]",We obtain the first input sparsity runtime algorithm for the problem of learning a latent simplex.,,,,
04cII6MumYV,2021,Accept (Poster),False,A Universal Representation Transformer Layer for Few-Shot Image Classification,"[""Lu Liu"", ""William L. Hamilton"", ""Guodong Long"", ""Jing Jiang"", ""Hugo Larochelle""]",[],code at: https://github.com/liulu112601/URT,,,,
04pGUg0-pdZ,2022,Accept (Spotlight),False,Finite-Time Convergence and Sample Complexity of Multi-Agent Actor-Critic Reinforcement Learning with Average Reward,"['FNU Hairi', 'Jia Liu', 'Songtao Lu']",[],,,,,
057dxuWpfx,2022,Reject,False,Shaped Rewards Bias Emergent Language,"['Brendon Boldt', 'Yonatan Bisk', 'David R Mortensen']","[""emergent language"", ""reinforcement learning"", ""neural networks""]","Shaped (i.e., auxiliary) rewards bias the structue and representations observed in an emergent language experiment.",,,,
068E_JSq9O,2021,Accept (Poster),False,Self-supervised Representation Learning with Relative Predictive Coding,"[""Yao-Hung Hubert Tsai"", ""Martin Q. Ma"", ""Muqiao Yang"", ""Han Zhao"", ""Louis-Philippe Morency"", ""Ruslan Salakhutdinov""]","[""self-supervised learning"", ""contrastive learning"", ""dependency based method""]","We present RPC, the Relative Predictive Coding, that achieves a good balance among the three challenges when modeling a contrastive learning objective: training stability, sensitivity to minibatch size, and downstream task performance. ",2103.11275,cs.LG,2021-03-21 01:04:24+00:00,2021-04-12 19:14:34+00:00
06Wy2BtxXrz,2022,Accept (Poster),False,Learning Scenario Representation for Solving Two-stage Stochastic Integer Programs,"['Yaoxin Wu', 'Wen Song', 'Zhiguang Cao', 'Jie Zhang']","[""Conditional Variational Autoencoder"", ""Stochastic Integer Programming"", ""Scenario Reduction""]",This paper provides a CVAE based method to learn scenario representations for solving stochastic integer programs.,,,,
06fUz_bJStS,2022,Reject,False,Differentially Private SGD with Sparse Gradients,"['Junyi Zhu', 'Matthew B. Blaschko']","[""differential privacy"", ""differentially private SGD"", ""privacy-preserving training""]",,,,,
083vV3utxpC,2021,Reject,True,Deep Partial Updating,"[""Zhongnan Qu"", ""Cong Liu"", ""Junfeng Guo"", ""Lothar Thiele""]","[""Partial updating"", ""communication constraints"", ""server-to-edge"", ""deep neural networks""]","To iteratively improve the deployed deep neural network with newly collected data samples, we propose the server only sends a weight-wise partial update to edge devices to save the communication and computation resources.",2007.03071,cs.LG,2020-07-06 21:22:20+00:00,2020-10-09 13:46:22+00:00
085y6YPaYjP,2022,Accept (Poster),False,Zero-Shot Self-Supervised Learning for MRI Reconstruction,"['Burhaneddin Yaman', 'Seyed Amir Hossein Hosseini', 'Mehmet Akcakaya']","[""Zero-shot learning"", ""Self-supervised learning"", ""MRI Reconstruction"", ""Transfer learning"", ""Physics-guided deep learning""]", Zero-shot self-supervised learning to perform robust subject-specific MRI reconstruction,,,,
09-528y2Fgf,2021,Accept (Poster),True,Rethinking Positional Encoding in Language Pre-training,"[""Guolin Ke"", ""Di He"", ""Tie-Yan Liu""]","[""Natural Language Processing"", ""Pre-training""]",A novel and better positional encoding method for Transformer-based language pre-training models.,2006.15595,cs.CL,2020-06-28 13:11:02+00:00,2021-03-15 07:56:22+00:00
0BaWDGvCa5p,2021,Reject,False,A Provably Convergent and Practical Algorithm for Min-Max Optimization with Applications to GANs,"[""Oren Mangoubi"", ""Sushant Sachdeva"", ""Nisheeth K Vishnoi""]","[""min-max optimization"", ""GANs""]",,,,,
0DALDI-xyW4,2021,Reject,False,A new accelerated gradient method inspired by continuous-time perspective,"[""Yasong Feng"", ""Weiguo Gao""]","[""accelerated gradient method"", ""matrix completion"", ""first-order methods"", ""differential equation""]",We give the precise order of the iterations of Nesterov's accelerated method converging to the solution of derived differential equation and present a new method with application in matrix completion.,,,,
0DLwqQLmqV,2022,Accept (Poster),False,NAS-Bench-Suite: NAS Evaluation is (Now) Surprisingly Easy,"['Yash Mehta', 'Colin White', 'Arber Zela', 'Arjun Krishnakumar', 'Guri Zabergja', 'Shakiba Moradian', 'Mahmoud Safari', 'Kaicheng Yu', 'Frank Hutter']","[""neural architecture search"", ""AutoML""]","We show that you cannot get away only with NAS-Bench-101 and -201; to fix this, we release a unified NAS benchmark suite with 25 benchmarks.",,,,
0DcZxeWfOPt,2022,Accept (Poster),False,Fast Model Editing at Scale,"['Eric Mitchell', 'Charles Lin', 'Antoine Bosselut', 'Chelsea Finn', 'Christopher D Manning']","[""editing"", ""transfomers"", ""meta-learning""]",A computationally efficient approach for learning to edit the behavior of very large pre-trained language models (10 billion+ parameters),,,,
0DecTiJFbm,2022,Reject,False,A New Perspective on Fluid Simulation: An Image-to-Image Translation Task via Neural Networks,"['Roman Lehmann', 'Markus Hoffmann', 'Simon Leufen', 'Wolfgang Karl']","[""cGAN"", ""CFD"", ""Image-to-Image"", ""Fluid Simulation""]",A new perspective on fluid simulation is presented which works directly on the image representation of the solution.  ,,,,
0EJjoRbFEcX,2021,Reject,False,Understanding Classifiers with Generative Models,"[""La\u00ebtitia Shao"", ""Yang Song"", ""Stefano Ermon""]","[""OOD detection"", ""adversarial samples detection"", ""deep learning"", ""classification""]",We show a new characterization of classification mistakes using a generative model learned on the feature space,,,,
0EL4vLgYKRW,2022,Reject,False,Plan Better Amid Conservatism: Offline Multi-Agent Reinforcement Learning with Actor Rectification,"['Ling Pan', 'Longbo Huang', 'Tengyu Ma', 'Huazhe Xu']","[""Multi-Agent Reinforcement Learning (MARL)"", ""Offline reinforcement learning (RL)"", ""Offline Multi-Agent Reinforcement Learning""]","We propose a simple yet effective OMAR algorithm to tackle the offline MARL setting via a combination of first-order policy gradients and zeroth-order optimization methods, which achieves SOTA performance in multi-agent continuous control benchmarks.",2111.11188,cs.LG,2021-11-22 13:27:42+00:00,2021-11-22 13:27:42+00:00
0EXmFzUn5I,2022,Accept (Oral),False,Pyraformer: Low-Complexity Pyramidal Attention for Long-Range Time Series Modeling and Forecasting,"['Shizhan Liu', 'Hang Yu', 'Cong Liao', 'Jianguo Li', 'Weiyao Lin', 'Alex X. Liu', 'Schahram Dustdar']","[""sparse attention"", ""pyramidal graph"", ""Transformer"", ""time series forecasting"", ""long-range dependence"", ""multiresolution""]","We propose a multiresolution pyramidal attention mechanism for long-range dependence modeling and time series forecasting, successfully reducing the maximum length of the signal traversing path to O(1) while achieving linear time and space complexity",,,,
0F_OC_oROWb,2021,Reject,True,RSO: A Gradient Free Sampling Based Approach For Training Deep Neural Networks,"[""Rohun Tripathi"", ""Bharat Singh""]",[],,2005.05955,cs.LG,2020-05-12 17:55:16+00:00,2020-05-12 17:55:16+00:00
0GhVG1de-Iv,2022,Reject,False,Stability and Generalisation in Batch Reinforcement Learning,"['Matthew J. A. Smith', 'Shimon Whiteson']","[""Reinforcement Learning"", ""Algorithmic Stability"", ""Generalisation"", ""Overfitting"", ""Target Network"", ""Fitted TD"", ""Off-Policy"", ""Batch Reinforcement Learning""]",We perform algorithmic stability analysis of a fitted TD algorithm.,,,,
0Hj3tFCSjUd,2021,Reject,True,Energy-based View of Retrosynthesis,"[""Ruoxi Sun"", ""Hanjun Dai"", ""Li Li"", ""Steven Kearnes"", ""Bo Dai""]","[""Applications"", ""Retrosynthesis"", ""Energy-based Model""]",The paper proposed new energy-based methods for retrosynthesis.,2007.13437,physics.chem-ph,2020-07-14 18:51:06+00:00,2020-07-14 18:51:06+00:00
0HkFxvSRDSW,2022,Reject,False,Role Diversity Matters: A Study of Cooperative Training Strategies for Multi-Agent RL,"['Siyi Hu', 'Chuanlong Xie', 'Xiaodan Liang', 'Xiaojun Chang']","[""Multi-agent Reinforcement Learning""]",A Study of Cooperative Training Strategies for Multi-Agent RL based on Role Diversity.,,,,
0IO5VdnSAaH,2021,Accept (Poster),True,On the Universality of the Double Descent Peak in Ridgeless Regression,"[""David Holzm\u00fcller""]","[""Double Descent"", ""Interpolation Peak"", ""Linear Regression"", ""Random Features"", ""Random Weights Neural Networks""]","We prove a distribution-independent lower bound for the generalization error of ridgeless (random) features regression under weak assumptions, showing universal sensitivity to label noise around the interpolation threshold.",2010.01851,stat.ML,2020-10-05 08:30:25+00:00,2021-03-25 10:33:56+00:00
0IOX0YcCdTn,2021,Accept (Poster),False,ALFWorld: Aligning Text and Embodied Environments for Interactive Learning,"[""Mohit Shridhar"", ""Xingdi Yuan"", ""Marc-Alexandre Cote"", ""Yonatan Bisk"", ""Adam Trischler"", ""Matthew Hausknecht""]","[""Textworld"", ""Text-based Games"", ""Embodied Agents"", ""Language Grounding"", ""Generalization"", ""Imitation Learning"", ""ALFRED""]",Pre-training in text-based environments allows agents to learn priors and policies that help solve embodied tasks.,,,,
0J98XyjlQ1,2022,Reject,False,D$^2$-GCN: Data-Dependent GCNs for Boosting Both Efficiency and Scalability,"['Chaojian Li', 'Xu Ouyang', 'Yang Zhao', 'Haoran You', 'Yonggan Fu', 'Yuchen Gu', 'Haonan Liu', 'Siyuan Miao', 'Yingyan Lin']","[""Graph Convolutional Networks"", ""Efficient Networks""]",Data-Dependent GCNs for Boosting Both Efficiency and Scalability,,,,
0JzqUlIVVDd,2022,Accept (Poster),False,KL Guided Domain Adaptation,"['A. Tuan Nguyen', 'Toan Tran', 'Yarin Gal', 'Philip Torr', 'Atilim Gunes Baydin']","[""domain adaptation"", ""invariant representation""]","We derive a generalization bound for the domain adaptation problem based on the reversed KL divergence, and propose to regularize the KL term to lower the generalization bound.",,,,
0Kj5mhn6sw,2022,Reject,False,Gesture2Vec: Clustering Gestures using  Representation Learning Methods for Co-speech Gesture Generation,"['Payam Jome Yazdian', 'Mo Chen', 'Angelica Lim']","[""representation learning"", ""gesture generation"", ""vector quantization"", ""machine translation""]","In this paper, we propose a Gesture2Vec model using representation learning methods to learn the relationship between semantic features and corresponding gestures.",,,,
0LlujmaN0R_,2021,Reject,False,Truthful Self-Play,"[""Shohei Ohsawa""]","[""Comm-POSG"", ""Imaginary Rewards""]",TSP is a general framework for evolutionary learning to emergent unbiased state representation without any supervision. ,,,,
0MjC3uMthAb,2021,Reject,False,Learning Flexible Classifiers with Shot-CONditional Episodic (SCONE) Training,"[""Eleni Triantafillou"", ""Vincent Dumoulin"", ""Hugo Larochelle"", ""Richard Zemel""]","[""few-shot classification"", ""few-shot learning"", ""episodic training"", ""meta-learning""]","We propose a form of episodic training that allows a model to flexibly solve few-shot classification tasks of a wide range of shots, leading to improved performance on a challenging environment.",,,,
0Mo_5PkLpwc,2022,Reject,False,Robust Cross-Modal Semi-supervised Few Shot Learning,['Xu Chen'],"[""few-shot learning"", ""noisy labels"", ""variational inference"", ""cross-modality"", ""uncertainty"", ""robustness""]",A novel robust cross-modal Bayesian semi-supervised few shot learning is presented to jointly tackle outliers and noisy labels simultaneously.,,,,
0N8jUH4JMv6,2021,Accept (Spotlight),True,Implicit Convex Regularizers of CNN Architectures: Convex Optimization of Two- and Three-Layer Networks in Polynomial Time,"[""Tolga Ergen"", ""Mert Pilanci""]","[""Convex optimization"", ""non-convex optimization"", ""group sparsity"", ""$\\ell_1$ norm"", ""convex duality"", ""polynomial time"", ""deep learning""]",We study the training problem for various CNN architectures with ReLU activations and introduce equivalent finite dimensional convex formulations that can be used to globally optimize these architectures.,2006.14798,cs.LG,2020-06-26 04:47:20+00:00,2021-03-18 15:30:26+00:00
0NQdxInFWT_,2021,Reject,False,Active Deep Probabilistic Subsampling,"[""Hans van Gorp"", ""Iris A.M. Huijben"", ""Bastiaan S. Veeling"", ""Nicola Pezzotti"", ""Ruud Van Sloun""]","[""Compressed Sensing"", ""subsampling"", ""active acquisition"", ""accelerated MRI""]","This paper proposes an active extension of the Deep Probabilistic Subsampling framework, which learns to actively pick the next sample based on the information acquired so far.",,,,
0O_cQfw6uEh,2021,Accept (Poster),False,Gradient Origin Networks,"[""Sam Bond-Taylor"", ""Chris G. Willcocks""]","[""Deep Learning"", ""Generative Models"", ""Implicit Representation""]",A new model that uses the negative gradient of the loss with respect to the origin as a latent vector is found to be superior to equivalent networks.,,,,
0OlrLvrsHwQ,2021,Accept (Poster),False,Learning Parametrised Graph Shift Operators,"[""George Dasoulas"", ""Johannes F. Lutzeyer"", ""Michalis Vazirgiannis""]","[""graph neural networks"", ""graph shift operators"", ""graph classification"", ""node classification"", ""graph representation learning""]","We propose a parametrised graph shift operator (PGSO) to encode graph structure, providing a unified view of the most common GSOs, and improve GNN performance by incorporating the PGSO into the model training in an end-to-end manner.",,,,
0PtUPB9z6qK,2021,Accept (Poster),True,Generalized Energy Based Models,"[""Michael Arbel"", ""Liang Zhou"", ""Arthur Gretton""]","[""Sampling"", ""MCMC"", ""Generative Models"", ""Adversarial training"", ""Optimization"", ""Density estimation""]",We introduce the Generalized Energy Based Model (GEBM) for generative modelling. ,2003.05033,stat.ML,2020-03-10 23:22:09+00:00,2020-10-09 20:57:20+00:00
0Q6BzWbvg0P,2022,Reject,False,Less is More: Dimension Reduction Finds On-Manifold Adversarial Examples in Hard-Label Attacks,"['Washington Garcia', 'Pin-Yu Chen', 'Somesh Jha', 'Hamilton Scott Clouse', 'Kevin R. B. Butler']","[""hard-label attacks"", ""adversarial machine learning"", ""generalization""]",,,,,
0RDcd5Axok,2022,Accept (Spotlight),False,Towards a Unified View of Parameter-Efficient Transfer Learning,"['Junxian He', 'Chunting Zhou', 'Xuezhe Ma', 'Taylor Berg-Kirkpatrick', 'Graham Neubig']","[""parameter-efficient transfer learning"", ""unified view"", ""natural language processing""]","We propose a unified framework for several state-of-the-art parameter-efficient tuning methods, ",,,,
0RqDp8FCW5Z,2022,Accept (Poster),False,W-CTC: a Connectionist Temporal Classification Loss with Wild Cards,"['Xingyu Cai', 'Jiahong Yuan', 'Yuchen Bian', 'Guangxu Xun', 'Jiaji Huang', 'Kenneth Church']","[""CTC"", ""wild cards"", ""dynamic programing"", ""partial alignment""]",This paper proposes wild-card CTC to solve the problem that the label only matches middle part of the sequence.,,,,
0SPUQoRMAvc,2021,Reject,False,Semantic-Guided Representation Enhancement for Self-supervised Monocular Trained Depth Estimation,"[""Rui Li"", ""Qing Mao"", ""Pei Wang"", ""Xiantuo He"", ""Yu Zhu"", ""Jinqiu Sun"", ""Yanning Zhang""]","[""Self-supervised depth estimation"", ""semantic-guided depth"", ""multitask learning"", ""semantic-guided attention mechanism""]",,2012.08048,cs.CV,2020-12-15 02:24:57+00:00,2020-12-15 02:24:57+00:00
0SiVrAfIxOe,2022,Reject,False,Closed-Loop Control of Additive Manufacturing via Reinforcement Learning,"['Michal Piovarci', 'Michael Foshey', 'Timothy Erps', 'Jie Xu', 'Vahid Babaei', 'Piotr Didyk', 'Wojciech Matusik', 'Szymon Rusinkiewicz', 'Bernd Bickel']","[""additive manufacturing"", ""closed-loop"", ""reinforcement learning"", ""in-process""]",We propose a numerical model for additive manufacturing that enables learning of closed-loop control policies with minimal sim-to-real gap.,,,,
0Su7gvitc1H,2021,Reject,False,ARMCMC: Online Model Parameters full probability Estimation in Bayesian Paradigm,"[""Pedram Agand"", ""Mo Chen"", ""Hamid D. Taghirad""]","[""Bayesian estimation"", ""Full probability distribution"", ""MCMC"", ""Hybrid non-Gaussian system""]","We propose a novel online MCMC algorithm that effectively estimates parameters for nonlinear models, and achieves improved data efficiency compared to conventional MCMC methods.",,,,
0Tnl8uBHfQw,2022,Reject,False,Deep Classifiers with Label Noise Modeling and Distance Awareness,"['Vincent Fortuin', 'Mark Collier', 'Florian Wenzel', 'James Urquhart Allingham', 'Jeremiah Zhe Liu', 'Dustin Tran', 'Balaji Lakshminarayanan', 'Jesse Berent', 'Rodolphe Jenatton', 'Effrosyni Kokiopoulou']","[""Deep learning"", ""uncertainty estimation"", ""out-of-distribution detection""]",We propose a method for joint modeling of distance-aware epistemic uncertainties and heteroscedastic aleatoric uncertainties.,,,,
0U0C2pXfTZl,2022,Reject,True,SLASH: Embracing Probabilistic Circuits into Neural Answer Set Programming,"['Arseny Skryagin', 'Wolfgang Stammer', 'Daniel Ochs', 'Devendra Singh Dhami', 'Kristian Kersting']","[""Deep Probabilistic Programming Languages"", ""Probabilistic Circuits"", ""Neuro-Symbolic Computations""]","We propose a novel Deep Probabilistic Programming Language which takes advantage of neural computations, true probabilstic estimates and the expressivity of logical statements.",2110.03395,cs.AI,2021-10-07 12:35:55+00:00,2021-11-23 13:47:56+00:00
0UXT6PpRpW,2022,Accept (Poster),False,Large-Scale Representation Learning on Graphs via Bootstrapping,"['Shantanu Thakoor', 'Corentin Tallec', 'Mohammad Gheshlaghi Azar', 'Mehdi Azabou', 'Eva L Dyer', 'Remi Munos', 'Petar VeliÄkoviÄ', 'Michal Valko']",[],,,,,
0VezzBzLmBr,2022,Reject,False,Online Tuning for Offline Decentralized Multi-Agent Reinforcement Learning,"['Jiechuan Jiang', 'Zongqing Lu']","[""multi-agent reinforcement learning""]",,,,,
0WWj8muw_rj,2021,Reject,False,Adaptive Gradient Methods Can Be Provably Faster than SGD with Random Shuffling,"[""Xunpeng Huang"", ""Vicky Jiaqi Zhang"", ""Hao Zhou"", ""Lei Li""]",[],,,,,
0XXpJ4OtjW,2021,Accept (Oral),False,Evolving Reinforcement Learning Algorithms,"[""John D Co-Reyes"", ""Yingjie Miao"", ""Daiyi Peng"", ""Esteban Real"", ""Quoc V Le"", ""Sergey Levine"", ""Honglak Lee"", ""Aleksandra Faust""]","[""reinforcement learning"", ""evolutionary algorithms"", ""meta-learning"", ""genetic programming""]",We meta-learn RL algorithms by evolving computational graphs which compute the loss function for a value-based model-free RL agent to optimize.,,,,
0Zxk3ynq7jE,2021,Reject,False,An Empirical Exploration of Open-Set Recognition via Lightweight Statistical Pipelines,"[""Shu Kong"", ""Deva Ramanan""]","[""open-set recognition"", ""anomaly detection"", ""statistical models"", ""Gaussian Mixture Models"", ""open-world image classification"", ""open-world semantic segmentation""]","The paper proposes an empirical pipeline for open-world recognition based on classic statistical models, which are built on properly processed deep off-the-shelf features and achieve state-of-the-art performance under various setups.",,,,
0_ao8yS2eBw,2021,Reject,True,Solving NP-Hard Problems on Graphs with Extended AlphaGo Zero,"[""Kenshin Abe"", ""Zijian Xu"", ""Issei Sato"", ""Masashi Sugiyama""]","[""Graph neural network"", ""Combinatorial optimization"", ""Reinforcement learning""]",We train graph representation for combinatorial optimization problems without domain knowledge.,1905.11623,cs.LG,2019-05-28 06:04:25+00:00,2020-03-07 14:01:40+00:00
0aW6lYOYB7d,2021,Accept (Poster),False,Large-width functional asymptotics for deep Gaussian neural networks,"[""Daniele Bracale"", ""Stefano Favaro"", ""Sandra Fortini"", ""Stefano Peluchetti""]","[""deep learning theory"", ""infinitely wide neural network"", ""Gaussian process"", ""stochastic process""]",We establish the convergence of infinitely wide feed-forward deep neural networks in function space.,2102.10307,math.PR,2021-02-20 10:14:37+00:00,2021-02-20 10:14:37+00:00
0aZG2VcWLY,2021,Reject,True,Signal Coding and Reconstruction using Spike Trains,"[""Anik Chattopadhyay"", ""Arunava Banerjee""]","[""spike trains"", ""signal encoding"", ""reconstruction"", ""kernel"", ""representer theorem"", ""compression"", ""convolutional matching pursuit"", ""COMP""]"," A mathematical framework for signal encoding and decoding, based on a model of biological neurons, is formulated and its efficacy is established both via mathematical results and through simulation experiments on large corpora of audio signals.",1906.00092,q-bio.NC,2019-05-31 21:53:42+00:00,2019-07-30 19:40:29+00:00
0bXmbOt1oq,2022,Reject,False,Towards Learning to Speak and Hear Through Multi-Agent Communication over a Continuous Acoustic Channel,"['Kevin Michael Eloff', 'Arnu Pretorius', 'Okko RÃ¤sÃ¤nen', 'Herman Arnold Engelbrecht', 'Herman Kamper']","[""multi-agent reinforcement learning"", ""language acquisition"", ""emergent communication"", ""acoustic communication"", ""continuous signalling""]","Using reinforcement learning in a referential game, a Speaker agent and a Listener agent learns to communicate with each other using speech-like continuous signals over an acoustic channel",,,,
0cgU-BZp2ky,2022,Accept (Poster),False,Efficient Learning of Safe Driving Policy via Human-AI Copilot Optimization,"['Quanyi Li', 'Zhenghao Peng', 'Bolei Zhou']","[""Human in the Loop"", ""Safe Reinforcement Learning"", ""Autonomous Driving""]",,,,,
0cmMMy8J5q,2021,Accept (Poster),False,Zero-Cost Proxies for Lightweight NAS,"[""Mohamed S Abdelfattah"", ""Abhinav Mehrotra"", ""\u0141ukasz Dudziak"", ""Nicholas Donald Lane""]","[""NAS"", ""AutoML"", ""proxy"", ""pruning"", ""efficient""]",A single minibatch of data is used to score neural networks for NAS instead of performing full training.,,,,
0d1mLPC2q2,2022,Reject,False,Understanding the Success of Knowledge Distillation -- A Data Augmentation Perspective,"['Huan Wang', 'Suhas Lohit', 'Michael Jeffrey Jones', 'Yun Fu']","[""knowledge distillation"", ""data augmentation"", ""mixup"", ""cutmix"", ""model compression"", ""active learning""]",We explain the success of knowledge distillation (KD) from the data augmentation (DA) perspective: KD can take more advantage of DA than the cross-entropy loss.,,,,
0fqoSxXBwI6,2021,Reject,False,Self-Supervised Multi-View Learning via Auto-Encoding 3D Transformations,"[""Xiang Gao"", ""Wei Hu"", ""Guo-Jun Qi""]","[""Self-supervised Learning"", ""Multi-View Learning""]",,2103.00787,cs.CV,2021-03-01 06:24:17+00:00,2021-03-01 06:24:17+00:00
0gfSzsRDZFw,2021,Reject,False,Ablation Path Saliency,"[""Olivier Verdier"", ""Justus Sagem\u00fcller""]","[""image classification"", ""interpretability"", ""feature attribution"", ""saliency"", ""ablation""]",Understanding decisions by ablating as much of the input as possible without changing classification,,,,
0h9cYBqucS6,2021,Reject,False,Communication-Computation Efficient Secure Aggregation for Federated Learning,"[""Beongjun Choi"", ""Jy-yong Sohn"", ""Dong-Jun Han"", ""Jaekyun Moon""]","[""Federated Learning"", ""Privacy"", ""Graphs"", ""Secure Aggregation"", ""Communication-Efficient"", ""Computation-Efficient""]","Inspired by graph theory, we suggest communication-computation efficient secure aggregation (CCESA) which maintains the privacy of federated learning by using significantly reduced communication/computational resources than the conventional wisdom.",,,,
0jP2n0YFmKG,2022,Accept (Poster),False,Towards Training Billion Parameter Graph Neural Networks for Atomic Simulations,"['Anuroop Sriram', 'Abhishek Das', 'Brandon M Wood', 'C. Lawrence Zitnick']","[""Graph Neural Networks"", ""Atomic Simulations"", ""Computational Chemistry""]",We scale GNNs used for modeling atomic simulations by an order of magnitude and obtain large performance improvements on the Open Catalyst 2020 dataset.,,,,
0jPp4dKp3PL,2021,Reject,False,Integrating linguistic knowledge into DNNs: Application to online grooming detection,"[""Jay Morgan"", ""Adeline Paiement"", ""Nuria Lorenzo-Dus"", ""Anina Kinzel"", ""Matteo Di Cristofaro""]","[""Machine Learning"", ""Corpus Linguistics""]",Incorporating Corpus Linguistic knowledge in Deep Learning models to create accurate and interpretable models.,,,,
0kNbTghw7q,2022,Reject,False,Improving Generative Adversarial Networks via Adversarial Learning in Latent Space,"['Yang Li', 'Yichuan Mo', 'Liangliang Shi', 'Junchi Yan', 'Xiaolu Zhang', 'JUN ZHOU']","[""Generative Adversarial Networks"", ""Adversarial Traing"", ""Latent Space""]",Improve the performance of GAN in terms of generative quality and diversity by mining the latent space using adversarial learning.,,,,
0kPL3xO4R5,2022,Accept (Poster),False,Fast topological clustering with Wasserstein distance,"['Tananun Songdechakraiwut', 'Bryan M Krause', 'Matthew I Banks', 'Kirill V Nourski', 'Barry D Van Veen']","[""Topological data analysis"", ""cluster analysis"", ""persistent homology"", ""Wasserstein distance"", ""Wasserstein barycenter"", ""brain networks"", ""intracranial electrophysiology"", ""consciousness""]","In this paper, we propose a novel and computationally practical topological clustering method that clusters complex networks with intricate topology using principled theory from persistent homology and optimal transport.",,,,
0lSoIruExF,2022,Reject,False,Incorporating User-Item Similarity in Hybrid Neighborhood-based Recommendation System,"['Nghia Duong Tan', 'Giang Do Truong', 'Nam Doan Nguyen', 'Nghia Cao Tuan', 'Hoang Tran Manh', 'Minh Nguyen Duc', 'Hieu Dang Quang']","[""Recommendation system"", ""Neighborhood-based"", ""Collaborative filtering"", ""Data mining""]","This paper proposes various novel methods to learn user interests from their interactions, which are applied to estimate the user-item correlations to improve neighborhood-based collaborative filtering systems.",,,,
0m4c9ZfDrDt,2022,Reject,False,Generalizing Successor Features to continuous domains for Multi-task Learning,"['Melissa Mozifian', 'Dieter Fox', 'David Meger', 'Fabio Ramos', 'Animesh Garg']","[""Reinforcement learning"", ""multi-task learning"", ""representation learning""]",Successor feature framework extension to continuous control for multi-task learning,,,,
0migj5lyUZl,2021,Reject,False,A Strong On-Policy Competitor To PPO,"[""Xiangxiang Chu""]","[""proximal policy optimization"", ""deep reinforcement learning""]",a simple and effective reinforment learning algorithm that is comparable to PPO,,,,
0n1UvVzW99x,2022,Reject,False,Synthetic Reduced Nearest Neighbor Model for Regression,"['Pooya Tavallali', 'Vahid Behzadan', 'Mukesh Singhal']","[""Regression"", ""Nearest Neighbor"", ""Prototype Learning"", ""Prototype Nearest Neighbor""]",We propose a novel regression technique based on the Synthetic Reduced Nearest Neighbor approach.,,,,
0n3BaVlNsHI,2021,Reject,False,DJMix: Unsupervised Task-agnostic Augmentation for Improving Robustness,"[""Ryuichiro Hataya"", ""Hideki Nakayama""]","[""robustness"", ""uncertainty"", ""discretization"", ""data augmentation""]",We propose a task-agnostic data augmentation method to make CNN models robust to test-time noise on images,,,,
0naHZ3gZSzo,2021,Reject,False,Optimizing Large-Scale Hyperparameters via Automated Learning Algorithm,"[""Bin Gu"", ""Guodong Liu"", ""Yanfu Zhang"", ""Xiang Geng"", ""Heng Huang""]",[],,2102.09026,cs.LG,2021-02-17 21:03:05+00:00,2021-02-17 21:03:05+00:00
0no8Motr-zO,2022,Accept (Poster),False,An Experimental Design Perspective on Exploration in Reinforcement Learning,"['Viraj Mehta', 'Biswajit Paria', 'Jeff Schneider', 'Willie Neiswanger', 'Stefano Ermon']","[""reinforcement learning"", ""acquisition function"", ""information gain""]",We draw a connection between Bayesian Optimal Experiment Design and RL to develop an acquisition function to guide data collection in model based RL leading to improved sample efficiency.,,,,
0oSM3TC9Z5a,2022,Reject,False,Learning to Persuade,"['Xiaodong Liu', 'Zhikang Fan', 'Xun Wang', 'Weiran Shen']",[],,,,,
0oabwyZbOu,2021,Accept (Poster),False,Mastering Atari with Discrete World Models,"[""Danijar Hafner"", ""Timothy P Lillicrap"", ""Mohammad Norouzi"", ""Jimmy Ba""]","[""Atari"", ""world models"", ""model-based reinforcement learning"", ""reinforcement learning"", ""planning"", ""actor critic""]",DreamerV2 is the first agent based on a world model to achieve human-level performance on the Atari benchmark.,,,,
0owsv3F-fM,2021,Reject,False,Cross-Modal Domain Adaptation for Reinforcement Learning,"[""Xiong-Hui Chen"", ""Shengyi Jiang"", ""Feng Xu"", ""Yang Yu""]","[""Domain Adaptation"", ""Reinforcement Learning""]","By fully leveraging the sequential information in the trajectories and incorporating the policy to guide the training process, our method realizes cross-modal domain adaptation in RL settings.",,,,
0p-aRvcVs-U,2021,Reject,False,$\alpha$VIL: Learning to Leverage Auxiliary Tasks for Multitask Learning,"[""Rafael Kourdis"", ""Gabriel Gordon-Hall"", ""Philip John Gorinski""]","[""multitask learning"", ""meta-optimization"", ""deep learning""]",We use a metaoptimization approach to tweak task-specific weights in multitask learning settings.,,,,
0pxiMpCyBtr,2021,Accept (Poster),False,Monotonic Kronecker-Factored Lattice,"[""William Taylor Bakst"", ""Nobuyuki Morioka"", ""Erez Louidor""]","[""Theory"", ""Regularization"", ""Algorithms"", ""Classification"", ""Regression"", ""Matrix and Tensor Factorization"", ""Fairness"", ""Evaluation"", ""Efficiency"", ""Machine Learning""]","We show how to effectively and efficiently learn flexible and interpretable monotonic functions using Kronecker-Factored Lattice, an efficient reparameterization of flexible monotonic lattice regression via Kronecker product.",,,,
0q0REJNgtg,2022,Reject,False,Retrieval-Augmented Reinforcement Learning,"['Anirudh Goyal', 'Abram L. Friesen', 'Theophane Weber', 'Andrea Banino', 'Nan Rosemary Ke', 'Adria Puigdomenech Badia', 'Ksenia Konyushkova', 'Michal Valko', 'Simon Osindero', 'Timothy P Lillicrap', 'Nicolas Heess', 'Charles Blundell']","[""replay buffer"", ""reinforcement learning"", ""offline RL"", ""attention""]",Augment the RL agent with the helper process which helps the RL agent achieve goals faster and in a more efficient way,,,,
0qbEq5UBfGD,2021,Reject,False,Latent Space Semi-Supervised Time Series Data Clustering,"[""Andrew Hill"", ""Katerina Kechris"", ""Russell Bowler"", ""Farnoush Kashani""]","[""Semi-supervised clustering"", ""clustering"", ""deep learning"", ""autoencoder""]",,,,,
0rNLjXgchOC,2021,Reject,False,Dissecting Hessian: Understanding Common Structure of Hessian in Neural Networks,"[""Yikai Wu"", ""Xingyu Zhu"", ""Chenwei Wu"", ""Annie N. Wang"", ""Rong Ge""]","[""Hessian"", ""neural network"", ""Kronecker factorization"", ""PAC-Bayes bound"", ""eigenspace"", ""eigenvalue""]","We investigate several interesting structures of layer-wise Hessian by approximating the Hessian using Kronecker factorization, and provide a nonvacuous PAC-Bayes generalization bound using the approximated Hessian eigenbasis.",,,,
0rcbOaoBXbg,2022,Accept (Poster),False,Neural Spectral Marked Point Processes,"['Shixiang Zhu', 'Haoyun Wang', 'Zheng Dong', 'Xiuyuan Cheng', 'Yao Xie']",[],,,,,
0rjx6jy25R4,2022,Reject,False,Classify and Generate Reciprocally: Simultaneous Positive-Unlabelled Learning and Conditional Generation with Extra Data,"['Bing Yu', 'Ke Sun', 'He Wang', 'Zhanxing Zhu', 'Zhouchen Lin']","[""PU learning"", ""Robust Generative Models"", ""Lable noises""]",We present a novel training framework to jointly target both PU classification and conditional generation when exposing to extra data.,,,,
0sEIBFb4cs,2022,Reject,False,Practical Adversarial Attacks on Brain--Computer Interfaces,"['Rodolfo Octavio Siller Quintanilla', 'Xiaying Wang', 'Michael Hersche', 'Luca Benini', 'Gagandeep Singh']","[""neuroscience"", ""brain-computer interfaces"", ""practical attacks"", ""adversarial attacks"", ""EEGNet"", ""edge computing"", ""embedded systems""]",We show that state-of-the-art deep learning-based BCIs are vulnerable to practical attacks.,,,,
0sgntlpKDOz,2022,Accept (Poster),False,Learning Graphon Mean Field Games and Approximate Nash Equilibria,"['Kai Cui', 'Heinz Koeppl']","[""Mean Field Games"", ""Reinforcement Learning"", ""Multi Agent Systems""]","We propose, analyze and solve a novel, theoretically well-founded graph-based mean field game for Nash equilibria in discrete-time dynamical systems on otherwise infeasibly large dense graphs. ",2112.01280,cs.GT,2021-11-29 16:16:11+00:00,2021-12-17 13:15:59+00:00
0uZu36la_y4,2022,Reject,False,Protect the weak: Class focused online learning for adversarial training,"['Thomas Pethick', 'Grigorios Chrysos', 'Volkan Cevher']","[""Adversarial training"", ""Adversarial examples"", ""Minimax"", ""Robustness""]","We observe that the worst class can have much lower accuracy than the average class in adversarial examples, which we mitigate by solving a minmax formulation with tools from the bandit literature.",,,,
0vO-u0sucRF,2021,Reject,False,Information Theoretic Meta Learning with Gaussian Processes,"[""Michalis Titsias"", ""Sotirios Nikoloutsopoulos"", ""Alexandre Galashov""]","[""Meta Learning"", ""Information Bottleneck"", ""Gaussian Processes"", ""Few-shot learning"", ""Variational Inference""]",Meta learning using information bottleneck and combination of memory and gradient-based techniques using Gaussian processes. ,,,,
0xdQXkz69x9,2021,Reject,False,Attacking Few-Shot Classifiers with Adversarial Support Sets,"[""Elre Talea Oldewage"", ""John F Bronskill"", ""Richard E Turner""]","[""meta-learning"", ""few-shot learning"", ""adversarial attacks"", ""poisoning""]","We introduce an effective, novel adversarial attack called an Adversarial Support Set Attack that poisons the support set of trained few-shot learners to cause failure with high probability on unseen queries at test time.",,,,
0xiJLKH-ufZ,2022,Accept (Oral),False,Analytic-DPM: an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models,"['Fan Bao', 'Chongxuan Li', 'Jun Zhu', 'Bo Zhang']","[""diffusion probabilistic models"", ""generative models""]",We propose an analytic framework of estimating the optimal reverse variance in DPMs.,,,,
0z1HScLBEpb,2021,Reject,False,UneVEn: Universal Value Exploration for Multi-Agent Reinforcement Learning,"[""Tarun Gupta"", ""Anuj Mahajan"", ""Bei Peng"", ""Wendelin Boehmer"", ""Shimon Whiteson""]","[""multi-agent reinforcement learning"", ""deep Q-learning"", ""universal value functions"", ""successor features"", ""relative overgeneralization""]",We propose universal value exploration (UneVEn) for multi-agent reinforcement learning (MARL) to address the suboptimal approximations of employed monotonic joint-action value function in current SOTA value-based MARL methods on non-monotonic tasks.,,,,
0ze7XgWcYNV,2022,Reject,False,Learning When and What to Ask: a Hierarchical Reinforcement Learning Framework,"['Khanh Xuan Nguyen', 'Yonatan Bisk', 'Hal DaumÃ© III']","[""human-agent interaction"", ""reinforcement learning"", ""navigation""]",A hierarchical reinforcement learning framework for learning when to ask questions and what to ask,,,,
0zvfm-nZqQs,2021,Accept (Spotlight),False,Undistillable: Making A Nasty Teacher That CANNOT teach students,"[""Haoyu Ma"", ""Tianlong Chen"", ""Ting-Kuei Hu"", ""Chenyu You"", ""Xiaohui Xie"", ""Zhangyang Wang""]","[""knowledge distillation"", ""avoid knowledge leaking""]","We propose the Nasty Teacher, a defensive approach to prevent unauthorized cloning from a teacher model through knowledge distillation. ",2105.07381,cs.LG,2021-05-16 08:41:30+00:00,2021-05-16 08:41:30+00:00
1-Mh-cWROZ,2021,Reject,False,Fold2Seq: A Joint Sequence(1D)-Fold(3D) Embedding-based Generative Model for Protein Design,"[""Yue Cao"", ""Payel Das"", ""Pin-Yu Chen"", ""Vijil Chenthamarakshan"", ""Igor Melnyk"", ""Yang Shen""]","[""Joint Embedding Learning"", ""Generative Model"", ""Transformer Autoencoder"", ""Inverse Protein Folding"", ""Sequence Design""]",A novel transformer-based generative model for learning joint sequence-fold embedding and designing protein sequences shows superior performance and efficiency against existing methods.,,,,
1-YP2squpa7,2022,Reject,False,Deep learning via message passing algorithms based on belief propagation,"['Fabrizio Pittorino', 'Carlo Lucibello', 'Gabriele Perugini', 'Riccardo Zecchina']","[""belief propagation"", ""neural networks"", ""graphical models"", ""gradient-free algorithms"", ""discrete neural networks""]",Deep learning via message passing algorithms based on belief propagation.,,,,
1-j4VLSHApJ,2021,Reject,False,Learn2Weight: Weights Transfer Defense against Similar-domain Adversarial Attacks,"[""Siddhartha Datta""]","[""adversarial attack"", ""robustness"", ""domain adaptation"", ""privacy-preserving machine learning""]","We introduce Learn2Weight, a defense inspired by weights transfer learning, to defend against adversarial attacks that leverage domain similarities.",,,,
1-lFH8oYTI,2022,Reject,False,Calibration Regularized Training of Deep Neural Networks using Kernel Density Estimation,"['Teodora Popordanoska', 'Raphael Sayer', 'Matthew B. Blaschko']","[""calibration"", ""dirichlet kernel density estimation""]",We propose a consistent and differentiable estimator of an Lp calibration error using Dirichlet kernels which can be directly optimized alongside any loss function.,,,,
10XWPuAro86,2021,Reject,False,Hamiltonian Q-Learning: Leveraging Importance-sampling for Data Efficient RL,"[""Udari Madhushani"", ""Biswadip Dey"", ""Naomi Leonard"", ""Amit Chakraborty""]","[""Data efficient RL"", ""$Q$-Learning"", ""Hamiltonian Monte Carlo""]","We propose a data efficient modification of the $Q$-learning approach which uses Hamiltonian Monte Carlo to compute $Q$ function for problems with stochastic, high-dimensional dynamics.",,,,
12RoR2o32T,2022,Accept (Poster),False,Predictive Modeling in the Presence of Nuisance-Induced Spurious Correlations,"['Aahlad Manas Puli', 'Lily H Zhang', 'Eric Karl Oermann', 'Rajesh Ranganath']","[""spurious correlations"", ""out of distribution generalization"", ""ml for health"", ""representation learning""]","This paper build models robust to nuisance-induced spurious correlations by constructing a representation that distills out the influence of the nuisance variables, while also maximizing its information with the label.",,,,
14F3fI6MGxX,2022,Accept (Poster),False,A Generalized Weighted Optimization Method for Computational Learning and Inversion,"['Kui Ren', 'Yunan Yang', 'BjÃ¶rn Engquist']","[""weighted optimization"", ""generalization error"", ""feature regression"", ""machine learning""]","This paper proposes a generalized weighted optimization method for computational learning and inversion with noisy data and derives generalization error bounds for various feature regression models, demonstrating better generalization capabilities.",2201.09223,cs.LG,2022-01-23 10:35:34+00:00,2022-01-23 10:35:34+00:00
14kbUbOaZUc,2022,Reject,False,Metric Learning on Temporal Graphs via Few-Shot Examples,"['Dongqi Fu', 'Liri Fang', 'Ross Maciejewski', 'Vetle I Torvik', 'Jingrui He']","[""Metric Learning"", ""Few-Shot Learning"", ""Temporal Graph""]","The first attempt to learn temporal graph representations, on the graph-level, covering the whole lifetime, and only consuming a few labeled samples. ",,,,
14nC8HNd4Ts,2021,Reject,True,Synthesising Realistic Calcium Traces of Neuronal Populations Using GAN,"[""Bryan M. Li"", ""Theoklitos Amvrosiadis"", ""Nathalie Rochefort"", ""Arno Onken""]","[""calcium imaging"", ""calcium traces"", ""generative adversarial networks"", ""spike train analysis""]",Synthesising in vivo calcium traces from live animal using GAN,2009.02707,q-bio.NC,2020-09-06 10:58:11+00:00,2020-09-08 03:58:43+00:00
160xFQdp7HR,2021,Reject,False,Self-Organizing Intelligent Matter:  A blueprint for an AI generating algorithm,"[""Karol Gregor"", ""Frederic Besse""]","[""Artificial Life"", ""AI Generating Algorithms""]",We propose an artificial life framework of interacting neural elements as a basis of an AI generating algorithm.,2101.07627,cs.NE,2021-01-19 14:02:54+00:00,2021-01-19 14:02:54+00:00
17VnwXYZyhH,2021,Accept (Poster),False,Probing BERT in Hyperbolic Spaces,"[""Boli Chen"", ""Yao Fu"", ""Guangwei Xu"", ""Pengjun Xie"", ""Chuanqi Tan"", ""Mosha Chen"", ""Liping Jing""]","[""Hyperbolic"", ""BERT"", ""Probe"", ""Syntax"", ""Sentiment""]",We propose a PoincarÃ© probe for finding syntax and sentiments from BERT in hyperbolic spaces.,2104.03869,cs.CL,2021-04-08 16:24:53+00:00,2021-04-08 16:24:53+00:00
18Ys0-PzyPI,2022,Accept (Poster),False,Online Ad Hoc Teamwork under Partial Observability,"['Pengjie Gu', 'Mengchen Zhao', 'Jianye Hao', 'Bo An']","[""coordination"", ""reinforcement learning""]",,,,,
193sEnKY1ij,2021,Accept (Poster),False,No Cost Likelihood Manipulation at Test Time for Making Better Mistakes in Deep Networks,"[""Shyamgopal Karthik"", ""Ameya Prabhu"", ""Puneet K. Dokania"", ""Vineet Gandhi""]","[""Hierarchy-Aware Classification"", ""Conditional Risk Minimization"", ""Post-Hoc Correction""]",Conditional risk framework exploiting the label hierarchy outperforms state of the art and makes a strong baseline for future explorations.,2104.00795,cs.LG,2021-04-01 22:40:25+00:00,2021-04-01 22:40:25+00:00
19drPzGV691,2021,Reject,False,Distributional Reinforcement Learning for Risk-Sensitive Policies,"[""Shiau Hong Lim"", ""Ilyas Malik""]",[],,,,,
1AoMhc_9jER,2021,Accept (Poster),False,GANs Can Play Lottery Tickets Too,"[""Xuxi Chen"", ""Zhenyu Zhang"", ""Yongduo Sui"", ""Tianlong Chen""]","[""lottery tickets"", ""GAN compression"", ""generative adversarial networks""]","Winning tickets exist in the deep generative adversarial networks, which substantially outperform previous state-of-the-art compressed GAN",2106.00134,cs.LG,2021-05-31 23:03:00+00:00,2021-05-31 23:03:00+00:00
1AyPW2Emp6,2021,Reject,False,Tight Second-Order Certificates for Randomized Smoothing,"[""Alexander Levine"", ""Aounon Kumar"", ""Tom Goldstein"", ""Soheil Feizi""]","[""certificates"", ""adversarial"", ""robustness"", ""defenses"", ""smoothing"", ""curvature""]",We provide a tight robustness certificate for Gaussian smoothed classifiers using the gradient of the smoothed classifier in addition to its value.,,,,
1DUwCRNAbA,2022,Reject,False,An Investigation into the Role of Author Demographics in ICLR Participation and Review,"['Keshav Ganapathy', 'Emily Liu', 'Zain Zarger', 'Gowthami Somepalli', 'Micah Goldblum', 'Tom Goldstein']","[""Conference Review"", ""OpenReview"", ""Gender"", ""Bias"", ""Fairness""]",,,,,
1EVb8XRBDNr,2021,Reject,False,RMIX: Risk-Sensitive Multi-Agent Reinforcement Learning,"[""Wei Qiu"", ""Xinrun Wang"", ""Runsheng Yu"", ""Xu He"", ""Rundong Wang"", ""Bo An"", ""Svetlana Obraztsova"", ""Zinovi Rabinovich""]","[""Risk-sensitive learning"", ""cooperative multi-agent reinforcement learning"", ""reinforcement learning""]",We propose a novel risk-sensitive cooperative MARL method with CVaR measure over the learned return distributions to enhance multi-agent coordination.,,,,
1Fqg133qRaI,2021,Accept (Poster),False,Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis,"[""Bingchen Liu"", ""Yizhe Zhu"", ""Kunpeng Song"", ""Ahmed Elgammal""]","[""deep learning"", ""generative model"", ""image synthesis"", ""few-shot learning"", ""generative adversarial network"", ""self-supervised learning"", ""unsupervised learning""]","A computational-efficient GAN for few-shot hi-fi image dataset (converge on single gpu with few hours' training, on 1024 resolution sub-hundred images).",2101.04775,cs.CV,2021-01-12 22:02:54+00:00,2021-01-12 22:02:54+00:00
1FvkSpWosOl,2021,Accept (Poster),False,Is Attention Better Than Matrix Decomposition?,"[""Zhengyang Geng"", ""Meng-Hao Guo"", ""Hongxu Chen"", ""Xia Li"", ""Ke Wei"", ""Zhouchen Lin""]","[""attention models"", ""matrix decomposition"", ""computer vision""]",,2109.04553,cs.CV,2021-09-09 20:40:19+00:00,2021-09-09 20:40:19+00:00
1GTma8HwlYp,2021,Accept (Poster),False,"AUXILIARY TASK UPDATE DECOMPOSITION: THE GOOD, THE BAD AND THE NEUTRAL","[""Lucio M. Dery"", ""Yann Dauphin"", ""David Grangier""]","[""pre-training"", ""multitask learning"", ""deeplearning"", ""gradient decomposition""]",We improve how we use auxiliary task data for model pre-training by decomposing gradient updates into components guided by the primary task,2108.11346,cs.LG,2021-08-25 17:09:48+00:00,2021-08-25 17:09:48+00:00
1HxTO6CTkz,2022,Accept (Spotlight),False,Unifying Likelihood-free Inference with Black-box Sequence Design and Beyond,"['Dinghuai Zhang', 'Jie Fu', 'Yoshua Bengio', 'Aaron Courville']","[""biological sequence design"", ""black-box optimization"", ""likelihood-free inference"", ""Bayesian inference""]",We propose a framework to unify likelihood-free inference and black-box sequence design and further propose novel sequence design algorithms based on the framework.,,,,
1IBgFQbj7y,2021,Reject,False,Maximum Categorical Cross Entropy (MCCE): A noise-robust alternative loss function to mitigate racial bias in Convolutional Neural Networks (CNNs) by reducing overfitting,"[""Nidhi Gowdra"", ""Roopak Sinha"", ""Stephen MacDonell"", ""WeiQi Yan""]",[],,,,,
1JDiK_TbV4S,2022,Accept (Spotlight),False,Source-Free Adaptation to Measurement Shift via Bottom-Up Feature Restoration,"['Cian Eastwood', 'Ian Mason', 'Chris Williams', 'Bernhard SchÃ¶lkopf']","[""Transfer learning"", ""dataset shift"", ""unsupervised domain adaptation"", ""source-free domain adaptation""]",We identify a type of domain shift which can be resolved by restoring the *same* features and address it in the source-free setting by using softly-binned histograms to cheaply and flexibly align the marginal feature distributions.,,,,
1JN7MepVDFv,2022,Reject,False,On the relationship between disentanglement and multi-task learning,"['Lukasz Maziarka', 'Aleksandra Nowak', 'Maciej Wolczyk', 'Andrzej Bedychaj']","[""disentanglement representations"", ""multi-task learning""]","In our work, we study the relationship between the multi-task learning and disentanglement representations.",,,,
1Jv6b0Zq3qi,2021,Accept (Poster),True,Uncertainty in Gradient Boosting via Ensembles,"[""Andrey Malinin"", ""Liudmila Prokhorenkova"", ""Aleksei Ustimenko""]","[""uncertainty"", ""ensembles"", ""gradient boosting"", ""decision trees"", ""knowledge uncertainty""]",Propose and analyze an ensemble-based framework for deriving uncertainty estimates in GBDT models.,2006.10562,cs.LG,2020-06-18 14:11:27+00:00,2021-04-02 09:00:20+00:00
1Kxxduqpd3E,2021,Reject,False,Rotograd: Dynamic Gradient Homogenization for Multitask Learning,"[""Adri\u00e1n Javaloy"", ""Isabel Valera""]","[""multitask learning"", ""deep learning"", ""gradnorm""]",Rotograd is a gradient based multitask learning approach that dynamically homogenizes the gradient magnitudes and directions across tasks.,,,,
1L0C5ROtFp,2022,Accept (Oral),False,Filtered-CoPhy: Unsupervised Learning of Counterfactual Physics in Pixel Space,"['Steeven JANNY', 'Fabien Baradel', 'Natalia Neverova', 'Madiha Nadri', 'Greg Mori', 'Christian Wolf']",[],,2202.00368,cs.CV,2022-02-01 12:18:30+00:00,2022-02-01 12:18:30+00:00
1MJPtHogkwX,2021,Reject,False,A Multi-Modal and Multitask Benchmark in the Clinical Domain,"[""Yong Huang"", ""Edgar Mariano Marroquin"", ""Volodymyr Kuleshov""]","[""multi-modal"", ""multitask"", ""machine learning in healthcare"", ""benchmark""]",We introduce Multi-Modal Multitask MIMIC-III Benchmark (M3) --- a dataset and benchmark for evaluating machine learning algorithms in the healthcare domain.,,,,
1NRMmEUyXMu,2021,Reject,False,World Model as a Graph: Learning Latent Landmarks for Planning,"[""Lunjun Zhang"", ""Ge Yang"", ""Bradly C Stadie""]","[""Reinforcement Learning"", ""Planning""]",Graph-structured world models that enable RL agents to do temporally extended reasoning.,,,,
1NUsBU-7HAL,2022,Accept (Poster),False,Map Induction: Compositional spatial submap learning for efficient exploration in novel environments,"['Sugandha Sharma', 'Aidan Curtis', 'Marta Kryven', 'Joshua B. Tenenbaum', 'Ila R Fiete']","[""Cognitive Science"", ""Bayesian Framework"", ""Program Induction"", ""Spatial Navigation"", ""Planning"", ""Map Learning""]",Modelling Map Induction for efficient exploration in novel environments. ,,,,
1NvflqAdoom,2022,Accept (Poster),True,Neural Networks as Kernel Learners: The Silent Alignment Effect,"['Alexander Atanasov', 'Blake Bordelon', 'Cengiz Pehlevan']","[""Neural Tangent Kernel"", ""Feature Learning"", ""Inductive Bias of Neural Networks""]","Neural networks with small initialization, trained in the rich feature learning regime, can learn kernel regression solutions for a data adaptive kernel.",2111.00034,stat.ML,2021-10-29 18:22:46+00:00,2021-12-02 21:06:20+00:00
1O5UK-zoK8g,2022,Reject,False,Adaptive Generalization for Semantic Segmentation,"['Sherwin Bahmani', 'Oliver Hahn', 'Eduard Sebastian Zamfir', 'Nikita Araslanov', 'Stefan Roth']","[""domain generalization"", ""semantic segmentation"", ""test-time training""]",A study of a test-time training approach for improved generalization of semantic segmentation models,,,,
1OCTOShAmqB,2021,Accept (Poster),False,On the Dynamics of Training Attention Models,"[""Haoye Lu"", ""Yongyi Mao"", ""Amiya Nayak""]",[],,,,,
1OCwJdJSnSA,2021,Reject,False,Disentangled cyclic reconstruction for domain adaptation,"[""David Bertoin"", ""Emmanuel Rachelson""]","[""Domain adaptation"", ""Disentanglement""]","We tackle unsupervised domain adaptation by intra-domain and cross-domain cyclic reconstruction and achieve efficient representation disentanglement, including in the target domain.",,,,
1OHZX4YDqhT,2022,Reject,False,FedNAS: Federated Deep Learning via Neural Architecture Search,"['Chaoyang He', 'Erum Mushtaq', 'Jie Ding', 'Salman Avestimehr']",[],,,,,
1OP1kReyL56,2021,Reject,False,Model Selection for Cross-Lingual Transfer using a Learned Scoring Function,"[""Yang Chen"", ""Alan Ritter""]",[],,,,,
1OQ90khuUGZ,2021,Reject,False,Action Guidance: Getting the Best of Sparse Rewards and Shaped Rewards for Real-time Strategy Games,"[""Shengyi Huang"", ""Santiago Ontanon""]","[""reinforcement learning"", ""real-time strategy games"", ""sparse rewards"", ""shaped rewards"", ""policy gradient"", ""sample-efficiency""]",Training agents to eventually optimize the real objective without losing the sample efficiency of reward shaping.,,,,
1P2KAvsE59b,2021,Reject,False,Robustness to Pruning Predicts Generalization in Deep Neural Networks,"[""Lorenz Kuhn"", ""Clare Lyle"", ""Aidan Gomez"", ""Jonas Rothfuss"", ""Yarin Gal""]","[""Generalization"", ""Pruning"", ""Generalization Measures""]",We demonstrate empirically that a neural network's robustness to pruning is highly predictive of its generalization performance.,,,,
1Q-CqRjUzf,2021,Reject,False,On the Reproducibility of Neural Network Predictions,"[""Srinadh Bhojanapalli"", ""Kimberly Jenney Wilber"", ""Andreas Veit"", ""Ankit Singh Rawat"", ""Seungyeon Kim"", ""Aditya Krishna Menon"", ""Sanjiv Kumar""]","[""reproducibility"", ""churn"", ""confidence""]",We propose new methods to reduce model  churn and improve reproducibility of predictions for classification,,,,
1QxveKM654,2022,Reject,False,Genome Sequence Reconstruction Using Gated Graph Convolutional Network,"['Lovro VrÄek', 'Robert Vaser', 'Thomas Laurent', 'Mile Sikic', 'Xavier Bresson']","[""genome assembly"", ""graph neural networks"", ""assembly graph"", ""path finding""]","We train a graph convolutional network to find a path through an assembly graph, which could reduce fragmentation and execution time of the existing genome assemblers.",,,,
1R_PRbQK2eu,2022,Reject,False,Dual Training of Energy-Based Models with Overparametrized Shallow Neural Networks,"['Carles Domingo-Enrich', 'Alberto Bietti', 'Marylou GabriÃ©', 'Joan Bruna', 'Eric Vanden-Eijnden']","[""energy-based models"", ""generative modeling"", ""neural networks"", ""duality"", ""Fenchel"", ""maximum mean discrepancy"", ""maximum likelihood"", ""active"", ""lazy"", ""score matching"", ""measure"", ""feature""]","We derive dual algorithms to train maximum likelihoods EBMs with shallow overparametrized neural network energies, incorporating score matching in our framework.",,,,
1T5FmILBsq2,2022,Reject,False,SGORNN: Combining Scalar Gates and Orthogonal Constraints in Recurrent Networks,"['William Keith Taylor-Melanson', 'Martha Dais Ferreira', 'Stan Matwin']","[""Deep Learning"", ""Recurrent Neural Networks"", ""Exploding Gradient Problem"", ""Deep Learning Generalization"", ""Orthogonal RNNs""]",,,,,
1TIrbngpW0x,2021,Reject,False,Transformers with Competitive Ensembles of Independent Mechanisms,"[""Alex Lamb"", ""Di He"", ""Anirudh Goyal"", ""Guolin Ke"", ""Chien-Feng Liao"", ""Mirco Ravanelli"", ""Yoshua Bengio""]","[""transformer"", ""mechanism"", ""modularity"", ""modules"", ""independence""]","Transformers with Independent Mechanisms which have separate parameters, share information through attention, and specialize over positions.  ",2103.00336,cs.LG,2021-02-27 21:48:46+00:00,2021-02-27 21:48:46+00:00
1UtnrqVUeNE,2021,Reject,True,Detecting Misclassification Errors in Neural Networks with a Gaussian Process Model,"[""Xin Qiu"", ""Risto Miikkulainen""]","[""Neural Network Classifier"", ""Error Detection"", ""AI safety""]",This paper presents a Gaussian-Processes-based framework that generates more reliable confidence scores for detecting misclassification errors in Neural Network Classifiers.,2010.02065,cs.LG,2020-10-05 15:01:30+00:00,2021-05-28 13:21:05+00:00
1W0z96MFEoH,2022,Accept (Poster),True,Benchmarking the Spectrum of Agent Capabilities,['Danijar Hafner'],"[""Evaluation"", ""Reinforcement Learning"", ""Environment"", ""Benchmark"", ""Unsupervised Reinforcement Learning"", ""Exploration""]",,2109.06780,cs.AI,2021-09-14 15:49:31+00:00,2021-09-14 15:49:31+00:00
1XdUvpaTNlM,2022,Reject,False,BWCP: Probabilistic Learning-to-Prune Channels for ConvNets via Batch Whitening,"['Wenqi Shao', 'Hang Yu', 'Zhaoyang Zhang', 'Hang Xu', 'Zhenguo Li', 'Ping Luo']","[""Classification"", ""Normalization""]",,,,,
1YLJDvSx6J4,2021,Accept (Spotlight),False,Learning from Protein Structure with Geometric Vector Perceptrons,"[""Bowen Jing"", ""Stephan Eismann"", ""Patricia Suriana"", ""Raphael John Lamarre Townshend"", ""Ron Dror""]","[""structural biology"", ""graph neural networks"", ""proteins"", ""geometric deep learning""]",We introduce a novel graph neural network layer to learn from the structure of macromolecules.,,,,
1Z3h4rCLvo-,2022,Reject,False,Improving Long-Horizon Imitation Through Language Prediction,"['Donald Joseph Hejna III', 'Pieter Abbeel', 'Lerrel Pinto']","[""imitation learning"", ""language"", ""planning""]",We purpose a novel representation learning method that uses language instruction prediction to aid learning in low-data regimes.,,,,
1Z5P--ntu8,2022,Reject,True,On the Global Convergence of Gradient Descent for multi-layer ResNets in the mean-field regime,"['Zhiyan Ding', 'Shi Chen', 'Qin Li', 'Stephen Wright']",[],,2110.02926,cs.LG,2021-10-06 17:16:09+00:00,2021-11-28 15:32:53+00:00
1Zxv7TdLquI,2022,Reject,False,YOUR AUTOREGRESSIVE GENERATIVE MODEL CAN BE BETTER IF YOU TREAT IT AS AN ENERGY-BASED ONE,"['Yezhen Wang', 'Tong Che', 'Bo Li', 'Kaitao Song', 'Hengzhi Pei', 'Yoshua Bengio', 'Dongsheng Li']","[""autoregressive generative model"", ""exposure bias"", ""energy-based model""]","We proposed a novel method  for training the autoregressive generative model that takes advantage of a well-designed energy-based learning objective, alleviating the exposure bias problem while increasing temporal coherence of generations.",,,,
1bEaEzGwfhP,2022,Reject,False,Learning to Model Editing Processes,"['Machel Reid', 'Graham Neubig']","[""Edit"", ""Representation Learning"", ""Source-code"", ""natural language editing""]","We propose a new task, edit modeling to model document likelihood by way of its revisions and their respective changes.",,,,
1cEEqSp9kXV,2021,Reject,False,Constructing Multiple High-Quality Deep Neural Networks: A TRUST-TECH Based Approach,"[""Zhiyong Hao"", ""Hsiao-Dong Chiang"", ""Bin Wang""]","[""Nonlinear Dynamical Systems"", ""Global Optimization"", ""Deep Neural Networks"", ""Ensemble.""]",We propose a novel method of obtaining multiple diverse networks systematically in one training run.,,,,
1ch9DLxqF-,2022,Reject,False,Dominant Datapoints and the Block Structure Phenomenon in Neural Network Hidden Representations,"['Thao Nguyen', 'Maithra Raghu', 'Simon Kornblith']","[""representation learning"", ""representational similarity"", ""distributed representations""]","We study a recent phenomenon observed in large-capacity neural networks involving a block of highly similar hidden representations, and explore how it connects to the underlying dataset and training mechanisms.",,,,
1dm_j4ciZp,2021,Reject,True,How much progress have we made in neural network training? A New Evaluation Protocol for Benchmarking Optimizers,"[""Yuanhao Xiong"", ""Xuanqing Liu"", ""Li-Cheng Lan"", ""Yang You"", ""Si Si"", ""Cho-Jui Hsieh""]","[""deep learning"", ""optimization"", ""benchmarking""]",We propose a new benchmarking framework to evaluate various optimizers.,2010.09889,cs.LG,2020-10-19 21:46:39+00:00,2020-10-19 21:46:39+00:00
1eKz1kjHO1,2021,Reject,False,Contextual Image Parsing via Panoptic Segment Sorting,"[""Jyh-Jing Hwang"", ""Tsung-Wei Ke"", ""Stella Yu""]","[""metric learning"", ""context encoding"", ""context discovery"", ""image parsing"", ""panoptic segmentation""]","We present a metric learning framework, panoptic segment sorting, to leverage the dense labels from image parsing for object visual context encoding and discovery.",,,,
1flmvXGGJaa,2021,Reject,False,NAS-Bench-301 and the Case for Surrogate Benchmarks for Neural Architecture Search,"[""Julien Niklas Siems"", ""Lucas Zimmer"", ""Arber Zela"", ""Jovita Lukasik"", ""Margret Keuper"", ""Frank Hutter""]","[""Neural Architecture Search"", ""Benchmarking"", ""Performance Prediction"", ""Deep Learning""]",,,,,
1gEb_H1DEqZ,2022,Reject,False,Logic Pre-Training of Language Models,"['Siru Ouyang', 'Zhuosheng Zhang', 'hai zhao']","[""Language Models"", ""Pre-training"", ""Logical Reasoning"", ""Natural Language Understanding""]","We propose logic pre-training of language models to capture logic relations essentially, in consideration of the fundamental role of PrLM serving in NLP and NLU tasks.",,,,
1hkYtDXAgOZ,2021,Reject,False,Feature Integration and Group Transformers for Action Proposal Generation,"[""He-Yen Hsieh"", ""Ding-Jie Chen"", ""Tung-Ying Lee"", ""Tyng-Luh Liu""]","[""temporal action proposal"", ""transformer"", ""video analysis""]","We propose a Transformer-style network for addressing the problem of temporal action proposal generation (TAPG), which aims to provide a high-quality set of video segments that potentially contain actions events.",,,,
1iDVz-khM4P,2022,Reject,False,Neural Networks Playing Dough: Investigating Deep Cognition With a Gradient-Based Adversarial Attack,['Sahar Niknam'],"[""Deep Learning"", ""Adversarial Perturbation"", ""Adversarial Example"", ""Categorical Learning""]",This paper uses an adversarial attack to investigate the learned content of neural networks in classification tasks.,,,,
1ibNKMp8SKc,2021,Reject,False,On Disentangled Representations Learned From Correlated Data,"[""Frederik Tr\u00e4uble"", ""Elliot Creager"", ""Niki Kilbertus"", ""Anirudh Goyal"", ""Francesco Locatello"", ""Bernhard Sch\u00f6lkopf"", ""Stefan Bauer""]","[""representation learning"", ""disentanglement""]",The paper studies in a large-scale empirical study how correlations affect disentangled representation learning and how to address resulting ramifications.,,,,
1kqWZlj4QYJ,2022,Reject,False,Learning Two-Step Hybrid Policy for Graph-Based Interpretable Reinforcement Learning,"['Tongzhou Mu', 'Kaixiang Lin', 'Feiyang Niu', 'Govind Thattai']","[""Interpretable Reinforcement Learning"", ""Generalization"", ""Robustness""]",A two-step hybrid policy designed for graph-based interpretable reinforcement learning.,,,,
1nlRIagHDUB,2022,Reject,False,Coresets for Kernel Clustering,"['Shaofeng H.-C. Jiang', 'Robert Krauthgamer', 'Jianing Lou', 'Yubo Zhang']","[""coreset"", ""clustering"", ""kernel"", ""PTAS"", ""streaming"", ""spectral clustering"", ""k-means""]","We give the first coreset for kernel $k$-Means of size independent of number of input points, and use it to obtain new efficient algorithms.",,,,
1oEvY1a67c1,2022,Reject,False,"If your data distribution shifts, use self-learning","['Evgenia Rusak', 'Steffen Schneider', 'George Pachitariu', 'Luisa Eck', 'Peter Vincent Gehler', 'Oliver Bringmann', 'Wieland Brendel', 'Matthias Bethge']","[""Self-Learning"", ""Domain Adaptation"", ""Robustness"", ""Pseudolabeling"", ""Entropy Minimization"", ""Corruption Robustness""]","Test-time adaptation with self-learning improves robustness of large-scale computer vision models on ImageNet-C, -R, and -A.",,,,
1qJtBS8QF9,2021,Reject,False,Graph View-Consistent Learning Network,"[""Zhuolin Liao"", ""Kun Zhan""]",[],,,,,
1rxHOBjeDUW,2021,Accept (Poster),False,Drop-Bottleneck: Learning Discrete Compressed Representation for Noise-Robust Exploration,"[""Jaekyeom Kim"", ""Minjung Kim"", ""Dongyeon Woo"", ""Gunhee Kim""]","[""Reinforcement learning"", ""Information bottleneck""]","Our novel IB method, Drop-Bottleneck, discretely drops task-irrelevant input features to build the compressed representation and shows state-of-the-art performance on noisy, sparse-reward navigation tasks in reinforcement learning.",2103.12300,cs.LG,2021-03-23 04:31:28+00:00,2021-03-23 04:31:28+00:00
1s1T7xHc5l6,2021,Reject,False,FILTRA: Rethinking Steerable CNN by Filter Transform,"[""Bo Li"", ""Qili Wang"", ""Gim Hee Lee""]",[],,2105.11636,cs.CV,2021-05-25 03:32:34+00:00,2021-05-25 03:32:34+00:00
1sJWR4y1lG,2021,Reject,False,Deep Learning Is Composite Kernel Learning,"[""CHANDRA SHEKAR LAKSHMINARAYANAN"", ""Amit Vikram Singh""]","[""deep learning"", ""kernel methods""]",,,,,
1toB0Fo9CZy,2021,Reject,False,Neural Architecture Search of SPD Manifold Networks,"[""Rhea Sanjay Sukthanker"", ""Zhiwu Huang"", ""Suryansh Kumar"", ""Erik Goron"", ""Yan Wu"", ""Luc Van Gool""]","[""Neural Architecture Search"", ""AutoML""]",,,,,
1uf_kj0GUF-,2022,Reject,False,Nonparametric Learning of Two-Layer ReLU Residual Units,"['Zhunxuan Wang', 'Linyun He', 'Chunchuan Lyu', 'Shay B Cohen']","[""neural network learning"", ""nonparametric methods"", ""convex optimization""]",We propose an algorithm that solves 2-layer ReLU ResNets by nonparametric estimation through convex optimization.,,,,
1ugNpm7W6E,2022,Accept (Poster),True,Cold Brew: Distilling Graph Node Representations with Incomplete or Missing Neighborhoods,"['Wenqing Zheng', 'Edward W Huang', 'Nikhil Rao', 'Sumeet Katariya', 'Zhangyang Wang', 'Karthik Subbian']","[""Graph Neural Networks"", ""Cold Start"", ""Knowledge Distillation""]",Improve strict cold start performances for graph minings with a knowledge distillation framework.,2111.04840,cs.LG,2021-11-08 21:29:25+00:00,2021-11-10 01:40:04+00:00
1v1N7Zhmgcx,2022,Reject,False,Maximum Likelihood Training of Parametrized Diffusion Model,"['Dongjun Kim', 'Byeonghu Na', 'Se Jung Kwon', 'Dongsoo Lee', 'Wanmo Kang', 'Il-chul Moon']","[""Score-based Diffusion Model"", ""Normalizing Flow Model"", ""Variational Inference"", ""Variational Gap"", ""Stochastic Calculus""]",We introduce the diffusion model with nonlinear diffusing mechanism with the joint combination of the normalizing flow and the diffusion models.,,,,
1wVvweK3oIb,2022,Accept (Poster),False,Simple GNN Regularisation for 3D Molecular Property Prediction and Beyond,"['Jonathan Godwin', 'Michael Schaarschmidt', 'Alexander L Gaunt', 'Alvaro Sanchez-Gonzalez', 'Yulia Rubanova', 'Petar VeliÄkoviÄ', 'James Kirkpatrick', 'Peter Battaglia']","[""Graph Neural Networks"", ""GNNs"", ""Deep Learning"", ""Molecular Property Prediction""]",A simple regularisation technique for GNNs applied to 3D molecular property prediction & beyond.,,,,
1wtC_X12XXC,2021,Reject,False,Activation Relaxation: A Local Dynamical Approximation to Backpropagation in the Brain,"[""Beren Millidge"", ""Alexander Tschantz"", ""Anil K Seth"", ""Christopher Buckley""]","[""Neural Networks"", ""Biological Plausibility"", ""Backprop""]",A novel local learning algorithm is proposed which rapidly and robustly converges to the exact backprop gradients,,,,
1xXvPrAshao,2022,Accept (Spotlight),False,Learning Multimodal VAEs through Mutual Supervision,"['Tom Joy', 'Yuge Shi', 'Philip Torr', 'Tom Rainforth', 'Sebastian M Schmon', 'Siddharth N']","[""Multimodal Variational Autoencoder"", ""Variational Autoencoder""]","Here we re-purpose semi-supervised VAEs to leverage mutual supervision between encoding distributions, allowing us to learn multi-modal VAEs with partially obsereved data.",,,,
1yDrpckYHnN,2021,Reject,False,Self-supervised and Supervised Joint Training for Resource-rich Machine Translation,"[""Yong Cheng"", ""Wei Wang."", ""Lu Jiang"", ""Wolfgang Macherey""]","[""resource-rich machine translation"", ""neural machine translation"", ""pre-training"", ""self-supervised learning"", ""joint training""]",Train NMT models on resource-rich corpora by exploiting complementary self-supervised learning signals for supervised learning in a joint training framework. ,,,,
1yXhko8GZEE,2021,Reject,False,Precondition Layer and Its Use for GANs,"[""Tiantian Fang"", ""Alex Schwing"", ""Ruoyu Sun""]","[""GAN"", ""Preconditioning"", ""Condition Number""]","We introduce a preconditioning layer (PC-layer) that performs a low-degree polynomial preconditioning, and show that it improves the performance of GANs.",,,,
1zwleytEpYx,2022,Accept (Poster),True,Imitation Learning by Reinforcement Learning,['Kamil Ciosek'],"[""reinforcement learning"", ""imitation learning"", ""Markov Decision Process"", ""continuous control""]","For deterministic experts, you can do imitation learning by calling an RL solver once, with a stationary reward signal.",2108.04763,stat.ML,2021-08-10 16:14:41+00:00,2021-08-10 16:14:41+00:00
2-mkiUs9Jx7,2022,Accept (Poster),True,Stein Latent Optimization for Generative Adversarial Networks,"['Uiwon Hwang', 'Heeseung Kim', 'Dahuin Jung', 'Hyemi Jang', 'Hyungyu Lee', 'Sungroh Yoon']","[""Generative Adversarial Networks"", ""Unsupervised Conditional GANs""]","We propose a novel GAN method that performs unsupervised conditional generation robustly on real-world datasets with balanced or imbalanced attributes even in the absence of attribute information (e.g., the imbalance ratio)",2106.05319,cs.LG,2021-06-09 18:15:30+00:00,2022-01-05 09:12:13+00:00
20qC5K2ICZL,2021,Reject,False,Robust Learning via Golden Symmetric Loss of (un)Trusted Labels,"[""Amirmasoud Ghiassi"", ""Robert Birke"", ""Lydia Y. Chen""]",[],,,,,
21aG-pxQWa,2021,Reject,False,Counterfactual Fairness through Data Preprocessing,"[""Haoyu Chen"", ""Wenbin Lu"", ""Rui Song"", ""Pulak Ghosh""]","[""Counterfactual fairness"", ""data preprocessing"", ""fairness test"", ""discrimination detection"", ""affirmative action""]",We propose the Fair Learning through dAta Preprocessing (FLAP) algorithm to learn counterfactually fair decisions from biased training data.,,,,
2234Pp-9ikZ,2021,Reject,False,"Don't be picky, all students in the right family can learn from good teachers","[""Roy Henha Eyono"", ""Fabio Maria Carlucci"", ""Pedro M Esperan\u00e7a"", ""Binxin Ru"", ""Philip Torr""]","[""knowledge distillation"", ""neural architecture search"", ""nas"", ""automl"", ""knowledge trasfer"", ""model compression""]",An efficient method for emulating large models by searching for the optimal family of student architectures. ,,,,
23ZjUGpjcc,2021,Accept (Poster),False,Scalable Transfer Learning with Expert Models,"[""Joan Puigcerver"", ""Carlos Riquelme Ruiz"", ""Basil Mustafa"", ""Cedric Renggli"", ""Andr\u00e9 Susano Pinto"", ""Sylvain Gelly"", ""Daniel Keysers"", ""Neil Houlsby""]","[""Transfer Learning"", ""Expert Models"", ""Few Shot""]",,,,,
24-DxeAe2af,2021,Reject,False,Accurate and fast detection of copy number variations from short-read whole-genome sequencing with deep convolutional neural network,"[""Jiajin Li"", ""Stephen Hwang"", ""Luke Zhang"", ""Jae Hoon Sul""]","[""copy number variation"", ""deep learning"", ""convolutional neural network"", ""computational biology"", ""DNA sequencing""]","Developed CNV-Net to detect CNV, a type of genetic mutation, from short-read DNA sequencing using deep convolutional neural network",,,,
24N4XH2NaYq,2022,Reject,False,Sparse Hierarchical Table Ensemble,"['Guy Farjon', 'Aharon Bar HIllel']","[""tabular data"", ""DL alternative"", ""architecture""]",Extremely fast deep learning alternative for tabular data ,,,,
25OSRH9H0Gi,2021,Reject,False,Putting Theory to Work: From Learning Bounds to Meta-Learning Algorithms,"[""Quentin Bouniot"", ""Ievgen Redko"", ""Romaric Audigier"", ""Ang\u00e9lique Loesch"", ""Amaury Habrard""]","[""meta-learning"", ""few-shot learning""]",We put theory into practice by proposing a new approach to assess and guarantee theoretical assumptions on popular meta-learning algorithms.,,,,
25kzAhUB1lz,2022,Accept (Poster),True,Direct then Diffuse: Incremental Unsupervised Skill Discovery for State Covering and Goal Reaching,"['Pierre-Alexandre Kamienny', 'Jean Tarbouriech', 'Alessandro Lazaric', 'Ludovic Denoyer']","[""unsupervised reinforcement learning"", ""skill discovery"", ""mutual information""]",,2110.14457,cs.LG,2021-10-27 14:22:19+00:00,2021-10-27 14:22:19+00:00
26WnoE4hjS,2021,Reject,False,Measuring and mitigating interference in reinforcement learning,"[""Vincent Liu"", ""Adam M White"", ""Hengshuai Yao"", ""Martha White""]","[""Reinforcement Learning"", ""Representation Learning""]",,,,,
26gKg6x-ie,2022,Accept (Spotlight),False,Adversarial Support Alignment,"['Shangyuan Tong', 'Timur Garipov', 'Yang Zhang', 'Shiyu Chang', 'Tommi S. Jaakkola']","[""support alignment"", ""distribution alignment"", ""optimal transport"", ""domain adaptation""]",We study the problem of aligning the supports of distributions.,,,,
27acGyyI1BY,2021,Accept (Poster),False,Neural ODE Processes,"[""Alexander Norcliffe"", ""Cristian Bodnar"", ""Ben Day"", ""Jacob Moss"", ""Pietro Li\u00f2""]","[""differential equations"", ""neural processes"", ""dynamics"", ""deep learning"", ""neural ode""]",Neural Processes with time-awareness,2103.12413,cs.LG,2021-03-23 09:32:06+00:00,2021-08-17 08:56:29+00:00
27aftiBeius,2022,Reject,False,$$Research on fusion algorithm of multi-attribute decision making and reinforcement learning based on intuitionistic fuzzy number in wargame environment$$,"['Yuxiang Sun', 'Bo Yuan', 'Yufan Xue', 'Jiawei Zhou', 'Leonardo Stella', 'Xianzhong Zhou']","[""Wargame"", ""Reinforcement learning"", ""Multiple attribute decision making"", ""Intelligent game""]","The reinforcement learning algorithm in management method and control theory is combined for the first time, and the fusion algorithm is verified to be feasible and intelligent by wargame simulation environment.",,,,
28ib9tf6zhr,2022,Accept (Poster),False,Patch-Fool: Are Vision Transformers Always Robust Against Adversarial Perturbations?,"['Yonggan Fu', 'Shunyao Zhang', 'Shang Wu', 'Cheng Wan', 'Yingyan Lin']","[""Vision transformer"", ""adversarial examples"", ""robustness""]",We propose the Patch-Fool attack to unveil a vulnerability perspective of ViTs.,,,,
2AL06y9cDE-,2021,Accept (Poster),False,Towards Robust Neural Networks via Close-loop Control,"[""Zhuotong Chen"", ""Qianxiao Li"", ""Zheng Zhang""]","[""neural network robustness"", ""optimal control"", ""dynamical system""]",We propose a close-loop control framework to improve the robustness of neural networks under various data perturbations.,2102.01862,cs.LG,2021-02-03 03:50:35+00:00,2021-04-28 02:45:44+00:00
2CjEVW-RGOJ,2021,Accept (Poster),False,SkipW: Resource Adaptable RNN with Strict Upper Computational Limit,"[""Tsiry Mayet"", ""Anne Lambert"", ""Pascal Leguyadec"", ""Francoise Le Bolzer"", ""Fran\u00e7ois Schnitzler""]","[""Recurrent neural networks"", ""Flexibility"", ""Computational resources""]",Skip-Window is a method to allow recurrent neural networks (RNNs) to trade off accuracy for computational cost during the analysis of a sequence while keeping a strict upper computational limit.,,,,
2DJn3E7lXu,2022,Reject,False,What to expect of hardware metric predictors in NAS,"['Kevin Alexander Laube', 'Maximus Mutschler', 'Andreas Zell']","[""Neural Architecture Search"", ""Hardware-Aware"", ""Predictors"", ""Deep Learning""]",We evaluate several predictor models for hardware-aware neural architecture search and estimate their opportunity costs through simulation.,,,,
2DJwuD-elOt,2022,Reject,False,Hybrid Cloud-Edge Networks for Efficient Inference,"['Anil Kag', 'Igor Fedorov', 'Aditya Gangrade', 'Paul Whatmough', 'Venkatesh Saligrama']","[""low-capacity model"", ""large-scale prediction"", ""efficient inference"", ""hybrid networks"", ""routing nets"", ""coverage and latency"", ""FLOPs""]","Large-scale prediction tasks are handled by high-capacity DNNs in the cloud. To handle majority of the workload on low-capacity devices, we propose a hybrid approach, which passes on few and unusually hard examples to the high-capacity cloud model.",,,,
2DT7DptUiXv,2022,Reject,False,ConVAEr: Convolutional Variational AutoEncodeRs for incremental similarity learning,"['Jiahao Huo', 'Terence L van Zyl']","[""catastrophic forgetting"", ""incremental similarity learning""]",Investigating into incremental similarity learning.,,,,
2Ey_1FeNtOC,2021,Reject,False,Minimum Description Length Recurrent Neural Networks,"[""Nur Lan"", ""Emmanuel Chemla"", ""Roni Katzir""]","[""recurrent neural network"", ""neural network"", ""language modeling"", ""minimum description length"", ""genetic algorithm"", ""semantics"", ""syntax""]","Description length-based optimization of recurrent neural networks leads to interpretable and absolutely-correct networks for language modeling, using very small training data. ",,,,
2G9u-wu2tXP,2021,Reject,True,Continual learning using hash-routed convolutional neural networks,"[""Ahmad Berjaoui""]","[""Lifelong learning"", ""continual learning"", ""feature hashing""]","We present a scalable continual learning framework composed of individual units, selected using feature hashing.",2010.05880,cs.LG,2020-10-09 07:48:37+00:00,2020-10-09 07:48:37+00:00
2HLTMwxOxwe,2021,Reject,False,Learn what you can't learn: Regularized Ensembles for Transductive out-of-distribution detection,"[""Alexandru \u021aifrea"", ""Eric Petru Stavarache"", ""Fanny Yang""]","[""out-of-distribution detection"", ""transductive"", ""predictive uncertainty"", ""ensembles"", ""ensemble diversity"", ""outlier detection""]",Transductive out-of-distribution detection via ensembles of regularized models that agree on inliers and disagree on outliers.,,,,
2I1wy0y6xo,2022,Reject,False,Stability analysis of SGD through the normalized loss function,"['Alexandre Lemire Paquin', 'Brahim Chaib-draa', 'Philippe GiguÃ¨re']","[""Generalization bounds"", ""deep neural networks"", ""stability""]",Stability based generalization bounds for homogeneous neural networks,,,,
2Id6XxTjz7c,2021,Reject,False,Post-Training Weighted Quantization of Neural Networks for Language Models,"[""Se Jung Kwon"", ""Dongsoo Lee"", ""Yongkweon Jeon"", ""Byeongwook Kim"", ""Bae Seong Park"", ""Yeonju Ro""]","[""Model Compression"", ""Non-uniform Quantization"", ""Post-training Quantization"", ""Language Model""]",We propose a new post-training (importance-aware) weighted quantization method for language models as an efficient model compression technique.,,,,
2K5WDVL2KI,2021,Reject,True,Information Condensing Active Learning,"[""Siddhartha Jain"", ""Ge Liu"", ""David Gifford""]","[""active learning""]",Active Learning method for Deep Learning,2002.07916,cs.LG,2020-02-18 22:55:08+00:00,2020-02-20 02:52:05+00:00
2KSsaPGemn2,2021,Reject,False,Non-Linear Rewards For Successor Features,"[""Norman L Tasfi"", ""Miriam Capretz""]",[],,,,,
2LBhynkS2SC,2021,Reject,False,Individuality in the hive - Learning to embed lifetime social behaviour of honey bees,"[""Benjamin Wild"", ""David Dormagen"", ""Michael L Smith"", ""Tim Landgraf""]","[""matrix factorization"", ""honey bees"", ""explainable"", ""social networks"", ""implicit bias"", ""dataset""]",Factorizing social network of honey bees using a novel temporal NMF algorithm.,,,,
2LiGI26kRdt,2021,Reject,False,Progressively Stacking 2.0: A Multi-stage Layerwise Training Method for BERT Training Speedup,"[""Cheng Yang"", ""Shengnan Wang"", ""Chao Yang"", ""Yuechuan Li"", ""Ru He"", ""Jingqiao Zhang""]","[""BERT"", ""Training speedup"", ""Multi-stage training"", ""Natural language processing""]",This paper proposes a multi-stage layerwise training method to accelerate the training of BERT model.,2011.13635,cs.CL,2020-11-27 10:00:22+00:00,2020-11-27 10:00:22+00:00
2M0WXSP6Qi,2022,Reject,False,Information-theoretic stochastic contrastive conditional GAN: InfoSCC-GAN,"['Vitaliy Kinakh', 'Mariia Drozdova', 'Guillaume QuÃ©tant', 'Svyatoslav Voloshynovskyy', 'Tobias GOLLING']","[""GANs"", ""Generative adversarial networks"", ""Contrastive learning"", ""Conditional image generation""]","We propose a novel approach for conditional image generation, based on independent pretrained encoder, independent pretrained classifier and generator with explorable latent space",,,,
2NHl-ETnHxk,2021,Reject,False,Adversarial Privacy Preservation in MRI Scans of the Brain,"[""Lennart Alexander Van der Goten"", ""Tobias Hepp"", ""Zeynep Akata"", ""Kevin Smith""]","[""medical imaging"", ""generative modeling"", ""privacy"", ""de-identification""]",,,,,
2NU7a9AHo-6,2021,Reject,False,AUL is a better optimization metric  in PU learning,"[""Shangchuan Huang"", ""Songtao Wang"", ""Dan Li"", ""Liwei Jiang""]",[],,,,,
2NqIV8dzR7N,2022,Reject,True,Automatic Termination for Hyperparameter Optimization,"['Anastasia Makarova', 'Huibin Shen', 'Valerio Perrone', 'Aaron Klein', 'Jean Baptiste Faddoul', 'Andreas Krause', 'Matthias Seeger', 'Cedric Archambeau']","[""Bayesian optimization"", ""hyperparameter optimization"", ""automatic termination""]",We provide a termination criterion for Bayesian optimisation (BO) that is theoretically inspired and leads to competitive empirical results for BO-based hyperoptimization tuning.,2104.08166,cs.LG,2021-04-16 15:26:23+00:00,2021-12-21 08:34:12+00:00
2PSrjVtj6gU,2022,Reject,False,Graph Attention Multi-layer Perceptron,"['Wentao Zhang', 'Ziqi Yin', 'Zeang Sheng', 'Yang Li', 'Wen Ouyang', 'Xiaosen Li', 'Yangyu Tao', 'Zhi Yang', 'Bin CUI']","[""Graph Neural Network"", ""Attention"", ""Scalability""]",The first work to explore both node-adaptive feature and label propagation schemes for scalable GNNs.,,,,
2RNpZ8S4alJ,2022,Reject,False,KINet: Keypoint Interaction Networks for Unsupervised Forward Modeling,"['Alireza Rezazadeh', 'Changhyun Choi']",[],,,,,
2RYOwBOFesi,2022,Reject,False,An Empirical Study of Pre-trained Models on Out-of-distribution Generalization,"['Yaodong Yu', 'Heinrich Jiang', 'Dara Bahri', 'Hossein Mobahi', 'Seungyeon Kim', 'Ankit Singh Rawat', 'Andreas Veit', 'Yi Ma']","[""out-of-distribution generalization"", ""domain generalization"", ""pre-training""]",We show that larger models and larger datasets need to be simultaneously leveraged to improve OOD performance.,,,,
2V1ATRzaZQU,2021,Reject,False,Characterizing Lookahead Dynamics of Smooth Games,"[""Junsoo Ha"", ""Gunhee Kim""]","[""Lookahead optimizer"", ""game dynamics"", ""smooth game""]","For the first time, we derive theoretic results for convergence guarantee and acceleration of Lookahead optimization in smooth games.",,,,
2VXyy9mIyU3,2021,Accept (Poster),True,Learning with Instance-Dependent Label Noise: A Sample Sieve Approach,"[""Hao Cheng"", ""Zhaowei Zhu"", ""Xingyu Li"", ""Yifei Gong"", ""Xing Sun"", ""Yang Liu""]","[""Learning with noisy labels"", ""instance-based label noise"", ""deep neural networks.""]",This paper proposes a dynamic sample sieve method with strong theoretical guarantees to avoid overfitting to instance-based label noise.,2010.02347,cs.LG,2020-10-05 21:44:09+00:00,2021-03-22 22:01:05+00:00
2_Z6MECjPEa,2021,Reject,True,Emergent Properties of Foveated Perceptual Systems,"[""Arturo Deza"", ""Talia Konkle""]","[""Hybrid Perceptual Systems"", ""Foveation"", ""Visual Crowding"", ""Texture"", ""Two-stage models""]",We find computational support that texture-based foveation induces a representational advantage in machine perception.,2006.07991,cs.CV,2020-06-14 19:34:44+00:00,2021-06-22 21:21:08+00:00
2_dQlkDHnvN,2022,Reject,False,Defending Backdoor Data Poisoning Attacks by Using Noisy Label Defense Algorithm,"['Boyang Liu', 'Zhuangdi Zhu', 'Pang-Ning Tan', 'Jiayu Zhou']","[""Backdoor Attack"", ""Data Poisoning"", ""Noisy Label""]",Analyze the connection between Noisy Label Attacks and Backdoor Attack.,,,,
2_vhkAMARk,2022,Accept (Spotlight),False,Escaping limit cycles: Global convergence for constrained nonconvex-nonconcave minimax problems,"['Thomas Pethick', 'Puya Latafat', 'Panos Patrinos', 'Olivier Fercoq', 'Volkan Cevher']","[""Minimax"", ""Nonconvex-Nonconcave"", ""Variational inequilities"", ""Saddle point problem"", ""First-order methods"", ""Limit cycles""]",Under weak MVI we introduce a new extragradient-type algorithm that avoids limit cycles,,,,
2aC0_RxkBL_,2022,Reject,False,Where is the bottleneck in long-tailed classification?,"['Zaid Khan', 'Yun Fu']","[""fairness"", ""bias"", ""long tailed learning"", ""imbalanced learning""]",We investigate how learning from long-tailed distributions harms representations. ,,,,
2bO2x8NAIMB,2022,Accept (Poster),False,Should We Be Pre-training? An Argument for End-task Aware Training as an Alternative,"['Lucio M. Dery', 'Paul Michel', 'Ameet Talwalkar', 'Graham Neubig']","[""pre-training"", ""multitask learning"", ""meta-learning"", ""deeplearning"", ""end-task aware training"", ""NLP""]","When we know the end-task objective in advance, instead of pre-training on auxiliary objectives  and then fine-tuning, we advocate for it to be introduced directly in training with auxiliary objectives ",,,,
2cpsEstmH1,2022,Reject,False,Beyond Examples: Constructing Explanation Space for Explaining Prototypes,"['Hyungjun Joo', 'Seokhyeon Ha', 'Jae Myung Kim', 'Sungyeob Han', 'Jungwoo Lee']","[""Interpretable machine learning"", ""XAI"", ""Uncertainty"", ""Prototype-based classification""]",We have developed an inherently interpretable classification model that enhances the expressiveness of the explanation.,,,,
2d34y5bRWxB,2021,Reject,False,Regularization Cocktails for Tabular Datasets,"[""Arlind Kadra"", ""Marius Lindauer"", ""Frank Hutter"", ""Josif Grabocka""]","[""deep learning"", ""regularization"", ""hyperparameter optimization"", ""benchmarks.""]",An empirical study on the optimal combination of regularization methods.,,,,
2d4riGOpmU8,2022,Reject,False,Sequential Covariate Shift Detection Using Classifier Two-Sample Tests,"['Sooyong Jang', 'Sangdon Park', 'Insup Lee', 'Osbert Bastani']",[],,,,,
2eXhNpHeW6E,2022,Accept (Spotlight),False,R5: Rule Discovery with Reinforced and Recurrent Relational Reasoning,"['Shengyao Lu', 'Bang Liu', 'Keith G Mills', 'SHANGLING JUI', 'Di Niu']","[""systematicity"", ""graph reasoning""]",,,,,
2f1z55GVQN,2022,Accept (Poster),False,Critical Points in Quantum Generative Models,['Eric Ricardo Anschuetz'],"[""loss landscapes"", ""quantum"", ""Wishart spin-glass model""]","We show using techniques from random matrix theory that, unlike typical neural networks, quantum generative models often have poor quality local minima.",,,,
2g9m74He1Ky,2022,Reject,False,Spatio-temporal Disentangled representation learning for mobility prediction,"['Sichen Zhao', 'Wei Shao', 'Jeffrey Chan', 'Flora D. Salim']","[""Disentangled representation learning"", ""Spatio-temporal data"", ""principle of relevant information""]",Our deep generative model learns a latent representation that separates the temporal dynamics of the data from the spatially varying component and can achieve state-of-the-art performance across multiple spatio-temporal datasets.,,,,
2ggNjUisGyr,2022,Accept (Poster),False,Partial Wasserstein Adversarial Network for Non-rigid Point Set Registration,"['Ziming Wang', 'Nan Xue', 'Ling Lei', 'Gui-Song Xia']","[""partial Wasserstein discrepancy"", ""partial distribution matching"", ""point set registration""]","We propose a method for large scale partial distribution matching problem, and apply it to non-rigid point set registration task.",,,,
2hMEdc35xZ6,2022,Reject,False,Defect Transfer GAN: Diverse Defect Synthesis for Data Augmentation,"['Ruyu Wang', 'Sabrina Hoppe', 'Eduardo Monari', 'Marco Huber']","[""Defect synthesis"", ""Generative Adversarial Networks"", ""Content transfer"", ""Automated visual inspection"", ""Data augmentation""]",,,,,
2hT6Fbbwh6,2021,Reject,False,Deep Positive Unlabeled Learning with a Sequential Bias,"[""Walter Gerych"", ""Thomas Hartvigsen"", ""Luke Buquicchio"", ""Kavin Chandrasekaran"", ""Hamid Mansoor"", ""Abdulaziz alajaji""]",[],We develop a novel method that addresses the previously-overlooked challenge of sequential bias in positive-unlabeled data ,,,,
2ioNazs6lvw,2021,Reject,False,Learning to generate Wasserstein barycenters,"[""Julien Lacombe"", ""Julie Digne"", ""Nicolas Courty"", ""Nicolas Bonneel""]","[""Wasserstein barycenters"", ""Optimal Transport""]",Our paper introduces a fast way to generate approximate Wasserstein Barycenters.,2102.12178,cs.LG,2021-02-24 10:13:48+00:00,2021-02-24 10:13:48+00:00
2isb_482lP,2021,Reject,False,A Spectral Perspective on Deep Supervised Community Detection,"[""Nathan Grinsztajn"", ""Philippe Preux"", ""Edouard Oyallon""]","[""GCN"", ""graph spectrum"", ""stability"", ""graph Laplacian""]",We study the numerical performances of GCNs in the spectral domain and show that only a few low frequencies allow MLPs to become competitive.,,,,
2jYxq9_TkpG,2022,Reject,False,Network Pruning Optimization by Simulated Annealing Algorithm,"['Chun Lin Kuo', 'Ercan Engin Kuruoglu', 'Wai Kin Victor Chan']","[""optimization"", ""network pruning""]",DNN pruning process and architectural optimization using Simulated Annealing algorithm are effective modeling as a finite Markov chain.,,,,
2kImxCmYBic,2021,Reject,False,Numeric Encoding Options with Automunge,"[""Nicholas Teague""]","[""tabular"", ""feature engineering"", ""preprocessing""]",A survey of tabular data numeric feature set encodings as available in the Automunge library.,,,,
2m0g1wEafh,2021,Accept (Spotlight),False,Benefit of deep learning with non-convex noisy gradient descent: Provable excess risk bound and superiority to kernel methods,"[""Taiji Suzuki"", ""Shunta Akiyama""]","[""Excess risk"", ""minimax optimal rate"", ""local Rademacher complexity"", ""fast learning rate"", ""kernel method"", ""linear estimator""]",,2012.03224,stat.ML,2020-12-06 09:22:16+00:00,2020-12-06 09:22:16+00:00
2nm0fGwWBMr,2021,Reject,True,PanRep: Universal node embeddings for heterogeneous graphs,"[""Vassilis N. Ioannidis"", ""Da Zheng"", ""George Karypis""]","[""Graph neural networks"", ""universal node embeddings"", ""node classification"", ""link prediction"", ""unsupervised learning""]",,2007.10445,cs.LG,2020-07-20 20:14:10+00:00,2021-03-04 15:49:05+00:00
2p_5F9sHN9,2022,Reject,False,The Geometry of Adversarial Subspaces,"['Dylan M. Paiton', 'David Schultheiss', 'Matthias Kuemmerer', 'Zac Cranko', 'Matthias Bethge']","[""adversarial attack"", ""decision boundary"", ""riemannian geometry"", ""differential geometry"", ""interpretability"", ""adversarial training""]","We define adversarial subspaces, which are spanned by orthogonal directions of minimal perturbation to the decision boundary, to further our understanding of the decision space of ANN classifiers with and without adversarial training.",,,,
2rcgRSAa1A3,2021,Reject,False,Fighting Filterbubbles with Adversarial BERT-Training for News-Recommendation,"[""Lukas Pfahler"", ""Katharina Morik""]","[""Adversarial Learning"", ""Natural Language Processing"", ""BERT"", ""News Recommendation"", ""Attention""]","In order to fight the emergence of filterbubbles in news recommendation systems, we use adversarial training to learn representations of news articles that are less predictive of their respective news outlet.",,,,
2s4sNT11IcH,2022,Reject,False,On the Convergence and Calibration of Deep Learning with Differential Privacy,"['Zhiqi Bu', 'Hua Wang', 'Qi Long', 'Weijie J Su']","[""Deep Learning"", ""Differential Privacy"", ""Optimization Algorithms"", ""Convergence Theory"", ""Calibration""]","We initiate convergence analysis of private deep learning and propose new clipping method for private optimizers, which significantly and provably improves convergence and calibration.",,,,
2sDQwC_hmnM,2022,Accept (Poster),False,ZeroFL: Efficient On-Device Training for  Federated Learning with Local Sparsity,"['Xinchi Qiu', 'Javier Fernandez-Marques', 'Pedro PB Gusmao', 'Yan Gao', 'Titouan Parcollet', 'Nicholas Donald Lane']","[""Federated Learning"", ""sparse training""]","This work studies the challenges of accelerating on-device training in Federated Learning workloads by using highly sparse operations, with our framework we achieve lower accuracy degradation in addition to reducing the uplink communication costs. ",,,,
2t7CkQXNpuq,2022,Accept (Poster),True,ToM2C: Target-oriented Multi-agent Communication and Cooperation with Theory of Mind,"['Yuanfei Wang', 'fangwei zhong', 'Jing Xu', 'Yizhou Wang']","[""Theory of Mind"", ""Target-oriented Multi-Agent Cooperation"", ""Multi-agent Communication""]",,2111.09189,cs.MA,2021-10-15 18:29:55+00:00,2021-10-15 18:29:55+00:00
2wjKRmraNan,2021,Reject,False,Non-Inherent Feature Compatible Learning,"[""Yantao Shen"", ""Fanzi Wu"", ""Ying Shan""]","[""Deep Learning"", ""Feature Learning"", ""Compatible Learning""]",,,,,
2yITmG7YIFT,2022,Reject,False,HD-cos Networks: Efficient Neural Architechtures for Secure Multi-Party Computation,"['Wittawat Jitkrittum', 'Michal Lukasik', 'Ananda Theertha Suresh', 'Felix Yu', 'Gang Wang']","[""multi-party computation"", ""privacy"", ""cryptography"", ""privacy-preserving machine learning""]",We propose a new layer built with a fast Hadamard transform and cosine activation function that is efficient to be used for training and inference in the multi-party computation setup.,,,,
2z5h4hY-LQ,2022,Reject,False,GAETS: A Graph Autoencoder Time Series Approach Towards Battery Parameter Estimation,"['Edward Elson Kosasih', 'Rucha Bhalchandra Joshi', 'Janamejaya Channegowda']",[],,,,,
3-a23gHXQmr,2021,Reject,False,Parametric Density Estimation with Uncertainty using Deep Ensembles,"[""Abel Peirson"", ""Taylor Howell"", ""Marius Aurel Tirlea""]","[""Deep ensembles"", ""deep learning"", ""computer vision"", ""density estimation"", ""uncertainty""]",Deep ensemble predictive uncertainties can inform parametric density estimation in a number of applications.,,,,
30EvkP2aQLD,2021,Accept (Spotlight),False,What are the Statistical Limits of Offline RL with Linear Function Approximation?,"[""Ruosong Wang"", ""Dean Foster"", ""Sham M. Kakade""]","[""batch reinforcement learning"", ""function approximation"", ""lower bound"", ""representation""]",Exponential lower bounds for batch RL with linear function approximation. ,,,,
30I4Azqc_oP,2021,Reject,False,Deep Reinforcement Learning with Causality-based Intrinsic Reward,"[""Peng Zhang"", ""Furui Liu"", ""Zhitang Chen"", ""Jianye HAO"", ""Jun Wang""]","[""Reinforcement Learning"", ""Causal Relation""]","We propose a novel deep reinforcement learning algorithm, which firstly learns environmental causal relations between categories of entities and then leverages the learned relational information to assist policy learning.",,,,
30SS5VjvhrZ,2021,Reject,False,Bayesian Neural Networks with Variance Propagation for Uncertainty Evaluation,"[""Yuki Mae"", ""Wataru Kumagai"", ""Takafumi Kanamori""]","[""uncertainty evaluation"", ""sampling-free method"", ""variance propagation"", ""LSTM"", ""out-of-distribution""]",We developed a sampling-free method for uncertainty evaluation by converting DNNs/RNNs trained using dropout to the Bayesian neural networks with variance propagation. ,,,,
30SXt3-vvnM,2022,Reject,False,Model-Efficient Deep Learning with Kernelized Classification,"['Sadeep Jayasumana', 'Srikumar Ramalingam', 'Sanjiv Kumar']","[""deep networks"", ""kernels on the sphere"", ""nonlinear classification""]",We propose a kernelized classification layer for deep networks to obtain the best possible classifier with embeddings learned in the network.,,,,
30nbp1eV0dJ,2022,Reject,False,Tight lower bounds for Differentially Private ERM,"['Daogao Liu', 'Zhou Lu']","[""Differential Privacy"", ""Empirical Risk Minimization"", ""Lower bounds""]",We construct the first tight lower bounds for differentially private empirical risk minimization (ERM).,,,,
31d5RLCUuXC,2022,Accept (Poster),False,A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model,"['Jianwen Xie', 'Yaxuan Zhu', 'Jun Li', 'Ping Li']","[""Langevin dynamics"", ""energy-based model"", ""normalizing flow"", ""cooperative learning"", ""short-run MCMC""]",Joint learning of a short-run MCMC generator and a normalizing flow in the context of energy-based model for image representation and generation. ,,,,
327eol9Xgyi,2022,Reject,True,Trident Pyramid Networks: The importance of processing at the feature pyramid level for better object detection,"['CÃ©dric Picron', 'Tinne Tuytelaars']","[""feature pyramid"", ""network architecture"", ""object detection"", ""deep learning""]",We introduce the Trident Pyramid Network (TPN) and show improvements w.r.t. BiFPN and ResNet-101+FPN baseline.,2110.04004,cs.CV,2021-10-08 09:59:59+00:00,2022-02-09 18:04:34+00:00
32OdIHsu1_,2022,Reject,False,DL-based prediction of optimal actions of human experts,"['Jung H. Lee', 'Ryan S Butner', 'Elise Saxon', 'Nathan Oken Hodas']","[""deep learning"", ""expert system"", ""sequential learning""]",,,,,
33TBJachvOX,2021,Reject,False,How to compare adversarial robustness of classifiers from a global perspective,"[""Niklas Risse"", ""Jan Philip G\u00f6pfert"", ""Christina G\u00f6pfert""]","[""adversarial robustness"", ""robustness"", ""adversarial defense"", ""adversarial example""]","We demonstrate that point-wise measures are insufficient to adequately compare the adversarial robustness of differently trained models, and provide a module for global robustness analysis to reveal individual strengths of competing methods.",,,,
33nhOe3cTd,2022,Reject,False,Spending Thinking Time Wisely: Accelerating MCTS with Virtual Expansions,"['Weirui Ye', 'Pieter Abbeel', 'Yang Gao']","[""Computer Go"", ""Monte-Carlo Tree Search"", ""Reinforcement learning"", ""Adaptive"", ""Acceleration""]",,,,,
33rtZ4Sjwjn,2021,Accept (Poster),False,Effective and Efficient Vote Attack on Capsule Networks,"[""Jindong Gu"", ""Baoyuan Wu"", ""Volker Tresp""]","[""Capsule Networks"", ""Adversarial Attacks"", ""Adversarial Example Detection""]",We propose an effective and efficient vote attack to create adversarial examples and bypass adversarial example detection on Capsule Networks.,2102.10055,cs.CV,2021-02-19 17:35:07+00:00,2021-02-19 17:35:07+00:00
34KAZ9HbJco,2021,Reject,False,Adapt-and-Adjust: Overcoming the Long-tail Problem of Multilingual Speech Recognition,"[""Genta Indra Winata"", ""Guangsen Wang"", ""Caiming Xiong"", ""Steven Hoi""]","[""speech recognition"", ""multilingual"", ""long-tail"", ""adapter"", ""logit adjustments""]","Adapt-and-Adjust (A2), an end-to-end transformer-based multitask learning framework for multilingual speech recognition. ",2012.01687,cs.CL,2020-12-03 03:46:16+00:00,2020-12-03 03:46:16+00:00
34mWBCWMxh9,2022,Reject,True,"Blur Is an Ensemble: Spatial Smoothings to Improve Accuracy, Uncertainty, and Robustness","['Namuk Park', 'Songkuk Kim']","[""bayesian neural network"", ""uncertainty"", ""uncertainty estimation"", ""uncertainty quantification""]","To improve accuracy, uncertainty, and robustness, we propose spatial smoothing, a method that aggregates spatially nearby feature maps of CNNs. This spatial ensemble of feature mapsâeven GAPâhelps in optimization by flattening the loss landscape.",2105.12639,cs.LG,2021-05-26 15:58:11+00:00,2021-05-26 15:58:11+00:00
36SHWj0Gp1,2022,Reject,False,GenTAL: Generative Denoising Skip-gram Transformer for Unsupervised Binary Code Similarity Detection,"['Litao Li', 'Steven Ding', 'Philippe Charland', 'Hanbo Yu', 'Christopher James Molloy']","[""Representation Learning"", ""Transformer"", ""Autoencoder"", ""Binary Code Similarity Detection""]",This paper proposes a novel approach for unsupervised Transformer-based language model for code semantic representation learning.,,,,
36rU1ecTFvR,2022,Reject,False,Can standard training with clean images outperform adversarial one in robust accuracy?,"['Jing Wang', 'Jiahao Hu', 'Guanrong Li']","[""Adversarial Training"", ""Robust Accuracy""]"," We propose standard training with clean images, and its robust accuracy outperforms most of the existing methods.",,,,
37Fh1MiR5Ze,2021,Reject,False,A Chaos Theory Approach to Understand Neural Network Optimization,"[""Michele Sasdelli"", ""Thalaiyasingam Ajanthan"", ""Tat-Jun Chin"", ""Gustavo Carneiro""]","[""learning theory"", ""stochastic gradient descent"", ""deep learning"", ""neural networks"", ""dynamical systems"", ""chaos theory"", ""Lyapunov exponents""]",Studying neural network training dynamics with the largest Lyapunov exponent of the stochastic gradient descent optimization,,,,
37nvvqkCo5,2021,Accept (Spotlight),True,Long-tail learning via logit adjustment,"[""Aditya Krishna Menon"", ""Sadeep Jayasumana"", ""Ankit Singh Rawat"", ""Himanshu Jain"", ""Andreas Veit"", ""Sanjiv Kumar""]","[""long-tail learning"", ""class imbalance""]","Adjusting classifier logits based on class priors, either post-hoc or during training, can improve performance on rare classes.",2007.07314,cs.LG,2020-07-14 19:27:13+00:00,2021-07-09 21:23:25+00:00
389rLpWoOlG,2021,Reject,False,Machine Learning Algorithms for Data Labeling: An Empirical Evaluation,"[""Teodor Anders Fredriksson"", ""David Issa Mattos"", ""Jan Bosch"", ""Helena Holmstr\u00f6m Olsson""]","[""Data Labeling"", ""Empirical Evaluation"", ""Active Machine Learning"", ""Semi-Supervised Learning""]",This paper provides an empirical evaluation of automatic labeling methods based on machine learning.,,,,
3AOj0RCNC2,2021,Accept (Oral),False,Gradient Projection Memory for Continual Learning,"[""Gobinda Saha"", ""Isha Garg"", ""Kaushik Roy""]","[""Continual Learning"", ""Representation Learning"", ""Computer Vision"", ""Deep learning""]","To avoid catastrophic forgetting in continual learning, we propose a novel approach where a neural network learns new tasks by taking gradient steps in the orthogonal direction to the gradient subspaces deemed important for past tasks.",2103.09762,cs.LG,2021-03-17 16:31:29+00:00,2021-03-17 16:31:29+00:00
3AkuJOgL_X,2022,Reject,True,Federated Robustness Propagation: Sharing Adversarial Robustness in Federated Learning,"['Junyuan Hong', 'Haotao Wang', 'Zhangyang Wang', 'Jiayu Zhou']","[""federated learning"", ""data heterogeneity"", ""hardware heterogeneity"", ""security heterogeneity"", ""adversarial robustness""]",,2106.10196,cs.LG,2021-06-18 15:52:33+00:00,2021-06-18 15:52:33+00:00
3Aoft6NWFej,2021,Accept (Spotlight),True,PMI-Masking: Principled masking of correlated spans,"[""Yoav Levine"", ""Barak Lenz"", ""Opher Lieber"", ""Omri Abend"", ""Kevin Leyton-Brown"", ""Moshe Tennenholtz"", ""Yoav Shoham""]","[""Language modeling"", ""BERT"", ""pointwise mutual information""]",Joint masking of correlated tokens significantly speeds up and improves BERT's pretraining ,2010.01825,cs.LG,2020-10-05 07:19:52+00:00,2020-10-05 07:19:52+00:00
3EM0a2wC-jo,2021,Reject,False,Learning Online Data Association,"[""Yilun Du"", ""Joshua B. Tenenbaum"", ""Tomas Perez"", ""Leslie Pack Kaelbling""]","[""Data Association""]",,,,,
3F0Qm7TzNDM,2021,Reject,False,Variance Based Sample Weighting for Supervised Deep Learning,"[""Paul Novello"", ""Ga\u00ebl Po\u00ebtte"", ""David Lugato"", ""Pietro Congedo""]","[""supervised learning"", ""sample distribution"", ""statistical methods"", ""sample weighting"", ""approximation theory"", ""Taylor expansion""]",This paper constructs a new training distribution to weight the training data set and boost the performances of a Neural Network.,2101.07561,stat.ML,2021-01-19 11:08:40+00:00,2021-01-28 12:50:28+00:00
3FAl0W6gZ_e,2021,Reject,True,Three Dimensional Reconstruction of Botanical Trees with Simulatable Geometry,"[""Ed Quigley"", ""Winnie Lin"", ""Yilin Zhu"", ""Ronald Fedkiw""]",[],,1812.08849,cs.CV,2018-12-20 21:22:43+00:00,2018-12-20 21:22:43+00:00
3FK30d5BZdu,2021,Reject,True,Hidden Incentives for Auto-Induced Distributional Shift,"[""David Krueger"", ""Tegan Maharaj"", ""Jan Leike""]","[""distributional shift"", ""social impact of AI"", ""content recommendation"", ""incentives"", ""meta-learning""]","You can maximizing clicks by showing users what they want, or changing what they want to see; Population-based training could lead to the 2nd (undesirable) type of solution.",2009.09153,cs.LG,2020-09-19 03:31:27+00:00,2020-09-19 03:31:27+00:00
3FkrodAXdk,2021,Reject,False,Deep Ensembles with Hierarchical Diversity Pruning,"[""Yanzhao Wu"", ""Ling Liu""]","[""Ensemble"", ""Diversity Metrics"", ""Hierarchical Pruning"", ""Ensemble Accuracy"", ""Deep Neural Networks""]",Our proposed HQ-metrics significantly outperformed the state-of-the-art Q-metrics in effective selecting high quality deep ensembles.,,,,
3FvF1db-bKT,2022,Reject,True,Local Augmentation for Graph Neural Networks,"['Songtao Liu', 'Hanze Dong', 'Lanqing Li', 'Tingyang Xu', 'Yu Rong', 'Peilin Zhao', 'Junzhou Huang', 'Dinghao Wu']","[""Local Augmentation"", ""Graph Neural Networks""]",,2109.03856,cs.LG,2021-09-08 18:10:08+00:00,2021-12-01 14:13:30+00:00
3GHHpYrYils,2022,Reject,False,On Anytime Learning at Macroscale,"['Lucas Caccia', 'Jing Xu', 'Myle Ott', 'MarcAurelio Ranzato', 'Ludovic Denoyer']","[""Anytime Learning"", ""Mixture of experts"", ""growing architectures""]",We investigate and formalize the setting where data arrive sequentially in large batches over time,,,,
3GYfIYvNNhL,2021,Reject,False,Characterizing Structural Regularities of Labeled Data in Overparameterized Models,"[""Ziheng Jiang"", ""Chiyuan Zhang"", ""Kunal Talwar"", ""Michael Curtis Mozer""]",[],,,,,
3HJOA-1hb0e,2022,Accept (Poster),False,Toward Efficient Low-Precision Training: Data Format Optimization and Hysteresis Quantization,"['Sunwoo Lee', 'Jeongwoo Park', 'Dongsuk Jeon']","[""low-precision training"", ""quantized training"", ""logarithmic weight"", ""data format optimization"", ""hysteresis quantization""]",We propose a systematic data format optimization method and hysteresis quantization scheme to enable efficient low-precision training.,,,,
3ILxkQ7yElm,2022,Accept (Poster),False,Learning Continuous Environment Fields via Implicit Functions,"['Xueting Li', 'Sifei Liu', 'Shalini De Mello', 'Xiaolong Wang', 'Ming-Hsuan Yang', 'Jan Kautz']","[""Continuous Scene Representation"", ""Implicit Neural Networks""]",We propose a novel scene representation that can dynamically change behaviors of agents inside the scene.,,,,
3InxcRQsYLf,2021,Reject,False,VideoGen: Generative Modeling of Videos using VQ-VAE and Transformers,"[""Yunzhi Zhang"", ""Wilson Yan"", ""Pieter Abbeel"", ""Aravind Srinivas""]","[""video generation"", ""vqvae"", ""transformers"", ""gpt""]",Video generation model with latent space autoregressive transformer,,,,
3JI45wPuReY,2021,Reject,False,Neural Network Surgery: Combining Training with Topology Optimization,"[""Elisabeth Schiessler"", ""Roland Aydin"", ""Kevin Linka"", ""Christian Cyron""]","[""Neural Architecture Search"", ""Genetic Algorithm"", ""SVD""]",We demonstrate a hybrid approach for combining neural network training with a genetic-algorithm based architecture optimization.,,,,
3Li0OPkhQU,2022,Reject,False,Provable Learning of Convolutional Neural Networks with Data Driven Features,"['Alon Brutzkus', 'Amir Globerson', 'eran malach', 'Shai Shalev-Shwartz']","[""Deep learning theory"", ""convolutional neural networks""]",,,,,
3LujMJM9EMp,2021,Reject,False,DEMI: Discriminative Estimator of Mutual Information ,"[""Ruizhi Liao"", ""Daniel Moyer"", ""Polina Golland"", ""William M Wells""]","[""Mutual information estimation"", ""discriminative classification""]",,,,,
3M3t3tUbA2Y,2022,Reject,False,DreamerPro: Reconstruction-Free Model-Based Reinforcement Learning with Prototypical Representations,"['Fei Deng', 'Ingook Jang', 'Sungjin Ahn']","[""model-based reinforcement learning"", ""representation learning""]",,,,,
3MjOIZ2CF9,2022,Reject,False,An evaluation of quality and robustness of smoothed explanations,"['Ahmad Ajalloeian', 'Seyed-Mohsen Moosavi-Dezfooli', 'Michalis Vlachos', 'Pascal Frossard']","[""Explanation methods"", ""Interpretability"", ""Robustness"", ""Adversarial attacks""]",We evaluate the smoothed explanations in terms of their quality and robustness properties.,,,,
3Od_-TkEdnG,2022,Reject,False,Domain-wise Adversarial Training for Out-of-Distribution Generalization,"['Shiji Xin', 'Yifei Wang', 'Jingtong Su', 'Yisen Wang']","[""Domain Generalization"", ""IRM"", ""Adversarial Training""]","We explore the similarity between Invariant Risk Minimization (IRM) and Adversarial Training (AT), based on which we propose a Domain-wise AT (DAT) with superior performance on benchmark OOD datasets.",,,,
3PN4iyXBeF,2022,Accept (Poster),False,Amortized Implicit Differentiation for Stochastic Bilevel Optimization,"['Michael Arbel', 'Julien Mairal']","[""bilevel optimization"", ""stochastic optimization""]",We provide a unified framework for analyzing bilevel optimization algorithm based on approximate implicit differentiation with a warm-start strategy,2111.14580,math.OC,2021-11-29 15:10:09+00:00,2021-11-30 04:43:47+00:00
3Pbra-_u76D,2022,Accept (Poster),False,Rethinking Network Design and Local Geometry in Point Cloud: A Simple Residual MLP Framework,"['Xu Ma', 'Can Qin', 'Haoxuan You', 'Haoxi Ran', 'Yun Fu']","[""point cloud representation"", ""local relation"", ""mlp""]","In this paper, we present a new design for point cloud analysis , dubbed as PointMLP, which delivers new state-of-the-art results on multiple benchmarks and exhibits gratifying inference speed.",,,,
3Qh8ezpsca,2022,Reject,False,Towards simple time-to-event modeling: optimizing neural networks via rank regression,"['Hyunjun Lee', 'Junhyun Lee', 'Taehwa Choi', 'Jaewoo Kang', 'Sangbum Choi']","[""time-to-event analysis"", ""survival analysis"", ""semiparametric method"", ""accelerated failure time""]","We introduce a Deep AFT Rank-regression for Time-to-event prediction model (DART), which is a deep learning-based semiparametric AFT model, and propose a L1-type rank loss function that is more suitable for optimizing neural networks.",,,,
3R--2TdxMps,2021,Reject,False,Defuse: Debugging Classifiers Through Distilling Unrestricted Adversarial Examples,"[""Dylan Z Slack"", ""Nathalie Rauschmayr"", ""Krishnaram Kenthapadi""]","[""debugging"", ""interpretability"", ""explainability""]",We propose failure scenarios -- regions in the latent space of a generative model which are heaviliy misclassified -- and Defuse -- a framework that fixes the predictions in these scenarios.,,,,
3RLN4EPMdYd,2021,Accept (Poster),False,Revisiting Hierarchical Approach for Persistent Long-Term Video Prediction,"[""Wonkwang Lee"", ""Whie Jung"", ""Han Zhang"", ""Ting Chen"", ""Jing Yu Koh"", ""Thomas Huang"", ""Hyungsuk Yoon"", ""Honglak Lee"", ""Seunghoon Hong""]","[""Video prediction"", ""generative model"", ""long-term prediction""]",We propose a simple yet effective hierarchical video prediction model that can synthesize future frames orders of magnitude longer than existing methods (thousands frames),2104.06697,cs.CV,2021-04-14 08:39:38+00:00,2021-04-14 08:39:38+00:00
3SV-ZePhnZM,2021,Accept (Poster),False,Incremental few-shot learning via vector quantization in deep embedded space,"[""Kuilin Chen"", ""Chi-Guhn Lee""]","[""incremental learning"", ""few-shot"", ""vector quantization""]",,,,,
3Skn65dgAr4,2022,Reject,False,Differentiable Self-Adaptive Learning Rate,"['Bozhou Chen', 'Hongzhi Wang', 'Chenmin Ba']","[""self-adaptive learning rate""]",We achieve truly self-adaptive learning rate because it is differentiable with the goal of minizing loss function.,,,,
3SqrRe8FWQ-,2021,Accept (Poster),False,WrapNet:  Neural Net Inference with Ultra-Low-Precision Arithmetic,"[""Renkun Ni"", ""Hong-min Chu"", ""Oscar Castaneda"", ""Ping-yeh Chiang"", ""Christoph Studer"", ""Tom Goldstein""]","[""quantization"", ""efficient inference""]","We adapt neural networks to integer overflow and extreme low-bit accumulator, and show the efficacy on both software and hardware platforms. ",,,,
3T9iFICe0Y9,2021,Accept (Poster),True,The Recurrent Neural Tangent Kernel,"[""Sina Alemohammad"", ""Zichao Wang"", ""Randall Balestriero"", ""Richard Baraniuk""]","[""Neural Tangent Kernel"", ""Recurrent Neural Network"", ""Gaussian Process"", ""Overparameterization""]",,2006.10246,cs.LG,2020-06-18 02:59:21+00:00,2021-06-15 00:43:41+00:00
3UDSdyIcBDA,2021,Accept (Spotlight),False,RMSprop converges with proper hyper-parameter,"[""Naichen Shi"", ""Dawei Li"", ""Mingyi Hong"", ""Ruoyu Sun""]","[""RMSprop"", ""convergence"", ""hyperparameter""]",,,,,
3UTezOEABr,2021,Reject,False,TimeAutoML: Autonomous Representation Learning for Multivariate Irregularly  Sampled Time Series,"[""Yang Jiao"", ""Kai Yang"", ""shaoyu dou"", ""pan luo"", ""Sijia Liu"", ""Dongjin Song""]","[""representation learning"", ""AutoML"", ""irregularly sampled time series"", ""anomaly detection"", ""clustering""]",This paper presents an autonomous representation learning approach for multivariate irregularly  sampled time series. ,,,,
3Wp8HM2CNdR,2021,Reject,True,Whitening for Self-Supervised Representation Learning,"[""Aleksandr Ermolov"", ""Aliaksandr Siarohin"", ""Enver Sangineto"", ""Nicu Sebe""]","[""self-supervised learning"", ""unsupervised learning"", ""contrastive loss"", ""triplet loss"", ""whitening""]",self-supervised loss based on whitening,2007.06346,cs.LG,2020-07-13 12:33:25+00:00,2021-05-14 15:10:06+00:00
3Wybo29gGlx,2022,Reject,False,Should we Replace CNNs with Transformers for Medical Images?,"['Christos Matsoukas', 'Johan Fredin Haslum', 'Moein Sorkhei', 'Magnus Soderberg', 'Kevin Smith']","[""vision transformers"", ""medical image analysis""]",We investigate whether vision transformers can be used as drop-in replacements for CNNs in medical image analysis tasks,,,,
3X64RLgzY6O,2021,Accept (Poster),True,Direction Matters: On the Implicit Bias of Stochastic Gradient Descent with Moderate Learning Rate,"[""Jingfeng Wu"", ""Difan Zou"", ""Vladimir Braverman"", ""Quanquan Gu""]","[""SGD"", ""regularization"", ""implicit bias""]",We show a directional regularization effect for SGD with moderate learning rate,2011.02538,cs.LG,2020-11-04 21:07:52+00:00,2021-03-29 17:24:24+00:00
3XD_rnM97s,2022,Reject,False,Understanding Knowledge Integration in Language Models with Graph Convolutions,"['Yifan Hou', 'Guoji Fu', 'MRINMAYA SACHAN']","[""knowledge integration"", ""graph convolution"", ""language model"", ""interpretation"", ""knowledge graph"", ""mutual information""]",,2202.00964,cs.CL,2022-02-02 11:23:36+00:00,2022-02-10 22:27:19+00:00
3YQAVD9_Dz3,2021,Reject,False,NOSE Augment: Fast and Effective Data Augmentation Without Searching,"[""Qingrui Li"", ""Song Xie"", ""An\u0131l Oymagil"", ""Mustafa Furkan Eseoglu"", ""Ziyin Zhang"", ""CM Lee""]","[""data augmentation"", ""stochastic policy"", ""multi-stage augmentation""]",Fast and Effective Data Augmentation Without Searching,,,,
3YdNZD5dMxI,2021,Reject,True,Unconditional Synthesis of Complex Scenes Using a Semantic Bottleneck,"[""Samaneh Azadi"", ""Michael Tschannen"", ""Eric Tzeng"", ""Sylvain Gelly"", ""Trevor Darrell"", ""Mario Lucic""]","[""Unconditional Image Synthesis"", ""Complex Scene"", ""GAN"", ""Semantic Bottleneck""]",We propose a semantic bottleneck GAN model for unconditional synthesis of complex scenes which outperforms state-of-the-art unsupervised generative models.,1911.11357,cs.LG,2019-11-26 06:01:09+00:00,2019-11-26 06:01:09+00:00
3YqeuCVwy1d,2022,Accept (Poster),False,GDA-AM: ON THE EFFECTIVENESS OF SOLVING MIN-IMAX OPTIMIZATION VIA ANDERSON MIXING,"['Huan He', 'Shifan Zhao', 'Yuanzhe Xi', 'Joyce Ho', 'Yousef Saad']",[],,,,,
3ZeGLibhFo0,2021,Reject,False,Enabling counterfactual survival analysis with balanced representations,"[""Paidamoyo Chapfuwa"", ""Serge Assaad"", ""Shuxi Zeng"", ""Michael Pencina"", ""Lawrence Carin"", ""Ricardo Henao""]","[""survival analysis"", ""time-to-event"", ""counterfactual inference"", ""causal survival analysis""]","We propose a counterfactual survival analysis framework for adjusting for bias from two unknown sources, namely, confounding due to covariate dependent selection bias and censoring mechanism (informative or non-informative).",,,,
3c3EhwbKoXw,2021,Reject,True,Spectral Synthesis for Satellite-to-Satellite Translation,"[""Thomas Vandal"", ""Daniel McDuff"", ""Weile Wang"", ""Andrew Michaelis"", ""Ramakrishna Nemani""]",[],,2010.06045,cs.CV,2020-10-12 21:36:39+00:00,2020-10-12 21:36:39+00:00
3eIrli0TwQ,2022,Accept (Poster),False,On the Importance of Difficulty Calibration in Membership Inference Attacks,"['Lauren Watson', 'Chuan Guo', 'Graham Cormode', 'Alexandre Sablayrolles']","[""membership inference attack"", ""privacy""]","Membership inference attacks can greatly benefit from a technique called difficulty calibration, significantly improving their reliability.",,,,
3eNrIs9I78x,2021,Reject,False,SALR: Sharpness-aware Learning Rates for Improved Generalization,"[""Xubo Yue"", ""Maher Nouiehed"", ""Raed Al Kontar""]","[""Loss-surface"", ""sharpness"", ""learning rate"", ""generalization""]",A Sharpness-aware Learning Rate Framework.,2011.05348,cs.LG,2020-11-10 19:00:52+00:00,2021-10-16 16:46:21+00:00
3hGNqpI4WS,2021,Accept (Poster),False,Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization,"[""Tatsuya Matsushima"", ""Hiroki Furuta"", ""Yutaka Matsuo"", ""Ofir Nachum"", ""Shixiang Gu""]","[""Reinforcement Learning"", ""deployment-efficiency"", ""offline RL"", ""Model-based RL""]","We propose a novel method that achieves both high sample-efficiency in offline RL and ""deployment-efficiency"" in online RL.",,,,
3iH9ewU_KJT,2022,Reject,False,MT-GBM: A Multi-Task Gradient Boosting Machine  with Shared Decision Trees,"['Zhenzhe Ying', 'Zhuoer Xu', 'LANQING XUE', 'Changhua Meng', 'Weiqiang Wang']","[""Multi-Task learning"", ""Classification""]","We propose an algorithm to combine gradients of all tasks to build the trees whose efficiency is on par with the original GBDT, to get that the performance of the main task significantly improved.",,,,
3jJKpFbLkU2,2021,Reject,True,Amortized Conditional Normalized Maximum Likelihood,"[""Aurick Zhou"", ""Sergey Levine""]","[""Uncertainty Estimation"", ""Calibration""]",,2011.02696,cs.LG,2020-11-05 08:04:34+00:00,2021-03-01 21:03:05+00:00
3jjmdp7Hha,2021,Accept (Poster),False,Meta Back-Translation,"[""Hieu Pham"", ""Xinyi Wang"", ""Yiming Yang"", ""Graham Neubig""]","[""meta learning"", ""machine translation"", ""back translation""]",Use meta learning to teach the back-translation model to generate better back-translated sentences.,,,,
3jooF27-0Wy,2022,Accept (Poster),False,FlexConv: Continuous Kernel Convolutions With Differentiable Kernel Sizes,"['David W. Romero', 'Robert-Jan Bruintjes', 'Jakub Mikolaj Tomczak', 'Erik J Bekkers', 'Mark Hoogendoorn', 'Jan van Gemert']","[""Convolutional neural networks"", ""learnable kernel size"", ""continuous convolutional kernels"", ""alias-free convolutional networks"", ""implicit neural representations"", ""resolution-agnostic representations"", ""time series"", ""sequential data"", ""computer vision""]","We provide a high bandwidth, alias-free convolutional kernel parameterization with learnable kernel size and constant parameter cost.",,,,
3k20LAiHYL2,2021,Accept (Poster),False,Pre-training Text-to-Text Transformers for Concept-centric Common Sense,"[""Wangchunshu Zhou"", ""Dong-Ho Lee"", ""Ravi Kiran Selvam"", ""Seyeon Lee"", ""Xiang Ren""]","[""Language Model Pre-training"", ""Commonsense Reasoning"", ""Self-supervised Learning""]",We propose self-supervised objectives and a joint training framework to augment pre-trained language models with common sense without relying on external knowledge bases.,,,,
3kTt_W1_tgw,2022,Reject,False,$f$-Mutual Information Contrastive Learning,"['Guojun Zhang', 'Yiwei Lu', 'Sun Sun', 'Hongyu Guo', 'Yaoliang Yu']","[""contrastive learning"", ""f-divergence"", ""mutual information""]",We provide a new framework for self-supervised contrastive learning by directly maximizing the $f$-divergence-based generalization of mutual information.,,,,
3mgYqlH60Uj,2022,Reject,False,Learning Symmetric Locomotion using Cumulative Fatigue for Reinforcement Learning,"['Rui Xu', 'Noshaba Cheema', 'Erik Herrmann', 'Perttu HÃ¤mÃ¤lÃ¤inen', 'Philipp Slusallek']","[""reinforcement learning"", ""biomechanical model"", ""cumulative fatigue"", ""animation"", ""bioinspired models"", ""physics-based simulation"", ""locomotion""]",,,,,
3mm5rjb7nR8,2022,Reject,False,Learning Global Spatial Information for Multi-View Object-Centric Models,"['Yuya Kobayashi', 'Masahiro Suzuki', 'Yutaka Matsuo']","[""deep generative models"", ""object-centric representation learning"", ""segmentation""]",Introducing global representation to multi-view object-centric model for further inference quality and for gaining novel scene generation ability.,,,,
3nSU-sDEOG9,2021,Reject,False,Empirical Sufficiency Featuring Reward Delay Calibration,"[""Yixuan Liu"", ""Hu Wang"", ""Xiaowei Wang"", ""Xiaoyue Sun"", ""Liuyue Jiang"", ""Minhui Xue""]","[""Deep Reinforcement Learning"", ""Reward Calibration"", ""Empirical Sufficiency"", ""Overfitting.""]",We give an empirical sufficient condition to calibrate DRL reward delay by using an overfitting classifier.,,,,
3pZTPQjeQDR,2022,Reject,True,How BPE Affects Memorization in Transformers,"['Eugene Kharitonov', 'Marco Baroni', 'Dieuwke Hupkes']","[""training data memorization"", ""Byte-Pair Encoding"", ""Transformers""]",Larger BPE vocabulary sizes lead to increased ability and tendency for training data memorization in Transformers.,2110.02782,cs.CL,2021-10-06 14:01:56+00:00,2021-12-02 09:54:05+00:00
3pugbNqOh5m,2022,Accept (Poster),False,Practical Conditional Neural Process Via Tractable Dependent Predictions,"['Stratis Markou', 'James Requeima', 'Wessel Bruinsma', 'Anna Vaughan', 'Richard E Turner']","[""conditional neural processes"", ""neural processes"", ""meta-learning"", ""convolutional conditional neural processes"", ""Gaussian neural processes""]",,,,,
3q5IqUrkcF,2021,Accept (Poster),False,Implicit Gradient Regularization,"[""David Barrett"", ""Benoit Dherin""]","[""implicit regularization"", ""deep learning"", ""deep learning theory"", ""theoretical issues in deep learning"", ""theory"", ""regularization""]","We have found a hidden form of regularization in gradient descent - Implicit Gradient Regularization - that biases overparameterized models towards flat, low test error solutions and helps us to understand why deep learning works so well.",,,,
3r034NfDKnL,2022,Reject,False,"The Role of Learning Regime, Architecture and Dataset Structure on Systematic Generalization in Simple Neural Networks","['Devon Jarvis', 'Richard Klein', 'Benjamin Rosman', 'Andrew M Saxe']","[""Systematic Generalization"", ""Iterated Learning"", ""Linear Neural Networks""]",We theoretically and empirically studied the ability of simple NNs to acquire systematic knowledge.,,,,
3rRgu7OGgBI,2021,Reject,False,Bi-tuning of Pre-trained Representations,"[""Jincheng Zhong"", ""Ximei Wang"", ""Zhi Kou"", ""Jianmin Wang"", ""Mingsheng Long""]","[""Deep learning"", ""fine-tuning"", ""pre-training""]",This paper proposes a general approach to deeply fine-tuning both supervised and unsupervised pre-trained representations to downstream tasks.,,,,
3rULBvOJ8D2,2022,Accept (Poster),False,Unraveling Model-Agnostic Meta-Learning via The Adaptation Learning Rate,"['Yingtian Zou', 'Fusheng Liu', 'Qianxiao Li']","[""Meta-Learning"", ""Learning rate"", ""Optimization""]",Theoretical analysis of Model-Agnostic Meta-Learning (MAML) through the inner loop (adaptation) learning rate.,,,,
3tFAs5E-Pe,2021,Accept (Poster),False,Continuous Wasserstein-2 Barycenter Estimation without Minimax Optimization,"[""Alexander Korotin"", ""Lingxiao Li"", ""Justin Solomon"", ""Evgeny Burnaev""]","[""wasserstein-2 barycenters"", ""non-minimax optimization"", ""cycle-consistency regularizer"", ""input convex neural networks"", ""continuous case""]",We present a new algorithm to compute Wasserstein-2 barycenters of continuous distributions powered by a straightforward optimization procedure without introducing bias or a generative model.,2102.01752,cs.LG,2021-02-02 21:01:13+00:00,2021-02-02 21:01:13+00:00
3tbDrs77LJ5,2022,Accept (Poster),True,Large Learning Rate Tames Homogeneity: Convergence and Balancing Effect,"['Yuqing Wang', 'Minshuo Chen', 'Tuo Zhao', 'Molei Tao']","[""large learning rate"", ""gradient descent"", ""matrix factorization"", ""implicit regularization"", ""convergence"", ""balancing"", ""alignment""]",Large learning rate well beyond 2/L provably induces an implicit regularization effect of balancing in gradient descent for matrix factorization.,2110.03677,cs.LG,2021-10-07 17:58:21+00:00,2021-10-07 17:58:21+00:00
3teh9zI0j4L,2021,Reject,False,Quantifying Exposure Bias for Open-ended Language Generation,"[""Tianxing He"", ""Jingzhao Zhang"", ""Zhiming Zhou"", ""James R. Glass""]","[""exposure bias"", ""natural language generation"", ""autoregressive""]","We design metrics to quantify the impact of the exposure bias problem, but find it to be only a minor problem for open-ended language generation.",,,,
3u3ny6UYmjy,2021,Reject,False,RetCL: A Selection-based Approach for Retrosynthesis via Contrastive Learning,"[""Hankook Lee"", ""Sungsoo Ahn"", ""Seung-Woo Seo"", ""You Young Song"", ""Eunho Yang"", ""Sung Ju Hwang"", ""Jinwoo Shin""]","[""molecule"", ""retrosynthesis"", ""contrastive learning"", ""graph representation learning""]",We propose a framework to consider the commercial availability of reactants for retrosynthesis. ,,,,
3uiR9bkbDjL,2021,Reject,False,ColdExpand: Semi-Supervised Graph Learning in Cold Start,"[""Il-Jae Kwon"", ""Kyoung-Woon On"", ""Dong-Geon Lee"", ""Byoung-Tak Zhang""]","[""Graph Neural Networks"", ""Cold Start"", ""Semi-supervised Learning""]","This paper draws attention to a new task Expanded Semi-Supervised Learning, and propose the ColdExpand method which uses multi-task strategy to overcome the lack of topological information in the cold start setting.",,,,
3wNcr5nq56,2022,Accept (Poster),True,The Uncanny Similarity of Recurrence and Depth,"['Avi Schwarzschild', 'Arjun Gupta', 'Amin Ghiasi', 'Micah Goldblum', 'Tom Goldstein']","[""Deep learning"", ""recurrent networks"", ""depth""]",We show quantitatively and qualitatively that recurrent models have the same behaviors as feed-forward networks despite reusing parameters at each recurrence.,2102.11011,cs.LG,2021-02-22 14:09:20+00:00,2021-06-08 17:10:22+00:00
3wU2UX0voE,2022,Accept (Oral),True,The Information Geometry of Unsupervised Reinforcement Learning,"['Benjamin Eysenbach', 'Ruslan Salakhutdinov', 'Sergey Levine']","[""unsupervised skill learning"", ""reward-free RL"", ""mutual information"", ""DIAYN""]",We show that mutual information skill learning is optimal in one sense but not optimal in another sense.,2110.02719,cs.LG,2021-10-06 13:08:36+00:00,2021-10-06 13:08:36+00:00
3xUBgZQ04X,2021,Reject,False,The Bures Metric for Taming Mode Collapse in Generative Adversarial Networks,"[""Hannes De Meulemeester"", ""Joachim Schreurs"", ""Micha\u00ebl Fanuel"", ""Bart De Moor"", ""Johan Suykens""]","[""Generative Adversarial Networks"", ""Deep Learning"", ""Neural Networks""]",,,,,
3z9RnbAS49,2022,Reject,False,A Theoretical and Empirical Model of the Generalization Error under Time-Varying Learning Rate,"['Toru Makuuchi', 'YUSUKE Mukuta', 'Tatsuya Harada']","[""deep learning"", ""generalization error"", ""stochastic gradient descent"", ""functional form"", ""hyperparameter"", ""batch size"", ""learning rate""]","We modeled the generalization error for the batch size and learning rate in both the constant and time-varying case, then used the model for hyperparamter optimization.",,,,
3zaVN0M0BIb,2021,Reject,False,Learning and Generalization in Univariate Overparameterized Normalizing Flows,"[""Kulin Shah"", ""Amit Deshpande"", ""Navin Goyal""]",[],,2106.10535,cs.LG,2021-06-19 17:11:42+00:00,2021-06-19 17:11:42+00:00
4-D6CZkRXxI,2022,Accept (Spotlight),False,Value Gradient weighted Model-Based Reinforcement Learning,"['Claas A Voelcker', 'Victor Liao', 'Animesh Garg', 'Amir-massoud Farahmand']","[""model-based reinforcement learning"", ""reinforcment learning"", ""objective mismatch"", ""value function"", ""sensitivity""]","We propose the Value-gradient weighted Model loss, a method for value-aware model learning in challenging settings, such as small model capacity and the presence of distracting state dimensions.",,,,
412_KkkGjJ4,2021,Reject,False,Weakly Supervised Scene Graph Grounding,"[""Yizhou Zhang"", ""Zhaoheng Zheng"", ""Yan Liu""]","[""Weakly Supervised Learning"", ""Scene Graph Grounding"", ""Visual Relation"", ""Computer Vision""]",We propose the task of weakly supervised scene graph grounding and provide a state-of-the-art solution.,,,,
41e9o6cQPj,2022,Accept (Spotlight),False,GreaseLM: Graph REASoning Enhanced Language Models,"['Xikun Zhang', 'Antoine Bosselut', 'Michihiro Yasunaga', 'Hongyu Ren', 'Percy Liang', 'Christopher D Manning', 'Jure Leskovec']","[""language models"", ""commonsense"", ""question answering"", ""knowledge graphs"", ""KG augmentation""]","We propose GreaseLM, a new model that fuses encoded representations from pretrained LMs and GNNs over multiple layers of modality interaction operations, allowing both modalities to bidirectionally inform the representation of the other.",,,,
42kiJ7n_8xO,2021,Accept (Poster),False,The geometry of integration in text classification RNNs,"[""Kyle Aitken"", ""Vinay Venkatesh Ramasesh"", ""Ankush Garg"", ""Yuan Cao"", ""David Sussillo"", ""Niru Maheswaranathan""]","[""Recurrent neural networks"", ""dynamical systems"", ""interpretability"", ""document classification"", ""reverse engineering""]","We study text classification RNNs using tools from dynamical systems analysis, finding and explaining the geometry of low-dimensional attractor manifolds.",,,,
43VKWxg_Sqr,2021,Accept (Poster),True,Unsupervised Audiovisual Synthesis via Exemplar Autoencoders,"[""Kangle Deng"", ""Aayush Bansal"", ""Deva Ramanan""]","[""unsupervised learning"", ""autoencoders"", ""speech-impaired"", ""assistive technology"", ""audiovisual synthesis"", ""voice conversion""]",We present an unsupervised approach that converts the input speech of any individual into audiovisual streams of potentially-infinitely many output speakers.,2001.04463,cs.CV,2020-01-13 18:56:45+00:00,2021-07-03 05:24:44+00:00
45L_dgP48Vd,2022,Accept (Spotlight),False,Graph-Augmented Normalizing Flows for Anomaly Detection of Multiple Time Series,"['Enyan Dai', 'Jie Chen']","[""Anomaly Detection"", ""Normalizing Flow"", ""DAG"", ""Multiple Time Series""]",,,,,
45Mr7LeKR9,2022,Accept (Spotlight),False,Explanations of Black-Box Models based on Directional Feature Interactions,"['Aria Masoomi', 'Davin Hill', 'Zhonghui Xu', 'Craig P Hersh', 'Edwin K. Silverman', 'Peter J. Castaldi', 'Stratis Ioannidis', 'Jennifer Dy']","[""Explainability"", ""Shapley values"", ""Interpretability"", ""Directional interaction"", ""feature interaction""]",We introduce a bivariate explainer to explain directional feature interactions in black box models. ,,,,
45NZvF1UHam,2021,Accept (Poster),False,Identifying Physical Law of Hamiltonian Systems via Meta-Learning,"[""Seungjun Lee"", ""Haesang Yang"", ""Woojae Seong""]","[""Learning physical laws"", ""meta-learning"", ""Hamiltonian systems""]",We introduce meta-learning algorithms to identify the shared representation of Hamiltonian systems.,2102.11544,cs.LG,2021-02-23 08:16:13+00:00,2021-02-23 08:16:13+00:00
45uOPa46Kh,2021,Accept (Poster),True,Generative Language-Grounded Policy in Vision-and-Language Navigation with Bayes' Rule,"[""Shuhei Kurita"", ""Kyunghyun Cho""]","[""vision-and-language-navigation""]",We propose the novel generative language-grounded policy for vision-and-language navigation(VLN).,2009.07783,cs.CL,2020-09-16 16:23:17+00:00,2020-10-08 17:16:49+00:00
46lmrnVBHBL,2022,Reject,False,Explanatory Learning: Beyond Empiricism in Neural Networks,"['Antonio Norelli', 'Giorgio Mariani', 'Luca Moschella', 'Andrea Santilli', 'Giambattista Parascandolo', 'Simone Melzi', 'Emanuele RodolÃ ']","[""explainability"", ""rationalism"", ""deep learning""]","We introduce Explanatory Learning (EL), an explanation-driven machine learning framework to use existing knowledge buried in symbolic sequences expressed in an unknown language.",2201.10222,cs.LG,2022-01-25 10:21:53+00:00,2022-01-25 10:21:53+00:00
48RBsJwGkJf,2022,Accept (Poster),False,CrossMatch: Cross-Classifier Consistency Regularization for Open-Set Single Domain Generalization,"['Ronghang Zhu', 'Sheng Li']","[""Single Domain Generalization"", ""Open-Set Recognition""]",,,,,
48goXfYCVFX,2021,Reject,False,Interpretable Relational Representations for Food Ingredient Recommendation Systems,"[""Kana Maruyama"", ""Michael Spranger""]","[""Metric Learning"", ""Gastronomy"", ""Memory Network"", ""Knowledge Graph"", ""Interpretable""]",,,,,
49A1Y6tRhaq,2022,Accept (Spotlight),False,Linking Emergent and Natural Languages via Corpus Transfer,"['Shunyu Yao', 'Mo Yu', 'Yang Zhang', 'Karthik R Narasimhan', 'Joshua B. Tenenbaum', 'Chuang Gan']","[""Emergent Language"", ""Emergent Communication"", ""Transfer Learning""]","We find that pre-training on an emergent language corpus improves natural language tasks in a low resource setup, and propose a metric to predict such a transferability.",,,,
49V11oUejQ,2021,Reject,True,Efficient Robust Training via Backward Smoothing,"[""Jinghui Chen"", ""Yu Cheng"", ""Zhe Gan"", ""Quanquan Gu"", ""Jingjing Liu""]","[""Efficient Robust Training"", ""Backward Smoothing"", ""Robustness""]","We propose a new principle towards understanding Fast Adversarial Training, and a new initialization strategy that significantly improves both stability and model robustness over the single-step robust training methods.",2010.01278,cs.LG,2020-10-03 04:37:33+00:00,2020-10-03 04:37:33+00:00
49h_IkpJtaE,2022,Accept (Poster),False,How to Train Your MAML to Excel in Few-Shot Classification,"['Han-Jia Ye', 'Wei-Lun Chao']","[""meta-learning"", ""few-shot learning"", ""classification"", ""MAML""]",,,,,
49mMdsxkPlD,2021,Reject,True,Iterative Amortized Policy Optimization,"[""Joseph Marino"", ""Alexandre Pich\u00e9"", ""Alessandro Davide Ialongo"", ""Yisong Yue""]","[""Reinforcement Learning"", ""Policy Optimization"", ""Amortization"", ""Variational Inference""]","Policy networks in RL are direct amortized optimizers, and we demonstrate the benefits of using more flexible iterative amortized optimizers.",2010.10670,cs.LG,2020-10-20 23:25:42+00:00,2021-10-22 20:44:57+00:00
4ADnf1HqIw,2021,Reject,True,Recovering Geometric Information with Learned Texture Perturbations,"[""Jane Wu"", ""Yongxu Jin"", ""Zhenglin Geng"", ""Hui Zhou"", ""Ronald Fedkiw""]",[],,2001.07253,cs.CV,2020-01-20 21:15:13+00:00,2020-01-20 21:15:13+00:00
4AWko4A35ss,2021,Reject,False,Self-Supervised Video Representation Learning with Constrained Spatiotemporal Jigsaw,"[""Yuqi Huo"", ""Mingyu Ding"", ""Haoyu Lu"", ""Zhiwu Lu"", ""Tao Xiang"", ""Ji-Rong Wen"", ""Ziyuan Huang"", ""Jianwen Jiang"", ""Shiwei Zhang"", ""Mingqian Tang"", ""Songfang Huang"", ""Ping Luo""]","[""self-supervised learning"", ""video representation learning"", ""spatiotemporal jigsaw""]",This is the first work on self-supervised video representation learning that leverages spatiotemporal jigsaw understanding.,,,,
4AZz9osqrar,2022,Accept (Spotlight),True,Self-supervised Learning is More Robust to Dataset Imbalance,"['Hong Liu', 'Jeff Z. HaoChen', 'Adrien Gaidon', 'Tengyu Ma']","[""self-supervised learning"", ""dataset imbalance"", ""representation learning"", ""long-tailed recognition""]","We show that self-supervised pre-training yields representations more robust to dataset imbalance, because it captures more diverse features from the frequent classes, and can be improved further by re-weighting regularization.",2110.05025,cs.LG,2021-10-11 06:29:56+00:00,2021-10-11 06:29:56+00:00
4C93Qvn-tz,2022,Accept (Poster),True,MCMC Should Mix: Learning Energy-Based Model with Flow-Based Backbone,"['Erik Nijkamp', 'Ruiqi Gao', 'Pavel Sountsov', 'Srinivas Vasudevan', 'Bo Pang', 'Song-Chun Zhu', 'Ying Nian Wu']","[""Generative models"", ""energy-based models"", ""MCMC""]",Learning energy-based models with mixing Markov chains.,2006.06897,stat.ML,2020-06-12 01:25:51+00:00,2020-06-12 01:25:51+00:00
4CqesJ7GO7Q,2021,Reject,False,Intriguing class-wise properties of adversarial training,"[""Qi Tian"", ""Kun Kuang"", ""Fei Wu"", ""Yisen Wang""]","[""adversarial training"", ""class-wise properties"", ""robustness"", ""adversarial example""]",Explore class-wise properties of adversarial training.,,,,
4CxsUBDQJqv,2021,Reject,True,Learning Intrinsic Symbolic Rewards in Reinforcement Learning,"[""Hassam Sheikh"", ""Shauharda Khadka"", ""Santiago Miret"", ""Somdeb Majumdar""]","[""Reinforcement Learning"", ""Intrinsic Rewards"", ""Symbolic Regression""]","A framework to discover intrinsic, dense rewards in the form of interpretable, symbolic rules which can then be used to train Deep RL policies",2010.03694,cs.LG,2020-10-08 00:02:46+00:00,2020-10-09 06:42:03+00:00
4D4Rjrwaw3q,2021,Reject,False,Black-Box Optimization Revisited: Improving Algorithm Selection Wizards through Massive Benchmarking,"[""Laurent Meunier"", ""Herilalaina Rakotoarison"", ""Jeremy Rapin"", ""Paco Wong"", ""Baptiste Roziere"", ""Olivier Teytaud"", ""Antoine Moreau"", ""Carola Doerr""]","[""black-box optimization"", ""mujoco"", ""wizard"", ""benchmarking"", ""BBOB"", ""LSGO""]",We propose a huge benchmark aggregating many well known benchmarks and derive an algorithm selection tool on it.,,,,
4GBHVfEcmoS,2022,Reject,False,Propagating Distributions through Neural Networks,"['Felix Petersen', 'Christian Borgelt', 'Mikhail Yurochkin', 'Hilde Kuehne', 'Oliver Deussen']","[""propagating distributions"", ""uncertainty quantification""]",,,,,
4HGL3H9eL9U,2021,Reject,True,AT-GAN: An Adversarial Generative Model for Non-constrained Adversarial Examples,"[""Xiaosen Wang"", ""Kun He"", ""Chuanbiao Song"", ""Liwei Wang"", ""John E. Hopcroft""]","[""adversarial examples"", ""adversarial attack"", ""generation-based attack"", ""adversarial generative model"", ""non-constrained adversarial examples""]","We propose to train an adversarial generative model called AT-GAN that aims to learn the distribution of adversarial examples, and can directly produce adversarial examples once trained.",1904.07793,cs.CV,2019-04-16 16:26:19+00:00,2020-02-07 18:11:58+00:00
4I5THWNSjC,2021,Reject,False,BasisNet: Two-stage Model Synthesis for Efficient Inference,"[""Mingda Zhang"", ""Andrey Zhmoginov"", ""Andrew G. Howard"", ""Brendan Jou"", ""Yukun Zhu"", ""Li Zhang"", ""Rebecca Hwa"", ""Adriana Kovashka""]",[],Use two-stage model synthesis to generate input-dependent specialist model for making more accurate predictions on given inputs.,,,,
4IwieFS44l,2021,Accept (Poster),False,Fooling a Complete Neural Network Verifier,"[""D\u00e1niel Zombori"", ""Bal\u00e1zs B\u00e1nhelyi"", ""Tibor Csendes"", ""Istv\u00e1n Megyeri"", ""M\u00e1rk Jelasity""]","[""adversarial examples"", ""complete verifiers"", ""numerical errors""]",We propose an attack (along with a defense)  to fool complete verification based on exploiting numerical errors.,,,,
4JLiaohIk9,2021,Reject,False,Motion Forecasting with Unlikelihood Training,"[""Deyao Zhu"", ""Mohamed Zahran"", ""Li Erran Li"", ""Mohamed Elhoseiny""]",[],,,,,
4JlwgTbmzXQ,2022,Reject,False,EqR: Equivariant Representations for Data-Efficient Reinforcement Learning,"['Arnab Kumar Mondal', 'Vineet Jain', 'Kaleem Siddiqi', 'Siamak Ravanbakhsh']","[""Equivariance"", ""Invariance"", ""Representation learning"", ""Reinforcement learning"", ""Symmetric MDPs"", ""MDP homomorphism"", ""Lie parameterization.""]",Equivariant representation learning for data-efficient reinforcement learning.,,,,
4KOJ5XJ_z5W,2022,Reject,False,Improving State-of-the-Art in One-Class Classification by Leveraging Unlabeled Data,"['Farid Bagirov', 'Dmitry Ivanov', 'Aleksei Shpilman']",[],,,,,
4K_NaDAHc0d,2021,Reject,False,Unsupervised Task Clustering for Multi-Task Reinforcement Learning,"[""Johannes Ackermann"", ""Oliver Paul Richter"", ""Roger Wattenhofer""]","[""Reinforcement Learning"", ""Multi-Task Learning"", ""Clustering"", ""Expectation-Maximization""]",We propose an expectation-maximization inspired approach that reduces negative transfer in multi-task reinforcement learning through unsupervised task clustering.,,,,
4Muj-t_4o4,2022,Accept (Poster),True,Learning a subspace of policies for online adaptation in Reinforcement Learning,"['Jean-Baptiste Gaya', 'Laure Soulier', 'Ludovic Denoyer']","[""Deep Reinforcement Learning"", ""Online adaptation""]",We propose an approach to learn a subspace of policies that are robust to different variations of the train environment. ,2110.05169,cs.LG,2021-10-11 11:43:34+00:00,2021-10-11 11:43:34+00:00
4N-17dske79,2022,Accept (Poster),False,"Associated Learning: an Alternative to End-to-End Backpropagation that Works on CNN, RNN, and Transformer","['Dennis Y.H. Wu', 'Dinan Lin', 'Vincent Chen', 'Hung-Hsuan Chen']","[""pipeline training"", ""parallel training"", ""backpropagation"", ""associated learning""]","This paper studies Associate Learning, an alternative methodology to the end-to-end backpropagation",,,,
4NNQ3l2hbN0,2021,Reject,False,Search Data Structure Learning,"[""Mathieu Duchesneau"", ""Hansenclever Bassani"", ""Alain Tapp""]","[""Machine Learning"", ""Search Data Structure"", ""Information Retrieval"", ""Binary Embeddings""]",We describe a new field of Machine Learning call Search Data Structure Learning for which we develop a novel model that outperforms related approaches. ,,,,
4Nt1F3qf9Gn,2021,Reject,True,"CLOCS: Contrastive Learning of Cardiac Signals Across Space, Time, and Patients","[""Dani Kiyasseh"", ""Tingting Zhu"", ""David A. Clifton""]","[""Contrastive learning"", ""physiological signals"", ""healthcare""]",,2005.13249,cs.LG,2020-05-27 09:25:41+00:00,2021-05-16 13:12:14+00:00
4P35MfnBQIY,2021,Reject,False,Consistency and Monotonicity Regularization for Neural Knowledge Tracing,"[""Seewoo Lee"", ""Youngduck Choi"", ""Juneyoung Park"", ""Byungsoo Kim"", ""Jinwoo Shin""]","[""knowledge tracing"", ""data augmentation"", ""regularization""]",We propose simple yet effective data augmentation strategies along with corresponding regularization losses for training knowledge tracing models.,2105.00607,cs.LG,2021-05-03 02:36:29+00:00,2021-05-03 02:36:29+00:00
4QUoBU27oXN,2022,Reject,False,Cognitively Inspired Learning of Incremental Drifting Concepts,"['Mohammad Rostami', 'Aram Galstyan']","[""Complementary Learning Systems"", ""continual learning"", ""Parallel Distributed Processing""]",,,,,
4RbdgBh9gE,2021,Accept (Poster),True,Teaching with Commentaries,"[""Aniruddh Raghu"", ""Maithra Raghu"", ""Simon Kornblith"", ""David Duvenaud"", ""Geoffrey Hinton""]","[""learning to teach"", ""metalearning"", ""hypergradients""]","We propose a flexible framework for neural network teaching, demonstrate it in various settings, and find that it can improve performance and yield insights about datasets and the training process.",2011.03037,cs.LG,2020-11-05 18:52:46+00:00,2021-03-12 00:37:38+00:00
4SZ9Ft--pDl,2021,Reject,False,Prior-guided Bayesian Optimization,"[""Artur Souza"", ""Luigi Nardi"", ""Leonardo Oliveira"", ""Kunle Olukotun"", ""Marius Lindauer"", ""Frank Hutter""]","[""Bayesian Optimization"", ""Automated Machine Learning""]",We introduce a novel Bayesian Optimization framework called PrBO that allows users to inject their expert knowledge into the optimization in the form of priors about which parts of the input space will yield the best performance.,,,,
4SiMia0kjba,2021,Reject,False,Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets,"[""Shixiang Wan"", ""Shikai Luo"", ""Hongtu Zhu""]","[""Spatio-temporal Prediction"", ""Causal Inference"", ""Efficient Transformers"", ""Two-sided Markets""]",We develop a novel causal transformer with causal inference and efficient taylor attention to address large scale spatio-temporal predictions. Our method achieves up to 15% error reduction compared with various baseline methods. ,,,,
4Stc6i97dVN,2022,Reject,False,Sharper Utility Bounds for Differentially Private Models,"['Yilin Kang', 'Yong Liu', 'Jian Li', 'Weipinng Wang']",[],,,,,
4T489T4yav,2021,Accept (Poster),True,Differentiable Segmentation of Sequences,"[""Erik Scharw\u00e4chter"", ""Jonathan Lennartz"", ""Emmanuel M\u00fcller""]","[""segmented models"", ""segmentation"", ""change point detection"", ""concept drift"", ""warping functions"", ""gradient descent""]",We propose an architecture for effective gradient-based learning of segmented models for sequential data.,2006.13105,cs.LG,2020-06-23 15:51:48+00:00,2021-01-18 11:11:04+00:00
4TSiOTkKe5P,2021,Accept (Poster),False,Latent Convergent Cross Mapping,"[""Edward De Brouwer"", ""Adam Arany"", ""Jaak Simm"", ""Yves Moreau""]","[""Causality"", ""Time Series"", ""Chaos"", ""Neural ODE"", ""Missing Values""]",Latent CCM uses reconstruction between latent processes of dynamical systems to infer causality between short and sporadic time series.,,,,
4Un_FnHiN8C,2021,Reject,False,Architecture Agnostic Neural Networks,"[""Sabera J Talukder"", ""Guruprasad Raghavan"", ""Yisong Yue""]","[""Architecture Agnostic"", ""Sparse"", ""Binary"", ""Stochastic"", ""Pruning"", ""Biologically Inspired""]",,,,,
4V4TZG7i7L_,2022,Reject,False,Hierarchical Multimodal Variational Autoencoders,"['Jannik Wolff', 'Rahul G Krishnan', 'Lukas Ruff', 'Jan Nikolas Morshuis', 'Tassilo Klein', 'Shinichi Nakajima', 'Moin Nabi']","[""hierarchical vae"", ""variational inference"", ""multimodal learning""]",Multimodal modal data can have hierarchical structure and hence deserves a hierarchical latent space,,,,
4VixXVZJkoY,2021,Reject,False,TRIP: Refining Image-to-Image Translation via Rival Preferences,"[""Yinghua Yao"", ""Yuangang Pan"", ""Ivor Tsang"", ""Xin Yao""]","[""Fine-grained image-to-image translation"", ""GAN"", ""relative attributes"", ""ranker""]","We propose TRIP consisting of a ranker and a generator for a high-quality fine-grained translation, where the rival preference is constructed to evoke the adversarial training between the ranker and the generator.",,,,
4XtpgPsvxE8,2022,Reject,False,Multi-Objective Model Selection for Time Series Forecasting,"['Oliver Borchert', 'David Salinas', 'Valentin Flunkert', 'Tim Januschowski', 'Stephan GÃ¼nnemann']","[""time series"", ""forecasting"", ""model selection"", ""multiobjective optimization"", ""transfer-learning"", ""tabular dataset.""]",A method and a benchmark to learn good defaults for time-series forecasting models that optimize not only accuracy but also latency.,,,,
4YOOO4ZNKM,2022,Reject,False,Self-supervised Learning for Sequential Recommendation with Model Augmentation,"['Zhiwei Liu', 'Yongjun Chen', 'Jia Li', 'Man Luo', 'Philip S. Yu', 'Caiming Xiong']","[""Sequential Recommendation"", ""Self-supervised Learning"", ""Contrastive Learning"", ""Model Augmentation""]",We propose a novel model augmentation SSL paradigm for sequential recommendation,,,,
4Ycr8oeCoIh,2022,Accept (Poster),False,"When, Why, and Which Pretrained GANs Are Useful?","['Timofey Grigoryev', 'Andrey Voynov', 'Artem Babenko']","[""GAN"", ""pretraining""]",,,,,
4YzI0KpRQtZ,2021,Reject,True,Streaming Probabilistic Deep Tensor Factorization,"[""shikai fang"", ""Zheng Wang"", ""Zhimeng pan"", ""Ji Liu"", ""Shandian Zhe""]","[""Probabilistic Methods"", ""online learing"", ""tensor factorization""]",A BNNï¼Bayesian neural networksï¼-based probabilistic methods for tensor factorization which allows Streaming update and Uncertainty measure,2007.07367,cs.LG,2020-07-14 21:25:39+00:00,2020-07-14 21:25:39+00:00
4_57x7xhymn,2021,Reject,False,Action Concept Grounding Network for Semantically-Consistent Video Generation,"[""Wei Yu"", ""Wenxin Chen"", ""Animesh Garg""]","[""action-conditional video prediction"", ""self-supervised learning"", ""counterfactual generation""]",,,,,
4artD3N3xB0,2021,Reject,False,Bayesian Learning to Optimize: Quantifying the Optimizer Uncertainty,"[""Yue Cao"", ""Tianlong Chen"", ""Zhangyang Wang"", ""Yang Shen""]","[""Optimizer Uncertainty"", ""Optimization"", ""Uncertainty Quantification""]",We develop the first method that quantifies optimizer uncertainty and shows superior performance of optimization and uncertainty quantification on extensive applications against state-of-the-art methods. ,,,,
4c0J6lwQ4_,2021,Accept (Poster),False,Multi-Time Attention Networks for Irregularly Sampled Time Series,"[""Satya Narayan Shukla"", ""Benjamin Marlin""]","[""irregular sampling"", ""multivariate time series"", ""attention"", ""missing data""]",This paper presents a new architecture for learning with sparse and irregularly sampled multivariate time series that achieves improved performance than current state-of-the-art methods while providing significantly reduced training times.,,,,
4c3WeBTErrE,2021,Reject,False,Jumpy Recurrent Neural Networks,"[""Samuel James Greydanus"", ""Stefan Lee"", ""Alan Fern""]","[""RNNs"", ""temporal abstraction"", ""planning"", ""intuitive physics""]","We propose a Jumpy RNN model which does not predict state transitions over uniform intervals of time, but rather predicts a sequence of linear dynamics functions and intervals of time over which their predictions can be expected to be accurate. ",,,,
4cC0HFuVd2d,2021,Reject,False,Decoy-enhanced Saliency Maps ,"[""Yang Young Lu"", ""Wenbo Guo"", ""Xinyu Xing"", ""William Noble""]","[""Deep neural network"", ""Explainable AI"", ""Saliency methods"", ""Decoys""]","We propose the decoy-enhanced saliency method and demonstrate its effectiveness and robustness, both theoretically and empirically. ",,,,
4dXmpCDGNp7,2021,Accept (Poster),False,Evaluations and Methods for Explanation through Robustness Analysis,"[""Cheng-Yu Hsieh"", ""Chih-Kuan Yeh"", ""Xuanqing Liu"", ""Pradeep Kumar Ravikumar"", ""Seungyeon Kim"", ""Sanjiv Kumar"", ""Cho-Jui Hsieh""]","[""Interpretability"", ""Explanations"", ""Adversarial Robustness""]",We propose a suite of objective measurements for evaluating feature based explanations by the notion of robustness analysis; we further derive new explanation that captures different characteristics of explanation comparing to existing methods.,,,,
4emQEegFhSy,2021,Reject,False,Adaptive Multi-model Fusion Learning for Sparse-Reward Reinforcement Learning,"[""Giseung Park"", ""Whiyoung Jung"", ""Sungho Choi"", ""Youngchul Sung""]","[""sparse-reward RL"", ""intrinsic reward generation"", ""adaptive fusion"", ""information geometry"", ""scale-free property""]",We propose a new optimal adaptive fusion algorithm for intrinsic reward generation in sparse-reward RL.,,,,
4f04RAhMUo6,2021,Reject,False,PODS: Policy Optimization via Differentiable Simulation,"[""Miguel Angel Zamora Mora"", ""Momchil Peychev"", ""Sehoon Ha"", ""Martin Vechev"", ""Stelian Coros""]","[""Reinforcement Learning"", ""Decision and Control"", ""Planning"", ""Robotics.""]",Policy Optimization via Differentiable Simulation,,,,
4j4qVy8OQA1,2022,Reject,True,A Koopman Approach to Understanding Sequence Neural Models,"['Ilan Naiman', 'Omri Azencot']","[""Koopman methods"", ""sequence neural models"", ""understanding deep learning""]",A linear framework for analyzing and understanding the inner mechanisms of sequence neural models,2102.07824,cs.LG,2021-02-15 20:05:11+00:00,2021-10-07 15:34:04+00:00
4jUmjIoTz2,2022,Reject,False,Collaborate to Defend Against Adversarial Attacks,"['Sen Cui', 'Jingfeng Zhang', 'Jian Liang', 'Masashi Sugiyama', 'Changshui Zhang']","[""adversarial defense"", ""collaboration"", ""ensemble.""]",We provide a novel collaboration framework to defend against adversarial attacks. ,,,,
4jXnFYaDOuD,2021,Reject,False,Importance-based Multimodal Autoencoder,"[""Sayan Ghosh"", ""Eugene Laksana"", ""Louis-Philippe Morency"", ""Stefan Scherer""]","[""Neural networks"", ""Speech analysis"", ""Multimodal"", ""Autoencoders"", ""Representation Learning""]",,,,,
4kWGWoFGA_H,2021,Reject,False,Beyond the Pixels: Exploring the Effects of Bit-Level Network and File Corruptions on Video Model Robustness,"[""Trenton Chang"", ""Daniel Yang Fu"", ""Yixuan Li""]","[""robustness"", ""machine learning"", ""file corruption"", ""network corruption"", ""video""]",We investigate the problem of video model robustness to bit-level network and file corruptions. ,,,,
4l5iO9eoh3f,2022,Reject,False,Supervised Permutation Invariant Networks for solving the CVRP with bounded fleet size,"['Daniela Thyssens', 'Jonas Falkner', 'Lars Schmidt-Thieme']","[""Deep Learning"", ""Combinatorial Optimization"", ""Vehicle Routing""]","The paper presents an end-to-end supervised deep learning framework which is able to solve capacitated vehicle routing problems with an apriori fixed fleet size, which is benchmarked against leading reinforcement learning based approaches.",2201.01529,cs.LG,2022-01-05 10:32:18+00:00,2022-01-05 10:32:18+00:00
4lLyoISm9M,2022,Reject,False,Range-Net: A High Precision Neural SVD,"['Soumyajit Gupta', 'Gurpreet Singh', 'Clint N. Dawson']","[""SVD"", ""Eigen"", ""Interpretable"", ""Neural Nets"", ""Streaming"", ""Big Data""]","A low memory, high precision, low rank Singular Value Decomposition for Big Data applications.",,,,
4mkxyuPcFt,2021,Reject,False,Disentangling Adversarial Robustness in Directions of the Data Manifold,"[""Jiancong Xiao"", ""Liusha Yang"", ""Zhi-Quan Luo""]","[""Adversarial Robustness"", ""Adversarial Training"", ""Generative Models""]",,,,,
4o1xPXaS4X,2022,Reject,False,Fooling Adversarial Training with Induction Noise,"['Zhirui Wang', 'Yifei Wang', 'Yisen Wang']","[""Data poisoning"", ""adversarial training"", ""data privacy""]",,2111.10130,cs.LG,2021-11-19 09:59:28+00:00,2021-11-19 09:59:28+00:00
4p6_5HBWPCw,2022,Accept (Poster),True,Graph-less Neural Networks: Teaching Old MLPs New Tricks Via Distillation,"['Shichang Zhang', 'Yozen Liu', 'Yizhou Sun', 'Neil Shah']","[""Graph Neural Networks"", ""Distillation"", ""Node Classification"", ""Model Inference Acceleration""]",Distill knowledge from GNNs to MLPs to accelerate model inference and facilitate deployment for large-scale applications,2110.08727,cs.LG,2021-10-17 05:16:58+00:00,2021-10-17 05:16:58+00:00
4pijrj4H_B,2022,Reject,False,Fair Node Representation Learning via Adaptive Data Augmentation,"['Oyku Deniz Kose', 'Yanning Shen']","[""Fair node representations"", ""fairness-aware graph data augmentations"", ""unsupervised node representation learning"", ""graph contrastive learning""]",This paper develops fairness-aware graph data augmentation schemes based on an analysis for the reduction of implicit bias in node representations obtained via Graph Neural Networks (GNNs).,,,,
4q8qGBf4Zxb,2021,Reject,True,Network Architecture Search for Domain Adaptation,"[""Yichen Li"", ""Xingchao Peng""]",[],,2008.05706,cs.CV,2020-08-13 06:15:57+00:00,2020-08-13 06:15:57+00:00
4qR3coiNaIv,2021,Accept (Poster),False,Scalable Bayesian Inverse Reinforcement Learning,"[""Alex James Chan"", ""Mihaela van der Schaar""]","[""Bayesian"", ""Inverse reinforcement learning"", ""Imitation Learning""]",A variational inference approach to Bayesian inverse reinforcement learning.,,,,
4qgEGwOtxU,2021,Reject,False,Importance and Coherence: Methods for Evaluating Modularity in Neural Networks,"[""Shlomi Hod"", ""Stephen Casper"", ""Daniel Filan"", ""Cody Wild"", ""Andrew Critch"", ""Stuart Russell""]","[""interpretability"", ""modularity""]","Toward better tools for interpretability, we develop methods for evaluating modularity in neural networks and apply them to partitions of neurons from a graph-based clustering algorithm.",2110.08058,cs.LG,2021-10-13 20:33:30+00:00,2021-10-13 20:33:30+00:00
4rLw09TgRw9,2022,Accept (Poster),True,Query Embedding on Hyper-Relational Knowledge Graphs,"['Dimitrios Alivanistos', 'Max Berrendorf', 'Michael Cochez', 'Mikhail Galkin']","[""Query embedding"", ""Approximate Query Answering"", ""Graph Neural Network"", ""Hyper-relational Graph"", ""Knowledge Graph""]",We investigate how to extend the multi-hop reasoning problem to hyper-relational queries on knowledge graphs and consider methods for solving it.,2106.08166,cs.AI,2021-06-15 14:08:50+00:00,2021-06-17 13:53:13+00:00
4rsTcjH7co,2021,Reject,True,Autoencoder Image Interpolation by Shaping the Latent Space,"[""Alon Oring"", ""Zohar Yakhini"", ""Yacov Hel-Or""]","[""deep learning"", ""autoencoders"", ""deep generative models"", ""representation learning""]","Regularization technique that shapes the latent representation to follow a manifold that is consistent with the training data using adversarial, cycle consistency and smoothness losses.",2008.01487,cs.LG,2020-08-04 12:32:54+00:00,2020-10-22 02:03:08+00:00
4sCyjwaVtZ9,2021,Reject,False,"Whitening and second order optimization both destroy information about the dataset, and can make generalization impossible","[""Neha S. Wadia"", ""Daniel Duckworth"", ""Samuel Stern Schoenholz"", ""Ethan Dyer"", ""Jascha Sohl-Dickstein""]","[""whitening"", ""second order optimization"", ""deep networks"", ""generalization""]",Whitening and pure second order optimization have a dimensionality-dependent negative effect on generalization.,,,,
4sz0AcJ8HUB,2022,Reject,False,SERCNN: Stacked Embedding Recurrent Convolutional Neural Network in Depression Detection on Twitter,"['Heng Ee Tay', 'Mei Kuan Lim', 'Chun Yong Chong']","[""Social Media"", ""Twitter"", ""NLP"", ""Depression"", ""Mental Health""]","SERCNN incorporates and exploits the rich representation extracted from two pretrained GloVe embeddings and the learned context, achieving 78% accuracy even we have only 10 tweets for each user",,,,
4tOrvK-fFOR,2022,Reject,False,Sound Source Detection from Raw Waveforms with Multi-Scale Synperiodic Filterbanks,['Yuhang He'],"[""speech processing"", ""object detection"", ""deep neural network"", ""sound object"", ""detection and localization"", ""filter bank design""]",Design novel learnable filter bank to detect sound sources from multi-channel sound raw waveforms,,,,
4vDf4Qtodh,2021,Reject,False,InstantEmbedding: Efficient Local Node Representations,"[""Stefan Postavaru"", ""Anton Tsitsulin"", ""Filipe Miguel Goncalves de Almeida"", ""Yingtao Tian"", ""Silvio Lattanzi"", ""Bryan Perozzi""]","[""Node Embedding"", ""Structural Graph Representations"", ""Graph Embedding"", ""Local Algorithms""]","Embed nodes using only local graph information, in sublinear time and space.",,,,
4xzY5yod28y,2021,Reject,False,Scheduled Restart Momentum for Accelerated Stochastic Gradient Descent,"[""Bao Wang"", ""Tan Minh Nguyen"", ""Tao Sun"", ""Andrea Bertozzi"", ""Richard Baraniuk"", ""Stanley Osher""]","[""Nesterov Accelerated Gradient"", ""Deep Learning"", ""Image Classification""]",We propose a Nesterov Accelerated Gradient-style momentum to improve training deep neural networks.,,,,
4zr9e5xwZ9Y,2021,Reject,False,Distributed Training of Graph Convolutional Networks using Subgraph Approximation,"[""Alexandra Angerd"", ""Keshav Balasubramanian"", ""Murali Annavaram""]",[],,2012.04930,cs.LG,2020-12-09 09:23:49+00:00,2020-12-09 09:23:49+00:00
5-2mX9_U5i,2022,Accept (Poster),True,Sqrt(d) Dimension Dependence of Langevin Monte Carlo,"['Ruilin Li', 'Hongyuan Zha', 'Molei Tao']","[""unadjusted Langevin algorithm / Langevin Monte Carlo"", ""non-asymptotic sampling error in Wasserstein-2 distance"", ""optimal dimension dependence"", ""mean square analysis""]","The known dimension dependence of LMC is improved, under regularity assumptions, from d to sqrt(d), based on a refined mean square analysis framework.",2109.03839,cs.LG,2021-09-08 18:00:05+00:00,2021-09-23 17:59:14+00:00
53WS781RzT9,2021,Reject,False,The Impact of the Mini-batch Size on the Dynamics of SGD: Variance and Beyond,"[""Xin Qian"", ""Diego Klabjan""]",[],,,,,
54-QTuqSLyn,2021,Reject,False,Mitigating Mode Collapse by Sidestepping Catastrophic Forgetting,"[""Karttikeya Mangalam"", ""Rohin Garg"", ""Jathushan Rajasegaran"", ""Taesung Park""]","[""mode collapse"", ""catastrophic forgetting"", ""multi-adversarial training""]",We propose a relationship between catastrophic forgetting in discriminator and mode collapse in generator and propose a dynamic multi adversarial training (DMAT) solution to tackle this issue in GAN training. ,,,,
541PxiEKN3F,2022,Accept (Poster),False,Acceleration of Federated Learning with Alleviated Forgetting in Local Training,"['Chencheng Xu', 'Zhiwei Hong', 'Minlie Huang', 'Tao Jiang']","[""Federated learning"", ""non-i.i.d. data""]",,,,,
57PipS27Km,2022,Accept (Spotlight),False,Continuous-Time Meta-Learning with Forward Mode Differentiation,"['Tristan Deleu', 'David Kanaa', 'Leo Feng', 'Giancarlo Kerg', 'Yoshua Bengio', 'Guillaume Lajoie', 'Pierre-Luc Bacon']","[""meta-learning"", ""few-shot learning"", ""dynamical systems""]","COMLN is a new meta-learning algorithm, where adaptation follows a gradient flow. It enables learning the amount of adaptation using SGD. We devise a novel efficient algorithm to compute the meta-gradients of COMLN, based on forward-mode diff.",,,,
57T1ctyxtP,2022,Reject,False,Structured Stochastic Gradient MCMC,"['Antonios Alexos', 'Alex James Boyd', 'Stephan Mandt']","[""Approximate MCMC"", ""Langevin Dynamics"", ""Stochastic Gradient MCMC""]",A new approximation scheme to Langevin dynamics that breaks selected posterior correlations for the sake of enhanced mixing rates.,,,,
5ALGcXpmFyC,2022,Reject,False,Training Data Size Induced Double Descent For Denoising Neural Networks and the Role of Training Noise Level,"['Rishi Sonthalia', 'Raj Rao Nadakuditi']","[""Double Descent"", ""Denoising Neural Neworks"", ""High Dimensional Statistics.""]",,,,,
5B8YAz6W3eX,2021,Reject,True,Apollo: An Adaptive Parameter-wised Diagonal Quasi-Newton Method for Nonconvex Stochastic Optimization,"[""Xuezhe Ma""]","[""Optimization"", ""Stochastic Optimization"", ""Nonconvex"", ""Quasi-Newton"", ""Neural Network"", ""Deep Learning""]",An Adaptive Parameter-wised Diagonal Quasi-Newton Method for Nonconvex Stochastic Optimization,2009.13586,cs.LG,2020-09-28 19:07:02+00:00,2021-08-20 05:31:09+00:00
5Dj8rVRg9Ui,2021,Reject,False,Using Synthetic Data to Improve the Long-range Forecasting of Time Series Data,"[""Shiyu Liu"", ""Mehul Motani""]","[""long-range time series data prediction"", ""Generative Adversarial Network"", ""Long Short-term Memory""]",Improve the Long-range Forecasting of Time Series Data Using Synthetic Data Generated by a Novel GAN based Neural Network. ,2110.08770,cs.LG,2021-10-17 09:13:45+00:00,2021-10-17 09:13:45+00:00
5ECQL05ub0J,2022,Accept (Poster),False,Resonance in Weight Space: Covariate Shift Can Drive Divergence of SGD with Momentum,"['Kirby Banman', 'Garnet Liam Peet-Pare', 'Nidhi Hegde', 'Alona Fyshe', 'Martha White']","[""optimization"", ""momentum"", ""stochastic gradient descent"", ""non-iid sampling""]",We show that SGDm under covariate shift with fixed step-size can be unstable and diverge due to a phenomenon known as parametric resonance.,,,,
5FRJWsiLRmA,2021,Reject,False,Reservoir Transformers,"[""Sheng Shen"", ""Alexei Baevski"", ""Ari S. Morcos"", ""Kurt Keutzer"", ""Michael Auli"", ""Douwe Kiela""]",[],,,,,
5FUq05QRc5b,2022,Accept (Spotlight),False,Understanding Latent Correlation-Based Multiview Learning and Self-Supervision: An Identifiability Perspective,"['Qi Lyu', 'Xiao Fu', 'Weiran Wang', 'Songtao Lu']",[],,,,,
5HvpvYd68b,2022,Accept (Poster),False,Non-Autoregressive Models are Better Multilingual Translators,"['Zhenqiao Song', 'Hao Zhou', 'Lihua Qian', 'Jingjing Xu', 'Shanbo Cheng', 'Mingxuan Wang', 'Lei Li']","[""multilingual non-autoregressive machine translation"", ""contextualized code-switching"", ""back-translation""]",,,,,
5IqTrksw9S,2021,Reject,False,GLUECode: A Benchmark for Source Code Machine Learning Models,"[""Anjan Karmakar"", ""Julian Aron Prenner"", ""Miltiadis Allamanis"", ""Romain Robbes""]","[""benchmark"", ""source code"", ""code understanding"", ""deep learning""]",,,,,
5JdLZg346Lw,2022,Accept (Poster),False,Generative Modeling with Optimal Transport Maps,"['Litu Rout', 'Alexander Korotin', 'Evgeny Burnaev']","[""Optimal Transport Map"", ""Generative Modeling"", ""Unpaired Image Restoration""]","While optimal transport cost serves as the loss for popular generative models, we demonstrate that the optimal transport map can be used as the generative model itself.",,,,
5JnS8wROG9,2021,Reject,False,On the Inductive Bias of a CNN for Distributions with Orthogonal Patterns,"[""Alon Brutzkus"", ""Amir Globerson""]","[""Deep learning theory"", ""generalization"", ""overparemeterization"", ""CNN""]",,,,,
5K7RRqZEjoS,2022,Accept (Poster),False,Multiset-Equivariant Set Prediction with Approximate Implicit Differentiation,"['Yan Zhang', 'David W Zhang', 'Simon Lacoste-Julien', 'Gertjan J. Burghouts', 'Cees G. M. Snoek']","[""set prediction"", ""permutation equivariance"", ""implicit differentiation""]",We propose a better permutation-equivariance property for multisets and improve an existing set predictor that has this property with approximate implicit differentiation,,,,
5K8ZG9twKY,2021,Reject,False,Efficient Estimators for Heavy-Tailed Machine Learning,"[""Vishwak Srinivasan"", ""Adarsh Prasad"", ""Sivaraman Balakrishnan"", ""Pradeep Kumar Ravikumar""]",[],,,,,
5L8XMh667qz,2021,Reject,True,Encoded Prior Sliced Wasserstein AutoEncoder for learning latent manifold representations,"[""Sanjukta Krishnagopal"", ""Jacob Bedrossian""]","[""VAE"", ""sliced Wasserstein distance"", ""latent representation"", ""interpolation"", ""manifold embedding"", ""geodesics"", ""network algorithm""]","A novel VAE-like architecture that uses an encoded-prior network to match the prior to the encoded data manifold using nonlinear sliced Wasserstein distances, and a graph-based algorithm for network-geodesic interpolations along the latent manifold.",2010.01037,cs.LG,2020-10-02 14:58:54+00:00,2020-10-02 14:58:54+00:00
5LXw_QplBiF,2022,Accept (Spotlight),True,Learning Hierarchical Structures with Differentiable Nondeterministic Stacks,"['Brian DuSell', 'David Chiang']","[""RNN"", ""pushdown automata"", ""nondeterminism"", ""formal languages"", ""language modeling""]",We present a new stack-augmented RNN with strong results on CFL language modeling tasks.,2109.01982,cs.CL,2021-09-05 03:25:23+00:00,2021-09-05 03:25:23+00:00
5MLb3cLCJY,2022,Accept (Poster),False,Adaptive Wavelet Transformer Network for 3D Shape Representation Learning,"['Hao Huang', 'Yi Fang']",[],,,,,
5MbRzxoCAql,2022,Reject,False,Fight fire with fire: countering bad shortcuts in imitation learning with good shortcuts,"['Chuan Wen', 'Jianing Qian', 'Jierui Lin', 'Dinesh Jayaraman', 'Yang Gao']",[],,,,,
5NA1PinlGFu,2021,Accept (Poster),False,Colorization Transformer,"[""Manoj Kumar"", ""Dirk Weissenborn"", ""Nal Kalchbrenner""]",[],Self-attention for colorization,2102.04432,cs.CV,2021-02-08 18:45:06+00:00,2021-03-07 08:38:49+00:00
5NsEIflpbSv,2021,Accept (Poster),False,Learning Better Structured Representations Using Low-rank Adaptive Label Smoothing,"[""Asish Ghoshal"", ""Xilun Chen"", ""Sonal Gupta"", ""Luke Zettlemoyer"", ""Yashar Mehdad""]","[""label smoothing"", ""calibration"", ""semantic parsing"", ""structured prediction""]",We propose an extension of label smoothing which improves generalization performance by adapting to the structure present in label space of structured prediction tasks.,,,,
5PiSFHhRe2C,2021,Reject,False,Meta Auxiliary Labels with Constituent-based Transformer for Aspect-based Sentiment Analysis,"[""Ling Min Serena Khoo"", ""Hai Leong Chieu""]","[""Natural Language Processing"", ""Sentiment Analysis""]",A Constituent based Transformer with Meta-learnt auxiliary labels for Aspect based Sentiment Analysis,,,,
5QhUE1qiVC6,2022,Accept (Poster),False,The Convex Geometry of Backpropagation: Neural Network Gradient Flows Converge to Extreme Points of the Dual Convex Program,"['Yifei Wang', 'Mert Pilanci']","[""Two-layer ReLU networks"", ""convex optimization"", ""convex duality"", ""gradient flow""]",,,,,
5Qkd7-bZfI,2022,Accept (Poster),False,On the role of population heterogeneity in emergent communication,"['Mathieu Rita', 'Florian Strub', 'Jean-Bastien Grill', 'Olivier Pietquin', 'Emmanuel Dupoux']",[],"This paper discusses the role of population heterogeneities in structuring emergent languages, partially resolving an apparent contraction between the psycho-linguistic and AI literature.",,,,
5SgoJKayTvs,2022,Reject,False,Intervention Adversarial Auto-Encoder,"['Yang Hu', 'Cheng Zhang']","[""Deep Learning"", ""Generative Models"", ""Adversarial Training""]",We propose a generative model which possess robust and stable training property by leveraging interventions on latent variables and classifying them.,,,,
5Spjp0zDYt,2021,Reject,True,Failure Modes of Variational Autoencoders and Their Effects on Downstream Tasks,"[""Yaniv Yacoby"", ""Weiwei Pan"", ""Finale Doshi-Velez""]","[""Variational Autoencoders"", ""Variational Inference"", ""VAE"", ""Approximate Inference"", ""Semi-Supervision""]",We concretely characterize conditions under which VAE training exhibits pathologies and connect these failure modes to undesirable effects on specific downstream tasks.,2007.07124,stat.ML,2020-07-14 15:44:18+00:00,2021-02-25 23:59:19+00:00
5USOVm2HkfG,2021,Reject,False,Jointly-Trained State-Action Embedding for Efficient Reinforcement Learning,"[""Paul Julian Pritz"", ""Liang Ma"", ""Kin Leung""]","[""reinforcement learning"", ""embedding"", ""representation learning"", ""state-action embedding""]","We proposed a new architecture for jointly embedding states/actions and combined this with common RL algorithms, the results of which show it outperforms state-of-the-art approaches in the presence of large state/action spaces.",,,,
5UY7aZ_h37,2021,Reject,False,Transferring Inductive Biases through Knowledge Distillation,"[""Samira Abnar"", ""Mostafa Dehghani"", ""Willem H. Zuidema""]","[""Knowledge Distillation"", ""Inductive Biases"", ""Analyzing and Understanding Neural Networks"", ""Recurrent Inductive Bias""]",We study the effect of inductive biases on the solutions the models converge to and investigate to what extent the effect of inductive biases is transferred through knowledge distillation. ,,,,
5WcLI0e3cAY,2021,Reject,False,K-PLUG: KNOWLEDGE-INJECTED PRE-TRAINED LANGUAGE MODEL FOR NATURAL LANGUAGE UNDERSTANDING AND GENERATION,"[""Song Xu"", ""Haoran Li"", ""Peng Yuan"", ""Yujia Wang"", ""Youzheng Wu"", ""Xiaodong He"", ""Ying Liu"", ""Bowen Zhou""]",[],,,,,
5XmLzdslFNN,2022,Accept (Poster),False,Modular Lifelong Reinforcement Learning via Neural Composition,"['Jorge A Mendez', 'Harm van Seijen', 'ERIC EATON']","[""lifelong learning"", ""continual learning"", ""reinforcement learning"", ""composition"", ""modularity"", ""compositionality""]","We explore the problem of lifelong RL of functionally composable knowledge, and develop an algorithm that demonstrates zero-shot and forward transfer, avoidance of forgetting, and backward transfer in discrete 2-D and robotic manipulation domains.",,,,
5Y21V0RDBV,2021,Accept (Poster),False,Generalized Multimodal ELBO,"[""Thomas M. Sutter"", ""Imant Daunhawer"", ""Julia E Vogt""]","[""Multimodal"", ""VAE"", ""ELBO"", ""self-supervised"", ""generative learning""]",We propose a generalized ELBO for modeling multiple data types in a scalable and self-supervised way.,,,,
5ZFeGYBBPgs,2021,Reject,False,Second-Moment Loss: A Novel Regression Objective for Improved Uncertainties,"[""Joachim Sicking"", ""Maram Akila"", ""Maximilian Alexander Pintz"", ""Tim Wirtz"", ""Asja Fischer"", ""Stefan Wrobel""]","[""regression"", ""uncertainty quantification"", ""uncertainty evaluation"", ""dropout""]",We propose a novel regression loss for dropout networks that improves on the state-of-the-art of uncertainty quantification.,,,,
5_zwnS5oJDp,2022,Reject,False,Bayesian Learning with Information Gain Provably Bounds Risk for a Robust Adversarial Defense,"['Bao Gia Doan', 'Ehsan M Abbasnejad', 'Damith C. Ranasinghe']",[],,,,,
5fJ0qcwBNr0,2021,Reject,False,A Gradient-based Kernel Approach for Efficient Network Architecture Search,"[""Jingjing Xu"", ""Liang Zhao"", ""Junyang Lin"", ""Xu Sun"", ""Hongxia Yang""]","[""NAS""]",,,,,
5fbUEUTZEn7,2022,Reject,False,Graph Kernel Neural Networks,"['Luca Cosmo', 'Giorgia Minello', 'Michael M. Bronstein', 'Emanuele RodolÃ ', 'Luca Rossi', 'Andrea Torsello']","[""graph neural network"", ""graph kernel"", ""deep learning""]",,,,,
5fmBRf5rrC,2022,Reject,False,Knothe-Rosenblatt transport for Unsupervised Domain Adaptation,"['Aladin Virmaux', 'Illyyne Saffar', 'Jianfeng Zhang', 'BalÃ¡zs KÃ©gl']","[""domain adaptation"", ""transfer learning"", ""deep learning"", ""density estimation"", ""transport""]",,,,,
5g5x0eVdRg,2021,Reject,False,DHOG: Deep Hierarchical Object Grouping,"[""Luke Nicholas Darlow"", ""Amos Storkey""]","[""Unsupervised learning"", ""Deep neural networks"", ""clustering""]","A deep clustering technique that uses mutual information maximisation for multiple diverse solutions, thereby improving the performance on the original mutual information-based unsupervised objective. ",,,,
5hLP5JY9S2d,2022,Accept (Oral),True,Open-Set Recognition: A Good Closed-Set Classifier is All You Need,"['Sagar Vaze', 'Kai Han', 'Andrea Vedaldi', 'Andrew Zisserman']","[""open set recognition"", ""image recognition"", ""computer vision""]",We show that the baseline method for open-set recognition can achieve state-of-the-art performance and introduce new benchmark settings,2110.06207,cs.CV,2021-10-12 17:58:59+00:00,2021-10-12 17:58:59+00:00
5i2f-aR6B8H,2022,Accept (Poster),False,Privacy Implications of Shuffling,"['Casey Meehan', 'Amrita Roy Chowdhury', 'Kamalika Chaudhuri', 'Somesh Jha']","[""local differential privacy"", ""shuffle DP model""]",a novel formalization of the privacy offered by shuffling ,,,,
5i4vRgoZauw,2021,Reject,False,Wiring Up Vision: Minimizing Supervised Synaptic Updates Needed to Produce a Primate Ventral Stream,"[""Franziska Geiger"", ""Martin Schrimpf"", ""Tiago Marques"", ""James J. DiCarlo""]","[""computational neuroscience"", ""primate ventral stream"", ""convolutional neural networks"", ""biologically plausible learning""]",We develop biologically-motivated initialization and training procedures to train models with 200x fewer synaptic updates (epochs x labeled images x weights) while maintaining 80% of brain predictivity on a set of neural and behavioral benchmarks.,,,,
5i7lJLuhTm,2022,Accept (Poster),False,Learning by Directional Gradient Descent,"['David Silver', 'Anirudh Goyal', 'Ivo Danihelka', 'Matteo Hessel', 'Hado van Hasselt']","[""credit assignment"", ""directional derivative"", ""recurrent networks""]","Computing directional derivative of a recurrent function along a candidate direction, and using it to create a valid descent direction.",,,,
5jRVa89sZk,2021,Accept (Poster),False,Empirical Analysis of Unlabeled Entity Problem in Named Entity Recognition,"[""Yangming Li"", ""lemao liu"", ""Shuming Shi""]","[""Named Entity Recognition"", ""Unlabeled Entity Problem"", ""Negative Sampling""]",This work studys what are the impacts of unlabeled entity problem on NER models and how to effectively eliminate them by a general method.,2012.05426,cs.CL,2020-12-10 02:53:59+00:00,2021-03-18 06:38:57+00:00
5jzlpHvvRk,2021,Accept (Poster),False,Loss Function Discovery for Object Detection via Convergence-Simulation Driven Search,"[""Peidong Liu"", ""Gengwei Zhang"", ""Bochao Wang"", ""Hang Xu"", ""Xiaodan Liang"", ""Yong Jiang"", ""Zhenguo Li""]","[""Object detection"", ""AutoML"", ""Evolutionary algorithm"", ""Loss function search""]","We propose an effective convergence-simulation driven evolutionary search algorithm, called CSE-Autoloss, for object detection loss function discovery, which achieves 20x speedup via progressive convergence-simulation modules.",2102.04700,cs.CV,2021-02-09 08:34:52+00:00,2021-02-09 08:34:52+00:00
5k8F6UU39V,2021,Accept (Spotlight),True,Autoregressive Entity Retrieval,"[""Nicola De Cao"", ""Gautier Izacard"", ""Sebastian Riedel"", ""Fabio Petroni""]","[""entity retrieval"", ""document retrieval"", ""autoregressive language model"", ""entity linking"", ""end-to-end entity linking"", ""entity disambiguation"", ""constrained beam search""]","We address entity retrieval by generating their unique name identifiers, left to right, in an autoregressive fashion, and conditioned on the context showing SOTA results in more than 20 datasets with a tiny fraction of the memory of recent systems.",2010.00904,cs.CL,2020-10-02 10:13:31+00:00,2021-03-24 07:21:07+00:00
5kq11Tl1z4,2022,Accept (Poster),True,IGLU: Efficient GCN Training via Lazy Updates,"['S Deepak Narayanan', 'Aditya Sinha', 'Prateek Jain', 'Purushottam Kar', 'SUNDARARAJAN SELLAMANICKAM']","[""Graph convolutional networks"", ""Graph neural networks"", ""Optimization"", ""Lazy updates""]",IGLU is a novel lazy update-based optimization technique for accelerated GCN training with provable convergence guarantees,2109.13995,cs.LG,2021-09-28 19:11:00+00:00,2021-09-28 19:11:00+00:00
5l9zj5G7vDY,2021,Accept (Poster),False,Spatially Structured Recurrent Modules,"[""Nasim Rahaman"", ""Anirudh Goyal"", ""Muhammad Waleed Gondal"", ""Manuel Wuthrich"", ""Stefan Bauer"", ""Yash Sharma"", ""Yoshua Bengio"", ""Bernhard Sch\u00f6lkopf""]","[""spatio-temporal modelling"", ""modular architectures"", ""recurrent neural networks"", ""partially observed environments""]",We model a dynamical system as a collection of recurrent modules that interact according to a spatially informed but learned topology. ,,,,
5lhWG3Hj2By,2021,Accept (Poster),False,Enforcing robust control guarantees within neural network policies,"[""Priya L. Donti"", ""Melrose Roderick"", ""Mahyar Fazlyab"", ""J Zico Kolter""]","[""robust control"", ""reinforcement learning"", ""differentiable optimization""]","We develop a generic nonlinear control policy class, parameterized by neural networks, that nonetheless enforces the same provable robustness criteria as robust control.",,,,
5m3SEczOV8L,2021,Accept (Spotlight),True,VAEBM: A Symbiosis between Variational Autoencoders and Energy-based Models,"[""Zhisheng Xiao"", ""Karsten Kreis"", ""Jan Kautz"", ""Arash Vahdat""]","[""Energy-based Models"", ""Variational Auto-encoder"", ""MCMC""]",We introduce an energy-based generative model where the data distribution is defined jointly by a VAE and an energy network.,2010.00654,cs.LG,2020-10-01 19:28:28+00:00,2021-11-04 23:49:01+00:00
5mhViEOQxaV,2021,Reject,False,Controllable Pareto Multi-Task Learning,"[""Xi Lin"", ""Zhiyuan YANG"", ""Qingfu Zhang"", ""Sam Kwong""]","[""Multi-Task Learning"", ""Multi-Objective Optimization""]",This work proposes a novel approach to learn the entire trade-off curve for MTL problems.,,,,
5o7lEUYRvM,2022,Reject,False,Function-Space Variational Inference for Deep Bayesian Classification,"['Jihao Andreas Lin', 'Joe Watson', 'Pascal Klink', 'Jan Peters']","[""Bayesian deep learning"", ""image classification"", ""functional variational inference"", ""Dirichlet distribution""]",We apply function-space variational inference to Bayesian deep learning in classification tasks by assuming Dirichlet predictives for variational implicit processes.,,,,
5qK0RActG1x,2021,Reject,False,Democratizing Evaluation of Deep Model Interpretability through Consensus,"[""Xuhong Li"", ""Haoyi Xiong"", ""Siyu Huang"", ""Shilei Ji"", ""Yanjie Fu"", ""Dejing Dou""]","[""interpretability evaluation"", ""deep model interpretability""]",,,,,
5qwA7LLbgP0,2022,Reject,False,Disentangling Sources of Risk for Distributional Multi-Agent Reinforcement Learning,"['Kyunghwan Son', 'Junsu Kim', 'Yung Yi', 'Jinwoo Shin']","[""multi-agent reinforcement learning"", ""risk-sensitive reinforcement learning"", ""reinforcement learning"", ""distributional reinforcement learning""]",We propose a novel distributional multi-agent reinforcement learning algorithm with state-of-the-art performance.,,,,
5rc0K0ezhqI,2021,Reject,True,Unpacking Information Bottlenecks: Surrogate Objectives for Deep Learning,"[""Andreas Kirsch"", ""Clare Lyle"", ""Yarin Gal""]","[""deep learning"", ""information bottleneck"", ""information theory""]",,2003.12537,cs.LG,2020-03-27 17:05:03+00:00,2021-01-05 18:09:22+00:00
5sP_PUUS78v,2022,Reject,False,SeqPATE: Differentially Private Text Generation via Knowledge Distillation,"['Zhiliang Tian', 'Yingxiu Zhao', 'Ziyue Huang', 'Yu-Xiang Wang', 'Nevin Zhang', 'He He']","[""Natural Language Generation"", ""Text Generation"", ""Privacy Protection""]",SeqPATE: Differentially Private Text Generation via Knowledge Distillation,,,,
5slGDu_bVc6,2021,Reject,False,Learning from deep model via exploring local targets,"[""Wenxian Shi"", ""Yuxuan Song"", ""Hao Zhou"", ""Bohan Li"", ""Lei Li""]",[],,,,,
5tJMTHv0l8g,2021,Reject,False,Stego Networks: Information Hiding on Deep Neural Networks,"[""Youngwoo Cho"", ""Beomsoo Kim"", ""Jaegul Choo""]","[""Steganography"", ""Information Hiding"", ""Security""]","We propose a novel design of the steganographic system, Stego Networks, which allow us to conceal information in the neural network parameters without performance degradation.",,,,
5ueTHF0yAlZ,2022,Reject,False,Improving greedy core-set configurations for active learning with uncertainty-scaled distances,"['Yuchen Li', 'Frank Rudzicz']","[""Active learning""]",Improved core-set for active learning using confidence-scaled distances.,,,,
5wmNjjvGOXh,2021,Reject,False,Selfish Sparse RNN Training,"[""SHiwei Liu"", ""Decebal Constantin Mocanu"", ""Yulong Pei"", ""Mykola Pechenizkiy""]","[""dynamic sparse training"", ""sparse neural networks"", ""dynamic sparse RNN training"", ""recurrent neural networks""]",An algorithm to train sparse RNNs with a fixed parameter count in one single run without compromising performance.,2101.09048,cs.LG,2021-01-22 10:45:40+00:00,2021-06-15 05:46:23+00:00
5xEgrl_5FAJ,2022,Accept (Poster),False,BiBERT: Accurate Fully Binarized BERT,"['Haotong Qin', 'Yifu Ding', 'Mingyuan Zhang', 'Qinghua YAN', 'Aishan Liu', 'Qingqing Dang', 'Ziwei Liu', 'Xianglong Liu']","[""Network Binarization"", ""Model Compression"", ""BERT"", ""NLP""]","Our BiBERT, for the first time, presents a promising route towards the accurate fully binarized BERT (with 1-bit weight, embedding, and activation) and gives impressive 56.3 times and 31.2 times saving on FLOPs and model size, respectively.",,,,
5xaInvrGWp,2021,Reject,False,Adversarially Robust Federated Learning for Neural Networks,"[""Yao Zhou"", ""Jun Wu"", ""Jingrui He""]","[""federated learning"", ""adversarial training"", ""robustness"", ""bias-variance decomposition""]",A robust federated learning framework based on bias-variance oriented adversarial training.,,,,
5y35LXrRMMz,2022,Reject,False,Exploiting Minimum-Variance Policy Evaluation for Policy Optimization,"['Alberto Maria Metelli', 'Samuele Meta', 'Marcello Restelli']","[""Reinforcement Learning"", ""Policy Optimization"", ""Importance Sampling"", ""Variance Reduction""]",,,,,
5ziLr3pWz77,2022,Reject,False,Neural network architectures for disentangling the multimodal structure of data ensembles,['M. Alex O. Vasilescu'],"[""autoencoders"", ""SEMs""]",This paper seeks to connect structural equations that model the mechanism of data formation and deep neural network architectures. ,,,,
6-lLt2zxbZR,2022,Reject,False,An Application of Pseudo-log-likelihoods to Natural Language Scoring,"['Darren Abramson', 'Ali Emami']",[],A recent method for scoring sentences with language models shows SOTA performance on a number of benchmarks with an Albert variant.,2201.09377,cs.CL,2022-01-23 22:00:54+00:00,2022-01-23 22:00:54+00:00
60j5LygnmD,2021,Accept (Poster),False,Meta-learning with negative learning rates,"[""Alberto Bernacchia""]","[""Meta-learning""]",We show theoretically that the optimal inner learning rate of MAML during training is always negative in a family of models  ,,,,
62r41yOG5m,2022,Reject,False,Inducing Reusable Skills From Demonstrations with Option-Controller Network,"['Siyuan Zhou', 'Yikang Shen', 'Yuchen Lu', 'Aaron Courville', 'Joshua B. Tenenbaum', 'Chuang Gan']","[""Reusable Skill"", ""Option-Controller Network""]",We introduce an Option-Controller Network to induce reusable skills.,,,,
64trBbOhdGU,2022,Accept (Poster),True,HyAR: Addressing Discrete-Continuous Action Reinforcement Learning via Hybrid Action Representation,"['Boyan Li', 'Hongyao Tang', 'YAN ZHENG', 'Jianye HAO', 'Pengyi Li', 'Zhen Wang', 'Zhaopeng Meng', 'LI Wang']",[],,2109.05490,cs.LG,2021-09-12 11:26:27+00:00,2021-10-07 06:04:09+00:00
65MxtdJwEnl,2021,Reject,False,Neural CDEs for Long Time Series via the Log-ODE Method,"[""James Morrill"", ""Patrick Kidger"", ""Cristopher Salvi"", ""James Foster"", ""Terry Lyons""]","[""CDE"", ""neural differential equation"", ""time series"", ""long time series"", ""log-ODE""]","We process very long (17k) time series by using a neural CDE with a numerical solver that (a) steps over multiple data points at once, (b) may be interpreted as a binning technique, (c) represents a length/channel tradeoff.",,,,
65sCF5wmhpv,2021,Reject,False,Learning to Observe with Reinforcement Learning,"[""Mehmet Koseoglu"", ""Ece Kunduracioglu"", ""Ayca Ozcelikkale""]","[""Reinforcement learning"", ""observation strategies"", ""active data collection""]",We propose a reinforcement learning based active data acqusition framework which reveals the information structure of the observation space demonstrating the type of observations that are the most important during the actual operation of the agent.,,,,
66H4g_OHdnl,2021,Reject,True,Revealing the Structure of Deep Neural Networks via Convex Duality,"[""Tolga Ergen"", ""Mert Pilanci""]","[""Convex optimization"", ""non-convex optimization"", ""deep learning"", ""convex duality"", ""regularization"", ""ReLU activation"", ""linear networks""]",We study norm regularized deep neural networks and develop a framework based on convex duality such that a set of optimal solutions to the training problem can be explicitly and analytically characterized.,2002.09773,cs.LG,2020-02-22 21:13:44+00:00,2021-06-11 17:21:01+00:00
66kgCIYQW3,2022,Reject,False,Automatic Concept Extraction for Concept Bottleneck-based Video Classification,"['Jeya Vikranth Jeyakumar', 'Luke Dickens', 'Yu-Hsi Cheng', 'Joseph Noor', 'Luis Antonio Garcia', 'Diego Ramirez Echavarria', 'Alessandra Russo', 'Lance M. Kaplan', 'Mani Srivastava']","[""Explainable AI"", ""Video Classification"", ""Concept Extraction""]",A method that extracts a rich set of complex concepts from natural language explanations for concept-based video classification,,,,
66miN107dRS,2022,Reject,True,Contrastive Attraction and Contrastive Repulsion for Representation Learning,"['Huangjie Zheng', 'Xu Chen', 'Jiangchao Yao', 'Hongxia Yang', 'Chunyuan Li', 'Ya Zhang', 'Hao Zhang', 'Ivor Tsang', 'Jingren Zhou', 'Mingyuan Zhou']","[""contrastive learning"", ""Bayesian methods"", ""conditional distribution"", ""label imbalance"", ""doubly contrastive""]","Guided by a doubly-contrastive strategy, the proposed CACR algorithm consistently improves the performance and robustness of existing contrastive learning methods",2105.03746,cs.LG,2021-05-08 17:25:08+00:00,2021-06-29 04:12:54+00:00
67T66kchK_7,2022,Reject,False,SPLID: Self-Imitation Policy Learning through Iterative Distillation,"['Zhihan Liu', 'Hao Sun', 'Bolei Zhou']","[""Multi-goal RL"", ""RL with sparse reward.""]",,,,,
67q9f8gChCF,2021,Reject,False,Learning Efficient Planning-based Rewards for Imitation Learning,"[""Xingrui Yu"", ""Yueming Lyu"", ""Ivor Tsang""]",[],,,,,
68747kJ0qKt,2021,Reject,False,"On Dropout, Overfitting, and Interaction Effects in Deep Neural Networks","[""Ben Lengerich"", ""Eric Xing"", ""Rich Caruana""]","[""Dropout"", ""Interaction Effects"", ""Neural Networks"", ""Functional ANOVA""]",We show that Dropout regularizes against interaction effects.,,,,
68n2s9ZJWF8,2022,Accept (Poster),False,Offline Reinforcement Learning with In-sample Q-Learning,"['Ilya Kostrikov', 'Ashvin Nair', 'Sergey Levine']","[""Deep Reinforcement Learning"", ""Offline Reinforcement Learning"", ""Batch Reinforcement Learning"", ""Continuous Control""]",Offline RL method with only dataset actions.,,,,
69EFStdgTD2,2021,Reject,False,Secure Byzantine-Robust Machine Learning,"[""Lie He"", ""Sai Praneeth Karimireddy"", ""Martin Jaggi""]","[""Byzantine robustness"", ""distributed learning"", ""secure aggregation""]","We propose a multi-server protocol that offers both input privacy and Byzantine-robustness and demonstrate it is communication-efficient, fault-tolerant, and enjoys local differential privacy.",,,,
6BRLOfrMhW,2021,Accept (Poster),False,Partitioned Learned Bloom Filters,"[""Kapil Vaidya"", ""Eric Knorr"", ""Michael Mitzenmacher"", ""Tim Kraska""]","[""optimization"", ""data structures"", ""algorithms"", ""theory"", ""learned algorithms""]",,,,,
6BWY3yDdDi,2021,Reject,False,A Truly Constant-time Distribution-aware Negative Sampling,"[""Shabnam Daghaghi"", ""Tharun Medini"", ""Beidi Chen"", ""Mengnan Zhao"", ""Anshumali Shrivastava""]",[],We provide two LSH based hard-negative sampling strategies and an efficient C++implementation that outperforms Tensorflow-GPU on time while retaining precision.,,,,
6DOZ8XNNfGN,2021,Accept (Poster),False,Graph Traversal with Tensor Functionals: A Meta-Algorithm for Scalable Learning,"[""Elan Sopher Markowitz"", ""Keshav Balasubramanian"", ""Mehrnoosh Mirtaheri"", ""Sami Abu-El-Haija"", ""Bryan Perozzi"", ""Greg Ver Steeg"", ""Aram Galstyan""]","[""Graph"", ""Learning"", ""Algorithm"", ""Scale"", ""Message Passing"", ""Node Embeddings""]","GTTF is a meta-algorithm, upon which, many algorithms for graph learning can be implemented, automatically giving them efficiency and scale, yet unbiased learning.",,,,
6Dz7RiRiMFd,2022,Reject,False,3D-Transformer: Molecular Representation with Transformer in 3D Space ,"['Fang Wu', 'Qiang Zhang', 'Dragomir Radev', 'Jiyu Cui', 'Wen Zhang', 'Huabin Xing', 'Ningyu Zhang', 'Huajun Chen']","[""structural biology"", ""self-attention"", ""transformer"", ""proteins"", ""small molecules"", ""crystals"", ""geometric deel learning""]",We present a universal neural architecture designed for 3D molecular representations.,,,,
6ET9SzlgNX,2022,Accept (Poster),False,Understanding Intrinsic Robustness Using Label Uncertainty,"['Xiao Zhang', 'David Evans']","[""Concentration of Measure"", ""Intrinsic Adversarial Robustness"", ""Label Uncertainty""]",,,,,
6EVxJKlpGR,2022,Reject,False,Surprise Minimizing Multi-Agent Learning with Energy-based Models,['Karush Suri'],"[""Multi-Agent Learning"", ""Reinforcement Learning"", ""Energy-based Models.""]",Multi-Agent surprise minimization can be achieved by virtue of a temporal Energy-based Model (EBM).,,,,
6FqKiVAdI3Y,2021,Accept (Poster),True,DOP: Off-Policy Multi-Agent Decomposed Policy Gradients,"[""Yihan Wang"", ""Beining Han"", ""Tonghan Wang"", ""Heng Dong"", ""Chongjie Zhang""]","[""Multi-Agent Reinforcement Learning"", ""Multi-Agent Policy Gradients""]","We propose an off-policy multi-agent decomposed policy gradient method, addressing the drawbacks that prevent existing multi-agent policy gradient methods from achieving state-of-the-art performance.",2007.12322,cs.LG,2020-07-24 02:21:55+00:00,2020-10-04 08:07:44+00:00
6FsCHsZ66Fp,2021,Reject,False,Towards certifying $\ell_\infty$ robustness using Neural networks with $\ell_\infty$-dist Neurons,"[""Bohang Zhang"", ""Zhou Lu"", ""Tianle Cai"", ""Di He"", ""Liwei Wang""]",[],,,,,
6FtFPKw8aLj,2021,Reject,False,Systematic Analysis of Cluster Similarity Indices: How to Validate Validation Measures,"[""Martijn G\u00f6sgens"", ""Liudmila Prokhorenkova"", ""Aleksei Tikhonov""]","[""cluster similarity indices"", ""cluster validation"", ""clustering"", ""community detection"", ""constant baseline""]",Provide a systematic theoretical analysis of cluster similarity indices: define a number of properties that are desirable across many applications and check them for a number of known indices.,,,,
6GkL6qM3LV,2021,Reject,False,N-Bref : A High-fidelity Decompiler Exploiting Programming Structures ,"[""Cheng Fu"", ""Kunlin Yang"", ""Xinyun Chen"", ""Yuandong Tian"", ""Jishen Zhao""]","[""Programming Language"", ""Reverse engineering"", ""neural machine translation"", ""machine learning for system""]",,,,,
6HN7LHyzGgC,2022,Accept (Poster),False,Uncertainty Modeling for Out-of-Distribution Generalization,"['Xiaotong Li', 'Yongxing Dai', 'Yixiao Ge', 'Jun Liu', 'Ying Shan', 'LINGYU DUAN']","[""domain generalization"", ""uncertainty modeling""]",We for the first time treat feature statistics as uncertain distributions to improve the model generalization ability.,,,,
6HlaJSlQFEj,2021,Reject,False,Small Input Noise is Enough to Defend Against Query-based Black-box Attacks,"[""Junyoung Byun"", ""Hyojun Go"", ""Changick Kim""]","[""Gaussian noise"", ""input noise"", ""adversarial defense"", ""black-box attack"", ""adversarial attack"", ""query-based attack""]",We highlight the effectiveness of adding small Gaussian noise to input in defending against query-based black-box attacks. ,2101.04829,cs.CR,2021-01-13 01:45:59+00:00,2021-11-08 07:30:25+00:00
6IVdytR2W90,2021,Reject,False,MSFM: Multi-Scale Fusion Module for Object Detection,"[""Xuesong Wang"", ""Caisheng Wang""]","[""Feature Fusion"", ""Object Detection"", ""Multi-Scale""]",We present a Multi-Scale Fusion Module (MSFM) that extracts both detail and semantical information from a single input but at different scales within the same layer.,,,,
6IYp-35L-xJ,2022,Accept (Poster),False,CADDA: Class-wise Automatic Differentiable Data Augmentation for EEG Signals,"['CÃ©dric Rommel', 'Thomas Moreau', 'Joseph Paillard', 'Alexandre Gramfort']","[""Neuroscience"", ""EEG"", ""Sleep staging"", ""Automatic data augmentation""]","We propose a new gradient-based automatic data augmentation technique where samples are transformed based on their labels, and demonstrate its relevance on EEG sleep staging data.",,,,
6Jf6HX4MoLH,2022,Reject,False,Motion Planning Transformers: One Model to Plan them All,"['Jacob John Johnson', 'Linjun Li', 'Ahmed Qureshi', 'Michael C. Yip']","[""Motion Planning"", ""Attention Networks""]",A motion planning algorithm using Transformers for 2D navigation systems.,,,,
6KZ_kUVCfTa,2021,Reject,False,Non-Markovian Predictive Coding For Planning In Latent Space,"[""Tung Nguyen"", ""Rui Shu"", ""Tuan Pham"", ""Hung Bui"", ""Stefano Ermon""]","[""representation learning"", ""reinforcement learning"", ""information theory""]",We develop a contrastive learning alternative to Dreamer that works well in both the standard and non-standard setting (dominated by task-irrelevant information).,2106.07156,cs.LG,2021-06-14 04:31:15+00:00,2021-06-14 04:31:15+00:00
6LHiNULIeiC,2022,Reject,False,SOInter: A Novel Deep Energy-Based Interpretation Method for Explaining Structured Output Models,"['Seyyede Fatemeh Seyyedsalehi', 'Mahdieh Soleymani Baghshah', 'Hamid R. Rabiee']","[""Structured Output Model"", ""Interpretable Learning"", ""Deep Learning""]",Proposing a Novel Deep Energy-Based Interpretation Method for Explaining Structured Output Models,,,,
6Lhv4x2_9pw,2021,Reject,True,Bayesian neural network parameters provide insights into the earthquake rupture physics.,"[""Sabber Ahamed""]","[""Bayesian neural network"", ""earthquake rupture"", ""simulation"", ""Explainable neural network""]",A trained Bayesian Neural network parameter can provide information patterns to understand earthquake rupture physics.,1911.09660,stat.ML,2019-11-21 18:42:35+00:00,2019-11-21 18:42:35+00:00
6M4c3WegNtX,2021,Reject,False,Neural Ensemble Search for Uncertainty Estimation and Dataset Shift,"[""Sheheryar Zaidi"", ""Arber Zela"", ""Thomas Elsken"", ""Chris Holmes"", ""Frank Hutter"", ""Yee Whye Teh""]","[""uncertainty estimation"", ""deep ensemble"", ""dataset shift"", ""robustness"", ""uncertainty calibration""]","We propose methods for constructing ensembles of neural networks with varying architectures, demonstrating that they outperform deep ensembles, in terms of uncertainty calibration, predictive performance and robustness to dataset shift.",,,,
6MaBrlQ5JM,2021,Reject,False,THE EFFICACY OF L1 REGULARIZATION IN NEURAL NETWORKS,"[""Gen Li"", ""Yuantao Gu"", ""Jie Ding""]","[""Model selection"", ""Neural Network"", ""Regularization""]",We develop novel theoretical results on the efficacy of L1 regularization for shallow neural networks. ,,,,
6MmiS0HUJHR,2022,Accept (Poster),True,When Can We Learn General-Sum Markov Games with a Large Number of Players Sample-Efficiently?,"['Ziang Song', 'Song Mei', 'Yu Bai']","[""reinforcement learning theory"", ""multi-agent RL"", ""Markov games"", ""general-sum games""]","We present new algorithms for several learning goals in multi-player general-sum Markov games, with mild PAC sample complexity in terms of the number of players.",2110.04184,cs.LG,2021-10-08 15:06:22+00:00,2021-10-08 15:06:22+00:00
6NFBvWlRXaG,2021,Accept (Poster),True,On the Universality of Rotation Equivariant Point Cloud Networks,"[""Nadav Dym"", ""Haggai Maron""]","[""3D deep learning"", ""Rotation invariance"", ""Invariant and equivariant deep networks"", ""Universal approximation"", ""Point clouds""]",We provide sufficient conditions for universality of rotation equivariant point cloud networks and use these conditions to show that current models are universal as well as for devising new universal architectures.,2010.02449,cs.LG,2020-10-06 03:14:16+00:00,2020-10-06 03:14:16+00:00
6NT1a56mNim,2022,Reject,False,Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents,"['Wenlong Huang', 'Pieter Abbeel', 'Deepak Pathak', 'Igor Mordatch']","[""GPT-3"", ""Codex"", ""LLMs"", ""Language Models"", ""Knowledge Extraction"", ""Embodied Agents"", ""Action Planning""]","We extract actionable knowledge from Codex to do action planning for embodied agents, without any additional training.",2201.07207,cs.LG,2022-01-18 18:59:45+00:00,2022-01-18 18:59:45+00:00
6NePxZwfae,2022,Accept (Poster),False,Goal-Directed Planning via Hindsight Experience Replay,"['Lorenzo Moro', 'Amarildo Likmeta', 'Enrico Prati', 'Marcello Restelli']","[""Reinforcement Learning"", ""Goal-Directed Planning"", ""Monte Carlo Tree Search""]",This paper presents an extension of AlphaZero to tackle sparse reward goal-based tasks,,,,
6P6-N1gLQDC,2022,Reject,False,Structural Causal Interpretation Theorem,"['Matej Zecevic', 'Devendra Singh Dhami', 'Constantin A. Rothkopf', 'Kristian Kersting']","[""causality"", ""interpretations"", ""neural causal models"", ""induction""]",We present a theoretical investigation from first-principles on causal interpretability of neural induction methods alongside empirical evidence.,,,,
6PTUd_zPdHL,2022,Reject,False,Differentiable Top-k Classification Learning,"['Felix Petersen', 'Hilde Kuehne', 'Christian Borgelt', 'Oliver Deussen']","[""top-k"", ""top-5"", ""imagenet""]",,,,,
6PahjGFjVG-,2022,Reject,True,Secure Distributed Training at Scale,"['Eduard Gorbunov', 'Alexander Borzunov', 'Michael Diskin', 'Max Ryabinin']","[""distributed training"", ""byzantine tolerance"", ""volunteer computing""]",We propose and rigorously analyze a protocol for secure (Byzantine-tolerant) decentralized training that emphasizes communication efficiency.,2106.11257,cs.LG,2021-06-21 17:00:42+00:00,2021-10-07 15:31:02+00:00
6Pe99Juo9gd,2022,Accept (Poster),False,Learning Value Functions from Undirected State-only Experience,"['Matthew Chang', 'Arjun Gupta', 'Saurabh Gupta']","[""Reinforcement Learning"", ""Offline RL"", ""Offline RL without actions""]",We present a method for offline value learning without action labels.,,,,
6PlIkYUK9As,2022,Reject,True,Less data is more: Selecting informative and diverse subsets with balancing constraints,"['Srikumar Ramalingam', 'Daniel Glasner', 'Kaushal Patel', 'Raviteja Vemulapalli', 'Sadeep Jayasumana', 'Sanjiv Kumar']","[""subset selection"", ""approximation algorithm"", ""active learning"", ""efficient training""]",We propose a novel subset selection algorithm for training large and accurate deep models with less data. ,2104.12835,cs.CV,2021-04-26 19:22:27+00:00,2021-10-08 16:59:33+00:00
6PvWo1kEvlT,2022,Accept (Poster),True,Exposing the Implicit Energy Networks behind Masked Language Models via Metropolis--Hastings,"['Kartik Goyal', 'Chris Dyer', 'Taylor Berg-Kirkpatrick']","[""Masked Language Models"", ""Energy-based models"", ""Metropolis Hastings Monte Carlo"", ""Bidirectional Sequence models""]",We interpret masked language models for sequences as energy based models and propose a tractable scheme inspired by Metropolis--Hasting Monte Carlo to draw samples from these models.,2106.02736,cs.LG,2021-06-04 22:04:30+00:00,2021-06-04 22:04:30+00:00
6Q52pZ-Th7N,2022,Accept (Poster),False,Pseudo-Labeled Auto-Curriculum Learning for Semi-Supervised Keypoint Localization,"['Can Wang', 'Sheng Jin', 'Yingda Guan', 'Wentao Liu', 'Chen Qian', 'Ping Luo', 'Wanli Ouyang']","[""Keypoint Localization"", ""Semi-Supervised Learning"", ""Curriculum Learning""]",The first work that explores automatic curriculum learning for semi-supervised keypoint localization,2201.08613,cs.CV,2022-01-21 09:51:58+00:00,2022-01-24 11:04:47+00:00
6Qvjzr2VGLl,2022,Reject,False,Towards Generative Latent Variable Models for Speech,"['Jakob Drachmann Havtorn', 'Lasse Borgholt', 'Jes Frellsen', 'SÃ¸ren Hauberg', 'Lars MaalÃ¸e']","[""hierarchical temporal latent variable models"", ""generative speech modelling"", ""variational autoencoder""]",Hierarchical latent variable models with autoregression only in latent space are state-of-the-art models in-class for speech.,,,,
6SXNhWc5HFe,2021,Reject,True,Provable Fictitious Play for General Mean-Field Games,"[""Qiaomin Xie"", ""Zhuoran Yang"", ""Zhaoran Wang"", ""Andreea Minca""]","[""Mean-field games"", ""Fictitious play"", ""Entropy regularization"", ""Nash equilibrium""]",We propose a fictitious play algorithm for mean-field games that converges to the Nash equilibrium at a sublinear rate. ,2010.04211,cs.LG,2020-10-08 18:46:48+00:00,2020-10-08 18:46:48+00:00
6Tk2noBdvxt,2022,Accept (Spotlight),False,Programmatic Reinforcement Learning without Oracles,"['Wenjie Qiu', 'He Zhu']","[""Reinforcement Learning"", ""Programmatic Reinforcement Learning"", ""Compositional Reinforcement Learning"", ""Program Synthesis"", ""Differentiable Architecture Search""]","We present a differentiable program architecture search framework to synthesize interpretable, generalizable, and compositional programs for controlling reinforcement learning applications.",,,,
6Tm1mposlrM,2021,Accept (Spotlight),True,Sharpness-aware Minimization for Efficiently Improving Generalization,"[""Pierre Foret"", ""Ariel Kleiner"", ""Hossein Mobahi"", ""Behnam Neyshabur""]","[""Sharpness Minimization"", ""Generalization"", ""Regularization"", ""Training Method"", ""Deep Learning""]","Motivated by the connection between geometry of the loss landscape and generalization, we introduce a procedure for simultaneously minimizing loss value and loss sharpness.",2010.01412,cs.LG,2020-10-03 19:02:10+00:00,2021-04-29 16:44:25+00:00
6UdQLhqJyFD,2021,Accept (Poster),False,Parameter Efficient Multimodal Transformers for Video Representation Learning,"[""Sangho Lee"", ""Youngjae Yu"", ""Gunhee Kim"", ""Thomas Breuel"", ""Jan Kautz"", ""Yale Song""]","[""Self-supervised learning"", ""audio-visual representation learning"", ""video representation learning""]",We propose a technique to reduce the number of parameters in multimodal BERT models up to 97% (from 128 million to 4 million parameters).,2012.04124,cs.CV,2020-12-08 00:16:13+00:00,2021-09-22 16:19:39+00:00
6VPl9khIMz,2021,Reject,False,Adaptive Stacked Graph Filter,"[""Hoang NT"", ""Takanori Maehara"", ""Tsuyoshi Murata""]","[""Graph Convolutional Network"", ""vertex classification"", ""graph signal processing"", ""adaptive graph filter""]",We show that simply learning the polynomial coefficients of a graph filter can lead to a highly adaptive semi-supervised vertex classification model.,2011.10988,cs.LG,2020-11-22 11:20:14+00:00,2020-11-22 11:20:14+00:00
6VhmvP7XZue,2021,Reject,False,Open-world Semi-supervised Learning,"[""Kaidi Cao"", ""Maria Brbic"", ""Jure Leskovec""]","[""deep learning"", ""semi-supervised learning"", ""novel class discovery"", ""clustering""]","ORCA recognizes previously seen classes and discovers novel, never-before-seen classes.",,,,
6VpeS27viTq,2022,Accept (Poster),False,Learnability Lock: Authorized Learnability Control Through Adversarial Invertible Transformations,"['Weiqi Peng', 'Jinghui Chen']",[],,2202.03576,cs.LG,2022-02-03 17:38:11+00:00,2022-02-03 17:38:11+00:00
6XGgutacQ0B,2022,Accept (Poster),False,Demystifying Batch Normalization in ReLU Networks: Equivalent Convex Optimization Models and Implicit Regularization,"['Tolga Ergen', 'Arda Sahiner', 'Batu Ozturkler', 'John M. Pauly', 'Morteza Mardani', 'Mert Pilanci']","[""batch normalization"", ""ReLU networks"", ""deep networks"", ""convex optimization"", ""whitening"", ""implicit regularization"", ""algorithmic bias""]",We introduce an analytic framework based on convex duality to obtain exact and polynomial-time trainable convex representations of weight-decay regularized ReLU networks with BN.,,,,
6X_32jLUaDg,2021,Reject,False,Exploiting Playbacks in Unsupervised Domain Adaptation for 3D Object Detection,"[""Yurong You"", ""Carlos Andres Diaz-Ruiz"", ""Yan Wang"", ""Wei-Lun Chao"", ""Bharath Hariharan"", ""Mark Campbell"", ""Kilian Q Weinberger""]","[""Unsupervised domain adaptation"", ""3D vision"", ""object detection"", ""autonomous driving""]",,2103.14198,cs.CV,2021-03-26 01:18:11+00:00,2021-03-26 01:18:11+00:00
6YEQUn0QICG,2021,Accept (Poster),False,FedBN: Federated Learning on Non-IID Features via Local Batch Normalization,"[""Xiaoxiao Li"", ""Meirui JIANG"", ""Xiaofei Zhang"", ""Michael Kamp"", ""Qi Dou""]","[""Federated Learning"", ""Non-IID"", ""Batch Normalization""]","We propose a novel and efficient federated learning aggregation method, denoted FedBN, that uses local batch normalization to effectively tackle the underexplored non-iid problem of heterogeneous feature distributions, or feature shift.",2102.07623,cs.LG,2021-02-15 16:04:10+00:00,2021-05-11 14:21:00+00:00
6YVIk0sAkF_,2022,Accept (Poster),False,Multi-Mode Deep Matrix and Tensor Factorization,['Jicong Fan'],[],,,,,
6YuRviF_FC-,2021,Reject,False,ZCal: Machine learning methods for calibrating radio interferometric data ,"[""Simphiwe Zitha"", ""Arun aniyan"", ""Oleg Smirnov"", ""Risuna Nkolele""]","[""Radio astronomy"", ""Calibration"", ""Radio interferometry"", ""ska"", ""kat-7"", ""MeerKat""]",Machine learning as a calibration tool for radio interferometric data,,,,
6_FjMpi_ebO,2021,Reject,False,Redesigning the Classification Layer by Randomizing the Class Representation Vectors,"[""Gabi Shalev"", ""Gal Lev Shalev"", ""Yossi Keshet""]",[],,,,,
6c6KZUdm1Nq,2021,Reject,False,Regression from Upper One-side Labeled Data,"[""Takayuki Katsuki""]","[""regression"", ""weakly-supervised learning"", ""healthcare""]",,,,,
6deUA11mOJ5,2021,Reject,False,A Large-scale Study on Training Sample Memorization in Generative Modeling,"[""Ching-Yuan Bai"", ""Hsuan-Tien Lin"", ""Colin Raffel"", ""Wendy Kan""]","[""GAN"", ""generative adversarial networks"", ""generative modeling"", ""memorization""]","We critically evaluate training sample memorization in generative modeling by running a competition and analyze the submissions, hence evaluate the effectiveness of state of the art metrics for generative modeling such as FID. ",,,,
6fb4mex_pUT,2021,Reject,False,An Algorithm for Out-Of-Distribution Attack to Neural Network Encoder ,"[""Liang Liang"", ""Linhai Ma"", ""Linchen Qian"", ""Jiasong Chen""]","[""Out-Of-Distribution"", ""DNN"", ""image classification""]",Neural network is easily fooled by OOD samples due to non-bijective mapping caused by dimensionality reduction:  a new method to generate OOD samples.,,,,
6g4VoBTaq6I,2022,Reject,False,A Variance Reduction Method for Neural-based Divergence Estimation,"['Jeremiah Birrell', 'Markos A. Katsoulakis', 'Yannis Pantazis', 'Dipjyoti Paul', 'Anastasios Tsourtis']","[""Divergence estimation"", ""Variational formulas"", ""Variance reduction"", ""Representation learning""]",A novel variance reduction approach for stable divergence estimation.,,,,
6gLEKETxUWp,2022,Reject,False,Interpreting Molecule Generative Models for Interactive Molecule Discovery,"['Yuanqi Du', 'Xian Liu', 'Shengchao Liu', 'Bolei Zhou']","[""Molecule Generation"", ""Controllable Molecule Generation"", ""Interpretable Molecule Generation"", ""Molecule Manipulation""]",,,,,
6gZJ6f6pU6h,2021,Reject,False,Multi-EPL: Accurate Multi-source Domain Adaptation,"[""Seongmin Lee"", ""Hyunsik Jeon"", ""U Kang""]","[""Multi-Source Domain Adaptation"", ""Label-wise Moment Matching"", ""Pseudolabel"", ""Ensemble of Feature Representation""]",We propose a novel state-of-the-art method for multi-source domain adaptation.,,,,
6hTObFz_nB,2022,Reject,False,Do Androids Dream of Electric Fences? Safety-Aware Reinforcement Learning with Latent Shielding,"['Peter He', 'Borja G. LeÃ³n', 'Francesco Belardinelli']","[""Model-Based Reinforcement Learning"", ""Safety-Aware Reinforcement Learning"", ""Shielding"", ""World Models""]","RL agents can be made safer by getting them to ""imagine"" the consequences of their actions.",,,,
6htjOqus6C3,2021,Reject,True,DynamicVAE: Decoupling Reconstruction Error and Disentangled Representation Learning,"[""Huajie Shao"", ""Haohong Lin"", ""Qinmin Yang"", ""Shuochao Yao"", ""Han Zhao"", ""Tarek Abdelzaher""]","[""disentangled representation learning"", ""dynamic learning"", ""Variational Autoencoder"", ""PID contoller""]",The goal of this paper is to decouple disentangling and reconstruction for disentangled representation learning via dynamic control.,2009.06795,cs.LG,2020-09-15 00:01:11+00:00,2020-09-30 22:11:07+00:00
6isfR3JCbi,2021,Accept (Poster),False,Private Post-GAN Boosting,"[""Marcel Neunhoeffer"", ""Steven Wu"", ""Cynthia Dwork""]",[],,,,,
6j9YOwh8itH,2022,Reject,False,Unified Recurrence Modeling for Video Action Anticipation,"['Tsung-Ming Tai', 'Giuseppe Fiameni', 'Cheng-Kuang Lee', 'Simon See', 'Oswald Lanz']",[],,,,,
6jlNy83JUQ_,2021,Reject,False,Low Complexity Approximate Bayesian Logistic Regression for Sparse Online Learning,"[""Gil I. Shamir"", ""Wojciech Szpankowski""]","[""Bayesian methods"", ""logistic regression"", ""regret"", ""online learning"", ""MDL.""]",Simple online learning methods for logistic regression with empirical regret better than other methods that appears to be close to lower bounds.,2101.12113,cs.LG,2021-01-28 16:59:31+00:00,2021-01-28 16:59:31+00:00
6k7VdojAIK,2021,Accept (Poster),False,Practical Massively Parallel Monte-Carlo Tree Search Applied to Molecular Design,"[""Xiufeng Yang"", ""Tanuj Aasawat"", ""Kazuki Yoshizoe""]","[""parallel Monte Carlo Tree Search (MCTS)"", ""Upper Confidence bound applied to Trees (UCT)"", ""molecular design""]",Novel massively parallel MCTS achieves state-of-the-art score in molecular design benchmark.,,,,
6kCiVaoQdx9,2022,Accept (Poster),False,Few-shot Learning via Dirichlet Tessellation Ensemble,"['Chunwei Ma', 'Ziyun Huang', 'Mingchen Gao', 'Jinhui Xu']","[""Few-shot Learning"", ""Computational Geometry"", ""Dirichlet Tessellation"", ""Voronoi Diagram"", ""Ensemble Learning""]","We developed a novel geometric framework that greatly improves few-shot classification, based on Cluster-induced Voronoi Diagram (CIVD).",,,,
6kruvdT0yfY,2022,Reject,False,C+1 Loss: Learn to Classify C Classes of Interest and the Background Class Differentially,"['Changhuai Chen', 'Xile Shen', 'Mengyu Ye', 'Yi Lu', 'Jun Che', 'Shiliang Pu']","[""C+1 loss"", ""classes of interest"", ""background class""]",We propose a C+1 loss driving the C+1 classifier to learn the C classes of interest and the background class differentially.,,,,
6lH8nkwKRXV,2021,Reject,False,Graph Structural Aggregation for Explainable Learning,"[""Alexis Galland"", ""marc lelarge""]","[""graph"", ""deep"", ""learning""]",An aggregation process to detect structural roles to bring explainability to a graph classification task.,,,,
6ooiNCGZa5K,2022,Reject,False,On-Target Adaptation,"['Dequan Wang', 'Shaoteng Liu', 'Sayna Ebrahimi', 'Evan Shelhamer', 'Trevor Darrell']","[""domain adaptation"", ""source-free adaptation"", ""unsupervised domain adaptation""]","Because target accuracy is the goal, we argue for optimizing as much as possible on the target data, and decouple the adaptation of source predictions from the source representation to do so.",,,,
6p8D4V_Wmyp,2022,Reject,False,RainNet: A Large-Scale Imagery Dataset for Spatial Precipitation Downscaling,"['Xuanhong Chen', 'Kairui Feng', 'Naiyuan Liu', 'Yifan Lu', 'Bingbing Ni', 'Ziang Liu', 'Maofeng Liu']","[""Dateset"", ""Downscaling"", ""Computer Vision"", ""Physics"", ""Weather Forecast""]","We propose the first large-scale dataset for precipitation downscaling that is based on real observational data (named RainNet) and 14 state-of-the-art models, including deep models and traditional approaches, are evaluated on the proposed dataset.",,,,
6puCSjH3hwA,2021,Accept (Spotlight),False,A Good Image Generator Is What You Need for High-Resolution Video Synthesis,"[""Yu Tian"", ""Jian Ren"", ""Menglei Chai"", ""Kyle Olszewski"", ""Xi Peng"", ""Dimitris N. Metaxas"", ""Sergey Tulyakov""]","[""high-resolution video generation"", ""contrastive learning"", ""cross-domain video generation""]",Reuse a pre-trained image generator for high-resolution video synthesis,2104.15069,cs.CV,2021-04-30 15:38:41+00:00,2021-04-30 15:38:41+00:00
6puUoArESGp,2021,Accept (Poster),False,Debiasing Concept-based Explanations with Causal Analysis,"[""Mohammad Taha Bahadori"", ""David Heckerman""]","[""Interpretability"", ""Concept-based Explanation""]",We use a technique from instrumental variables literature and remove the impact of noise and latent confounding from concept-based explanations.,,,,
6q_2b6u0BnJ,2022,Accept (Poster),True,TRAIL: Near-Optimal Imitation Learning with Suboptimal Data,"['Mengjiao Yang', 'Sergey Levine', 'Ofir Nachum']","[""Imitation Learning"", ""Action Representations"", ""Latent Dynamics Model"", ""Offline Datasets""]",A provably beneficial way to learn action representations for imitation learning from suboptimal auxiliary data.,2110.14770,cs.LG,2021-10-27 21:05:00+00:00,2021-10-27 21:05:00+00:00
6s480DdlRQQ,2021,Reject,False,Dynamic Backdoor Attacks Against Deep Neural Networks,"[""Ahmed Salem"", ""Rui Wen"", ""Michael Backes"", ""Shiqing Ma"", ""Yang Zhang""]","[""Backdoor attack"", ""Deep Neural Networks security""]",We propose the first class of dynamic backdooring techniques against machine learning models which can bypass state-of-the-art backdooring defense mechanisms.,,,,
6s7ME_X5_Un,2021,Accept (Spotlight),False,DDPNOpt: Differential Dynamic Programming Neural Optimizer,"[""Guan-Horng Liu"", ""Tianrong Chen"", ""Evangelos Theodorou""]","[""deep learning training"", ""optimal control"", ""trajectory optimization"", ""differential dynamica programming""]","We introduce a new class of optimal-control-theoretic training methods, DDPNOpt, that performs a distinct backward pass inherited with Bellman optimality and generates layer-wise feedback policies to robustify training over existing training methods",,,,
6sh3pIzKS-,2022,Accept (Poster),False,Chemical-Reaction-Aware Molecule Representation Learning,"['Hongwei Wang', 'Weijiang Li', 'Xiaomeng Jin', 'Kyunghyun Cho', 'Heng Ji', 'Jiawei Han', 'Martin Burke']","[""molecule representation learning"", ""graph neural networks"", ""chemical reaction""]",We make use of chemical reactions to improve the generalization ability of learned molecule embeddings,,,,
6t_dLShIUyZ,2021,Accept (Poster),False,Greedy-GQ with Variance Reduction: Finite-time Analysis and Improved Complexity,"[""Shaocong Ma"", ""Ziyi Chen"", ""Yi Zhou"", ""Shaofeng Zou""]","[""Optimization"", ""Reinforcement Learning"", ""Machine Learning""]",,2103.16377,cs.LG,2021-03-30 14:17:50+00:00,2021-03-30 14:17:50+00:00
6tmjoym9LR6,2022,Accept (Poster),False,Stability Regularization for Discrete Representation Learning,"['Adeel Pervez', 'Efstratios Gavves']",[],,,,,
6u6N8WWwYSM,2022,Accept (Poster),False,Bootstrapping Semantic Segmentation with Regional Contrast,"['Shikun Liu', 'Shuaifeng Zhi', 'Edward Johns', 'Andrew Davison']","[""semi-supervised learning"", ""semantic segmentation"", ""contrastive learning""]",We present a pixel-level contrastive learning framework to achieve a high-quality semantic segmeantation model trained with very few human annotations.,,,,
6uu1t8jQ-M,2022,Reject,False,Generating Novel Scene Compositions from Single Images and Videos,"['Vadim Sushko', 'Dan Zhang', 'Juergen Gall', 'Anna Khoreva']","[""GANs"", ""Image Generation"", ""Deep Learning"", ""Image Synthesis"", ""Generative Models""]","We introduce SIV-GAN, an unconditional, one-stage GAN model that can learn to generate novel scene compositions when trained only on a single image or video.",,,,
6vkzF28Hur8,2022,Accept (Poster),False,Training Transition Policies via Distribution Matching for Complex Tasks,"['JU-SEUNG BYUN', 'Andrew Perrault']","[""Reinforcement Learning"", ""Hierarchical Reinforcement Learning"", ""Inverse Reinforcement Learning""]",Training transition policies via distribution matching,,,,
6w2zSI9RAnf,2022,Reject,False,Reasoning With Hierarchical Symbols: Reclaiming Symbolic Policies For Visual Reinforcement Learning,"['Wenqing Zheng', 'S P Sharan', 'Zhiwen Fan', 'Zhangyang Wang']","[""Symbolic Regression"", ""Reinforcement Learning"", ""Convolutional Neural Networks"", ""Interpretability""]",Learning to distill CNN based policy networks into whitebox symbolic rules.,,,,
6xHJ37MVxxp,2021,Accept (Poster),False,Domain Generalization with MixStyle,"[""Kaiyang Zhou"", ""Yongxin Yang"", ""Yu Qiao"", ""Tao Xiang""]","[""Domain Generalization"", ""Style Mixing""]",MixStyle makes CNNs more domain-generalizable by mixing instance-level feature statistics of training samples across domains.,2104.02008,cs.CV,2021-04-05 16:58:09+00:00,2021-04-05 16:58:09+00:00
6y2KBh-0Fd9,2022,Accept (Poster),False,Revisiting flow generative models for Out-of-distribution detection,"['Dihong Jiang', 'Sun Sun', 'Yaoliang Yu']","[""flow models"", ""out-of-distribution detection"", ""random projection"", ""distribution comparison""]",,,,,
6y3-wzlGHkb,2021,Reject,False,Non-robust Features through the Lens of Universal Perturbations,"[""Sung Min Park"", ""Kuo-An Wei"", ""Kai Yuanqing Xiao"", ""Jerry Li"", ""Aleksander Madry""]","[""adversarial examples"", ""robustness"", ""non-robust features""]","We analyze non-robust features through universal perturbations, and find evidence of weak yet human-aligned non-robust features.",,,,
6yVvwR9H9Oj,2022,Accept (Poster),False,On Non-Random Missing Labels in Semi-Supervised Learning,"['Xinting Hu', 'Yulei Niu', 'Chunyan Miao', 'Xian-Sheng Hua', 'Hanwang Zhang']","[""Semi-Supervised Learning"", ""Missing Not At Random"", ""Image Classification""]",We presented a principled class-aware doubly robust solution to handle the non-random missing labels in semi-supervised learning.,,,,
6ya8C6sCiD,2022,Reject,False,Multi-Agent Language Learning: Symbolic Mapping,"['Yicheng Feng', 'Zongqing Lu']","[""emergent communication"", ""multi-agent reinforcement learning""]",,,,,
6zaTwpNSsQ2,2021,Accept (Poster),False,A Block Minifloat Representation for Training Deep Neural Networks,"[""Sean Fox"", ""Seyedramin Rasoulinezhad"", ""Julian Faraone"", ""david boland"", ""Philip Leong""]",[],"A new number representation, comparable to recently proposed 8-bit formats, for efficiently training a subset of DNN models.",,,,
71zCSP_HuBN,2021,Accept (Poster),False,Individually Fair Rankings,"[""Amanda Bower"", ""Hamid Eftekhari"", ""Mikhail Yurochkin"", ""Yuekai Sun""]","[""algorithmic fairness"", ""learning to rank"", ""optimal transport""]",We present an algorithm for training individually fair learning-to-rank systems using optimal transport tools.,2103.11023,stat.ML,2021-03-19 21:17:11+00:00,2021-03-19 21:17:11+00:00
73MEhZ0anV,2022,Accept (Poster),False,QUERY-EFFICIENT DECISION-BASED SPARSE ATTACKS AGAINST BLACK-BOX MACHINE LEARNING MODELS,"['Viet Vo', 'Ehsan M Abbasnejad', 'Damith Ranasinghe']","[""decision-based attacks"", ""sparse attacks"", ""evolution algorithms"", ""vision transformer"", ""convolutional neural network""]",,,,,
73WTGs96kho,2021,Accept (Poster),False,Net-DNF: Effective Deep Modeling of Tabular Data,"[""Liran Katzir"", ""Gal Elidan"", ""Ran El-Yaniv""]","[""Neural Networks"", ""Architectures"", ""Tabular Data"", ""Predictive Modeling""]",Neural network architecture for tabular data,,,,
74cDdRwm4NV,2022,Reject,False,Learning to Shape Rewards using a Game of Two Partners,"['David Henry Mguni', 'Jianhong Wang', 'Taher Jafferjee', 'Nicolas Perez-Nieves', 'Wenbin Song', 'Feifei Tong', 'Hui Chen', 'Jiangcheng Zhu', 'Yaodong Yang', 'Jun Wang']","[""Reinforcement learning"", ""Reward Shaping"", ""Markov game"", ""Sparse rewards""]",,,,,
74x5BXs4bWD,2022,Accept (Poster),False,Evolutionary Diversity Optimization with Clustering-based Selection for Reinforcement Learning,"['Yutong Wang', 'Ke Xue', 'Chao Qian']","[""Reinforcement learning"", ""Quality-Diversity"", ""Evolutionary algorithms""]","We propose EDO-CS, a new Evolutionary Diversity Optimization algorithm with Clustering-based Selection that can achieve a set of policies with both high quality and diversity efficiently.",,,,
76M3pxkqRl,2021,Reject,False,Status-Quo Policy Gradient in Multi-agent Reinforcement Learning,"[""Pinkesh Badjatiya"", ""Mausoom Sarkar"", ""Abhishek Sinha"", ""Nikaash Puri"", ""Jayakumar Subramanian"", ""Siddharth Singh"", ""Balaji Krishnamurthy""]","[""multi-agent rl"", ""reinforcement learning"", ""social dilemma"", ""policy gradient"", ""game theory""]",,,,,
784_F-WCW46,2021,Reject,False,Rethinking Sampling in 3D Point Cloud Generative Adversarial Networks,"[""He Wang"", ""Zetian Jiang"", ""Li Yi"", ""Kaichun Mo"", ""Hao Su"", ""Leonidas Guibas""]","[""3D point cloud"", ""GAN"", ""sampling pattern"", ""evaluation metrics"", ""discriminator""]", we examine the long-neglected yet important effects of point sampling patterns in point cloud GANs and found a functional 3D point cloud discriminator shouldn't be oversensitive to point sampling pattern.,,,,
78SlGFxtlM,2021,Reject,False,Robust Meta-learning with Noise via Eigen-Reptile,"[""Dong Chen"", ""Lingfei Wu"", ""Siliang Tang"", ""Fangli Xu"", ""Juncheng Li"", ""Chang Zong"", ""Chilie Tan"", ""Yueting Zhuang""]","[""meta-learning"", ""few-shot learning"", ""generalization""]","We propose and prove the effectiveness of Eigen-Reptile and  Introspective Self-paced Learning, respectively, theoretically and experimentally.",,,,
7ADMMyZpeY,2022,Reject,False,A theoretically grounded characterization of feature representations ,"['Bharath Hariharan', 'Cheng Perng Phoo']","[""features"", ""analysis"", ""generalization"", ""transfer"", ""few-shot""]",We present intuitive properties of the feature space that (theoretically and empirically) govern the performance of downstream classifiers.,,,,
7AzOUBeajwl,2022,Reject,False,Text Style Transfer with Confounders,"['Tianxiao Shen', 'Regina Barzilay', 'Tommi S. Jaakkola']","[""style transfer"", ""confounder"", ""invariance""]","We solve the problem of style transfer in the presence of confounding factors, which need to be differentiated from the style and preserved during transfer.",,,,
7B3IJMM1k_M,2022,Accept (Poster),False,Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks,"['Tong Bu', 'Wei Fang', 'Jianhao Ding', 'PENGLIN DAI', 'Zhaofei Yu', 'Tiejun Huang']","[""Spiking Neural Networks"", ""ANN-SNN Conversion"", ""Ultra-low Latency"", ""Quantization Clip-floor-shift Activation""]",An ANN-SNN conversion method enables high-accuracy and ultra-low-latency deep SNNs.,,,,
7Bc2U-dLJ6N,2022,Reject,False,SGDEM: stochastic gradient descent with energy and momentum,"['Hailiang Liu', 'Xuping Tian']","[""stochastic optimization"", ""energy stability"", ""momentum""]","We propose SGDEM, Stochastic Gradient Descent with Energy and Momentum to solve a large class of general nonconvex stochastic optimization problems.",,,,
7DI6op61AY,2022,Accept (Poster),False,Neural Markov Controlled SDE: Stochastic Optimization for Continuous-Time Data,"['Sung Woo Park', 'Kyungjae Lee', 'Junseok Kwon']","[""controlled stochastic differential equation"", ""time-series prediction""]",We propose a novel probabilistic framework for modelling stochastic dynamics with the rigorous use of optimal control theory. ,,,,
7EDgLu9reQD,2021,Accept (Poster),True,SALD: Sign Agnostic Learning with Derivatives,"[""Matan Atzmon"", ""Yaron Lipman""]","[""implicit neural representations"", ""3D shapes learning"", ""sign agnostic learning""]",Sign agnostic learning with derivatives for learning high fidelity 3D implicit neural representations shape space from raw data.,2006.05400,cs.CV,2020-06-09 16:54:57+00:00,2020-10-03 17:24:48+00:00
7F9cOhdvfk_,2022,Accept (Spotlight),False,$\mathrm{SO}(2)$-Equivariant Reinforcement Learning,"['Dian Wang', 'Robin Walters', 'Robert Platt']","[""Reinforcement Learning"", ""Equivariance"", ""Robotic Manipulation""]",This paper proposes equivariant DQN and equivariant SAC that significantly improve the sample efficiency of RL in robotic manipulation.,,,,
7FNqrcPtieT,2021,Accept (Poster),False,On Data-Augmentation and Consistency-Based Semi-Supervised Learning,"[""Atin Ghosh"", ""Alexandre H. Thiery""]","[""Semi-Supervised Learning"", ""Regularization"", ""Data augmentation""]",We propose a simple and natural framework leveraging the Hidden Manifold Model to study modern SSL methods.,,,,
7HhX4mbern,2022,Reject,False,Randomized Signature Layers for Signal Extraction in Time Series Data,"['Enea Monzio Compagnoni', 'Luca Biggio', 'Antonio Orvieto', 'Thomas Hofmann', 'Josef Teichmann']","[""signature"", ""random features"", ""time series"", ""SDE"", ""differential equations"", ""rough path""]",We show high expressiveness of theoretically grounded random features for times series data,2201.00384,cs.LG,2022-01-02 17:37:25+00:00,2022-01-02 17:37:25+00:00
7I12hXRi8F,2021,Accept (Poster),False,ANOCE: Analysis of Causal Effects with Multiple Mediators via Constrained Structural Learning,"[""Hengrui Cai"", ""Rui Song"", ""Wenbin Lu""]","[""Causal network"", ""Constrained optimization"", ""COVID-19"", ""Individual mediation effects"", ""Structure learning""]","Analysis of causal effects on the level of individual mediators via constrained structural learning, with application to the COVID-19 Spread in China.",,,,
7I8LPkcx8V,2022,Accept (Poster),True,Differentially Private Fractional Frequency Moments Estimation with Polylogarithmic Space,"['Lun Wang', 'Iosif Pinelis', 'Dawn Song']","[""Differential Privacy"", ""Fractional Frequency Moments""]","We prove that $\mathbb{F}_p$ sketch, a well-celebrated streaming algorithm for frequency moments estimation, is differentially private as is when $p\in(0, 1]$.",2105.12363,cs.CR,2021-05-26 07:11:05+00:00,2021-10-01 02:39:13+00:00
7IDIy7Jb00l,2021,Reject,False,Offline Meta Learning of Exploration,"[""Ron Dorfman"", ""Aviv Tamar""]","[""Meta-RL"", ""Offline RL"", ""Bayesian RL""]","Given complete training histories of RL agents trained on $N$ different tasks, we train a meta-RL agent that quickly solves a new task from the same task distribution.",,,,
7IElVSrNm54,2021,Reject,False,Zero-shot Fairness with Invisible Demographics,"[""Thomas Kehrenberg"", ""Viktoriia Sharmanska"", ""Myles Scott Bartlett"", ""Novi Quadrianto""]","[""fairness"", ""missing data"", ""adversary"", ""classification"", ""disentanglement""]",We use perfect batches to disentangle the outcomes from the demographic groups via adversarial distribution-matching.,,,,
7IWGzQ6gZ1D,2022,Accept (Poster),False,Constructing a Good Behavior Basis for Transfer using Generalized Policy Updates,"['Safa Alver', 'Doina Precup']","[""reinforcement learning"", ""lifelong learning"", ""transfer learning"", ""successor features""]",,2112.15025,cs.LG,2021-12-30 12:20:46+00:00,2022-02-06 22:24:21+00:00
7JSTDTZtn7-,2021,Reject,False,Byzantine-Robust Learning on Heterogeneous Datasets via Resampling,"[""Lie He"", ""Sai Praneeth Karimireddy"", ""Martin Jaggi""]","[""Byzantine robustness"", ""distributed training"", ""heterogeneous dataset""]","In this paper, we studied robust distributed learning problem under realistic heterogeneous data and proposed a general resampling technique which greatly improves the current robust aggregation rules on heterogeneous data.",,,,
7K0UUL9y9lE,2021,Reject,False,You Only Sample (Almost) Once: Linear Cost Self-Attention Via Bernoulli Sampling,"[""Zhanpeng Zeng"", ""Yunyang Xiong"", ""Sathya N. Ravi"", ""Shailesh Acharya"", ""Glenn Fung"", ""Vikas Singh""]","[""self-attention"", ""efficient"", ""linear complexity"", ""language model"", ""transformer"", ""BERT""]",,2111.09714,cs.LG,2021-11-18 14:24:34+00:00,2021-11-18 14:24:34+00:00
7KdAoOsI81C,2022,Accept (Poster),False,Transfer RL across Observation Feature Spaces via Model-Based Regularization,"['Yanchao Sun', 'Ruijie Zheng', 'Xiyao Wang', 'Andrew E Cohen', 'Furong Huang']","[""transfer reinforcement learning"", ""representation learning"", ""observation space change"", ""latent dynamics model""]","We propose a model-based transfer learning algorithm that transfers knowledge across tasks with drastically different observation spaces, without any prior knowledge of the inter-task mapping.",,,,
7MLeqJrHNa,2022,Reject,False,Continual Learning of Neural Networks for Realtime Wireline Cable Position Inference,"['Jun Wang', 'Tianxiang Su']","[""Continual Learning"", ""Wireline Automation""]",We proposed a new continual learning method to enable multiple re-training procedures with longer memory to historical data and no memory overflow for deep learning-based computer vision methods on wireline cable spooling automation.,,,,
7MV6uLzOChW,2022,Accept (Poster),False,Conditional Image Generation by Conditioning Variational Auto-Encoders,"['William Harvey', 'Saeid Naderiparizi', 'Frank Wood']","[""variational auto-encoders"", ""Bayesian inference"", ""variational inference"", ""amortized inference"", ""image completion""]","We create fast-to-train conditional VAEs using amortized inference in pretrained unconditional VAEs, and demonstrate diverse samples on image completion tasks.",,,,
7MjfPd-Irao,2021,Reject,False,Impact-driven Exploration with Contrastive Unsupervised Representations,"[""Min Jae Song"", ""Dan Kushnir""]","[""reinforcement learning"", ""exploration"", ""curiosity"", ""episodic memory""]",modification of RIDE by using observation embeddings trained with SimCLR and episodic memory.,,,,
7N-6ZLyFUXz,2022,Reject,False,Thompson Sampling for (Combinatorial) Pure Exploration,"['Siwei Wang', 'Jun Zhu']","[""pure exploration"", ""(combinatorial) multi-armed bandit"", ""Thompson Sampling""]",This paper studies applying the Thompson Sampling approach to (combinatorial) pure exploration problems under the frequentist setting.,,,,
7ODIasgLJlU,2021,Reject,False,Deep Q-Learning with Low Switching Cost,"[""Shusheng Xu"", ""Simon Shaolei Du"", ""Yi Wu""]","[""deep Q-network"", ""DQN"", ""switching cost"", ""deep Q-learning""]",A systematic study on deep Q-learning that requires low switching cost.,,,,
7QDPaL-Yl8U,2022,Reject,True,LPRules: Rule Induction in Knowledge Graphs Using Linear Programming,"['Sanjeeb Dash', 'Joao Goncalves']",[],We perform rule induction for Knowledge Graph link completion using a simple linear programming model.,2110.08245,cs.AI,2021-10-15 17:58:16+00:00,2021-10-15 17:58:16+00:00
7QfLW-XZTl,2022,Accept (Poster),False,Neural Energy Minimization for Molecular Conformation Optimization,"['Jiaqi Guan', 'Wesley Wei Qian', 'qiang liu', 'Wei-Ying Ma', 'Jianzhu Ma', 'Jian Peng']",[],,,,,
7R7fAoUygoa,2021,Accept (Poster),False,Optimal Regularization can Mitigate Double Descent,"[""Preetum Nakkiran"", ""Prayaag Venkat"", ""Sham M. Kakade"", ""Tengyu Ma""]","[""double descent"", ""generalization"", ""regularization"", ""regression"", ""monotonicity""]",Optimal regularization can provably avoid double-descent in certain settings.,,,,
7Rnf1F7rQhR,2022,Reject,False,Best Practices in Pool-based Active Learning for Image Classification,"['Adrian Lang', 'Christoph Mayer', 'Radu Timofte']","[""Active Learning"", ""Deep Learning"", ""Image classification""]",Evaluation of the novel state-of-the-art Active Learning strategies,,,,
7TBP8k7TLFA,2021,Reject,False,Universal Approximation Theorem for Equivariant Maps by Group CNNs,"[""Wataru Kumagai"", ""Akiyoshi Sannai""]","[""Universal Approximation Theorem"", ""CNN"", ""Deep Learning"", ""Symmetry""]",This paper provides a unified method to obtain universal approximation theorems for equivariant maps by CNNs in various settings.,2012.13882,stat.ML,2020-12-27 07:09:06+00:00,2020-12-27 07:09:06+00:00
7TFcl1Xkr7,2022,Reject,False,Interactive Model with Structural Loss for Language-based Abductive Reasoning,"['Linhao Li', 'Ming Xu', 'Yongfeng Dong', 'Xin Li', 'Jianhua Tao', 'Qinghua Hu']","[""abductive  natural  language"", ""abductive reasoning"", ""BiLSTM"", ""joint loss function.""]","For abductive NLI task, on one hand, we establish a way to reorganize the hypotheses groups and construct a joint loss for this; on the other hand, we propose a novel interactive language model that exploits the rich interaction among hypotheses.",,,,
7TZeCsNOUB_,2022,Accept (Poster),False,Collapse by Conditioning: Training Class-conditional GANs with Limited Data,"['Mohamad Shahbazi', 'Martin Danelljan', 'Danda Pani Paudel', 'Luc Van Gool']","[""Generative Adversarial Network"", ""GAN"", ""Conditional GAN"", ""limited data""]",,2201.06578,cs.CV,2022-01-17 18:59:23+00:00,2022-01-17 18:59:23+00:00
7U-rmW7TPHM,2022,Reject,True,"EfficientPhys: Enabling Simple, Fast, and Accurate Camera-Based Vitals Measurement","['Xin Liu', 'Brian L. Hill', 'Ziheng Jiang', 'Shwetak Patel', 'Daniel McDuff']","[""Computer Vision"", ""Healthcare"", ""Deep Learning""]",,2110.04447,cs.CV,2021-10-09 03:51:26+00:00,2021-10-09 03:51:26+00:00
7UmjRGzp-A,2022,Accept (Oral),False,Understanding over-squashing and bottlenecks on graphs via curvature,"['Jake Topping', 'Francesco Di Giovanni', 'Benjamin Paul Chamberlain', 'Xiaowen Dong', 'Michael M. Bronstein']","[""Graph neural networks"", ""Geometric deep learning"", ""Differential geometry"", ""Ricci curvature""]",,2111.14522,stat.ML,2021-11-29 13:27:56+00:00,2021-11-29 13:27:56+00:00
7UyqgFhPqAd,2021,Reject,False,Connection- and Node-Sparse Deep Learning: Statistical Guarantees,"[""Johannes Lederer""]",[],,,,,
7VH_ZMpwZXa,2022,Reject,False,No Shifted Augmentations (NSA): strong baselines for self-supervised Anomaly Detection,"['Mohamed Yousef', 'Tom Bishop', 'Unmesh Kurup']","[""self-supervised learning"", ""anomaly detection""]",,,,,
7WVAI3dRwhR,2022,Reject,False,Adversarial twin neural networks: maximizing physics recovery for physical system,"['Haoran Li', 'Erik Blasch', 'Jingyi Yuan', 'Yang Weng']","[""Physical Equation Learning"", ""Incomplete Observability"", ""Twin Neural Network"", ""Mini-Max Game""]",A novel neural network architecture to model system with unobservability,,,,
7WwYBADS3E_,2021,Reject,False,Learning Lagrangian Fluid Dynamics with Graph Neural Networks,"[""Zijie Li"", ""Amir Barati Farimani""]","[""particle hydrodynamics"", ""graph neural networks"", ""Lagrangian fluids""]",We use graph neural networks to learn Lagrangian incompressible fluid simulation.,,,,
7YDLgf9_zgm,2022,Accept (Spotlight),False,Continual Learning with Recursive Gradient Optimization,"['Hao Liu', 'Huaping Liu']","[""continual learning"", ""lifelong learning""]","This paper proposes a novel method for continual learning in a fixed capacity network in the non-replay regime, which minimizes the loss on the current task while also minimizing an upper bound of loss increment on previous tasks.",2201.12522,cs.LG,2022-01-29 07:50:43+00:00,2022-01-29 07:50:43+00:00
7YctWnyhjpL,2021,Reject,False,Multi-Task Learning by a Top-Down Control Network,"[""Hila Levi"", ""Shimon Ullman""]","[""multi task learning"", ""computer vision""]","We present a multi-task learning scheme, which uses a dedicated top-down control network to modify the main recognition network in a manner that makes it highly selective to the selected task, obtaining high accuracy demonstrated on several datasets.",,,,
7Yhok3vJpU,2021,Reject,False,"High-Likelihood Area Matters --- Rewarding Correct,Rare Predictions Under Imbalanced Distributions","[""guangxiang zhao"", ""Lei Li"", ""Xuancheng Ren"", ""Xu Sun"", ""Bin He""]","[""classification"", ""imbalance"", ""long-tailed"", ""likelihood"", ""focal loss""]",We chanllenge the intuition that high-likelihood area should be weaken for learning under imbalanced distributions and find that the correct predictions of rare classes paly an important role.,,,,
7Z29QbHxIL,2021,Reject,False,FTSO: Effective NAS via First Topology Second Operator,"[""Likang Wang"", ""Lei Chen""]","[""Neural Architecture Search"", ""DARTS""]","Our method, named FTSO, reduces NAS's search time from days to 0.68 seconds while achieving 76.42% testing accuracy on ImageNet and 97.77% testing accuracy on CIFAR10 via searching for network topology and operators separately",,,,
7Z7u2z1Ornl,2022,Reject,False,Pruning Edges and Gradients to Learn Hypergraphs from Larger Sets,"['David W Zhang', 'Gertjan J. Burghouts', 'Cees G. M. Snoek']","[""set-to-hypergraph""]",We improve the asymptotic memory complexity for set-to-hypergraph tasks.,,,,
7ZJPhriEdRQ,2021,Reject,False,AR-ELBO: Preventing Posterior Collapse Induced by Oversmoothing in Gaussian VAE,"[""Yuhta Takida"", ""Wei-Hsiang Liao"", ""Toshimitsu Uesaka"", ""Shusuke Takahashi"", ""Yuki Mitsufuji""]","[""Generative model"", ""variational autoencoders"", ""posterior collapse"", ""regularization""]",Controls the strength of regularization in ELBO to avoid posterior collapse in Gaussian VAE.,2102.08663,cs.LG,2021-02-17 10:00:49+00:00,2021-02-17 10:00:49+00:00
7_G8JySGecm,2021,Accept (Poster),False,Monte-Carlo Planning and Learning with Language Action Value Estimates,"[""Youngsoo Jang"", ""Seokin Seo"", ""Jongmin Lee"", ""Kee-Eung Kim""]","[""natural language processing"", ""Monte-Carlo tree search"", ""reinforcement learning"", ""interactive fiction""]",We present Monte-Carlo planning with Language Action Value Estimates (MC-LAVE) that combines a Monte-Carlo tree search with language-driven exploration for Interactive Fiction games.,,,,
7_JR7WpwKV1,2022,Accept (Poster),True,The Effects of Invertibility on the Representational Complexity of Encoders in Variational Autoencoders ,"['Divyansh Pareek', 'Andrej Risteski']","[""variational autoencoders"", ""encoder"", ""representational complexity"", ""Langevin"", ""invertibility"", ""deep learning theory""]",VAEs with invertible mean map have small approximate encoders; non-invertible maps can result in large encoders. ,2107.04652,cs.LG,2021-07-09 19:53:29+00:00,2021-07-09 19:53:29+00:00
7aL-OtQrBWD,2021,Accept (Poster),True,A Learning Theoretic Perspective on Local Explainability,"[""Jeffrey Li"", ""Vaishnavh Nagarajan"", ""Gregory Plumb"", ""Ameet Talwalkar""]","[""Interpretability"", ""Learning Theory"", ""Local Explanations"", ""Generalization""]",,2011.01205,cs.LG,2020-11-02 18:48:46+00:00,2020-11-02 18:48:46+00:00
7aogOj_VYO0,2021,Accept (Poster),False,Do not Let Privacy Overbill Utility:  Gradient Embedding Perturbation for Private Learning,"[""Da Yu"", ""Huishuai Zhang"", ""Wei Chen"", ""Tie-Yan Liu""]","[""privacy preserving machine learning"", ""differentially private deep learning"", ""gradient redundancy""]",A new algorithm for differentially private learning that advances state-of-the-art performance on several benchmark datasets. Code: https://github.com/dayu11/Gradient-Embedding-Perturbation,2102.12677,cs.LG,2021-02-25 04:29:58+00:00,2021-10-12 09:38:48+00:00
7apQQsbahFz,2021,Reject,True,Intention Propagation for  Multi-agent Reinforcement Learning,"[""Chao Qu"", ""Hui Li"", ""Chang Liu"", ""Junwu Xiong"", ""james zhang"", ""Wei Chu"", ""Weiqiang Wang"", ""Yuan Qi"", ""Le Song""]",[],,2004.08883,cs.LG,2020-04-19 15:42:55+00:00,2021-01-18 02:16:01+00:00
7b4zxUnrO2N,2022,Accept (Spotlight),False,Possibility Before Utility: Learning And Using Hierarchical Affordances,"['Robby Costales', 'Shariq Iqbal', 'Fei Sha']","[""RL"", ""HRL"", ""reinforcement learning"", ""hierarchical reinforcement learning"", ""affordances"", ""hierarchical affordances""]",We introduce a method that achieves superior performance in complex hierarchical tasks by utilizing a notion of subtask dependency grounded in the present state.,,,,
7dpmlkBuJFC,2021,Accept (Poster),False,Bypassing the Ambient Dimension: Private SGD with Gradient Subspace Identification,"[""Yingxue Zhou"", ""Steven Wu"", ""Arindam Banerjee""]",[],,,,,
7eD88byszZ,2021,Reject,True,A Unified Spectral Sparsification Framework for Directed Graphs,"[""ying zhang"", ""Zhiqiang Zhao"", ""Zhuo Feng""]","[""Spectral Graph Theory"", ""Spectral Sparsification"", ""Directed Graphs"", ""Laplacian Solver"", ""PageRank Vectors""]",A unified directed graphs spectral sparsification approach that is more general than prior theoretical results,1812.04165,cs.DS,2018-12-11 00:56:38+00:00,2020-04-30 19:21:20+00:00
7ehDLD1yoE0,2021,Reject,False,"STRATA: Simple, Gradient-free Attacks for Models of Code","[""Jacob M. Springer"", ""Bryn Marie Reinstadler"", ""Una-May O'Reilly""]","[""Deep Learning"", ""Models of Code"", ""Black-box Adversarial Attacks"", ""Adversarial Robustness""]",We present an efficient state-of-the-art method for constructing gradient-free adversarial attacks for models of code that outperform currently available gradient-based attacks.,,,,
7fFO4cMBx_9,2022,Accept (Poster),False,Variational Neural Cellular Automata,"['Rasmus Berg Palm', 'Miguel GonzÃ¡lez Duque', 'Shyam Sudhakaran', 'Sebastian Risi']","[""Neural Cellular Automata"", ""Cellular Automata"", ""Self-Organization"", ""Generative Models""]","We propose and evaluate the Variational Neural Cellular Automata, a self-organising generative model based on neural cellular automata",,,,
7gE9V9GBZaI,2022,Accept (Poster),False,Exploring Memorization in Adversarial Training,"['Yinpeng Dong', 'Ke Xu', 'Xiao Yang', 'Tianyu Pang', 'Zhijie Deng', 'Hang Su', 'Jun Zhu']","[""Adversarial examples"", ""adversarial training"", ""memorization"", ""robust overfitting""]","This paper explores the memorization effect in adversarial training and analyzes its connections with model capacity, convergence, generalization, and especially robust overfitting of the adversarially trained models.",,,,
7gRvcAulxa,2022,Reject,False,A Frequency Perspective of Adversarial Robustness,"['Shishira Maiya', 'Max Ehrlich', 'Vatsal Agarwal', 'Ser-Nam Lim', 'Tom Goldstein', 'Abhinav Shrivastava']","[""Adversarial examples"", ""Frequency analysis"", ""Adversarial Robustness"", ""Adversarial training""]",We propose a frequency-based framework to analyze the constituent frequencies of adversarial examples which resolves misconceptions in the field.,,,,
7gWSJrP3opB,2022,Accept (Spotlight),False,A General Analysis of Example-Selection for Stochastic Gradient Descent,"['Yucheng Lu', 'Si Yi Meng', 'Christopher De Sa']",[],,,,,
7grkzyj89A_,2022,Accept (Poster),False,Generalization Through the Lens of Leave-One-Out Error,"['Gregor Bachmann', 'Thomas Hofmann', 'Aurelien Lucchi']",[],,,,,
7hMenh--8g,2021,Reject,False,Uncertainty Weighted Offline Reinforcement Learning,"[""Yue Wu"", ""Shuangfei Zhai"", ""Nitish Srivastava"", ""Joshua M. Susskind"", ""Jian Zhang"", ""Ruslan Salakhutdinov"", ""Hanlin Goh""]","[""reinforcement learning"", ""offline"", ""batch reinforcement learning"", ""off-policy"", ""uncertainty estimation"", ""dropout"", ""actor-critic"", ""bootstrap error""]",A simple and effective uncertainty weighted training mechanism for stabilizing offline reinforcement learning.,,,,
7inCJ3MhXt3,2022,Accept (Poster),False,Learning Neural Contextual Bandits through Perturbed Rewards,"['Yiling Jia', 'Weitong ZHANG', 'Dongruo Zhou', 'Quanquan Gu', 'Hongning Wang']","[""contextual bandit"", ""neural bandit""]",,2201.09910,cs.LG,2022-01-24 19:10:22+00:00,2022-01-24 19:10:22+00:00
7kOsYRp4EmB,2022,Reject,False,Improving Meta-Continual Learning Representations with Representation Replay,"['Lawrence Ki-On Chan', 'James Kwok']","[""meta-learning"", ""continual learning"", ""meta-continual learning"", ""replay""]",We propose the Online aware Meta-Representation Replay (OMREP) to meta-learn representations for continual learning and the Predictive Sample Selection (PSS) to select the most significant samples for replay.,,,,
7kqWcX_r2w,2022,Reject,False,Meta Attention For Off-Policy Actor-Critic,"['Jiateng Huang', 'Wanrong Huang', 'Long Lan', 'Dan Wu']","[""reinforcement learning"", ""meta learning"", ""Attention Mechanism""]",,,,,
7ktHTjV9FHw,2022,Reject,False,Relative Molecule Self-Attention Transformer,"['Lukasz Maziarka', 'Dawid Majchrowski', 'Tomasz Danel', 'Piotr GaiÅski', 'Jacek Tabor', 'Igor T. Podolak', 'Pawel Morkisz', 'Stanislaw Kamil Jastrzebski']","[""molecular property prediction"", ""transformer-based methods"", ""graph neural networks"", ""self-supervised learing""]",We present Relative Molecule Attention Transformer -- a transformer-based model for a molecular property prediction task that is based on relative self-attention.,,,,
7l1IjZVddDW,2022,Accept (Spotlight),False,Improving Federated Learning Face Recognition via Privacy-Agnostic Clusters,"['Qiang Meng', 'Feng Zhou', 'Hainan Ren', 'Tianshu Feng', 'Guochao Liu', 'Yuanqing Lin']",[],,,,,
7nfCtKep-v,2021,Reject,False,EXPLORING VULNERABILITIES OF BERT-BASED APIS,"[""Xuanli He"", ""Lingjuan Lyu"", ""Lichao Sun"", ""Xiaojun Chang"", ""Jun Zhao""]","[""BERT-based models"", ""vulnerabilities"", ""attribute inference"", ""transferability""]",We demonstrate that the extracted model can be used to enhance the sensitive attribute inference and adversarial transferability.,,,,
7oyVOECcrt,2022,Reject,False,Local Permutation Equivariance For Graph Neural Networks,"['Joshua Mitton', 'Roderick Murray-Smith']","[""Graphs"", ""Equivariance"", ""Permutation Equivariance"", ""Graph Neural Networks"", ""Representations""]","A framework for building graph neural networks that operate on local node neighbourhoods, through sub-graphs, while using permutation equivariant update functions.",,,,
7pZiaojaVGU,2022,Reject,False,An Equivalence Between Data Poisoning and Byzantine Gradient Attacks,"['Sadegh Farhadkhani', 'Rachid Guerraoui', 'LÃª-NguyÃªn Hoang', 'Oscar Villemaud']","[""Federated learning"", ""PAC learning"", ""Byzantine attack"", ""Data poisoning"", ""Personalized  learning""]","We show that in a personalized federated learning system with PAC guarantees, the data poisoning attack is equivalent to the Byzantine gradient attack.",,,,
7pgFL2Dkyyy,2021,Accept (Poster),True,Class Normalization for (Continual)? Generalized Zero-Shot Learning,"[""Ivan Skorokhodov"", ""Mohamed Elhoseiny""]","[""zero-shot learning"", ""normalization"", ""continual learning"", ""initialization""]","We develop theoretical understanding of signal normalization inside zero-shot learning models, propose a novel normalization scheme and use it to achieve SotA ZSL performance with a simple MLP",2006.11328,cs.LG,2020-06-19 19:05:24+00:00,2021-04-14 16:12:34+00:00
7qaCQiuOVf,2022,Reject,False,Interpreting Reinforcement Policies through Local Behaviors,"['Ronny Luss', 'Amit Dhurandhar', 'Miao Liu']","[""Reinforcement Learning"", ""Explainability""]",We seek local explanations of reinforcement policies by clustering nearby states as a function of the policy dynamics and identifying which states within the clusters are most prudent to aim for.,,,,
7qmQNB6Wn_B,2021,Reject,True,Diversity Actor-Critic: Sample-Aware Entropy Regularization for Sample-Efficient Exploration,"[""Seungyul Han"", ""Youngchul Sung""]","[""Reinforcement Learning"", ""Entropy Regularization"", ""Exploration""]",The paper introduces sample-aware entropy regularization for sample-efficient exploration and the corresponding diversity actor-critic algorithm that generalizes SAC.,2006.01419,cs.LG,2020-06-02 06:51:25+00:00,2021-06-09 03:05:50+00:00
7r6kDq0mK_,2022,Accept (Poster),False,Latent Image Animator: Learning to animate image via latent space navigation,"['Yaohui Wang', 'Di Yang', 'Francois Bremond', 'Antitza Dantcheva']","[""Video generation"", ""Generative Adversarial Network""]",Image animation via latent space navigation,,,,
7sz69eztw9,2022,Reject,False,"Context-invariant, multi-variate time series representations","['Stephan Rabanser', 'Tim Januschowski', 'Kashif Rasul', 'Oliver Borchert', 'Richard Kurle', 'Jan Gasthaus', 'Michael Bohlke-Schneider', 'Nicolas Papernot', 'Valentin Flunkert']","[""time series"", ""representation learning"", ""contrastive learning"", ""context invariance"", ""anomaly detection"", ""domain adversarial learning""]",We present embeddings for time series that are invariant with respect to a given (time series) context and enable down-stream applications such as data exploration or contextual anomaly detection.,,,,
7t1FcJUWhi3,2021,Accept (Poster),False,Neural Networks for Learning Counterfactual G-Invariances from Single Environments,"[""S Chandra Mouli"", ""Bruno Ribeiro""]","[""Extrapolation"", ""G-invariance regularization"", ""Counterfactual inference"", ""Invariant subspaces""]","This work introduces a novel learning framework for single-environment extrapolations, where invariance to transformation groups is mandatory even without evidence, unless the learner deems it inconsistent with the training data.",2104.10105,cs.LG,2021-04-20 16:35:35+00:00,2021-04-20 16:35:35+00:00
7t_6BiC69a,2022,Reject,False,Fieldwise Factorized Networks for Tabular Data Classification,"['Chen Almagor', 'Yedid Hoshen']",[],,,,,
7twQI5VnC8,2022,Accept (Spotlight),False,Learning Causal Relationships from Conditional Moment Restrictions by Importance Weighting,"['Masahiro Kato', 'Masaaki Imaizumi', 'Kenichiro McAlinn', 'Shota Yasui', 'Haruo Kakehi']","[""Causal inference"", ""Conditional moment restrictions""]",Learning causal relationships under conditional moment restrictions by importance weighting using the conditional density ratio function.,,,,
7uVcpu-gMD,2021,Accept (Poster),True,Are Neural Nets Modular? Inspecting Functional Modularity Through Differentiable Weight Masks,"[""R\u00f3bert Csord\u00e1s"", ""Sjoerd van Steenkiste"", ""J\u00fcrgen Schmidhuber""]","[""modularity"", ""systematic generalization"", ""compositionality""]",We develop a method for analyzing emerging functional modularity in neural networks based on differentiable weight masks and use it to point out important issues in current-day neural networks.,2010.02066,cs.NE,2020-10-05 15:04:11+00:00,2021-03-06 17:35:13+00:00
7udZAsEzd60,2022,Accept (Poster),False,VC dimension of partially quantized neural networks in the overparametrized regime,"['Yutong Wang', 'Clayton Scott']","[""VC dimension"", ""quantized neural networks"", ""classification"", ""minimax theory"", ""overparametrization""]",We apply VC theory to analyze the performance of a neural network in the overparametrized regime and obtain a minimax-optimality result.,,,,
7vXQJ2QW8hR,2022,Reject,False,Max-Affine Spline Insights Into Deep Network Pruning,"['Randall Balestriero', 'Haoran You', 'Zhihan Lu', 'Yutong Kou', 'Huihong Shi', 'Yingyan Lin', 'Richard Baraniuk']","[""DNN Interpretability"", ""Network pruning"", ""Max-affine spline theory"", ""Visualization""]",We leverage the spline theory to interpret network pruning and propose a principal and efficient pruning method.,,,,
7vcKot39bsv,2022,Reject,False,Adaptive Inertia: Disentangling the Effects of Adaptive Learning Rate and Momentum,"['Zeke Xie', 'Xinrui Wang', 'Huishuai Zhang', 'Issei Sato', 'Masashi Sugiyama']","[""Learning Dynamics"", ""Diffusion"", ""Stochastic Optimization"", ""Momentum""]","The proposed Adaptive Inertia method, which uses parameter-wise adaptive momentum hyperparameters, may provably select flat minima better than the conventional Adaptive Gradient methods.",,,,
7wCBOfJ8hJM,2021,Accept (Poster),True,Nearest Neighbor Machine Translation,"[""Urvashi Khandelwal"", ""Angela Fan"", ""Dan Jurafsky"", ""Luke Zettlemoyer"", ""Mike Lewis""]","[""nearest neighbors"", ""machine translation""]","We augment the decoder of a pre-trained machine translation model with a nearest neighbor classifier, substantially improving performance in the single language-pair, multilingual and domain adaptation settings, without any additional training.",2010.00710,cs.CL,2020-10-01 22:24:46+00:00,2021-07-22 14:44:51+00:00
7x_47XJULn,2022,Reject,False,Federated Learning with Heterogeneous Architectures using Graph HyperNetworks,"['Or Litany', 'Haggai Maron', 'David Acuna', 'Jan Kautz', 'Gal Chechik', 'Sanja Fidler']","[""federated learning"", ""graph neural networks"", ""hypernetworks""]",A graph-hypernetwork-based solution for federated learning where clients have different neural architectures,,,,
7xzVpAP5Cm,2022,Reject,False,Non-reversible Parallel Tempering for Uncertainty Approximation in Deep Learning,"['Wei Deng', 'Qian Zhang', 'Qi Feng', 'Faming Liang', 'Guang Lin']","[""replica exchange"", ""parallel tempering"", ""non-reversibility"", ""stochastic approximation"", ""round trip rate"", ""deep learning""]",A user-friendly parallel tempering algorithm that tracks the non-reversibility property with an optimal round trip time in deep learning.,,,,
7yuU9VeIpde,2022,Reject,False,Memory-Constrained Policy Optimization,"['Hung Le', 'Thommen Karimpanal George', 'Majid Abdolshah', 'Dung Nguyen', 'Kien Do', 'Sunil Gupta', 'Svetha Venkatesh']","[""reinforcement learning"", ""trust region policy optimization"", ""on-policy"", ""policy gradient"", ""neural network""]",A new constrained policy optimization method using two trust-regions instead of one.,,,,
7zFokR7k_86,2022,Reject,False,Learning Symbolic Rules for Reasoning in Quasi-Natural Language,"['Kaiyu Yang', 'Jia Deng']",[],,,,,
7zc05Ua_HOK,2022,Reject,False,Learning Sample Reweighting for Adversarial Robustness,"['Chester Holtz', 'Tsui-Wei Weng', 'Gal Mishne']","[""deep learning"", ""adversarial attack"", ""robust training""]",,,,,
8-sxWOto_iI,2021,Reject,False,Introducing Sample Robustness,"[""Monty Maximilian Z\u00fchlke""]",[],"We introduce the concept of sample robustness for measuring how sensitive elements of a dataset are towards label-changing perturbations, followed by a theoretical discussion and an empirical analysis. ",,,,
80FMcTSZ6J0,2021,Accept (Spotlight),False,Noise against noise: stochastic label noise helps combat inherent label noise,"[""Pengfei Chen"", ""Guangyong Chen"", ""Junjie Ye"", ""jingwei zhao"", ""Pheng-Ann Heng""]","[""Noisy Labels"", ""Robust Learning"", ""SGD noise"", ""Regularization""]","SGD noise induced by stochastic label noise helps escape sharp minima and prevents overconfidence, hence can mitigate the effects of inherent label noise and improve generalization.",,,,
81e1aeOt-sd,2022,Accept (Poster),False,On-Policy Model Errors in Reinforcement Learning,"['Lukas Froehlich', 'Maksym Lefarov', 'Melanie Zeilinger', 'Felix Berkenkamp']","[""Model-based reinforcement learning"", ""reinforcement learning"", ""model learning""]",We combine real-world data and a learned model for data-efficient reinforcement learning with reduced model-bias.,,,,
827jG3ahxL,2022,Reject,False,REFACTOR: Learning to Extract Theorems from Proofs,"['Jin Peng Zhou', 'Yuhuai Wu', 'Qiyang Li', 'Roger Baker Grosse']","[""theorem extraction"", ""mathematical reasoning"", ""theorem proving"", ""reasoning""]","We extract useful mathematical theorems using neural networks, evaluating on several downstream tasks to demonstrate their great utility.",,,,
844kbKgwDL,2022,Reject,False,Predicting subscriber usage: Analyzing multi-dimensional time-series using Convolutional Neural Networks,"['Benjamin Azaria', 'Lee-Ad Gottlieb']","[""Convolutional Neural Network"", ""time series"", ""usage prediction""]",,,,,
847CwJv9Vx,2022,Reject,False,Benchmarking person re-identification approaches and training datasets for practical real-world implementations,"['Jose Miguel Huaman Cruz', 'Felix Oliver Sumari Huayta', 'Luigy Alex Machaca Arcana', 'Esteban GONZALEZ CLUA', 'Joris Guerin']","[""person re-identification"", ""benchmark study"", ""practical deployment""]",This paper introduces a complete methodology to evaluate Re-ID approaches and training datasets with respect to their suitability for deployment for live operations.,,,,
84NMXTHYe-,2022,Accept (Poster),True,Evidential Turing Processes ,"['Melih Kandemir', 'Abdullah AkgÃ¼l', 'Manuel Haussmann', 'Gozde Unal']","[""Evidential Deep Learning"", ""Neural Processes"", ""Attention"", ""Neural Turing Machines""]",An original extension of evidential deep learning with neural processes and neural Turing machines makes it possible to attain both in-domain calibration and out-of-domain detection in a single model. ,2106.01216,cs.LG,2021-06-02 15:09:20+00:00,2021-10-06 07:34:00+00:00
84gjULz1t5,2021,Accept (Poster),True,Linear Convergent Decentralized Optimization with Compression,"[""Xiaorui Liu"", ""Yao Li"", ""Rongrong Wang"", ""Jiliang Tang"", ""Ming Yan""]","[""Decentralized Optimization"", ""Communication Compression"", ""Linear Convergence"", ""Heterogeneous data""]",A Linear Convergent Decentralized Optimization with Communication Compression,2007.00232,cs.LG,2020-07-01 04:35:00+00:00,2021-03-18 20:46:05+00:00
85d8bg9RvDT,2021,Reject,False,Deep Retrieval: An End-to-End Structure Model for Large-Scale Recommendations,"[""Weihao Gao"", ""Xiangjun Fan"", ""Jiankai Sun"", ""Kai Jia"", ""Wenzhi Xiao"", ""Chong Wang"", ""Xiaobing Liu""]","[""Large-scale recommendation system"", ""End-to-end training""]","We proposed Deep Retrieval, a novel end-to-end learnable structure model which can accurately and efficiently retrieve top relevant candidates in large-scale recommendation system.",,,,
86PW5gch8VZ,2021,Reject,False,DQSGD: DYNAMIC QUANTIZED STOCHASTIC GRADIENT DESCENT FOR COMMUNICATION-EFFICIENT DISTRIBUTED LEARNING,"[""Guangfeng Yan"", ""Shao-Lun Huang"", ""Tian Lan"", ""Linqi Song""]","[""Distributed Learning"", ""Communication"", ""Gradient Quantization""]",DQSGD: DYNAMIC QUANTIZED STOCHASTIC GRADIENT DESCENT FOR COMMUNICATION-EFFICIENT DISTRIBUTED LEARNING,,,,
86sEVRfeGYS,2022,Reject,False,Continual Backprop: Stochastic Gradient Descent with Persistent Randomness,"['Shibhansh Dohare', 'Richard S. Sutton', 'A. Rupam Mahmood']","[""Continual Adaptation"", ""Reinforcement Learning"", ""Continual Learning"", ""Online Learning""]",We show that Backprop is unsuitable for continual adaptation and then propose more suitable algorithms,,,,
86t2GlfzFo,2021,Reject,False,Deep Curvature Suite,"[""Diego Granziol"", ""Xingchen Wan"", ""Timur Garipov""]","[""Hessian computation"", ""Deep Learning"", ""Loss Curvature"", ""Lanczos""]",This package allows the easy computation and visualisation of curvature information for deep neural networks.,,,,
87Ks7PvYVJi,2022,Reject,False,Offline Decentralized Multi-Agent Reinforcement Learning,"['Jiechuan Jiang', 'Zongqing Lu']","[""multi-agent reinforcement learning""]",A novel method for offline decentralized multi-agent reinforcement learning,,,,
87Ti3dufEv,2021,Reject,True,A Half-Space Stochastic Projected Gradient Method for Group Sparsity Regularization,"[""Tianyi Chen"", ""Guanyi Wang"", ""Tianyu DING"", ""Bo Ji"", ""Sheng Yi"", ""Zhihui Zhu""]","[""Group Sparsity"", ""Stochastic Learning"", ""Half-Space Projection"", ""Group-Sparsity Identification""]",We propose a Half-Space Projection to effectively explore group sparsity structure with theoretical convergence guarantee in order to overcome the limitation of existing stochastic proximal method.,2009.12078,math.OC,2020-09-25 08:00:07+00:00,2021-02-13 04:51:43+00:00
87ZwsaQNHPZ,2021,Accept (Spotlight),False,CPT: Efficient Deep Neural Network Training via Cyclic Precision,"[""Yonggan Fu"", ""Han Guo"", ""Meng Li"", ""Xin Yang"", ""Yining Ding"", ""Vikas Chandra"", ""Yingyan Lin""]","[""Efficient training"", ""low precision training""]",We propose Cyclic Precision Training towards better accuracy-efficiency trade-offs in DNN training.,2101.09868,cs.LG,2021-01-25 02:56:18+00:00,2021-05-07 01:59:49+00:00
88_MfcJoJlS,2021,Reject,True,Guided Exploration with Proximal Policy Optimization using a Single Demonstration,"[""Gabriele Libardi"", ""Gianni De Fabritiis""]","[""PPO"", ""sparse rewards"", ""single demonstration"", ""3D environment""]",An algorithm based on importance sampling for effienciently use a single human demonstration to solve hard-exploration problems in reinforcement learning ,2007.03328,cs.AI,2020-07-07 10:30:32+00:00,2021-06-16 21:38:35+00:00
89W18gW0-6o,2022,Reject,True,Provably Improved Context-Based Offline Meta-RL with Attention and Contrastive Learning,"['Lanqing Li', 'Yuanhao HUANG', 'Mingzhe Chen', 'siteng luo', 'Dijun Luo', 'Junzhou Huang']","[""Reinforcement Learning"", ""Representation learning for planning"", ""Meta-RL"", ""Attention Mechanism"", ""Contrastive Learning"", ""Offline RL""]",A new offline meta-RL SOTA with provably robustified task inference module via intra-task attention mechanism and inter-task contrastive learning.,2102.10774,cs.LG,2021-02-22 05:05:16+00:00,2021-10-15 10:10:32+00:00
8CCwiOHx_17,2021,Reject,False,Adversarial Environment Generation for Learning  to Navigate the Web,"[""Izzeddin Gur"", ""Natasha Jaques"", ""Kevin Malta"", ""Manoj Tiwari"", ""Honglak Lee"", ""Aleksandra Faust""]","[""Web Navigation"", ""Adversarial Environment Generation"", ""Web Environment Design"", ""Minimax Regret Adversary"", ""Auto Curriculum""]",Adversarial web environment generation via budget enforced minimax regret training.,2103.01991,cs.LG,2021-03-02 19:19:30+00:00,2021-03-02 19:19:30+00:00
8CEJlHbKoP4,2022,Reject,False,Learning a metacognition for object detection,"['Marlene Berke', 'Mario Belledonne', 'Zhangir Azerbayev', 'Julian Jara-Ettinger']","[""metacognition"", ""object detection"", ""unsupervised learning""]","We present MetaGen, a model for the unsupervised learning of a metacognition for object detection systems that enhances accuracy and generalizability.",,,,
8CjVaaSSVxg,2021,Reject,False,Learning Predictive Communication by Imagination in Networked System Control,"[""Yali Du"", ""Yifan Zhao"", ""Meng Fang"", ""Jun Wang"", ""Gangyan Xu"", ""Haifeng Zhang""]","[""Reinforcement Learning"", ""Multi-agent Reinforcement Learning"", ""Networked System Control""]","To eliminate the delay of global information sharing in networked system control, we introduce predictive communication by allowing an agent to imagine its future states and communicate that with its neighbors.",,,,
8Dhw-NmmwT3,2022,Reject,False,Lifting Imbalanced Regression with Self-Supervised Learning,"['Weiguo Pian', 'Hanyu Peng', 'Mingming Sun', 'Ping Li']","[""Imbalanced Regression"", ""Self-Supervised Learning"", ""Long-Tailed Learning""]",A novel self-supervised learning-based method for imbalanced regression,,,,
8E1-f3VhX1o,2021,Accept (Poster),False,Combining Label Propagation and Simple Models out-performs Graph Neural Networks,"[""Qian Huang"", ""Horace He"", ""Abhay Singh"", ""Ser-Nam Lim"", ""Austin Benson""]","[""graphs"", ""graph neural networks"", ""label propagation"", ""simple"", ""residual""]",,,,,
8EGmvcCVrmZ,2021,Reject,True,"Deep Learning is Singular, and That's Good","[""Daniel Murfet"", ""Susan Wei"", ""Mingming Gong"", ""Hui Li"", ""Jesse Gell-Redman"", ""Thomas Quella""]","[""deep learning theory"", ""effective degrees of freedom"", ""generalisation"", ""posterior predictive distribution"", ""real log canonical threshold"", ""singular learning theory""]",An invitation to singular learning theory as a theory of deep learning,2010.11560,cs.LG,2020-10-22 09:33:59+00:00,2020-10-22 09:33:59+00:00
8FRw857AYba,2021,Reject,False,Sample efficient Quality Diversity for neural continuous control,"[""Thomas PIERROT"", ""Valentin Mac\u00e9"", ""Geoffrey Cideron"", ""Nicolas Perrin"", ""Karim Beguir"", ""Olivier Sigaud""]","[""Deep Neuroevolution"", ""Quality Diversity"", ""Reinforcement Learning""]","QD-RL is a novel more sample efficient Deep Neuroevolution algorithm, that combines the strengths of off-policy reinforcement learning (RL) algorithms and Quality Diversity (QD) approaches to solve continuous control problems with neural controllers.",,,,
8FhxBtXSl0,2022,Accept (Poster),False,CKConv: Continuous Kernel Convolution For Sequential Data,"['David W. Romero', 'Anna Kuzina', 'Erik J Bekkers', 'Jakub Mikolaj Tomczak', 'Mark Hoogendoorn']","[""Convolutional Networks"", ""Continuous kernel Convolutions"", ""Continuous Convolutional Kernels"", ""Implicit Neural Representations"", ""Sequential Data.""]","We provide  a continuous parameterization to convolutional kernels, with which several advantages upon conventional (discrete) parameterizations are obtained.",,,,
8H5bpVwvt5,2022,Accept (Spotlight),True,"AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning","['Biwei Huang', 'Fan Feng', 'Chaochao Lu', 'Sara Magliacane', 'Kun Zhang']","[""Transfer RL"", ""Graphical models"", ""Efficient adaptation""]",Efficient policy adaptation across domains by learning a parsimonious graphical representation that encodes changes in a compact way.,2107.02729,cs.LG,2021-07-06 16:56:25+00:00,2021-10-07 21:17:20+00:00
8HhkbjrWLdE,2021,Accept (Poster),False,Separation and Concentration in Deep Networks,"[""John Zarka"", ""Florentin Guth"", ""St\u00e9phane Mallat""]","[""fisher ratio"", ""neural collapse"", ""mean separation"", ""concentration"", ""variance reduction"", ""deep learning"", ""image classification""]",,2012.10424,cs.LG,2020-12-18 18:27:37+00:00,2021-03-15 15:06:51+00:00
8IXBbFjkMat,2022,Reject,True,Bag-of-Vectors Autoencoders for Unsupervised Conditional Text Generation,"['Florian Mai', 'James Henderson']","[""autoencoders"", ""latent space learning"", ""variable-size"", ""natural language processing""]",We represent text as a set of vectors and present a method to learn unsupervised sequence-to-sequence tasks as a mapping from one set of vectors to another set of vectors.,2110.07002,cs.CL,2021-10-13 19:30:40+00:00,2021-10-13 19:30:40+00:00
8IbZUle6ieH,2021,Reject,False,Graph Neural Network Acceleration via Matrix Dimension Reduction,"[""Shunhua Jiang"", ""Yunze Man"", ""Zhao Song"", ""Danyang Zhuo""]","[""Graph Neural Networks"", ""Deep learning"", ""Optimization"", ""Kernel Method""]",,,,,
8KD0wdSF2NE,2022,Reject,False,A composable autoencoder-based algorithm for accelerating numerical simulations,"['Rishikesh Ranade', 'Derek Christopher Hill', 'Haiyang He', 'Amir Maleki', 'Norman Chang', 'Jay Pathak']","[""numerical simulations"", ""machine learning""]","We present a composable, unsupervised autoencoder-based iterative algorithm for accelerating numerical simulations for a variety of engineering applications.",,,,
8KhxoxKP3iL,2021,Reject,False,Analyzing Attention Mechanisms through Lens of Sample Complexity and Loss Landscape,"[""Bingyuan Liu"", ""Yogesh Balaji"", ""Lingzhou Xue"", ""Martin Renqiang Min""]","[""Attention mechanisms"", ""deep learning"", ""sample complexity"", ""self-attention""]",We theoretically and empirically analyze the superiority of attention mechanisms in aspect of sample complexity and loss landscape.,,,,
8Ln-Bq0mZcy,2021,Accept (Poster),False,On the Critical Role of Conventions in Adaptive Human-AI Collaboration,"[""Andy Shih"", ""Arjun Sawhney"", ""Jovana Kondic"", ""Stefano Ermon"", ""Dorsa Sadigh""]","[""Multi-agent games"", ""emergent behavior"", ""transfer learning"", ""human-AI collaboration""]",Training agents that can adapt to new settings in multi-agent games.,2104.02871,cs.LG,2021-04-07 02:46:19+00:00,2021-04-07 02:46:19+00:00
8MN_GH4Ckp4,2022,Reject,True,Model Compression via Symmetries of the Parameter Space,"['Iordan Ganev', 'Robin Walters']","[""symmetry"", ""orthogonal group"", ""quiver representation"", ""representation theory"", ""model compression"", ""parameter optimization"", ""projected gradient descent""]",The representation theory of quivers describes symmetry in the structure of the neural networks which can be used for model compression.,2107.02550,cs.LG,2021-07-06 11:41:02+00:00,2021-07-06 11:41:02+00:00
8PS8m9oYtNy,2021,Accept (Spotlight),False,Implicit Normalizing Flows,"[""Cheng Lu"", ""Jianfei Chen"", ""Chongxuan Li"", ""Qiuhao Wang"", ""Jun Zhu""]","[""Normalizing flows"", ""deep generative models"", ""probabilistic inference"", ""implicit functions""]","We generalize normalizing flows, allowing the mapping to be implicitly defined by the roots of an equation and enlarging the expressiveness power while retaining the tractability.",2103.09527,stat.ML,2021-03-17 09:24:04+00:00,2021-03-17 09:24:04+00:00
8Py-W8lSUgy,2022,Accept (Spotlight),False,Relational Multi-Task Learning: Modeling Relations between Data and Tasks,"['Kaidi Cao', 'Jiaxuan You', 'Jure Leskovec']","[""Graph Neural Networks"", ""Relational Representation Learning"", ""Multi-task Learning"", ""Meta Learning""]","We propose MetaLink to solve a variety of multi-task learning settings, by constructing a knowledge graph over data points and tasks.",,,,
8QAXsAOSBjE,2021,Reject,False,Reusing Preprocessing Data as Auxiliary Supervision in Conversational Analysis,"[""Joshua Yee Kim"", ""Kalina Yacef""]","[""Multitask Learning"", ""Multimodal Conversational Analysis""]","For multimodal conversational analysis, we have identified what are the beneficially auxiliary tasks, how to construct them through reusing preprocessing data, and the model architecture design to improve the primary tasks performances.",,,,
8QE3pwEVc8P,2022,Reject,False,Zero-Cost Operation Scoring in Differentiable Architecture Search,"['Lichuan Xiang', 'Åukasz Dudziak', 'Mohamed S Abdelfattah', 'Thomas Chun Pong Chau', 'Nicholas Donald Lane', 'Hongkai Wen']",[],"A new perturbation-based NAS method for supernetworks using zero-cost proxies, achieving SOTA accuracy but >40x faster ",,,,
8SP2-AiWttb,2021,Reject,False,Imbalanced Gradients: A New Cause of Overestimated Adversarial Robustness,"[""Linxi Jiang"", ""Xingjun Ma"", ""Zejia Weng"", ""James Bailey"", ""Yu-Gang Jiang""]","[""Adversarial Attack"", ""Robustness Evaluation"", ""Adversarial Defense"", ""Deep Neural Networks""]",A new subtle gradient problem in adversarial robustness evaluation is identified and addressed by a new attack.,,,,
8Sqhl-nF50,2021,Accept (Poster),True,On the Curse of Memory in Recurrent Neural Networks: Approximation and Optimization Analysis,"[""Zhong Li"", ""Jiequn Han"", ""Weinan E"", ""Qianxiao Li""]","[""recurrent neural network"", ""dynamical system"", ""universal approximation"", ""optimization"", ""curse of memory""]","We study the approximation properties and optimization dynamics of RNNs in the linear setting, where we uncover precisely the adverse effect of memory on learning.",2009.07799,cs.LG,2020-09-16 16:48:28+00:00,2021-05-16 03:36:21+00:00
8VXvj1QNRl1,2021,Accept (Poster),False,On the Transfer of Disentangled Representations in Realistic Settings,"[""Andrea Dittadi"", ""Frederik Tr\u00e4uble"", ""Francesco Locatello"", ""Manuel Wuthrich"", ""Vaibhav Agrawal"", ""Ole Winther"", ""Stefan Bauer"", ""Bernhard Sch\u00f6lkopf""]","[""representation learning"", ""disentanglement"", ""real-world""]",We scale disentangled representation learning to a new realistic dataset and conduct a large-scale empirical study on OOD generalization.,,,,
8W7LTo_zxdE,2021,Reject,False,Variational Deterministic Uncertainty Quantification,"[""Joost van Amersfoort"", ""Lewis Smith"", ""Andrew Jesson"", ""Oscar Key"", ""Yarin Gal""]","[""Uncertainty estimation"", ""gaussian processes"", ""deep learning"", ""variational inference""]",Uncertainty estimation using Deep Kernel Learning and a spectral normalized feature extractor.,,,,
8WawVDdKqlL,2022,Accept (Spotlight),False,Label Encoding for Regression Networks,"['Deval Shah', 'Zi Yu Xue', 'Tor Aamodt']","[""Regression"", ""Label encoding"", ""Output codes""]",We propose binary-encoded labels (BEL) which improves regression by generalizing the application of binary classification. ,,,,
8Wdj6IJsSyJ,2022,Reject,False,Fully differentiable model discovery,"['Gert-Jan Both', 'Remy Kusters']","[""Model discovery"", ""Sparse Bayesian Learning"", ""Normalizing Flows""]",We show how to do differentiable model discovery.,,,,
8X2eaSZxTP,2021,Accept (Poster),False,PC2WF: 3D Wireframe Reconstruction from Raw Point Clouds,"[""Yujia Liu"", ""Stefano D'Aronco"", ""Konrad Schindler"", ""Jan Dirk Wegner""]","[""deep neural network"", ""3d point cloud"", ""wireframe model""]",An end-to-end trainable deep neural network for converting a 3D point cloud into a wireframe model.,2103.02766,cs.CV,2021-03-04 00:18:06+00:00,2021-03-04 00:18:06+00:00
8XM-AXMnAk_,2022,Reject,False,Deep Active Learning by Leveraging Training Dynamics,"['Haonan Wang', 'Wei Huang', 'Hanghang Tong', 'Andrew J Margenot', 'Jingrui He']","[""deep learning"", ""active learning"", ""neural tangent kernel""]",,,,,
8Xi5MLFE_IW,2021,Reject,False,Episodic Memory for Learning Subjective-Timescale Models,"[""Alexey Zakharov"", ""Matthew Crosby"", ""Zafeirios Fountas""]","[""Episodic Memory"", ""Time Perception"", ""Active Inference"", ""Model-based Reinforcement Learning""]",A subjective-timescale transition model of episodic memory for planning over variable timescales in an active inference agent.,,,,
8YFhXYe1Ps,2021,Reject,False,Interpretability Through Invertibility: A Deep Convolutional Network With Ideal Counterfactuals And Isosurfaces,"[""Leon Sixt"", ""Martin Schuessler"", ""Philipp Wei\u00df"", ""Tim Landgraf""]","[""Interpretable Machine Learning"", ""Counterfactuals"", ""Computer Vision"", ""Human Evaluation"", ""User Study""]",We use invertible neural networks to generate ideal counterfactuals and isofactuals.,,,,
8_7yhptEWD,2021,Reject,False,On the Neural Tangent Kernel of Equilibrium Models,"[""Zhili Feng"", ""J Zico Kolter""]","[""deel learning"", ""equilibrium model"", ""neural tangent kernel""]","We present the neural tangent kernel for equilibrium models, which directly computes the infinite-depth limit of a weight-tied network.",,,,
8bZC3CyF-f7,2021,Reject,False,Align-RUDDER: Learning From Few Demonstrations by Reward Redistribution,"[""Vihang Prakash Patil"", ""Markus Hofmarcher"", ""Marius-Constantin Dinu"", ""Matthias Dorfer"", ""Patrick M Blies"", ""Johannes Brandstetter"", ""Jose Arjona-Medina"", ""Sepp Hochreiter""]",[],,,,,
8c50f-DoWAu,2022,Accept (Oral),False,Diffusion-Based Voice Conversion with Fast Maximum Likelihood Sampling Scheme,"['Vadim Popov', 'Ivan Vovk', 'Vladimir Gogoryan', 'Tasnima Sadekova', 'Mikhail Sergeevich Kudinov', 'Jiansheng Wei']","[""speech"", ""voice conversion"", ""diffusion models"", ""stochastic differential equations""]",,,,,
8cpHIfgY4Dj,2021,Accept (Poster),True,FOCAL: Efficient Fully-Offline Meta-Reinforcement Learning via Distance Metric Learning and Behavior Regularization,"[""Lanqing Li"", ""Rui Yang"", ""Dijun Luo""]","[""offline/batch reinforcement learning"", ""meta-reinforcement learning"", ""multi-task reinforcement learning"", ""distance metric learning"", ""contrastive learning""]","A novel model-free, end-to-end fully-offline meta-RL algorithm designed to maximize practicality, performance and sample/computational efficiency.",2010.01112,cs.LG,2020-10-02 17:13:39+00:00,2021-05-06 09:06:50+00:00
8e2vrVvvaeQ,2022,Reject,True,Indiscriminate Poisoning Attacks Are Shortcuts,"['Da Yu', 'Huishuai Zhang', 'Wei Chen', 'Jian Yin', 'Tie-Yan Liu']","[""Data Security"", ""Data Poisoning"", ""Shortcuts""]",We show poisoning attacks provide shortcuts to the target model by using linear separable perturbations.,2111.00898,cs.LG,2021-11-01 12:44:26+00:00,2021-11-01 12:44:26+00:00
8e6BrwU6AjQ,2021,Accept (Poster),False,MoVie: Revisiting Modulated Convolutions for Visual Counting and Beyond,"[""Duy Kien Nguyen"", ""Vedanuj Goswami"", ""Xinlei Chen""]","[""visual counting"", ""visual question answering"", ""common object counting"", ""visual reasoning"", ""modulated convolution""]",2020 VQA challenge winner; state-of-the-art performance on three counting benchmarks; can work beyond counting towards general visual reasoning,,,,
8eb12UQYxrG,2022,Accept (Poster),False,The Role of Pretrained Representations for the OOD Generalization of RL Agents,"['Frederik TrÃ¤uble', 'Andrea Dittadi', 'Manuel Wuthrich', 'Felix Widmaier', 'Peter Vincent Gehler', 'Ole Winther', 'Francesco Locatello', 'Olivier Bachem', 'Bernhard SchÃ¶lkopf', 'Stefan Bauer']","[""representations"", ""out-of-distribution"", ""generalization"", ""deep learning"", ""reinforcement learning""]",We study the role of pretrained representations for the out-of-distribution generalization of RL agents.,,,,
8f95ajHrIFc,2022,Reject,False,On Reward Maximization and Distribution Matching for Fine-Tuning Language Models,"['Tomasz Korbak', 'Hady Elsahar', 'GermÃ¡n Kruszewski', 'Marc Dymetman']","[""Reinforcement Learning"", ""Language Models"", ""Reward Maximization"", ""Distribution Matching"", ""Energy Based Models"", ""Controlled Text Generation""]",We describe and exploit connections between two distinct paradigms for expressing preferences over outputs of language models: reward maximization and distribution matching.,,,,
8gX3bY78aCb,2022,Reject,False,Molecular Graph Representation Learning via Heterogeneous Motif Graph Construction,"['Zhaoning Yu', 'Hongyang Gao']","[""Molecular Graph Representation"", ""Graph Neural Networks"", ""Heterogeneous""]",We propose a novel molecular graph representation learning method by constructing a Heterogeneous Motif graph to learn motif-level feature representations.,2202.00529,cs.LG,2022-02-01 16:21:01+00:00,2022-02-01 16:21:01+00:00
8hWs60AZcWk,2022,Accept (Poster),False,Discrete Representations Strengthen Vision Transformer Robustness,"['Chengzhi Mao', 'Lu Jiang', 'Mostafa Dehghani', 'Carl Vondrick', 'Rahul Sukthankar', 'Irfan Essa']","[""vision transformer"", ""robustness"", ""image recognition""]",We present a simple and effective architecture modification to ViT's input layer with discrete token representations.,2111.10493,cs.CV,2021-11-20 01:49:56+00:00,2021-11-20 01:49:56+00:00
8iW8HOidj1_,2021,Reject,False,Dream and Search to Control: Latent Space Planning for Continuous Control,"[""Anurag Koul"", ""Varun Kumar Vijay"", ""Alan Fern"", ""Somdeb Majumdar""]","[""Reinforcement Learning"", ""Model Based RL"", ""Continuous Control"", ""Search"", ""Planning"", ""MCTS""]","We show that performing tree-based search on learnt, latent dynamics as a planning mechanism for continuous control outperforms Dreamer.",,,,
8in_5gN9I0,2022,Accept (Poster),False,Triangle and Four Cycle Counting with Predictions in Graph Streams,"['Justin Y Chen', 'Talya Eden', 'Piotr Indyk', 'Honghao Lin', 'Shyam Narayanan', 'Ronitt Rubinfeld', 'Sandeep Silwal', 'Tal Wagner', 'David Woodruff', 'Michael Zhang']","[""learning augmented"", ""streaming"", ""graph streaming"", ""data driven"", ""cycle counting"", ""triangle counting""]",We propose algorithms for counting triangles and four cycles in graph streams with the aid of ML predictors.,,,,
8kVP8m93VqN,2022,Reject,False,Task-oriented Dialogue System for Automatic Disease Diagnosis via Hierarchical Reinforcement Learning,"['Kangenbei Liao', 'CHENG ZHONG', 'Wei Chen', 'Qianlong Liu', 'zhongyu wei', 'Baolin Peng', 'Xuanjing Huang']","[""Dialogue System"", ""Automatic Disease Diagnosis"", ""Hierarchical Reinforcement Learning""]",A Hierarchical Reinforcement Learning method for Automatic Disease Diagnosis,,,,
8kpSWDgzsh0,2022,Reject,False,Network Learning in Quadratic Games from Fictitious Plays,"['KEMI DING', 'Yijun Chen', 'Lei Wang', 'Xiaoqiang Ren', 'Guodong Shi']","[""network learning"", ""game theory""]",This paper presents theories and algorithms for learning the underlying network structure of linear-quadratic games from players' actions in repeated best responses.,,,,
8la28hZOwug,2022,Accept (Poster),False,Prototypical Contrastive Predictive Coding,['Kyungmin Lee'],"[""Knowledge distillation"", ""contrastive learning"", ""self-supervised learning""]",We propose prototypical contrastive predictive coding for efficient distillation of representational knowledge of one network into other network.,,,,
8mVSD0ETOXl,2021,Reject,False,Prediction of Enzyme Specificity using Protein Graph Convolutional Neural Networks,"[""Changpeng Lu"", ""Samuel Z Stentz"", ""Joseph H Lubin"", ""Sijian Wang"", ""Sagar D Khare""]","[""graph convolutional neural networks"", ""protease specificity"", ""proteins"", ""Rosetta energy function""]",A graphical convolutional neural network applied to protein structures predicts with high accuracy the specificity of molecular recognition and sets the stage for design of tailored enzymes against disease targets.,,,,
8nXkyH2_s6,2021,Reject,False,Neural networks behave as hash encoders: An empirical study,"[""Fengxiang He"", ""Shiye Lei"", ""Jianmin Ji"", ""Dacheng Tao""]","[""Explainability of deep learning""]",This paper reports and studies the encoding properties exhibited in the activation patterns.,2101.05490,cs.LG,2021-01-14 07:50:40+00:00,2021-01-14 07:50:40+00:00
8nl0k08uMi,2021,Accept (Poster),False,Selectivity considered harmful: evaluating the causal impact of class selectivity in DNNs,"[""Matthew L Leavitt"", ""Ari S. Morcos""]","[""interpretability"", ""explainability"", ""empirical analysis"", ""deep learning"", ""selectivity""]",Class selectivity in CNNs is neither sufficient nor strictly necessary for optimal test accuracy,,,,
8pz6GXZ3YT,2021,Reject,False,Why Lottery Ticket Wins? A Theoretical Perspective of Sample Complexity on Sparse Neural Networks,"[""Shuai Zhang"", ""Meng Wang"", ""Sijia Liu"", ""Pin-Yu Chen"", ""Jinjun Xiong""]","[""Sparse neural network"", ""Lottery Ticket Hypothesis"", ""network pruning"", ""generalization analysis"", ""optimization landscape"", ""sample complexity""]",This paper provides the first theoretical analysis of one-hidden-layer sparse neural networks and validates the improved test accuracy of the lottery ticket hypothesis theoretically.,2110.05667,cs.LG,2021-10-12 01:11:07+00:00,2021-10-12 01:11:07+00:00
8qDwejCuCN,2021,Accept (Poster),False,Unsupervised Representation Learning for Time Series with Temporal Neighborhood Coding,"[""Sana Tonekaboni"", ""Danny Eytan"", ""Anna Goldenberg""]",[],An unsupervised representation learning framework for high-dimensional non-stationary time series ,2106.00750,cs.LG,2021-06-01 19:53:24+00:00,2021-06-01 19:53:24+00:00
8qQ48aMXR_g,2022,Reject,False,On Locality in Graph Learning via Graph Neural Network,"['Junwei Su', 'Jiaqi Han', 'Chuan Wu']","[""Graph Neural Network"", ""Structural Behavior"", ""Learning Process""]",This paper studies the structural relation between training set and performance of GNN.,,,,
8qWazUd8Jm,2022,Reject,False,How Faithful is your Synthetic Data? Sample-level Metrics for Evaluating and Auditing Generative Models,"['Ahmed Alaa', 'Boris van Breugel', 'Evgeny Saveliev', 'Mihaela van der Schaar']",[],Developing metrics for evaluating the quality of data synthesized by generative models,,,,
8q_ca26L1fz,2021,Reject,False,Revisiting Graph Neural Networks for Link Prediction,"[""Muhan Zhang"", ""Pan Li"", ""Yinglong Xia"", ""Kai Wang"", ""Long Jin""]","[""Graph Neural Networks"", ""Link Prediction""]","We showed that simply aggregating pairwise node embeddings learned by a GNN does not lead to effective link representations, and proposed a labeling trick to address this issue.",,,,
8qsqXlyn-Lp,2021,Reject,False,Factoring out Prior Knowledge from Low-Dimensional Embeddings,"[""Edith Heiter"", ""Jonas Fischer"", ""Jilles Vreeken""]","[""embedding"", ""visualization"", ""prior"", ""tsne"", ""umap""]",We propose two methods for factoring out prior knowledge from low-dimensional embeddings of high dimensional data.,2103.01828,cs.LG,2021-03-02 16:10:36+00:00,2021-03-02 16:10:36+00:00
8rCMq0yJMG,2022,Reject,False,Source-Target Unified Knowledge Distillation for Memory-Efficient Federated Domain Adaptation on Edge Devices,"['Xiaochen Zhou', 'Yuchuan Tian', 'Xudong Wang']",[],,,,,
8rR8bIZnzMA,2022,Reject,False,Dynamic Graph Representation Learning via Graph Transformer Networks,"['Weilin Cong', 'Yanhong Wu', 'Yuandong Tian', 'Mengting Gu', 'Yinglong Xia', 'Mehrdad Mahdavi', 'Chun-cheng Jason Chen']","[""dynamic graphs"", ""graph neural networks"", ""graph representation learning"", ""transformers"", ""graph transformers""]",A transformer-based dynamic graph learning methods with spatial-temporal encoding and complementary pre-training strategies with information-theoretic analysis that shows significant gains comparing with state-of-the-art baselines.,2111.10447,cs.LG,2021-11-19 21:44:23+00:00,2021-11-19 21:44:23+00:00
8rpv8g3zfF,2022,Reject,False,Federated Learning with GAN-based Data Synthesis for Non-IID Clients,"['Zijian Li', 'Jiawei Shao', 'Yuyi Mao', 'Jessie Hui Wang', 'Jun Zhang']","[""federated learning"", ""non-IID"", ""generative model"", ""data augmentation""]","We introduce a novel federated framework, namely Synthetic Data Aided Federated Learning (SDA-FL), to resolve the non-IID issue by sharing differentially private synthetic data.",,,,
8svLJL54sj8,2022,Reject,False,Automatic prior selection for meta Bayesian optimization with a case study on tuning deep neural network optimizers,"['Zi Wang', 'George Edward Dahl', 'Kevin Swersky', 'Chansoo Lee', 'Zelda E Mariet', 'Zachary Nado', 'Justin Gilmer', 'Jasper Snoek', 'Zoubin Ghahramani']","[""Bayesian optimization"", ""Gaussian process"", ""hyperparameter tuning"", ""meta learning"", ""transfer learning"", ""multi task""]",A principled meta Bayesian optimization method and a multi-task optimizer hyperparameter tuning dataset.,,,,
8uqOMUHgW4M,2022,Reject,False,Learning shared neural manifolds from multi-subject FMRI data,"['Jessie Huang', 'Erica Lindsey Busch', 'Tom Wallenstein', 'Michal Gerasimiuk', 'Guillaume Lajoie', 'Guy Wolf', 'Nicholas Turk-Browne', 'Smita Krishnaswamy']",[],,,,,
8uz0EWPQIMu,2022,Accept (Poster),True,On the Pitfalls of Analyzing Individual Neurons in Language Models,"['Omer Antverg', 'Yonatan Belinkov']","[""NLP"", ""interpretability"", ""multilingual"", ""individual neurons""]","We analyze and compare methods to rank neurons in hidden representations according to their relevance to morphologic attributes, and show some of their weaknesses.",2110.07483,cs.CL,2021-10-14 15:57:07+00:00,2022-01-23 17:03:26+00:00
8wI4UUN5RxC,2022,Reject,False,Variational Inference via Resolution of Singularities,['Susan Wei'],"[""singular learning theory"", ""Bayesian neural networks"", ""variational inference"", ""normalizing flow""]",A variational approximation for Bayesian neural networks based on singular learning theory.,,,,
8wa7HrUsElL,2021,Reject,False,D3C: Reducing the Price of Anarchy in Multi-Agent Learning,"[""Ian Gemp"", ""Kevin McKee"", ""Richard Everett"", ""Edgar Alfredo Duenez-Guzman"", ""Yoram Bachrach"", ""David Balduzzi"", ""Andrea Tacchetti""]","[""multiagent"", ""social dilemma"", ""reinforcement learning""]","We propose a decentralized, gradient-based meta-algorithm to adapt the losses of agents in a multi-agent system such that the price of anarchy is reduced.",,,,
8wqCDnBmnrT,2021,Accept (Poster),False,Zero-shot Synthesis with Group-Supervised Learning,"[""Yunhao Ge"", ""Sami Abu-El-Haija"", ""Gan Xin"", ""Laurent Itti""]","[""Disentangled representation learning"", ""Group-supervised learning"", ""Zero-shot synthesis"", ""Knowledge factorization""]","To aid neural networks to envision objects with different attributes,  we propose GSL which allows us to decompose inputs into a disentangled representation with swappable components, that can be recombined to synthesize new samples. ",,,,
8xLkv08d70T,2021,Accept (Poster),False,Adaptive Procedural Task Generation for Hard-Exploration Problems,"[""Kuan Fang"", ""Yuke Zhu"", ""Silvio Savarese"", ""L. Fei-Fei""]","[""reinforcement learning"", ""curriculum learning"", ""procedural generation"", ""task generation""]",We propose a framework which creates tasks as curricula via procedural generation to expedite reinforcement learning in hard-exploration problems.,,,,
8xeBUgD8u9,2021,Accept (Poster),False,Continual learning in recurrent neural networks,"[""Benjamin Ehret"", ""Christian Henning"", ""Maria Cervera"", ""Alexander Meulemans"", ""Johannes Von Oswald"", ""Benjamin F Grewe""]","[""Recurrent Neural Networks"", ""Continual Learning""]",This paper studies the behavior of established approaches to the problem of continual learning in the context of recurrent neural networks.,,,,
8yKEo06dKNo,2021,Accept (Spotlight),True,How Does Mixup Help With Robustness and Generalization?,"[""Linjun Zhang"", ""Zhun Deng"", ""Kenji Kawaguchi"", ""Amirata Ghorbani"", ""James Zou""]","[""Mixup"", ""adversarial robustness"", ""generalization""]",A theoretical point of view for Mixup training,2010.04819,cs.LG,2020-10-09 21:38:14+00:00,2021-03-17 19:43:43+00:00
8znruLfUZnT,2021,Reject,False,Frequency Regularized Deep Convolutional Dictionary Learning and Application to Blind Denoising,"[""Nikola Pavle Janjusevic"", ""Amirhossein Khalilian-Gourtani"", ""Yao Wang""]","[""Dictionary learning"", ""unrolled algorithm"", ""convolutional sparse coding"", ""interpretable deep learning"", ""inverse problems"", ""blind denoising"", ""LISTA""]","We propose to construct strided, frequency-regularized, convolutional dictionaries for use in an unrolled deep-learning model, demonstrating application in blind and non-blind natural image denoising.",,,,
9-Rfew334N,2022,Accept (Poster),False,Givens Coordinate Descent Methods for Rotation Matrix Learning in Trainable Embedding Indexes,"['Yunjiang Jiang', 'Han Zhang', 'Yiming Qiu', 'Yun Xiao', 'Bo Long', 'Wen-Yun Yang']","[""Search index"", ""Product quantization"", ""Block coordinate descent""]",Learning orthonormal matrix in neural networks via Givens rotations,,,,
90JprVrJBO,2021,Accept (Poster),False,Learning a Latent Search Space for Routing Problems using Variational Autoencoders,"[""Andr\u00e9 Hottung"", ""Bhanu Bhandari"", ""Kevin Tierney""]","[""heuristic search"", ""variational autoencoders"", ""learning to optimize"", ""routing problems"", ""traveling salesperson problem"", ""vehicle routing problem"", ""combinatorial optimization""]",We use conditional variational autoencoders to learn continuous search spaces for routing problems that can be searched with any unconstrained continuous optimizer.,,,,
91muTwt1_t5,2022,Reject,False,Knowledge Guided Geometric Editing for Unsupervised Drug Design,"['Yuwei Yang', 'Siqi Ouyang', 'Meihua Dang', 'Mingyue Zheng', 'Lei Li', 'Hao Zhou']","[""drug discovery"", ""3D molecular generation"", ""monte carlo sampling""]",,,,,
92awwjGxIZI,2022,Reject,False,Self-GenomeNet: Self-supervised Learning with Reverse-Complement Context Prediction for Nucleotide-level Genomics Data,"['HÃ¼seyin Anil GÃ¼ndÃ¼z', 'Martin Binder', 'Xiao-Yin To', 'RenÃ© Mreches', 'Philipp C. MÃ¼nch', 'Alice C McHardy', 'Bernd Bischl', 'Mina Rezaei']","[""Genome Sequence Analysis"", ""Self-supervised Learning"", ""Representation Learning"", ""Application in Computational Biology""]","We introduce, Self-GenomeNet, a novel contrastive self-supervised learning method for nucleotide-level genomic data which improves the quality of the learned representations and performance.",,,,
92tYQiil17,2022,Accept (Poster),False,Learning Transferable Reward for Query Object Localization with Policy Adaptation,"['Tingfeng Li', 'Shaobo Han', 'Martin Renqiang Min', 'Dimitris N. Metaxas']",[],,,,,
93SVBUB1r5C,2022,Reject,False,Learning with convolution and pooling operations in kernel methods,"['Theodor Misiakiewicz', 'Song Mei']","[""convolutional kernels"", ""inductive bias"", ""average pooling"", ""downsampling"", ""kernel ridge regression"", ""generalization error"", ""neural tangent kernel""]","We quantify the improvement in statistical complexity of kernel methods using kernels with single-layers of convolution, pooling and downsampling operations.",2111.08308,stat.ML,2021-11-16 09:00:44+00:00,2021-11-16 09:00:44+00:00
97WDkHzofx,2022,Reject,False,Interventional Black-Box Explanations,"['Ola Ahmad', 'Simon Corbeil', 'Vahid Hashemi', 'Freddy Lecue']","[""Causal Inference"", ""Interventions"", ""black-Box Models"", ""Explanations"", ""Deep Neural Networks""]",The paper is about explaining post-hoc DNNs using causal inference,,,,
97r5Y5DrJTo,2022,Reject,False,The Effect of diversity in Meta-Learning,"['Ramnath Kumar', 'Tristan Deleu', 'Yoshua Bengio']","[""Meta-Learning"", ""Few-shot learning""]",Analysis of different task sampling schemes for meta-learning to understand the effect of task diversity in meta-learning,2201.11775,cs.LG,2022-01-27 19:39:07+00:00,2022-01-27 19:39:07+00:00
97ru13Fdmbt,2022,Reject,False,Monotonicity as a requirement and as a regularizer: efficient methods and applications,"['Joao Monteiro', 'Mohamed Osama Ahmed', 'Hossein Hajimirsadeghi', 'Greg Mori']","[""Monotonic neural networks"", ""Gradient penalties"", ""Structural risk minimization""]",We introduce efficient approaches that render neural networks monotonic with respect to a subset of the input dimensions.,,,,
98fWAc-sFkv,2021,Reject,False,A Unified Bayesian Framework for Discriminative and Generative Continual Learning,"[""Abhishek Kumar"", ""Sunabha Chatterjee"", ""Piyush Rai""]","[""continual learning"", ""bayesian learning""]","A Bayesian approach for continual learning under supervised as well as unsupervised setting, with the flexibility to adapt the model complexity as more and more tasks arrive.",,,,
98ntbCuqf4i,2021,Reject,False,MQES: Max-Q Entropy Search for Efficient Exploration in Continuous Reinforcement Learning,"[""Jinyi Liu"", ""Zhi Wang"", ""Jianye HAO"", ""YAN ZHENG""]",[],,,,,
99M-4QlinPr,2021,Reject,False,Efficient Competitive Self-Play Policy Optimization,"[""Yuanyi Zhong"", ""Yuan Zhou"", ""Jian Peng""]","[""self-play"", ""policy optimization"", ""two-player zero-sum game"", ""multiagent""]",We present a population-based self-play policy optimization algorithm with a principled opponent-selection rule.,,,,
9BIN1yr5Gp,2022,Reject,True,Parallel Deep Neural Networks Have Zero Duality Gap,"['Yifei Wang', 'Tolga Ergen', 'Mert Pilanci']","[""Deep neural networks"", ""convex duality"", ""convex optimization""]",,2110.06482,cs.LG,2021-10-13 04:03:51+00:00,2021-10-13 04:03:51+00:00
9CG8RW_p3Y,2021,Reject,False,Fundamental Limits and Tradeoffs in Invariant Representation Learning,"[""Han Zhao"", ""Chen Dan"", ""Bryon Aragam"", ""Tommi S. Jaakkola"", ""Geoff Gordon"", ""Pradeep Kumar Ravikumar""]","[""Representation learning""]",We provide an information-theoretic analysis of the tradeoff problem between accuracy and invariance under both classification and regression settings.,,,,
9Cwxjd6nRh,2022,Reject,False,High Fidelity Visualization of What Your Self-Supervised Representation Knows About,"['Florian Bordes', 'Randall Balestriero', 'Pascal Vincent']","[""self-supervised learning"", ""visualization"", ""diffusion model"", ""conditional generative model"", ""representation""]",We introduce a high fidelity visualization method to get insights about what information is contained in self-supervised representations. ,2112.09164,cs.LG,2021-12-16 19:23:33+00:00,2021-12-16 19:23:33+00:00
9DQ0SdY4UIz,2021,Reject,False,Effective Subspace Indexing via Interpolation on Stiefel and Grassmann manifolds,"[""Wenqing Hu"", ""Tiefeng Jiang"", ""Zhu Li""]","[""subspace indexing"", ""locality preserving projection"", ""Stiefel and Grassmann manifolds""]","We propose Subspace Indexing Model with Interpolation that uses ""center-of-mass"" calculation on Stiefel and Grassmann manifolds",,,,
9D_Ovq4Mgho,2021,Reject,False,Network-Agnostic Knowledge Transfer for Medical Image Segmentation,"[""Shuhang Wang"", ""Eugene Cheah"", ""Elham Yousef Kalafi"", ""Mercy Asiedu"", ""Alex Benjamin"", ""Vivek Kumar Singh"", ""Ge Zhang"", ""Viksit Kumar"", ""Anthony Edward Samir""]","[""Knowledge Transfer"", ""Deep Learning"", ""Medical Image Segmentation"", ""Pseudo Annotation""]",We propose to transfer the knowledge of a neural network (teacher) to another independent one (student) by training the student on a transferal dataset whose annotations are generated by the teacher.,,,,
9EKHN1jOlA,2021,Accept (Poster),False,Uncertainty Estimation and Calibration with Finite-State Probabilistic RNNs,"[""Cheng Wang"", ""Carolin Lawrence"", ""Mathias Niepert""]","[""uncertainty estimation"", ""calibration"", ""RNN""]",A method to estimate and calibrate uncertainty in recurrent state transitions.,2011.12010,cs.LG,2020-11-24 10:35:28+00:00,2020-11-24 10:35:28+00:00
9EsrXMzlFQY,2021,Accept (Spotlight),False,Async-RED: A Provably Convergent Asynchronous Block Parallel Stochastic Method using Deep Denoising Priors,"[""Yu Sun"", ""Jiaming Liu"", ""Yiran Sun"", ""Brendt Wohlberg"", ""Ulugbek Kamilov""]","[""Regularization by denoising"", ""Computational imaging"", ""asynchronous parallel algorithm"", ""Deep denoising priors""]",Our work develops a novel deep-regularized asynchronous parallel method with provable convergence guarantees for solving large-scale inverse problems.,,,,
9FWas6YbmB3,2021,Accept (Poster),False,DrNAS: Dirichlet Neural Architecture Search,"[""Xiangning Chen"", ""Ruochen Wang"", ""Minhao Cheng"", ""Xiaocheng Tang"", ""Cho-Jui Hsieh""]",[],,,,,
9FfAEgUYGON,2022,Reject,True,Mismatched No More: Joint Model-Policy Optimization for Model-Based RL,"['Benjamin Eysenbach', 'Alexander Khazatsky', 'Sergey Levine', 'Ruslan Salakhutdinov']","[""reinforcement learning"", ""model-based RL"", ""joint optimization""]","An algorithm for model-based RL where the model and policy optimize the same objective, which is a (global) lower bound on expected rewards.",2110.02758,cs.LG,2021-10-06 13:43:27+00:00,2021-10-06 13:43:27+00:00
9G5MIc-goqB,2021,Accept (Poster),False,Reweighting Augmented Samples by Minimizing the Maximal Expected Loss,"[""Mingyang Yi"", ""Lu Hou"", ""Lifeng Shang"", ""Xin Jiang"", ""Qun Liu"", ""Zhi-Ming Ma""]","[""data augmentation"", ""sample reweighting""]",a new reweighting strategy on augmented samples,2103.08933,cs.LG,2021-03-16 09:31:04+00:00,2021-03-16 09:31:04+00:00
9GBZBPn0Jx,2021,Accept (Poster),False,HalentNet: Multimodal Trajectory Forecasting with Hallucinative Intents,"[""Deyao Zhu"", ""Mohamed Zahran"", ""Li Erran Li"", ""Mohamed Elhoseiny""]",[],,,,,
9GUTgHZgKCH,2021,Reject,False,Reducing the number of neurons of Deep ReLU Networks based on the current theory of Regularization,"[""Jakob Heiss"", ""Alexis Stockinger"", ""Josef Teichmann""]","[""Reduction"", ""Compression"", ""Regularization"", ""Theory"", ""Pruning"", ""Deep"", ""Interpretability"", ""Generalization""]",An algorithm which reduces the number of neurons in a Deep ReLU Network and allows several important benefits is presented.,,,,
9GsFOUyUPi,2021,Accept (Poster),False,Progressive Skeletonization: Trimming more fat from a network at initialization,"[""Pau de Jorge"", ""Amartya Sanyal"", ""Harkirat Behl"", ""Philip Torr"", ""Gr\u00e9gory Rogez"", ""Puneet K. Dokania""]","[""Pruning"", ""Pruning at initialization"", ""Sparsity""]","We find performance of current methods for pruning at initialization plummets at high sparsity levels, we study the possible reasons and present a more robust method overall.",,,,
9HXfisrWl1,2022,Reject,False,"DeepDebug: Fixing Python Bugs Using Stack Traces, Backtranslation, and Code Skeletons","['Dawn Drain', 'Colin Clement', 'Guillermo Serrato Castilla', 'Neel Sundaresan']","[""program repair"", ""bugpatching"", ""backtranslation"", ""transformers""]","Creates a large-scale dataset of executable tests along with synthetic bugs, which allows for training with stack traces",,,,
9Hrka5PA7LW,2022,Accept (Oral),False,Rethinking the Representational Continuity: Towards Unsupervised Continual Learning,"['Divyam Madaan', 'Jaehong Yoon', 'Yuanchun Li', 'Yunxin Liu', 'Sung Ju Hwang']","[""Continual Learning"", ""Representational Learning"", ""Deep Learning""]",We attempt to bridge the gap between continual learning & representation learning and show that unsupervised continual learning achieves better performance and learns perceptual features with a smoother loss landscape than SCL.,,,,
9ITXiTrAoT,2021,Accept (Poster),False,Multi-timescale Representation Learning in LSTM Language Models,"[""Shivangi Mahto"", ""Vy Ai Vo"", ""Javier S. Turek"", ""Alexander Huth""]","[""Language Model"", ""LSTM"", ""timescales""]",This work presents a theoretically-motivated analysis of memory and timescale in LSTM language models.,,,,
9L1BsI4wP1H,2022,Accept (Poster),False,Adversarially Robust Conformal Prediction,"['Asaf Gendler', 'Tsui-Wei Weng', 'Luca Daniel', 'Yaniv Romano']","[""Conformal Prediction"", ""Adversarial Robustness"", ""Randomized Smoothing"", ""Uncertainty Estimation"", ""Calibration""]",Multi-class calibration procedure that is provably robust to adversarial attacks,,,,
9MdLwggYa02,2021,Reject,False,ROMUL: Scale Adaptative Population Based Training,"[""Daniel HAZIZA"", ""J\u00e9r\u00e9my Rapin"", ""Gabriel Synnaeve""]","[""hyperparameter search"", ""population based training"", ""differential evolution"", ""hyperparameter optimization"", ""online optimization"", ""deep learning""]",We benchmark several PBT algorithms and propose a new one that shows to be robust across domains.,,,,
9NVd-DMtThY,2022,Accept (Poster),False,Distributionally Robust Fair Principal Components via Geodesic Descents,"['Hieu Vu', 'Toan Tran', 'Man-Chung Yue', 'Viet Anh Nguyen']","[""fair principal component analysis"", ""distributionally robust optimization"", ""manifold optimization""]",,2202.03071,cs.LG,2022-02-07 11:08:13+00:00,2022-02-07 11:08:13+00:00
9Nk6AJkVYB,2022,Accept (Poster),False,"Audio Lottery: Speech Recognition Made Ultra-Lightweight, Noise-Robust, and Transferable","['Shaojin Ding', 'Tianlong Chen', 'Zhangyang Wang']","[""Speech Recognition"", ""Lottery Ticket Hypothesis""]","We for the first time investigate three unique properties that were rarely studied in previous LTH research but are key to user-interactive ASR devices, bringing new insights to both LTH theory and lightweight ASR research.",,,,
9OHFhefeB86,2021,Accept (Spotlight),True,Graph Convolution with Low-rank Learnable Local Filters,"[""Xiuyuan Cheng"", ""Zichen Miao"", ""Qiang Qiu""]",[],Graph convolution model for landmark data with local graph regularization and provable graph signal representation expressiveness and stability.,2008.01818,stat.ML,2020-08-04 20:34:59+00:00,2020-10-11 17:07:57+00:00
9QLRCVysdlO,2021,Accept (Poster),False,BiPointNet: Binary Neural Network for Point Clouds,"[""Haotong Qin"", ""Zhongang Cai"", ""Mingyuan Zhang"", ""Yifu Ding"", ""Haiyu Zhao"", ""Shuai Yi"", ""Xianglong Liu"", ""Hao Su""]","[""point clouds"", ""efficient deep learning"", ""binary neural networks""]","We present BiPointNet, the first model binarization approach to efficient deep learning on point clouds, targeting at extreme compression and acceleration.",,,,
9RUHPlladgh,2022,Accept (Poster),False,Visual Representation Learning Does Not Generalize Strongly Within the Same Domain,"['Lukas Schott', 'Julius Von KÃ¼gelgen', 'Frederik TrÃ¤uble', 'Peter Vincent Gehler', 'Chris Russell', 'Matthias Bethge', 'Bernhard SchÃ¶lkopf', 'Francesco Locatello', 'Wieland Brendel']","[""Generalization"", ""Composition"", ""Out of distribution"", ""Disentanglement""]",We study and benchmark the inductive biases for generalization in visual representation learning on systematic out-of-distribution settings. ,,,,
9SDQB3b68K,2022,Accept (Poster),False,DARA: Dynamics-Aware Reward Augmentation in Offline Reinforcement Learning,"['Jinxin Liu', 'Zhang Hongyin', 'Donglin Wang']",[],,,,,
9SS69KwomAM,2021,Accept (Poster),False,Solving Compositional Reinforcement Learning Problems via Task Reduction,"[""Yunfei Li"", ""Yilin Wu"", ""Huazhe Xu"", ""Xiaolong Wang"", ""Yi Wu""]","[""compositional task"", ""sparse reward"", ""reinforcement learning"", ""task reduction"", ""imitation learning""]",We propose a deep RL algorithm for learning compositional strategies to solve sparse-reward continuous-control problems.,2103.07607,cs.LG,2021-03-13 03:26:33+00:00,2021-03-19 01:44:03+00:00
9TdCcMlmsLm,2022,Reject,False,Text Generation with Efficient (Soft) $Q$-Learning,"['Han Guo', 'Bowen Tan', 'Zhengzhong Liu', 'Eric Xing', 'Zhiting Hu']","[""text generation"", ""reinforcement learning for text generation""]","We introduce a new RL formulation for text generation from the soft $Q$-learning perspective, and apply the approach to a wide range of tasks.",,,,
9UFIOHeVEh,2021,Reject,False,Identifying the Sources of Uncertainty in Object Classification,"[""Luis Armando P\u00e9rez Rey"", ""Berk \u0130\u015fler"", ""Mike Holenderski"", ""Dmitri Jarnikov""]","[""Classification"", ""Interpretability"", ""Disentangled Representations"", ""Uncertainty Estimation""]",In this work we propose a method for the identification of the external factors that affect the confidence of predictions in image-based object classification via the use of disentangled representations.,,,,
9Vimsa_gGG5,2022,Reject,False,Initializing ReLU networks in an expressive subspace of weights,"['Dayal Singh', 'G J Sreejith']","[""Signal propagation"", ""deep ReLU networks"", ""mean-field theory"", ""improved initialization""]",ReLU networks initialized with asymmetric anti-correlated weights learn faster.,,,,
9Vrb9D0WI4,2022,Accept (Spotlight),False,Multitask Prompted Training Enables Zero-Shot Task Generalization,"['Victor Sanh', 'Albert Webson', 'Colin Raffel', 'Stephen Bach', 'Lintang Sutawika', 'Zaid Alyafeai', 'Antoine Chaffin', 'Arnaud Stiegler', 'Arun Raja', 'Manan Dey', 'M Saiful Bari', 'Canwen Xu', 'Urmish Thakker', 'Shanya Sharma Sharma', 'Eliza Szczechla', 'Taewoon Kim', 'Gunjan Chhablani', 'Nihal Nayak', 'Debajyoti Datta', 'Jonathan Chang', 'Mike Tian-Jian Jiang', 'Han Wang', 'Matteo Manica', 'Sheng Shen', 'Zheng Xin Yong', 'Harshit Pandey', 'Rachel Bawden', 'Thomas Wang', 'Trishala Neeraj', 'Jos Rozen', 'Abheesht Sharma', 'Andrea Santilli', 'Thibault Fevry', 'Jason Alan Fries', 'Ryan Teehan', 'Teven Le Scao', 'Stella Biderman', 'Leo Gao', 'Thomas Wolf', 'Alexander M Rush']",[],,,,,
9W2KnHqm_xN,2022,Reject,False,Successive POI Recommendation via Brain-inspired Spatiotemporal Aware Representation,"['Gehua Ma', 'Jingyuan Zhao', 'Huajin Tang']","[""Neuroscience"", ""spatiotemporal aware modeling"", ""successive POI recommendation""]",,,,,
9WlOIHve8dU,2021,Reject,False,Learning Binary Trees via Sparse Relaxation,"[""Valentina Zantedeschi"", ""Matt Kusner"", ""Vlad Niculae""]","[""optimization"", ""binary trees""]",We present a new sparse differentiable relaxation of mixed-integer programming methods for tree learning.,,,,
9XhPLAjjRB,2022,Accept (Spotlight),False,SGD Can Converge to Local Maxima,"['Liu Ziyin', 'Botao Li', 'James B Simon', 'Masahito Ueda']","[""stochastic gradient descent"", ""saddle points"", ""convergence"", ""amsgrad"", ""deep learning""]",We show that it can be common for SGD to converge to saddle points and maxima.,,,,
9Y7_c5ZAd5i,2021,Reject,False,A Sharp Analysis of Model-based Reinforcement Learning with Self-Play,"[""Qinghua Liu"", ""Tiancheng Yu"", ""Yu Bai"", ""Chi Jin""]","[""Reinforcement learning theory"", ""Markov games"", ""model-based RL"", ""task-agnostic RL"", ""multi-agent RL""]",We design a new model-based algorithm for Markov games that achieves nearly optimal regret bound and PAC sample complexity.,,,,
9YlaeLfuhJF,2021,Accept (Poster),False,Model Patching: Closing the Subgroup Performance Gap with Data Augmentation,"[""Karan Goel"", ""Albert Gu"", ""Yixuan Li"", ""Christopher Re""]","[""Robust Machine Learning"", ""Data Augmentation"", ""Consistency Training"", ""Invariant Representations""]",We describe how to fix classifiers that fail on subgroups of a class using a combination of learned data augmentation & consistency training to achieve subgroup invariance.,,,,
9ZPegFuFTFv,2022,Accept (Poster),True,miniF2F: a cross-system benchmark for formal Olympiad-level mathematics,"['Kunhao Zheng', 'Jesse Michael Han', 'Stanislas Polu']","[""Neural theorem proving"", ""Benchmark dataset""]",,2109.00110,cs.AI,2021-08-31 23:21:12+00:00,2021-08-31 23:21:12+00:00
9_J4DrgC_db,2021,Reject,False,Deep Coherent Exploration For Continuous Control,"[""Yijie Zhang"", ""Herke van Hoof""]","[""reinforcement learning"", ""exploration"", ""latent variable models""]",,,,,
9az9VKjOx00,2021,Reject,False,TopoTER: Unsupervised Learning of Topology Transformation Equivariant Representations,"[""Xiang Gao"", ""Wei Hu"", ""Guo-Jun Qi""]","[""Unsupervised learning"", ""node representations"", ""mutual information""]",,2105.11689,cs.LG,2021-05-25 06:11:03+00:00,2021-05-25 06:11:03+00:00
9dn7CjyTFoS,2022,Reject,True,"One Thing to Fool them All: Generating Interpretable, Universal, and Physically-Realizable Adversarial Features","['Stephen Casper', 'Max Nadeau', 'Gabriel Kreiman']","[""adversaries"", ""interpretablity"", ""generative modeling""]",Using generative models to create interpretable and versatile adversarial features. ,2110.03605,cs.LG,2021-10-07 16:33:11+00:00,2022-01-28 18:04:56+00:00
9gz8qakpyhG,2022,Reject,False,Test-time Batch Statistics Calibration for Covariate Shift,"['fuming you', 'Jingjing Li', 'Zhou Zhao']",[],,,,,
9hgEG-k57Zj,2021,Reject,False,Addressing Distribution Shift in Online Reinforcement Learning with Offline Datasets,"[""Seunghyun Lee"", ""Younggyo Seo"", ""Kimin Lee"", ""Pieter Abbeel"", ""Jinwoo Shin""]","[""reinforcement learning"", ""offline reinforcement learning"", ""control"", ""distribution shift""]","We present a simple framework, BRED, that incorporates a balanced replay scheme and an ensemble distillation scheme, for fine-tuning an offline RL agent more efficiently. ",,,,
9jInD9JjicF,2022,Accept (Poster),True,PoNet: Pooling Network for Efficient Token Mixing in Long Sequences,"['Chao-Hong Tan', 'Qian Chen', 'Wen Wang', 'Qinglin Zhang', 'Siqi Zheng', 'Zhen-Hua Ling']","[""Transformer"", ""Efficient Transformers"", ""Token Mixing"", ""Pooling"", ""Linear"", ""Long Range Arena"", ""Transfer Learning"", ""BERT"", ""GLUE""]","We propose a novel Pooling Network for token mixing with linear complexity, achieve competitive performance on the Long Range Arena benchmark, and 95.7% of the accuracy of BERT on the GLUE demonstrating its transferability.",2110.02442,cs.CL,2021-10-06 01:07:54+00:00,2021-10-07 04:49:37+00:00
9jsZiUgkCZP,2022,Accept (Poster),False,Unified Visual Transformer Compression,"['Shixing Yu', 'Tianlong Chen', 'Jiayi Shen', 'Huan Yuan', 'Jianchao Tan', 'Sen Yang', 'Ji Liu', 'Zhangyang Wang']","[""Vision Transformer"", ""Model Compression"", ""Pruning"", ""Layer Skipping"", ""Distillation""]"," This paper proposes a unified ViT compression framework that seamlessly assembles three effective techniques: pruning, layer skipping, and knowledge distillation, which outperforms existing competitors. ",,,,
9kBDWEmA6i,2022,Reject,False,When high-performing models behave poorly in practice: periodic sampling can help,"['Stanislas Chambon', 'Julien GUILLAUMIN', 'Luis Montero', 'Yaroslav Nikulin', 'Paul Wambergue', 'Pierre Fillard']","[""Periodic sampling"", ""deep learning"", ""computer vision"", ""mammography""]",,,,,
9kpuB2bgnim,2022,Accept (Poster),False,Huber Additive Models for Non-stationary Time Series Analysis,"['Yingjie Wang', 'Xianrui Zhong', 'Fengxiang He', 'Hong Chen', 'Dacheng Tao']","[""Sparse additive models"", ""variable selection"", ""Huber"", ""non-stationary"", ""robust forecasting""]",An adaptive sparse Huber additive model for robust forecasting and  variable selection in  non-Gaussian  and (non)stationary time series data ,,,,
9l0K4OM-oXE,2021,Accept (Poster),False,Neural Attention Distillation: Erasing Backdoor Triggers from Deep Neural Networks,"[""Yige Li"", ""Xixiang Lyu"", ""Nodens Koren"", ""Lingjuan Lyu"", ""Bo Li"", ""Xingjun Ma""]","[""Backdoor Defense"", ""Deep Neural Networks"", ""Neural Attention Distillation""]",A simple but effective nerual attention distillation method for backdoor defense.,2101.05930,cs.LG,2021-01-15 01:35:22+00:00,2021-01-27 06:23:25+00:00
9l9WD4ahJgs,2021,Reject,False,Automatic Data Augmentation for Generalization in Reinforcement Learning,"[""Roberta Raileanu"", ""Maxwell Goldstein"", ""Denis Yarats"", ""Ilya Kostrikov"", ""Rob Fergus""]","[""reinforcement learning"", ""generalization"", ""data augmentation""]","We propose an approach for automatically finding an augmentation, which is used to regularize the policy and value function in order to improve generalization in reinforcement learning.",,,,
9n9c8sf0xm,2022,Accept (Poster),False,Plant 'n' Seek: Can You Find the Winning Ticket?,"['Jonas Fischer', 'Rebekka Burkholz']","[""lottery tickets"", ""ground truth"", ""planting"", ""LTH""]",We derive a framework to plant ground truth lottery tickets in randomly initialized deep neural networks.,,,,
9nIulvlci5,2021,Reject,True,Neural Random Projection: From the Initial Task To the Input Similarity Problem,"[""Alan Savushkin"", ""Nikita Benkovich"", ""Dmitry Golubev""]",[],A neural network from the Random Projection perspective,2010.04555,cs.LG,2020-10-09 13:20:24+00:00,2020-10-09 13:20:24+00:00
9otKVlgrpZG,2022,Accept (Poster),False,Multi-Task Processes,"['Donggyun Kim', 'Seongwoong Cho', 'Wonkwang Lee', 'Seunghoon Hong']","[""stochastic processes"", ""neural processes"", ""multi-task learning"", ""incomplete data""]","We propose a new family of stochastic processes that can infer multiple heterogeneous functions jointly given a few incomplete observations (i.e., some functions may not be observed at each input).",,,,
9p2CltauWEY,2021,Reject,True,On Size Generalization in Graph Neural Networks,"[""Gilad Yehudai"", ""Ethan Fetaya"", ""Eli Meirom"", ""Gal Chechik"", ""Haggai Maron""]","[""graph neural networks"", ""gnn"", ""generalization"", ""Weisfeiler-Lehman""]","Graph neural networks can process graphs of any size, yet their capacity to generalize across sizes is unclear. We study the problem of size generalization both empirically and theoretically.",2010.08853,cs.LG,2020-10-17 19:36:54+00:00,2021-07-15 19:18:06+00:00
9p2ekP904Rs,2021,Accept (Poster),False,Representation Learning via Invariant Causal Mechanisms,"[""Jovana Mitrovic"", ""Brian McWilliams"", ""Jacob C Walker"", ""Lars Holger Buesing"", ""Charles Blundell""]","[""Representation Learning"", ""Self-supervised Learning"", ""Contrastive Methods"", ""Causality""]",We propose a new self-supervised objective with an explicit invariance regularizer and provide an alternative explanation for the success of contrastive learning using causality; we outperform competing methods on ImageNet and Atari. ,,,,
9pEJSVfDbba,2022,Accept (Poster),True,Embedded-model flows: Combining the inductive biases of model-free deep learning and explicit probabilistic modeling,"['Gianluigi Silvestri', 'Emily Fertig', 'Dave Moore', 'Luca Ambrogioni']","[""Normalizing Flows"", ""Probabilistic model"", ""Probabilistic programming"", ""Generative modeling"", ""Variational Inference""]",We introduce bijective transformations that embed domain-specific inductive biases in Normalizing Flow architectures.,2110.06021,stat.ML,2021-10-12 14:12:16+00:00,2021-10-17 14:58:25+00:00
9q3g_5gQbbA,2022,Reject,False,Towards Understanding Data Values: Empirical Results on Synthetic Data,"['Danilo Brajovic', 'Omar De Mitri', 'Alex Windberger', 'Marco Huber']",[],,,,,
9qKAGxS1Tq2,2022,Reject,False,From SCAN to Real Data: Systematic Generalization via Meaningful Learning,"['Ning Shi', 'Boxin Wang', 'Wei Wang', 'Xiangyu Liu', 'Rong Zhang', ""Hui Xue'"", 'Xinbing Wang', 'Zhouhan Lin']","[""systematic generalization"", ""meaningful learning"", ""inductive learning"", ""deductive learning"", ""data augmentation""]",Modern sequence-to-sequence models can achieve systematic generalization by meaningful learning through either inductively or deductively established semantic linking.,,,,
9r30XCjf5Dt,2021,Accept (Poster),True,Vulnerability-Aware Poisoning Mechanism for Online RL with Unknown Dynamics,"[""Yanchao Sun"", ""Da Huo"", ""Furong Huang""]","[""poisoning attack"", ""policy gradient"", ""vulnerability of RL"", ""deep RL""]","We propose the first poisoning algorithm against deep policy-based RL methods, without any prior knowledge of the environment, covering heterogeneous poisoning models.",2009.00774,cs.LG,2020-09-02 01:43:30+00:00,2021-05-04 16:09:16+00:00
9rKTy4oZAQt,2022,Reject,False,A Risk-Sensitive Policy Gradient Method,"['Jared Markowitz', 'Ryan Gardner', 'Ashley Llorens', 'Raman Arora', 'I-Jeng Wang']","[""deep reinforcement learning"", ""policy gradient"", ""risk-sensitive"", ""ai safety""]","We derive an expression for the policy gradient of a broad class of risk-sensitive objectives, leading to a practical learning algorithm that can be used to tune agent risk profiles and produces strong performance.",,,,
9sF3n8eAco,2021,Reject,False,All-You-Can-Fit 8-Bit Flexible Floating-Point Format for Accurate and Memory-Efficient Inference of Deep Neural Networks,"[""Juinn-Dar Huang"", ""Cheng-Wei Huang"", ""Tim-Wei Chen""]","[""8-bit floating-point format"", ""accuracy loss minimization"", ""numerics"", ""memory-efficient inference"", ""deep learning""]","An extremely flexible 8-bit floating-point format, where all parameters (bit width of sign/exponent/fraction field and exponent bias) are configurable, is proposed to achieve more accurate inference even without the need of model retraining.",,,,
9t0CV2iD5gE,2021,Reject,False,Robust Learning Rate Selection for Stochastic Optimization via Splitting Diagnostic,"[""Matteo Sordello"", ""Hangfeng He"", ""Weijie J Su""]","[""Optimization"", ""Deep Learning"", ""Stationarity"", ""Adaptive""]",A method to detect stationarity in stochastic optimization to adaptively reduce the learning rate.,,,,
9u5E8AFudRx,2022,Reject,False,Help Me Explore: Minimal Social Interventions for Graph-Based Autotelic Agents,"['Ahmed Akakzia', 'Olivier Serris', 'Olivier Sigaud', 'CÃ©dric Colas']","[""Deep reinforcement learning"", ""intrinsic motivations"", ""autonomous learning"", ""social learning""]",We propose an autotelic agent that discovers and masters thousands of semantic goal configurations and a social interaction protocol where a social partner drives the agent towards its zone of proximal development.,2202.05129,cs.AI,2022-02-10 16:34:28+00:00,2022-02-10 16:34:28+00:00
9uvhpyQwzM_,2021,Accept (Poster),False,Evaluation of Similarity-based Explanations,"[""Kazuaki Hanawa"", ""Sho Yokoi"", ""Satoshi Hara"", ""Kentaro Inui""]","[""Interpretability"", ""Explainability""]","We investigated empirically which of the relevance metrics (e.g. similarity of hidden layer, influence function, etc.) are appropriate for similarity-based explanation.",,,,
9vCLOXwprc,2021,Reject,False,Iterated graph neural network system,"[""Hanju Li""]",[],,,,,
9vsRT9mc7U,2022,Reject,False,Generative Adversarial Training for Neural Combinatorial Optimization Models,"['Liang Xin', 'Wen Song', 'Zhiguang Cao', 'Jie Zhang']","[""Deep Learning"", ""Combinatorial Optimization Problem""]",We propose a general framework to improve the generalization performance of Neural Combinatorial Optimization Models.,,,,
9w03rTs7w5,2021,Reject,False,Transfer among Agents: An Efficient Multiagent Transfer Learning Framework,"[""Tianpei Yang"", ""Jianye HAO"", ""Weixun Wang"", ""Hongyao Tang"", ""Zhaopeng Meng"", ""Hangyu Mao"", ""Dong Li"", ""Wulong Liu"", ""Yujing Hu"", ""Yingfeng Chen"", ""Changjie Fan""]","[""Multiagent learning"", ""transfer learning"", ""reinforcement learning""]",A novel multiagent option-based transfer learning (MAOPT) framework is proposed to improve multiagent learning efficiency. ,,,,
9wHe4F-lpp,2021,Reject,True,FTBNN: Rethinking Non-linearity for 1-bit CNNs and Going Beyond,"[""Zhuo Su"", ""Linpu Fang"", ""Deke Guo"", ""Dewen Hu"", ""Matti Pietik\u00e4inen"", ""Li Liu""]","[""Binary neural networks"", ""network quantization"", ""network compression""]","We proposed a highly efficient and effective binary neural network by introduing proper non-linearities, and further enhanced that with binary purification and group execution.",2010.09294,cs.CV,2020-10-19 08:11:48+00:00,2020-12-30 09:48:00+00:00
9wOQOgNe-w,2022,Accept (Poster),False,Differentiable DAG Sampling,"['Bertrand Charpentier', 'Simon Kibler', 'Stephan GÃ¼nnemann']","[""DAG"", ""Differentiable"", ""Sampling"", ""Probabilistic model""]",,,,,
9xC2tWEwBD,2021,Accept (Spotlight),False,"A Panda? No, It's a Sloth: Slowdown Attacks on Adaptive Multi-Exit Neural Network Inference","[""Sanghyun Hong"", ""Yigitcan Kaya"", ""Ionu\u021b-Vlad Modoranu"", ""Tudor Dumitras""]","[""Slowdown attacks"", ""efficient inference"", ""input-adaptive multi-exit neural networks"", ""adversarial examples""]",Is the computational savings provided by the input-adaptive 'multi-exit architectures' robust against adversarial perturbations? No.,,,,
9xhgmsNVHu,2022,Accept (Poster),False,Is High Variance Unavoidable in RL? A Case Study in Continuous Control,"['Johan Bjorck', 'Carla P Gomes', 'Kilian Q Weinberger']","[""reinforcement learning"", ""continuous control""]",we study sources of variance in RL and propose methods to decrease it.,,,,
9y4qOAIfA9r,2021,Reject,False,Does injecting linguistic structure into language models lead to better alignment with brain recordings?,"[""Mostafa Abdou"", ""Ana Valeria Gonz\u00e1lez"", ""Mariya K Toneva"", ""Daniel Hershcovich"", ""Anders S\u00f8gaard""]","[""neurolinguistics"", ""natural language processing"", ""computational neuroscience""]",,,,,
9z_dNsC4B5t,2021,Accept (Poster),False,MetaNorm: Learning to Normalize Few-Shot Batches Across Domains,"[""Yingjun Du"", ""Xiantong Zhen"", ""Ling Shao"", ""Cees G. M. Snoek""]","[""Meta-learning"", ""batch normalization"", ""few-shot domain generalization""]","We propose MetaNorm, a simple yet effective meta-learning normalization approach that learns adaptive statistics for few-shot classification and domain generalization",,,,
9zcjXdavnX,2022,Reject,False,Sampling from Discrete Energy-Based Models with Quality/Efficiency Trade-offs,"['Bryan Eikema', 'GermÃ¡n Kruszewski', 'Hady Elsahar', 'Marc Dymetman']","[""Monte Carlo"", ""sampling"", ""rejection sampling"", ""Energy-Based Models"", ""EBMs"", ""controlled text generation"", ""language models""]",We propose an extension of rejection sampling with explicit convergence diagnostics that allows to trade-off efficiency for quality.,2112.05702,cs.LG,2021-12-10 17:51:37+00:00,2021-12-10 17:51:37+00:00
A-Sp6CR9-AA,2021,Reject,False,Sandwich Batch Normalization,"[""Xinyu Gong"", ""Wuyang Chen"", ""Tianlong Chen"", ""Zhangyang Wang""]","[""normalization""]","We present Sandwich Batch Normalization, a plug-and-play module which is able to boost network performance on several tasks, including neural architecture search, conditional image generation, adversarial robustness and neural style transfer.",2102.11382,cs.CV,2021-02-22 22:09:43+00:00,2021-10-14 18:41:12+00:00
A05I5IvrdL-,2022,Accept (Poster),False,The Geometry of Memoryless Stochastic Policy Optimization in Infinite-Horizon POMDPs,"['Johannes MÃ¼ller', 'Guido Montufar']","[""POMDPs"", ""Memoryless Policies"", ""Critical points"", ""State-action frequencies"", ""Algebraic degree""]",We provide an explicit description of the optimization problem and derive bounds on the number of critical points in POMDPs with memoryless stochastic policies depending on the degree of observability.,,,,
A2gNouoXE7,2021,Accept (Poster),True,Filtered Inner Product Projection for Crosslingual Embedding Alignment,"[""Vin Sachidananda"", ""Ziyi Yang"", ""Chenguang Zhu""]","[""multilingual representations"", ""word embeddings"", ""natural language processing""]",,2006.03652,cs.CL,2020-06-05 19:53:30+00:00,2021-03-23 22:00:24+00:00
A3HHaEdqAJL,2022,Accept (Spotlight),False,Task Relatedness-Based Generalization Bounds for Meta Learning,"['Jiechao Guan', 'Zhiwu Lu']",[],,,,,
A4-dkBuXbA,2022,Reject,False,Deep convolutional recurrent neural network for short-interval EEG motor imagery classification,"['Ahmed Bahaa Selim', 'Ian van der Linde']","[""Attention"", ""Brain-Computer Interface (BCI)"", ""Electroencephalography (EEG)"", ""Convolutional Neural Networks (CNN)"", ""Motor Imagery (MI)"", ""Recurrent Neural Networks (RNN)"", ""grad-CAM""]",Development of a novel EEG-based motor-imagery classifier with state-of-the art performance for use in real-time brain computer interfaces (BCIs),,,,
A5VV3UyIQz,2021,Accept (Poster),False,Explainable Deep One-Class Classification,"[""Philipp Liznerski"", ""Lukas Ruff"", ""Robert A. Vandermeulen"", ""Billy Joe Franks"", ""Marius Kloft"", ""Klaus Robert Muller""]","[""anomaly-detection"", ""deep-learning"", ""explanations"", ""interpretability"", ""xai"", ""one-class-classification"", ""deep-anomaly-detection"", ""novelty-detection"", ""outlier-detection""]",We introduce an approach to explainable deep anomaly detection based on fully convolutional neural networks. ,,,,
A7-rYAC-np1,2021,Reject,False,Syntactic representations in the human brain: beyond effort-based metrics,"[""Aniketh Janardhan Reddy"", ""Leila Wehbe""]","[""neuroscience"", ""fMRI"", ""syntactic representations"", ""graph embeddings""]",Designing explicit syntactic representations to study syntactic processing in the human brain.,,,,
A993YzEUKB7,2021,Reject,False,Extrapolatable Relational Reasoning With Comparators in Low-Dimensional Manifolds,"[""Duo Wang"", ""Mateja Jamnik"", ""Pietro Li\u00f2""]","[""Visual Reasoning"", ""Relational Reasoning"", ""Generalisation""]",A novel neural module that improves neural network architecture's generalisation for relational reasoning tasks.,,,,
AAJLBoGt0XM,2022,Accept (Poster),False,Conditional Contrastive Learning with Kernel,"['Yao-Hung Hubert Tsai', 'Tianqin Li', 'Martin Q. Ma', 'Han Zhao', 'Kun Zhang', 'Louis-Philippe Morency', 'Ruslan Salakhutdinov']","[""Contrastive Learning"", ""Conditional Sampling"", ""Kernel methods""]",This paper presents Conditional Contrastive Learning with Kernel (CCL-K) for conditional contrastive learning tasks under the scenario when we have insufficient data for some values of the condioning variable.,2202.05458,cs.LG,2022-02-11 05:37:54+00:00,2022-02-11 05:37:54+00:00
AAeMQz0x4nA,2022,Reject,False,Learning Explicit Credit Assignment for Multi-agent Joint Q-learning,"['Hangyu Mao', 'Jianye HAO', 'Dong Li', 'Jun Wang', 'Weixun Wang', 'Xiaotian Hao', 'Bin Wang', 'Kun Shao', 'Zhen Xiao', 'Wulong Liu']","[""Mutli-agent Credit Assignment"", ""Mutli-agent Joint Q-learning""]",An explicit credit assignment method for IGM-based joint Q-learning.,,,,
AAes_3W-2z,2021,Accept (Poster),True,Wasserstein Embedding for Graph Learning,"[""Soheil Kolouri"", ""Navid Naderializadeh"", ""Gustavo K. Rohde"", ""Heiko Hoffmann""]","[""Wasserstein"", ""graph embedding"", ""graph-level prediction""]",Wasserstein Embedding for Graph Learning (WEGL) is a novel and fast framework for embedding entire graphs into a vector space in which the Euclidean distance between representations approximates the 2-Wasserstein distance.,2006.09430,cs.LG,2020-06-16 18:23:00+00:00,2021-03-02 02:21:28+00:00
AB2r0YKBSpD,2022,Reject,False,Data Scaling Laws in NMT: The Effect of Noise and Architecture,"['Yamini Bansal', 'Behrooz Ghorbani', 'Ankush Garg', 'Biao Zhang', 'Colin Cherry', 'Maxim Krikun', 'Behnam Neyshabur', 'Orhan Firat']","[""Scaling laws"", ""Neural Machine Translation""]",We study the effect of changing architecture and training distribution noise levels on the data scaling laws for NMT.,,,,
ABZSAe9gNeg,2021,Reject,False,Differentially Private Synthetic Data: Applied Evaluations and Enhancements,"[""Lucas Rosenblatt"", ""Xiaoyan Liu"", ""Samira Pouyanfar"", ""Eduardo de Leon"", ""Anuj Desai"", ""Joshua Allen""]","[""privacy"", ""differential privacy"", ""generative adversarial networks"", ""gan"", ""security"", ""synthetic data"", ""evaluation"", ""benchmarking"", ""ensemble""]","We present both extensive benchmarking for state-of-the-art differentially private synthesizers and QUAIL, an ensemble-based modeling approach to generating differentially private synthetic data with high utility.",2011.05537,cs.LG,2020-11-11 04:03:08+00:00,2020-11-11 04:03:08+00:00
ADWd4TJO13G,2021,Accept (Poster),False,Lifelong Learning of Compositional Structures,"[""Jorge A Mendez"", ""ERIC EATON""]","[""lifelong learning"", ""continual learning"", ""compositional learning"", ""modular networks""]","We create a general-purpose framework for lifelong learning of compositional structures that splits the learning process into two stages: assimilation of new tasks with existing components, and accommodation of new knowledge into the components.",,,,
ADwLLmSda3,2021,Reject,False,Neural Nonnegative CP Decomposition for Hierarchical Tensor Analysis,"[""Joshua Vendrow"", ""Jamie Haddock"", ""Deanna Needell""]","[""nonnegative tensor decompositions"", ""topic modeling"", ""hierarchical model"", ""CP decomposition"", ""neural network"", ""backpropagation""]","We propose a new hierarchical nonnegative CANDECOMP/PARAFAC (CP) decomposition (hierarchical NCPD) model and a training method, Neural NCPD, for performing hierarchical topic modeling on multi-modal tensor data.",,,,
AEa_UepnMDX,2022,Reject,False,Resolving label uncertainty with implicit generative models,"['Esther Rolf', 'Nikolay Malkin', 'Alexandros Graikos', 'Ana Jojic', 'Caleb Robinson', 'Nebojsa Jojic']","[""weakly supervised learning"", ""generative models"", ""image segmentation""]","Unified approach to learning with uncertain targets, applied to a variety of machine learning settings.",,,,
AFH3FnBksHT,2022,Reject,False,Model Fusion of Heterogeneous Neural Networks via Cross-Layer Alignment,"['Dang Nguyen', 'Khai Nguyen', 'Nhat Ho', 'Dinh Phung', 'Hung Bui']","[""Model Fusion"", ""Cross-layer Alignment"", ""Knowledge Distillation"", ""Model Compression"", ""Model Transfer""]",A novel framework that can fuse neural networks with a different number of layers.,,,,
AHOs7Sm5H7R,2021,Accept (Poster),False,Towards Resolving the Implicit Bias of Gradient Descent for Matrix Factorization: Greedy Low-Rank Learning,"[""Zhiyuan Li"", ""Yuping Luo"", ""Kaifeng Lyu""]","[""matrix factorization"", ""gradient descent"", ""implicit regularization"", ""implicit bias""]","We prove that for depth-2 matrix factorization, gradient flow with infinitesimal initialization is mathematically equivalent to a simple heuristic rank minimization algorithm, Greedy Low-Rank Learning, under some reasonable assumptions.",2012.09839,cs.LG,2020-12-17 18:57:01+00:00,2021-04-11 12:40:57+00:00
AHm3dbp7D1D,2021,Accept (Poster),False,SEED: Self-supervised Distillation For Visual Representation,"[""Zhiyuan Fang"", ""Jianfeng Wang"", ""Lijuan Wang"", ""Lei Zhang"", ""Yezhou Yang"", ""Zicheng Liu""]","[""Self Supervised Learning"", ""Knowledge Distillation"", ""Representation Learning""]","We propose ${\large S}$EED, a self-supervised distillation technique for visual representation learning.",,,,
AICNpd8ke-m,2021,Accept (Poster),False,Multi-Class Uncertainty Calibration via Mutual Information Maximization-based Binning,"[""Kanil Patel"", ""William H. Beluch"", ""Bin Yang"", ""Michael Pfeiffer"", ""Dan Zhang""]","[""uncertainty calibration"", ""post-hoc calibration"", ""histogram binning"", ""mutual information"", ""deep neural networks""]","We propose I-Max binning, a novel method for multi-class calibration, improving over previous methods in terms of various ECE measures",,,,
AIgn9uwfcD1,2022,Accept (Poster),False,Prospect Pruning: Finding Trainable Weights at Initialization using Meta-Gradients,"['Milad Alizadeh', 'Shyam A. Tailor', 'Luisa M Zintgraf', 'Joost van Amersfoort', 'Sebastian Farquhar', 'Nicholas Donald Lane', 'Yarin Gal']","[""pruning"", ""lottery ticket hypothesis"", ""pruning at initialization""]","We use meta-gradients to prune neural networks at initialization based on ""trainability"" of weights instead of their impact on the loss at a single step.",,,,
AJAR-JgNw__,2022,Accept (Spotlight),False,DEPTS: Deep Expansion Learning for Periodic Time Series Forecasting,"['Wei Fan', 'Shun Zheng', 'Xiaohan Yi', 'Wei Cao', 'Yanjie Fu', 'Jiang Bian', 'Tie-Yan Liu']",[],,,,,
AJO2mBSTOHl,2022,Reject,False,Analytically Tractable Bayesian Deep Q-Learning,"['Luong-Ha Nguyen', 'James-A. Goulet']","[""Bayesian Learning"", ""Probabilistic Methods"", ""Uncertainty Quantification"", ""Reinforcement Learning"", ""Deep Q-learning""]",We apply tractable approximate Bayesian inference to deep reinforcement learning,,,,
AJTAcS7SZzf,2021,Reject,False,AUTOSAMPLING: SEARCH FOR EFFECTIVE DATA SAMPLING SCHEDULES,"[""Ming Sun"", ""Haoxuan Dou"", ""Baopu Li"", ""Junjie Yan"", ""Wanli Ouyang""]","[""Hyper-parameter Learning"", ""AutoML"", ""Computer Vision""]",An efficient method to learn robust data samplers for computer vision tasks,,,,
AJY3fGPF1DC,2021,Reject,False,Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge,"[""Trent Kyono"", ""Ioana Bica"", ""Zhaozhi Qian"", ""Mihaela van der Schaar""]","[""causal inference"", ""treatment effects"", ""healthcare""]",We take advantage of the invariance of causal graphs across domains and propose a novel model selection metric for individualized treatment effect models in the unsupervised domain adaptation setting. ,2102.06271,cs.LG,2021-02-11 21:03:14+00:00,2021-02-11 21:03:14+00:00
AJg35fkqOPA,2022,Reject,False,Text-Driven Image Manipulation via Semantic-Aware Knowledge Transfer,"['Ziqi Zhang', 'Cheng Deng', 'Kun Wei', 'Xu Yang']",[],,,,,
AJsI-ymaKn_,2022,Accept (Spotlight),False,POETREE: Interpretable Policy Learning with Adaptive Decision Trees,"['AlizÃ©e Pace', 'Alex Chan', 'Mihaela van der Schaar']","[""Imitation Learning"", ""Interpretable ML"", ""Clinical Decision Support"", ""Sequential Decision-Making""]","Policy Extraction through decision Trees (POETREE) is a novel framework for interpretable policy learning, compatible with fully-offline and partially-observable clinical decision environments.",,,,
ALSupSRaBH,2021,Reject,False,Deep Goal-Oriented Clustering,"[""Yifeng Shi"", ""Christopher M Bender"", ""Linnea Olsson"", ""Melissa Troester"", ""Katherine A Hoadley"", ""Junier Oliva"", ""Marc Niethammer""]","[""clustering"", ""variational inference""]",A clustering method that incorporates both the supervised information (if provided) and the unsupervised signal. ,,,,
AM0PBmqmojH,2021,Reject,False,"Warpspeed Computation of Optimal Transport, Graph Distances, and Embedding Alignment","[""Johannes Klicpera"", ""Marten Lienen"", ""Stephan G\u00fcnnemann""]","[""Optimal transport"", ""sinkhorn distance"", ""locality sensitive hashing"", ""nystr\u00f6m method"", ""graph neural networks"", ""embedding alignment""]","We propose the locally corrected NystrÃ¶m (LCN) method for kernels, develop two fast approximations of entropy-regularized optimal transport (sparse Sinkhorn and LCN-Sinkhorn) and evaluate them for embedding alignment and graph distance regression.",2107.06876,cs.LG,2021-07-14 17:40:08+00:00,2021-07-14 17:40:08+00:00
AMoDLAx6GCC,2021,Reject,True,Uncertainty Prediction for Deep Sequential Regression Using Meta Models,"[""Jiri Navratil"", ""Matthew Arnold"", ""Benjamin Elder""]","[""Uncertainty Quantification"", ""Uncertainty Prediction"", ""Deep Learning"", ""Regression"", ""Meta Modeling""]",Meta modeling is highly effective in uncertainty quantification in sequential regression tasks using deep recurrent NNs. ,2007.01350,cs.LG,2020-07-02 19:27:17+00:00,2021-07-22 21:59:50+00:00
AMpki9kp8Cn,2022,Accept (Poster),False,Nonlinear ICA Using Volume-Preserving Transformations,"['Xiaojiang Yang', 'Yi Wang', 'Jiacheng Sun', 'Xing Zhang', 'Shifeng Zhang', 'Zhenguo Li', 'Junchi Yan']","[""Independent Component Analysis"", ""Nonlinear ICA"", ""Identifiability""]","We propose a general framework for nonlinear ICA, in which the mixing function is restricted to a volume-preserving transformation, and establish two novel identifiability theorems and provide insightful proofs.",,,,
AOn-gHymcx,2022,Reject,False,A neural network framework for learning Green's function,"['Guochang Lin', 'Fukai Chen', 'Pipi Hu', 'Xiang Chen', 'Junqing Chen', 'Jun Wang', 'Zuoqiang Shi']","[""Green's function"", ""partial differential equation"", ""boundary integral"", ""neural network""]","We proposed a novel neural network based method to compute Green's function directly in bounded domains, unbounded domains and domains with interfaces, which is difficult for traditional method to handle.",,,,
AP1MKT37rJ,2022,Accept (Poster),False,Should I Run Offline Reinforcement Learning or Behavioral Cloning?,"['Aviral Kumar', 'Joey Hong', 'Anikait Singh', 'Sergey Levine']","[""offline RL""]",Characterization of scenarios where offline reinforcement learning outperforms behavioral cloning,,,,
ARFshOO1Iu,2021,Reject,True,Adaptive Self-training for Neural Sequence Labeling with Few Labels,"[""Yaqing Wang"", ""Subhabrata Mukherjee"", ""Haoda Chu"", ""Yuancheng Tu"", ""Ming Wu"", ""Jing Gao"", ""Ahmed Hassan Awadallah""]","[""Self-training"", ""Neural Sequence Labeling"", ""Meta Learning""]",We develop techniques leveraging self-training and meta-learning for few-shot training of neural sequence taggers based on large-scale pre-trained language models.,2010.03680,cs.CL,2020-10-07 22:29:05+00:00,2020-12-11 17:16:57+00:00
ARQAdp7F8OQ,2021,Reject,False,Brain-like approaches to unsupervised learning of hidden representations - a comparative study ,"[""Naresh Balaji"", ""Anders Lansner"", ""Pawel Herman""]","[""neural networks"", ""bio-inspired"", ""brain-like"", ""unsupervised learning"", ""structural plasticity""]","We compare unsupervised learning algorithms implementing biologically plausible local plasticity rules on MNIST dataset, with special emphasis on the Bayesian Confidence Propagating Neural Network (BCPNN).",,,,
ARw4igiN2Qm,2022,Reject,False,A stepped sampling method for video detection using LSTM,['Dengshan Li'],"[""stepped sampler"", ""LSTM"", ""video detection"", ""psychology"", ""human memory rule""]",The paper uses the human learning method to machine learning.,,,,
ARyEf6Z77Y,2022,Reject,False,Collaboration of Experts: Achieving 80% Top-1 Accuracy on ImageNet with 100M FLOPs,"['Yikang Zhang', 'Zhuo Chen', 'Zhao Zhong']",[],The paper presents a system called Collaboration of Experts (CoE) in which expert networks are encouraged to focus on unique portions of the dataset. ,,,,
AS0dhAKIYA0,2022,Reject,False,Interpretable Semantic Role Relation Table for Supporting Facts Recognition of Reading Comprehension,"['YanQing Bai', 'Zhichang Zhang', 'HaoYuan Chen', 'Xiaohui Qin', 'Yanglong Qiu']","[""interpretability"", ""semantic role relation table"", ""supporting facts""]","We believe that the model uses interpretable features for reasoning, which contributes to enhanced interpretability. So we propose a handy and interpretable feature semantic role relationship table.",,,,
ASAJvUPWaDI,2021,Reject,False,A Near-Optimal Recipe for Debiasing Trained Machine Learning Models,"[""Ibrahim Alabdulmohsin"", ""Mario Lucic""]","[""Fairness"", ""Classification"", ""Statistical Parity"", ""Deep Learning""]", The paper introduces a new near-optimal algorithm debiasing learned models. ,2106.12887,cs.LG,2021-06-06 09:45:37+00:00,2021-06-06 09:45:37+00:00
AT0K-SZ3QGq,2022,Reject,False,"On Heterogeneously Distributed Data, Sparsity Matters","['Tiansheng Huang', 'Shiwei Liu', 'Li Shen', 'Fengxiang He', 'Weiwei Lin', 'Dacheng Tao']","[""Federated Learning"", ""Dynamic Sparse Training"", ""Communication-efficient Personalized Federated Learning""]","We propose federated learning with personalized sparse mask (FedSpa), a novel personalized federated learning scheme that employs personalized sparse masks to customize sparse local models on the edge.",,,,
AT7jak63NNK,2021,Reject,True,Meta-Reinforcement Learning Robust to Distributional Shift via Model Identification and Experience Relabeling,"[""Russell Mendonca"", ""Xinyang Geng"", ""Chelsea Finn"", ""Sergey Levine""]","[""Meta-Reinforcement Learning"", ""Meta Learning"", ""Reinforcement Learning""]","We present model identification and experience relabeling (MIER), a meta-reinforcement learning algorithm that is both efficient and extrapolates well when faced with out-of-distribution tasks at test time.",2006.07178,cs.LG,2020-06-12 13:34:46+00:00,2020-06-15 18:34:23+00:00
ATUh28lnSuW,2022,Accept (Poster),False,Graph Auto-Encoder via Neighborhood Wasserstein Reconstruction,"['Mingyue Tang', 'Pan Li', 'Carl Yang']","[""graph representation learning"", ""unsupervised learning"", ""autoencoder"", ""wasserstein distance""]",We study unsupervised graph representation learning and propose a novel decoder based on neighborhood reconstruction with Wasserstein distance to facilitate the GNN encoding of entire neighborhood information beyond direct links.,,,,
ATp1nW2FuZL,2021,Accept (Poster),False,Neural Learning of One-of-Many Solutions for Combinatorial Problems in Structured Output Spaces,"[""Yatin Nandwani"", ""Deepanshu Jindal"", ""Mausam ."", ""Parag Singla""]","[""Neuro symbolic"", ""constraint satisfaction"", ""reasoning""]",This work identifies and proposes a solution for handling solution multiplicity while learning neural methods for combinatorial problems in structured output spaces.,,,,
AUGBfDIV9rL,2022,Accept (Spotlight),False,Emergent Communication at Scale,"['Rahma Chaabouni', 'Florian Strub', 'Florent AltchÃ©', 'Eugene Tarassov', 'Corentin Tallec', 'Elnaz Davoodi', 'Kory Wallace Mathewson', 'Olivier Tieleman', 'Angeliki Lazaridou', 'Bilal Piot']","[""emergent communication"", ""multi-agent reinforcement learning"", ""representation learning""]","This work argues the importance of scaling up the emergent communication framework and investigates the impact of three scaling up aspects, namely the dataset, task complexity, and population size.",,,,
AUszBTiYBB6,2022,Reject,False,FEDERATED LEARNING FRAMEWORK BASED ON TRIMMED MEAN AGGREGATION RULES,"['Wang Tian Xiang', 'Meiyue Shao', 'Yanwei Fu', 'Riheng Jia', 'Feilong Lin', 'Zhonglong Zheng']","[""Tmean\uff0cByzantine attack\uff0cByzantine-resilient""]",We analyze the Tmean(.) aggregation rule and use experiments to prove its robustness.,,,,
AV8FPoMTTa,2022,Accept (Poster),False,Shallow and Deep Networks are Near-Optimal Approximators of Korobov Functions,"['Moise Blanchard', 'Mohammed Amine Bennouna']",[],We analyze the number of neurons and training parameters that a neural network needs to approximate multivariate functions of bounded second mixed derivatives,,,,
AVKFuhH1Fo4,2021,Reject,False,Transformers are Deep Infinite-Dimensional Non-Mercer Binary Kernel Machines,"[""Matthew A Wright"", ""Joseph E. Gonzalez""]","[""Transformer models"", ""attention models"", ""kernel methods"", ""reproducing kernel Banach spaces""]","We obtain theoretical results relating Transformer models to generalizations of kernel methods, and empirical results concerning the importance of characteristics of the standard Transformer's kernel.",,,,
AVShGWiL9z,2022,Reject,False,Tractable Dendritic RNNs for Identifying Unknown Nonlinear Dynamical Systems,"['Manuel Brenner', 'Leonard Bereska', 'Jonas Magdy Mikhaeil', 'Florian Hess', 'Zahra Monfared', 'Po-Chen Kuo', 'Daniel Durstewitz']","[""chaos"", ""dendritic computation"", ""piecewise linear"", ""recurrent neural network"", ""variational inference"", ""interpretability"", ""tractability"", ""basis expansion""]",To approximate dynamical systems we augment an interpretable and tractable piecewise-linear recurrent neural network by a dendrite-inspired basis expansion.,,,,
AWOSz_mMAPx,2021,Accept (Poster),False,Local Convergence Analysis of Gradient Descent Ascent with Finite Timescale Separation,"[""Tanner Fiez"", ""Lillian J Ratliff""]","[""game theory"", ""continuous games"", ""generative adversarial networks"", ""theory"", ""gradient descent-ascent"", ""equilibrium"", ""convergence""]",We show that there exists a range of finite learning ratios which we construct such that gradient descent-ascent converges to a critical point if and only if it is a strict local minmax equilibrium,,,,
AXWygMvuT6Q,2022,Accept (Poster),False,Retriever: Learning Content-Style Representation as a Token-Level Bipartite Graph,"['Dacheng Yin', 'Xuanchi Ren', 'Chong Luo', 'Yuwang Wang', 'Zhiwei Xiong', 'Wenjun Zeng']","[""Content-style decomposed representation"", ""Zero-shot voice conversion"", ""Style transfer"", ""Transformer"", ""Unsupervised learning""]",We propose a model-agnostic and unsupervised framework to learn a novel token-level bipartite graph representation of content and style from structured input.,,,,
AY8zfZm0tDd,2021,Accept (Poster),False,Randomized Ensembled Double Q-Learning: Learning Fast Without a Model,"[""Xinyue Chen"", ""Che Wang"", ""Zijian Zhou"", ""Keith W. Ross""]","[""Artificial Integlligence"", ""Machine Learning"", ""Deep Reinforcement Learning""]",We propose and analyze a novel model-free algorithm that achieves strong performance with a high update-to-data ratio.,,,,
AZ4vmLoJft,2021,Reject,False,(Updated submission 11/20/2020) MISIM: A Novel Code Similarity System,"[""Fangke Ye"", ""Shengtian Zhou"", ""Anand Venkat"", ""Ryan Marcus"", ""Nesime Tatbul"", ""Jesmin Jahan Tithi"", ""Niranjan Hasabnis"", ""Paul Petersen"", ""Timothy G Mattson"", ""Tim Kraska"", ""Pradeep Dubey"", ""Vivek Sarkar"", ""Justin Gottschlich""]","[""Machine Programming"", ""Machine Learning"", ""Code Similarity"", ""Code Representation""]",We present a new state-of-the-art code similarity system that includes a novel code structure and a flexible neural back-end to learn the code similarity algorithm for different code corpi.,,,,
AawMbgacl0t,2022,Reject,False,Image Functions In Neural Networks: A Perspective On Generalization,['Arushi Gupta'],"[""generalization"", ""ensembling"", ""algorithmic stability""]",,,,,
Ab0o8YMJ8a,2022,Reject,False,Automated Channel Pruning with Learned Importance,"['Åukasz Treszczotko', 'Pawel Kubik']","[""channel pruning"", ""knowledge distillation""]",Channel pruning via automated discovery of channel interdependence and learned channel importance.,,,,
AcH9xD24Hd,2021,Reject,False,Learning the Step-size Policy for the Limited-Memory Broyden-Fletcher-Goldfarb-Shanno Algorithm,"[""Lucas N. Egidio"", ""Anders Hansson"", ""Bo Wahlberg""]","[""Unconstrained optimization"", ""Step-size policy"", ""L-BFGS"", ""Learned optimizers""]",A framework to automatically learn a policy from data that generates step sizes for the Limited-Memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) algorithm and performs better than heuristically tuned ADAM and RMSprop in tests on MNIST dataset.,,,,
AcrlgZ9BKed,2022,Accept (Poster),False,A Reduction-Based Framework for Conservative Bandits and Reinforcement Learning,"['Yunchang Yang', 'Tianhao Wu', 'Han Zhong', 'Evrard Garcelon', 'Matteo Pirotta', 'Alessandro Lazaric', 'Liwei Wang', 'Simon Shaolei Du']","[""bandits"", ""lower bound"", ""reinforcement learning theory""]",We give general framework that turns upper and lower bounds in non-conservative settings to bounds in conservative settings.,,,,
AdEM_SzfSd,2022,Reject,False,Assessing two novel distance-based loss functions for few-shot image classification,"['Mauricio Mendez Ruiz', 'Gilberto Ochoa Ruiz', 'Andres Mendez Vazquez', 'Jorge Gonzalez-Zapata']","[""Metric learning"", ""few-shot learning"", ""image classification""]",,,,,
AgDwZa1AiJt,2022,Reject,True,"When in Doubt, Summon the Titans: A Framework for Efficient Inference with Large Models","['Ankit Singh Rawat', 'Manzil Zaheer', 'Aditya Krishna Menon', 'Amr Ahmed', 'Sanjiv Kumar']","[""Distillation"", ""Large models"", ""Efficient inference""]","We use the large teacher models to guide the lightweight student models to only make correct predictions on a subset of ""easy"" examples; for the ""hard"" examples, we fall-back to the teacher.",2110.10305,cs.LG,2021-10-19 22:56:49+00:00,2021-10-19 22:56:49+00:00
AhElGnhU2BV,2021,Accept (Poster),False,"On InstaHide, Phase Retrieval, and Sparse Matrix Factorization","[""Sitan Chen"", ""Xiaoxiao Li"", ""Zhao Song"", ""Danyang Zhuo""]","[""Distributed learning"", ""InstaHide"", ""phase retrieval"", ""matrix factorization""]","We examine the security of InstaHide, a recently proposed framework for private distributed learning, through the lens of phase retrieval and give an attack when the underlying datasets are Gaussian.",2011.11181,cs.LG,2020-11-23 02:47:08+00:00,2021-03-25 00:08:38+00:00
Aj4_e50nB8,2021,Reject,False,Contextual Knowledge Distillation for Transformer Compression,"[""Geondo Park"", ""Gyeongman Kim"", ""Eunho Yang""]","[""Knowledge Distillation"", ""Transformer Compression"", ""BERT""]",,,,,
AjGC97Aofee,2022,Accept (Poster),False,Learning Efficient Image Super-Resolution Networks via Structure-Regularized Pruning,"['Yulun Zhang', 'Huan Wang', 'Can Qin', 'Yun Fu']","[""image super-resolution""]",Learning efficient compressed models for bother lightweight and large image super-resolution networks,,,,
AjrRA6WYSW,2021,Reject,False,Estimation of Number of Communities in Assortative Sparse Networks,"[""Neil Hwang"", ""Jiarui Xu"", ""Shirshendu Chatterjee"", ""Sharmodeep Bhattacharyya""]","[""networks"", ""number of communities"", ""Bethe-Hessian"", ""sparse networks"", ""stochastic block model""]",Estimation of number of communities in sparse networks using eigenvalues of the Bethe-Hessian Matrix,,,,
AkJyAE46GA,2022,Reject,False,Pretrained models are active learners,"['Alex Tamkin', 'Dat Nguyen', 'Salil Deshpande', 'Jesse Mu', 'Noah Goodman']","[""pretraining"", ""active learning"", ""alignment"", ""safety""]","Pretraining makes models better active learners, which learn up to 6x faster and can resolve task ambiguity",,,,
Al7Wpsy49g,2021,Reject,True,Noisy Agents: Self-supervised Exploration by Predicting Auditory Events,"[""Chuang Gan"", ""Xiaoyu Chen"", ""Phillip Isola"", ""Antonio Torralba"", ""Joshua B. Tenenbaum""]","[""Audio Curiosity"", ""RL exploration""]",We introduce using auditory event prediction as an intrinsic reward to guide RL exploration.,2007.13729,cs.CV,2020-07-27 17:59:08+00:00,2020-07-27 17:59:08+00:00
AlPBx2zq7Jt,2022,Reject,False,Align-RUDDER: Learning From Few Demonstrations by Reward Redistribution,"['Vihang Prakash Patil', 'Markus Hofmarcher', 'Marius-Constantin Dinu', 'Matthias Dorfer', 'Patrick M Blies', 'Johannes Brandstetter', 'Jose Arjona-Medina', 'Sepp Hochreiter']","[""RUDDER"", ""reinforcement learning"", ""reward redistribution"", ""return decomposition"", ""delayed reward"", ""sparse reward"", ""episodic reward"", ""minecraft""]",Learn faster by redistributing reward to important events obtained by multiple sequence alignment of successful sequences. ,,,,
AmUhwTOHgm,2022,Accept (Poster),True,Trans-Encoder: Unsupervised sentence-pair modelling through self- and mutual-distillations,"['Fangyu Liu', 'Yunlong Jiao', 'Jordan Massiah', 'Emine Yilmaz', 'Serhii Havrylov']","[""self-supervised learning"", ""sentence embeddings"", ""sentence representations"", ""knowledge distillation""]","Bootstrapping an unsupervised sentence encoder by self-distilling knowledge between its bi-encoder and cross-encoder forms, enhancing each other iteratively.",2109.13059,cs.CL,2021-09-27 14:06:47+00:00,2021-12-05 19:12:25+00:00
Ao2-JgYxuQf,2021,Reject,True,Active Tuning,"[""Sebastian Otte"", ""Matthias Karlbauer"", ""Martin V. Butz""]","[""Signal Filtering"", ""Recurrent Neural Network"", ""Time Series"", ""Denoising"", ""Temporal Gradients""]","Given a capable time series predictor, Active Tuning enhances its online signal filtering, denoising, and reconstruction abilities without the need for additional training. ",2010.03958,cs.LG,2020-10-02 20:21:58+00:00,2020-11-25 15:01:40+00:00
Aoq37n5bhpJ,2021,Reject,False,Federated learning using mixture of experts,"[""Edvin Listo Zec"", ""John Martinsson"", ""Olof Mogren"", ""Leon Ren\u00e9 S\u00fctfeld"", ""Daniel Gillblad""]","[""federated learning"", ""mixture of experts""]",We use a mixture of expert approach to learn personalized models in a federated learning setting with heterogeneous client data,,,,
Aot3sKdraW,2022,Reject,False,AA-PINN: ATTENTION AUGMENTED PHYSICS INFORMED NEURAL NETWORKS,['Abhinav Sagar'],[],,,,,
ArY-zkyHI_l,2022,Reject,False,Resilience to Multiple Attacks via Adversarially Trained MIMO Ensembles,"['Ruqi Bai', 'David I. Inouye', 'Saurabh Bagchi']","[""Adversarial Example"", ""Adversarial Attack"", ""Evasion Attack"", ""Defense"", ""Adversarial Training"", ""Security in Machine Learning""]",,,,,
AsDSpwXYGeT,2022,Reject,False,Back to Basics: Efficient Network Compression via IMP,"['Max Zimmer', 'Sebastian Pokutta', 'Christoph Spiegel']","[""Magnitude pruning"", ""Sparsity"", ""IMP"", ""Model Compression""]",We demonstrate that basic IMP can already provide state-of-the-art pruning results on par or outperforming more complex or heavily parameterized approaches and aim to establish a more realistic yet easily realizable baseline for future research.,,,,
AsQz_GFFDQp,2022,Reject,False,Agnostic Personalized Federated Learning with Kernel Factorization,"['Wonyong Jeong', 'Sung Ju Hwang']","[""Federated Learning"", ""Personalized Federated Learning""]",We introduce a futuristic scenario of federated learning at worldwide scale with two essential challenges and propose a novel method to tackle the problems utilizing similarity matching and kernel factorization.,2202.00270,cs.LG,2022-02-01 08:00:59+00:00,2022-02-01 08:00:59+00:00
AsyICRrQ7Lp,2022,Reject,False,Bootstrapped Hindsight Experience replay with Counterintuitive Prioritization,"['Jiawei Xu', 'Shuxing Li', 'Chun Yuan', 'Zhengyou Zhang', 'Lei Han']","[""Reinforcement learning"", ""hindsight experience replay"", ""counterintuitive prioritization""]","We reveal a counterintuitive conclusion that for hindsight experiences, exploiting lower uncertainty data samples will significantly improve the performance.",,,,
Atpv9GUhRt6,2021,Reject,False,Learning from multiscale wavelet superpixels using GNN with spatially heterogeneous pooling,"[""Maxime Bassenne"", ""Varun Vasudevan"", ""Lei Xing""]","[""Image classification"", ""GNN"", ""superpixel"", ""SLIC"", ""wavelet""]",We investigate learning from a new principled representation in which individual images are represented by an image-specific number of multiscale superpixels.,,,,
Au1gNqq4brw,2021,Reject,False,SEQUENCE-LEVEL FEATURES: HOW GRU AND LSTM CELLS CAPTURE N-GRAMS,"[""Xiaobing Sun"", ""Wei Lu""]","[""GRU"", ""LSTM"", ""Sequence-level"", ""Features"", ""N-grams""]",We found that the impressive performances of GRU or LSTM cells might be attributed to sequence-level representations brought in by the gating mechanism.,,,,
AvcfxqRy4Y,2022,Accept (Spotlight),False,Understanding the Role of Self Attention for Efficient Speech Recognition,"['Kyuhong Shim', 'Jungwook Choi', 'Wonyong Sung']","[""transformer"", ""self attention"", ""speech recognition""]",We analyze the role of self attention in Transformer-based speech recognition and present a practical technique to design a model that accelerates the inference and improve the performance.,,,,
AwPGPgExiYA,2021,Reject,False,Differentiable Learning of Graph-like Logical Rules from Knowledge Graphs,"[""Hongzhi Shi"", ""quanming yao"", ""Yong Li""]","[""knowledge graph"", ""logical rules"", ""logical query""]","We propose the first method which can learn from graph-like logical rules, thus can better capture complex semantics in knowledge graphs.",,,,
AwgtcUAhBq,2022,Accept (Poster),False,Domain Adversarial Training: A Game Perspective,"['David Acuna', 'Marc T Law', 'Guojun Zhang', 'Sanja Fidler']","[""Domain Adversarial Training"", ""Domain Adaptation"", ""Neural Networks Optimization"", ""Game Theory""]",A novel perspective on domain-adversarial training that leads to more stable and performant optimizers.,2202.05352,cs.LG,2022-02-10 22:17:30+00:00,2022-02-10 22:17:30+00:00
AypVMhFfuc5,2022,Reject,True,FrugalMCT: Efficient Online ML API Selection for Multi-Label Classification Tasks,"['Lingjiao Chen', 'Matei Zaharia', 'James Zou']","[""ML as a Service"", ""Multi-label classifications"", ""ML systems"", ""adaptive learning""]","We design a principled framework, FrugalMCT, to adaptively select multi-label APIs to use for different data in an online fashion under budget constraints.",2102.09127,cs.LG,2021-02-18 02:59:58+00:00,2021-02-18 02:59:58+00:00
Az-7gJc6lpr,2022,Accept (Poster),False,Relational Learning with Variational Bayes,['Kuang-Hung Liu'],"[""Relational learning"", ""psychology"", ""unsupervised learning"", ""variational inference"", ""probabilistic graphical model.""]",Propose an unsupervised learning method for addressing the relational learning problem where we learn the underlying relationship between a pair of data irrespective of the nature of those data.,,,,
Az7opqbQE-3,2022,Accept (Poster),False,Heteroscedastic Temporal Variational Autoencoder For Irregularly Sampled Time Series,"['Satya Narayan Shukla', 'Benjamin Marlin']","[""irregular sampling"", ""uncertainty"", ""imputation"", ""interpolation"", ""multivariate time series"", ""missing data"", ""variational autoencoder""]",We present a new deep learning architecture for probabilistic interpolation of irregularly sampled time series.,,,,
Azh9QBQ4tR7,2022,Accept (Poster),False,Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off,"['Rahul Rade', 'Seyed-Mohsen Moosavi-Dezfooli']","[""adversarial training"", ""robustness""]",,,,,
B0JH7vR2iGh,2022,Reject,False,PMIC: Improving Multi-Agent Reinforcement Learning with Progressive Mutual Information Collaboration,"['Pengyi Li', 'Hongyao Tang', 'Tianpei Yang', 'Xiaotian Hao', 'Sang Tong', 'YAN ZHENG', 'Jianye HAO', 'Matthew E. Taylor', 'Jinyi Liu']","[""Multi-Agent Reinforcement Learning"", ""Collaboration""]",A novel collaboration criterion to evalute the collaboration and a novel mutual information framwork to better use the MI-based collaboration signals.,,,,
B0oHOwT5ENL,2022,Accept (Poster),False,Neural Deep Equilibrium Solvers,"['Shaojie Bai', 'Vladlen Koltun', 'J Zico Kolter']","[""Deep learning"", ""Implicit models"", ""Deep equilibrium models""]",A custom and lightweight neural solver for deep equilibrium models significantly improves their efficiency with minimal training.,,,,
B1-Hhnslg,2017,Reject,False,Prototypical Networks for Few-shot Learning,"[""Jake Snell"", ""Kevin Swersky"", ""Richard Zemel""]","[""Deep learning"", ""Transfer Learning""]",We learn a metric space in which few-shot classification can be performed by computing Euclidean distances to a single prototype representative of each class.,,,,
B1-q5Pqxl,2017,Accept (Poster),False,Machine Comprehension Using Match-LSTM and Answer Pointer,"[""Shuohang Wang"", ""Jing Jiang""]","[""Natural language processing"", ""Deep learning""]",Using Match-LSTM and Answer Pointer to select a variable length answer from a paragraph,,,,
B12Js_yRb,2018,Accept (Poster),False,Learning to Count Objects in Natural Images for Visual Question Answering,"[""Yan Zhang"", ""Jonathon Hare"", ""Adam Pr\u00fcgel-Bennett""]","[""visual question answering"", ""vqa"", ""counting""]",Enabling Visual Question Answering models to count by handling overlapping object proposals.,,,,
B13EC5u6W,2018,Reject,False,Thinking like a machine â generating visual rationales through latent space optimization,"[""Jarrel Seah"", ""Jennifer Tang"", ""Andy Kitchen"", ""Jonathan Seah""]","[""interpretability"", ""generative adversarial networks""]",We propose a method of using GANs to generate high quality visual rationales to help explain model predictions. ,,,,
B13njo1R-,2018,Accept (Poster),False,Progressive Reinforcement Learning with Distillation for Multi-Skilled Motion Control,"[""Glen Berseth"", ""Cheng Xie"", ""Paul Cernek"", ""Michiel Van de Panne""]","[""Reinforcement Learning"", ""Distillation"", ""Transfer Learning"", ""Continual Learning""]",A continual learning method that uses distillation to combine expert policies and transfer learning to accelerate learning new skills.,,,,
B14TlG-RW,2018,Accept (Poster),False,QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension,"[""Adams Wei Yu"", ""David Dohan"", ""Minh-Thang Luong"", ""Rui Zhao"", ""Kai Chen"", ""Mohammad Norouzi"", ""Quoc V. Le""]","[""squad"", ""stanford question answering dataset"", ""reading comprehension"", ""attention"", ""text convolutions"", ""question answering""]",A simple architecture consisting of convolutions and attention achieves results on par with the best documented recurrent models.,,,,
B14ejsA5YQ,2019,Reject,False,Neural Causal Discovery with Learnable Input Noise,"[""Tailin Wu"", ""Thomas Breuel"", ""Jan Kautz""]","[""neural causal learning"", ""learnable noise""]",,,,,
B14rPj0qY7,2019,Reject,False,RETHINKING SELF-DRIVING : MULTI -TASK KNOWLEDGE FOR BETTER GENERALIZATION AND ACCIDENT EXPLANATION ABILITY,"[""Zhihao LI"", ""Toshiyuki MOTOYOSHI"", ""Kazuma SASAKI"", ""Tetsuya OGATA"", ""Shigeki SUGANO""]","[""Autonomous car"", ""convolution network"", ""image segmentation"", ""depth estimation"", ""generalization ability"", ""explanation ability"", ""multi-task learning""]",we proposed a new self-driving model which is composed of perception module for see and think and driving module for behave to acquire better generalization  and accident explanation ability.,,,,
B14uJzW0b,2018,Invite to Workshop Track,False,No Spurious Local Minima in a Two Hidden Unit ReLU Network,"[""Chenwei Wu"", ""Jiajun Luo"", ""Jason D. Lee""]","[""Non-convex optimization"", ""Deep Learning""]","Recovery guarantee of stochastic gradient descent with random initialization for learning a two-layer neural network with two hidden nodes, unit-norm weights, ReLU activation functions and Gaussian inputs.",,,,
B16Jem9xe,2017,Invite to Workshop Track,False,Learning in Implicit Generative Models,"[""Shakir Mohamed"", ""Balaji Lakshminarayanan""]","[""Unsupervised Learning""]","Showing connections between GANs, ABC, ratio estimation and other approaches for learning in deep generative models.",,,,
B16_iGWCW,2018,Reject,False,Deep Boosting of Diverse Experts,"[""Wei Zhang"", ""Qiuyu Chen"", ""Jun Yu"", ""Jianping Fan""]","[""boosting learning"", ""deep learning"", ""neural network""]", A deep boosting algorithm is developed to learn more discriminative ensemble classifier by seamlessly combining a set of base deep CNNs.,,,,
B16dGcqlx,2017,Accept (Poster),False,Third Person Imitation Learning,"[""Bradly C Stadie"", ""Pieter Abbeel"", ""Ilya Sutskever""]",[],Agent watches another agent at a different camera angle completing the task and learns via raw pixels how to imitate. ,,,,
B16yEqkCZ,2018,Reject,False,Avoiding Catastrophic States with Intrinsic Fear,"[""Zachary C. Lipton"", ""Kamyar Azizzadenesheli"", ""Abhishek Kumar"", ""Lihong Li"", ""Jianfeng Gao"", ""Li Deng""]","[""reinforcement learning"", ""safe exploration"", ""dqn""]",Shape reward with intrinsic motivation to avoid catastrophic states and mitigate catastrophic forgetting.,,,,
B17JTOe0-,2018,Accept (Poster),False,Emergence of grid-like representations by training recurrent neural networks to perform spatial localization,"[""Christopher J. Cueva"", ""Xue-Xin Wei""]","[""recurrent neural network"", ""grid cell"", ""neural representation of space""]","To our knowledge, this is the first study to show how neural representations of space, including grid-like cells and border cells as observed in the brain, could emerge from training a recurrent neural network to perform navigation tasks.",1803.07770,q-bio.NC,2018-03-21 07:09:57+00:00,2018-03-21 07:09:57+00:00
B184E5qee,2017,Accept (Poster),False,Improving Neural Language Models with a Continuous Cache,"[""Edouard Grave"", ""Armand Joulin"", ""Nicolas Usunier""]","[""Natural language processing""]",,,,,
B186cP9gx,2017,Reject,False,Eigenvalues of the Hessian in Deep Learning: Singularity and Beyond,"[""Levent Sagun"", ""Leon Bottou"", ""Yann LeCun""]","[""Optimization"", ""Deep learning""]","The eigenvalues of the Hessian of loss functions in deep learning have two components: singular bulk at zero that depends on the over-parametrization, and the discrete part that depends on the data.",,,,
B18WgG-CZ,2018,Accept (Poster),False,Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning,"[""Sandeep Subramanian"", ""Adam Trischler"", ""Yoshua Bengio"", ""Christopher J Pal""]","[""distributed sentence representations"", ""multi-task learning""]",A large-scale multi-task learning framework with diverse training objectives to learn fixed-length sentence representations,1804.00079,cs.CL,2018-03-30 23:05:15+00:00,2018-03-30 23:05:15+00:00
B1CNpYg0-,2018,Reject,False,Learning to Compute Word Embeddings On the Fly,"[""Dzmitry Bahdanau"", ""Tom Bosc"", ""Stanis\u0142aw Jastrz\u0119bski"", ""Edward Grefenstette"", ""Pascal Vincent"", ""Yoshua Bengio""]","[""NLU"", ""word embeddings"", ""representation learning""]",We propose a method to deal with rare words by computing their embedding from definitions.,,,,
B1CQGfZ0b,2018,Reject,False,Learning to select examples for program synthesis,"[""Yewen Pu"", ""Zachery Miranda"", ""Armando Solar-Lezama"", ""Leslie Pack Kaelbling""]","[""program synthesis"", ""program induction"", ""example selection""]","In a program synthesis context where the input is a set of examples, we reduce the cost by computing a subset of representative examples",,,,
B1D6ty-A-,2018,Reject,False,Training Autoencoders by Alternating Minimization,"[""Sneha Kudugunta"", ""Adepu Shankar"", ""Surya Chavali"", ""Vineeth Balasubramanian"", ""Purushottam Kar""]","[""Deep Learning"", ""Autoencoders"", ""Alternating Optimization""]",We utilize the alternating minimization principle to provide an effective novel technique to train deep autoencoders.,,,,
B1DmUzWAW,2018,Accept (Poster),False,A Simple Neural Attentive Meta-Learner,"[""Nikhil Mishra"", ""Mostafa Rohaninejad"", ""Xi Chen"", ""Pieter Abbeel""]","[""meta-learning"", ""few-shot learning""]",a simple RNN-based meta-learner that achieves SOTA performance on popular benchmarks,,,,
B1E7Pwqgl,2017,Reject,False,Cooperative Training of Descriptor and Generator Networks,"[""Jianwen Xie"", ""Yang Lu"", ""Ruiqi Gao"", ""Song-Chun Zhu"", ""Ying Nian Wu""]","[""Unsupervised Learning"", ""Deep learning""]",Cooperative training of the descriptor and generator networks by coupling two maximum likelihood learning algorithms.,,,,
B1EA-M-0Z,2018,Accept (Poster),False,Deep Neural Networks as Gaussian Processes,"[""Jaehoon Lee"", ""Yasaman Bahri"", ""Roman Novak"", ""Samuel S. Schoenholz"", ""Jeffrey Pennington"", ""Jascha Sohl-Dickstein""]","[""Gaussian process"", ""Bayesian regression"", ""deep networks"", ""kernel methods""]","We show how to make predictions using deep networks, without training deep networks.",,,,
B1EGg7ZCb,2018,Reject,False,Autonomous Vehicle Fleet Coordination With Deep Reinforcement Learning,"[""Cane Punma""]","[""Deep Reinforcement Learning"", ""mult-agent systems""]",Utilized Deep Reinforcement Learning to teach agents ride-sharing fleet style coordination.,,,,
B1EPYJ-C-,2018,Reject,False,Federated Learning: Strategies for Improving Communication Efficiency,"[""Jakub Kone\u010dn\u00fd"", ""H. Brendan McMahan"", ""Felix X. Yu"", ""Ananda Theertha Suresh"", ""Dave Bacon"", ""Peter Richt\u00e1rik""]",[],,,,,
B1EVwkqTW,2018,Reject,False,Make SVM great again with Siamese kernel for  few-shot learning,"[""Bence Tilk""]","[""SVM"", ""siamese network"", ""one-shot learning"", ""few-shot learning""]","The proposed method is an end-to-end neural SVM, which is optimized for few-shot learning.",,,,
B1EjKsRqtQ,2019,Reject,False,Hierarchical Attention: What Really Counts in Various NLP Tasks,"[""Zehao Dou"", ""Zhihua Zhang""]","[""attention"", ""hierarchical"", ""machine reading comprehension"", ""poem generation""]",The paper proposed a novel hierarchical model to replace the original attention model in various NLP tasks.,,,,
B1ElR4cgg,2017,Accept (Poster),False,Adversarially Learned Inference,"[""Vincent Dumoulin"", ""Ishmael Belghazi"", ""Ben Poole"", ""Alex Lamb"", ""Martin Arjovsky"", ""Olivier Mastropietro"", ""Aaron Courville""]","[""Computer vision"", ""Deep learning"", ""Unsupervised Learning"", ""Semi-Supervised Learning""]",We present and adverserially trained generative model with an inference network. Samples quality is high. Competitive semi-supervised results are achieved.,,,,
B1G5ViAqFm,2019,Accept (Poster),False,Convolutional Neural Networks on Non-uniform Geometrical Signals Using Euclidean Spectral Transformation,"[""Chiyu Max Jiang"", ""Dequan Wang"", ""Jingwei Huang"", ""Philip Marcus"", ""Matthias Niessner""]","[""Non-uniform Fourier Transform"", ""3D Learning"", ""CNN"", ""surface reconstruction""]","We use non-Euclidean Fourier Transformation of shapes defined by a simplicial complex for deep learning, achieving significantly better results than point-based sampling techiques used in current 3D learning literature.",,,,
B1G9doA9F7,2019,Accept (Poster),True,Augmented Cyclic Adversarial Learning for Low Resource Domain Adaptation,"[""Ehsan Hosseini-Asl"", ""Yingbo Zhou"", ""Caiming Xiong"", ""Richard Socher""]","[""Domain adaptation"", ""generative adversarial network"", ""cyclic adversarial learning"", ""speech""]",A new cyclic adversarial learning augmented with auxiliary task model which improves domain adaptation performance in low resource supervised and unsupervised situations ,1807.00374,cs.LG,2018-07-01 19:16:11+00:00,2019-01-23 19:35:27+00:00
B1G9tvcgx,2017,Reject,False,Neural Machine Translation with Latent Semantic of Image and Text,"[""Joji Toyama"", ""Masanori Misono"", ""Masahiro Suzuki"", ""Kotaro Nakayama"", ""Yutaka Matsuo""]",[],,,,,
B1GAUs0cKQ,2019,Accept (Poster),False,Variance Networks: When Expectation Does Not Meet Your Expectations,"[""Kirill Neklyudov"", ""Dmitry Molchanov"", ""Arsenii Ashukha"", ""Dmitry Vetrov""]","[""deep learning"", ""variational inference"", ""variational dropout""]","It is possible to learn a zero-centered Gaussian distribution over the weights of a neural network by learning only variances, and it works surprisingly well.",,,,
B1GHJ3R9tQ,2019,Reject,False,HyperGAN:  Exploring the Manifold of Neural Networks,"[""Neale Ratzlaff"", ""Li  Fuxin""]","[""hypernetworks"", ""generative adversarial networks"", ""anomaly detection""]",We use a GAN to generate parameters of a neural network in one forward pass.,,,,
B1GIB3A9YX,2019,Reject,False,Explicit Recall for Efficient Exploration,"[""Honghua Dong"", ""Jiayuan Mao"", ""Xinyue Cui"", ""Lihong Li""]","[""Exploration"", ""goal-directed"", ""deep reinforcement learning"", ""explicit memory""]",We advocate the use of explicit memory for efficient exploration in reinforcement learning,,,,
B1GIQhCcYm,2019,Reject,False,Unsupervised  one-to-many image translation,"[""Samuel Lavoie-Marchildon"", ""Sebastien Lachapelle"", ""Miko\u0142aj Bi\u0144kowski"", ""Aaron Courville"", ""Yoshua Bengio"", ""R Devon Hjelm""]","[""Image-to-image"", ""Translation"", ""Unsupervised"", ""Generation"", ""Adversarial"", ""Learning""]",We train an image to image translation network that take as input the source image and a sample from a prior distribution to generate a sample from the target distribution,,,,
B1GMDsR5tm,2019,Accept (Poster),False,Initialized Equilibrium Propagation for Backprop-Free Training,"[""Peter O'Connor"", ""Efstratios Gavves"", ""Max Welling""]","[""credit assignment"", ""energy-based models"", ""biologically plausible learning""]",We train a feedforward network without backprop by using an energy-based model to provide local targets,,,,
B1GOWV5eg,2017,Accept (Poster),False,Learning to Repeat: Fine Grained Action Repetition for Deep Reinforcement Learning,"[""Sahil Sharma"", ""Aravind S. Lakshminarayanan"", ""Balaraman Ravindran""]","[""Deep learning"", ""Reinforcement Learning""]",Framework for temporal abstractions in policy space by learning to repeat actions,,,,
B1GSBsRcFX,2019,Reject,False,Stop memorizing: A data-dependent regularization framework for intrinsic pattern learning,"[""Wei Zhu"", ""Qiang Qiu"", ""Bao Wang"", ""Jianfeng Lu"", ""Guillermo Sapiro"", ""Ingrid Daubechies""]","[""deep neural networks"", ""memorizing"", ""data-dependent regularization""]",we propose a new framework for data-dependent DNN regularization that can prevent DNNs from overfitting random data or random labels.,,,,
B1Gi6LeRZ,2018,Accept (Poster),False,Learning from Between-class Examples for Deep Sound Recognition,"[""Yuji Tokozume"", ""Yoshitaka Ushiku"", ""Tatsuya Harada""]","[""sound recognition"", ""supervised learning"", ""feature learning""]",We propose an novel learning method for deep sound recognition named BC learning.,,,,
B1IDRdeCW,2018,Accept (Poster),True,The High-Dimensional Geometry of Binary Neural Networks,"[""Alexander G. Anderson"", ""Cory P. Berg""]","[""Binary Neural Networks"", ""Neural Network Visualization""]",Recent successes of Binary Neural Networks can be understood based on the geometry of high-dimensional binary vectors,1705.07199,cs.LG,2017-05-19 21:33:00+00:00,2017-05-19 21:33:00+00:00
B1Igu2ogg,2017,Accept (Poster),False,Efficient Vector Representation for Documents through Corruption,"[""Minmin Chen""]","[""Natural language processing"", ""Deep learning"", ""Semi-Supervised Learning""]",a simple document representation learning framework that is very efficient to train and test,,,,
B1IzH7cxl,2017,Reject,False,A Neural Stochastic Volatility Model,"[""Rui Luo"", ""Xiaojun Xu"", ""Weinan Zhang"", ""Jun Wang""]","[""Deep learning"", ""Supervised Learning""]",A novel integration of statistical models with recurrent neural networks providing a new way of formulating volatility models.,,,,
B1J_rgWRW,2018,Accept (Poster),False,Understanding Deep Neural Networks with Rectified Linear Units,"[""Raman Arora"", ""Amitabh Basu"", ""Poorya Mianjy"", ""Anirbit Mukherjee""]","[""expressive power"", ""benefits of depth"", ""empirical risk minimization"", ""global optimality"", ""computational hardness"", ""combinatorial optimization""]","This paper 1) characterizes functions representable by ReLU DNNs, 2) formally studies the benefit of depth in such architectures,  3) gives an algorithm to implement empirical risk minimization to global optimality for two layer ReLU nets.",,,,
B1KBHtcel,2017,Reject,False,Here's My Point: Argumentation Mining with Pointer Networks,"[""Peter Potash"", ""Alexey Romanov"", ""Anna Rumshisky""]","[""Natural language processing""]",We use a modified Pointer Network to predict 1) types of argument components; 2) links between argument components.,,,,
B1KFAGWAZ,2018,Reject,False,Revisiting The Master-Slave Architecture In Multi-Agent Deep Reinforcement Learning,"[""Xiangyu Kong"", ""Fangchen Liu"", ""Bo Xin"", ""Yizhou Wang""]","[""Deep Reinforcement Learning"", ""Multi-Agent Reinforcement Learning"", ""StarCraft Micromanagement Tasks""]",We revisit the idea of the master-slave architecture in multi-agent deep reinforcement learning and outperforms state-of-the-arts.,,,,
B1KJJf-R-,2018,Invite to Workshop Track,False,Neural Program Search: Solving Data Processing Tasks from Description and Examples,"[""Illia Polosukhin"", ""Alexander Skidanov""]","[""Deep learning"", ""Structured Prediction"", ""Natural Language Processing"", ""Neural Program Synthesis""]",Program synthesis from natural language description and input / output examples via Tree-Beam Search over Seq2Tree model,,,,
B1Lc-Gb0Z,2018,Accept (Poster),True,Deep Learning as a Mixed Convex-Combinatorial Optimization Problem,"[""Abram L. Friesen"", ""Pedro Domingos""]","[""hard-threshold units"", ""combinatorial optimization"", ""target propagation"", ""straight-through estimation"", ""quantization""]","We learn deep networks of hard-threshold units by setting hidden-unit targets using combinatorial optimization and weights by convex optimization, resulting in improved performance on ImageNet.",1710.11573,cs.LG,2017-10-31 16:42:44+00:00,2018-04-16 20:46:14+00:00
B1M8JF9xx,2017,Accept (Poster),False,On the Quantitative Analysis of Decoder-Based Generative Models,"[""Yuhuai Wu"", ""Yuri Burda"", ""Ruslan Salakhutdinov"", ""Roger Grosse""]","[""Deep learning"", ""Unsupervised Learning""]","We propose to use Annealed Importance Sampling to evaluate decoder-based generative network, and investigate various properties of these models.",,,,
B1M9FjC5FQ,2019,Reject,True,Gradient Acceleration in Activation Functions,"[""Sangchul Hahn"", ""Heeyoul Choi""]","[""Gradient Acceleration"", ""Saturation Areas"", ""Dropout"", ""Coadaptation""]",,1806.09783,cs.LG,2018-06-26 03:43:17+00:00,2019-10-09 06:27:52+00:00
B1MAJhR5YX,2019,Reject,True,Empirical Bounds on Linear Regions of Deep Rectifier Networks,"[""Thiago Serra"", ""Srikumar Ramalingam""]","[""linear regions"", ""approximate model counting"", ""mixed-integer linear programming""]","We provide improved upper bounds for the number of linear regions used in network expressivity, and an highly efficient algorithm (w.r.t. exact counting) to obtain probabilistic lower bounds on the actual number of linear regions.",1810.03370,cs.LG,2018-10-08 11:06:50+00:00,2019-12-14 11:34:01+00:00
B1MB5oRqtQ,2019,Reject,False,On-Policy Trust Region Policy Optimisation with Replay Buffers,"[""Dmitry Kangin"", ""Nicolas Pugeault""]","[""reinforcement learning"", ""on-policy learning"", ""trust region policy optimisation"", ""replay buffer""]",We investigate the theoretical and practical evidence of on-policy reinforcement learning improvement by reusing the data from several consecutive policies.,,,,
B1MIBs05F7,2019,Reject,False,On the Ineffectiveness of Variance Reduced Optimization for Deep Learning,"[""Aaron Defazio""]","[""machine learning"", ""optimization"", ""variance reduction""]",The SVRG method fails on modern deep learning problems,,,,
B1MRcPclx,2017,Accept (Poster),False,Query-Reduction Networks for Question Answering,"[""Minjoon Seo"", ""Sewon Min"", ""Ali Farhadi"", ""Hannaneh Hajishirzi""]","[""Natural language processing"", ""Deep learning""]",,,,,
B1MUroRct7,2019,Reject,False,Online Learning for Supervised Dimension Reduction,"[""Ning Zhang"", ""Qiang Wu""]","[""Online Learning"", ""Supervised Dimension Reduction"", ""Incremental Sliced Inverse Regression"", ""Effective Dimension Reduction Space""]","We proposed two new approaches,  the incremental sliced inverse regression and incremental overlapping sliced inverse regression, to implement supervised dimension reduction in an online learning manner.",,,,
B1MX5j0cFX,2019,Reject,False,Universal Attacks on Equivariant Networks,"[""Amit Deshpande"", ""Sandesh Kamath"", ""K V Subrahmanyam""]","[""adversarial"", ""equivariance"", ""universal"", ""rotation"", ""translation"", ""CNN"", ""GCNN""]",Universal attacks on equivariant networks using a small sample of test data,,,,
B1MXz20cYQ,2019,Accept (Poster),False,Explaining Image Classifiers by Counterfactual Generation,"[""Chun-Hao Chang"", ""Elliot Creager"", ""Anna Goldenberg"", ""David Duvenaud""]","[""Explainability"", ""Interpretability"", ""Generative Models"", ""Saliency Map"", ""Machine Learning"", ""Deep Learning""]","We compute saliency by using a strong generative model to efficiently marginalize over plausible alternative inputs, revealing concentrated pixel areas that preserve label information.",,,,
B1MbDj0ctQ,2019,Reject,False,Switching Linear Dynamics for Variational Bayes Filtering,"[""Philip Becker-Ehmck"", ""Jan Peters"", ""Patrick van der Smagt""]","[""sequence model"", ""switching linear dynamical systems"", ""variational bayes"", ""filter"", ""variational inference"", ""stochastic recurrent neural network""]",A recurrent variational autoencoder with a latent transition function modeled by switching linear dynamical systems.,,,,
B1MhpiRqFm,2019,Reject,False,A Convergent Variant of the Boltzmann Softmax Operator in Reinforcement Learning,"[""Ling Pan"", ""Qingpeng Cai"", ""Qi Meng"", ""Wei Chen"", ""Tie-Yan Liu""]","[""Reinforcement Learning"", ""Boltzmann Softmax Operator"", ""Value Function Estimation""]",,,,,
B1NGT8xCZ,2018,Reject,False,Principled Hybrids of Generative and Discriminative Domain Adaptation,"[""Han Zhao"", ""Zhenyao Zhu"", ""Junjie Hu"", ""Adam Coates"", ""Geoff Gordon""]","[""domain adaptation"", ""neural networks"", ""generative models"", ""discriminative models""]",,,,,
B1NOXfWR-,2018,Reject,False,Neural Task Graph Execution,"[""Sungryull Sohn"", ""Junhyuk Oh"", ""Honglak Lee""]","[""deep reinforcement learning"", ""task execution"", ""instruction execution""]",,,,,
B1PA8fqeg,2017,Reject,False,Multiagent System for Layer Free Network,"[""Hiroki Kurotaki"", ""Kotaro Nakayama"", ""Yutaka Matsuo""]",[],We propose a multiagent system that have feed-forward networks as its subset but free from layer scheme.,,,,
B1QRgziT-,2018,Accept (Oral),False,Spectral Normalization for Generative Adversarial Networks,"[""Takeru Miyato"", ""Toshiki Kataoka"", ""Masanori Koyama"", ""Yuichi Yoshida""]","[""Generative Adversarial Networks"", ""Deep Generative Models"", ""Unsupervised Learning""]",We propose a novel weight normalization technique called spectral normalization to stabilize the training of the discriminator of GANs.,1802.05957,cs.LG,2018-02-16 14:41:39+00:00,2018-02-16 14:41:39+00:00
B1QgVti6Z,2018,Accept (Poster),True,Empirical Risk Landscape Analysis for Understanding Deep Neural Networks,"[""Pan Zhou"", ""Jiashi Feng""]","[""Deep Learning Analysis"", ""Deep Learning Theory"", ""Empirical Risk"", ""Landscape Analysis"", ""Nonconvex Optimization""]",,1705.07038,stat.ML,2017-05-19 15:07:07+00:00,2017-08-05 12:30:25+00:00
B1TTpYKgx,2017,Reject,False,On the Expressive Power of Deep Neural Networks,"[""Maithra Raghu"", ""Ben Poole"", ""Jon Kleinberg"", ""Surya Ganguli"", ""Jascha Sohl-Dickstein""]","[""Theory"", ""Deep learning""]","Derives and explains the exponential depth sensitivity of different expressivity measures for deep neural networks, and explores consequences during and after training. ",,,,
B1VWtsA5tQ,2019,Reject,False,PPO-CMA: Proximal Policy Optimization with Covariance Matrix Adaptation,"[""Perttu H\u00e4m\u00e4l\u00e4inen"", ""Amin Babadi"", ""Xiaoxiao Ma"", ""Jaakko Lehtinen""]","[""Continuous Control"", ""Reinforcement Learning"", ""Policy Optimization"", ""Policy Gradient"", ""Evolution Strategies"", ""CMA-ES"", ""PPO""]",We propose a new continuous control reinforcement learning method with a variance adaptation strategy inspired by the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) optimization method,,,,
B1VZqjAcYX,2019,Accept (Poster),False,SNIP: SINGLE-SHOT NETWORK PRUNING BASED ON CONNECTION SENSITIVITY,"[""Namhoon Lee"", ""Thalaiyasingam Ajanthan"", ""Philip Torr""]","[""neural network pruning"", ""connection sensitivity""]","We present a new approach, SNIP, that is simple, versatile and interpretable; it prunes irrelevant connections for a given task at single-shot prior to training and is applicable to a variety of neural network models without modifications.",,,,
B1X0mzZCW,2018,Accept (Poster),False,Fidelity-Weighted Learning,"[""Mostafa Dehghani"", ""Arash Mehrjou"", ""Stephan Gouws"", ""Jaap Kamps"", ""Bernhard Sch\u00f6lkopf""]","[""fidelity-weighted learning"", ""semisupervised learning"", ""weakly-labeled data"", ""teacher-student""]","We propose Fidelity-weighted Learning, a semi-supervised teacher-student approach for training neural networks using weakly-labeled data.",,,,
B1X4DWWRb,2018,Reject,False,Learning Weighted Representations for Generalization Across Designs,"[""Fredrik D. Johansson"", ""Nathan Kallus"", ""Uri Shalit"", ""David Sontag""]","[""Distributional shift"", ""causal effects"", ""domain adaptation""]","A theory and algorithmic framework for prediction under distributional shift, including causal effect estimation and domain adaptation",,,,
B1YfAfcgl,2017,Accept (Poster),False,Entropy-SGD: Biasing Gradient Descent Into Wide Valleys,"[""Pratik Chaudhari"", ""Anna Choromanska"", ""Stefano Soatto"", ""Yann LeCun"", ""Carlo Baldassi"", ""Christian Borgs"", ""Jennifer Chayes"", ""Levent Sagun"", ""Riccardo Zecchina""]","[""Deep learning"", ""Optimization""]",This paper focuses on developing new optimization tools for deep learning that are tailored to exploit the local geometric properties of the objective function.,,,,
B1Yy1BxCZ,2018,Accept (Poster),False,"Don't Decay the Learning Rate, Increase the Batch Size","[""Samuel L. Smith"", ""Pieter-Jan Kindermans"", ""Chris Ying"", ""Quoc V. Le""]","[""batch size"", ""learning rate"", ""simulated annealing"", ""large batch training"", ""scaling rules"", ""stochastic gradient descent"", ""sgd"", ""imagenet"", ""optimization""]",Decaying the learning rate and increasing the batch size during training are equivalent.,,,,
B1Z3W-b0W,2018,Invite to Workshop Track,False,Learning to Infer,"[""Joseph Marino"", ""Yisong Yue"", ""Stephan Mandt""]","[""Bayesian Deep Learning"", ""Amortized Inference"", ""Variational Auto-Encoders"", ""Learning to Learn""]",We propose a new class of inference models that iteratively encode gradients to estimate approximate posterior distributions.,,,,
B1ZXuTolx,2017,Reject,False,Revisiting Denoising Auto-Encoders,"[""Luis Gonzalo Sanchez Giraldo""]",[],Modified objective for denoising autoencoders with explicit robustness in the encoding.,,,,
B1ZZTfZAW,2018,Reject,False,Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs,"[""Stephanie Hyland"", ""Crist\u00f3bal Esteban"", ""Gunnar R\u00e4tsch""]","[""GAN"", ""medical"", ""records"", ""time"", ""series"", ""generation"", ""privacy""]","Conditional recurrent GANs for real-valued medical sequences generation, showing novel evaluation approaches and an empirical privacy analysis.",,,,
B1ZvaaeAZ,2018,Accept (Poster),True,WRPN: Wide Reduced-Precision Networks,"[""Asit Mishra"", ""Eriko Nurvitadhi"", ""Jeffrey J Cook"", ""Debbie Marr""]","[""Low precision"", ""binary"", ""ternary"", ""4-bits networks""]","Lowering precision (to 4-bits, 2-bits and even binary) and widening the filter banks gives as accurate network as those obtained with FP32 weights and activations.",1709.01134,cs.CV,2017-09-04 19:56:48+00:00,2017-09-04 19:56:48+00:00
B1ae1lZRb,2018,Accept (Poster),False,Apprentice: Using Knowledge Distillation Techniques To Improve Low-Precision Network Accuracy,"[""Asit Mishra"", ""Debbie Marr""]","[""Ternary"", ""4-bits"", ""low precision"", ""knowledge distillation"", ""knowledge transfer"", ""model compression""]",We show that knowledge transfer techniques can improve the accuracy of low precision networks and set new state-of-the-art accuracy for ternary and 4-bits precision. ,,,,
B1akgy9xx,2017,Reject,False,Making Stochastic Neural Networks from Deterministic Ones,"[""Kimin Lee"", ""Jaehyung Kim"", ""Song Chong"", ""Jinwoo Shin""]","[""Deep learning"", ""Multi-modal learning"", ""Structured prediction""]",,,,,
B1al7jg0b,2018,Accept (Poster),False,Overcoming Catastrophic Interference using Conceptor-Aided Backpropagation,"[""Xu He"", ""Herbert Jaeger""]","[""Catastrophic Interference"", ""Conceptor"", ""Backpropagation"", ""Continual Learning"", ""Lifelong Learning""]","We propose a variant of the backpropagation algorithm, in which gradients are shielded by conceptors against degradation of previously learned tasks.",,,,
B1bgpzZAZ,2018,Reject,False,ElimiNet: A Model for Eliminating Options for Reading Comprehension with Multiple Choice Questions,"[""Soham Parikh"", ""Ananya Sai"", ""Preksha Nema"", ""Mitesh M Khapra""]","[""Reading Comprehension"", ""Answering Multiple Choice Questions""]",A model combining elimination and selection for answering multiple choice questions,,,,
B1ckMDqlg,2017,Accept (Poster),False, Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer,"[""Noam Shazeer"", ""*Azalia Mirhoseini"", ""*Krzysztof Maziarz"", ""Andy Davis"", ""Quoc Le"", ""Geoffrey Hinton"", ""Jeff Dean""]","[""Deep learning""]",,,,,
B1e-kxSKDH,2020,Accept (Poster),True,Structured Object-Aware Physics Prediction for Video Modeling and Planning,"[""Jannik Kossen"", ""Karl Stelzner"", ""Marcel Hussing"", ""Claas Voelcker"", ""Kristian Kersting""]","[""self-supervised learning"", ""probabilistic deep learning"", ""structured models"", ""video prediction"", ""physics prediction"", ""planning"", ""variational auteoncoders"", ""model-based reinforcement learning"", ""VAEs"", ""unsupervised"", ""variational"", ""graph neural networks"", ""tractable probabilistic models"", ""attend-infer-repeat"", ""relational learning"", ""AIR"", ""sum-product networks"", ""object-oriented"", ""object-centric"", ""object-aware"", ""MCTS""]","We propose a structured object-aware video prediction model, which explicitly reasons about objects and demonstrate that it provides high-quality long term video predictions for planning.",1910.02425,cs.LG,2019-10-06 11:48:26+00:00,2020-02-12 09:38:20+00:00
B1e0KsRcYQ,2019,Reject,False,Efficient Codebook and Factorization for Second Order Representation Learning,"[""Pierre jacob"", ""David Picard"", ""Aymeric Histace"", ""Edouard Klein""]","[""Second order pooling""]",We propose a joint codebook and factorization scheme to improve second order pooling.,,,,
B1e0X3C9tQ,2019,Accept (Poster),False,Diagnosing and Enhancing VAE Models,"[""Bin Dai"", ""David Wipf""]","[""variational autoencoder"", ""generative models""]",We closely analyze the VAE objective function and draw novel conclusions that lead to simple enhancements.,,,,
B1e3OlStPB,2020,Accept (Spotlight),False,DeepSphere: a graph-based spherical CNN,"[""Micha\u00ebl Defferrard"", ""Martino Milani"", ""Fr\u00e9d\u00e9rick Gusset"", ""Nathana\u00ebl Perraudin""]","[""spherical cnns"", ""graph neural networks"", ""geometric deep learning""]",A graph-based spherical CNN that strikes an interesting balance of trade-offs for a wide variety of applications.,2012.15000,cs.LG,2020-12-30 01:35:27+00:00,2020-12-30 01:35:27+00:00
B1e4wo09K7,2019,Reject,False,Invariant-equivariant representation learning for multi-class data,"[""Ilya Feige""]","[""representation learning"", ""semantic representations"", ""local vs global information"", ""latent variable modelling"", ""generative modelling"", ""semi-supervised learning"", ""variational autoencoders.""]",This paper presents a novel latent-variable generative modelling technique that enables the representation of global information into one latent variable and local information into another latent variable.,,,,
B1e5TA4FPr,2020,Reject,False,Pareto Optimality in No-Harm Fairness,"[""Natalia Martinez"", ""Martin Bertran"", ""Guillermo Sapiro""]","[""Fairness"", ""Fairness in Machine Learning"", ""No-Harm Fairness""]","We propose a method to reduce risk disparity gaps between sensitive groups in classification and regression tasks following the no unnecessary harm principle, ensuring that tradeoffs are minimally costly to any subgroup",,,,
B1e5ef-C-,2018,Accept (Poster),False,"A Compressed Sensing View of Unsupervised Text Embeddings, Bag-of-n-Grams, and LSTMs","[""Sanjeev Arora"", ""Mikhail Khodak"", ""Nikunj Saunshi"", ""Kiran Vodrahalli""]","[""theory"", ""LSTM"", ""unsupervised learning"", ""word embeddings"", ""compressed sensing"", ""sparse recovery"", ""document representation"", ""text classification""]",We use the theory of compressed sensing to prove that LSTMs can do at least as well on linear text classification as Bag-of-n-Grams.,,,,
B1e7hs05Km,2019,Reject,False,Efficient Exploration through Bayesian Deep Q-Networks,"[""Kamyar Azizzadenesheli"", ""Animashree Anandkumar""]","[""Deep RL"", ""Exploration Exploitation"", ""DQN"", ""Bayesian Regret"", ""Thompson Sampling""]","Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound",,,,
B1e8CsRctX,2019,Reject,False,Generative Ensembles for Robust Anomaly Detection,"[""Hyunsun Choi"", ""Eric Jang""]","[""Anomaly Detection"", ""Uncertainty"", ""Out-of-Distribution"", ""Generative Models""]","We use generative models to perform out-of-distribution detection, and improve their robustness with uncertainty estimation.",,,,
B1e9W3AqFX,2019,Reject,False,Multi-task Learning with Gradient Communication,"[""Pengfei Liu"", ""Xuanjing Huang""]","[""Pretend to share"", ""Gradient Communication""]","We introduce an inductive bias for multi-task learning, allowing different tasks to communicate by gradient passing.",,,,
B1e9Y2NYvS,2020,Accept (Spotlight),False,On Robustness of Neural Ordinary Differential Equations,"[""Hanshu YAN"", ""Jiawei DU"", ""Vincent TAN"", ""Jiashi FENG""]","[""Neural ODE""]",,,,,
B1e9csRcFm,2019,Reject,False,The Importance of Norm Regularization in Linear Graph Embedding: Theoretical Analysis and Empirical Demonstration,"[""Yihan Gao"", ""Chao Zhang"", ""Jian Peng"", ""Aditya Parameswaran""]","[""Graph Embedding"", ""Generalization Analysis"", ""Matrix Factorization""]",We argue that the generalization of linear graph embedding is not due to the dimensionality constraint but rather the small norm of embedding vectors.,,,,
B1eB5xSFvr,2020,Accept (Poster),False,DiffTaichi: Differentiable Programming for Physical Simulation,"[""Yuanming Hu"", ""Luke Anderson"", ""Tzu-Mao Li"", ""Qi Sun"", ""Nathan Carr"", ""Jonathan Ragan-Kelley"", ""Fredo Durand""]","[""Differentiable programming"", ""robotics"", ""optimal control"", ""physical simulation"", ""machine learning system""]","We study the problem of learning and optimizing through physical simulations via differentiable programming, using our proposed DiffSim programming language and compiler.",,,,
B1eBoJStwr,2020,Reject,False,"Semi-supervised semantic segmentation needs strong, high-dimensional perturbations","[""Geoff French"", ""Timo Aila"", ""Samuli Laine"", ""Michal Mackiewicz"", ""Graham Finlayson""]","[""computer vision"", ""semantic segmentation"", ""semi-supervised"", ""consistency regularisation""]",Why semi-supervised semantic segmentation is a challenging problem (no cluster assumption) and how to get consistency regularisation to work,,,,
B1eCCoR5tm,2019,Reject,False,Pseudosaccades: A simple ensemble scheme for improving classification performance of deep nets,"[""Jin Sean Lim"", ""Robert John Durrant""]","[""Ensemble classification"", ""random subspace"", ""data sketching""]","Inspired by saccades we describe a simple, cheap, effective way to improve deep net performance on an image labelling task.",,,,
B1eCk1StPH,2020,Reject,True,The Generalization-Stability Tradeoff in Neural Network Pruning,"[""Brian R. Bartoldson"", ""Ari S. Morcos"", ""Adrian Barbu"", ""Gordon Erlebacher""]","[""pruning"", ""generalization"", ""stability"", ""dynamics"", ""regularization""]","We demonstrate that pruning methods which introduce greater instability into the loss also confer improved generalization, and explore the mechanisms underlying this effect.",1906.03728,cs.LG,2019-06-09 22:35:00+00:00,2020-10-22 22:24:16+00:00
B1eEKi0qYQ,2019,Reject,False,Interactive Parallel Exploration for Reinforcement Learning in Continuous Action Spaces,"[""Whiyoung Jung"", ""Giseung Park"", ""Youngchul Sung""]","[""reinforcement learning"", ""continuous action space RL""]",,,,,
B1eKk2CcKm,2019,Reject,False,Towards the Latent Transcriptome,"[""Assya Trofimov"", ""Francis Dutil"", ""Claude Perreault"", ""Sebastien Lemieux"", ""Yoshua Bengio"", ""Joseph Paul Cohen""]","[""representation learning"", ""RNA-Seq"", ""gene expression"", ""bioinformatics"", ""computational biology"", ""transcriptomics"", ""deep learning"", ""genomics""]",,,,,
B1eO9oA5Km,2019,Reject,False,A Guider Network for Multi-Dual Learning,"[""Wenpeng Hu"", ""Zhengwei Tao"", ""Zhanxing Zhu"", ""Bing Liu"", ""Zhou Lin"", ""Jinwen Ma"", ""Dongyan Zhao"", ""Rui Yan""]",[],,,,,
B1eP504YDr,2020,Reject,False,Independence-aware Advantage Estimation,"[""Pushi Zhang"", ""Li Zhao"", ""Guoqing Liu"", ""Jiang Bian"", ""Minglie Huang"", ""Tao Qin"", ""Tie-Yan Liu""]","[""Reinforcement Learning"", ""Advantage Estimation""]",,,,,
B1ePui0ctQ,2019,Reject,False,SnapQuant: A Probabilistic and Nested Parameterization for Binary Networks,"[""Kuan Wang"", ""Hao Zhao"", ""Anbang Yao"", ""Aojun Zhou"", ""Dawei Sun"", ""Yurong Chen""]","[""Binary weight networks"", ""neural network quantization"", ""reinforcement learning""]","We propose SnapQuant, a reinforcement learning method for training binary weight networks from scratch under the Bayesian deep learning perspective, which approximates the posterior distribution of binary weights instead of a single point estimation.",,,,
B1eQcCEtDB,2020,Reject,False,"Calibration, Entropy Rates, and Memory in Language Models","[""Mark Braverman"", ""Xinyi Chen"", ""Sham Kakade"", ""Karthik Narasimhan"", ""Cyril Zhang"", ""Yi Zhang""]","[""information theory"", ""natural language processing"", ""calibration""]",,,,,
B1eSg3C9Ym,2019,Reject,False,MEAN-FIELD ANALYSIS OF BATCH NORMALIZATION,"[""Mingwei Wei"", ""James Stokes"", ""David J Schwab""]","[""neural networks"", ""optimization"", ""batch normalization"", ""mean field theory"", ""Fisher information""]",,,,,
B1eWOJHKvB,2020,Accept (Poster),False,Kernel of CycleGAN as a principal homogeneous space,"[""Nikita Moriakov"", ""Jonas Adler"", ""Jonas Teuwen""]","[""Generative models"", ""CycleGAN""]","The space of approximate solutions of CycleGAN admits a lot of symmetry, and an identity loss does not fix this.",2001.09061,cs.LG,2020-01-24 15:47:12+00:00,2020-01-24 15:47:12+00:00
B1eWbxStPH,2020,Accept (Spotlight),False,Directional Message Passing for Molecular Graphs,"[""Johannes Klicpera"", ""Janek Gro\u00df"", ""Stephan G\u00fcnnemann""]","[""GNN"", ""Graph neural network"", ""message passing"", ""graphs"", ""equivariance"", ""molecules""]",Directional message passing incorporates spatial directional information to improve graph neural networks.,2003.03123,cs.LG,2020-03-06 10:30:17+00:00,2020-03-06 10:30:17+00:00
B1eX_a4twH,2020,Reject,False,Superseding Model Scaling by Penalizing Dead Units and Points with Separation Constraints,"[""Carles Riera"", ""Camilo Rey-Torres"", ""Eloi Puertas"", ""Oriol Pujol""]","[""Dead Point"", ""Dead Unit"", ""Model Scaling"", ""Separation Constraints"", ""Dying ReLU"", ""Constant Width"", ""Deep Neural Networks"", ""Backpropagation""]",We propose using a set of constraints to penalize dead neurons and points in order to train very deep networks of constant width.,,,,
B1eXbn05t7,2019,Reject,False,Open-Ended Content-Style Recombination Via Leakage Filtering,"[""Karl Ridgeway"", ""Michael C. Mozer""]",[],,,,,
B1eXvyHKwS,2020,Reject,False,THE EFFECT OF ADVERSARIAL TRAINING: A THEORETICAL CHARACTERIZATION,"[""Mingyang Yi"", ""Huishuai Zhang"", ""Wei Chen"", ""Zhi-Ming Ma"", ""Tie-Yan Liu""]","[""adversarial training"", ""robustness"", ""separable data""]","We prove adversarial training within linear classifier can rapidly converge to a robust solution. In addition, adversarial training is stable to outliers in dataset.  ",,,,
B1eXygBFPH,2020,Reject,True,Attacking Graph Convolutional Networks via Rewiring,"[""Yao Ma"", ""Suhang Wang"", ""Tyler Derr"", ""Lingfei Wu"", ""Jiliang Tang""]","[""Graph Neural Networks"", ""Rewiring"", ""Adversarial Attacks""]",Using rewiring operation to conduct adversarial attacks on graph structured data.,1906.03750,cs.LG,2019-06-10 01:00:07+00:00,2019-09-28 21:58:52+00:00
B1eY_pVYvB,2020,Accept (Poster),False,Efficient and Information-Preserving Future Frame Prediction and Beyond,"[""Wei Yu"", ""Yichao Lu"", ""Steve Easterbrook"", ""Sanja Fidler""]","[""self-supervised learning"", ""generative pre-training"", ""video prediction"", ""reversible architecture""]",,,,,
B1eYlgBYPH,2020,Reject,False,A Deep Recurrent Neural Network via Unfolding Reweighted l1-l1 Minimization,"[""Huynh Van Luong"", ""Duy Hung Le"", ""Nikos Deligiannis""]",[],,,,,
B1eZRiC9YX,2019,Reject,False,Sufficient Conditions for Robustness to Adversarial Examples: a Theoretical and Empirical Study with Bayesian Neural Networks,"[""Yarin Gal"", ""Lewis Smith""]","[""Bayesian deep learning"", ""Bayesian neural networks"", ""adversarial examples""]","We prove that idealised Bayesian neural networks can have no adversarial examples, and give empirical evidence with real-world BNNs.",,,,
B1eZYkHYPS,2020,Reject,False,Shifted Randomized Singular Value Decomposition,"[""Ali Basirat""]","[""SVD"", ""PCA"", ""Randomized Algorithms""]",A randomized algorithm to estimate the SVD of a shifted data matrix without explicitly constructing the matrix in the memory.,1911.11772,stat.ML,2019-11-26 14:38:42+00:00,2019-11-28 12:12:23+00:00
B1eZweHFwr,2020,Reject,False,Statistical Verification of General Perturbations by Gaussian Smoothing,"[""Marc Fischer"", ""Maximilian Baader"", ""Martin Vechev""]","[""adversarial robustness"", ""certified network"", ""randomised smoothing"", ""geometric perturbations""]","We present a statistical certification method to certify robustness for rotations, translations and other transformations.",,,,
B1ecVlrtDr,2020,Reject,False,Symmetric-APL Activations: Training Insights and Robustness to Adversarial Attacks,"[""Mohammadamin Tavakoli"", ""Forest Agostinelli"", ""Pierre Baldi""]","[""Activation function"", ""Adaptive"", ""Training"", ""Robustness"", ""Adversarial attack""]",Symmetric Adaptive Piecewise Linear activations are proposed as new activation function with deep explanation on training behavior and robustness to adversarial attacks.,,,,
B1edvs05Y7,2019,Reject,False,Sparse Binary Compression: Towards Distributed Deep Learning with minimal Communication,"[""Felix Sattler"", ""Simon Wiedemann"", ""Klaus-Robert M\u00fcller"", ""Wojciech Samek""]",[],,,,,
B1eiJyrtDB,2020,Reject,False,Improved Generalization Bound of Permutation Invariant Deep Neural Networks,"[""Akiyoshi Sannai"", ""Masaaki Imaizumi""]","[""Deep Neural Network"", ""Invariance"", ""Symmetry"", ""Group"", ""Generalization""]",We theoretically prove that a permutation invariant property of deep neural networks largely improves its generalization performance.,,,,
B1eibJrtwr,2020,Reject,True,Abstractive Dialog Summarization with Semantic Scaffolds,"[""Lin Yuan"", ""Zhou Yu""]","[""Abstractive Summarization"", ""Dialog"", ""Multi-task Learning""]",We propose a novel end-to-end model (SPNet) to incorporate semantic scaffolds for improving abstractive dialog summarization.,1910.00825,cs.CL,2019-10-02 08:22:03+00:00,2019-10-02 08:22:03+00:00
B1elCp4KwH,2020,Accept (Talk),False,Learning Hierarchical Discrete Linguistic Units from Visually-Grounded Speech,"[""David Harwath*"", ""Wei-Ning Hsu*"", ""James Glass""]","[""visually-grounded speech"", ""self-supervised learning"", ""discrete representation learning"", ""vision and language"", ""vision and speech"", ""hierarchical representation learning""]","Vector quantization layers incorporated into a self-supervised neural model of speech audio learn hierarchical and discrete linguistic units (phone-like, word-like) when trained with a visual-grounding objective. ",,,,
B1elqkrKPH,2020,Reject,False,Learning robust visual representations using data augmentation invariance,"[""Alex Hernandez-Garcia"", ""Peter K\u00f6nig"", ""Tim C. Kietzmann""]","[""deep neural networks"", ""visual cortex"", ""invariance"", ""data augmentation""]","We propose data augmentation invariance: a simple, yet effective and efficient way of learning robust features by adding a layer-wise invariance objective in the loss function.",,,,
B1em8TVtPr,2020,Reject,True,Discourse-Based Evaluation of Language Understanding,"[""Damien Sileo"", ""Tim Van-De-Cruys"", ""Camille Pradel"", ""Philippe Muller""]","[""Natural Language Understanding"", ""Pragmatics"", ""Discourse"", ""Semantics"", ""Evaluation"", ""BERT"", ""Natural Language Processing""]",Semantics is not all you need,1907.08672,cs.CL,2019-07-19 20:09:03+00:00,2019-07-19 20:09:03+00:00
B1em9h4KDS,2020,Reject,False,Generative Imputation and Stochastic Prediction,"[""Mohammad Kachuee"", ""Kimmo K\u00e4rkk\u00e4inen"", ""Orpaz Goldstein"", ""Sajad Darabi"", ""Majid Sarrafzadeh""]",[],A method to generate imputations and measure uncertainties over target class assignments based on incomplete feature vectors,,,,
B1eoyAVFwH,2020,Reject,True,Feature Partitioning for Efficient Multi-Task Architectures,"[""Alejandro Newell"", ""Lu Jiang"", ""Chong Wang"", ""Li-Jia Li"", ""Jia Deng""]","[""multi-task learning"", ""neural architecture search"", ""multi-task architecture search""]",automatic search for multi-task architectures that reduce per-task feature use,1908.04339,cs.LG,2019-08-12 19:06:32+00:00,2019-08-12 19:06:32+00:00
B1epooR5FX,2019,Reject,False,Predicted Variables in Programming,"[""Victor Carbune"", ""Thierry Coppey"", ""Alexander Daryin"", ""Thomas Deselaers"", ""Nikhil Sarda"", ""Jay Yagnik""]","[""predicted variables"", ""machine learning"", ""programming"", ""computing systems"", ""reinforcement learning""]","We present Predicted Variables, an approach to making machine learning a first class citizen in programming languages.",,,,
B1erJJrYPH,2020,Reject,False,Optimizing Loss Landscape Connectivity via Neuron Alignment,"[""N. Joseph Tatro"", ""Pin-Yu Chen"", ""Payel Das"", ""Igor Melnyk"", ""Prasanna Sattigeri"", ""Rongjie Lai""]","[""deep learning"", ""optimization"", ""non-convex optimization""]",We investigate the effect of weight symmetry on the loss landscape of deep networks. ,2009.02439,cs.LG,2020-09-05 02:25:23+00:00,2020-11-02 23:56:40+00:00
B1esx6EYvr,2020,Accept (Poster),False,"A critical analysis of self-supervision, or what we can learn from a single image","[""Asano YM."", ""Rupprecht C."", ""Vedaldi A.""]","[""self-supervision"", ""feature representation learning"", ""CNN""]",We evaluate self-supervised feature learning methods and find that with sufficient data augmentation early layers can be learned using just one image.  This is informative about self-supervision and the role of augmentations.,,,,
B1esygHFwS,2020,Reject,False,Detecting Change in Seasonal Pattern via Autoencoder and Temporal Regularization,"[""Raphael Fettaya"", ""Dor Bank"", ""Rachel Lemberg"", ""Linoy Barel""]","[""Autoencoder"", ""Change Point Detection"", ""Timeseries""]",,,,,
B1ethsR9Ym,2019,Reject,False,"Look Ma, No GANs! Image Transformation with ModifAE","[""Chad Atalla"", ""Bartholomew Tam"", ""Amanda Song"", ""Gary Cottrell""]","[""Computer Vision"", ""Deep Learning"", ""Autoencoder"", ""GAN"", ""Image Modification"", ""Social Traits"", ""Social Psychology""]","ModifAE is a standalone neural network, trained exclusively on an autoencoding task, that implicitly learns to make image modifications (without GANs).",,,,
B1euhoAcKX,2019,Reject,False,DppNet: Approximating Determinantal Point Processes with Deep Networks,"[""Zelda Mariet"", ""Jasper Snoek"", ""Yaniv Ovadia""]","[""dpp"", ""submodularity"", ""determinant""]",We approximate Determinantal Point Processes with neural nets; we justify our model theoretically and empirically.,,,,
B1evfa4tPB,2020,Accept (Talk),False,Neural Network Branching for Neural Network Verification ,"[""Jingyue Lu"", ""M. Pawan Kumar""]","[""Neural Network Verification"", ""Branch and Bound"", ""Graph Neural Network"", ""Learning to branch""]",We propose a novel learning to branch framework using graph neural networks to improve branch and bound based neural network verification methods. ,1912.01329,cs.LG,2019-12-03 12:12:29+00:00,2019-12-03 12:12:29+00:00
B1ewdt9xe,2017,Accept (Poster),False,Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning,"[""William Lotter"", ""Gabriel Kreiman"", ""David Cox""]",[],,,,,
B1excoAqKQ,2019,Reject,False,What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning,"[""Siddharth Reddy"", ""Anca D. Dragan"", ""Sergey Levine""]","[""imitation learning"", ""reinforcement learning""]","We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.",,,,
B1exrnCcF7,2019,Accept (Poster),False,Disjoint Mapping Network for Cross-modal Matching of Voices and Faces,"[""Yandong Wen"", ""Mahmoud Al Ismail"", ""Weiyang Liu"", ""Bhiksha Raj"", ""Rita Singh""]","[""cross-modal matching"", ""voices"", ""faces""]",,,,,
B1eyA3VFwS,2020,Reject,False,Enforcing Physical Constraints in Neural Neural Networks through Differentiable PDE Layer,"[""Chiyu \""Max\"" Jiang"", ""Karthik Kashinath"", ""Prabhat"", ""Philip Marcus""]","[""PDE"", ""Hard Constraints"", ""Turbulence"", ""Super-Resolution"", ""Spectral Methods""]",A novel way of enforcing hard linear constraints within a convolutional neural network using a differentiable PDE layer.,,,,
B1eyO1BFPr,2020,Accept (Poster),True,"Don't Use Large Mini-batches, Use Local SGD","[""Tao Lin"", ""Sebastian U. Stich"", ""Kumar Kshitij Patel"", ""Martin Jaggi""]",[],,1808.07217,cs.LG,2018-08-22 04:50:55+00:00,2020-02-17 11:42:10+00:00
B1fA3oActQ,2019,Reject,False,GraphSeq2Seq: Graph-Sequence-to-Sequence for Neural Machine Translation,"[""Guoshuai Zhao"", ""Jun Li"", ""Lu Wang"", ""Xueming Qian"", ""Yun Fu""]","[""Neural Machine Translation"", ""Natural Language Generation"", ""Graph Embedding"", ""LSTM""]",Graph-Sequence-to-Sequence for Neural Machine Translation,,,,
B1fPYj0qt7,2019,Reject,False,Riemannian Stochastic Gradient Descent for Tensor-Train Recurrent Neural Networks,"[""Jun Qi"", ""Chin-Hui Lee"", ""Javier Tejedor""]","[""Riemannian Stochastic Gradient Descent"", ""Tensor-Train"", ""Recurrent Neural Networks""]",Applying the Riemannian SGD (RSGD) algorithm for training Tensor-Train RNNs to further reduce model parameters.,,,,
B1fbosCcYm,2019,Reject,False,A Biologically Inspired Visual Working Memory for Deep Networks,"[""Ethan Harris"", ""Mahesan Niranjan"", ""Jonathon Hare""]","[""memory"", ""visual attention"", ""image classification"", ""image reconstruction"", ""latent representations""]",A biologically inspired working memory that can be integrated in recurrent visual attention models for state of the art performance,,,,
B1ffQnRcKX,2019,Accept (Poster),False,Automatically Composing Representation Transformations as a Means for Generalization,"[""Michael Chang"", ""Abhishek Gupta"", ""Sergey Levine"", ""Thomas L. Griffiths""]","[""compositionality"", ""deep learning"", ""metareasoning""]",We explore the problem of compositional generalization and propose a means for endowing neural network architectures with the ability to compose themselves to solve these problems.,,,,
B1fpDsAqt7,2019,Accept (Poster),True,Visual Reasoning by Progressive Module Networks,"[""Seung Wook Kim"", ""Makarand Tapaswi"", ""Sanja Fidler""]",[],,1806.02453,cs.CV,2018-06-06 23:02:35+00:00,2018-09-27 18:09:38+00:00
B1fysiAqK7,2019,Reject,False,Probabilistic Binary Neural Networks,"[""Jorn W.T. Peters"", ""Tim Genewein"", ""Max Welling""]","[""binary neural Network"", ""efficient deep learning"", ""stochastic training"", ""discrete neural network"", ""efficient inference""]",We introduce a stochastic training method for training Binary Neural Network with both binary weights and activations.,,,,
B1g-X3RqKm,2019,Reject,False,A Proposed Hierarchy of Deep Learning Tasks,"[""Joel Hestness"", ""Sharan Narang"", ""Newsha Ardalani"", ""Heewoo Jun"", ""Hassan Kianinejad"", ""Md. Mostofa Ali Patwary"", ""Yang Yang"", ""Yanqi Zhou"", ""Gregory Diamos"", ""Kenneth Church""]","[""Deep learning"", ""scaling with data"", ""computational complexity"", ""learning curves"", ""speech recognition"", ""image recognition"", ""machine translation"", ""language modeling""]","We use 50 GPU years of compute time to study how deep learning scales with more data, and propose a new way to organize the space of problems by difficulty.",,,,
B1g29oAqtm,2019,Reject,False,Understanding the Asymptotic Performance of Model-Based RL Methods,"[""William Whitney"", ""Rob Fergus""]","[""model-based reinforcement learning"", ""mbrl"", ""reinforcement learning"", ""predictive models"", ""predictive learning"", ""forward models"", ""deep learning""]","Long-term prediction accuracy limits the performance of model-based RL, and can be improved with a simple change to the form of the model.",,,,
B1g30j0qF7,2019,Accept (Poster),False,Bayesian Deep Convolutional Networks with Many Channels are Gaussian Processes,"[""Roman Novak"", ""Lechao Xiao"", ""Yasaman Bahri"", ""Jaehoon Lee"", ""Greg Yang"", ""Jiri Hron"", ""Daniel A. Abolafia"", ""Jeffrey Pennington"", ""Jascha Sohl-dickstein""]","[""Deep Convolutional Neural Networks"", ""Gaussian Processes"", ""Bayesian""]",Finite-width SGD trained CNNs vs. infinitely wide fully Bayesian CNNs. Who wins?,,,,
B1g5sA4twr,2020,Accept (Poster),False,Deep Double Descent: Where Bigger Models and More Data Hurt,"[""Preetum Nakkiran"", ""Gal Kaplun"", ""Yamini Bansal"", ""Tristan Yang"", ""Boaz Barak"", ""Ilya Sutskever""]","[""deep learning"", ""double descent"", ""optimization"", ""SGD"", ""complexity""]","We demonstrate, and characterize, realistic settings where bigger models are worse, and more data hurts.",1912.02292,cs.LG,2019-12-04 22:47:31+00:00,2019-12-04 22:47:31+00:00
B1g79grKPr,2020,Reject,False,Goal-Conditioned Video Prediction,"[""Oleh Rybkin"", ""Karl Pertsch"", ""Frederik Ebert"", ""Dinesh Jayaraman"", ""Chelsea Finn"", ""Sergey Levine""]","[""predictive models"", ""video prediction"", ""latent variable models""]",We propose a new class of visual generative models: goal-conditioned predictors. We show experimentally that conditioning on the goal allows to reduce uncertainty and produce predictions over much longer horizons.,,,,
B1g8VkHFPH,2020,Accept (Poster),False,Rethinking the Hyperparameters for Fine-tuning,"[""Hao Li"", ""Pratik Chaudhari"", ""Hao Yang"", ""Michael Lam"", ""Avinash Ravichandran"", ""Rahul Bhotika"", ""Stefano Soatto""]","[""fine-tuning"", ""hyperparameter search"", ""transfer learning""]",This paper re-examines several common practices of setting hyper-parameters for fine-tuning and identify optimal hyperparameter depends on source-target domain similarity.,2002.11770,cs.CV,2020-02-19 18:59:52+00:00,2020-02-19 18:59:52+00:00
B1gF56VYPH,2020,Accept (Poster),True,"Deep 3D Pan via local adaptive ""t-shaped"" convolutions with global and local adaptive dilations","[""Juan Luis Gonzalez Bello"", ""Munchurl Kim""]","[""Deep learning"", ""Stereoscopic view synthesis"", ""Monocular depth"", ""Deep 3D Pan""]",Novel architecture for stereoscopic view synthesis at arbitrary camera shifts utilizing adaptive t-shaped kernels with adaptive dilations.,1910.01089,eess.SP,2019-10-02 17:09:58+00:00,2019-10-21 01:52:19+00:00
B1gHjoRqYQ,2019,Reject,False,An Efficient and Margin-Approaching Zero-Confidence Adversarial Attack,"[""Yang Zhang"", ""Shiyu Chang"", ""Mo Yu"", ""Kaizhi Qian""]","[""adversarial attack"", ""zero-confidence attack""]","This paper introduces MarginAttack, a stronger and faster zero-confidence adversarial attack.",,,,
B1gHokBKwS,2020,Accept (Poster),False,Learning to Guide Random Search,"[""Ozan Sener"", ""Vladlen Koltun""]","[""Random search"", ""Derivative-free optimization"", ""Learning continuous control""]",We improve the sample-efficiency of the random search for functions defined on low-dimensional manifolds. Our method jointly learns the underlying manifold and optimizes the function.,,,,
B1gIf305Ym,2019,Reject,False,NSGA-Net: A Multi-Objective Genetic Algorithm for Neural Architecture Search,"[""Zhichao Lu"", ""Ian Whalen"", ""Vishnu Boddeti"", ""Yashesh Dhebar"", ""Kalyanmoy Deb"", ""Erik Goodman"", ""Wolfgang Banzhaf""]","[""neural architecture search"", ""evolutionary algorithms""]",An efficient multi-objective neural architecture search algorithm using NSGA-II,,,,
B1gJ1L2aW,2018,Accept (Oral),False,Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality,"[""Xingjun Ma"", ""Bo Li"", ""Yisen Wang"", ""Sarah M. Erfani"", ""Sudanthi Wijewickrema"", ""Grant Schoenebeck"", ""Dawn Song"", ""Michael E. Houle"", ""James Bailey""]","[""Adversarial Subspace"", ""Local Intrinsic Dimensionality"", ""Deep Neural Networks""]",We characterize the dimensional properties of adversarial subspaces in the neighborhood of adversarial examples via the use of Local Intrinsic Dimensionality (LID).,1801.02613,cs.LG,2018-01-08 18:54:40+00:00,2018-03-14 07:24:10+00:00
B1gJOoRcYQ,2019,Reject,False,"S3TA: A Soft, Spatial, Sequential, Top-Down Attention Model","[""Alex Mott"", ""Daniel Zoran"", ""Mike Chrzanowski"", ""Daan Wierstra"", ""Danilo J. Rezende""]","[""Attention"", ""RL"", ""Top-Down"", ""Interpretability""]",http://sites.google.com/view/s3ta,,,,
B1gNKxrYPB,2020,Reject,False,Attributed Graph Learning with 2-D Graph Convolution,"[""Qimai Li"", ""Xiaotong Zhang"", ""Han Liu"", ""Xiao-Ming Wu""]","[""2-D Graph Convolution"", ""Attributed Graph"", ""Representation learning""]",We propose a novel 2-D graph convolution framework to jointly model node relations and attribute relations for attributed graph learning.,,,,
B1gR3ANFPS,2020,Reject,False,Non-linear System Identification from Partial Observations via Iterative Smoothing and Learning,"[""Kunal Menda"", ""Jean de Becdeli\u00e8vre"", ""Jayesh K Gupta"", ""Ilan Kroo"", ""Mykel J. Kochenderfer"", ""Zachary Manchester""]","[""System Identification"", ""Dynamical Systems"", ""Partial Observations"", ""Non-linear Programming"", ""Expectation Maximization"", ""Neural Networks""]",This work presents a scalable algorithm for non-linear offline system identification from partial observations.,,,,
B1gTShAct7,2019,Accept (Poster),False,Learning to Learn without Forgetting by Maximizing Transfer and Minimizing Interference,"[""Matthew Riemer"", ""Ignacio Cases"", ""Robert Ajemian"", ""Miao Liu"", ""Irina Rish"", ""Yuhai Tu"", ""and Gerald Tesauro""]",[],,,,,
B1gUn24tPr,2020,Reject,False,Classification Attention for Chinese NER,"[""Yuchen Ge"", ""FanYang"", ""PeiYang""]","[""Chinese NER"", ""NER"", ""tagging"", ""deeplearning"", ""nlp""]",Classification Attention for Chinese NER,,,,
B1gX8JrYPr,2020,Reject,True,Connecting the Dots Between MLE and RL for Sequence Prediction,"[""Bowen Tan"", ""Zhiting Hu"", ""Zichao Yang"", ""Ruslan Salakhutdinov"", ""Eric Xing""]","[""Sequence generation"", ""sequence prediction"", ""reinforcement learning""]",An entropy regularized policy optimization formalism subsumes a set of sequence prediction learning algorithms. A new interpolation algorithm with improved results on text generation and game imitation learning.,1811.09740,cs.LG,2018-11-24 01:33:39+00:00,2019-06-29 19:44:06+00:00
B1gX8kBtPr,2020,Accept (Poster),True,Universal Approximation with Certified Networks,"[""Maximilian Baader"", ""Matthew Mirman"", ""Martin Vechev""]","[""adversarial robustness"", ""universal approximation"", ""certified network"", ""interval bound propagation""]",We prove that for a large class of functions f there exists an interval certified robust network approximating f up to arbitrary precision.,1909.13846,cs.LG,2019-09-30 17:11:23+00:00,2020-01-14 19:14:37+00:00
B1gXR3NtwS,2020,Reject,False,Deep Bayesian Structure Networks,"[""Zhijie Deng"", ""Yucen Luo"", ""Jun Zhu"", ""Bo Zhang""]",[],,,,,
B1gXWCVtvr,2020,Reject,False,Adapting Behaviour for Learning Progress,"[""Tom Schaul"", ""Diana Borsa"", ""David Ding"", ""David Szepesvari"", ""Georg Ostrovski"", ""Will Dabney"", ""Simon Osindero""]","[""adaptation"", ""behaviour"", ""reinforcement learning"", ""modulated behaviour"", ""exploration"", ""deep reinforcement learning""]",Donât tune exploration by hand: automagically adapt behaviour modulation for learning progress instead!,,,,
B1gXYR4YDH,2020,Reject,False,DSReg: Using Distant Supervision as a Regularizer,"[""Yuxian Meng"", ""Muyu Li"", ""Xiaoya Li"", ""Wei Wu"", ""Fei Wu"", ""Jiwei Li""]",[],,,,,
B1gZV1HYvS,2020,Accept (Poster),False,Multi-Agent Interactions Modeling with Correlated Policies,"[""Minghuan Liu"", ""Ming Zhou"", ""Weinan Zhang"", ""Yuzheng Zhuang"", ""Jun Wang"", ""Wulong Liu"", ""Yong Yu""]","[""Multi-agent reinforcement learning"", ""Imitation learning""]",Modeling complex multi-agent interactions under multi-agent imitation learning framework with explicit modeling of correlated policies by approximating opponentsâ policies. ,2001.03415,cs.MA,2020-01-04 17:31:53+00:00,2020-06-11 11:22:24+00:00
B1g_BT4FvS,2020,Reject,True,Samples Are Useful? Not Always: denoising policy gradient updates using variance explained,"[""Yannis Flet-Berliac"", ""Philippe Preux""]","[""reinforcement learning"", ""policy gradient"", ""sampling""]",SAUNA uses the fraction of variance explained (Vex) as a metric to filter the transitions used for policy gradient updates: such filtering improves the sampling prior for a better exploration of the environment and yields a better performance.,1904.04025,cs.LG,2019-04-08 12:53:12+00:00,2020-11-20 16:04:51+00:00
B1gabhRcYX,2019,Accept (Oral),True,BA-Net: Dense Bundle Adjustment Networks,"[""Chengzhou Tang"", ""Ping Tan""]","[""Structure-from-Motion"", ""Bundle Adjustment"", ""Dense Depth Estimation""]",This paper introduces a network architecture to solve the structure-from-motion (SfM) problem via feature bundle adjustment (BA),1806.04807,cs.CV,2018-06-13 00:51:48+00:00,2019-08-25 19:20:00+00:00
B1gcblSKwB,2020,Reject,False,Meta-Learning with Network Pruning for Overfitting Reduction,"[""Hongduan Tian"", ""Bo Liu"", ""Xiao-Tong Yuan"", ""Qingshan Liu""]","[""Meta-Learning"", ""Few-shot Learning"", ""Network Pruning"", ""Generalization Analysis""]",,2007.03219,cs.LG,2020-07-07 06:13:11+00:00,2020-07-22 14:15:19+00:00
B1gd7REFDB,2020,Reject,False,Context-Aware Object Detection With Convolutional Neural Networks,"[""Yizhou Yan"", ""Lei Cao"", ""Samuel Madden"", ""Elke Rundensteiner""]","[""Object Detection"", ""CNN"", ""Context"", ""CRF""]",A deep neural network that leverages conditional random field to enforce context semantics constrains in object detection,,,,
B1gdkxHFDH,2020,Accept (Spotlight),True,Training individually fair ML models with sensitive subspace robustness,"[""Mikhail Yurochkin"", ""Amanda Bower"", ""Yuekai Sun""]","[""fairness"", ""adversarial robustness""]",Algorithm for training individually fair classifier using adversarial robustness,1907.00020,stat.ML,2019-06-28 18:11:25+00:00,2020-03-13 05:25:24+00:00
B1ggosR9Ym,2019,Reject,False,Using Deep Siamese Neural Networks to Speed up Natural Products Research,"[""Nicholas Roberts"", ""Poornav S. Purushothama"", ""Vishal T. Vasudevan"", ""Siddarth Ravichandran"", ""Chen Zhang"", ""William H. Gerwick"", ""Garrison W. Cottrell""]","[""clustering"", ""deep learning"", ""application"", ""chemistry"", ""natural products""]",We learn a direct mapping from NMR spectra of small molecules to a molecular structure based cluster space. ,,,,
B1gi0TEFDB,2020,Reject,False,Understanding Top-k Sparsification in Distributed Deep Learning,"[""Shaohuai Shi"", ""Xiaowen Chu"", ""Ka Chun Cheung"", ""Simon See""]","[""Distributed Deep Learning"", ""SGD"", ""Gradient Sparsification"", ""Communication-efficient SGD"", ""Top-k""]",,1911.08772,cs.LG,2019-11-20 08:50:59+00:00,2019-11-20 08:50:59+00:00
B1gjs6EtDr,2020,Reject,False,Efficient Content-Based Sparse Attention with Routing Transformers,"[""Aurko Roy*"", ""Mohammad Taghi Saffar*"", ""David Grangier"", ""Ashish Vaswani""]","[""Sparse attention"", ""autoregressive"", ""generative models""]",We propose a content-based sparse attention model and show improvements on language modeling and image generation.,,,,
B1gkpR4FDB,2020,Reject,False,Statistical Adaptive Stochastic Optimization,"[""Pengchuan Zhang"", ""Hunter Lang"", ""Qiang Liu"", ""Lin Xiao""]",[],,,,,
B1gm-a4tDH,2020,Reject,False,Modeling treatment events in disease progression,"[""Guanyang Wang"", ""Yumeng Zhang"", ""Yong Deng"", ""Xuxin Huang"", ""Lukasz Kidzinski""]","[""disease progression"", ""treatment events"", ""matrix completion""]",A novel matrix completion based algorithm to model disease progression with events,,,,
B1gn-pEKwH,2020,Reject,False,"INFERENCE, PREDICTION, AND ENTROPY RATE OF CONTINUOUS-TIME, DISCRETE-EVENT PROCESSES","[""Sarah Marzen"", ""James P. Crutchfield""]","[""continuous-time prediction""]","A new method for inferring a model of, estimating the entropy rate of, and predicting continuous-time, discrete-event processes.",,,,
B1gqipNYwH,2020,Accept (Poster),False,Option Discovery using Deep Skill Chaining,"[""Akhil Bagaria"", ""George Konidaris""]","[""Hierarchical Reinforcement Learning"", ""Reinforcement Learning"", ""Skill Discovery"", ""Deep Learning"", ""Deep Reinforcement Learning""]",We present a new hierarchical reinforcement learning algorithm which can solve high-dimensional goal-oriented tasks  more reliably than non-hierarchical agents and other state-of-the-art skill discovery techniques.,,,,
B1grSREtDH,2020,Reject,False,Bayesian Residual Policy Optimization: Scalable Bayesian Reinforcement Learning with Clairvoyant Experts,"[""Gilwoo Lee"", ""Brian Hou"", ""Sanjiban Choudhury"", ""Siddhartha S. Srinivasa""]","[""Bayesian Residual Reinforcement Learning"", ""Residual Reinforcement Learning"", ""Bayes Policy Optimization""]",We propose a scalable Bayesian Reinforcement Learning algorithm that learns a Bayesian correction over an ensemble of clairvoyant experts to solve problems with complex latent rewards and dynamics.,2002.03042,cs.RO,2020-02-07 23:10:05+00:00,2020-02-07 23:10:05+00:00
B1gskyStwr,2020,Accept (Poster),False,Frequency-based Search-control in Dyna,"[""Yangchen Pan"", ""Jincheng Mei"", ""Amir-massoud Farahmand""]","[""Model-based reinforcement learning"", ""search-control"", ""Dyna"", ""frequency of a signal""]",Acquire states from high frequency region for search-control in Dyna.,2002.05822,cs.LG,2020-02-14 00:27:58+00:00,2020-02-14 00:27:58+00:00
B1gstsCqt7,2019,Accept (Poster),False,Sparse Dictionary Learning by Dynamical Neural Networks,"[""Tsung-Han Lin"", ""Ping Tak Peter Tang""]","[""dynamical neural networks"", ""spiking neural networks"", ""dynamical system"", ""hardware friendly learning"", ""feedback"", ""contrastive learning"", ""dictionary learning"", ""sparse coding""]",,,,,
B1gtu5ilg,2017,Accept (Poster),False,Transfer of View-manifold Learning to Similarity Perception of Novel Objects,"[""Xingyu Lin"", ""Hao Wang"", ""Zhihao Li"", ""Yimeng Zhang"", ""Alan Yuille"", ""Tai Sing Lee""]","[""Deep learning"", ""Transfer Learning""]",DCNN trained with multiple views of the same object can develop human-like perpetual similarity judgment that can transfer to novel objects,,,,
B1guLAVFDB,2020,Accept (Poster),False,Span Recovery for Deep Neural Networks with Applications to Input Obfuscation,"[""Rajesh Jayaram"", ""David P. Woodruff"", ""Qiuyi Zhang""]","[""Span recovery"", ""low rank neural networks"", ""adversarial attack""]",We provably recover the span of a deep multi-layered neural network with latent structure and empirically apply efficient span recovery algorithms to attack networks by obfuscating inputs.,2002.08202,cs.DS,2020-02-19 14:17:15+00:00,2020-02-19 14:17:15+00:00
B1gzLaNYvr,2020,Reject,False,TSInsight: A local-global attribution framework for interpretability in time-series data,"[""Shoaib Ahmed Siddiqui"", ""Dominique Mercier"", ""Andreas Dengel"", ""Sheraz Ahmed""]","[""Deep Learning"", ""Representation Learning"", ""Convolutional Neural Networks"", ""Time-Series Analysis"", ""Feature Importance"", ""Visualization"", ""Demystification""]",We present an attribution technique leveraging sparsity inducing norms to achieve interpretability.,2004.02958,cs.LG,2020-04-06 19:34:25+00:00,2020-04-06 19:34:25+00:00
B1hYRMbCW,2018,Accept (Poster),False,On the regularization of Wasserstein GANs,"[""Henning Petzka"", ""Asja Fischer"", ""Denis Lukovnikov""]",[],A new regularization term can improve your training of wasserstein gans,,,,
B1hcZZ-AW,2018,Accept (Poster),False,N2N learning: Network to Network Compression via Policy Gradient Reinforcement Learning,"[""Anubhav Ashok"", ""Nicholas Rhinehart"", ""Fares Beainy"", ""Kris M. Kitani""]","[""Deep learning"", ""Neural networks"", ""Model compression""]",A novel reinforcement learning based approach to compress deep neural networks with knowledge distillation,,,,
B1hdzd5lg,2017,Accept (Poster),False,Words or Characters? Fine-grained Gating for Reading Comprehension,"[""Zhilin Yang"", ""Bhuwan Dhingra"", ""Ye Yuan"", ""Junjie Hu"", ""William W. Cohen"", ""Ruslan Salakhutdinov""]","[""Natural language processing"", ""Deep learning""]",,,,,
B1i7ezW0-,2018,Reject,False,Semi-Supervised Learning via New Deep Network Inversion,"[""Balestriero R."", ""Roger V."", ""Glotin H."", ""Baraniuk R.""]","[""inversion scheme"", ""deep neural networks"", ""semi-supervised learning"", ""MNIST"", ""SVHN"", ""CIFAR10""]",We exploit an inversion scheme for arbitrary deep neural networks to develop a new semi-supervised learning framework applicable to many topologies.,,,,
B1jnyXXJx,2017,Invite to Workshop Track,False,Charged Point Normalization: An Efficient Solution to the Saddle Point Problem,"[""Armen Aghajanyan""]","[""Deep learning"", ""Computer vision"", ""Optimization""]",,,,,
B1jscMbAW,2018,Accept (Poster),False,Divide and Conquer Networks,"[""Alex Nowak"", ""David Folqu\u00e9"", ""Joan Bruna""]","[""Neural Networks"", ""Combinatorial Optimization"", ""Algorithms""]",Dynamic model that learns divide and conquer strategies by weak supervision.,,,,
B1kIr-WRb,2018,Reject,False,LEARNING SEMANTIC WORD RESPRESENTATIONS VIA TENSOR FACTORIZATION,"[""Eric Bailey"", ""Charles Meyer"", ""Shuchin Aeron""]","[""Word Embeddings"", ""Tensor Factorization"", ""Natural Language Processing""]",,,,,
B1kJ6H9ex,2017,Accept (Poster),False,Combining policy gradient and Q-learning,"[""Brendan O'Donoghue"", ""Remi Munos"", ""Koray Kavukcuoglu"", ""Volodymyr Mnih""]","[""Deep learning"", ""Reinforcement Learning""]",We combine a policy gradient style update with a Q-learning style update into a single RL algorithm we call PGQL.,,,,
B1l08oAct7,2019,Accept (Oral),False,Deterministic Variational Inference for Robust Bayesian Neural Networks,"[""Anqi Wu"", ""Sebastian Nowozin"", ""Edward Meeds"", ""Richard E. Turner"", ""Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"", ""Alexander L. Gaunt""]","[""Bayesian neural network"", ""variational inference"", ""variational bayes"", ""variance reduction"", ""empirical bayes""]",A method for eliminating gradient variance and automatically tuning priors for effective training of bayesian neural networks,,,,
B1l0wp4tvr,2020,Reject,True,Information Plane Analysis of Deep Neural Networks via Matrix--Based Renyi's Entropy and Tensor Kernels,"[""Kristoffer Wickstr\u00f8m"", ""Sigurd L\u00f8kse"", ""Michael Kampffmeyer"", ""Shujian Yu"", ""Jose Principe"", ""Robert Jenssen""]","[""information plane"", ""information theory"", ""deep neural networks"", ""entropy"", ""mutual information"", ""tensor kernels""]",First comprehensive information plane analysis of large scale deep neural networks using matrix based entropy and tensor kernels.,1909.11396,stat.ML,2019-09-25 10:42:39+00:00,2019-09-25 10:42:39+00:00
B1l1b205KX,2019,Reject,False,Unsupervised Disentangling Structure and Appearance,"[""Wayne Wu"", ""Kaidi Cao"", ""Cheng Li"", ""Chen Qian"", ""Chen Change Loy""]","[""disentangled representations"", ""VAE"", ""generative models"", ""unsupervised learning""]",We present a novel framework to learn the disentangled representation of structure and appearance in a completely unsupervised manner. ,,,,
B1l1qnEFwH,2020,Reject,False,Deep Audio Prior,"[""Yapeng Tian"", ""Chenliang Xu"", ""Dingzeyu Li""]","[""deep audio prior"", ""blind sound separation"", ""deep learning"", ""audio representation""]",a deep audio network that does not require any external training data,1912.10292,cs.SD,2019-12-21 16:35:54+00:00,2019-12-21 16:35:54+00:00
B1l2bp4YwS,2020,Accept (Poster),True,What graph neural networks cannot learn: depth vs width,"[""Andreas Loukas""]","[""graph neural networks"", ""capacity"", ""impossibility results"", ""lower bounds"", ""expressive power""]",Several graph problems are impossible unless the product of a graph neural network's depth and width exceeds a polynomial of the graph size.,1907.03199,cs.LG,2019-07-06 22:26:17+00:00,2020-01-28 13:24:15+00:00
B1l3M64KwB,2020,Reject,False,How many weights are enough : can tensor factorization learn efficient policies ?,"[""Pierre H. Richemond"", ""Arinbjorn Kolbeinsson"", ""Yike Guo""]","[""reinforcement learning"", ""Q-learning"", ""tensor factorization"", ""low-rank approximation"", ""data efficiency"", ""second-order optimization"", ""scattering""]",,,,,
B1l4SgHKDH,2020,Accept (Poster),False,Residual Energy-Based Models for Text Generation,"[""Yuntian Deng"", ""Anton Bakhtin"", ""Myle Ott"", ""Arthur Szlam"", ""Marc'Aurelio Ranzato""]","[""energy-based models"", ""text generation""]",We show that Energy-Based models when trained on the residual of an auto-regressive language model can be used effectively and efficiently to generate text. ,2004.11714,cs.CL,2020-04-22 23:19:55+00:00,2020-04-22 23:19:55+00:00
B1l5m6VFwr,2020,Reject,False,EINS: Long Short-Term Memory with Extrapolated Input Network Simplification,"[""Nicholas I-Hsien Kuo"", ""Mehrtash T. Harandi"", ""Nicolas Fourrier"", ""Gabriela Ferraro"", ""Christian Walder"", ""Hanna Suominen""]","[""recurrent neural network"", ""RNN"", ""long short-term memory"", ""LSTM"", ""gated recurrent network"", ""GRU"", ""dynamical mathematics"", ""interpretability""]","This paper modelled cell states of LSTMs and GRUs as dynamic Hopfield networks to present the novel light-weight RNN of EINS with either comparable, or better performances than the LSTM in a wide range of tasks.",,,,
B1l6e3RcF7,2019,Reject,True,A Walk with SGD: How SGD Explores Regions of Deep Network Loss?,"[""Chen Xing"", ""Devansh Arpit"", ""Christos Tsirigotis"", ""Yoshua Bengio""]",[],,1802.08770,stat.ML,2018-02-24 00:21:10+00:00,2018-05-30 01:15:02+00:00
B1l6nnEtwr,2020,Reject,False,AN EFFICIENT HOMOTOPY TRAINING ALGORITHM FOR NEURAL NETWORKS,"[""Qipin Chen"", ""Wenrui Hao""]","[""Homotopy training algorithm"", ""Convergence analysis"", ""Neural networks""]",,,,,
B1l6qiR5F7,2019,Accept (Oral),False,Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks,"[""Yikang Shen"", ""Shawn Tan"", ""Alessandro Sordoni"", ""Aaron Courville""]","[""Deep Learning"", ""Natural Language Processing"", ""Recurrent Neural Networks"", ""Language Modeling""]",We introduce a new inductive bias that integrates tree structures in recurrent neural networks.,,,,
B1l6y0VFPr,2020,Accept (Poster),True,Identity Crisis: Memorization and Generalization Under Extreme Overparameterization,"[""Chiyuan Zhang"", ""Samy Bengio"", ""Moritz Hardt"", ""Michael C. Mozer"", ""Yoram Singer""]","[""Generalization"", ""Memorization"", ""Understanding"", ""Inductive Bias""]",,1902.04698,stat.ML,2019-02-13 01:45:30+00:00,2020-01-09 04:31:25+00:00
B1l8BtlCb,2018,Accept (Poster),False,Non-Autoregressive Neural Machine Translation,"[""Jiatao Gu"", ""James Bradbury"", ""Caiming Xiong"", ""Victor O.K. Li"", ""Richard Socher""]","[""machine translation"", ""non-autoregressive"", ""transformer"", ""fertility"", ""nmt""]","We introduce the first NMT model with fully parallel decoding, reducing inference latency by 10x.",,,,
B1l8L6EtDS,2020,Accept (Poster),False,Self-Adversarial Learning with Comparative Discrimination for Text Generation,"[""Wangchunshu Zhou"", ""Tao Ge"", ""Ke Xu"", ""Furu Wei"", ""Ming Zhou""]","[""adversarial learning"", ""text generation""]",We propose a self-adversarial learning (SAL) paradigm which improves the generator in a self-play fashion for improving GANs' performance in text generation.,2001.11691,cs.CL,2020-01-31 07:50:25+00:00,2020-02-12 09:18:24+00:00
B1l8iiA9tQ,2019,Reject,False,Backdrop: Stochastic Backpropagation,"[""Siavash Golkar"", ""Kyle Cranmer""]","[""stochastic optimization"", ""multi-scale data analysis"", ""non-decomposable loss"", ""generalization"", ""one-shot learning""]","We introduce backdrop, intuitively described as dropout acting on the backpropagation pipeline and find significant improvements in generalization for problems with non-decomposable losses and problems with multi-scale, hierarchical data structure.",,,,
B1l9qsA5KQ,2019,Reject,False,Mental Fatigue Monitoring using Brain Dynamics Preferences,"[""Yuangang Pan"", ""Avinash K Singh"", ""Ivor W. Tsang"", ""Chin-teng Lin""]","[""mental fatigue"", ""brain dynamics preference"", ""brain dynamics ranking"", ""channel reliability"", ""channel Selection""]",,,,,
B1lC62EKwr,2020,Reject,False,Evidence-Aware Entropy Decomposition For  Active Deep Learning,"[""Weishi Shi"", ""Xujiang Zhao"", ""Feng Chen"", ""Qi Yu""]","[""active learning"", ""entropy decomposition"", ""uncertainty""]",An evidence-aware entropy decomposition approach for active deep learning using multiple sources of uncertainty,,,,
B1lCn64tvS,2020,Reject,True,Improving SAT Solver Heuristics with Graph Networks and Reinforcement Learning,"[""Vitaly Kurin"", ""Saad Godil"", ""Shimon Whiteson"", ""Bryan Catanzaro""]","[""SAT"", ""reinforcement learning"", ""graph neural networks"", ""heuristics"", ""DQN"", ""boolean satisfiability""]",We use reinforcement learning with graph neural networks to augment a branching heuristic of a SAT solver achieving 2-3X reduction in the number of iterations and generalizing to problems up to 5X larger than the training set.,1909.11830,cs.LG,2019-09-26 00:44:40+00:00,2020-11-25 10:28:55+00:00
B1lDoJSYDH,2020,Accept (Poster),False,Lagrangian Fluid Simulation with Continuous Convolutions,"[""Benjamin Ummenhofer"", ""Lukas Prantl"", ""Nils Thuerey"", ""Vladlen Koltun""]","[""particle-based physics"", ""fluid mechanics"", ""continuous convolutions"", ""material estimation""]",We learn particle-based fluid simulation with convolutional networks.,,,,
B1lFa3EFwB,2020,Reject,False,Stablizing Adversarial Invariance Induction by Discriminator Matching,"[""Yusuke Iwasawa"", ""Kei Akuzawa"", ""Yutaka Matsuo""]","[""invariance induction"", ""adversarial training"", ""domain generalization""]",,,,,
B1lG42C9Km,2019,Reject,False,Intrinsic Social Motivation via Causal Influence in Multi-Agent RL,"[""Natasha Jaques"", ""Angeliki Lazaridou"", ""Edward Hughes"", ""Caglar Gulcehre"", ""Pedro A. Ortega"", ""DJ Strouse"", ""Joel Z. Leibo"", ""Nando de Freitas""]","[""multi-agent reinforcement learning"", ""causal inference"", ""game theory"", ""social dilemma"", ""intrinsic motivation"", ""counterfactual reasoning"", ""empowerment"", ""communication""]","We reward agents for having a causal influence on the actions of other agents, and show that this gives rise to better cooperation and more meaningful emergent communication protocols. ",,,,
B1lGU64tDr,2020,Accept (Poster),False,Relational State-Space Model for Stochastic Multi-Object Systems,"[""Fan Yang"", ""Ling Chen"", ""Fan Zhou"", ""Yusong Gao"", ""Wei Cao""]","[""state-space model"", ""time series"", ""deep sequential model"", ""graph neural network""]",A deep hierarchical state-space model in which the state transitions of correlated objects are coordinated by graph neural networks.,2001.04050,cs.LG,2020-01-13 03:45:21+00:00,2020-01-13 03:45:21+00:00
B1lJzyStvS,2020,Accept (Poster),False,Self-Supervised Learning of Appliance Usage,"[""Chen-Yu Hsu"", ""Abbas Zeitoun"", ""Guang-He Lee"", ""Dina Katabi"", ""Tommi Jaakkola""]","[""Appliance usage"", ""self-supervised learning"", ""multi-modal learning"", ""unsupervised learning""]","We learn appliance usage patterns in homes without labels, using self-supervised learning with energy and location data",,,,
B1lKDlHtwS,2020,Reject,False,Measuring causal influence with back-to-back regression: the linear case,"[""Jean-Remi King"", ""Francois Charton"", ""Maxime Oquab"", ""David Lopez-Paz""]",[],,,,,
B1lKS2AqtX,2019,Accept (Poster),False,Eidetic 3D LSTM: A Model for Video Prediction and Beyond,"[""Yunbo Wang"", ""Lu Jiang"", ""Ming-Hsuan Yang"", ""Li-Jia Li"", ""Mingsheng Long"", ""Li Fei-Fei""]",[],,,,,
B1lKtjA9FQ,2019,Reject,False,Overfitting Detection of Deep Neural Networks without a Hold Out Set,"[""Konrad Groh""]","[""deep learning"", ""overfitting"", ""generalization"", ""memorization""]",We introduce and analyze several criteria for detecting overfitting.,,,,
B1lLw6EYwB,2020,Accept (Poster),True,Gap-Aware Mitigation of Gradient Staleness,"[""Saar Barkai"", ""Ido Hakimi"", ""Assaf Schuster""]","[""distributed"", ""asynchronous"", ""large scale"", ""gradient staleness"", ""staleness penalization"", ""sgd"", ""deep learning"", ""neural networks"", ""optimization""]","A new distributed, asynchronous, SGD-based algorithm, which achieves state-of-the-art accuracy on existing architectures using staleness penalization without having to re-tune the hyperparameters.",1909.10802,cs.LG,2019-09-24 10:46:21+00:00,2020-02-03 17:28:14+00:00
B1lMMx1CW,2018,Invite to Workshop Track,False,THE EFFECTIVENESS OF A TWO-LAYER NEURAL NETWORK FOR RECOMMENDATIONS,"[""Oleg Rybakov"", ""Vijai Mohan"", ""Avishkar Misra"", ""Scott LeGrand"", ""Rejith Joseph"", ""Kiuk Chung"", ""Siddharth Singh"", ""Qian You"", ""Eric Nalisnick"", ""Leo Dirac"", ""Runfei Luo""]","[""Recommender systems"", ""deep learning"", ""personalization""]",Improving recommendations using time sensitive modeling with neural networks in multiple product categories on a retail website,,,,
B1lOraEFPB,2020,Reject,False,Transition Based Dependency Parser for Amharic Language Using Deep Learning,"[""Mizanu Zelalem"", ""Million Meshesha (PhD)""]","[""Amharic dependency parsing"", ""arc-eager transition"", ""LSTM"", ""Transition action prediction"", ""Relationship type prediction""]",,,,,
B1lPETVFPS,2020,Reject,False,Towards Principled Objectives for Contrastive Disentanglement,"[""Anwesa Choudhuri"", ""Ashok Vardhan Makkuva"", ""Ranvir Rana"", ""Sewoong Oh"", ""Girish Chowdhary"", ""Alexander Schwing""]","[""Disentanglement"", ""Contrastive""]",,,,,
B1lPaCNtPB,2020,Accept (Spotlight),False,"Real or Not Real, that is the Question","[""Yuanbo Xiangli*"", ""Yubin Deng*"", ""Bo Dai*"", ""Chen Change Loy"", ""Dahua Lin""]","[""GAN"", ""generalization"", ""realness"", ""loss function""]",,,,,
B1lTqgSFDH,2020,Reject,False,Antifragile and Robust Heteroscedastic Bayesian Optimisation,"[""Ryan Rhys-Griffiths"", ""Miguel Garcia-Ortegon"", ""Alexander A. Aldrick"", ""Alpha A. Lee""]","[""Bayesian Optimisation"", ""Gaussian Processeses"", ""Heteroscedasticity""]","We present a heteroscedastic Bayesian Optimisation scheme capable of both representing and minimising aleatoric noise, which is crucial for many scientific applications.",,,,
B1lXGnRctX,2019,Reject,False,Classification in the dark using tactile exploration,"[""Mayur Mudigonda"", ""Blake Tickell"", ""Pulkit Agrawal""]","[""tactile sensing"", ""multimodal representations"", ""vision"", ""object identification""]","In this work, we study the problem of learning representations to identify novel objects by exploring objects using tactile sensing. Key point here is that the query is provided in image domain.",,,,
B1lXfA4Ywr,2020,Reject,False,Towards Modular Algorithm Induction,"[""Daniel A. Abolafia"", ""Rishabh Singh"", ""Manzil Zaheer"", ""Charles Sutton""]","[""algorithm induction"", ""reinforcement learning"", ""program synthesis"", ""modular""]",An architecture for learning to compose modules to learn algorithmic tasks.,2003.04227,cs.LG,2020-02-27 22:05:56+00:00,2020-02-27 22:05:56+00:00
B1lda1HtvB,2020,Reject,True,Feature Selection using Stochastic Gates,"[""Yutaro Yamada"", ""Ofir Lindenbaum"", ""Sahand Negahban"", ""Yuval Kluger""]","[""Feature selection"", ""classification"", ""regression"", ""survival analysis""]",We develop a fully embedded feature selection method based directly on approximating the $\ell_0$ penalty. ,1810.04247,cs.LG,2018-10-09 21:17:37+00:00,2020-07-26 15:45:08+00:00
B1ldb6NKDr,2020,Reject,False,Multi-Agent Hierarchical Reinforcement Learning for Humanoid Navigation,"[""Glen Berseth"", ""Brandon haworth"", ""Seonghyeon Moon"", ""Mubbasir Kapadia"", ""Petros Faloutsos""]","[""Multi-Agent Reinforcement Learning"", ""Reinforcement Learning"", ""Hierarchical Reinforcement Learning""]",Improving MARL by sharing task agnostic sub policies.,,,,
B1lfHhR9tm,2019,Reject,False,The Natural Language Decathlon: Multitask Learning as Question Answering,"[""Bryan McCann"", ""Nitish Shirish Keskar"", ""Caiming Xiong"", ""Richard Socher""]","[""multitask learning"", ""natural language processing"", ""question answering"", ""machine translation"", ""relation extraction"", ""semantic parsing"", ""commensense reasoning"", ""summarization"", ""entailment"", ""sentiment"", ""dialog""]",We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ,,,,
B1lgUkBFwr,2020,Reject,False,Unsupervised domain adaptation with imputation,"[""Matthieu Kirchmeyer"", ""Patrick Gallinari"", ""Alain Rakotomamonjy"", ""Amin Mantrach""]","[""domain adaptation"", ""imputation"", ""missing data"", ""advertising""]",We propose a way to jointly tackle unsupervised domain adaptation and non-stochastic missing data in a target domain using distant supervision from a complete source domain.,2109.09505,cs.LG,2021-09-16 06:37:07+00:00,2021-09-16 06:37:07+00:00
B1liIlBKvS,2020,Reject,False,Selfish Emergent Communication,"[""Michael Noukhovitch"", ""Travis LaCroix"", ""Aaron Courville""]","[""multi agent reinforcement learning"", ""emergent communication"", ""game theory""]","We manage to emerge communication with selfish agents, contrary to the current view in ML",,,,
B1liraVYwr,2020,Reject,False,LocalGAN: Modeling Local Distributions for Adversarial Response Generation,"[""Zhen Xu"", ""Baoxun Wang"", ""Huan Zhang"", ""Kexin Qiu"", ""Deyuan Zhang"", ""Chengjie Sun""]","[""neural response generation"", ""adversarial learning"", ""local distribution"", ""energy-based distribution modeling""]",A study on leveraging the local distribution of query-response pairs to adversarial response generation.,,,,
B1lj20NFDS,2020,Accept (Poster),False,Variational Autoencoders for Highly Multivariate Spatial Point Processes Intensities,"[""Baichuan Yuan"", ""Xiaowei Wang"", ""Jianxin Ma"", ""Chang Zhou"", ""Andrea L. Bertozzi"", ""Hongxia Yang""]","[""VAE"", ""collaborative filtering"", ""recommender systems"", ""spatial point process""]",,,,,
B1lnbRNtwr,2020,Accept (Poster),False,Global Relational Models of Source Code,"[""Vincent J. Hellendoorn"", ""Charles Sutton"", ""Rishabh Singh"", ""Petros Maniatis"", ""David Bieber""]","[""Models of Source Code"", ""Graph Neural Networks"", ""Structured Learning""]",Models of source code that combine global and structural features learn more powerful representations of programs.,,,,
B1lnjo05Km,2019,Reject,False,Graph Spectral Regularization For Neural Network Interpretability,"[""Alexander Tong"", ""David van Dijk"", ""Jay Stanley"", ""Guy Wolf"", ""Smita Krishnaswamy""]","[""autoencoder"", ""interpretable"", ""graph signal processing"", ""graph spectrum"", ""graph filter"", ""capsule""]",Imposing graph structure on neural network layers for improved visual interpretability.,,,,
B1lnzn0ctQ,2019,Accept (Poster),False,ALISTA: Analytic Weights Are As Good As Learned Weights in LISTA,"[""Jialin Liu"", ""Xiaohan Chen"", ""Zhangyang Wang"", ""Wotao Yin""]","[""sparse recovery"", ""neural networks""]",,,,,
B1lqDertwr,2020,Reject,True,Regularization Matters in Policy Optimization,"[""Zhuang Liu"", ""Xuanlin Li"", ""Bingyi Kang"", ""Trevor Darrell""]","[""Regularization"", ""Policy Optimization"", ""Reinforcement Learning""]","We show that conventional regularization methods (e.g., $L_2$, dropout), which have been largely ignored in RL methods, can be very effective in policy optimization.",1910.09191,cs.LG,2019-10-21 08:00:33+00:00,2021-11-28 07:21:35+00:00
B1lsXREYvr,2020,Reject,True,One-Shot Neural Architecture Search via Compressive Sensing,"[""Minsu Cho"", ""Mohammadreza Soltani"", ""Chinmay Hegde""]","[""deep learning"", ""autoML"", ""neural architecture search"", ""image classification"", ""language modeling""]",A new approach for one-shot neural architecture search that blends in techniques from Fourier-sparse recovery.,1906.02869,cs.LG,2019-06-07 02:35:52+00:00,2019-06-07 02:35:52+00:00
B1ltfgSYwS,2020,Reject,False,Few-Shot One-Class Classification via Meta-Learning,"[""Ahmed Frikha"", ""Denis Krompa\u00df"", ""Hans-Georg Koepken"", ""Volker Tresp""]","[""meta-learning"", ""few-shot learning"", ""one-class classification"", ""class-imbalance learning""]","We develop an approach for the novel and challenging few-shot one-class classification problem and validate it on datasets from the image and time-series domain, including a real-world dataset of industrial sensor readings.",,,,
B1lwSsC5KX,2019,Reject,False,DÃ©jÃ  Vu: An Empirical Evaluation of the Memorization Properties of Convnets,"[""Alexandre Sablayrolles"", ""Matthijs Douze"", ""Cordelia Schmid"", ""Herv\u00e9 J\u00e9gou""]","[""membership inference"", ""memorization"", ""attack"", ""privacy""]",We analyze the memorization properties by a convnet of the training set and propose several use-cases where we can extract some information about the training set. ,,,,
B1lx42A9Ym,2019,Reject,False,Neural Rendering Model: Joint Generation and Prediction for Semi-Supervised Learning,"[""Nhat Ho"", ""Tan Nguyen"", ""Ankit B. Patel"", ""Anima Anandkumar"", ""Michael I. Jordan"", ""Richard G. Baraniuk""]","[""neural nets"", ""generative models"", ""semi-supervised learning"", ""cross-entropy""]",We develop a new deep generative model for semi-supervised learning and propose a new Max-Min cross-entropy for training CNNs.,,,,
B1lxH20qtX,2019,Reject,False,Learning to control self-assembling morphologies: a study of generalization via modularity,"[""Deepak Pathak"", ""Chris Lu"", ""Trevor Darrell"", ""Philip Isola"", ""Alexei A. Efros""]","[""modularity"", ""compostionality"", ""graphs"", ""dynamics"", ""network""]",Learning to control self-assembling agents via dynamic graph networks,,,,
B1lxV6NFPH,2020,Reject,False,BANANAS: Bayesian Optimization with Neural Networks for Neural Architecture Search,"[""Colin White"", ""Willie Neiswanger"", ""Yash Savani""]","[""neural architecture search"", ""Bayesian optimization""]","We design a NAS algorithm that performs Bayesian optimization using a neural network model, which takes advantage of a novel way to featurize neural architectures, and it performs very well on multiple search spaces.",,,,
B1lyZpEYvH,2020,Reject,False,Multi-Dimensional Explanation of Reviews,"[""Diego Antognini"", ""Claudiu Musat"", ""Boi Faltings""]","[""deep learning"", ""explanation"", ""interpretability"", ""reviews"", ""multi-aspect"", ""sentiment analysis"", ""mask""]","Neural model predicting multi-aspect sentiments and generating a probabilistic multi-dimensional mask simultaneously. Model outperforms strong baselines and generates masks that are: strong feature predictors, meaningful, and interpretable.",,,,
B1lz-3Rct7,2019,Accept (Poster),True,Three Mechanisms of Weight Decay Regularization,"[""Guodong Zhang"", ""Chaoqi Wang"", ""Bowen Xu"", ""Roger Grosse""]","[""Generalization"", ""Regularization"", ""Optimization""]",We investigate weight decay regularization for different optimizers and identify three distinct mechanisms by which weight decay improves generalization.,1810.12281,cs.LG,2018-10-29 17:51:25+00:00,2018-10-29 17:51:25+00:00
B1mAJI9gl,2017,Reject,False,Towards Understanding the Invertibility of Convolutional Neural Networks,"[""Anna C. Gilbert"", ""Yi Zhang"", ""Kibok Lee"", ""Yuting Zhang"", ""Honglak Lee""]","[""Deep learning"", ""Theory""]",,,,,
B1mAkPxCZ,2018,Reject,False,VOCABULARY-INFORMED VISUAL FEATURE AUGMENTATION FOR ONE-SHOT LEARNING,"[""jianqi ma"", ""hangyu lin"", ""yinda zhang"", ""yanwei fu"", ""xiangyang xue""]","[""vocabulary-informed learning"", ""data augmentation""]",,,,,
B1mSWUxR-,2018,Reject,False,Softmax Q-Distribution Estimation for Structured Prediction: A Theoretical Interpretation for RAML,"[""Xuezhe Ma"", ""Pengcheng Yin"", ""Jingzhou Liu"", ""Graham Neubig"", ""Eduard Hovy""]","[""structured prediction"", ""RAML"", ""theory"", ""Bayes decision rule"", ""reward function""]",,,,,
B1mvVm-C-,2018,Accept (Poster),False,Universal Agent for Disentangling Environments and Tasks,"[""Jiayuan Mao"", ""Honghua Dong"", ""Joseph J. Lim""]","[""reinforcement learning"", ""transfer learning""]",We propose a DRL framework that disentangles task and environment specific knowledge.,,,,
B1n8LexRZ,2018,Accept (Poster),False,Generalizing Hamiltonian Monte Carlo with Neural Networks,"[""Daniel Levy"", ""Matt D. Hoffman"", ""Jascha Sohl-Dickstein""]","[""markov"", ""chain"", ""monte"", ""carlo"", ""sampling"", ""posterior"", ""deep"", ""learning"", ""hamiltonian"", ""mcmc""]","General method to train expressive MCMC kernels parameterized with deep neural networks. Given a target distribution p, our method provides a fast-mixing sampler, able to efficiently explore the state space.",,,,
B1nLkl-0Z,2018,Reject,False,Learning Gaussian Policies from Smoothed Action Value Functions,"[""Ofir Nachum"", ""Mohammad Norouzi"", ""George Tucker"", ""Dale Schuurmans""]","[""Reinforcement learning""]",We propose a new Q-value function that enables better learning of Gaussian policies.,,,,
B1nZ1weCZ,2018,Accept (Poster),False,Learning to Multi-Task by Active Sampling,"[""Sahil Sharma*"", ""Ashutosh Kumar Jha*"", ""Parikshit S Hegde"", ""Balaraman Ravindran""]","[""Deep Reinforcement Learning""]",Letting a meta-learner decide the task to train on for an agent in a multi-task setting improves multi-tasking ability substantially,,,,
B1nxTzbRZ,2018,Reject,False,Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger,"[""Gabriel Synnaeve"", ""Zeming Lin"", ""Jonas Gehring"", ""Vasil Khalidov"", ""Nicolas Carion"", ""Nicolas Usunier""]","[""forward modeling"", ""partially observable"", ""deep learning"", ""strategy game"", ""real-time strategy""]","This paper presents a defogger, a model that learns to predict future hidden information from partial observations, applied to a StarCraft dataset.",,,,
B1oK8aoxe,2017,Accept (Poster),False,Stochastic Neural Networks for Hierarchical Reinforcement Learning,"[""Carlos Florensa"", ""Yan Duan"", ""Pieter Abbeel""]","[""Deep learning"", ""Unsupervised Learning"", ""Reinforcement Learning""]","We propose a framework for learning a diverse set of skills using stochastic neural networks with minimum supervision, and utilize these skills in a hierarchical architecture to solve challenging tasks with sparse rewards",,,,
B1p461b0W,2018,Reject,False,Deep Learning is Robust to Massive Label Noise,"[""David Rolnick"", ""Andreas Veit"", ""Serge Belongie"", ""Nir Shavit""]","[""label noise"", ""weakly supervised learning"", ""robustness of neural networks"", ""deep learning"", ""large datasets""]",We show that deep neural networks are able to learn from data that has been diluted by an arbitrary amount of noise.,,,,
B1s6xvqlx,2017,Accept (Poster),False,Recurrent Environment Simulators,"[""Silvia Chiappa"", ""S\u00e9bastien Racaniere"", ""Daan Wierstra"", ""Shakir Mohamed""]","[""Deep learning"", ""Unsupervised Learning"", ""Applications""]",,,,,
B1spAqUp-,2018,Reject,False,Pixel Deconvolutional Networks,"[""Hongyang Gao"", ""Hao Yuan"", ""Zhengyang Wang"", ""Shuiwang Ji""]","[""Deep Learning"", ""Deconvolutional Layer"", ""Pixel CNN""]",Solve checkerboard problem in Deconvolutional layer by building dependencies between pixels,,,,
B1suU-bAW,2018,Reject,False,Learning Covariate-Specific Embeddings with Tensor Decompositions,"[""Kevin Tian"", ""Teng Zhang"", ""James Zou""]","[""Word embedding"", ""tensor decomposition""]","Using the same embedding across covariates doesn't make sense, we show that a tensor decomposition algorithm learns sparse covariate-specific embeddings and naturally separable topics jointly and data-efficiently.",,,,
B1tC-LT6W,2018,Reject,False,Trace norm regularization and faster inference for embedded speech recognition RNNs,"[""Markus Kliegl"", ""Siddharth Goyal"", ""Kexin Zhao"", ""Kavya Srinet"", ""Mohammad Shoeybi""]","[""LVCSR"", ""speech recognition"", ""embedded"", ""low rank factorization"", ""RNN"", ""GRU"", ""trace norm""]",We compress and speed up speech recognition models on embedded devices through a trace norm regularization technique and optimized kernels.,,,,
B1tExikAW,2018,Reject,False,LatentPoison -- Adversarial Attacks On The Latent Space,"[""Antonia Creswell"", ""Biswa Sengupta"", ""Anil A. Bharath""]","[""adversarial attacks"", ""security"", ""auto-encoder""]",Adversarial attacks on the latent space of variational autoencoders to change the semantic meaning of inputs,,,,
B1twdMCab,2018,Reject,False,Dynamic Integration of Background Knowledge in Neural NLU Systems,"[""Dirk Weissenborn"", ""Tomas Kocisky"", ""Chris Dyer""]","[""natural language processing"", ""background knowledge"", ""word embeddings"", ""question answering"", ""natural language inference""]",In this paper we present a task-agnostic reading architecture for the dynamic integration of explicit background knowledge in neural NLU models. ,,,,
B1uvH_gC-,2018,Reject,False,Parametric Manifold Learning Via Sparse Multidimensional Scaling,"[""Gautam Pai"", ""Ronen Talmon"", ""Ron Kimmel""]","[""Manifold Learning"", ""Non-linear Dimensionality Reduction"", ""Neural Networks"", ""Unsupervised Learning""]",Parametric Manifold Learning with Neural Networks in a Geometric Framework ,,,,
B1vRTeqxg,2017,Invite to Workshop Track,False,Learning Continuous Semantic Representations of Symbolic Expressions,"[""Miltiadis Allamanis"", ""Pankajan Chanthirasegaran"", ""Pushmeet Kohli"", ""Charles Sutton""]","[""Deep learning""]","Assign continuous vectors to logical and algebraic symbolic expressions in such a way that semantically equivalent, but syntactically diverse expressions are assigned to identical (or highly similar) continuous vectors.",,,,
B1x-LjAcKX,2019,Reject,False,Local Critic Training of Deep Neural Networks,"[""Hojung Lee"", ""Jong-Seok Lee""]","[""inter-layer locking"", ""local critic network"", ""backpropagation"", ""convolutional neural network"", ""structural optimization"", ""progress inference"", ""ensemble inference""]","We propose a new learning algorithm of deep neural networks, which unlocks the layer-wise dependency of backpropagation.",,,,
B1x0enCcK7,2019,Reject,False,Automatic generation of object shapes with desired functionalities,"[""Mihai Andries"", ""Atabak Dehban"", ""Jose Santos-Victor""]","[""automated design"", ""affordance learning""]","It's difficult to make objects with desired affordances. We propose an automated method for generating object shapes with desired affordances, based on neural networks.",,,,
B1x1MerYPB,2020,Reject,False,Putting Machine Translation in Context with the Noisy Channel Model,"[""Lei Yu"", ""Laurent Sartran"", ""Wojciech Stokowiec"", ""Wang Ling"", ""Lingpeng Kong"", ""Phil Blunsom"", ""Chris Dyer""]","[""machine translation"", ""context-aware machine translation"", ""bayes rule""]",,,,,
B1x1ma4tDr,2020,Accept (Spotlight),False,DDSP: Differentiable Digital Signal Processing,"[""Jesse Engel"", ""Lamtharn (Hanoi) Hantrakul"", ""Chenjie Gu"", ""Adam Roberts""]","[""dsp"", ""audio"", ""music"", ""nsynth"", ""wavenet"", ""wavernn"", ""vocoder"", ""synthesizer"", ""sound"", ""signal"", ""processing"", ""tensorflow"", ""autoencoder"", ""disentanglement""]",Better audio synthesis by combining interpretable DSP with end-to-end learning.,,,,
B1x2eCNFvH,2020,Reject,False,Local Label Propagation for Large-Scale Semi-Supervised Learning,"[""Chengxu Zhuang"", ""Chaofei Fan"", ""Xuehao Ding"", ""Divyanshu Murli"", ""Daniel Yamins""]",[],,,,,
B1x33sC9KQ,2019,Reject,False,ACIQ: Analytical Clipping for Integer Quantization of neural networks,"[""Ron Banner"", ""Yury Nahshan"", ""Elad Hoffer"", ""Daniel Soudry""]","[""quantization"", ""reduced precision"", ""training"", ""inference"", ""activation""]","We analyze the trade-off between quantization noise and clipping distortion in low precision networks, and show marked improvements over standard quantization schemes that normally avoid clipping",,,,
B1x3EgHtwB,2020,Reject,True,ExpandNets: Linear Over-parameterization to Train Compact Convolutional Networks,"[""Shuxuan Guo"", ""Jose M. Alvarez"", ""Mathieu Salzmann""]","[""Compact Network Training"", ""Linear Expansion"", ""Over-parameterization"", ""Knowledge Transfer""]",This paper proposes linear expansion strategies building upon over-parameterization to facilitate practical compact network training. ,1811.10495,cs.CV,2018-11-26 16:40:24+00:00,2021-04-14 11:55:22+00:00
B1x5KiCcFX,2019,Reject,False,Understanding GANs via Generalization Analysis for Disconnected Support,"[""Masaaki Imaizumi"", ""Kenji Fukumizu""]","[""Generalization analysis"", ""Statistical estimation"", ""Understanding GANs"", ""Disconnected support""]",We investigate the generalization performance of GANs and show how GANs outperform others with a specific property of data.,,,,
B1x62TNtDS,2020,Accept (Poster),True,Understanding the Limitations of Variational Mutual Information Estimators,"[""Jiaming Song"", ""Stefano Ermon""]",[],,1910.06222,cs.LG,2019-10-14 15:45:21+00:00,2020-03-24 04:40:12+00:00
B1x6BTEKwr,2020,Accept (Poster),False,Piecewise linear activations substantially shape the loss surfaces of neural networks,"[""Fengxiang He"", ""Bohan Wang"", ""Dacheng Tao""]","[""neural network"", ""nonlinear activation"", ""loss surface"", ""spurious local minimum""]",This paper presents how the loss surfaces of nonlinear neural networks are substantially shaped by the nonlinearities in activations.,2003.12236,cs.LG,2020-03-27 04:59:34+00:00,2020-03-27 04:59:34+00:00
B1x6w0EtwH,2020,Accept (Poster),False,Graph Constrained Reinforcement Learning for Natural Language Action Spaces,"[""Prithviraj Ammanabrolu"", ""Matthew Hausknecht""]","[""natural language generation"", ""deep reinforcement learning"", ""knowledge graphs"", ""interactive fiction""]","We present KG-A2C, a reinforcement learning agent that builds a dynamic knowledge graph while exploring and generates natural language using a template-based action space - outperforming all current agents on a wide set of text-based games.",2001.08837,cs.LG,2020-01-23 22:33:18+00:00,2020-01-23 22:33:18+00:00
B1x8anVFPr,2020,Reject,False,On Layer Normalization in the Transformer Architecture,"[""Ruibin Xiong"", ""Yunchang Yang"", ""Di He"", ""Kai Zheng"", ""Shuxin Zheng"", ""Huishuai Zhang"", ""Yanyan Lan"", ""Liwei Wang"", ""Tie-Yan Liu""]","[""Transformer"", ""BERT"", ""Layer Normalization"", ""Natural Language Processing""]",,,,,
B1x996EKPS,2020,Reject,False,Fast Machine Learning with Byzantine Workers and Servers,"[""El-Mahdi El-Mhamdi"", ""Rachid Guerraoui"", ""Arsany Guirguis""]","[""Distributed machine learning"", ""Byzantine resilience"", ""Fault tolerance""]",We present an algorithm that tolerates not only Byzantine workers but also Byzantine servers in synchronous networks with a low overhead.,,,,
B1x9ITVYDr,2020,Reject,True,"Compressive Recovery Defense: A Defense Framework for $\ell_0, \ell_2$ and $\ell_\infty$ norm attacks.","[""Jasjeet Dhaliwal"", ""Kyle Hambrook""]","[""adversarial input"", ""adversarial machine learning"", ""neural networks"", ""compressive sensing.""]",,1907.06565,cs.CV,2019-07-15 16:15:12+00:00,2019-08-07 16:53:34+00:00
B1x9siCcYQ,2019,Reject,False,SENSE: SEMANTICALLY ENHANCED NODE SEQUENCE EMBEDDING,"[""Swati Rallapalli"", ""Liang Ma"", ""Mudhakar Srivatsa"", ""Ananthram Swami"", ""Heesung Kwon"", ""Graham Bent"", ""Christopher Simpkin""]","[""Semantic"", ""Graph"", ""Sequence"", ""Embeddings""]",Node sequence embedding mechanism that captures both graph and text properties.,,,,
B1xBAA4FwH,2020,Reject,False,On Evaluating Explainability Algorithms,"[""Gokula Krishnan Santhanam"", ""Ali Alami-Idrissi"", ""Nuno Mota"", ""Anika Schumann"", ""Ioana Giurgiu""]","[""interpretability"", ""Deep Learning""]",We propose a suite of metrics that capture desired properties of explainability algorithms and use it to objectively compare and evaluate such methods,,,,
B1xDq2EFDH,2020,Reject,False,Analytical Moment Regularizer for Training Robust Networks,"[""Modar Alfadly"", ""Adel Bibi"", ""Muhammed Kocabas"", ""Bernard Ghanem""]","[""robustness"", ""analytic regularizer"", ""first moment""]",An efficient estimate to the Gaussian first moment of DNNs as a regularizer to training robust networks.,,,,
B1xFVhActm,2019,Reject,True,Fake Sentence Detection as a Training Task for Sentence Encoding,"[""Viresh Ranjan"", ""Heeyoung Kwon"", ""Niranjan Balasubramanian"", ""Minh Hoai""]",[],,1808.03840,cs.CL,2018-08-11 17:31:15+00:00,2018-08-24 03:55:24+00:00
B1xFhiC9Y7,2019,Reject,False,Domain Adaptation for Structured Output via Disentangled Patch Representations,"[""Yi-Hsuan Tsai"", ""Kihyuk Sohn"", ""Samuel Schulter"", ""Manmohan Chandraker""]","[""Domain Adaptation"", ""Feature Representation Learning"", ""Semantic Segmentation""]",A domain adaptation method for structured output via learning patch-level discriminative feature representations,,,,
B1xFxh0cKX,2019,Reject,True,Guided Evolutionary Strategies: Escaping the curse of dimensionality in random search,"[""Niru Maheswaranathan"", ""Luke Metz"", ""George Tucker"", ""Dami Choi"", ""Jascha Sohl-Dickstein""]","[""evolutionary strategies"", ""optimization"", ""gradient estimators"", ""biased gradients""]","We propose an optimization method for when only biased gradients are available--we define a new gradient estimator for this scenario, derive the bias and variance of this estimator, and apply it to example problems.",1806.10230,cs.NE,2018-06-26 22:14:36+00:00,2019-06-10 18:19:33+00:00
B1xGGTEtDH,2020,Reject,True,Universal Approximation with Deep Narrow Networks,"[""Patrick Kidger"", ""Terry Lyons""]","[""deep learning"", ""universal approximation"", ""deep narrow networks""]",,1905.08539,cs.LG,2019-05-21 10:47:55+00:00,2020-06-08 14:08:06+00:00
B1xGxgSYvH,2020,Reject,False,Domain-Invariant Representations: A Look on Compression and Weights,"[""Victor Bouvier"", ""C\u00e9line Hudelot"", ""Cl\u00e9ment Chastagnol"", ""Philippe Very"", ""Myriam Tami""]","[""Domain Adaptation"", ""Invariant Representation"", ""Compression"", ""Machine Learning Theory""]",We introduce a new theoretical bound of the target risk for domain invariant representation which emphasizes both the role of compression and weights.,,,,
B1xIj3VYvr,2020,Accept (Poster),True,Weakly Supervised Clustering by Exploiting Unique Class Count,"[""Mustafa Umit Oner"", ""Hwee Kuan Lee"", ""Wing-Kin Sung""]","[""weakly supervised clustering"", ""weakly supervised learning"", ""multiple instance learning""]",A weakly supervised learning based clustering framework performs comparable to that of fully supervised learning models by exploiting unique class count.,1906.07647,cs.CV,2019-06-18 15:44:54+00:00,2020-01-25 08:47:04+00:00
B1xJAsA5F7,2019,Accept (Poster),False,Learning Multimodal Graph-to-Graph Translation for Molecule Optimization,"[""Wengong Jin"", ""Kevin Yang"", ""Regina Barzilay"", ""Tommi Jaakkola""]","[""graph-to-graph translation"", ""graph generation"", ""molecular optimization""]",We introduce a graph-to-graph encoder-decoder framework for learning diverse graph translations.,1812.01070,cs.LG,2018-12-03 20:28:09+00:00,2019-01-28 19:38:39+00:00
B1xMEerYvB,2020,Accept (Poster),False,Smooth markets: A basic mechanism for organizing gradient-based learners,"[""David Balduzzi"", ""Wojciech M. Czarnecki"", ""Tom Anthony"", ""Ian Gemp"", ""Edward Hughes"", ""Joel Leibo"", ""Georgios Piliouras"", ""Thore Graepel""]","[""game theory"", ""optimization"", ""gradient descent"", ""adversarial learning""]",We introduce a class of n-player games suited to gradient-based methods.,,,,
B1xOYoA5tQ,2019,Reject,False,Multi-way Encoding for Robustness to Adversarial Attacks,"[""Donghyun Kim"", ""Sarah Adel Bargal"", ""Jianming Zhang"", ""Stan Sclaroff""]","[""Adversarial Defense"", ""Robustness of Deep Convolutional Networks""]","We demonstrate that by leveraging a multi-way output encoding, rather than the widely used one-hot encoding, we can make deep models more robust to adversarial attacks.",,,,
B1xRGkHYDS,2020,Reject,False,A bi-diffusion based layer-wise sampling method for deep learning in large graphs,"[""Yu He"", ""Shiyang Wen"", ""Wenjin Wu"", ""Yan Zhang"", ""Siran Yang"", ""Yuan Wei"", ""Di Zhang"", ""Guojie  Song"", ""Wei Lin"", ""Liang Wang"", ""Bo Zheng""]","[""Layerwise Sampling"", ""Graph Neural Networks"", ""Attention Mechanism""]",,,,,
B1xSperKvH,2020,Accept (Poster),False,Enabling Deep Spiking Neural Networks with Hybrid Conversion and Spike Timing Dependent Backpropagation,"[""Nitin Rathi"", ""Gopalakrishnan Srinivasan"", ""Priyadarshini Panda"", ""Kaushik Roy""]","[""spiking neural networks"", ""ann-snn conversion"", ""spike-based backpropagation"", ""imagenet""]",A hybrid training technique that combines ANN-SNN conversion and spike-based backpropagation to optimize training effort and inference latency.,2005.01807,cs.LG,2020-05-04 19:30:43+00:00,2020-05-04 19:30:43+00:00
B1xU4nAqK7,2019,Reject,False,Unsupervised Exploration with Deep Model-Based Reinforcement Learning,"[""Kurtland Chua"", ""Rowan McAllister"", ""Roberto Calandra"", ""Sergey Levine""]","[""exploration"", ""model based reinforcement learning""]",,,,,
B1xVTjCqKQ,2019,Accept (Poster),False,A Data-Driven and Distributed Approach to Sparse Signal Representation and Recovery,"[""Ali Mousavi"", ""Gautam Dasarathy"", ""Richard G. Baraniuk""]","[""Sparsity"", ""Compressive Sensing"", ""Convolutional Network""]",We use deep learning techniques to solve the sparse signal representation and recovery problem.,,,,
B1xWcj0qYm,2019,Accept (Poster),False,On the Minimal Supervision for Training Any Binary Classifier from Only Unlabeled Data,"[""Nan Lu"", ""Gang Niu"", ""Aditya Krishna Menon"", ""Masashi Sugiyama""]","[""learning from only unlabeled data"", ""empirical risk minimization"", ""unbiased risk estimator""]","Three class priors are all you need to train deep models from only U data, while any two should not be enough.",,,,
B1xY-hRctX,2019,Accept (Poster),False,Neural Logic Machines,"[""Honghua Dong"", ""Jiayuan Mao"", ""Tian Lin"", ""Chong Wang"", ""Lihong Li"", ""Denny Zhou""]","[""Neuro-Symbolic Computation"", ""Logic Induction""]","We propose the Neural Logic Machine (NLM), a neural-symbolic architecture for both inductive learning and logic reasoning.",,,,
B1xZD1rtPr,2020,Reject,False,The Dual Information Bottleneck,"[""Zoe Piran"", ""Naftali Tishby""]","[""optimal prediction learning"", ""exponential families"", ""critical points"", ""information theory""]","A new dual formulation of the Information Bottleneck, optimizing label prediction and preserving distributions of exponential form.",,,,
B1xbTlBKwB,2020,Reject,False,Measuring Numerical Common Sense: Is A Word Embedding Approach Effective?,"[""Hiroaki Yamane"", ""Chin-Yew Lin"", ""Tatsuya Harada""]","[""numerical common sense"", ""word embedding"", ""semantic representation""]",,,,,
B1xcLJrYwH,2020,Reject,False,Lean Images for Geo-Localization,"[""Moti Kadosh"", ""Yael Moses"", ""Ariel Shamir""]","[""Geo Localization"", ""Deep Learning"", ""Computer Vision"", ""Camera Localization""]",,,,,
B1xeZJHKPB,2020,Reject,False,Aggregating explanation methods for neural networks stabilizes explanations,"[""Laura Rieger"", ""Lars Kai Hansen""]","[""explainability"", ""deep learning"", ""interpretability"", ""XAI""]",We show in theory and in practice that combining multiple explanation methods for DNN benefits the explanation.,,,,
B1xewR4KvH,2020,Reject,False,MANIFOLD FORESTS: CLOSING THE GAP ON NEURAL NETWORKS,"[""Ronan Perry"", ""Tyler M. Tomita"", ""Jesse Patsolic"", ""Benjamin Falk"", ""Joshua Vogelstein""]","[""machine learning"", ""structured learning"", ""projections"", ""structured data"", ""images"", ""classification""]","Classification accuracy of decision forests on structured data, data in which the feature indices matter, can be improved using a specific projection distribution.",,,,
B1xeyhCctQ,2019,Reject,False,Bias Also Matters: Bias Attribution for Deep Neural Network Explanation,"[""Shengjie Wang"", ""Tianyi Zhou"", ""Jeff Bilmes""]","[""explainable AI"", ""interpreting deep neural networks"", ""bias"", ""attribution method"", ""piecewise linear activation function"", ""backpropagation""]",Attribute the bias terms of deep neural networks to input features by a backpropagation-type algorithm; Generate complementary and highly interpretable explanations of DNNs in addition to gradient-based attributions.,,,,
B1xf9jAqFQ,2019,Accept (Poster),False,Neural Speed Reading with Structural-Jump-LSTM,"[""Christian Hansen"", ""Casper Hansen"", ""Stephen Alstrup"", ""Jakob Grue Simonsen"", ""Christina Lioma""]","[""natural language processing"", ""speed reading"", ""recurrent neural network"", ""classification""]",We propose a new model for neural speed reading that utilizes the inherent punctuation structure of a text to define effective jumping and skipping behavior.,1904.00761,cs.CL,2019-03-20 12:01:46+00:00,2019-04-02 08:59:34+00:00
B1xfElrKPr,2020,Reject,True,Enhancing the Transformer with explicit relational encoding for math problem solving,"[""Imanol Schlag"", ""Paul Smolensky"", ""Roland Fernandez"", ""Nebojsa Jojic"", ""J\u00fcrgen Schmidhuber"", ""Jianfeng Gao""]","[""Tensor Product Representation"", ""Transformer"", ""Mathematics Dataset"", ""Attention""]",Our Tensor-Product Transformer sets a new state of the art on the recently-introduced Mathematics Dataset containing 56 categories of free-form math word-problems. ,1910.06611,cs.LG,2019-10-15 09:19:55+00:00,2020-11-04 15:28:24+00:00
B1xgQkrYwS,2020,Reject,False,"On Iterative Neural Network Pruning, Reinitialization, and the Similarity of Masks","[""Michela Paganini"", ""Jessica Forde""]","[""Pruning"", ""Lottery Tickets"", ""Science of Deep Learning"", ""Experimental Deep Learning"", ""Empirical Study""]","Different pruning techniques identify multiple trainable sub-networks within an over-parametrize model, with similar performance but significantly different emergent connectivity structure, weight evolution, and learned functions.",2001.05050,cs.LG,2020-01-14 21:11:19+00:00,2020-01-14 21:11:19+00:00
B1xhQhRcK7,2019,Accept (Poster),False,Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures,"[""Jonathan Uesato*"", ""Ananya Kumar*"", ""Csaba Szepesvari*"", ""Tom Erez"", ""Avraham Ruderman"", ""Keith Anderson"", ""Krishnamurthy (Dj) Dvijotham"", ""Nicolas Heess"", ""Pushmeet Kohli""]","[""agent evaluation"", ""adversarial examples"", ""robustness"", ""safety"", ""reinforcement learning""]","We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.",,,,
B1xhpa4FvS,2020,Reject,False,Modeling Fake News in Social Networks with Deep Multi-Agent Reinforcement Learning,"[""Christoph Aymanns"", ""Matthias Weber"", ""Co-Pierre Georg"", ""Jakob Foerster""]","[""deep multi-agent reinforcement learning"", ""fake news"", ""social networks"", ""information aggregation""]",We model fake news on social networks using deep multi-agent reinforcement learning and propose interventions to curb the effectiveness of fake news in swaying public opinion. ,,,,
B1xm3RVtwB,2020,Accept (Spotlight),False,Simplified Action Decoder for Deep Multi-Agent Reinforcement Learning,"[""Hengyuan Hu"", ""Jakob N Foerster""]","[""multi-agent RL"", ""theory of mind""]","We develop Simplified Action Decoder, a simple MARL algorithm that beats previous SOTA on Hanabi by a big margin across 2- to 5-player games.",1912.02288,cs.AI,2019-12-04 22:34:54+00:00,2021-05-12 05:32:45+00:00
B1xmOgrFPS,2020,Reject,False,Meta-RCNN: Meta Learning for Few-Shot Object Detection,"[""Xiongwei Wu"", ""Doyen Sahoo"", ""Steven C. H. Hoi""]","[""Few-shot detection"", ""Meta-Learning"", ""Object Detection""]",We develop Meta-RCNN which learns both the object classifier and the region proposal network via meta-learning in order to do few-shot detection,,,,
B1xnPsA5KX,2019,Reject,False,Modular Deep Probabilistic Programming,"[""Zhenwen Dai"", ""Eric Meissner"", ""Neil D. Lawrence""]",[],,,,,
B1xoserKPH,2020,Reject,False,Analyzing Privacy Loss in Updates of Natural Language Models,"[""Shruti Tople"", ""Marc Brockschmidt"", ""Boris K\u00f6pf"", ""Olga Ohrimenko"", ""Santiago Zanella-B\u00e9guelin""]","[""Language Modelling"", ""Privacy""]",comparing updates of language models reveals many details about changes in training data,,,,
B1xpI1BFDS,2020,Reject,False,Semi-Supervised Few-Shot Learning with a Controlled Degree of Task-Adaptive Conditioning,"[""Sung Whan Yoon"", ""Jun Seo"", ""Jaekyun Moon""]","[""few-shot learning"", ""meta-learning"", ""semi-supervised learning"", ""task-adaptive clustering"", ""task-adaptive projection space""]",We propose a semi-supervised few-shot learning algorithm with a controlled degree of task-adaptive conditioning by an iterative update of a task-conditioned projection space where the clustering of unlabeled samples takes place.,,,,
B1xq264YvH,2020,Reject,True,Encoder-Agnostic Adaptation for Conditional Language Generation,"[""Zachary M. Ziegler"", ""Luke Melas-Kyriazi"", ""Sebastian Gehrmann"", ""Alexander M. Rush""]","[""NLP"", ""generation"", ""pretraining""]",,1908.06938,cs.CL,2019-08-19 17:22:58+00:00,2019-09-11 02:45:34+00:00
B1xsqj09Fm,2019,Accept (Oral),False,Large Scale GAN Training for High Fidelity Natural Image Synthesis,"[""Andrew Brock"", ""Jeff Donahue"", ""Karen Simonyan""]","[""GANs"", ""Generative Models"", ""Large Scale Training"", ""Deep Learning""]",GANs benefit from scaling up.,,,,
B1xtFpVtvB,2020,Reject,False,Improving the Generalization of Visual Navigation Policies using Invariance Regularization,"[""Michel Aractingi"", ""Christopher Dance"", ""Julien Perez"", ""Tomi Silander""]","[""Generalization"", ""Deep Reinforcement Learning"", ""Invariant Representation""]","We propose a regularization term that, when added to the reinforcement learning objective, allows the policy to maximize the reward and simultaneously learn to be invariant to the irrelevant changes within the input..",,,,
B1xtd1HtPS,2020,Reject,False,Quaternion Equivariant Capsule Networks for 3D Point Clouds,"[""Yongheng Zhao"", ""Tolga Birdal"", ""Jan Eric Lenssen"", ""Emanuele Menegatti"", ""Leonidas Guibas"", ""Federico Tombari""]","[""3d"", ""capsule networks"", ""pointnet"", ""quaternion"", ""equivariant networks"", ""rotations"", ""local reference frame""]","Deep architectures for 3D point clouds that are equivariant to SO(3) rotations, as well as translations and permutations. ",1912.12098,cs.LG,2019-12-27 13:51:17+00:00,2020-08-23 13:12:46+00:00
B1xu6yStPH,2020,Reject,False,Using Explainabilty to Detect Adversarial Attacks,"[""Ohad Amosy and Gal Chechik""]","[""adversarial"", ""detection"", ""explainability""]","A novel adversarial detection approach, which uses explainability methods to identify images whose explanations are inconsistent with the predicted class.  ",,,,
B1xv9pEKDS,2020,Reject,False,LightPAFF: A Two-Stage Distillation Framework for Pre-training and Fine-tuning,"[""Kaitao Song"", ""Hao Sun"", ""Xu Tan"", ""Tao Qin"", ""Jianfeng Lu"", ""Hongzhi Liu"", ""Tie-Yan Liu""]","[""Knowledge Distillation"", ""Pre-training"", ""Fine-tuning"", ""BERT"", ""GPT-2"", ""MASS""]",,2004.12817,cs.CL,2020-04-27 14:00:09+00:00,2020-04-27 14:00:09+00:00
B1xw9n4Kwr,2020,Reject,False,Model Architecture Controls Gradient Descent Dynamics: A Combinatorial Path-Based Formula,"[""Xin Zhou"", ""Newsha Ardalani""]",[],,,,,
B1xwcyHFDr,2020,Accept (Poster),False,Learning Robust Representations via Multi-View Information Bottleneck,"[""Marco Federici"", ""Anjan Dutta"", ""Patrick Forr\u00e9"", ""Nate Kushman"", ""Zeynep Akata""]","[""Information Bottleneck"", ""Multi-View Learning"", ""Representation Learning"", ""Information Theory""]",We extend the information bottleneck method to the unsupervised multiview setting and show state of the art results on standard datasets,2002.07017,cs.LG,2020-02-17 16:01:52+00:00,2020-02-18 09:47:50+00:00
B1xwv1StvS,2020,Reject,False,Few-shot Learning by Focusing on Differences,"[""Muhammad Rizki Maulana"", ""Lee Wee Sun""]","[""Deep learning"", ""few-shot learning""]",We propose a model for few-shot classification that incorporates explicit prior which construct class representatives that are orthogonal to the local average of closely related class representatives.,,,,
B1xxAJHFwS,2020,Reject,False,A Finite-Time Analysis of  Q-Learning with Neural Network Function Approximation,"[""Pan Xu"", ""Quanquan Gu""]","[""Reinforcement Learning"", ""Neural Networks""]",,,,,
B1xybgSKwB,2020,Reject,True,Self-Attentional Credit Assignment for Transfer in Reinforcement Learning,"[""Johan Ferret"", ""Rapha\u00ebl Marinier"", ""Matthieu Geist"", ""Olivier Pietquin""]","[""reinforcement learning"", ""transfer learning"", ""credit assignment""]",Secret is a transfer method for RL based on the transfer of credit assignment.,1907.08027,cs.LG,2019-07-18 13:02:16+00:00,2019-11-22 14:22:44+00:00
B1ydPgTpW,2018,Reject,False,Predicting Auction Price of Vehicle License Plate with Deep Recurrent Neural Network,"[""Vinci Chow""]","[""price predictions"", ""expert system"", ""recurrent neural networks"", ""deep learning"", ""natural language processing""]","Predicting auction price of vehicle license plates in Hong Kong with deep recurrent neural network, based on the characters on the plates.",,,,
B1zMDjAqKQ,2019,Reject,False,Unsupervised Expectation Learning for Multisensory Binding,"[""Pablo Barros"", ""German I. Parisi"", ""Manfred Eppe"", ""Stefan Wermter""]","[""multisensory binding"", ""expectation learning"", ""unsupervised learning"", ""Deep autoencoder"", ""Growing-When-Required Network"", ""animal recognition""]",A hybrid deep neural network which adapts concepts of expectation learning for improving unisensory recognition using multisensory binding. ,,,,
B1zlp1bRW,2018,Accept (Poster),False,Large Scale Optimal Transport and Mapping Estimation,"[""Vivien Seguy"", ""Bharath Bhushan Damodaran"", ""Remi Flamary"", ""Nicolas Courty"", ""Antoine Rolet"", ""Mathieu Blondel""]","[""optimal transport"", ""Wasserstein"", ""domain adaptation"", ""generative models"", ""Monge map"", ""optimal mapping""]",Learning optimal mapping with deepNN between distributions along with theoretical guarantees.,,,,
B2pZkS2urk_,2022,Reject,True,Do What Nature Did To Us: Evolving Plastic Recurrent Neural Networks For Generalized Tasks,"['Fan Wang', 'Hao Tian', 'Haoyi Xiong', 'hua wu', 'Yang Cao', 'Yu Kang', 'Haifeng Wang']","[""Evolving Plasticity"", ""Learning to learn""]",,2109.03554,cs.AI,2021-09-08 11:34:14+00:00,2021-09-29 13:23:27+00:00
B3Nde6lvab,2022,Accept (Poster),True,Eliminating Sharp Minima from SGD with Truncated Heavy-tailed Noise,"['Xingyu Wang', 'Sewoong Oh', 'Chang-Han Rhee']","[""Stochastic Gradient Descent"", ""SGD"", ""Heavy-Tails"", ""Generalization""]",Empirical evidence and the first theoretical analysis that show SGD with truncated heavy-tailed gradient noise finds flatter minima and achieves better generalization.,2102.04297,cs.LG,2021-02-08 16:03:49+00:00,2021-06-23 06:05:05+00:00
B5VvQrI49Pa,2021,Accept (Poster),True,Nonseparable Symplectic Neural Networks,"[""Shiying Xiong"", ""Yunjin Tong"", ""Xingzhe He"", ""Shuqi Yang"", ""Cheng Yang"", ""Bo Zhu""]","[""Data-driven modeling"", ""nonseparable Hailtonian system"", ""symplectic networks""]", ,2010.12636,cs.LG,2020-10-23 19:50:13+00:00,2021-03-29 05:33:32+00:00
B5XahNLmna,2022,Accept (Poster),False,Data Poisoning Wonât Save You From Facial Recognition,"['Evani Radiya-Dixit', 'Sanghyun Hong', 'Nicholas Carlini', 'Florian Tramer']","[""Poisoning attacks"", ""adversarial examples"", ""facial recognition"", ""arms race"", ""defenses""]",Data poisoning and adversarial examples won't protect users from facial recognition,,,,
B5bZp0m7jZd,2021,Reject,False,Beyond Prioritized Replay: Sampling States in Model-Based RL via Simulated Priorities,"[""Jincheng Mei"", ""Yangchen Pan"", ""Martha White"", ""Amir-massoud Farahmand"", ""Hengshuai Yao""]","[""Experience replay"", ""prioritized sampling"", ""model-based reinforcement learning"", ""Dyna architecture""]",We theoretically understand why prioritized experience replay can help and point out its limitations and propose new algorithms to address these limitations.,,,,
B6EIcyp-Rb7,2022,Accept (Poster),False,Learning Object-Oriented Dynamics for Planning from Text,"['Guiliang Liu', 'Ashutosh Adhikari', 'Amir-massoud Farahmand', 'Pascal Poupart']","[""Object Oriented Markov Decision Process"", ""Reinforcement Learning"", ""Model-Based Planning"", ""Text-Based Games"", ""Knowledge Extraction""]",We propose an Object-Oriented Text Dynamic (OOTD) model for solving decision-making problems in the text domain.,,,,
B6YDcqpMk30,2022,Reject,False,PRIMA: Planner-Reasoner Inside a Multi-task Reasoning Agent,"['Daoming Lyu', 'Bo Liu', 'Jianshu Chen']","[""inductive logic programming"", ""logic reasoning"", ""first-order logic"", ""reinforcement learning"", ""Monte Carlo tree search""]",This paper proposes a novel neural-symbolic framework for multitask reasoning.,2202.00531,cs.AI,2022-02-01 16:22:19+00:00,2022-02-01 16:22:19+00:00
B72HXs80q4,2022,Accept (Poster),False,Taming Sparsely Activated Transformer with Stochastic Experts,"['Simiao Zuo', 'Xiaodong Liu', 'Jian Jiao', 'Young Jin Kim', 'Hany Hassan', 'Ruofei Zhang', 'Jianfeng Gao', 'Tuo Zhao']",[],"We propose a new variant of MoE, Transformer with Stochastic Experts, that is more parameter efficient.",,,,
B7O85qTDgU4,2022,Reject,True,Meta-Learning Dynamics Forecasting Using Task Inference,"['Rui Wang', 'Robin Walters', 'Rose Yu']","[""meta-learning"", ""generalizability"", ""dynamical systems""]",Inferring time-invariant latent vectors theoretically and experimentally leads to improved generalization over heterogeneous dynamics prediction domains.,2102.10271,cs.LG,2021-02-20 06:41:08+00:00,2021-08-23 20:05:23+00:00
B7ZbqNLDn-_,2022,Accept (Poster),False,Recycling Model Updates in Federated Learning: Are Gradient Subspaces Low-Rank?,"['Sheikh Shams Azam', 'Seyyedali Hosseinalipour', 'Qiang Qiu', 'Christopher Brinton']","[""Distributed Machine Learning"", ""Federated Learning"", ""Gradient Subspace"", ""SGD""]","We observe that ""gradient-space is low rank"" and propose the LBGM algorithm that utilitizes this low-rank property to recycle gradients between model update rounds in federated learning.",2202.00280,cs.LG,2022-02-01 09:05:32+00:00,2022-02-01 09:05:32+00:00
B7abCaIiN_v,2022,Reject,False,Triangular Dropout: Variable Network Width without Retraining,"['Edward W Staley', 'Corban G Rivera', 'Neil Joshi']","[""architecture"", ""compression"", ""variable network"", ""neural network design"", ""deep learning""]","We present Triangular Dropout, a new neural network layer which can have its width adjusted after training to trade performance for compression.",,,,
B7v4QMR6Z9w,2021,Accept (Oral),False,Federated Learning Based on Dynamic Regularization,"[""Durmus Alp Emre Acar"", ""Yue Zhao"", ""Ramon Matas"", ""Matthew Mattina"", ""Paul Whatmough"", ""Venkatesh Saligrama""]","[""Federated Learning"", ""Deep Neural Networks"", ""Distributed Optimization""]","We present, FedDyn, a novel dynamic regularization method for Federated Learning where the risk objective for each device is dynamically updated to ensure the device optima is asymptotically consistent with stationary points of the global loss.",,,,
B8DVo9B1YE0,2022,Accept (Poster),False,Relating transformers to models and neural representations of the hippocampal formation,"['James C. R. Whittington', 'Joseph Warren', 'Tim E.J. Behrens']","[""Neuroscience"", ""representation learning"", ""hippocampus"", ""cortex"", ""transformers""]",Transformers learn brain representatations and they are algorithmically related to models of the hippocampal formation.,,,,
B8fp0LVMHa,2021,Reject,False,EMaQ: Expected-Max Q-Learning Operator for Simple Yet Effective Offline and Online RL,"[""Seyed Kamyar Seyed Ghasemipour"", ""Dale Schuurmans"", ""Shixiang Gu""]","[""Offline Reinforcement Learning"", ""Off-Policy Reinforcement Learning""]","We introduce the EMaQ backup operator, which we use to design a practical offline/batch RL algorithm with fewer moving parts, leading to SOTA empirical performance and an intuitive measure of complexity for offline RL problems",,,,
B9nDuDeanHK,2021,Reject,False,Weights Having Stable Signs Are Important: Finding Primary Subnetworks and Kernels to Compress Binary Weight Networks,"[""Zhaole Sun"", ""Anbang Yao""]",[],,,,,
B9t708KMr9d,2021,Reject,True,Masked Label Prediction: Unified Message Passing Model for Semi-Supervised Classification,"[""Yunsheng Shi"", ""Zhengjie Huang"", ""shikun feng"", ""Hui Zhong"", ""Wenjin Wang"", ""Yu Sun""]","[""Unified Message Passing Model"", ""Graph Neural Network"", ""Label Propagation Algorithm"", ""Semi-Supervised Classification.""]","We propose a unified message passing model, incorporating feature propagation and label propagation for getting better performance in semi-supervised classification.",2009.03509,cs.LG,2020-09-08 04:04:04+00:00,2021-05-10 02:23:20+00:00
BAtutOziapg,2022,Reject,True,Can Stochastic Gradient Langevin Dynamics Provide Differential Privacy for Deep Learning?,"['Guy Heller', 'Ethan Fetaya']","[""differential privacy"", ""bayesian inference"", ""sgld""]",,2110.05057,cs.LG,2021-10-11 07:53:54+00:00,2022-02-02 06:14:55+00:00
BB4e8Atc1eR,2022,Accept (Spotlight),False,Scalable Sampling for Nonsymmetric Determinantal Point Processes,"['Insu Han', 'Mike Gartrell', 'Jennifer Gillenwater', 'Elvis Dohmatob', 'amin karbasi']","[""determinantal point processes"", ""sampling""]",We propose the first scalable linear-time and sublinear-time sampling algorithms for nonsymmetric determinantal point processes.,2201.08417,cs.LG,2022-01-20 19:21:59+00:00,2022-01-20 19:21:59+00:00
BEs-Q1ggdwT,2021,Reject,False,Policy Gradient with Expected Quadratic Utility Maximization: A New Mean-Variance Approach in Reinforcement Learning,"[""Masahiro Kato"", ""Kei Nakagawa""]","[""mean-variance reinforcement learning"", ""finance""]",Proposition of a expected quadratic utility maximization for mean-variance reinforcement learning,,,,
BGvt0ghNgA,2022,Accept (Poster),False,Lipschitz-constrained Unsupervised Skill Discovery,"['Seohong Park', 'Jongwook Choi', 'Jaekyeom Kim', 'Honglak Lee', 'Gunhee Kim']","[""Reinforcement learning""]","We propose Lipschitz-constrained Skill Discovery (LSD), which encourages the agent to discover more dynamic and diverse skills without external rewards and additional prior knowledge, enabling zero-shot control on goal-reaching downstream tasks.",2202.00914,cs.LG,2022-02-02 08:29:04+00:00,2022-02-08 07:34:26+00:00
BIIwfP55pp,2021,Reject,False,PERIL: Probabilistic Embeddings for hybrid Meta-Reinforcement and Imitation Learning,"[""Alvaro Prat"", ""Edward Johns""]","[""Meta-learning"", ""Imitation Learning"", ""Reinforcement Learning""]",Strategies for hybrid Meta-Reinforcement and Imitation Learning. ,,,,
BIwkgTsSp_8,2021,Reject,True,Learning to Noise: Application-Agnostic Data Sharing with Local Differential Privacy,"[""Alex Mansbridge"", ""Gregory Barbour"", ""Davide Piras"", ""Christopher Frye"", ""Ilya Feige"", ""David Barber""]","[""Differential Privacy"", ""Representation Learning"", ""Variational Inference"", ""Generative Modelling""]","Using representation learning to induce local differential privacy on high-dimensional data, via an application-agnostic privatization mechanism.",2010.12464,cs.LG,2020-10-23 15:01:19+00:00,2021-02-19 17:00:15+00:00
BJ--gPcxl,2017,Reject,False,Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks,"[""Emily Denton"", ""Sam Gross"", ""Rob Fergus""]","[""Deep learning"", ""Semi-Supervised Learning"", ""Computer vision""]",Training GANs to in-paint images produces feature representations that yield leading results on various benchmarks.,,,,
BJ0Ee8cxx,2017,Reject,False,Hierarchical Memory Networks,"[""Sarath Chandar"", ""Sungjin Ahn"", ""Hugo Larochelle"", ""Pascal Vincent"", ""Gerald Tesauro"", ""Yoshua Bengio""]","[""Deep learning"", ""Natural language processing""]",We propose a hierarchical memory organization strategy for efficient memory access in memory networks with large memory.,,,,
BJ0hF1Z0b,2018,Accept (Poster),False,Learning Differentially Private Recurrent Language Models,"[""H. Brendan McMahan"", ""Daniel Ramage"", ""Kunal Talwar"", ""Li Zhang""]","[""differential privacy"", ""LSTMs"", ""language models"", ""privacy""]",User-level differential privacy for recurrent neural network language models is possible with a sufficiently large dataset.,,,,
BJ3filKll,2017,Accept (Poster),False,Efficient Representation of Low-Dimensional Manifolds using Deep Networks,"[""Ronen Basri"", ""David W. Jacobs""]","[""Theory"", ""Deep learning""]",We show constructively that deep networks can learn to represent manifold data efficiently,,,,
BJ46w6Ule,2017,Reject,False,Dynamic Partition Models,"[""Marc Goessling"", ""Yali Amit""]",[],Learning of compact binary representations through partitioning of the variables,,,,
BJ4AFsRcFQ,2019,Reject,False,Total Style Transfer with a Single Feed-Forward Network,"[""Minseong Kim"", ""Hyun-Chul Choi""]","[""Image Style Transfer"", ""Deep Learning"", ""Neural Network""]",A paper suggesting a method to transform the style of images using deep neural networks.,,,,
BJ4BVhRcYX,2019,Reject,True,INTERPRETABLE CONVOLUTIONAL FILTER PRUNING,"[""Zhuwei Qin"", ""Fuxun Yu"", ""Chenchen Liu"", ""Xiang Chen""]",[],,1810.07322,cs.LG,2018-10-12 20:39:47+00:00,2019-09-12 03:24:06+00:00
BJ4prNx0W,2018,Reject,False,Learning what to learn in a neural program,"[""Richard Shin"", ""Dawn Song""]",[],,,,,
BJ5UeU9xx,2017,Accept (Poster),False,Visualizing Deep Neural Network Decisions: Prediction Difference Analysis,"[""Luisa M Zintgraf"", ""Taco S Cohen"", ""Tameem Adel"", ""Max Welling""]","[""Deep learning"", ""Applications""]",Method for visualizing evidence for and against deep convolutional neural network classification decisions in a given input image.,,,,
BJ6anzb0Z,2018,Reject,False,Multimodal Sentiment Analysis To Explore the Structure of Emotions,"[""Anthony Hu"", ""Seth Flaxman""]",[],,,,,
BJ6oOfqge,2017,Accept (Poster),False,Temporal Ensembling for Semi-Supervised Learning,"[""Samuli Laine"", ""Timo Aila""]",[],,,,,
BJ78bJZCZ,2018,Reject,False,Efficiently applying attention to sequential data with the Recurrent Discounted Attention unit,"[""Brendan Maginnis"", ""Pierre Richemond""]","[""RNNs""]",We introduce the Recurrent Discounted Unit which applies attention to any length sequence in linear time,,,,
BJ7d0fW0b,2018,Reject,False,Faster Reinforcement Learning with Expert State Sequences,"[""Xiaoxiao Guo"", ""Shiyu Chang"", ""Mo Yu"", ""Miao Liu"", ""Gerald Tesauro""]","[""Reinforcement Learning"", ""Imitation Learning""]",,,,,
BJ8c3f-0b,2018,Accept (Poster),False,Auto-Encoding Sequential Monte Carlo,"[""Tuan Anh Le"", ""Maximilian Igl"", ""Tom Rainforth"", ""Tom Jin"", ""Frank Wood""]","[""Variational Autoencoders"", ""Inference amortization"", ""Model learning"", ""Sequential Monte Carlo"", ""ELBOs""]","We build on auto-encoding sequential Monte Carlo, gain new theoretical insights and develop an improved training procedure based on those insights.",,,,
BJ8fyHceg,2017,Invite to Workshop Track,False,Tuning Recurrent Neural Networks with Reinforcement Learning,"[""Natasha Jaques"", ""Shixiang Gu"", ""Richard E. Turner"", ""Douglas Eck""]","[""Deep learning"", ""Reinforcement Learning"", ""Structured prediction"", ""Supervised Learning"", ""Applications""]","RL Tuner is a method for refining an LSTM trained on data by using RL to impose desired behaviors, while maintaining good predictive properties learned from data.",,,,
BJ8vJebC-,2018,Accept (Oral),False,Synthetic and Natural Noise Both Break Neural Machine Translation,"[""Yonatan Belinkov"", ""Yonatan Bisk""]","[""neural machine translation"", ""characters"", ""noise"", ""adversarial examples"", ""robust training""]",CharNMT is brittle,,,,
BJ9fZNqle,2017,Reject,False,Multi-modal Variational Encoder-Decoders,"[""Iulian V. Serban"", ""Alexander G. Ororbia II"", ""Joelle Pineau"", ""Aaron Courville""]","[""Deep learning"", ""Structured prediction"", ""Natural language processing""]",Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.,,,,
BJAA4wKxg,2017,Reject,False,A Convolutional Encoder Model for Neural Machine Translation,"[""Jonas Gehring"", ""Michael Auli"", ""David Grangier"", ""Yann N. Dauphin""]",[],Investigate encoder models for translation and demonstrate that convolutions can outperform LSTMs as encoders.,,,,
BJAFbaolg,2017,Accept (Poster),False,Learning to Generate Samples from Noise through Infusion Training,"[""Florian Bordes"", ""Sina Honari"", ""Pascal Vincent""]","[""Deep learning"", ""Unsupervised Learning""]","We learn a markov transition operator acting on inputspace, to denoise random noise into a target distribution. We use a novel target injection technique to guide the training.",,,,
BJB7fkWR-,2018,Reject,False,Domain Adaptation for Deep Reinforcement Learning in Visually Distinct Games,"[""Dino S. Ratcliffe"", ""Luca Citi"", ""Sam Devlin"", ""Udo Kruschwitz""]","[""Deep Reinforcement Learning"", ""Domain Adaptation"", ""Adversarial Networks""]",An approach to learning a shared embedding space between visually distinct games.,,,,
BJC8LF9ex,2017,Reject,False,Recurrent Neural Networks for Multivariate Time Series with Missing Values,"[""Zhengping Che"", ""Sanjay Purushotham"", ""Kyunghyun Cho"", ""David Sontag"", ""Yan Liu""]","[""Deep learning""]",,,,,
BJC_jUqxe,2017,Accept (Poster),False,A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING,"[""Zhouhan Lin"", ""Minwei Feng"", ""Cicero Nogueira dos Santos"", ""Mo Yu"", ""Bing Xiang"", ""Bowen Zhou"", ""Yoshua Bengio""]","[""Natural language processing"", ""Deep learning"", ""Supervised Learning""]",a new model for extracting an interpretable sentence embedding by introducing self-attention and matrix representation.,,,,
BJDEbngCZ,2018,Reject,False,Global Convergence of Policy Gradient Methods for Linearized  Control Problems,"[""Maryam Fazel"", ""Rong Ge"", ""Sham M. Kakade"", ""Mehran Mesbahi""]","[""linear quadratic regulator"", ""policy gradient"", ""natural gradient"", ""reinforcement learning"", ""non-convex optimization""]",This paper shows that model-free policy gradient methods can converge to the global optimal solution for non-convex linearized control problems.,,,,
BJDH5M-AW,2018,Reject,False,Synthesizing Robust Adversarial Examples,"[""Anish Athalye"", ""Logan Engstrom"", ""Andrew Ilyas"", ""Kevin Kwok""]","[""adversarial examples""]",We introduce a new method for synthesizing adversarial examples robust in the physical world and use it to fabricate the first 3D adversarial objects.,,,,
BJE-4xW0W,2018,Accept (Poster),False,CausalGAN: Learning Causal Implicit Generative Models with Adversarial Training,"[""Murat Kocaoglu"", ""Christopher Snyder"", ""Alexandros G. Dimakis"", ""Sriram Vishwanath""]","[""causality"", ""structural causal models"", ""GANs"", ""conditional GANs"", ""BEGAN"", ""adversarial training""]","We introduce causal implicit generative models, which can sample from conditional and interventional distributions and also propose two new conditional GANs which we use for training them.",,,,
BJEOOsCqKm,2019,Reject,False,Psychophysical vs. learnt texture representations in novelty detection,"[""Michael Grunwald"", ""Matthias Hermann"", ""Fabian Freiberg"", ""Matthias O. Franz""]","[""novelty detection"", ""learnt texture representation"", ""one-class neural network"", ""human-vision-inspired anomaly detection""]",Comparison of psychophysical and CNN-encoded  texture representations in a one-class neural network novelty detection application.,,,,
BJFG8Yqxl,2017,Reject,False,Group Sparse CNNs for Question Sentence Classification with Answer Sets,"[""Mingbo Ma"", ""Liang Huang"", ""Bing Xiang"", ""Bowen Zhou""]",[],,,,,
BJG0voC9YQ,2019,Accept (Poster),False,"Woulda, Coulda, Shoulda: Counterfactually-Guided Policy Search","[""Lars Buesing"", ""Theophane Weber"", ""Yori Zwols"", ""Nicolas Heess"", ""Sebastien Racaniere"", ""Arthur Guez"", ""Jean-Baptiste Lespiau""]","[""reinforcement learning"", ""generative models"", ""model-based reinforcement learning"", ""causal inference""]",,,,,
BJGVX3CqYm,2019,Reject,False,Mixed Precision Quantization of ConvNets via Differentiable Neural Architecture Search,"[""Bichen Wu"", ""Yanghan Wang"", ""Peizhao Zhang"", ""Yuandong Tian"", ""Peter Vajda"", ""Kurt Keutzer""]","[""Neural Net Quantization"", ""Neural Architecture Search""]",A novel differentiable neural architecture search framework for mixed quantization of ConvNets.,,,,
BJGWO9k0Z,2018,Accept (Poster),False,Critical Percolation as a Framework to Analyze the Training of Deep Networks,"[""Zohar Ringel"", ""Rodrigo Andrade de Bem""]","[""Deep Convolutional Networks"", ""Loss function landscape"", ""Graph Structured Data"", ""Training Complexity"", ""Theory of deep learning"", ""Percolation theory"", ""Anderson Localization""]",A toy dataset based on critical percolation in a planar graph provides an analytical window to the training dynamics of deep neural networks  ,,,,
BJG__i0qF7,2019,Reject,False,Learning to encode spatial relations from natural language,"[""Tiago Ramalho"", ""Tomas Kocisky\u200e"", ""Frederic Besse"", ""S. M. Ali Eslami"", ""Gabor Melis"", ""Fabio Viola"", ""Phil Blunsom"", ""Karl Moritz Hermann""]","[""generative model"", ""grounded language"", ""scene understanding"", ""natural language""]",We introduce a system capable of capturing the semantics of spatial relations by grounding representation learning in vision.,,,,
BJGfCjA5FX,2019,Reject,False,PAIRWISE AUGMENTED GANS WITH ADVERSARIAL RECONSTRUCTION LOSS,"[""Aibek Alanov"", ""Max Kochurov"", ""Daniil Yashkov"", ""Dmitry Vetrov""]","[""Computer vision"", ""Deep learning"", ""Unsupervised Learning"", ""Generative Adversarial Networks""]",We propose a novel autoencoding model with augmented adversarial reconstruction loss. We intoduce new metric for content-based assessment of reconstructions. ,,,,
BJGjOi09t7,2019,Reject,False,A Variational Autoencoder for Probabilistic Non-Negative Matrix Factorisation,"[""Steven Squires"", ""Adam Prugel-Bennett"", ""Mahesan Niranjan""]","[""Non-negative matrix factorisation"", ""Variational autoencoder"", ""Probabilistic""]",,,,,
BJIgi_eCZ,2018,Accept (Poster),False,FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension,"[""Hsin-Yuan Huang"", ""Chenguang Zhu"", ""Yelong Shen"", ""Weizhu Chen""]","[""Attention Mechanism"", ""Machine Comprehension"", ""Natural Language Processing"", ""Deep Learning""]","We propose a light-weight enhancement for attention and a neural architecture, FusionNet, to achieve SotA on SQuAD and adversarial SQuAD.",,,,
BJInEZsTb,2018,Invite to Workshop Track,False,Learning Representations and Generative Models for 3D Point Clouds,"[""Panos Achlioptas"", ""Olga Diamanti"", ""Ioannis Mitliagkas"", ""Leonidas Guibas""]","[""representation learning"", ""auto-encoders"", ""3D point clouds"", ""generative models"", ""GANs"", ""Gaussian Mixture Models""]",Deep autoencoders to learn a good representation for geometric 3D point-cloud data; Generative models for point clouds.,,,,
BJInMmWC-,2018,Reject,False,Generative Entity Networks: Disentangling Entitites and Attributes in Visual Scenes using Partial Natural Language Descriptions,"[""Charlie Nash"", ""Sebastian Nowozin"", ""Nate Kushman""]","[""VAE"", ""Generative Model"", ""Vision"", ""Natural Language""]",,,,,
BJJ9bz-0-,2018,Invite to Workshop Track,False,Reinforcement Learning from Imperfect Demonstrations,"[""Yang Gao"", ""Huazhe(Harry) Xu"", ""Ji Lin"", ""Fisher Yu"", ""Sergey Levine"", ""Trevor Darrell""]","[""learning from demonstration"", ""reinforcement learning"", ""maximum entropy learning""]",,,,,
BJJLHbb0-,2018,Accept (Poster),False,Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection,"[""Bo Zong"", ""Qi Song"", ""Martin Renqiang Min"", ""Wei Cheng"", ""Cristian Lumezanu"", ""Daeki Cho"", ""Haifeng Chen""]","[""Density estimation"", ""unsupervised anomaly detection"", ""high-dimensional data"", ""Deep autoencoder"", ""Gaussian mixture modeling"", ""latent low-dimensional space""]",An end-to-end trained deep neural network that leverages Gaussian Mixture Modeling to perform density estimation and unsupervised anomaly detection in a low-dimensional space learned by deep autoencoder.,,,,
BJK3Xasel,2017,Accept (Poster),False,Nonparametric Neural Networks,"[""George Philipp"", ""Jaime G. Carbonell""]","[""Deep learning"", ""Supervised Learning""]",We automatically set the size of an MLP by adding and removing units during training as appropriate.,,,,
BJKYvt5lg,2017,Accept (Poster),False,PixelVAE: A Latent Variable Model for Natural Images,"[""Ishaan Gulrajani"", ""Kundan Kumar"", ""Faruk Ahmed"", ""Adrien Ali Taiga"", ""Francesco Visin"", ""David Vazquez"", ""Aaron Courville""]","[""Deep learning"", ""Unsupervised Learning""]","VAE with an autoregressive PixelCNN-based decoder with strong performance on binarized MNIST, ImageNet 64x64, and LSUN bedrooms.",,,,
BJLmN8xRW,2018,Reject,False,Character Level Based Detection of DGA Domain Names,"[""Bin Yu"", ""Jie Pan"", ""Jiaming Hu"", ""Anderson Nascimento"", ""Martine De Cock""]","[""deep neural networks"", ""short text classification"", ""cybersecurity"", ""domain generation algorithms"", ""malicious domain names""]",A comparison of five deep neural network architectures for detection of malicious domain names shows surprisingly little difference.,,,,
BJMuY-gRW,2018,Reject,False,Jointly Learning Sentence Embeddings and Syntax with Unsupervised Tree-LSTMs,"[""Jean Maillard"", ""Stephen Clark"", ""Dani Yogatama""]","[""hierarchical"", ""tree-lstm"", ""treelstm"", ""syntax"", ""composition""]",Represent sentences by composing them with Tree-LSTMs according to automatically induced parse trees.,,,,
BJMvBjC5YQ,2019,Reject,False,Cutting Down Training Memory by Re-fowarding,"[""Jianwei Feng"", ""Dong Huang""]","[""deep learning"", ""training memory"", ""computation-memory trade off"", ""optimal solution""]","This paper proposes fundamental theory and optimal algorithms for DNN training, which reduce up to 80% of training memory for popular DNNs.",,,,
BJNRFNlRW,2018,Accept (Poster),False,TRAINING GENERATIVE ADVERSARIAL NETWORKS VIA PRIMAL-DUAL SUBGRADIENT METHODS: A LAGRANGIAN PERSPECTIVE ON GAN,"[""Xu Chen"", ""Jiang Wang"", ""Hao Ge""]","[""GAN"", ""Primal-Dual Subgradient"", ""Mode Collapse"", ""Saddle Point""]",We propose a primal-dual subgradient method for training GANs and this method effectively alleviates mode collapse.,,,,
BJO-BuT1g,2017,Accept (Poster),False,A Learned Representation For Artistic Style,"[""Vincent Dumoulin"", ""Jonathon Shlens"", ""Manjunath Kudlur""]","[""Computer vision"", ""Deep learning""]",A deep neural network to learn and combine artistic styles.,,,,
BJOFETxR-,2018,Accept (Oral),False,Learning to Represent Programs with Graphs,"[""Miltiadis Allamanis"", ""Marc Brockschmidt"", ""Mahmoud Khademi""]","[""programs"", ""source code"", ""graph neural networks""]","Programs have structure that can be represented as graphs, and graph neural networks can learn to find bugs on such graphs",,,,
BJQPG5lR-,2018,Reject,False,Avoiding degradation in deep feed-forward networks by phasing out skip-connections,"[""Ricardo Pio Monti"", ""Sina Tootoonian"", ""Robin Cao""]","[""optimization"", ""vanishing gradients"", ""shattered gradients"", ""skip-connections""]",Phasing out skip-connections in a principled manner avoids degradation in deep feed-forward networks.,,,,
BJQRKzbA-,2018,Accept (Poster),False,Hierarchical Representations for Efficient Architecture Search,"[""Hanxiao Liu"", ""Karen Simonyan"", ""Oriol Vinyals"", ""Chrisantha Fernando"", ""Koray Kavukcuoglu""]","[""deep learning"", ""architecture search""]",In this paper we propose a hierarchical architecture representation in which doing random or evolutionary architecture search yields highly competitive results using fewer computational resources than the prior art.,,,,
BJRIA3Fgg,2017,Invite to Workshop Track,False,Modularized Morphing of Neural Networks,"[""Tao Wei"", ""Changhu Wang"", ""Chang Wen Chen""]","[""Deep learning"", ""Computer vision""]",,,,,
BJRZzFlRb,2018,Accept (Poster),False,Compressing Word Embeddings via Deep Compositional Code Learning,"[""Raphael Shu"", ""Hideki Nakayama""]","[""natural language processing"", ""word embedding"", ""compression"", ""deep learning""]",Compressing the word embeddings over 94% without hurting the performance.,,,,
BJRxfZbAW,2018,Reject,False,The Context-Aware Learner,"[""Conor Durkan"", ""Amos Storkey"", ""Harrison Edwards""]",[],,,,,
BJVEEF9lx,2017,Reject,False,Learning Approximate Distribution-Sensitive Data Structures,"[""Zenna Tavares"", ""Armando Solar-Lezama""]","[""Unsupervised Learning""]",We model mental representations as abstract distribution-sensitive data types and synthesize concrete implementations using deep networks from specification,,,,
BJWfW2C9Y7,2019,Reject,False,Predictive Local Smoothness for Stochastic Gradient Methods,"[""Jun Li"", ""Hongfu Liu"", ""Bineng Zhong"", ""Yue Wu"", ""Yun Fu""]","[""stochastic gradient method"", ""local smoothness"", ""linear system"", ""AMSGrad""]",,,,,
BJYwwY9ll,2017,Accept (Poster),False,"Snapshot Ensembles: Train 1, Get M for Free","[""Gao Huang"", ""Yixuan Li"", ""Geoff Pleiss"", ""Zhuang Liu"", ""John E. Hopcroft"", ""Kilian Q. Weinberger""]","[""Deep learning"", ""Computer vision""]",,,,,
BJ_MGwqlg,2017,Reject,False,Rethinking Numerical Representations for Deep Neural Networks,"[""Parker Hill"", ""Babak Zamirai"", ""Shengshuo Lu"", ""Yu-Wei Chao"", ""Michael Laurenzano"", ""Mehrzad Samadi"", ""Marios Papaefthymiou"", ""Scott Mahlke"", ""Thomas Wenisch"", ""Jia Deng"", ""Lingjia Tang"", ""Jason Mars""]","[""Deep learning""]",We find that the optimal numerical representation for large-scale DNNs is very different than the small-scale ones that are used in current DNN hardware research.,,,,
BJ_QxP1AZ,2018,Reject,False,Unleashing the Potential of CNNs for Interpretable Few-Shot Learning,"[""Boyang Deng"", ""Qing Liu"", ""Siyuan Qiao"", ""Alan Yuille""]","[""Few-Shot Learning"", ""Neural Network Understanding"", ""Visual Concepts""]",We enable ordinary CNNs for few-shot learning by exploiting visual concepts which are interpretable visual cues learnt within CNNs.,,,,
BJ_UL-k0b,2018,Accept (Poster),False,Recasting Gradient-Based Meta-Learning as Hierarchical Bayes,"[""Erin Grant"", ""Chelsea Finn"", ""Sergey Levine"", ""Trevor Darrell"", ""Thomas Griffiths""]","[""meta-learning"", ""learning to learn"", ""hierarchical Bayes"", ""approximate Bayesian methods""]","A specific gradient-based meta-learning algorithm, MAML, is equivalent to an inference procedure in a hierarchical Bayesian model. We use this connection to improve MAML via methods from approximate inference and curvature estimation.",,,,
BJ_wN01C-,2018,Accept (Poster),False,Deep Rewiring: Training very sparse deep networks,"[""Guillaume Bellec"", ""David Kappel"", ""Wolfgang Maass"", ""Robert Legenstein""]","[""deep learning"", ""pruning"", ""LSTM"", ""convolutional networks"", ""recurrent neural network"", ""sparse networks"", ""neuromorphic hardware"", ""energy efficient computing"", ""low memory hardware"", ""stochastic differential equation"", ""fokker-planck equation""]","The paper presents Deep Rewiring, an algorithm that can be used to train deep neural networks when the network connectivity is severely constrained during training.",,,,
BJa0ECFxe,2017,Reject,False,Information Dropout: learning optimal representations through noise,"[""Alessandro Achille"", ""Stefano Soatto""]","[""Theory"", ""Deep learning""]","We introduce Information Dropout, an information theoretic generalization of dropout that highlights how injecting noise can help in learning invariant representations.",,,,
BJaU__eCZ,2018,Reject,False,Hallucinating brains with artificial brains,"[""Peiye Zhuang"", ""Alexander G. Schwing"", ""Oluwasanmi Koyejo""]","[""3D fMRI data"", ""Deep Learning"", ""Generative Adversarial Network"", ""Classification""]",Two novel GANs are constructed to generate high-quality 3D fMRI brain images and synthetic brain images greatly help to improve downstream classification tasks.,,,,
BJbD_Pqlg,2017,Reject,False,Human perception in computer vision,"[""Ron Dekel""]","[""Computer vision"", ""Transfer Learning""]",Correlates for several properties of human perception emerge in convolutional neural networks following image categorization learning.,,,,
BJcAWaeCW,2018,Reject,False,Graph Topological Features via GAN,"[""Weiyi Liu"", ""Hal Cooper"", ""Min-Hwan Oh""]","[""graph topology"", ""GAN"", ""network science"", ""hierarchical learning""]",A GAN based method to learn important topological features of an arbitrary input graph.,,,,
BJe-91BtvH,2020,Accept (Poster),True,Masked Based Unsupervised Content Transfer,"[""Ron Mokady"", ""Sagie Benaim"", ""Lior Wolf"", ""Amit Bermano""]",[],,1906.06558,cs.CV,2019-06-15 13:15:51+00:00,2020-01-13 12:04:01+00:00
BJe-DsC5Fm,2019,Accept (Poster),False,signSGD via Zeroth-Order Oracle,"[""Sijia Liu"", ""Pin-Yu Chen"", ""Xiangyi Chen"", ""Mingyi Hong""]","[""nonconvex optimization"", ""zeroth-order algorithm"", ""black-box adversarial attack""]","We design and analyze a new zeroth-order stochastic optimization algorithm, ZO-signSGD, and demonstrate its connection and application to black-box adversarial attacks in robust deep learning",,,,
BJe-Sn0ctm,2019,Reject,False,Ain't Nobody Got Time for Coding: Structure-Aware Program Synthesis from Natural Language,"[""Jakub Bednarek"", ""Karol Piaskowski"", ""Krzysztof Krawiec""]","[""Program synthesis"", ""tree2tree autoencoders"", ""soft attention"", ""doubly-recurrent neural networks"", ""LSTM"", ""nlp2tree""]","We generate source code based on short descriptions in natural language, using deep neural networks.",,,,
BJe-_CNKPH,2020,Reject,True,Attention Interpretability Across NLP Tasks,"[""Shikhar Vashishth"", ""Shyam Upadhyay"", ""Gaurav Singh Tomar"", ""Manaal Faruqui""]","[""Attention"", ""NLP"", ""Interpretability""]",Analysis of attention mechanism across diverse NLP tasks.,1909.11218,cs.CL,2019-09-24 22:58:44+00:00,2019-09-24 22:58:44+00:00
BJe-unNYPr,2020,Reject,False,Accelerated Information Gradient flow,"[""Yifei Wang"", ""Wuchen Li""]","[""Optimal transport"", ""Information geometry"", ""Nesterov accelerated gradient method""]",We study the accelerated gradient flows in the probability space.,,,,
BJe0Gn0cY7,2019,Accept (Poster),False,Preventing Posterior Collapse with delta-VAEs,"[""Ali Razavi"", ""Aaron van den Oord"", ""Ben Poole"", ""Oriol Vinyals""]","[""Posterior Collapse"", ""VAE"", ""Autoregressive Models""]", Avoid posterior collapse by lower bounding the rate.,,,,
BJe1334YDH,2020,Accept (Poster),False,A Learning-based Iterative Method for Solving Vehicle Routing Problems,"[""Hao Lu"", ""Xingwen Zhang"", ""Shuang Yang""]","[""vehicle routing"", ""reinforcement learning"", ""optimization"", ""heuristics""]",,,,,
BJe1E2R5KX,2019,Accept (Poster),False,Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees,"[""Yuping Luo"", ""Huazhe Xu"", ""Yuanzhi Li"", ""Yuandong Tian"", ""Trevor Darrell"", ""Tengyu Ma""]","[""model-based reinforcement learning"", ""sample efficiency"", ""deep reinforcement learning""]",We design model-based reinforcement learning algorithms with theoretical guarantees and achieve state-of-the-art results on Mujuco benchmark tasks when one million or fewer samples are permitted.,,,,
BJe1hsCcYQ,2019,Reject,False,Lorentzian Distance Learning,"[""Marc T Law"", ""Jake Snell"", ""Richard S Zemel""]","[""distance learning"", ""metric learning"", ""hyperbolic geometry"", ""hierarchy tree""]",A distance learning approach to learn hyperbolic representations,,,,
BJe4JJBYwS,2020,Reject,True,CROSS-DOMAIN CASCADED DEEP TRANSLATION,"[""Oren Katzir"", ""Dani Lischinski"", ""Daniel Cohen-Or""]","[""computer vision"", ""image translation"", ""generative adversarial networks""]","Image-to-image translation in a cascaded, deep-to-shallow, fashion, along the deep feature of a pre-trained classification network",1906.01526,cs.CV,2019-06-04 15:37:09+00:00,2019-06-04 15:37:09+00:00
BJe4PyrFvB,2020,Reject,False,Imagining the Latent Space of a Variational Auto-Encoders,"[""Zezhen Zeng"", ""Jonathon Hare"", ""Adam Pr\u00fcgel-Bennett""]","[""VAE"", ""GAN""]","To understand the information stored in the latent space, we train a GAN-style decoder constrained to produce images that the VAE encoder will map to the same region of latent space.",,,,
BJe4V1HFPr,2020,Reject,True,Disentangling Style and Content in Anime Illustrations,"[""Sitao Xiang"", ""Hao Li""]","[""Adversarial Training"", ""Generative Models"", ""Style Transfer"", ""Anime""]","An adversarial training-based method for disentangling two complementary sets of variations in a dataset where only one of them is labelled, tested on style vs. content in anime illustrations.",1905.10742,cs.CV,2019-05-26 06:17:09+00:00,2019-12-20 14:52:26+00:00
BJe4oxHYPB,2020,Reject,False,Winning the Lottery with Continuous Sparsification,"[""Pedro Savarese"", ""Hugo Silva"", ""Michael Maire""]",[],We propose a new algorithm that quickly finds winning tickets in neural networks.,,,,
BJe55gBtvH,2020,Accept (Spotlight),False,Depth-Width Trade-offs for ReLU Networks via Sharkovsky's Theorem,"[""Vaggos Chatziafratis"", ""Sai Ganesh Nagarajan"", ""Ioannis Panageas"", ""Xiao Wang""]","[""Depth-Width trade-offs"", ""ReLU networks"", ""chaos theory"", ""Sharkovsky Theorem"", ""dynamical systems""]","In this work, we point to a new connection between DNNs expressivity and Sharkovskyâs Theorem from dynamical systems, that enables us to characterize the depth-width trade-offs of ReLU networks ",1912.04378,cs.LG,2019-12-09 21:11:02+00:00,2019-12-09 21:11:02+00:00
BJe7h34YDS,2020,Reject,False,Understanding and Stabilizing GANs' Training Dynamics with Control Theory,"[""Kun Xu"", ""Chongxuan Li"", ""Huanshu Wei"", ""Jun Zhu"", ""Bo Zhang""]","[""Generative Adversarial Nets"", ""Stability Analysis"", ""Control Theory""]",We adopt the control theory to understand and stabilize the dynamics of GANs.,,,,
BJe8pkHFwS,2020,Accept (Poster),True,GraphSAINT: Graph Sampling Based Inductive Learning Method,"[""Hanqing Zeng"", ""Hongkuan Zhou"", ""Ajitesh Srivastava"", ""Rajgopal Kannan"", ""Viktor Prasanna""]","[""Graph Convolutional Networks"", ""Graph sampling"", ""Network embedding""]",We propose a graph sampling based minibatch construction method for training deep Graph Convolutional Networks on large graphs. ,1907.04931,cs.LG,2019-07-10 21:11:13+00:00,2020-02-16 00:42:48+00:00
BJe932EYwS,2020,Reject,False,PNAT: Non-autoregressive Transformer by Position Learning,"[""Yu Bao"", ""Hao Zhou"", ""Jiangtao Feng"", ""Mingxuan Wang"", ""Shujian Huang"", ""Jiajun Chen"", ""Lei Li""]","[""Text Generation""]",,1911.10677,cs.CL,2019-11-25 03:08:42+00:00,2019-11-25 03:08:42+00:00
BJeAHkrYDS,2020,Accept (Talk),False,Fast Task Inference with Variational Intrinsic Successor Features,"[""Steven Hansen"", ""Will Dabney"", ""Andre Barreto"", ""David Warde-Farley"", ""Tom Van de Wiele"", ""Volodymyr Mnih""]","[""Reinforcement Learning"", ""Variational Intrinsic Control"", ""Successor Features""]","We introduce Variational Intrinsic Successor FeatuRes (VISR), a novel algorithm which learns controllable features that can be leveraged to provide fast task inference through the successor features framework.",,,,
BJeB5hVtvB,2020,Accept (Poster),False,Distance-Based Learning from Errors for Confidence Calibration,"[""Chen Xing"", ""Sercan Arik"", ""Zizhao Zhang"", ""Tomas Pfister""]","[""Confidence Calibration"", ""Uncertainty Estimation"", ""Prototypical Learning""]",,1912.01730,cs.LG,2019-12-03 22:51:51+00:00,2020-02-18 03:44:43+00:00
BJeFQ0NtPS,2020,Reject,True,Parallel Neural Text-to-Speech,"[""Kainan Peng"", ""Wei Ping"", ""Zhao Song"", ""Kexin Zhao""]","[""text-to-speech"", ""non-autoregressive model"", ""parallel decoding""]",,1905.08459,cs.CL,2019-05-21 06:36:15+00:00,2020-06-29 20:15:59+00:00
BJeGA6VtPS,2020,Reject,False,TrojanNet: Exposing the Danger of Trojan Horse Attack on Neural Networks,"[""Chuan Guo"", ""Ruihan Wu"", ""Kilian Q. Weinberger""]","[""machine learning security""]","Parameters of a trained neural network can be permuted to produce a completely separate model for a different task, enabling the embedding of Trojan horse networks inside another network.",,,,
BJeGZxrFvS,2020,Reject,True,A Simple Technique to Enable Saliency Methods to Pass the Sanity Checks,"[""Arushi Gupta"", ""Sanjeev Arora""]","[""saliency"", ""attribution"", ""interpretability"", ""sanity checks""]",We devise a mechanism called competition among pixels that allows (approximately) complete saliency methods to pass the sanity checks.,1905.12152,cs.LG,2019-05-27 23:15:11+00:00,2019-06-07 00:55:44+00:00
BJeGlJStPr,2020,Accept (Poster),False,IMPACT: Importance Weighted Asynchronous Architectures with Clipped Target Networks,"[""Michael Luo"", ""Jiahao Yao"", ""Richard Liaw"", ""Eric Liang"", ""Ion Stoica""]","[""Reinforcement Learning"", ""Artificial Intelligence"", ""Distributed Computing"", ""Neural Networks""]",IMPACT helps RL agents train faster by decreasing training wall-clock time and increasing sample efficiency simultaneously.,1912.00167,cs.LG,2019-11-30 09:44:19+00:00,2020-01-23 07:30:51+00:00
BJeKh3VYDH,2020,Accept (Spotlight),True,Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds,"[""Lukas Prantl"", ""Nuttapong Chentanez"", ""Stefan Jeschke"", ""Nils Thuerey""]","[""point clouds"", ""spatio-temporal representations"", ""Lagrangian data"", ""temporal coherence"", ""super-resolution"", ""denoising""]",We propose a generative neural network approach for temporally coherent point clouds.,1907.05279,cs.CV,2019-07-03 18:54:02+00:00,2020-01-29 10:55:16+00:00
BJeKwTNFvB,2020,Accept (Poster),True,Physics-as-Inverse-Graphics: Unsupervised Physical Parameter Estimation from Video,"[""Miguel Jaques"", ""Michael Burke"", ""Timothy Hospedales""]",[],"We propose a model that is able to perform physical parameter estimation of systems from video, where the differential equations governing the scene dynamics are known, but labeled states or objects are not available.",1905.11169,cs.CV,2019-05-27 12:37:14+00:00,2020-04-21 12:14:26+00:00
BJeOioA9Y7,2019,Accept (Poster),False,Knowledge Flow: Improve Upon Your Teachers,"[""Iou-Jen Liu"", ""Jian Peng"", ""Alexander Schwing""]","[""Transfer Learning"", ""Reinforcement Learning""]",âKnowledge Flowâ trains a deep net (student) by injecting information from multiple nets (teachers). The student is independent upon training and performs very well on learned tasks irrespective of the setting (reinforcement or supervised learning).,,,,
BJeRg205Fm,2019,Reject,False,"Neural Network Regression with Beta, Dirichlet, and Dirichlet-Multinomial Outputs","[""Peter Sadowski"", ""Pierre Baldi""]","[""regression"", ""uncertainty"", ""deep learning""]",Neural network regression should use Dirichlet output distribution when targets are probabilities in order to quantify uncertainty of predictions.,,,,
BJeRykBKDH,2020,Reject,False,Empowering Graph Representation Learning with Paired Training and Graph Co-Attention,"[""Andreea Deac"", ""Yu-Hsiang Huang"", ""Petar Velickovic"", ""Pietro Lio"", ""Jian Tang""]","[""graph neural networks"", ""graph co-attention"", ""paired graphs"", ""molecular properties"", ""drug-drug interaction""]",We use graph co-attention in a paired graph training system for graph classification and regression.,,,,
BJeS62EtwH,2020,Accept (Poster),True,Knowledge Consistency between Neural Networks and Beyond,"[""Ruofan Liang"", ""Tianlin Li"", ""Longfei Li"", ""Jing Wang"", ""Quanshi Zhang""]","[""Deep Learning"", ""Interpretability"", ""Convolutional Neural Networks""]",,1908.01581,cs.LG,2019-08-05 12:25:37+00:00,2020-01-14 17:30:39+00:00
BJeTCAEtDB,2020,Reject,True,Feature Map Transform Coding for Energy-Efficient CNN Inference,"[""Brian Chmiel"", ""Chaim Baskin"", ""Ron Banner"", ""Evgenii Zheltonozhskii"", ""Yevgeny Yermolin"", ""Alex Karbachevsky"", ""Alex M. Bronstein"", ""Avi Mendelson""]","[""compression"", ""efficient inference"", ""quantization"", ""memory bandwidth"", ""entropy""]",Using PCA as decorellation transformation on activations to reduce memory bandwidth and energy footprint of NN accelerators,1905.10830,cs.CV,2019-05-26 16:29:47+00:00,2019-09-26 14:43:47+00:00
BJeUs3VFPH,2020,Reject,False,Domain Adaptation via Low-Rank Basis Approximation,"[""Christoph Raab"", ""Frank-Michael Schleif""]","[""Domain Adaptation"", ""Basis Transfer"", ""Transfer Learning"", ""Low Rank Approximation"", ""Nystr\u00f6m Approximation""]",The paper describes a low-rank basis transfer algorithm using only a subset from the domains with outstanding results.,,,,
BJeVklHtPr,2020,Reject,False,Batch Normalization has Multiple Benefits: An Empirical Study on Residual Networks,"[""Soham De"", ""Samuel L Smith""]","[""batch normalization"", ""residual networks"", ""initialization"", ""batch size"", ""learning rate"", ""ImageNet""]",The multiple benefits of batch normalization can only be understood if one experiments at a range of batch sizes,,,,
BJeWOi09FQ,2019,Reject,False,SHAMANN: Shared Memory Augmented Neural Networks,"[""Cosmin I. Bercea"", ""Olivier Pauly"", ""Andreas K. Maier"", ""Florin C. Ghesu""]","[""memory networks"", ""deep learning"", ""medical image segmentation""]",Multiple virtual actors cooperating through shared memory solve medical image segmentation.,,,,
BJeWUs05KQ,2019,Accept (Poster),False,Directed-Info GAIL: Learning Hierarchical Policies from Unsegmented Demonstrations using Directed Information,"[""Mohit Sharma"", ""Arjun Sharma"", ""Nicholas Rhinehart"", ""Kris M. Kitani""]","[""Imitation Learning"", ""Reinforcement Learning"", ""Deep Learning""]",Learning Hierarchical Policies from Unsegmented Demonstrations using Directed Information,,,,
BJeWVpNtwr,2020,Reject,False,On the Pareto Efficiency of Quantized CNN,"[""Ting-Wu Chin"", ""Pierce I-Jen Chuang"", ""Vikas Chandra"", ""Diana Marculescu""]","[""convolutional neural networks quantization"", ""model compression"", ""efficient neural network""]",,,,,
BJeXaJHKvB,2020,Reject,False,P-BN: Towards Effective Batch Normalization in the Path Space,"[""Xufang Luo"", ""Qi Meng"", ""Wei Chen"", ""Tie-Yan Liu""]",[],,,,,
BJeY6sR9KX,2019,Reject,False,Aligning Artificial Neural Networks to the Brain yields Shallow Recurrent Architectures,"[""Jonas Kubilius"", ""Martin Schrimpf"", ""Ha Hong"", ""Najib J. Majaj"", ""Rishi Rajalingham"", ""Elias B. Issa"", ""Kohitij Kar"", ""Pouya Bashivan"", ""Jonathan Prescott-Roy"", ""Kailyn Schmidt"", ""Aran Nayebi"", ""Daniel Bear"", ""Daniel L. K. Yamins"", ""James J. DiCarlo""]","[""Computational Neuroscience"", ""Brain-Inspired"", ""Neural Networks"", ""Simplified Models"", ""Recurrent Neural Networks"", ""Computer Vision""]",,,,,
BJe_z1HFPr,2020,Reject,False,Resizable Neural Networks,"[""Yichen Zhu"", ""Xiangyu Zhang"", ""Tong Yang"", ""Jian Sun""]",[],,,,,
BJeapjA5FX,2019,Reject,False,GEOMETRIC AUGMENTATION FOR ROBUST NEURAL NETWORK CLASSIFIERS,"[""Robert M. Taylor"", ""Yusong Tan""]","[""Bayesian nonparametric"", ""robust"", ""deep neural network"", ""classifier"", ""unsupervised learning"", ""geometric""]",We develop a statistical-geometric unsupervised learning augmentation framework for deep neural networks to make them robust to adversarial attacks.,,,,
BJedHRVtPB,2020,Accept (Poster),True,Pseudo-LiDAR++: Accurate Depth for 3D Object Detection in Autonomous Driving,"[""Yurong You"", ""Yan Wang"", ""Wei-Lun Chao"", ""Divyansh Garg"", ""Geoff Pleiss"", ""Bharath Hariharan"", ""Mark Campbell"", ""Kilian Q. Weinberger""]","[""pseudo-LiDAR"", ""3D-object detection"", ""stereo depth estimation"", ""autonomous driving""]",,1906.06310,cs.CV,2019-06-14 17:36:11+00:00,2020-02-15 07:29:02+00:00
BJedt6VKPS,2020,Reject,False,"Scaling Laws for the Principled Design, Initialization, and Preconditioning of ReLU Networks","[""Aaron Defazio"", ""Leon Bottou""]","[""initialization"", ""mlp"", ""relu""]",A theory for initialization and scaling of ReLU neural network layers,,,,
BJeem3C9F7,2019,Reject,False,Pix2Scene: Learning Implicit 3D Representations from Images,"[""Sai Rajeswar"", ""Fahim Mannan"", ""Florian Golemo"", ""David Vazquez"", ""Derek Nowrouzezahrai"", ""Aaron Courville""]","[""Representation learning"", ""generative model"", ""adversarial learning"", ""implicit 3D generation"", ""scene generation""]",pix2scene: a deep generative based approach for implicitly modelling the geometrical properties of a 3D scene from images,,,,
BJeguTEKDB,2020,Reject,False,INSTANCE CROSS ENTROPY FOR DEEP METRIC LEARNING,"[""Xinshao Wang"", ""Elyor Kodirov"", ""Yang Hua"", ""Neil M. Robertson""]","[""Deep Metric Learning"", ""Instance Cross Entropy"", ""Sample Mining/Weighting"", ""Image Retrieval""]",We propose instance cross entropy (ICE) which measures the difference between an estimated instance-level matching distribution and its ground-truth one. ,,,,
BJehNfW0-,2018,Accept (Poster),False,Do GANs learn the distribution? Some Theory and Empirics,"[""Sanjeev Arora"", ""Andrej Risteski"", ""Yi Zhang""]","[""Generative Adversarial Networks"", ""mode collapse"", ""birthday paradox"", ""support size estimation""]","We propose a support size estimator of GANs's learned distribution to show they indeed suffer from mode collapse, and we prove that encoder-decoder GANs do not avoid the issue as well.",,,,
BJej72AqF7,2019,Accept (Poster),False,A Max-Affine Spline Perspective of Recurrent Neural Networks,"[""Zichao Wang"", ""Randall Balestriero"", ""Richard Baraniuk""]","[""RNN"", ""max-affine spline operators""]",We provide new insights and interpretations of RNNs from a max-affine spline operators perspective.,,,,
BJemQ209FQ,2019,Accept (Poster),False,Learning to Navigate the Web,"[""Izzeddin Gur"", ""Ulrich Rueckert"", ""Aleksandra Faust"", ""Dilek Hakkani-Tur""]","[""navigating web pages"", ""reinforcement learning"", ""q learning"", ""curriculum learning"", ""meta training""]","We train reinforcement learning policies using reward augmentation, curriculum learning, and meta-learning  to successfully navigate web pages.",,,,
BJena3VtwS,2020,Reject,False,The Visual Task Adaptation Benchmark,"[""Xiaohua Zhai"", ""Joan Puigcerver"", ""Alexander Kolesnikov"", ""Pierre Ruyssen"", ""Carlos Riquelme"", ""Mario Lucic"", ""Josip Djolonga"", ""Andre Susano Pinto"", ""Maxim Neumann"", ""Alexey Dosovitskiy"", ""Lucas Beyer"", ""Olivier Bachem"", ""Michael Tschannen"", ""Marcin Michalski"", ""Olivier Bousquet"", ""Sylvain Gelly"", ""Neil Houlsby""]","[""representation learning"", ""self-supervised learning"", ""benchmark"", ""large-scale study""]","VTAB is a unified, realistic, and challenging benchmark for general visual representation learning. With it, we evaluate many methods.",,,,
BJepcaEtwB,2020,Reject,False,Meta-Graph: Few shot Link Prediction via Meta Learning,"[""Avishek Joey Bose"", ""Ankit Jain"", ""Piero Molino"", ""William L. Hamilton""]","[""Meta Learning"", ""Link Prediction"", ""Graph Representation Learning"", ""Graph Neural Networks""]",We apply gradient based meta-learning to the graph domain and introduce a new graph specific transfer function to further bootstrap the process.,1912.09867,cs.LG,2019-12-20 15:09:50+00:00,2020-03-01 21:03:29+00:00
BJepq2VtDB,2020,Reject,False,Training Deep Networks with Stochastic Gradient Normalized by Layerwise Adaptive Second Moments,"[""Boris Ginsburg"", ""Patrice Castonguay"", ""Oleksii Hrinchuk"", ""Oleksii Kuchaiev"", ""Vitaly Lavrukhin"", ""Ryan Leary"", ""Jason Li"", ""Huyen Nguyen"", ""Yang Zhang"", ""Jonathan M. Cohen""]","[""deep learning"", ""optimization"", ""SGD"", ""Adam"", ""NovoGrad"", ""large batch training""]",NovoGrad -  an adaptive SGD method with layer-wise gradient normalization and decoupled weight decay. ,,,,
BJerUCEtPB,2020,Reject,False,Smooth Kernels Improve Adversarial Robustness and Perceptually-Aligned Gradients,"[""Haohan Wang"", ""Xindi Wu"", ""Songwei Ge"", ""Zachary C. Lipton"", ""Eric P. Xing""]","[""adversarial robustness"", ""computer vision"", ""smoothness regularization""]",We introduce a smoothness regularization for convolutional kernels of CNN that can help improve adversarial robustness and lead to perceptually-aligned gradients,,,,
BJesDsA9t7,2019,Reject,False,Better Accuracy with Quantified Privacy: Representations Learned via Reconstructive Adversarial Network,"[""Sicong Liu"", ""Anshumali Shrivastava"", ""Junzhao Du"", ""Lin Zhong""]","[""end-user privacy"", ""utility"", ""feature learning"", ""adversarial training""]",,,,,
BJes_xStwS,2020,Reject,False,GRASPEL: GRAPH SPECTRAL LEARNING AT SCALE,"[""Yongyu Wang"", ""Zhiqiang Zhao"", ""Zhuo Feng""]","[""Spectral graph theory"", ""graph learning"", ""data clustering"", ""t-SNE visualization""]",A spectral approach to scalable graph learning from data,1911.10373,cs.LG,2019-11-23 14:51:13+00:00,2020-07-28 21:08:51+00:00
BJeuKnEtDH,2020,Reject,False,Cascade Style Transfer,"[""Zhizhong Wang"", ""Lei Zhao"", ""Qihang Mo"", ""Sihuan Lin"", ""Zhiwen Zuo"", ""Wei Xing"", ""Dongming Lu""]","[""style transfer"", ""cascade"", ""quality"", ""flexibility"", ""domain-independent"", ""serial"", ""parallel""]",,,,,
BJevJCVYvB,2020,Reject,False,Training Neural Networks for and by Interpolation,"[""Leonard Berrada"", ""Andrew Zisserman"", ""Pawan M. Kumar""]","[""optimization"", ""adaptive learning-rate"", ""Polyak step-size"", ""Newton-Raphson""]",An adaptive learning-rate with a single hyper-parameter for neural networks that can interpolate the data,,,,
BJevihVtwB,2020,Reject,True,BOOSTING ENCODER-DECODER CNN FOR INVERSE PROBLEMS,"[""Eunju Cha"", ""Jaeduck Jang"", ""Junho Lee"", ""Eunha Lee"", ""Jong Chul Ye""]","[""Prediction error"", ""Boosting"", ""Encoder-decoder convolutional neural network"", ""Inverse problem""]",,1906.07330,cs.CV,2019-06-18 01:21:40+00:00,2019-06-18 01:21:40+00:00
BJewlyStDr,2020,Accept (Poster),False,On Bonus Based Exploration Methods In The Arcade Learning Environment,"[""Adrien Ali Taiga"", ""William Fedus"", ""Marlos C. Machado"", ""Aaron Courville"", ""Marc G. Bellemare""]","[""exploration"", ""arcade learning environment"", ""bonus-based methods""]",We find that existing bonus-based exploration methods have not been able to address the exploration-exploitation trade-off in the Arcade Learning Environment. ,,,,
BJexP6VKwH,2020,Reject,False,Generalized Domain Adaptation with Covariate and Label Shift CO-ALignment,"[""Shuhan Tan"", ""Xingchao Peng"", ""Kate Saenko""]","[""Domain Adaptation"", ""Label Shift"", ""Covariate Shift""]",We propose a covariate and label distribution CO-ALignment (COAL) model to tackle Generalized Domain Adaptation (GDA) with covariant shift and label shift.,,,,
BJfIVjAcKm,2019,Accept (Poster),False,Training for Faster Adversarial Robustness Verification via Inducing ReLU Stability,"[""Kai Y. Xiao"", ""Vincent Tjeng"", ""Nur Muhammad (Mahi) Shafiullah"", ""Aleksander Madry""]","[""verification"", ""adversarial robustness"", ""adversarial examples"", ""stability"", ""deep learning"", ""regularization""]",We develop methods to train deep neural models that are both robust to adversarial perturbations and whose robustness is significantly easier to verify.,,,,
BJfOXnActQ,2019,Accept (Poster),False,Learning to Learn with Conditional Class Dependencies,"[""Xiang Jiang"", ""Mohammad Havaei"", ""Farshid Varno"", ""Gabriel Chartrand"", ""Nicolas Chapados"", ""Stan Matwin""]","[""meta-learning"", ""learning to learn"", ""few-shot learning""]",CAML is an instance of MAML with conditional class dependencies.,,,,
BJfRpoA9YX,2019,Reject,False,Adversarial Information Factorization,"[""Antonia Creswell"", ""Yumnah Mohamied"", ""Biswa Sengupta"", ""Anil Bharath""]","[""disentangled representations"", ""factored representations"", ""generative adversarial networks"", ""variational auto encoders"", ""generative models""]",Learn representations for images that factor out a single attribute.,,,,
BJfYvo09Y7,2019,Accept (Poster),False,Hierarchical Visuomotor Control of Humanoids,"[""Josh Merel"", ""Arun Ahuja"", ""Vu Pham"", ""Saran Tunyasuvunakool"", ""Siqi Liu"", ""Dhruva Tirumala"", ""Nicolas Heess"", ""Greg Wayne""]","[""hierarchical reinforcement learning"", ""motor control"", ""motion capture""]","Solve tasks involving vision-guided humanoid locomotion, reusing locomotion behavior from motion capture data.",,,,
BJf_YjCqYX,2019,Reject,False,Identifying Bias in AI using Simulation,"[""Daniel McDuff"", ""Roger Cheng"", ""Ashish Kapoor""]","[""Bias"", ""Simulation"", ""Optimization"", ""Face Detection""]",We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. ,,,,
BJfguoAcFm,2019,Reject,False,Learning Kolmogorov Models for Binary Random Variables,"[""Hadi Ghauch"", ""Hossein S. Ghadikolaei"", ""Mikael Skoglund"", ""Carlo Fischione""]","[""Kolmogorov model"", ""interpretable models"", ""causal relations mining"", ""non-convex optimization"", ""relaxations""]",,,,,
BJfvAoC9YQ,2019,Reject,False,Feature Transformers: A Unified Representation Learning Framework for Lifelong Learning,"[""Hariharan Ravishankar"", ""Rahul Venkataramani"", ""Saihareesh Anamandra"", ""Prasad Sudhakar""]","[""continual learning"", ""deep learning"", ""lifelong learning"", ""new task learning"", ""representation learning""]",Single generic mathematical framework for lifelong learning paradigms with data privacy,,,,
BJfvknCqFQ,2019,Reject,False,A Rotation and a Translation Suffice: Fooling CNNs with Simple Transformations,"[""Logan Engstrom"", ""Brandon Tran"", ""Dimitris Tsipras"", ""Ludwig Schmidt"", ""Aleksander Madry""]","[""robustness"", ""spatial transformations"", ""invariance"", ""rotations"", ""data augmentation"", ""robust optimization""]",We show that CNNs are not robust to simple rotations and translation and explore methods of improving this.,,,,
BJg15lrKvS,2020,Reject,False,Towards Understanding the Spectral Bias of Deep Learning,"[""Yuan Cao"", ""Zhiying Fang"", ""Yue Wu"", ""Ding-Xuan Zhou"", ""Quanquan Gu""]",[],,1912.01198,cs.LG,2019-12-03 05:34:30+00:00,2020-10-05 17:51:35+00:00
BJg1f6EFDB,2020,Accept (Poster),False,On Identifiability in Transformers,"[""Gino Brunner"", ""Yang Liu"", ""Damian Pascual"", ""Oliver Richter"", ""Massimiliano Ciaramita"", ""Roger Wattenhofer""]","[""Self-attention"", ""interpretability"", ""identifiability"", ""BERT"", ""Transformer"", ""NLP"", ""explanation"", ""gradient attribution""]",We investigate the identifiability and interpretability of attention distributions and tokens within contextual embeddings in the self-attention based BERT model.,,,,
BJg1fgBYwH,2020,Reject,False,SAFE-DNN: A Deep Neural Network with Spike Assisted Feature Extraction for Noise Robust Inference,"[""Xueyuan She"", ""Priyabrata Saha"", ""Daehyun Kim"", ""Yun Long"", ""Saibal Mukhopadhyay""]","[""Noise robust"", ""deep learning"", ""DNN"", ""image classification""]",A noise robust deep learning architecture.,,,,
BJg4NgBKvH,2020,Accept (Poster),False,Training binary neural networks with real-to-binary convolutions,"[""Brais Martinez"", ""Jing Yang"", ""Adrian Bulat"", ""Georgios Tzimiropoulos""]","[""binary networks""]",,2003.11535,cs.CV,2020-03-25 17:54:38+00:00,2020-03-25 17:54:38+00:00
BJg4Z3RqF7,2019,Accept (Poster),False,Unsupervised Adversarial Image Reconstruction,"[""Arthur Pajot"", ""Emmanuel de Bezenac"", ""Patrick Gallinari""]","[""Deep Learning"", ""Adversarial"", ""MAP"", ""GAN"", ""neural networks""]",,,,,
BJg641BKPH,2020,Reject,True,Gradient Descent can Learn Less Over-parameterized Two-layer Neural Networks on Classification Problems,"[""Atsushi Nitanda"", ""Geoffrey Chinot"", ""Taiji Suzuki""]","[""gradient descent"", ""neural network"", ""over-parameterization""]",,1905.09870,stat.ML,2019-05-23 18:57:35+00:00,2020-03-18 13:59:10+00:00
BJg73xHtvr,2020,Reject,False,Constant Curvature Graph Convolutional Networks,"[""Gregor Bachmann"", ""Gary B\u00e9cigneul"", ""Octavian-Eugen Ganea""]","[""graph convolutional neural networks"", ""hyperbolic spaces"", ""gyrvector spaces"", ""riemannian manifolds"", ""graph embeddings""]",We generalize GCNs to (products of) spaces of constant sectional curvature using the gyrovector space formalism.,1911.05076,cs.LG,2019-11-12 16:57:00+00:00,2020-05-19 17:48:48+00:00
BJg7x1HFvB,2020,Reject,True,Well-Read Students Learn Better: On the Importance of Pre-training Compact Models,"[""Iulia Turc"", ""Ming-Wei Chang"", ""Kenton Lee"", ""Kristina Toutanova""]","[""NLP"", ""self-supervised learning"", ""language model pre-training"", ""knowledge distillation"", ""BERT"", ""compact models""]",Studies how self-supervised learning and knowledge distillation interact in the context of building compact models.,1908.08962,cs.CL,2019-08-23 18:02:05+00:00,2019-09-25 22:55:20+00:00
BJg866NFvB,2020,Accept (Spotlight),False,Estimating counterfactual treatment outcomes over time through adversarially balanced representations,"[""Ioana Bica"", ""Ahmed M Alaa"", ""James Jordon"", ""Mihaela van der Schaar""]","[""treatment effects over time"", ""causal inference"", ""counterfactual estimation""]",,,,,
BJg8_xHtPr,2020,Reject,False,OBJECT-ORIENTED REPRESENTATION OF 3D SCENES,"[""Chang Chen"", ""Sungjin Ahn""]","[""unsupervised learning"", ""representation learning"", ""3D scene decomposition"", ""3D detection""]",,,,,
BJg9DoR9t7,2019,Accept (Poster),False,Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds,"[""Peng Cao*"", ""Yilun Xu*"", ""Yuqing Kong"", ""Yizhou  Wang""]","[""crowdsourcing"", ""information theory""]",,,,,
BJg9hTNKPH,2020,Reject,False,Behavior Regularized Offline Reinforcement Learning,"[""Yifan Wu"", ""George Tucker"", ""Ofir Nachum""]","[""reinforcement learning"", ""offline RL"", ""batch RL""]",,,,,
BJgAf6Etwr,2020,Reject,True,XLDA: Cross-Lingual Data Augmentation for Natural Language Inference and Question Answering,"[""Jasdeep Singh"", ""Bryan McCann"", ""Nitish Shirish Keskar"", ""Caiming Xiong"", ""Richard Socher""]","[""cross-lingual"", ""transfer learning"", ""BERT""]",Translating portions of the input during training can improve cross-lingual performance.,1905.11471,cs.CL,2019-05-27 19:44:33+00:00,2019-05-27 19:44:33+00:00
BJgEd6NYPH,2020,Reject,False,Ellipsoidal Trust Region Methods for Neural Network Training,"[""Leonard Adolphs"", ""Jonas Kohler"", ""Aurelien Lucchi""]","[""non-convex"", ""optimization"", ""neural networks"", ""trust-region""]",We prepose a generalization of adaptive gradient methods to second-order algorithms.,,,,
BJgEjiRqYX,2019,Reject,False,A Case for Object Compositionality in Deep Generative Models of Images,"[""Sjoerd van Steenkiste"", ""Karol Kurach"", ""Sylvain Gelly""]","[""Objects"", ""Compositionality"", ""Generative Models"", ""GAN"", ""Unsupervised Learning""]","We propose to structure the generator of a GAN to consider objects and their relations explicitly, and generate images by means of composition",,,,
BJgGhiR5KX,2019,Reject,False,Learning Cross-Lingual Sentence Representations via a Multi-task Dual-Encoder Model,"[""Muthuraman Chidambaram"", ""Yinfei Yang"", ""Daniel Cer"", ""Steve Yuan"", ""Yun-Hsuan Sung"", ""Brian Strope"", ""Ray Kurzweil""]","[""sentence"", ""embeddings"", ""zero-shot"", ""multilingual"", ""multi-task"", ""cross-lingual""]",State-of-the-art zero-shot learning performance by using a translation task to bridge multi-task training across languages.,,,,
BJgK6iA5KX,2019,Accept (Poster),False,AutoLoss: Learning Discrete Schedule for Alternate Optimization,"[""Haowen Xu"", ""Hao Zhang"", ""Zhiting Hu"", ""Xiaodan Liang"", ""Ruslan Salakhutdinov"", ""Eric Xing""]","[""Meta Learning"", ""AutoML"", ""Optimization Schedule""]","We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.",,,,
BJgLg3R9KQ,2019,Accept (Poster),False,Learning what and where to attend,"[""Drew Linsley"", ""Dan Shiebler"", ""Sven Eberhardt"", ""Thomas Serre""]","[""Attention models"", ""human feature importance"", ""object recognition"", ""cognitive science""]","A large-scale dataset for training attention models for object recognition leads to more accurate, interpretable, and human-like object recognition.",,,,
BJgLpaEtDS,2020,Reject,False,PoincarÃ© Wasserstein Autoencoder,"[""Ivan Ovinnikov""]","[""Variational inference"", ""hyperbolic geometry"", ""hierarchical latent space"", ""representation learning""]",Wasserstein Autoencoder with hyperbolic latent space,,,,
BJgMFxrYPB,2020,Accept (Poster),False,Learning to Move with Affordance Maps,"[""William Qi"", ""Ravi Teja Mullapudi"", ""Saurabh Gupta"", ""Deva Ramanan""]","[""navigation"", ""exploration""]","We address the task of autonomous exploration and navigation using spatial affordance maps that can be learned in a self-supervised manner, these outperform classic geometric baselines while being more sample efficient than contemporary RL algorithms",2001.02364,cs.RO,2020-01-08 04:05:11+00:00,2020-02-14 19:01:26+00:00
BJgNJgSFPS,2020,Accept (Talk),False,Building Deep Equivariant Capsule Networks,"[""Sai Raam Venkataraman"", ""S. Balasubramanian"", ""R. Raghunatha Sarma""]","[""Capsule networks"", ""equivariance""]","A new scalable, group-equivariant model for capsule networks that preserves compositionality under transformations, and is empirically more transformation-robust to older capsule network models.",,,,
BJgPCveAW,2018,Reject,False,Characterizing Sparse Connectivity Patterns in Neural Networks,"[""Sourya Dey"", ""Kuan-Wen Huang"", ""Peter A. Beerel"", ""Keith M. Chugg""]","[""Machine learning"", ""Neural networks"", ""Sparse neural networks"", ""Pre-defined sparsity"", ""Scatter"", ""Connectivity patterns"", ""Adjacency matrix"", ""Parameter Reduction"", ""Morse code""]",Neural networks can be pre-defined to have sparse connectivity without performance degradation.,,,,
BJgQ4lSFPH,2020,Accept (Poster),False,StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding,"[""Wei Wang"", ""Bin Bi"", ""Ming Yan"", ""Chen Wu"", ""Jiangnan Xia"", ""Zuyi Bao"", ""Liwei Peng"", ""Luo Si""]",[],,,,,
BJgQB20qFQ,2019,Reject,False,Learning to Progressively Plan,"[""Xinyun Chen"", ""Yuandong Tian""]",[],,,,,
BJgQfkSYDS,2020,Accept (Poster),True,Neural Policy Gradient Methods: Global Optimality and Rates of Convergence,"[""Lingxiao Wang"", ""Qi Cai"", ""Zhuoran Yang"", ""Zhaoran Wang""]",[],,1909.01150,cs.LG,2019-08-29 15:38:19+00:00,2019-11-12 21:42:43+00:00
BJgRDjR9tQ,2019,Accept (Poster),False,ROBUST ESTIMATION VIA GENERATIVE ADVERSARIAL NETWORKS,"[""Chao GAO"", ""jiyi LIU"", ""Yuan YAO"", ""Weizhi ZHU""]","[""robust statistics"", ""neural networks"", ""minimax rate"", ""data depth"", ""contamination model"", ""Tukey median"", ""GAN""]",GANs are shown to provide us a new effective robust mean estimate against agnostic contaminations with both statistical optimality and practical tractability.,,,,
BJgRsyBtPB,2020,Reject,False,A Greedy Approach to Max-Sliced Wasserstein GANs,"[""Andr\u00e1s Horv\u00e1th""]","[""GEnerative Adversarial Networks"", ""GANs"", ""Wasserstein distances"", ""Sliced Wasserstein Distance"", ""Max-sliced Wasserstein distance""]",We apply a greedy assignment on the projected samples instead of sorting to approximate Wasserstein distance,,,,
BJgTZ3C5FX,2019,Reject,False,Generative model based on minimizing exact empirical Wasserstein distance,"[""Akihiro Iohara"", ""Takahito Ogawa"", ""Toshiyuki Tanaka""]","[""Generative modeling"", ""Generative Adversarial Networks (GANs)"", ""Wasserstein GAN"", ""Optimal transport""]",We have proposed a flexible generative model that learns stably by directly minimizing exact empirical Wasserstein distance.,,,,
BJgVaG-Ab,2018,Reject,False,AUTOMATA GUIDED HIERARCHICAL REINFORCEMENT LEARNING FOR ZERO-SHOT SKILL COMPOSITION,"[""Xiao Li"", ""Yao Ma"", ""Calin Belta""]","[""Hierarchical reinforcement learning"", ""temporal logic"", ""skill composition""]",Combine temporal logic with hierarchical reinforcement learning for skill composition,,,,
BJgWE1SFwS,2020,Accept (Poster),True,PCMC-Net: Feature-based Pairwise Choice Markov Chains,"[""Alix Lh\u00e9ritier""]","[""choice modeling"", ""pairwise choice Markov chains"", ""deep learning"", ""amortized inference"", ""automatic differentiation"", ""airline itinerary choice modeling""]",We propose a generic neural network architecture equipping Pairwise Choice Markov Chains choice models with amortized and automatic differentiation based inference using alternatives' and individuals' features.,1909.11553,cs.LG,2019-09-25 15:30:38+00:00,2020-01-31 14:48:18+00:00
BJgWbpEtPr,2020,Reject,True,One-way prototypical networks,"[""Anna Kruspe""]","[""few-shot learning"", ""one-shot learning"", ""prototypical networks"", ""one-class classification"", ""anomaly detection"", ""outlier detection"", ""matching networks""]",We show how to adapt prototypical few-shot networks to one-class problems; the key is a null class for comparison.,1906.00820,cs.LG,2019-06-03 14:00:46+00:00,2019-06-03 14:00:46+00:00
BJgYl205tQ,2019,Reject,False,Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality,"[""Sukarna Barua"", ""Xingjun Ma"", ""Sarah Monazam Erfani"", ""Michael Houle"", ""James Bailey""]","[""Generative Adversarial Networks"", ""Evaluation Metric"", ""Local Intrinsic Dimensionality""]",We propose a new metric for evaluating GAN models.,,,,
BJgZBxBYPB,2020,Reject,False,Learning Underlying Physical Properties From Observations For Trajectory Prediction,"[""Ekaterina Nikonova"", ""Jochen Renz""]","[""Physical Games"", ""Deep Learning"", ""Physical Reasoning"", ""Transfer of Knowledge""]",We present a model that learns physical properties from observations and uses them for trajectory prediction in physical games.,,,,
BJgZGeHFPH,2020,Accept (Poster),True,Dynamics-Aware Embeddings,"[""William Whitney"", ""Rajat Agarwal"", ""Kyunghyun Cho"", ""Abhinav Gupta""]","[""representation learning"", ""reinforcement learning"", ""rl""]",State and action embeddings which incorporate the dynamics improve exploration and RL from pixels.,1908.09357,cs.LG,2019-08-25 16:22:04+00:00,2020-01-14 14:50:13+00:00
BJg_2JHKvH,2020,Reject,False,Semi-Supervised Learning with Normalizing Flows,"[""Pavel Izmailov"", ""Polina Kirichenko"", ""Marc Finzi"", ""Andrew Wilson""]","[""Semi-Supervised Learning"", ""Normalizing Flows""]",Probabilistic semi-supervised learning method based on normalizing flows,,,,
BJg_roAcK7,2019,Accept (Poster),False,INVASE: Instance-wise Variable Selection using Neural Networks,"[""Jinsung Yoon"", ""James Jordon"", ""Mihaela van der Schaar""]","[""Instance-wise feature selection"", ""interpretability"", ""actor-critic methodology""]",,,,,
BJgbzhC5Ym,2019,Reject,False,NECST: Neural Joint Source-Channel Coding,"[""Kristy Choi"", ""Kedar Tatwawadi"", ""Tsachy Weissman"", ""Stefano Ermon""]","[""joint source-channel coding"", ""deep generative models"", ""unsupervised learning""]",jointly learn compression + error correcting codes with deep learning,,,,
BJgctpEKwr,2020,Reject,False,RPGAN: random paths as a latent space for GAN interpretability,"[""Andrey Voynov"", ""Artem Babenko""]","[""generative models"", ""GAN"", ""interpretability""]","We introduce an alternative GAN design based on random routes in generator, which can serve as a tool for generative models interpretability.",1912.10920,cs.CV,2019-12-23 15:29:54+00:00,2020-02-17 22:08:27+00:00
BJgcwh4FwS,2020,Reject,False,Neural Maximum Common Subgraph Detection with Guided Subgraph Extraction,"[""Yunsheng Bai"", ""Derek Xu"", ""Ken Gu"", ""Xueqing Wu"", ""Agustin Marinovic"", ""Christopher Ro"", ""Yizhou Sun"", ""Wei Wang""]","[""graph matching"", ""maximum common subgraph"", ""graph neural networks"", ""subgraph extraction"", ""graph alignment""]",,,,,
BJgd7m0xRZ,2018,Reject,False,Unsupervised Adversarial Anomaly  Detection using One-Class Support Vector Machines,"[""Prameesha Sandamal Weerasinghe"", ""Tansu Alpcan"", ""Sarah Monazam Erfani"", ""Christopher Leckie""]","[""anomaly detection"", ""one class support vector machine"", ""adversarial learning""]","A novel method to increase the resistance of OCSVMs against targeted, integrity attacks by selective nonlinear transformations of data to lower dimensions.",,,,
BJgd81SYwr,2020,Accept (Poster),True,Meta Dropout: Learning to Perturb Latent Features for Generalization,"[""Hae Beom Lee"", ""Taewook Nam"", ""Eunho Yang"", ""Sung Ju Hwang""]",[],,1905.12914,cs.LG,2019-05-30 08:44:16+00:00,2020-04-22 18:52:06+00:00
BJgdOh4Ywr,2020,Reject,False,Visual Imitation with Reinforcement Learning using Recurrent Siamese Networks,"[""Glen Berseth"", ""Christopher Pal""]","[""imitation learning"", ""reinforcement learning"", ""imitation from video""]",Learning recurrent distance models for imitation from a single video clip using reinforcement learning.,,,,
BJge3TNKwH,2020,Accept (Spotlight),False,Sliced Cramer Synaptic Consolidation for Preserving Deeply Learned Representations,"[""Soheil Kolouri"", ""Nicholas A. Ketz"", ""Andrea Soltoggio"", ""Praveen K. Pilly""]","[""selective plasticity"", ""catastrophic forgetting"", ""intransigence""]","""A novel framework for overcoming catastrophic forgetting by preserving the distribution of the network's output at an arbitrary layer.""",,,,
BJgkbyHKDS,2020,Reject,False,Invertible generative models for  inverse problems: mitigating representation error and dataset bias,"[""Muhammad Asim"", ""Ali Ahmed"", ""Paul Hand""]","[""Invertible generative models"", ""inverse problems"", ""generative prior"", ""Glow"", ""compressed sensing"", ""denoising"", ""inpainting.""]","Invertible generative neural networks provide effective natural image priors for inverse problems, outperforming GAN and Lasso priors in Compressive Sensing Problems, while exhibiting strong out-of-distribution performance.",,,,
BJgklhAcK7,2019,Accept (Poster),False,Meta-Learning with Latent Embedding Optimization,"[""Andrei A. Rusu"", ""Dushyant Rao"", ""Jakub Sygnowski"", ""Oriol Vinyals"", ""Razvan Pascanu"", ""Simon Osindero"", ""Raia Hadsell""]","[""meta-learning"", ""few-shot"", ""miniImageNet"", ""tieredImageNet"", ""hypernetworks"", ""generative"", ""latent embedding"", ""optimization""]",Latent Embedding Optimization (LEO) is a novel gradient-based meta-learner with state-of-the-art performance on the challenging 5-way 1-shot and 5-shot miniImageNet and tieredImageNet classification tasks.,,,,
BJglA3NKwS,2020,Reject,False,Siamese Attention Networks,"[""Hongyang Gao"", ""Yaochen Xie"", ""Shuiwang Ji""]",[],,,,,
BJgnXpVYwS,2020,Accept (Talk),True,Why Gradient Clipping Accelerates Training: A Theoretical Justification for Adaptivity,"[""Jingzhao Zhang"", ""Tianxing He"", ""Suvrit Sra"", ""Ali Jadbabaie""]","[""Adaptive methods"", ""optimization"", ""deep learning""]",Gradient clipping provably accelerates gradient descent for non-smooth non-convex functions.,1905.11881,math.OC,2019-05-28 15:23:12+00:00,2020-02-10 22:58:53+00:00
BJgnmhA5KQ,2019,Reject,False,Diverse Machine Translation with a Single Multinomial Latent Variable,"[""Tianxiao Shen"", ""Myle Ott"", ""Michael Auli"", ""Marc\u2019Aurelio Ranzato""]","[""machine translation"", ""latent variable models"", ""diverse decoding""]",,,,,
BJgolhR9Km,2019,Reject,False,Neural Networks with Structural Resistance to Adversarial Attacks,"[""Luca de Alfaro""]","[""machine learning"", ""adversarial attacks""]","We introduce a type of neural network that is structurally resistant to adversarial attacks, even when trained on unaugmented training sets.  The resistance is due to the stability of network units wrt input perturbations.",,,,
BJgqQ6NYvB,2020,Accept (Poster),False,FasterSeg: Searching for Faster Real-time Semantic Segmentation,"[""Wuyang Chen"", ""Xinyu Gong"", ""Xianming Liu"", ""Qian Zhang"", ""Yuan Li"", ""Zhangyang Wang""]","[""neural architecture search"", ""real-time"", ""segmentation""]","We present a real-time segmentation model automatically discovered by a multi-scale NAS framework, achieving 30% faster than state-of-the-art models.",1912.10917,cs.CV,2019-12-23 15:26:39+00:00,2020-01-16 21:20:48+00:00
BJgqqsAct7,2019,Accept (Poster),False,Non-vacuous Generalization Bounds at the ImageNet Scale: a PAC-Bayesian Compression Approach,"[""Wenda Zhou"", ""Victor Veitch"", ""Morgane Austern"", ""Ryan P. Adams"", ""Peter Orbanz""]","[""generalization"", ""deep-learning"", ""pac-bayes""]",We obtain non-vacuous generalization bounds on ImageNet-scale deep neural networks by combining an original PAC-Bayes bound and an off-the-shelf neural network compression method.,,,,
BJgr4kSFDS,2020,Accept (Poster),False,Query2box: Reasoning over Knowledge Graphs in Vector Space Using Box Embeddings,"[""Hongyu Ren*"", ""Weihua Hu*"", ""Jure Leskovec""]","[""knowledge graph embeddings"", ""logical reasoning"", ""query answering""]",Answering a wide class of logical queries over knowledge graphs with box embeddings in vector space,,,,
BJgsN3R9Km,2019,Reject,False,AntMan: Sparse Low-Rank Compression To Accelerate RNN Inference,"[""Samyam Rajbhandari"", ""Harsh Shrivastava"", ""Yuxiong He""]","[""model compression"", ""RNN"", ""perforamnce optimization"", ""langugage model"", ""machine reading comprehension"", ""knowledge distillation"", ""teacher-student""]","Reducing computation and memory complexity of RNN models by up to 100x using sparse low-rank compression modules, trained via knowledge distillation.",,,,
BJgvg30ctX,2019,Reject,False,Information Regularized Neural Networks,"[""Tianchen Zhao"", ""Dejiao Zhang"", ""Zeyu Sun"", ""Honglak Lee""]","[""supervised classification"", ""information theory"", ""deep learning"", ""regularization""]",we propose a regularizer that improves the classification performance of neural networks,,,,
BJgxzlSFvr,2020,Reject,False,AN ATTENTION-BASED DEEP NET FOR LEARNING TO RANK,"[""Diego Klabjan"", ""Baiyang Wang""]","[""learning to rank"", ""deep learning""]",learning to rank with several embeddings and attentions,,,,
BJgy-n0cK7,2019,Reject,False,Inter-BMV: Interpolation with Block Motion Vectors for Fast Semantic Segmentation on Video,"[""Samvit Jain"", ""Joseph Gonzalez""]","[""semantic segmentation"", ""video"", ""efficient inference"", ""video segmentation"", ""video compression""]","We exploit video compression techniques (in particular, the block motion vectors in H.264 video) and feature similarity across frames to accelerate a classical image recognition task, semantic segmentation, on video.",,,,
BJgy96EYvr,2020,Accept (Spotlight),False,Influence-Based Multi-Agent Exploration,"[""Tonghan Wang*"", ""Jianhao Wang*"", ""Yi Wu"", ""Chongjie Zhang""]","[""Multi-agent reinforcement learning"", ""Exploration""]",,,,,
BJgyn1BFwS,2020,Reject,False,Global Adversarial Robustness Guarantees for Neural Networks,"[""Luca Laurenti"", ""Andrea Patane"", ""Matthew Wicker"", ""Luca Bortolussi"", ""Luca Cardelli"", ""Marta Kwiatkowska""]","[""Adversarial Robustness"", ""Statistical Guarantees"", ""Deep Neural Networks"", ""Bayesian Neural Networks""]","Given a neural network f we investigate the global adversarial robustness properties of f, showing how these can be computed up to any a priori specified statistical error.",,,,
BJgza6VtPB,2020,Accept (Poster),True,Language GANs Falling Short,"[""Massimo Caccia"", ""Lucas Caccia"", ""William Fedus"", ""Hugo Larochelle"", ""Joelle Pineau"", ""Laurent Charlin""]","[""NLP"", ""GAN"", ""MLE"", ""adversarial"", ""text generation"", ""temperature""]","GANs have been applied to text generation and are believed SOTA. However, we propose a new evaluation protocol demonstrating that maximum-likelihood trained models are still better.",1811.02549,cs.CL,2018-11-06 18:44:11+00:00,2020-02-19 22:44:37+00:00
BJh6Ztuxl,2017,Accept (Poster),False,Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks,"[""Yossi Adi"", ""Einat Kermany"", ""Yonatan Belinkov"", ""Ofer Lavi"", ""Yoav Goldberg""]","[""Natural language processing"", ""Deep learning""]",A method for analyzing sentence embeddings on a fine-grained level using auxiliary prediction tasks,,,,
BJhZeLsxx,2017,Accept (Poster),False,What does it take to generate natural textures?,"[""Ivan Ustyuzhaninov *"", ""Wieland Brendel *"", ""Leon Gatys"", ""Matthias Bethge""]","[""Deep learning"", ""Unsupervised Learning""]","Natural textures of high perceptual quality can be generated from networks with only a single layer, no pooling and random filters.",,,,
BJhxcGZCW,2018,Reject,False,Generative Discovery of Relational Medical Entity Pairs,"[""Chenwei Zhang"", ""Yaliang Li"", ""Nan Du"", ""Wei Fan"", ""Philip S. Yu""]","[""Knowledge Discovery"", ""Generative Modeling"", ""Medical"", ""Entity Pair""]","Generatively discover meaningful, novel entity pairs with a certain medical relationship by purely learning from the existing meaningful entity pairs, without the requirement of additional text corpus for discriminative extraction.",,,,
BJij4yg0Z,2018,Accept (Poster),False,A Bayesian Perspective on Generalization and Stochastic Gradient Descent,"[""Samuel L. Smith and Quoc V. Le""]","[""generalization"", ""stochastic gradient descent"", ""stochastic differential equations"", ""scaling rules"", ""large batch training"", ""bayes theorem"", ""batch size""]","Generalization is strongly correlated with the Bayesian evidence, and gradient noise drives SGD towards minima whose evidence is large.",,,,
BJj6qGbRW,2018,Accept (Poster),False,Few-Shot Learning with Graph Neural Networks,"[""Victor Garcia Satorras"", ""Joan Bruna Estrach""]",[],,,,,
BJjBnN9a-,2018,Reject,False,Continuous Convolutional Neural Networks for Image Classification,"[""Vitor Guizilini"", ""Fabio Ramos""]","[""convolutional neural networks"", ""image classification"", ""deep learning"", ""feature representation"", ""hilbert maps"", ""reproducing kernel hilbert space""]",This paper proposes a novel convolutional layer that operates in a continuous Reproducing Kernel Hilbert Space.,,,,
BJjn-Yixl,2017,Reject,False,Attentive Recurrent Comparators,"[""Pranav Shyam"", ""Ambedkar Dukkipati""]","[""Deep learning"", ""Computer vision""]",Attention and Recurrence can be as good as Convolution in some cases. Bigger returns when we combine all three.,,,,
BJjquybCW,2018,Invite to Workshop Track,False,The loss surface and expressivity of deep convolutional neural networks,"[""Quynh Nguyen"", ""Matthias Hein""]","[""convolutional neural networks"", ""loss surface"", ""expressivity"", ""critical point"", ""global minima"", ""linear separability""]",,,,,
BJk59JZ0b,2018,Accept (Poster),True,Guide Actor-Critic for Continuous Control,"[""Voot Tangkaratt"", ""Abbas Abdolmaleki"", ""Masashi Sugiyama""]","[""Reinforcement learning"", ""actor-critic"", ""continuous control""]",This paper proposes a novel actor-critic method that uses Hessians of a critic to update an actor.,1705.07606,stat.ML,2017-05-22 08:32:10+00:00,2018-02-22 04:32:24+00:00
BJk7Gf-CZ,2018,Accept (Poster),False,Global Optimality Conditions for Deep Neural Networks,"[""Chulhee Yun"", ""Suvrit Sra"", ""Ali Jadbabaie""]","[""deep linear neural networks"", ""global optimality"", ""deep learning""]","We provide efficiently checkable necessary and sufficient conditions for global optimality in deep linear neural networks, with some initial extensions to nonlinear settings.",,,,
BJl-5pNKDB,2020,Accept (Poster),False,On Computation and Generalization of Generative Adversarial Imitation Learning,"[""Minshuo Chen"", ""Yizhou Wang"", ""Tianyi Liu"", ""Zhuoran Yang"", ""Xingguo Li"", ""Zhaoran Wang"", ""Tuo Zhao""]",[],,,,,
BJl07ySKvS,2020,Accept (Poster),False,Guiding Program Synthesis by Learning to Generate Examples,"[""Larissa Laich"", ""Pavol Bielik"", ""Martin Vechev""]","[""program synthesis"", ""programming by examples""]",,,,,
BJl2_nVFPB,2020,Accept (Poster),False,Automatically Discovering and Learning New Visual Categories with Ranking Statistics,"[""Kai Han"", ""Sylvestre-Alvise Rebuffi"", ""Sebastien Ehrhardt"", ""Andrea Vedaldi"", ""Andrew Zisserman""]","[""deep learning"", ""classification"", ""novel classes"", ""transfer learning"", ""clustering"", ""incremental learning""]","A method to automatically discover new categories in unlabelled data, by effectively transferring knowledge from labelled data of other different categories using feature rank statistics.",2002.05714,cs.CV,2020-02-13 18:53:32+00:00,2020-02-13 18:53:32+00:00
BJl4f2A5tQ,2019,Reject,False,Surprising Negative Results for Generative  Adversarial Tree Search ,"[""Kamyar Azizzadenesheli"", ""Brandon Yang"", ""Weitang Liu"", ""Emma Brunskill"", ""Zachary Lipton"", ""Animashree Anandkumar""]","[""Deep Reinforcement Learning"", ""Generative Adversarial Nets""]",Surprising negative results on Model Based + Model deep RL,,,,
BJl4g0NYvB,2020,Reject,True,Causal Induction from Visual Observations for Goal Directed Tasks,"[""Suraj Nair"", ""Yuke Zhu"", ""Silvio Savarese"", ""Li Fei-Fei""]","[""meta-learning"", ""causal reasoning"", ""policy learning""]",Meta-learning algorithm for inducing causal structure from visual observations and using it to complete goal conditioned tasks,1910.01751,cs.LG,2019-10-03 22:32:40+00:00,2019-10-03 22:32:40+00:00
BJl65sA9tm,2019,Reject,False,Improving Generative Adversarial Imitation Learning with Non-expert Demonstrations,"[""Voot Tangkaratt"", ""Masashi Sugiyama""]","[""Imitation learning"", ""Generative adversarial imitation learning""]",We improve GAIL by learning discriminators using multiclass classification with non-expert regarded as an extra class.,,,,
BJl6AjC5F7,2019,Accept (Poster),True,Learning to Represent Edits,"[""Pengcheng Yin"", ""Graham Neubig"", ""Miltiadis Allamanis"", ""Marc Brockschmidt"", ""Alexander L. Gaunt""]","[""Representation Learning"", ""Source Code"", ""Natural Language"", ""edit""]",,1810.13337,cs.LG,2018-10-31 15:29:30+00:00,2019-02-22 05:16:03+00:00
BJl6TjRcY7,2019,Accept (Poster),False,Neural Probabilistic Motor Primitives for Humanoid Control,"[""Josh Merel"", ""Leonard Hasenclever"", ""Alexandre Galashov"", ""Arun Ahuja"", ""Vu Pham"", ""Greg Wayne"", ""Yee Whye Teh"", ""Nicolas Heess""]","[""Motor Primitives"", ""Distillation"", ""Reinforcement Learning"", ""Continuous Control"", ""Humanoid Control"", ""Motion Capture"", ""One-Shot Imitation""]",Neural Probabilistic Motor Primitives compress motion capture tracking policies into one flexible model capable of one-shot imitation and reuse as a low-level controller.,,,,
BJl6bANtwH,2020,Accept (Poster),False,Detecting Extrapolation with Local Ensembles,"[""David Madras"", ""James Atwood"", ""Alexander D'Amour""]","[""extrapolation"", ""reliability"", ""influence functions"", ""laplace approximation"", ""ensembles"", ""Rashomon set""]","We present local ensembles, a method for detecting extrapolation in trained models, which approximates the variance of an ensemble using local-second order information.",,,,
BJl6t64tvr,2020,Reject,False,Revisiting the Generalization of Adaptive Gradient Methods,"[""Naman Agarwal"", ""Rohan Anil"", ""Elad Hazan"", ""Tomer Koren"", ""Cyril Zhang""]","[""Adaptive Methods"", ""AdaGrad"", ""Generalization""]","Adaptive gradient methods, when done right, do not incur a generalization penalty. ",,,,
BJl7mxBYvB,2020,Reject,False,Robust Reinforcement Learning via Adversarial Training with  Langevin Dynamics,"[""Huang Yu-Ting"", ""Parameswaran Kamalaruban"", ""Paul Rolland"", ""Ya-Ping Hsieh"", ""Volkan Cevher""]","[""deep reinforcement learning"", ""robust reinforcement learning"", ""min-max problem""]",,,,,
BJl8ZlHFwr,2020,Reject,False,Relation-based Generalized Zero-shot Classification with the Domain Discriminator on the shared representation,"[""Masahiro Suzuki"", ""Yutaka Matsuo""]",[],,,,,
BJl9PRVKDS,2020,Reject,False,A Functional Characterization of Randomly Initialized Gradient Descent in Deep ReLU Networks,"[""Justin Sahs"", ""Aneel Damaraju"", ""Ryan Pyle"", ""Onur Tavaslioglu"", ""Josue Ortega Caro"", ""Hao Yang Lu"", ""Ankit Patel""]","[""Inductive Bias"", ""Generalization"", ""Interpretability"", ""Functional Characterization"", ""Loss Surface"", ""Initialization""]","A functional approach reveals that flat initialization, preserved by gradient descent, leads to generalization ability.",,,,
BJl9ZTVKwB,2020,Reject,True,MIM: Mutual Information Machine,"[""Micha Livne"", ""Kevin Swersky"", ""David J. Fleet""]","[""Mutual Information"", ""Representation Learning"", ""Generative Models"", ""Probability Density Estimator""]",We propose an alternative latent variable modelling framework to variational auto-encoders that encourages the principles of symmetry and high mutual information.,1910.03175,cs.LG,2019-10-08 02:31:29+00:00,2020-02-21 15:45:19+00:00
BJlA6eBtvH,2020,Reject,False,Differentiable Hebbian Consolidation for Continual Learning,"[""Vithursan Thangarasa"", ""Thomas Miconi"", ""Graham W. Taylor""]","[""continual learning"", ""catastrophic forgetting"", ""Hebbian learning"", ""synaptic plasticity"", ""neural networks""]",Hebbian plastic weights can behave as a compressed episodic memory storage in neural networks and with the combination of task-specific synaptic consolidation can improve the ability to alleviate catastrophic forgetting in continual learning.,2006.16558,cs.LG,2020-06-30 06:42:19+00:00,2020-06-30 06:42:19+00:00
BJlAzTEKwS,2020,Reject,False,Attraction-Repulsion Actor-Critic for Continuous Control Reinforcement Learning,"[""Thang Doan"", ""Bogdan Mazoure"", ""Audrey Durand"", ""Joelle Pineau"", ""R Devon Hjelm""]","[""reinforcement learning"", ""continuous control"", ""multi-agent"", ""mujoco""]",,,,,
BJlBSkHtDS,2020,Accept (Poster),True,PadÃ© Activation Units: End-to-end Learning of Flexible Activation Functions in Deep Networks,"[""Alejandro Molina"", ""Patrick Schramowski"", ""Kristian Kersting""]",[],"We introduce PAU, a new learnable activation function for neural networks. They free the network designers from the activation selection process and increase the test prediction accuracy.",1907.06732,cs.LG,2019-07-15 20:24:22+00:00,2020-02-04 11:25:30+00:00
BJlEEaEFDS,2020,Reject,False,Towards an Adversarially Robust Normalization Approach,"[""Muhammad Awais"", ""Fahad Shamshad"", ""Sung-Ho Bae""]","[""robustness"", ""BatchNorm"", ""adversarial""]",Investigation of how BatchNorm causes adversarial vulnerability and how to avoid it. ,2006.11007,cs.LG,2020-06-19 08:12:25+00:00,2020-06-19 08:12:25+00:00
BJlITC4KDB,2020,Reject,True,Multi-Sample Dropout for Accelerated Training and Better Generalization,"[""Hiroshi Inoue""]","[""dropout"", ""regularization"", ""convolutional neural networks""]",,1905.09788,cs.NE,2019-05-23 17:22:57+00:00,2020-10-21 02:39:55+00:00
BJlJVCEYDB,2020,Reject,False,Neural networks with motivation,"[""Sergey A. Shuvaev"", ""Ngoc B. Tran"", ""Marcus Stephenson-Jones"", ""Bo Li"", ""Alexei A. Koulakov""]","[""neuroscience"", ""brain"", ""motivation"", ""learning"", ""reinforcement learning"", ""recurrent neural network"", ""deep learning""]","We developed an RL model of motivated behaviors, then trained both our model and lab mice on biologically realistic task to make and validate predictions about neuronal connectivity in mouse brain.",,,,
BJlLdhNFPr,2020,Reject,False,Explaining A Black-box By Using A Deep Variational Information Bottleneck Approach,"[""Seojin Bang"", ""Pengtao Xie"", ""Heewook Lee"", ""Wei Wu"", ""Eric Xing""]","[""interpretable machine learning"", ""information bottleneck principle"", ""black-box""]",,,,,
BJlLvnEtDB,2020,Reject,False,Analysis and Interpretation of Deep CNN Representations as Perceptual Quality Features,"[""Taimoor Tariq"", ""Munchurl Kim""]","[""interpretation"", ""perceptual quality"", ""perceptual loss"", ""image-restoration.""]",,,,,
BJlMcjC5K7,2019,Reject,False,Neural Random Projections for Language Modelling,"[""Davide Nunes"", ""Luis Antunes""]","[""neural networks"", ""language modelling"", ""natural language processing"", ""uncertainty"", ""random projections""]","Neural language models can be trained with a compressed embedding space, by using sparse random projections, created incrementally for each unique discrete input.",,,,
BJlNs0VYPB,2020,Reject,False,The Sooner The Better: Investigating Structure of Early Winning Lottery Tickets,"[""Shihui Yin"", ""Kyu-Hyoun Kim"", ""Jinwook Oh"", ""Naigang Wang"", ""Mauricio Serrano"", ""Jae-Sun Seo"", ""Jungwook Choi""]","[""pruning"", ""lottery ticket hypothesis"", ""deep neural network"", ""compression"", ""image classification""]","A method to find winning lottery tickets in early epoch of training, saving computational cost for fast pruning.",,,,
BJlOcR4KwS,2020,Reject,False,Channel Equilibrium Networks,"[""Wenqi Shao"", ""Shitao Tang"", ""Xingang Pan"", ""Ping Tan"", ""Xiaogang Wang"", ""Ping Luo""]","[""Deep learning"", ""convolutional neural networks"", ""building block design""]",A design of  building block  for performance boosting,2003.00214,cs.CV,2020-02-29 09:02:31+00:00,2020-02-29 09:02:31+00:00
BJlPLlrFvH,2020,Reject,False,Variable Complexity in the Univariate and Multivariate Structural Causal Model,"[""Tomer Galanti"", ""Ofir Nabati"", ""Lior Wolf""]",[],,,,,
BJlPOlBKDB,2020,Reject,False,Closed loop deep Bayesian inversion:  Uncertainty driven acquisition for fast MRI,"[""Thomas Sanchez"", ""Igor Krawczuk"", ""Zhaodong Sun"", ""Volkan Cevher""]","[""Deep Bayesian Inversion"", ""accelerated MRI"", ""uncertainty quantification"", ""sampling mask design""]",We show that a single cWGAN can model the posterior distribution an array of inverse problems in MRI and leverage the posterior variance to design effective sampling strategies.,,,,
BJlQtJSKDB,2020,Accept (Talk),True,Watch the Unobserved: A Simple Approach to Parallelizing Monte Carlo Tree Search,"[""Anji Liu"", ""Jianshu Chen"", ""Mingze Yu"", ""Yu Zhai"", ""Xuewen Zhou"", ""Ji Liu""]","[""parallel Monte Carlo Tree Search (MCTS)"", ""Upper Confidence bound for Trees (UCT)"", ""Reinforcement Learning (RL)""]",We developed an effective parallel UCT algorithm that achieves linear speedup and suffers negligible performance loss.,1810.11755,cs.LG,2018-10-28 03:24:01+00:00,2020-02-25 22:03:23+00:00
BJlRs34Fvr,2020,Accept (Spotlight),False,Skip Connections Matter: On the Transferability of Adversarial Examples Generated with ResNets,"[""Dongxian Wu"", ""Yisen Wang"", ""Shu-Tao Xia"", ""James Bailey"", ""Xingjun Ma""]","[""Adversarial Example"", ""Transferability"", ""Skip Connection"", ""Neural Network""]",We identify the security weakness of skip connections in ResNet-like neural networks,2002.05990,cs.LG,2020-02-14 12:09:21+00:00,2020-02-14 12:09:21+00:00
BJlS634tPr,2020,Accept (Spotlight),True,PC-DARTS: Partial Channel Connections for Memory-Efficient Architecture Search,"[""Yuhui Xu"", ""Lingxi Xie"", ""Xiaopeng Zhang"", ""Xin Chen"", ""Guo-Jun Qi"", ""Qi Tian"", ""Hongkai Xiong""]","[""Neural Architecture Search"", ""DARTS"", ""Regularization"", ""Normalization""]",Allowing partial channel connection in super-networks to regularize and accelerate differentiable architecture search,1907.05737,cs.CV,2019-07-12 13:26:09+00:00,2020-04-07 06:20:35+00:00
BJlSHsAcK7,2019,Reject,False,Overcoming catastrophic forgetting through weight consolidation and long-term memory,"[""Shixian Wen"", ""Laurent Itti""]","[""Catastrophic Forgetting"", ""Life-Long Learning"", ""adversarial examples""]",We enable sequential learning of multiple tasks by adding task-dependent memory units to avoid interference between tasks,,,,
BJlSPRVFwS,2020,Reject,True,Asynchronous Stochastic Subgradient Methods for General Nonsmooth Nonconvex Optimization,"[""Vyacheslav Kungurtsev"", ""Malcolm Egan"", ""Bapi Chatterjee"", ""Dan Alistarh""]","[""optimziation"", ""stochastic optimization"", ""asynchronous parallel architecture"", ""deep neural networks""]",Asymptotic convergence for stochastic subgradien method with momentum under general parallel asynchronous computation for general nonconvex nonsmooth optimization,1905.11845,math.OC,2019-05-28 14:27:29+00:00,2020-07-11 10:16:14+00:00
BJlVeyHFwH,2020,Reject,False,On the Invertibility of Invertible Neural Networks,"[""Jens Behrmann"", ""Paul Vicol"", ""Kuan-Chieh Wang"", ""Roger B. Grosse"", ""J\u00f6rn-Henrik Jacobsen""]","[""Invertible Neural Networks"", ""Stability"", ""Normalizing Flows"", ""Generative Models"", ""Evaluation of Generative Models""]","Little known fact: Invertible Neural Networks can be non-invertible; we show why, when and how to fix it.",,,,
BJlVhsA5KX,2019,Reject,False,Sequenced-Replacement Sampling for Deep Learning,"[""Chiu Man Ho"", ""Dae Hoon Park"", ""Wei Yang"", ""Yi Chang""]","[""deep neural networks"", ""stochastic gradient descent"", ""sequenced-replacement sampling""]","Proposed a novel way (without adding new parameters) of training deep neural network in order to improve generalization, especially for the case where we have relatively small images-per-class.",,,,
BJlXUsR5KQ,2019,Reject,False,Learning Neuron Non-Linearities with Kernel-Based Deep Neural Networks,"[""Giuseppe Marra"", ""Dario Zanca"", ""Alessandro Betti"", ""Marco Gori""]","[""Activation functions"", ""Kernel methods"", ""Recurrent networks""]",,,,,
BJlXgkHYvS,2020,Reject,False,Information-Theoretic Local Minima Characterization and Regularization,"[""Zhiwei Jia"", ""Hao Su""]","[""local minima"", ""generalization"", ""regularization"", ""deep learning theory""]",,1911.08192,cs.LG,2019-11-19 10:14:33+00:00,2020-06-30 10:23:27+00:00
BJlZ5ySKPH,2020,Accept (Poster),False,U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation,"[""Junho Kim"", ""Minjae Kim"", ""Hyeonwoo Kang"", ""Kwang Hee Lee""]","[""Image-to-Image Translation"", ""Generative Attentional Networks"", ""Adaptive Layer-Instance Normalization""]",,,,,
BJl_VnR9Km,2019,Reject,False,A  Model Cortical Network for Spatiotemporal Sequence Learning and Prediction,"[""Jielin Qiu"", ""Ge Huang"", ""Tai Sing Lee""]","[""cortical models"", ""spatiotemporal memory"", ""video prediction"", ""predictive coding""]",A new hierarchical cortical model for encoding spatiotemporal memory and video prediction,1901.09002,cs.NE,2019-01-25 18:03:17+00:00,2021-10-01 12:59:31+00:00
BJlaG0VFDH,2020,Reject,False,Decoupling Weight Regularization from Batch Size for Model Compression,"[""Dongsoo Lee"", ""Se Jung Kwon"", ""Byeongwook Kim"", ""Yongkweon Jeon"", ""Baeseong Park"", ""Jeongin Yun"", ""Gu-Yeon Wei""]","[""Model compression"", ""Weight Regularization"", ""Batch Size"", ""Gradient Descent""]",We show that stronger regularization and high model compression ratio can be achieved when weight updates are conducted less frequently.,,,,
BJlahxHYDS,2020,Accept (Poster),False,Conservative Uncertainty Estimation By Fitting  Prior Networks,"[""Kamil Ciosek"", ""Vincent Fortuin"", ""Ryota Tomioka"", ""Katja Hofmann"", ""Richard Turner""]","[""uncertainty quantification"", ""deep learning"", ""Gaussian process"", ""epistemic uncertainty"", ""random network"", ""prior"", ""Bayesian inference""]",We provide theoretical support to uncertainty estimates for deep learning obtained fitting random priors.,,,,
BJlbo6VtDH,2020,Reject,False,A Generalized Framework of Sequence Generation with Application to Undirected Sequence Models,"[""Elman Mansimov"", ""Alex Wang"", ""Kyunghyun Cho""]","[""nlp"", ""sequence modeling"", ""natural language generation"", ""machine translation"", ""BERT"", ""Sesame Street""]","We unify several language generation paradigms (monotonic autoregressive, non-autoregressive, etc.) in a single framework, and use the framework to do machine translation with undirected sequence models.",,,,
BJlc6iA5YX,2019,Reject,False,ACE: Artificial Checkerboard Enhancer to Induce and Evade Adversarial Attacks,"[""Jisung Hwang"", ""Younghoon Kim"", ""Sanghyuk Chun"", ""Jaejun Yoo"", ""Ji-Hoon Kim"", ""Dongyoon Han"", ""Jung-Woo Ha""]","[""Adversarial Examples"", ""Neural Network Security"", ""Deep Neural Network"", ""Checkerboard Artifact""]",We propose a novel aritificial checkerboard enhancer (ACE) module which guides attacks to a pre-specified pixel space and successfully defends it with a simple padding operation.,,,,
BJleciCcKQ,2019,Reject,False,EXPLORATION OF EFFICIENT ON-DEVICE ACOUSTIC MODELING WITH NEURAL NETWORKS,"[""Wonyong Sung"", ""Lukas Lee"", ""Jinwhan Park""]","[""Parallelization"", ""Speech Recognition"", ""Sequence Modeling"", ""Recurrent Neural Network"", ""Embedded Systems""]","Multi-timestep parallelizable acoustic modeling with diagonal LSTM, QRNN and Gated ConvNet",,,,
BJleph4KvS,2020,Reject,False,HaarPooling: Graph Pooling with Compressive Haar Basis,"[""Yu Guang Wang"", ""Ming Li"", ""Zheng Ma"", ""Guido Montufar"", ""Xiaosheng Zhuang"", ""Yanan Fan""]","[""graph pooling"", ""graph neural networks"", ""tree"", ""graph classification"", ""graph regression"", ""deep learning"", ""Haar wavelet basis"", ""fast Haar transforms""]",,,,,
BJlgNh0qKQ,2019,Accept (Poster),False,Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder,"[""Caio Corro"", ""Ivan Titov""]","[""differentiable dynamic programming"", ""variational auto-encoder"", ""dependency parsing"", ""semi-supervised learning""]",Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE,,,,
BJlgt2EYwr,2020,Reject,True,Stabilizing DARTS with Amended Gradient Estimation on Architectural Parameters,"[""Kaifeng Bi"", ""Changping Hu"", ""Lingxi Xie"", ""Xin Chen"", ""Longhui Wei"", ""Qi Tian""]","[""Neural Architecture Search"", ""DARTS"", ""Stability""]",An improved optimization of differentiable NAS that largely improves search stability,1910.11831,cs.LG,2019-10-25 16:31:25+00:00,2020-05-04 10:19:18+00:00
BJlguT4YPr,2020,Accept (Poster),False,Scalable Neural Methods for Reasoning With a Symbolic Knowledge   Base,"[""William W. Cohen"", ""Haitian Sun"", ""R. Alex Hofer"", ""Matthew Siegler""]","[""question-answering"", ""knowledge base completion"", ""neuro-symbolic reasoning"", ""multihop reasoning""]",A scalable differentiable neural module that implements reasoning on symbolic KBs.,2002.06115,cs.CL,2020-02-14 16:32:19+00:00,2020-02-14 16:32:19+00:00
BJliakStvH,2020,Accept (Spotlight),False,Maximum Likelihood Constraint Inference for Inverse Reinforcement Learning,"[""Dexter R.R. Scobee"", ""S. Shankar Sastry""]","[""learning from demonstration"", ""inverse reinforcement learning"", ""constraint inference""]","Our method infers constraints on task execution by leveraging the principle of maximum entropy to quantify how demonstrations differ from expected, un-constrained behavior.",,,,
BJlisySYPS,2020,Reject,False,Modelling the influence of data structure on learning in neural networks,"[""S. Goldt"", ""M. M\u00e9zard"", ""F. Krzakala"", ""L. Zdeborov\u00e1""]","[""Neural Networks"", ""Generative models"", ""Synthetic data sets"", ""Generalisation"", ""Stochastic Gradient descent""]",We demonstrate how structure in data sets impacts neural networks and introduce a generative model for synthetic data sets that reproduces this impact.,,,,
BJlkgaNKvr,2020,Reject,False,Towards Understanding the Regularization of Adversarial Robustness on Neural Networks,"[""Yuxin Wen"", ""Shuai Li"", ""Kui Jia""]","[""Adversarial robustness"", ""Statistical Learning"", ""Regularization""]",We study the accuracy degradation in adversarial training through regularization perspective and find that such training induces diffident NNs that concentrate prediction around decision boundary which leads to worse standard performance.,,,,
BJll6o09tm,2019,Reject,False,Padam: Closing the Generalization Gap of Adaptive Gradient Methods in Training Deep Neural Networks,"[""Jinghui Chen"", ""Quanquan Gu""]",[],,,,,
BJlnmgrFvS,2020,Reject,False,BAIL: Best-Action Imitation Learning for Batch Deep Reinforcement Learning,"[""Xinyue Chen"", ""Zijian Zhou"", ""Zheng Wang"", ""Che Wang"", ""Yanqiu Wu"", ""Qing Deng"", ""Keith Ross""]","[""Deep Reinforcement Learning"", ""Batch Reinforcement Learning"", ""Sample Efficiency""]",We propose a new Batch Reinforcement Learning algorithm achieving state-of-the-art performance. ,,,,
BJlowyHYPr,2020,Reject,True,CloudLSTM: A Recurrent Neural Model for Spatiotemporal Point-cloud Stream Forecasting,"[""Chaoyun Zhang"", ""Marco Fiore"", ""Iain Murray"", ""Paul Patras""]","[""spatio-temporal forecasting"", ""point cloud stream forecasting"", ""recurrent neural network""]","This paper introduces CloudLSTM, a new branch of recurrent neural models tailored to forecasting over data streams generated by geospatial point-cloud sources.",1907.12410,cs.LG,2019-07-29 13:20:52+00:00,2021-02-21 22:13:18+00:00
BJlpCsC5Km,2019,Reject,False,Learning Gibbs-regularized GANs with variational discriminator reparameterization,"[""Nicholas Rhinehart"", ""Anqi Liu"", ""Kihyuk Sohn"", ""Paul Vernaza""]","[""deep generative models"", ""graphical models"", ""trajectory forecasting"", ""GANs"", ""density estimation"", ""structured prediction""]",We reparameterize a GAN's discriminator into a form that admits regularization using a structured Gibbs distribution,,,,
BJlqYlrtPB,2020,Reject,True,Negative Sampling in Variational Autoencoders,"[""Adri\u00e1n Csisz\u00e1rik"", ""Beatrix Benk\u0151"", ""D\u00e1niel Varga""]","[""Variational Autoencoder"", ""generative modelling"", ""out-of-distribution detection""]",Pulling near-manifold examples (utilizing an auxiliary dataset or generated samples) to a secondary prior improves the discriminative power of VAE models regarding out-of-distribution samples.,1910.02760,cs.LG,2019-10-07 12:57:45+00:00,2019-12-12 17:05:27+00:00
BJlrF24twB,2020,Accept (Talk),False,BackPACK: Packing more into Backprop,"[""Felix Dangel"", ""Frederik Kunstner"", ""Philipp Hennig""]",[],,1912.10985,cs.LG,2019-12-23 17:22:45+00:00,2020-02-15 15:10:34+00:00
BJlrSmbAZ,2018,Reject,False,Bayesian Uncertainty Estimation for Batch Normalized Deep Networks,"[""Mattias Teye"", ""Hossein Azizpour"", ""Kevin Smith""]","[""uncertainty estimation"", ""deep learning"", ""Bayesian learning"", ""batch normalization""]","We show that training a deep network using batch normalization is equivalent to approximate inference in Bayesian models, and we demonstrate how this finding allows us to make useful estimates of the model uncertainty in conventional networks.",,,,
BJlrZyrKDB,2020,Reject,False,Statistically Consistent Saliency Estimation,"[""Emre Barut"", ""Shunyan Luo""]","[""Deep Learning Interpretation"", ""Saliency Estimation"", ""High Dimensional Statistics""]",We propose a statistical framework and a theoretically consistent procedure for saliency estimation.,,,,
BJluGHcee,2017,Reject,False,Tensorial Mixture Models,"[""Or Sharir"", ""Ronen Tamari"", ""Nadav Cohen"", ""Amnon Shashua""]","[""Deep learning"", ""Supervised Learning"", ""Unsupervised Learning""]","A generative model realized through convolutional networks, which has the unique property of having both tractable inference and marginalization, showing state-of-the-art results on classification with missing data.",,,,
BJluxREKDB,2020,Accept (Poster),False,Learning Heuristics for Quantified Boolean Formulas through Reinforcement Learning,"[""Gil Lederman"", ""Markus Rabe"", ""Sanjit Seshia"", ""Edward A. Lee""]","[""Logic"", ""QBF"", ""Logical Reasoning"", ""SAT"", ""Graph"", ""Reinforcement Learning"", ""GNN""]","We use RL to automatically learn branching heuristic within a state of the art QBF solver, on industrial problems.",,,,
BJluxbWC-,2018,Reject,False,Unseen Class Discovery in Open-world Classification,"[""Lei Shu"", ""Hu Xu"", ""Bing Liu""]",[],,,,,
BJluy2RcFm,2019,Accept (Poster),False,Janossy Pooling: Learning Deep Permutation-Invariant Functions for Variable-Size Inputs,"[""Ryan L. Murphy"", ""Balasubramaniam Srinivasan"", ""Vinayak Rao"", ""Bruno Ribeiro""]","[""representation learning"", ""permutation invariance"", ""set functions"", ""feature pooling""]","We propose Janossy pooling, a method for learning deep permutation invariant functions designed to exploit relationships within the input sequence and tractable inference strategies such as a stochastic optimization procedure we call piSGD",,,,
BJlxdCVKDB,2020,Reject,False,MoET: Interpretable and Verifiable Reinforcement Learning via Mixture of Expert Trees,"[""Marko Vasic"", ""Andrija Petrovic"", ""Kaiyuan Wang"", ""Mladen Nikolic"", ""Rishabh Singh"", ""Sarfraz Khurshid""]","[""explainable machine learning"", ""reinforcement learning""]",Explainable reinforcement learning model using novel combination of mixture of experts with non-differentiable decision tree experts.,,,,
BJlxm30cKm,2019,Accept (Poster),False,An Empirical Study of Example Forgetting during Deep Neural Network Learning,"[""Mariya Toneva*"", ""Alessandro Sordoni*"", ""Remi Tachet des Combes*"", ""Adam Trischler"", ""Yoshua Bengio"", ""Geoffrey J. Gordon""]","[""catastrophic forgetting"", ""sample weighting"", ""deep generalization""]",We show that catastrophic forgetting occurs within what is considered to be a single task and find that examples that are not prone to forgetting can be removed from the training set without loss of generalization.,,,,
BJlxmAKlg,2017,Reject,False,ReasoNet: Learning to Stop Reading in Machine Comprehension,"[""Yelong Shen"", ""Po-Sen Huang"", ""Jianfeng Gao"", ""Weizhu Chen""]","[""Deep learning"", ""Natural language processing""]",ReasoNet Reader for machine reading and comprehension,,,,
BJlyi64FvB,2020,Reject,True,Wider Networks Learn Better Features,"[""Dar Gilboa"", ""Guy Gur-Ari""]","[""Interpretability"", ""transfer learning""]","We visualize the hidden states of wide networks, finding that they contain more information about the inputs than narrow networks with equal performance, and show that wide networks fine-tuned to perform novel tasks outperform narrow networks.",1909.11572,cs.LG,2019-09-25 16:00:27+00:00,2019-09-25 16:00:27+00:00
BJlyznAcFm,2019,Reject,False,Advocacy Learning,"[""Ian Fox"", ""Jenna Wiens""]","[""competition"", ""supervision"", ""deep learning"", ""adversarial"", ""debate""]","We introduce a method that encourages different components in a networks to compete, and show that this can improve attention quality.",,,,
BJlzm64tDH,2020,Accept (Poster),False,Pretrained Encyclopedia: Weakly Supervised Knowledge-Pretrained Language Model,"[""Wenhan Xiong"", ""Jingfei Du"", ""William Yang Wang"", ""Veselin Stoyanov""]",[],,1912.09637,cs.CL,2019-12-20 04:25:48+00:00,2019-12-20 04:25:48+00:00
BJm4T4Kgx,2017,Accept (Poster),False,Adversarial Machine Learning at Scale,"[""Alexey Kurakin"", ""Ian J. Goodfellow"", ""Samy Bengio""]","[""Computer vision"", ""Supervised Learning""]",,,,,
BJmCKBqgl,2017,Reject,False,DyVEDeep: Dynamic Variable Effort Deep Neural Networks,"[""Sanjay Ganapathy"", ""Swagath Venkataramani"", ""Balaraman Ravindran"", ""Anand Raghunathan""]",[],,,,,
BJrFC6ceg,2017,Accept (Poster),False,PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications,"[""Tim Salimans"", ""Andrej Karpathy"", ""Xi Chen"", ""Diederik P. Kingma""]",[],Adding discretized logistic mixture Likelihood and other modifications to PixelCNN improves performance.,,,,
BJtNZAFgg,2017,Accept (Poster),False,Adversarial Feature Learning,"[""Jeff Donahue"", ""Philipp Kr\u00e4henb\u00fchl"", ""Trevor Darrell""]",[],,,,,
BJuWrGW0Z,2018,Accept (Poster),True,Dynamic Neural Program Embeddings for Program Repair,"[""Ke Wang"", ""Rishabh Singh"", ""Zhendong Su""]","[""Program Embedding"", ""Program Semantics"", ""Dynamic Traces""]",A new way of learning semantic program embedding,1711.07163,cs.AI,2017-11-20 06:02:06+00:00,2018-06-30 00:33:27+00:00
BJubPWZRW,2018,Invite to Workshop Track,False,Cross-View Training for Semi-Supervised Learning,"[""Kevin Clark"", ""Thang Luong"", ""Quoc V. Le""]","[""semi-supervised learning"", ""image recognition"", ""sequence tagging"", ""dependency parsing""]","Self-training with different views of the input gives excellent results for semi-supervised image recognition, sequence tagging, and dependency parsing.",,,,
BJuysoFeg,2017,Reject,False,Revisiting Batch Normalization For Practical Domain Adaptation,"[""Yanghao Li"", ""Naiyan Wang"", ""Jianping Shi"", ""Jiaying Liu"", ""Xiaodi Hou""]",[],We propose a simple yet effective approach for domain adaptation on batch normalized neural networks.,,,,
BJvVbCJCb,2018,Reject,False,Neural Clustering By Predicting And Copying Noise,"[""Sam Coope"", ""Andrej Zukov-Gregoric"", ""Yoram Bachrach""]","[""unsupervised learning"", ""clustering"", ""deep learning""]",Neural clustering without needing a number of clusters,,,,
BJvWjcgAZ,2018,Reject,False,Sample-Efficient Deep Reinforcement Learning via Episodic Backward Update,"[""Su Young Lee"", ""Sungik Choi"", ""Sae-Young Chung""]","[""Deep Learning"", ""Reinforcement Learning""]","We propose Episodic Backward Update, a novel deep reinforcement learning algorithm which samples transitions episode by episode and updates values recursively in a backward manner to achieve fast and stable learning.",,,,
BJwFrvOeg,2017,Reject,False,A Neural Knowledge Language Model,"[""Sungjin Ahn"", ""Heeyoul Choi"", ""Tanel Parnamaa"", ""Yoshua Bengio""]","[""Natural language processing"", ""Deep learning""]","A neural recurrent language model which can extract knowledge from a knowledge base to generate knowledge related words such as person names, locations, years, etc.",,,,
BJx-ZeSKDB,2020,Reject,False,Compositional Embeddings: Joint Perception and Comparison of Class Label Sets,"[""Zeqian Li"", ""Jacob Whitehill""]","[""Embedding"", ""One-shot Learning"", ""Compositional Representation""]",We explored how a novel method of compositional set embeddings can both perceive and represent not just a single class but an entire set of classes that is associated with the input data.,,,,
BJx040EFvH,2020,Accept (Poster),False,Fast is better than free: Revisiting adversarial training,"[""Eric Wong"", ""Leslie Rice"", ""J. Zico Kolter""]","[""adversarial examples"", ""adversarial training"", ""fast gradient sign method""]","FGSM-based adversarial training, with randomization, works just as well as PGD-based adversarial training: we can use this to train a robust classifier in 6 minutes on CIFAR10, and 12 hours on ImageNet, on a single machine.",2001.03994,cs.LG,2020-01-12 20:30:22+00:00,2020-01-12 20:30:22+00:00
BJx0sjC5FX,2019,Accept (Poster),False,RNNs implicitly implement tensor-product representations,"[""R. Thomas McCoy"", ""Tal Linzen"", ""Ewan Dunbar"", ""Paul Smolensky""]","[""tensor-product representations"", ""compositionality"", ""neural network interpretability"", ""recurrent neural networks""]","RNNs implicitly implement tensor-product representations, a principled and interpretable method for representing symbolic structures in continuous space.",1812.08718,cs.CL,2018-12-20 17:44:05+00:00,2019-03-05 16:00:06+00:00
BJx1SsAcYQ,2019,Reject,False,Discovering Low-Precision Networks Close to Full-Precision Networks for Efficient Embedded Inference,"[""Jeffrey L. McKinstry"", ""Steven K. Esser"", ""Rathinakumar Appuswamy"", ""Deepika Bablani"", ""John V. Arthur"", ""Izzet B. Yildiz"", ""Dharmendra S. Modha""]","[""Deep Learning"", ""Convolutional Neural Networks"", ""Low-precision inference"", ""Network quantization""]",Finetuning after quantization matches or exceeds full-precision state-of-the-art networks at both 8- and 4-bit quantization.,,,,
BJx3_0VKPB,2020,Reject,True,On the Unintended Social Bias of Training Language Generation Models with News Articles,"[""Omar U. Florez""]","[""Fair AI"", ""latent representations"", ""sequence to sequence""]",we introduce a novel architecture that allows us to update a memory module with an equal ratio across gender types addressing biased correlations directly in the latent space. ,1911.00461,cs.CL,2019-11-01 16:52:02+00:00,2019-11-01 16:52:02+00:00
BJx4rerFwB,2020,Reject,False,wMAN: WEAKLY-SUPERVISED MOMENT ALIGNMENT NETWORK FOR TEXT-BASED VIDEO SEGMENT RETRIEVAL,"[""Reuben Tan"", ""Huijuan Xu"", ""Kate Saenko"", ""Bryan A. Plummer""]","[""vision"", ""language"", ""video moment retrieval""]",Weakly-Supervised Text-Based Video Moment Retrieval,,,,
BJx7N1SKvB,2020,Reject,False,A Random Matrix Perspective on Mixtures of Nonlinearities in High Dimensions,"[""Ben Adlam"", ""Jake Levinson"", ""Jeffrey Pennington""]",[],,,,,
BJx8Fh4KPB,2020,Reject,True,RL-LIM: Reinforcement Learning-based Locally Interpretable Modeling,"[""Jinsung Yoon"", ""Sercan O. Arik"", ""Tomas Pfister""]","[""Interpretability"", ""Explanable AI"", ""Explanability""]",,1909.12367,cs.LG,2019-09-26 20:06:45+00:00,2019-09-26 20:06:45+00:00
BJx8YnEFPH,2020,Reject,True,Data Valuation using Reinforcement Learning,"[""Jinsung Yoon"", ""Sercan O. Arik"", ""Tomas Pfister""]","[""Data valuation"", ""Domain adaptation"", ""Robust learning"", ""Corrupted sample discovery""]",,1909.11671,cs.LG,2019-09-25 18:00:02+00:00,2019-09-25 18:00:02+00:00
BJx9f305t7,2019,Reject,False,W2GAN: RECOVERING AN OPTIMAL TRANSPORT MAP WITH A GAN,"[""Leygonie Jacob*"", ""Jennifer She*"", ""Amjad Almahairi"", ""Sai Rajeswar"", ""Aaron Courville""]","[""Optimal Transportation"", ""Deep Learning"", ""Generative Adversarial Networks"", ""Wasserstein Distance""]","""A GAN-style model to recover a solution of the Monge Problem""",,,,
BJxAHgSYDB,2020,Reject,False,Learning to Rank Learning Curves,"[""Martin Wistuba"", ""Tejaswini Pedapati""]",[],Learn to rank learning curves in order to stop unpromising training jobs early. Novelty: use of pairwise ranking loss to directly model the probability of improving and transfer learning across data sets to reduce required training data.,2006.03361,cs.LG,2020-06-05 10:49:52+00:00,2020-06-05 10:49:52+00:00
BJxDNxSFDH,2020,Reject,False,Few-Shot Regression via Learning Sparsifying Basis Functions,"[""Yi Loo"", ""Yiluan Guo"", ""Ngai-Man Cheung""]","[""meta-learning"", ""few-shot learning"", ""regression"", ""learning basis functions"", ""self-attention""]",We propose a method of doing few-shot regression by learning a set of basis functions to represent the function distribution.,,,,
BJxG_0EtDS,2020,Accept (Poster),True,"Prediction, Consistency, Curvature: Representation Learning for Locally-Linear Control","[""Nir Levine"", ""Yinlam Chow"", ""Rui Shu"", ""Ang Li"", ""Mohammad Ghavamzadeh"", ""Hung Bui""]","[""Embed-to-Control"", ""Representation Learning"", ""Stochastic Optimal Control"", ""VAE"", ""iLQR""]",Learning embedding for control with high-dimensional observations,1909.01506,cs.LG,2019-09-04 00:34:27+00:00,2020-02-10 21:35:48+00:00
BJxGan4FPB,2020,Reject,False,Transfer Alignment Network for Double Blind Unsupervised Domain Adaptation,"[""Huiwen Xu"", ""U Kang""]","[""unsupervised domain adaptation"", ""double blind domain adaptation""]","We propose an effective method for double blind domain adaptation problem where either source or target domain cannot observe the data in the other domain, but data from both domains are used for training. ",,,,
BJxH22EKPS,2020,Accept (Poster),True,Understanding Architectures Learnt by Cell-based Neural Architecture Search,"[""Yao Shu"", ""Wei Wang"", ""Shaofeng Cai""]","[""Neural Architecture Search"", ""connection pattern"", ""optimization"", ""convergence"", ""Lipschitz smoothness"", ""gradient variance"", ""generalization""]",,1909.09569,cs.LG,2019-09-20 15:49:45+00:00,2020-01-01 13:57:23+00:00
BJxI5gHKDr,2020,Accept (Poster),False,Pitfalls of In-Domain Uncertainty Estimation and Ensembling in Deep Learning,"[""Arsenii Ashukha"", ""Alexander Lyzhov"", ""Dmitry Molchanov"", ""Dmitry Vetrov""]","[""uncertainty"", ""in-domain uncertainty"", ""deep ensembles"", ""ensemble learning"", ""deep learning""]",We highlight the problems with common metrics of in-domain uncertainty and perform a broad study of modern ensembling techniques.,2002.06470,stat.ML,2020-02-15 23:28:19+00:00,2021-07-18 16:17:28+00:00
BJxLH2AcYX,2019,Reject,False,Unsupervised Multi-Target Domain Adaptation: An Information Theoretic Approach,"[""Behnam Gholami"", ""Pritish Sahu"", ""Ognjen (Oggi) Rudovic"", ""Konstantinos Bousmalis"", ""Vladimir Pavlovic""]",[],,,,,
BJxOHs0cKm,2019,Reject,False,Identifying Generalization Properties in Neural Networks,"[""Huan Wang"", ""Nitish Shirish Keskar"", ""Caiming Xiong"", ""Richard Socher""]","[""generalization"", ""PAC-Bayes"", ""Hessian"", ""perturbation""]",a theory connecting Hessian of the solution and the generalization power of the model,,,,
BJxPk2A9Km,2019,Reject,False,Learning What to Remember: Long-term Episodic Memory Networks for Learning from Streaming Data,"[""Hyunwoo Jung"", ""Moonsu Han"", ""Minki Kang"", ""Sungju Hwang""]","[""Memory Network"", ""Lifelong Learning""]",,,,,
BJxQxeBYwH,2020,Reject,True,Are Powerful Graph Neural Nets Necessary? A Dissection on Graph Classification,"[""Ting Chen"", ""Song Bian"", ""Yizhou Sun""]","[""graph neural nets"", ""graph classification"", ""set function""]","We propose a dissection of GNNs through linearization of the parts, and find that linear graph filtering with non-linear set function is powerful enough for common graph classification benchmarks.",1905.04579,cs.LG,2019-05-11 19:47:19+00:00,2020-06-09 22:32:19+00:00
BJxRVnC5Fm,2019,Reject,False,Mean Replacement Pruning  ,"[""Utku Evci"", ""Nicolas Le Roux"", ""Pablo Castro"", ""Leon Bottou""]","[""pruning"", ""saliency"", ""neural networks"", ""optimization"", ""redundancy"", ""model compression""]",Mean Replacement is an efficient method to improve the loss after pruning and Taylor approximation based scoring functions works better with absolute values. ,,,,
BJxSI1SKDH,2020,Accept (Spotlight),True,A Latent Morphology Model for Open-Vocabulary Neural Machine Translation,"[""Duygu Ataman"", ""Wilker Aziz"", ""Alexandra Birch""]","[""neural machine translation"", ""low-resource languages"", ""latent-variable models""]",,1910.13890,cs.CL,2019-10-30 14:29:47+00:00,2020-02-26 20:47:17+00:00
BJxSWeSYPB,2020,Reject,True,Self-supervised Training of Proposal-based Segmentation via Background Prediction,"[""Isinsu Katircioglu"", ""Helge Rhodin"", ""Victor Constantin"", ""J\u00f6rg Sp\u00f6rri"", ""Mathieu Salzmann"", ""Pascal Fua""]",[],,1907.08051,cs.CV,2019-07-18 13:52:06+00:00,2019-07-18 13:52:06+00:00
BJxVI04YvB,2020,Accept (Poster),False,PAC Confidence Sets for Deep Neural Networks via Calibrated Prediction,"[""Sangdon Park"", ""Osbert Bastani"", ""Nikolai Matni"", ""Insup Lee""]","[""PAC"", ""confidence sets"", ""classification"", ""regression"", ""reinforcement learning""]",,2001.00106,cs.LG,2019-12-31 23:02:01+00:00,2020-02-15 19:50:39+00:00
BJxVT3EKDH,2020,Reject,False,Corpus Based Amharic Sentiment Lexicon Generation,"[""Girma Neshir"", ""Andeas Rauber"", ""and Solomon Atnafu""]","[""Amharic sentiment lexicon"", ""Amharic sentiment classification"", ""seed words""]",Corpus based Algorithm is developed generate Amharic Sentiment lexicon relying on corpus,,,,
BJxWx0NYPr,2020,Accept (Poster),False,Adaptive Structural Fingerprints for Graph Attention Networks,"[""Kai Zhang"", ""Yaokang Zhu"", ""Jun Wang"", ""Jie Zhang""]","[""Graph attention networks"", ""graph neural networks"", ""node classification""]","Exploiting rich strucural details in graph-structued data via adaptive ""strucutral fingerprints''",,,,
BJxYEsAqY7,2019,Reject,False,FEED: Feature-level Ensemble Effect for knowledge Distillation,"[""SeongUk Park"", ""Nojun Kwak""]","[""Knowledge Distillation"", ""Ensemble Effect"", ""Knowledge Transfer""]",,,,,
BJxYUaVtPB,2020,Reject,False,Match prediction from group comparison data using neural networks,"[""Sunghyun Kim"", ""Minje jang"", ""Changho Suh""]","[""Neural networks"", ""Group comparison"", ""Match prediction"", ""Rank aggregation""]","We investigate the merits of employing neural networks in the match prediction problem where one seeks to estimate the likelihood of a group of M items preferred over another, based on partial group comparison data.",,,,
BJx_JAVKDB,2020,Reject,False,In-Domain Representation Learning For Remote Sensing,"[""Maxim Neumann"", ""Andre Susano Pinto"", ""Xiaohua Zhai"", ""Neil Houlsby""]","[""Representation learning"", ""remote sensing""]",Exploration of in-domain representation learning for remote sensing datasets.,1911.06721,cs.CV,2019-11-15 16:09:38+00:00,2019-11-15 16:09:38+00:00
BJxbOlSKPr,2020,Reject,True,Learning Compact Embedding Layers via Differentiable Product Quantization,"[""Ting Chen"", ""Lala Li"", ""Yizhou Sun""]","[""efficient modeling"", ""compact embedding"", ""embedding table compression"", ""differentiable product quantization""]",We propose a differentiable product quantization framework that can reduce the size of embedding layer in an end-to-end training at no performance cost.,1908.09756,cs.LG,2019-08-26 15:56:10+00:00,2020-06-25 23:36:28+00:00
BJxbYoC9FQ,2019,Reject,False,Classifier-agnostic saliency map extraction,"[""Konrad Zolna"", ""Krzysztof J. Geras"", ""Kyunghyun Cho""]","[""saliency maps"", ""explainable AI"", ""convolutional neural networks"", ""generative adversarial training"", ""classification""]",We propose a new saliency map extraction method which results in extracting higher quality maps.,,,,
BJxeHyrKPB,2020,Reject,False,RATE-DISTORTION OPTIMIZATION GUIDED AUTOENCODER FOR GENERATIVE APPROACH,"[""Keizo Kato"", ""Jing Zhou"", ""Akira Nakagawa""]","[""Autoencoder"", ""Rate-distortion optimization"", ""Generative model"", ""Unsupervised learning"", ""Jacobian""]","We propose an autoencoder based on Rate-Distortion Optimization.  With our model, log-likelihood maximization is possible without ELBO.",,,,
BJxg_hVtwH,2020,Accept (Poster),False,StructPool: Structured Graph Pooling via Conditional Random Fields,"[""Hao Yuan"", ""Shuiwang Ji""]","[""Graph Pooling"", ""Representation Learning"", ""Graph Analysis""]",A novel graph pooling method considering relationships between different nodes via conditional random fields.,,,,
BJxgz2R9t7,2019,Accept (Poster),False,Learning To Solve Circuit-SAT: An Unsupervised Differentiable Approach,"[""Saeed Amizadeh"", ""Sergiy Matusevych"", ""Markus Weimer""]","[""Neuro-Symbolic Methods"", ""Circuit Satisfiability"", ""Neural SAT Solver"", ""Graph Neural Networks""]",We propose a neural framework that can learn to solve the Circuit Satisfiability problem from (unlabeled) circuit instances.,,,,
BJxh2j0qYm,2019,Accept (Poster),False,Dynamic Channel Pruning: Feature Boosting and Suppression,"[""Xitong Gao"", ""Yiren Zhao"", ""\u0141ukasz Dudziak"", ""Robert Mullins"", ""Cheng-zhong Xu""]","[""dynamic network"", ""faster CNNs"", ""channel pruning""]",We make convolutional layers run faster by dynamically boosting and suppressing channels in feature computation.,,,,
BJxhLAuxg,2017,Reject,False,A Deep Learning Approach for Joint Video Frame and Reward Prediction in Atari Games,"[""Felix Leibfried"", ""Nate Kushman"", ""Katja Hofmann""]",[],,,,,
BJxhijAcY7,2019,Accept (Poster),False,signSGD with Majority Vote is Communication Efficient and Fault Tolerant,"[""Jeremy Bernstein"", ""Jiawei Zhao"", ""Kamyar Azizzadenesheli"", ""Anima Anandkumar""]","[""large-scale learning"", ""distributed systems"", ""communication efficiency"", ""convergence rate analysis"", ""robust optimisation""]","Workers send gradient signs to the server, and the update is decided by majority vote. We show that this algorithm is convergent, communication efficient and fault tolerant, both in theory and in practice.",,,,
BJxiqxSYPB,2020,Reject,False,Learning to Prove Theorems by Learning to Generate Theorems,"[""Mingzhe Wang"", ""Jia Deng""]",[],,2002.07019,cs.LO,2020-02-17 16:06:02+00:00,2020-10-30 04:33:04+00:00
BJxkOlSYDH,2020,Accept (Poster),False,Provable Filter Pruning for Efficient Neural Networks,"[""Lucas Liebenwein"", ""Cenk Baykal"", ""Harry Lang"", ""Dan Feldman"", ""Daniela Rus""]","[""theory"", ""compression"", ""filter pruning"", ""neural networks""]",A sampling-based filter pruning approach for convolutional neural networks exhibiting provable guarantees on the size and performance of the pruned network.,1911.07412,cs.LG,2019-11-18 03:56:49+00:00,2020-03-23 04:39:39+00:00
BJxlmeBKwS,2020,Reject,False,FRICATIVE PHONEME DETECTION WITH ZERO DELAY,"[""Metehan Yurt"", ""Alberto N. Escalante B."", ""Veniamin I. Morgenshtern""]","[""fricative detection"", ""phoneme detection"", ""speech recognition"", ""deep learning"", ""hearing aids"", ""zero delay"", ""extrapolation"", ""TIMIT""]",A deep learning based approach for zero delay fricative phoneme detection,,,,
BJxmXhRcK7,2019,Reject,False,TENSOR RING NETS ADAPTED DEEP MULTI-TASK LEARNING,"[""Xinqi Chen"", ""Ming Hou"", ""Guoxu Zhou"", ""Qibin Zhao""]","[""deep learning"", ""deep multi-task learning"", ""tensor factorization"", ""tensor ring nets""]",a deep multi-task learning model adapting tensor ring representation,,,,
BJxnIxSKDr,2020,Reject,False,Mint: Matrix-Interleaving for Multi-Task Learning,"[""Tianhe Yu"", ""Saurabh Kumar"", ""Eric Mitchell"", ""Abhishek Gupta"", ""Karol Hausman"", ""Sergey Levine"", ""Chelsea Finn""]","[""multi-task learning""]","We propose an approach that endows a single model with the ability to represent both extremes: joint training and independent training, which leads to effective multi-task learning.",,,,
BJxqohNFPB,2020,Reject,False,S-Flow GAN,"[""Miron Yakov"", ""Coscas Yona""]","[""GAN"", ""Image Generation"", ""AI"", ""Generative Models"", ""CV""]",Simulation to real images translation and video generation,,,,
BJxsrgStvr,2020,Accept (Spotlight),True,Drawing Early-Bird Tickets: Toward More Efficient Training of Deep Networks,"[""Haoran You"", ""Chaojian Li"", ""Pengfei Xu"", ""Yonggan Fu"", ""Yue Wang"", ""Xiaohan Chen"", ""Richard G. Baraniuk"", ""Zhangyang Wang"", ""Yingyan Lin""]",[],,1909.11957,cs.LG,2019-09-26 07:43:56+00:00,2020-08-07 06:12:58+00:00
BJxssoA5KX,2019,Accept (Poster),False,Bounce and Learn: Modeling Scene Dynamics with Real-World Bounces,"[""Senthil Purushwalkam"", ""Abhinav Gupta"", ""Danny Kaufman"", ""Bryan Russell""]","[""intuitive physics"", ""visual prediction"", ""surface normal"", ""restitution"", ""bounces""]",,,,,
BJxt2aVFPr,2020,Reject,False,Optimizing Data Usage via Differentiable Rewards,"[""Xinyi Wang"", ""Hieu Pham"", ""Paul Michel"", ""Antonios Anastasopoulos"", ""Graham Neubig"", ""Jaime Carbonell""]","[""data selection"", ""multilingual neural machine translation"", ""data usage optimzation"", ""transfer learning"", ""classification""]",,,,,
BJxt60VtPr,2020,Accept (Poster),True,Learning from Unlabelled Videos Using Contrastive Predictive Neural 3D Mapping,"[""Adam W. Harley"", ""Shrinidhi K. Lakshmikanth"", ""Fangyu Li"", ""Xian Zhou"", ""Hsiao-Yu Fish Tung"", ""Katerina Fragkiadaki""]","[""3D feature learning"", ""unsupervised learning"", ""inverse graphics"", ""object discovery""]","We show that with the right loss and architecture, view-predictive learning improves 3D object detection",1906.03764,cs.CV,2019-06-10 01:53:42+00:00,2020-05-17 02:16:28+00:00
BJxvEh0cFQ,2019,Accept (Poster),False,K for the Price of 1: Parameter-efficient Multi-task and Transfer Learning,"[""Pramod Kaushik Mudrakarta"", ""Mark Sandler"", ""Andrey Zhmoginov"", ""Andrew Howard""]","[""deep learning"", ""mobile"", ""transfer learning"", ""multi-task learning"", ""computer vision"", ""small models"", ""imagenet"", ""inception"", ""batch normalization""]","A novel and practically effective method to adapt pretrained neural networks to new tasks by retraining a minimal (e.g., less than 2%) number of parameters",,,,
BJxvH1BtDS,2020,Reject,False,Three-Head Neural Network Architecture for AlphaZero Learning,"[""Chao Gao"", ""Martin Mueller"", ""Ryan Hayward"", ""Hengshuai Yao"", ""Shangling Jui""]","[""alphazero"", ""reinforcement learning"", ""two-player games"", ""heuristic search"", ""deep neural networks""]",An empirical study of three-head architecture for AlphaZero learning,,,,
BJxwPJHFwS,2020,Accept (Poster),False,Robustness Verification for Transformers,"[""Zhouxing Shi"", ""Huan Zhang"", ""Kai-Wei Chang"", ""Minlie Huang"", ""Cho-Jui Hsieh""]","[""Robustness"", ""Verification"", ""Transformers""]",We propose the first algorithm for verifying the robustness of Transformers.,2002.06622,cs.LG,2020-02-16 17:16:31+00:00,2020-12-23 12:36:47+00:00
BJxyzxrYPH,2020,Reject,False,Deep geometric matrix completion:  Are we doing it right?,"[""Amit Boyarski"", ""Sanketh Vedula"", ""Alex Bronstein""]","[""Geometric Matrix Completion"", ""Spectral Graph Theory"", ""Functional Maps"", ""Deep Linear Networks""]","A simple spectral geometric approach for matrix completion, based on the framework of functional maps.",,,,
BJy0fcgRZ,2018,Invite to Workshop Track,False,Capturing Human Category Representations by Sampling in Deep Feature Spaces,"[""Joshua Peterson"", ""Krishan Aghi"", ""Jordan Suchow"", ""Alexander Ku"", ""Tom Griffiths""]","[""category representations"", ""psychology"", ""cognitive science"", ""deep neural networks""]",using deep neural networks and clever algorithms to capture human mental visual concepts,,,,
BJypUGZ0Z,2018,Invite to Workshop Track,False,Accelerating Neural Architecture Search using Performance Prediction,"[""Bowen Baker*"", ""Otkrist Gupta*"", ""Ramesh Raskar"", ""Nikhil Naik""]",[],,,,,
BJzbG20cFQ,2019,Accept (Poster),False,Towards Metamerism via Foveated Style Transfer,"[""Arturo Deza"", ""Aditya Jonnalagadda"", ""Miguel P. Eckstein""]","[""Metamerism"", ""foveation"", ""perception"", ""style transfer"", ""psychophysics""]",We introduce a novel feed-forward framework to generate visual metamers,,,,
BJzmzn0ctX,2019,Reject,False,Scalable Neural Theorem Proving on Knowledge Bases and Natural Language,"[""Pasquale Minervini"", ""Matko Bosnjak"", ""Tim Rockt\u00e4schel"", ""Edward Grefenstette"", ""Sebastian Riedel""]","[""Machine Reading"", ""Natural Language Processing"", ""Neural Theorem Proving"", ""Representation Learning"", ""First Order Logic""]","We scale Neural Theorem Provers to large datasets, improve the rule learning process, and extend it to jointly reason over text and Knowledge Bases.",,,,
BJzuKiC9KX,2019,Reject,False,Revisiting Reweighted Wake-Sleep,"[""Tuan Anh Le"", ""Adam R. Kosiorek"", ""N. Siddharth"", ""Yee Whye Teh"", ""Frank Wood""]","[""variational inference"", ""approximate inference"", ""generative models"", ""gradient estimators""]",Empirical analysis and explanation of particle-based gradient estimators for approximate inference with deep generative models.,,,,
BK-4qbGgIE3,2022,Accept (Poster),False,No One Representation to Rule Them All: Overlapping Features of Training Methods,"['Raphael Gontijo-Lopes', 'Yann Dauphin', 'Ekin Dogus Cubuk']","[""Representation Learning"", ""Understanding Deep Learning"", ""Deep Phenomena"", ""Diversity"", ""Novelty"", ""Features"", ""Training Methodologies"", ""Contrastive Learning""]","We study the effect of training methodology on prediction diversity and show that diverging training setups produce diverse features, uncorrelated errors, and more efficient ensembles.",,,,
BKIS2NCUro9,2021,Reject,False,LATENT OPTIMIZATION VARIATIONAL AUTOENCODER FOR CONDITIONAL MOLECULAR GENERATION,"[""Kisoo Kwon"", ""Jung-Hyun Park"", ""Kuhwan Jeong"", ""Sunjae Lee"", ""Hoshik Lee""]","[""latent optimization"", ""Variational Autoencoder"", ""molecular generation""]","We proposed two-stage latent optimization for variational autoencoder, and the proposed method showed better performances in molecular generation task compared to existing works.",,,,
BKOiqcdpml3,2022,Reject,False,Low Entropy Deep Networks,"['Chris Subia-Waud', 'Srinandan Dasmahapatra']","[""Quantisation"", ""Compression"", ""AI Accelerators""]",A compression pipeline that uses a single network codebook and focusses on relative movement cost minimisation to produce highly compressible and hardware-friendly representations of networks using just a few unique weights.,,,,
BKmoW5K4sS,2022,Reject,True,On Adversarial Bias and the Robustness of Fair Machine Learning,"['Hongyan Chang', 'Ta Duy Nguyen', 'Sasi Kumar Murakonda', 'Ehsan Kazemi', 'Reza Shokri']","[""Robustness"", ""Algorithmic fairness""]",We quantitatively measure the impact of group fairness on the robustness of models in the adversarial setting.,2006.08669,stat.ML,2020-06-15 18:17:44+00:00,2020-06-15 18:17:44+00:00
BM---bH_RSh,2021,Accept (Poster),False,UMEC: Unified model and embedding compression for efficient recommendation systems,"[""Jiayi Shen"", ""Haotao Wang"", ""Shupeng Gui"", ""Jianchao Tan"", ""Zhangyang Wang"", ""Ji Liu""]","[""recommendation system"", ""model compression"", ""ADMM"", ""resource constrained""]",We propose a unified model and embedding compression (UMEC) framework to hammer an efficient neural network-based recommendation system.,,,,
BM7RjuhAK7W,2022,Reject,False,Model-Invariant State Abstractions for Model-Based Reinforcement Learning,"['Manan Tomar', 'Amy Zhang', 'Roberto Calandra', 'Matthew E. Taylor', 'Joelle Pineau']","[""Reinforcement Learning"", ""Model-based RL"", ""State Abstractions"", ""Generalization in RL""]",A practical method for avoiding spurious correlations pertaining to dynamics models in MBRL,,,,
BMua55nUyyt,2021,Reject,False,Median DC for Sign Recovery: Privacy can be Achieved by Deterministic Algorithms,"[""Jiyuan Tu"", ""Weidong Liu"", ""Xiaojun Mao""]","[""Median-of-means"", ""divide-and-conquer"", ""privacy"", ""sign recovery""]","This paper proposes a median divide-and-conquer approach to the sign recovery problem in a distributed setup, which can protect data privacy with high probability.",,,,
BNIt2myzSzS,2022,Reject,False,IA-MARL: Imputation Assisted Multi-Agent Reinforcement Learning for Missing Training Data,"['Dongsun Kim', 'Sinwoong Yun', 'Jemin Lee', 'Eunbyung Park']",[],,,,,
BRFWxcZfAdC,2022,Accept (Poster),False,Cross-Domain Lossy Compression as Optimal Transport with an Entropy Bottleneck,"['Huan Liu', 'George Zhang', 'Jun Chen', 'Ashish J Khisti']","[""Image Compression"", ""Image Restoration"", ""Optimal Transport"", ""Deep Learning""]","We consider the novel task of cross-distribution lossy compression and characterize it as an optimal transport problem under an entropy constraint, then provide experimental results to demonstrate the principles suggested by our theory.",,,,
BS49l-B5Bql,2022,Accept (Spotlight),True,GNN-LM: Language Modeling based on Global Contexts via GNN,"['Yuxian Meng', 'Shi Zong', 'Xiaoya Li', 'Xiaofei Sun', 'Tianwei Zhang', 'Fei Wu', 'Jiwei Li']",[],,2110.08743,cs.CL,2021-10-17 07:18:21+00:00,2022-01-24 02:25:05+00:00
BUPIRa1D2J,2021,Reject,False,Trans-Caps: Transformer Capsule Networks with Self-attention Routing,"[""Aryan Mobiny"", ""Pietro Antonio Cicalese"", ""Hien Van Nguyen""]","[""capsule network"", ""self-attention""]","In this paper, we propose a novel non-iterative routing strategy named self-attention routing (SAR) that computes the agreement between the capsules in one forward pass.",,,,
BUlyHkzjgmA,2021,Accept (Poster),False,Improved Estimation of Concentration Under $\ell_p$-Norm Distance Metrics Using Half Spaces,"[""Jack Prescott"", ""Xiao Zhang"", ""David Evans""]","[""Adversarial Examples"", ""Concentration of Measure"", ""Gaussian Isoperimetric Inequality""]",We show that concentration of measure does not prohibit the existence of adversarially robust classifiers using a novel method of empirical concentration estimation.,2103.12913,cs.LG,2021-03-24 01:16:28+00:00,2021-03-24 01:16:28+00:00
BVPowUU1cR,2021,Reject,True,Assisting the Adversary to Improve GAN Training,"[""Andreas Munk"", ""William Harvey"", ""Frank Wood""]","[""Generative Adversarial Networks"", ""GANs""]",We propose a method for improved training of generative adversarial networks (GANs) by regularizing the updates on the generator.,2010.01274,cs.LG,2020-10-03 04:20:45+00:00,2020-12-09 00:17:09+00:00
BVSM0x3EDK6,2021,Accept (Poster),True,Robust and Generalizable Visual Representation Learning via Random Convolutions,"[""Zhenlin Xu"", ""Deyi Liu"", ""Junlin Yang"", ""Colin Raffel"", ""Marc Niethammer""]","[""domain generalization"", ""robustness"", ""representation learning"", ""data augmentation""]",We use random convolutions as data augmentation to train robust visual representation that generalize to new domains.,2007.13003,cs.CV,2020-07-25 19:52:25+00:00,2021-05-03 16:12:15+00:00
BW5PuV4V-rL,2021,Reject,True,Gradient-based training of Gaussian Mixture Models for High-Dimensional Streaming Data,"[""Alexander Gepperth"", ""Benedikt Pf\u00fclb""]","[""Gaussian Mixture Models"", ""Stochastic Gradient Descent"", ""Unsupervised Representation Learning"", ""Continual Learning""]","We present a method to train Gaussian Mixture Models by SGD, which requires no prior k-means initialization as EM does, and is thus feasible for streaming data. ",1912.09379,cs.LG,2019-12-18 09:35:39+00:00,2021-07-02 16:25:30+00:00
BXewfAYMmJw,2021,Accept (Poster),False,Counterfactual Generative Networks,"[""Axel Sauer"", ""Andreas Geiger""]","[""Causality"", ""Counterfactuals"", ""Generative Models"", ""Robustness"", ""Image Classification"", ""Data Augmentation""]",A generative model structured into independent causal mechanisms produces images for training invariant classifiers.,,,,
BZbUtxOy3R,2022,Reject,False,Character Generation through Self-Supervised Vectorization,"['Gokcen Gokceoglu', 'Emre Akbas']","[""character generation"", ""parsing"", ""reconstruction"", ""self-supervised"", ""omniglot""]",A self-supervised stroke-based drawing agent that can handle all generation and parsing tasks in the Omniglot Challenge. ,,,,
BZnnMbt0pW,2022,Accept (Poster),False,Promoting Saliency From Depth: Deep Unsupervised RGB-D Saliency Detection,"['Wei Ji', 'Jingjing Li', 'Qi Bi', 'chuan guo', 'Jie Liu', 'Li Cheng']","[""RGB-D saliency detection"", ""salient object detection"", ""deep learning"", ""unsupervised learning""]","We propose the first deep unsupervised RGB-D saliency detection method, which achieves appealing performance and does not require any human efforts compared to fully-supervised learning.",,,,
BbNIbVPJ-42,2021,Accept (Poster),False,The Risks of Invariant Risk Minimization,"[""Elan Rosenfeld"", ""Pradeep Kumar Ravikumar"", ""Andrej Risteski""]","[""out-of-distribution generalization"", ""causality"", ""representation learning"", ""deep learning""]",We formally demonstrate that Invariant Risk Minimization and related alternative objectives often perform no better than standard ERM.,,,,
Bc4fwa76mRp,2022,Reject,False,Head2Toe: Utilizing Intermediate Representations for Better OOD Generalization,"['Utku Evci', 'Vincent Dumoulin', 'Hugo Larochelle', 'Michael Curtis Mozer']","[""efficient training"", ""transfer learning"", ""efficient transfer"", ""fine tuning"", ""computer vision"", ""linear probe""]","We propose a method, Head-to-Toe probing (Head2Toe), that selects features from all layers of a pretrained source model in order to achieve better out of distribution generalization.",,,,
Bd8JSwLVWQ5,2022,Reject,False,Equivalence of State Equations from Different Methods in High-dimensional Regression,"['Saidi Luo', 'Song tao Tian', 'Qian Lin']","[""Approximate message passing"", ""Lasso"", ""High dimensional statistics""]","We showed that for some specific problem, different set of equations derived from AMP, CGMT and LOO are equivalent.",,,,
BduNVoPyXBK,2022,Reject,False,Task-driven Discovery of Perceptual Schemas for Generalization in Reinforcement Learning,"['Wilka Torrico Carvalho', 'Andrew Kyle Lampinen', 'Kyriacos Nikiforou', 'Felix Hill', 'Murray Shanahan']","[""deep reinforcement learning"", ""reinforcement learning"", ""deep learning"", ""compositional generalization"", ""generalization"", ""recurrent architecture""]",We develop a modular and composable architecture that leverages dynamic feature attention to generalize across diverse environments.,,,,
Bel1Do_eZC,2022,Reject,False,Inductive Lottery Ticket Learning for Graph Neural Networks,"['Yongduo Sui', 'Xiang Wang', 'Tianlong Chen', 'Xiangnan He', 'Tat-Seng Chua']","[""Lottery Ticket Hypothesis"", ""Graph Neural Networks"", ""Neural Network Pruning""]","We propose a co-sparsify framework for input graphs and GNN model, which can successfully locate the graph lottery tickets in inductive learning setting.",,,,
BfayGoTV4iQ,2021,Reject,False,SketchEmbedNet: Learning Novel Concepts by Imitating Drawings,"[""Alexander Wang"", ""Mengye Ren"", ""Richard Zemel""]","[""generative"", ""probabilistic"", ""sketch"", ""drawing"", ""few-shot learning"", ""classification"", ""embedding learning""]",Learning a generative image to sketch model for few-shot classification and novel visual understanding in both embedding and image space.,,,,
Bi2OvVf1KPn,2021,Reject,False,Provable Robust Learning for Deep Neural Networks under Agnostic Corrupted Supervision,"[""Boyang Liu"", ""Mengying Sun"", ""Ding Wang"", ""Pang-Ning Tan"", ""Jiayu Zhou""]","[""Noisy Label"", ""Corrupted Supervision"", ""Robustness"", ""Optimization""]",A provable robust algorithm to defense agnostic label corruptions.,2102.06735,cs.LG,2021-02-12 19:36:04+00:00,2021-02-12 19:36:04+00:00
BjyvwnXXVn_,2022,Accept (Spotlight),False,EViT: Expediting Vision Transformers via Token Reorganizations,"['Youwei Liang', 'Chongjian GE', 'Zhan Tong', 'Yibing Song', 'Jue Wang', 'Pengtao Xie']","[""Vision Transformers"", ""multi-head self-attention"", ""efficient inference""]",We propose to reorganize attentive tokens in Vision Transformers to expedite inference speed.,,,,
Bk-ofQZRb,2018,Reject,False,TD Learning with Constrained Gradients,"[""Ishan Durugkar"", ""Peter Stone""]","[""Reinforcement Learning"", ""TD Learning"", ""DQN""]",We show that adding a constraint to TD updates stabilizes learning and allows Deep Q-learning without a target network,,,,
Bk0FWVcgx,2017,Accept (Poster),False,Topology and Geometry of Half-Rectified Network Optimization,"[""C. Daniel Freeman"", ""Joan Bruna""]","[""Theory"", ""Deep learning""]","We provide theoretical, algorithmical and experimental results concerning the optimization landscape of deep neural networks",,,,
Bk0MRI5lg,2017,Reject,False,Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units,"[""Dan Hendrycks"", ""Kevin Gimpel""]",[],A Competitor of ReLUs and ELUs with a Probabilistic Underpinning,,,,
Bk2TqVcxe,2017,Invite to Workshop Track,False,Discovering objects and their relations from entangled scene representations,"[""David Raposo"", ""Adam Santoro"", ""David Barrett"", ""Razvan Pascanu"", ""Timothy Lillicrap"", ""Peter Battaglia""]",[],,,,,
Bk346Ok0W,2018,Reject,False,Sensor Transformation Attention Networks,"[""Stefan Braun"", ""Daniel Neil"", ""Enea Ceolini"", ""Jithendar Anumula"", ""Shih-Chii Liu""]","[""attention"", ""sensor-selection"", ""multi-sensor"", ""natural noise""]",We introduce a modular multi-sensor network architecture with an attentional mechanism that enables dynamic sensor selection on real-world noisy data from CHiME-3.,,,,
Bk3F5Y9lx,2017,Reject,False,Epitomic Variational Autoencoders,"[""Serena Yeung"", ""Anitha Kannan"", ""Yann Dauphin"", ""Li Fei-Fei""]","[""Unsupervised Learning""]",We introduce an extension of variational autoencoders that learns multiple shared latent subspaces to address the issue of model capacity underutilization.,,,,
Bk67W4Yxl,2017,Reject,False,Improved Architectures for Computer Go,"[""Tristan Cazenave""]","[""Games"", ""Supervised Learning"", ""Deep learning""]",Improving training of deep networks for computer Go modifying the layers,,,,
Bk6qQGWRb,2018,Reject,False,Efficient Exploration through Bayesian   Deep Q-Networks,"[""Kamyar Azizzadenesheli"", ""Emma Brunskill"", ""Animashree Anandkumar""]","[""Deep RL"", ""Thompson Sampling"", ""Posterior update""]",Using Bayesian regression to estimate the posterior over Q-functions and deploy Thompson Sampling as a targeted exploration strategy with efficient trade-off the exploration and exploitation,,,,
Bk7wvW-C-,2018,Reject,False,Exploring Asymmetric Encoder-Decoder Structure for Context-based Sentence Representation Learning,"[""Shuai Tang"", ""Hailin Jin"", ""Chen Fang"", ""Zhaowen Wang"", ""Virginia R. de Sa""]","[""asymmetric structure"", ""RNN-CNN"", ""fast"", ""unsupervised"", ""representation"", ""sentence""]",We proposed an RNN-CNN encoder-decoder model for fast unsupervised sentence representation learning.,,,,
Bk8BvDqex,2017,Accept (Poster),False,Metacontrol for Adaptive Imagination-Based Optimization,"[""Jessica B. Hamrick"", ""Andrew J. Ballard"", ""Razvan Pascanu"", ""Oriol Vinyals"", ""Nicolas Heess"", ""Peter W. Battaglia""]","[""Deep learning"", ""Reinforcement Learning"", ""Optimization""]","We present a ""metacontroller"" neural architecture which can adaptively decide how long to run an model-based online optimization procedure for, and which models to use during the optimization.",,,,
Bk8N0RLxx,2017,Reject,False,Vocabulary Selection Strategies for Neural Machine Translation,"[""Gurvan L'Hostis"", ""David Grangier"", ""Michael Auli""]","[""Natural language processing""]",Neural machine translation can reach same accuracy with a 10x speedup by pruning the vocabulary prior to decoding.,,,,
Bk8ZcAxR-,2018,Accept (Poster),True,Eigenoption Discovery through the Deep Successor Representation,"[""Marlos C. Machado"", ""Clemens Rosenbaum"", ""Xiaoxiao Guo"", ""Miao Liu"", ""Gerald Tesauro"", ""Murray Campbell""]","[""reinforcement learning"", ""options"", ""successor representation"", ""proto-value functions"", ""Atari"", ""Arcade Learning Environment""]","We show how we can use the successor representation to discover eigenoptions in stochastic domains, from raw pixels. Eigenoptions are options learned to navigate the latent dimensions of a learned representation.",1710.11089,cs.LG,2017-10-30 17:36:19+00:00,2018-02-23 21:55:05+00:00
Bk8aOm9xl,2017,Invite to Workshop Track,False,Surprise-Based Intrinsic Motivation for Deep Reinforcement Learning,"[""Joshua Achiam"", ""Shankar Sastry""]","[""Reinforcement Learning""]",Learn a dynamics model and use it to make your agent boldly go where it has not gone before.,,,,
Bk9zbyZCZ,2018,Accept (Poster),False, Neural Map: Structured Memory for Deep Reinforcement Learning,"[""Emilio Parisotto"", ""Ruslan Salakhutdinov""]","[""deep reinforcement learning"", ""deep learning"", ""memory""]",,,,,
BkA7gfZAb,2018,Invite to Workshop Track,False,Stable Distribution Alignment Using the Dual of the Adversarial Distance,"[""Ben Usman"", ""Kate Saenko"", ""Brian Kulis""]","[""domain adaptation"", ""adversarial networks"", ""statistical distance"", ""duality""]", We propose a dual version of the logistic adversarial distance for feature alignment and show that it yields more stable gradient step iterations than the min-max objective.,,,,
BkCPyXm1l,2017,Reject,False,SoftTarget Regularization: An Effective Technique to Reduce Over-Fitting in Neural Networks,"[""Armen Aghajanyan""]","[""Deep learning"", ""Optimization"", ""Computer vision""]",,,,,
BkCV_W-AZ,2018,Invite to Workshop Track,False,Regret Minimization for Partially Observable Deep Reinforcement Learning,"[""Peter H. Jin"", ""Sergey Levine"", ""Kurt Keutzer""]","[""deep reinforcement learning""]","Advantage-based regret minimization is a new deep reinforcement learning algorithm that is particularly effective on partially observable tasks, such as 1st person navigation in Doom and Minecraft.",,,,
BkDB51WR-,2018,Reject,False,Learning temporal evolution of probability distribution with Recurrent Neural Network,"[""Kyongmin Yeo"", ""Igor Melnyk"", ""Nam Nguyen"", ""Eun Kyung Lee""]","[""predictive distribution estimation"", ""probabilistic RNN"", ""uncertainty in time series prediction""]",Proposed RNN-based algorithm to estimate predictive distribution in one- and multi-step forecasts in time series prediction problems,,,,
BkE8NjCqYm,2019,Reject,False,(Unconstrained) Beam Search is Sensitive to Large Search Discrepancies,"[""Eldan Cohen"", ""J. Christopher Beck""]","[""beam search"", ""sequence models"", ""search"", ""sequence to sequence""]",Analysis of the performance degradation in beam search and how constraining the the search can help avoiding it,,,,
BkG5SjR5YQ,2019,Accept (Poster),False,Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator,"[""Makoto Yamada"", ""Denny Wu"", ""Yao-Hung Hubert Tsai"", ""Hirofumi Ohta"", ""Ruslan Salakhutdinov"", ""Ichiro Takeuchi"", ""Kenji Fukumizu""]","[""Maximum Mean Discrepancy"", ""Selective Inference"", ""Feature Selection"", ""GAN""]",,,,,
BkG8sjR5Km,2019,Accept (Poster),False,Emergent Coordination Through Competition,"[""Siqi Liu"", ""Guy Lever"", ""Josh Merel"", ""Saran Tunyasuvunakool"", ""Nicolas Heess"", ""Thore Graepel""]","[""Multi-agent learning"", ""Reinforcement Learning""]","We introduce a new MuJoCo soccer environment for continuous multi-agent reinforcement learning research, and show that population-based training of independent reinforcement learners can learn cooperative behaviors",,,,
BkGakb9lx,2017,Invite to Workshop Track,False,RenderGAN: Generating Realistic Labeled Data,"[""Leon Sixt"", ""Benjamin Wild"", ""Tim Landgraf""]","[""Unsupervised Learning"", ""Computer vision"", ""Deep learning"", ""Applications""]","We embed a 3D model in the GAN framework to generate realistic, labeled data.",,,,
BkGiPoC5FX,2019,Reject,False,Efficient Convolutional Neural Network Training with Direct Feedback Alignment,"[""Donghyeon Han"", ""Hoi-jun Yoo""]","[""Direct Feedback Alignment"", ""Convolutional Neural Network"", ""DNN Training""]",,1901.01986,cs.LG,2019-01-06 04:36:38+00:00,2019-01-06 04:36:38+00:00
BkIV7EOXkSs,2022,Reject,False,Implicit Regularization of Bregman Proximal Point Algorithm and Mirror Descent on Separable Data,"['Yan Li', 'Caleb Ju', 'Ethan Fang', 'Tuo Zhao']",[],,,,,
BkIkkseAZ,2018,Reject,False,Theoretical properties of the global optimizer of two-layer Neural Network,"[""Digvijay Boob"", ""Guanghui Lan""]","[""Non-convex optimization"", ""Two-layer Neural Network"", ""global optimality"", ""first-order optimality""]",This paper talks about theoretical properties of first-order optimal point of two layer neural network in over-parametrized case,,,,
BkIqod5ll,2017,Reject,False,Convolutional Neural Networks Generalization Utilizing the Data Graph Structure,"[""Yotam Hechtlinger"", ""Purvasha Chakravarti"", ""Jining Qin""]","[""Supervised Learning"", ""Deep learning""]",A generalization of CNNs to standard regression and classification problems by using random walk on the data graph structure.,,,,
BkJ3ibb0-,2018,Accept (Poster),False,Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models,"[""Pouya Samangouei"", ""Maya Kabkab"", ""Rama Chellappa""]",[],Defense-GAN uses a Generative Adversarial Network to defend against white-box and black-box attacks in classification models.,,,,
BkJsCIcgl,2017,Reject,False,The Predictron: End-To-End Learning and Planning,"[""David Silver"", ""Hado van Hasselt"", ""Matteo Hessel"", ""Tom Schaul"", ""Arthur Guez"", ""Tim Harley"", ""Gabriel Dulac-Arnold"", ""David Reichert"", ""Neil Rabinowitz"", ""Andre Barreto"", ""Thomas Degris""]","[""Deep learning"", ""Reinforcement Learning"", ""Supervised Learning"", ""Semi-Supervised Learning""]",,,,,
BkLhaGZRW,2018,Accept (Poster),False,Improving GAN Training via Binarized Representation Entropy (BRE) Regularization,"[""Yanshuai Cao"", ""Gavin Weiguang Ding"", ""Kry Yik-Chau Lui"", ""Ruitong Huang""]",[],,,,,
BkLhzHtlg,2017,Accept (Poster),False,Learning Recurrent Representations for Hierarchical Behavior Modeling,"[""Eyrun Eyjolfsdottir"", ""Kristin Branson"", ""Yisong Yue"", ""Pietro Perona""]","[""Unsupervised Learning"", ""Semi-Supervised Learning"", ""Reinforcement Learning"", ""Applications""]",,,,,
BkM27IxR-,2018,Reject,False,Learning to Optimize Neural Nets,"[""Ke Li"", ""Jitendra Malik""]","[""Learning to learn"", ""meta-learning"", ""reinforcement learning"", ""optimization""]",We learn an optimization algorithm that generalizes to unseen tasks,,,,
BkM3ibZRW,2018,Invite to Workshop Track,False,Adversarially Regularized Autoencoders,"[""Junbo (Jake) Zhao"", ""Yoon Kim"", ""Kelly Zhang"", ""Alexander M. Rush"", ""Yann LeCun""]","[""representation learning"", ""natural language generation"", ""discrete structure modeling"", ""adversarial training"", ""unaligned text style-transfer""]","Adversarially Regularized Autoencoders learn smooth representations of discrete structures allowing for interesting results in text generation, such as unaligned style transfer, semi-supervised learning, and latent space interpolation and arithmetic.",,,,
BkMWx309FX,2019,Reject,False,Reinforcement Learning with Perturbed Rewards,"[""Jingkang Wang"", ""Yang Liu"", ""Bo Li""]","[""robust reinforcement learning"", ""noisy reward"", ""sample complexity""]",A new approach for learning with noisy rewards in reinforcement learning,,,,
BkMXkhA5Fm,2019,Reject,False,Learning State Representations in Complex Systems with Multimodal Data,"[""Pavel Solovev"", ""Vladimir Aliev"", ""Pavel Ostyakov"", ""Gleb Sterkin"", ""Elizaveta Logacheva"", ""Stepan Troeshestov"", ""Roman Suvorov"", ""Anton Mashikhin"", ""Oleg Khomenko"", ""Sergey I. Nikolenko""]","[""deep learning"", ""representation learning"", ""state representation"", ""disentangled representation"", ""dataset"", ""autonomous system"", ""temporal multimodal data""]","Multimodal synthetic dataset, collected from X-plane flight simulator, used for learning state representation and unified evaluation framework for representation learning",,,,
BkMiWhR5K7,2019,Accept (Poster),False,Prior Convictions: Black-box Adversarial Attacks with Bandits and Priors,"[""Andrew Ilyas"", ""Logan Engstrom"", ""Aleksander Madry""]","[""adversarial examples"", ""gradient estimation"", ""black-box attacks"", ""model-based optimization"", ""bandit optimization""]","We present a unifying view on black-box adversarial attacks as a gradient estimation problem, and then present a framework (based on bandits optimization) to integrate priors into gradient estimation, leading to significantly increased performance.",,,,
BkMn9jAcYQ,2019,Reject,False,Countering Language Drift via Grounding,"[""Jason Lee"", ""Kyunghyun Cho"", ""Douwe Kiela""]","[""grounding"", ""policy gradient"", ""language drift"", ""reinforcement learning""]",Grounding helps avoid language drift during fine-tuning natural language agents with policy gradients.,,,,
BkMq0oRqFQ,2019,Reject,False,Normalization Gradients are Least-squares Residuals,"[""Yi Liu""]","[""Deep Learning"", ""Normalization"", ""Least squares"", ""Gradient regression""]","Gaussian normalization performs a least-squares fit during back-propagation, which zero-centers and decorrelates partial derivatives from normalized activations.",,,,
BkN5UoAqF7,2019,Accept (Poster),False,Sample Efficient Imitation Learning for Continuous Control,"[""Fumihiro Sasaki"", ""Tetsuya Yohira"", ""Atsuo Kawaguchi""]","[""Imitation Learning"", ""Continuous Control"", ""Reinforcement Learning"", ""Inverse Reinforcement Learning"", ""Conditional Generative Adversarial Network""]","In this paper, we proposed a model-free, off-policy IL algorithm for continuous control. Experimental results showed that our algorithm achieves competitive results with GAIL while significantly reducing the environment interactions.",,,,
BkNUFjR5KQ,2019,Reject,False,Learning Internal Dense But External Sparse Structures of Deep Neural Network,"[""Yiqun Duan""]","[""Convolutional Neural Network"", ""Hierarchical Neural Architecture"", ""Structural Sparsity"", ""Evolving Algorithm""]","In this paper, we explore an internal dense yet external sparse network structure of deep neural networks and analyze its key properties.",,,,
BkN_r2lR-,2018,Accept (Poster),False,Identifying Analogies Across Domains,"[""Yedid Hoshen"", ""Lior Wolf""]","[""unsupervised mapping"", ""cross domain mapping""]",Finding correspondences between domains by performing matching/mapping iterations,,,,
BkPrDFgR-,2018,Reject,False,Piecewise Linear Neural Networks verification: A comparative study,"[""Rudy Bunel"", ""Ilker Turkaslan"", ""Philip H.S. Torr"", ""Pushmeet Kohli"", ""M. Pawan Kumar""]","[""Verification"", ""SMT solver"", ""Mixed Integer Programming"", ""Neural Networks""]",,,,,
BkQCGzZ0-,2018,Reject,False,Discrete Autoencoders for Sequence Models,"[""Lukasz Kaiser"", ""Samy Bengio""]","[""autoencoders"", ""sequence models"", ""discrete representations""]",Autoencoders for text with a new method for using discrete latent space.,,,,
BkQqq0gRb,2018,Accept (Poster),False,Variational Continual Learning,"[""Cuong V. Nguyen"", ""Yingzhen Li"", ""Thang D. Bui"", ""Richard E. Turner""]","[""continual learning"", ""online variational inference""]",This paper develops a principled method for continual learning in deep models.,,,,
BkS3fnl0W,2018,Reject,False,Semi-supervised Outlier Detection using Generative And Adversary Framework,"[""Jindong Gu"", ""Matthias Schubert"", ""Volker Tresp""]","[""Semi-supervised Learning"", ""Generative And Adversary Framework"", ""One-class classification"", ""Outlier detection""]",,,,,
BkSDMA36Z,2018,Accept (Poster),False,A New Method of Region Embedding for Text Classification,"[""chao qiao"", ""bo huang"", ""guocheng niu"", ""daren li"", ""daxiang dong"", ""wei he"", ""dianhai yu"", ""hua wu""]","[""region embedding"", ""local context unit"", ""text classification""]",,,,,
BkSmc8qll,2017,Reject,False,Dynamic Neural Turing Machine with Continuous and Discrete Addressing Schemes,"[""Caglar Gulcehre"", ""Sarath Chandar"", ""Kyunghyun Cho"", ""Yoshua Bengio""]","[""Deep learning"", ""Natural language processing"", ""Reinforcement Learning""]","We propose a new type of Neural Turing Machine, which is simpler than the original model and achieves better results than the baselines on non-trivial tasks. ",,,,
BkSqjHqxg,2017,Reject,False,Skip-graph: Learning graph embeddings with an encoder-decoder model,"[""John Boaz Lee"", ""Xiangnan Kong""]","[""Unsupervised Learning"", ""Deep learning""]",An unsupervised method for generating graph feature representations based on the encoder-decoder model.,,,,
BkUDW_lCb,2018,Reject,False,Pointing Out SQL Queries From Text,"[""Chenglong Wang"", ""Marc Brockschmidt"", ""Rishabh Singh""]","[""Program Synthesis"", ""Semantic Parsing"", ""WikiTable"", ""SQL"", ""Pointer Network""]",We present a type-based pointer network model together with a value-based loss method to effectively train a neural model to translate natural language to SQL.,,,,
BkUDvt5gg,2017,Reject,False,Wav2Letter: an End-to-End ConvNet-based Speech Recognition System,"[""Ronan Collobert"", ""Christian Puhrsch"", ""Gabriel Synnaeve""]","[""Deep learning"", ""Speech"", ""Structured prediction""]",We propose convnet models and new sequence criterions for training end-to-end letter-based speech systems.,,,,
BkUHlMZ0b,2018,Accept (Poster),False,Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach,"[""Tsui-Wei Weng*"", ""Huan Zhang*"", ""Pin-Yu Chen"", ""Jinfeng Yi"", ""Dong Su"", ""Yupeng Gao"", ""Cho-Jui Hsieh"", ""Luca Daniel""]","[""robustness"", ""adversarial machine learning"", ""neural network"", ""extreme value theory"", ""adversarial example"", ""adversarial perturbation""]","We propose the first attack-independent robustness metric, a.k.a CLEVER, that can be applied to any neural network classifier.",,,,
BkUp6GZRW,2018,Accept (Poster),False,Boosting the Actor with Dual Critic,"[""Bo Dai"", ""Albert Shaw"", ""Niao He"", ""Lihong Li"", ""Le Song""]","[""reinforcement learning"", ""actor-critic algorithm"", ""Lagrangian duality""]","We propose Dual Actor-Critic algorithm, which is derived in a principled way from the Lagrangian dual form of the Bellman optimality equation. The algorithm achieves the state-of-the-art performances across several benchmarks.",1712.10282,cs.LG,2017-12-29 17:17:58+00:00,2017-12-29 17:17:58+00:00
BkV4VS9ll,2017,Reject,False,The Incredible Shrinking Neural Network: New Perspectives on Learning Representations Through The Lens of Pruning,"[""Nikolas Wolfe"", ""Aditya Sharma"", ""Lukas Drude"", ""Bhiksha Raj""]","[""Theory"", ""Deep learning""]",Pruning algorithms reveal fundamental insights into neural network learning representations,,,,
BkVVOi0cFX,2019,Reject,False,Denoise while Aggregating: Collaborative Learning in Open-Domain Question Answering,"[""Haozhe Ji"", ""Yankai Lin"", ""Zhiyuan Liu"", ""Maosong Sun""]","[""natural language processing"", ""open-domain question answering"", ""semi-supervised learning""]",We propose denoising strategies to leverage information from supervised RC datasets to handle the noise issue in the open-domain QA task.,,,,
BkVf1AeAZ,2018,Reject,False,Label Embedding Network: Learning Label Representation for Soft Training of Deep Networks,"[""Xu Sun"", ""Bingzhen Wei"", ""Xuancheng Ren"", ""Shuming Ma""]","[""label embedding"", ""deep learning"", ""label representation"", ""computer vision"", ""natural language processing""]",Learning Label Representation for Deep Networks,,,,
BkVsEMYel,2017,Accept (Poster),False,Inductive Bias of Deep Convolutional Networks through Pooling Geometry,"[""Nadav Cohen"", ""Amnon Shashua""]","[""Theory"", ""Deep learning""]","We study the ability of convolutional networks to model correlations among regions of their input, showing that this is controlled by shapes of pooling windows.",,,,
BkVsWbbAW,2018,Reject,False,Deep Generative Dual Memory Network for Continual Learning,"[""Nitin Kamra"", ""Umang Gupta"", ""Yan Liu""]","[""Continual Learning"", ""Catastrophic Forgetting"", ""Sequential Multitask Learning"", ""Deep Generative Models"", ""Dual Memory Networks"", ""Deep Learning""]","A dual memory architecture inspired from human brain to learn sequentially incoming tasks, while averting catastrophic forgetting.",,,,
BkXMikqxx,2017,Reject,False,Cortical-Inspired Open-Bigram Representation for Handwritten Word Recognition,"[""Th\u00e9odore Bluche"", ""Christopher Kermorvant"", ""Claude Touzet"", ""Herv\u00e9 Glotin""]",[],"We propose an handwritten word recognition method based on an open-bigram representation of words, inspired from the research in cognitive psychology",,,,
BkXmYfbAZ,2018,Accept (Poster),False,Beyond Shared Hierarchies: Deep Multitask Learning through Soft Layer Ordering,"[""Elliot Meyerson"", ""Risto Miikkulainen""]","[""multitask learning"", ""deep learning"", ""modularity""]",Relaxing the constraint of shared hierarchies enables more effective deep multitask learning.,,,,
Bk_fs6gA-,2018,Reject,False,Long Term Memory Network for Combinatorial Optimization Problems,"[""Hazem A. A. Nomer"", ""Abdallah Aboutahoun"", ""Ashraf Elsayed""]","[""Memory Networks"", ""Combinatorial Optimization"", ""Binary LP""]",We propose a memory network model to solve Binary LP instances where the memory information is perseved for long-term use. ,,,,
Bk_zTU5eg,2017,Reject,False,Inefficiency of stochastic gradient descent with larger mini-batches (and more learners),"[""Onkar Bhardwaj"", ""Guojing Cong""]","[""Deep learning"", ""Optimization""]",We theoretically justify that increasing mini-batch size or increasing the number of learners can lead to slower SGD/ASGD convergence,,,,
Bkab5dqxe,2017,Accept (Poster),False,A Compositional Object-Based Approach to Learning Physical Dynamics,"[""Michael Chang"", ""Tomer Ullman"", ""Antonio Torralba"", ""Joshua Tenenbaum""]","[""Deep learning"", ""Unsupervised Learning""]",We propose a factorization of a physical scene into composable object-based representations and also a model architecture whose compositional structure factorizes object dynamics into pairwise interactions.,,,,
BkabRiQpb,2018,Accept (Poster),False,Consequentialist conditional cooperation in social dilemmas with imperfect information,"[""Alexander Peysakhovich"", ""Adam Lerer""]","[""deep reinforcement learning"", ""cooperation"", ""social dilemma"", ""multi-agent systems""]",We show how to use deep RL to construct agents that can solve social dilemmas beyond matrix games.,,,,
BkbY4psgg,2017,Accept (Oral),False,Making Neural Programming Architectures Generalize via Recursion,"[""Jonathon Cai"", ""Richard Shin"", ""Dawn Song""]","[""Deep learning""]",,,,,
Bkbc-Vqeg,2017,Reject,False,Learning Word-Like Units from Joint Audio-Visual Analylsis,"[""David Harwath"", ""James R. Glass""]","[""Speech"", ""Computer vision"", ""Deep learning"", ""Multi-modal learning"", ""Unsupervised Learning"", ""Semi-Supervised Learning""]",,,,,
BkdpaH9ll,2017,Reject,False,Boosting Image Captioning with Attributes,"[""Ting Yao"", ""Yingwei Pan"", ""Yehao Li"", ""Zhaofan Qiu"", ""Tao Mei""]","[""Computer vision"", ""Applications""]",Boosting Image Captioning with Attributes,,,,
Bke-6pVKvB,2020,Reject,True,Poisoning Attacks with Generative Adversarial Nets,"[""Luis Mu\u00f1oz-Gonz\u00e1lez"", ""Bjarne Pfitzner"", ""Matteo Russo"", ""Javier Carnerero-Cano"", ""Emil C. Lupu""]","[""data poisoning"", ""adversarial machine learning"", ""generative adversarial nets""]","In this paper we propose a novel generative model to craft systematic poisoning attacks with detectability constraints against machine learning classifiers, including deep networks. ",1906.07773,cs.LG,2019-06-18 19:14:09+00:00,2019-09-25 16:23:27+00:00
Bke02gHYwB,2020,Reject,False,Learn Interpretable Word Embeddings Efficiently with von Mises-Fisher Distribution,"[""Minghong Yao"", ""Liansheng Zhuang"", ""Houqiang Li"", ""Jian Yang"", ""Shafei Wang""]","[""word embedding"", ""natural language processing""]",Learn Interpretable Word Embeddings Efficiently with von Mises-Fisher Distribution,,,,
Bke0rjR5F7,2019,Reject,False,Stochastic Learning of Additive Second-Order Penalties with  Applications to Fairness,"[""Heinrich Jiang"", ""Yifan Wu"", ""Ofir Nachum""]","[""fairness""]",We propose a method to stochastically optimize second-order penalties and show how this may apply to training fairness-aware classifiers.,,,,
Bke13pVKPS,2020,Reject,True,"Improved Training Speed, Accuracy, and Data Utilization via Loss Function Optimization","[""Santiago Gonzalez"", ""Risto Miikkulainen""]","[""metalearning"", ""evolutionary computation"", ""loss functions"", ""optimization"", ""genetic programming""]","Using evolutionary computation, a system for loss function metalearning was built (GLO) that discovered a new loss function for classification that can train more accurate models in less time.",1905.11528,cs.LG,2019-05-27 22:24:21+00:00,2020-04-27 16:31:53+00:00
Bke4KsA5FX,2019,Accept (Poster),False,Generative Code Modeling with Graphs,"[""Marc Brockschmidt"", ""Miltiadis Allamanis"", ""Alexander L. Gaunt"", ""Oleksandr Polozov""]","[""Generative Model"", ""Source Code"", ""Graph Learning""]",Representing programs as graphs including semantics helps when generating programs,,,,
Bke61krFvS,2020,Accept (Poster),False,Learning representations for binary-classification without backpropagation,"[""Mathias Lechner""]","[""feedback alignment"", ""alternatives to backpropagation"", ""biologically motivated learning algorithms""]",First feedback alignment algorithm with provable learning guarantees for networks with single output neuron,,,,
Bke6vTVYwH,2020,Reject,True,Graph convolutional networks for learning with few clean and many noisy labels,"[""Ahmet Iscen"", ""Giorgos Tolias"", ""Yannis Avrithis"", ""Ondrej Chum"", ""Cordelia Schmid""]",[],,1910.00324,cs.CV,2019-10-01 11:56:09+00:00,2020-08-24 21:33:51+00:00
Bke7MANKvS,2020,Reject,False,A Kolmogorov Complexity Approach to Generalization in Deep Learning,"[""Hazar Yueksel"", ""Kush R. Varshney"", ""Brian Kingsbury""]","[""Kolmogorov complexity"", ""information distance"", ""generalization""]","We present a theoretical and experimental framework for defining, understanding, and achieving generalization, and as a result robustness, in deep learning by drawing on algorithmic information theory and coding theory.",,,,
Bke8764twr,2020,Reject,False,Bias-Resilient Neural Network,"[""Ehsan Adeli"", ""Qingyu Zhao"", ""Adolf Pfefferbaum"", ""Edith V. Sullivan"", ""L. Fei-Fei"", ""Juan Carlos Niebles"", ""Kilian M. Pohl""]","[""Invariant Feature Learning"", ""Vanished Correlation"", ""Generative Adversarial Networks"", ""Gender Shades"", ""Fairness in Machine Learning""]",We propose a method based on the adversarial training strategy to learn discriminative features unbiased and invariant to the confounder(s) by incorporating a loss function that encourages a vanished correlation between the bias and learned features.,,,,
Bke89JBtvB,2020,Accept (Poster),True,Batch-shaping for learning conditional channel gated networks,"[""Babak Ehteshami Bejnordi"", ""Tijmen Blankevoort"", ""Max Welling""]","[""Conditional computation"", ""channel gated networks"", ""gating"", ""Batch-shaping"", ""distribution matching"", ""image classification"", ""semantic segmentation""]",A method that trains large capacity neural networks with significantly improved accuracy and lower dynamic computational cost,1907.06627,cs.LG,2019-07-15 17:58:04+00:00,2020-04-03 08:42:24+00:00
Bke8UR4FPB,2020,Accept (Poster),True,Oblique Decision Trees from Derivatives of ReLU Networks,"[""Guang-He Lee"", ""Tommi S. Jaakkola""]","[""oblique decision trees"", ""ReLU networks""]",A novel neural architecture which implicitly realizes (oblique) decision trees.,1909.13488,cs.LG,2019-09-30 07:23:16+00:00,2020-05-03 18:55:49+00:00
Bke96sC5tm,2019,Reject,False,SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning,"[""Marvin Zhang*"", ""Sharad Vikram*"", ""Laura Smith"", ""Pieter Abbeel"", ""Matthew Johnson"", ""Sergey Levine""]","[""model-based reinforcement learning"", ""structured representation learning"", ""robotics""]",,,,,
Bke9u1HFwB,2020,Reject,False,Do recent advancements in model-based deep reinforcement learning really improve data efficiency?,"[""Kacper Piotr Kielak""]","[""deep learning"", ""reinforcement learning"", ""data efficiency"", ""DQN"", ""Rainbow"", ""SimPLe""]",Recent advancements in data-efficient model-based reinforcement learning are not any more data efficient than existing model-free approaches.,,,,
BkeC_J-R-,2018,Reject,False,Combination of Supervised and Reinforcement Learning For Vision-Based Autonomous Control,"[""Dmitry Kangin"", ""Nicolas Pugeault""]","[""Reinforcement learning"", ""deep learning"", ""autonomous control""]","The new combination of reinforcement and supervised learning, dramatically decreasing the number of required samples for training on video",,,,
BkeDEoCctQ,2019,Reject,True,Deep Curiosity Search: Intra-Life Exploration Can Improve Performance on Challenging Deep Reinforcement Learning Problems,"[""Christopher Stanton"", ""Jeff Clune""]",[],,1806.00553,cs.AI,2018-06-01 22:09:51+00:00,2018-11-24 00:29:31+00:00
BkeDGJBKvB,2020,Reject,True,Multitask Soft Option Learning,"[""Maximilian Igl"", ""Andrew Gambardella"", ""Jinke He"", ""Nantas Nardelli"", ""N. Siddharth"", ""Wendelin B\u00f6hmer"", ""Shimon Whiteson""]","[""Hierarchical Reinforcement Learning"", ""Reinforcement Learning"", ""Control as Inference"", ""Options"", ""Multitask Learning""]","In Hierarchical RL, we introduce the notion of a 'soft', i.e. adaptable, option and show that this helps learning in multitask settings.",1904.01033,cs.LG,2019-04-01 18:01:34+00:00,2020-06-21 10:36:45+00:00
BkeGPJrtwB,2020,Reject,False,Fairness with Wasserstein Adversarial Networks,"[""serrurier Mathieu"", ""Loubes Jean-Michel"", ""Edouard Pauwels""]",[],,,,,
BkeHt34Fwr,2020,Reject,False,Regional based query in graph active learning,"[""Abel Roy"", ""Louzoun Yoram""]","[""Active Learning"", ""Graph Convolution Networks"", ""Graph"", ""Graph Topology""]",Graph-oriented approaches to Active Learning for node classification,,,,
BkeJm6VtPH,2020,Reject,False,Continual Learning via Neural Pruning,"[""Siavash Golkar"", ""Micheal Kagan"", ""Kyunghyun Cho""]","[""continual learning"", ""lifelong learning"", ""catastrophic forgetting"", ""sparsification""]",We introduce a continual learning algorithm based on sparsification using activation based neural pruning. We show that we beat or match prior methods of much higher complexity.,,,,
BkeK-nRcFX,2019,Reject,False,The Nonlinearity Coefficient - Predicting Generalization in Deep Neural Networks,"[""George Philipp"", ""Jaime G. Carbonell""]","[""deep learning"", ""neural networks"", ""nonlinearity"", ""activation functions"", ""exploding gradients"", ""vanishing gradients"", ""neural architecture search""]","We introduce the NLC, a metric that is cheap to compute in the networks randomly initialized state and is highly predictive of generalization, at least in fully-connected networks.",,,,
BkeMXR4KvS,2020,Reject,False,DASGrad: Double Adaptive Stochastic Gradient,"[""Kin Gutierrez"", ""Cristian Challu"", ""Jin Li"", ""Artur Dubrawski""]","[""stochastic convex optimization"", ""adaptivity"", ""online learning"", ""transfer learning""]",Stochastic gradient descent with adaptive moments and adaptive probabilities,,,,
BkeOp6EKDH,2020,Reject,True,TriMap: Large-scale Dimensionality Reduction Using Triplets,"[""Ehsan Amid"", ""Manfred K. Warmuth""]","[""Dimensionality Reduction"", ""Triplets"", ""Data Visualization"", ""t-SNE"", ""LargeVis"", ""UMAP""]","A significantly faster dimensionality reduction method based on triplets that preserves the global structure of the data better than t-SNE, LargeVis, and UMAP.",1910.00204,cs.LG,2019-10-01 05:28:57+00:00,2019-10-01 05:28:57+00:00
BkePHaVKwS,2020,Reject,True,Learning Surrogate Losses,"[""Josif Grabocka"", ""Randolf Scholz"", ""Lars Schmidt-Thieme""]","[""Surrogate losses"", ""Non-differentiable losses""]",Optimizing Surrogate Loss Functions,1905.10108,cs.LG,2019-05-24 09:33:04+00:00,2019-05-24 09:33:04+00:00
BkePneStwH,2020,Reject,False,XD: Cross-lingual Knowledge Distillation for Polyglot Sentence Embeddings,"[""Maksym Del"", ""Mark Fishel""]","[""cross-lingual transfer"", ""sentence embeddings"", ""polyglot language models"", ""knowledge distillation"", ""natural language inference"", ""embedding alignment"", ""embedding mapping""]",Knowledge distillation for cross-lingual language model alignment with state-of-the-art results on XNLI,,,,
BkeStsCcKQ,2019,Accept (Poster),False,Critical Learning Periods in Deep Networks,"[""Alessandro Achille"", ""Matteo Rovere"", ""Stefano Soatto""]","[""Critical Period"", ""Deep Learning"", ""Information Theory"", ""Artificial Neuroscience"", ""Information Plasticity""]","Sensory deficits in early training phases can lead to irreversible performance loss in both artificial and neuronal networks, suggesting information phenomena as the common cause, and point to the importance of the initial transient and forgetting.",,,,
BkeU5j0ctQ,2019,Accept (Poster),False,CEM-RL: Combining evolutionary and gradient-based methods for policy search,"[""Pourchot"", ""Sigaud""]","[""evolution strategy"", ""deep reinforcement learning""]",We propose a new combination of evolution strategy and deep reinforcement learning which takes the best of both worlds,,,,
BkeUasA5YQ,2019,Reject,False,LIT: Block-wise Intermediate Representation Training for Model Compression,"[""Animesh Koratana*"", ""Daniel Kang*"", ""Peter Bailis"", ""Matei Zaharia""]",[],,,,,
BkeWw6VFwr,2020,Accept (Poster),False,Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing,"[""Jinyuan Jia"", ""Xiaoyu Cao"", ""Binghui Wang"", ""Neil Zhenqiang Gong""]","[""Certified Adversarial Robustness"", ""Randomized Smoothing"", ""Adversarial Examples""]",We study the certified robustness for top-k predictions via randomized smoothing under Gaussian noise and derive a tight robustness bound in L_2 norm.,1912.09899,cs.LG,2019-12-20 15:54:51+00:00,2019-12-20 15:54:51+00:00
BkeYSlrYwH,2020,Reject,False,Collaborative Inter-agent Knowledge Distillation for Reinforcement Learning,"[""Zhang-Wei Hong"", ""Prabhat Nagarajan"", ""Guilherme Maeda""]","[""Reinforcement learning"", ""distillation""]",,,,,
BkeYdyHYPS,2020,Reject,False,Evo-NAS: Evolutionary-Neural Hybrid Agent for Architecture Search,"[""Krzysztof Maziarz"", ""Mingxing Tan"", ""Andrey Khorlin"", ""Kuang-Yu Samuel Chang"", ""Andrea Gesmundo""]",[],,,,,
Bke_DertPB,2020,Accept (Poster),True,Adversarial Lipschitz Regularization,"[""D\u00e1vid Terj\u00e9k""]","[""generative adversarial networks"", ""wasserstein generative adversarial networks"", ""lipschitz regularization"", ""adversarial training""]",alternative to gradient penalty,1907.05681,cs.LG,2019-07-12 11:41:18+00:00,2020-01-03 09:11:31+00:00
BkeaEyBYDB,2020,Reject,True,Improving Federated Learning Personalization via Model Agnostic Meta Learning,"[""Yihan Jiang"", ""Jakub Kone\u010dn\u00fd"", ""Keith Rush"", ""Sreeram Kannan""]","[""Federated Learning"", ""Model Agnostic Meta Learning"", ""Personalization""]","Federated Averaging already is a Meta Learning algorithm, while datacenter-trained methods are significantly harder to personalize.",1909.12488,cs.LG,2019-09-27 04:26:37+00:00,2019-09-27 04:26:37+00:00
BkeaxAEKvB,2020,Reject,False,New Loss Functions for Fast Maximum Inner Product Search,"[""Ruiqi Guo"", ""Quan Geng"", ""David Simcha"", ""Felix Chern"", ""Phil Sun"", ""Sanjiv Kumar""]",[],,,,,
Bkeb7lHtvH,2020,Accept (Spotlight),True,At Stability's Edge: How to Adjust Hyperparameters to Preserve Minima Selection in Asynchronous Training of Neural Networks?,"[""Niv Giladi"", ""Mor Shpigel Nacson"", ""Elad Hoffer"", ""Daniel Soudry""]","[""implicit bias"", ""stability"", ""neural networks"", ""generalization gap"", ""asynchronous SGD""]",How to prevent stale gradients (in asynchronous SGD) from changing minima stability and degrade steady state generalization?,1909.12340,cs.LG,2019-09-26 19:05:58+00:00,2020-02-13 13:06:02+00:00
BkedwoC5t7,2019,Reject,False,Formal Limitations on the Measurement of Mutual Information,"[""David McAllester"", ""Karl Stratos""]","[""mutual information"", ""predictive coding"", ""unsupervised learning"", ""predictive learning"", ""generalization bounds"", ""MINE"", ""DIM"", ""contrastive predictive coding""]",We give a theoretical analysis of the measurement and optimization of mutual information.,1811.04251,cs.IT,2018-11-10 13:12:27+00:00,2020-05-20 12:03:39+00:00
BkedznAqKQ,2019,Accept (Poster),False,LanczosNet: Multi-Scale Deep Graph Convolutional Networks,"[""Renjie Liao"", ""Zhizhen Zhao"", ""Raquel Urtasun"", ""Richard Zemel""]","[""Lanczos Network"", ""Graph Neural Networks"", ""Deep Graph Convolutional Networks"", ""Deep Learning on Graph Structured Data"", ""QM8 Quantum Chemistry Benchmark""]",,,,,
Bkeeca4Kvr,2020,Accept (Poster),False,FEW-SHOT LEARNING ON GRAPHS VIA SUPER-CLASSES BASED ON GRAPH SPECTRAL MEASURES,"[""Jatin Chauhan"", ""Deepak Nathani"", ""Manohar Kaul""]","[""Few shot graph classification"", ""graph spectral measures"", ""super-classes""]",,2002.12815,cs.LG,2020-02-27 17:11:14+00:00,2020-02-27 17:11:14+00:00
Bkel1krKPS,2020,Reject,False,Attention on Abstract Visual Reasoning,"[""Lukas Hahne"", ""Timo L\u00fcddecke"", ""Florentin W\u00f6rg\u00f6tter"", ""David Kappel""]","[""Transformer Networks"", ""Self-Attention"", ""Wild Relation Networks"", ""Procedurally Generated Matrices""]",Introducing Attention Relation Network (ARNe) that combines features from WReN and Transformer Networks.,1911.05990,cs.LG,2019-11-14 08:33:40+00:00,2019-11-14 08:33:40+00:00
Bkel6ertwS,2020,Reject,False,Learning DNA folding patterns with Recurrent Neural Networks ,"[""Michal Rozenwald"", ""Aleksandra Galitsyna"", ""Ekaterina Khrameeva"", ""Grigory Sapunov"", ""Mikhail S. Gelfand""]","[""Machine Learning"", ""Recurrent Neural Networks"", ""3D chromatin structure"", ""topologically associating domains"", ""computational biology.""]",We apply RNN to solve the biological problem of chromatin folding patterns prediction from epigenetic marks and demonstrate for the first time that utilization of memory of sequential states on DNA molecule is significant for the best performance.,,,,
BkeoaeHKDS,2020,Accept (Poster),False,Gradients as Features for Deep Representation Learning,"[""Fangzhou Mu"", ""Yingyu Liang"", ""Yin Li""]","[""representation learning"", ""gradient features"", ""deep learning""]","Given a pre-trained model, we explored the per-sample gradients of the model parameters relative to a task-specific loss, and constructed a linear model that combines gradients of model parameters and the activation of the model.",2004.05529,cs.LG,2020-04-12 02:57:28+00:00,2020-04-12 02:57:28+00:00
BkepbpNFwr,2020,Accept (Poster),True,Progressive Memory Banks for Incremental Domain Adaptation,"[""Nabiha Asghar"", ""Lili Mou"", ""Kira A. Selby"", ""Kevin D. Pantasdo"", ""Pascal Poupart"", ""Xin Jiang""]","[""natural language processing"", ""domain adaptation""]","We present a neural memory-based architecture for incremental domain adaptation, and provide theoretical and empirical results.",1811.00239,cs.CL,2018-11-01 05:22:01+00:00,2020-02-14 04:04:14+00:00
Bkepl7cee,2017,Reject,False,Parametric Exponential Linear Unit for Deep Convolutional Neural Networks,"[""Ludovic Trottier"", ""Philippe Gigu\u00e8re"", ""Brahim Chaib-draa""]",[],Learning a parameterization of the ELU activation function improves its performance.,,,,
BkeqATVYwr,2020,Reject,False,GRAPH NEIGHBORHOOD ATTENTIVE POOLING,"[""Zekarias Tilahun Kefato"", ""Sarunas Girdzijauskas""]","[""Network Representation Learning"", ""Attentive Pooling Networks"", ""Context-sensitive Embedding"", ""Mutual Attention"", ""Link Prediction"", ""Node Clustering""]",,,,,
BkeqO7x0-,2018,Accept (Poster),False,Unsupervised Cipher Cracking Using Discrete GANs,"[""Aidan N. Gomez"", ""Sicong Huang"", ""Ivan Zhang"", ""Bryan M. Li"", ""Muhammad Osama"", ""Lukasz Kaiser""]",[],,,,,
BkesGnCcFX,2019,Reject,False,Learning Goal-Conditioned Value Functions with one-step Path rewards rather than Goal-Rewards,"[""Vikas Dhiman"", ""Shurjo Banerjee"", ""Jeffrey M Siskind"", ""Jason J Corso""]","[""Floyd-Warshall"", ""Reinforcement learning"", ""goal conditioned value functions"", ""multi-goal""]",Do Goal-Conditioned Value Functions need Goal-Rewards to Learn?,,,,
BkesJ3R9YX,2019,Reject,False,Where and when to look? Spatial-temporal attention for action recognition in videos,"[""Lili Meng"", ""Bo Zhao"", ""Bo Chang"", ""Gao Huang"", ""Frederick Tung"", ""Leonid Sigal""]","[""visual attention"", ""video action recognition"", ""network interpretability""]",,,,,
Bkeuz20cYm,2019,Reject,False,Double Neural Counterfactual Regret Minimization,"[""Hui Li"", ""Kailiang Hu"", ""Zhibang Ge"", ""Tao Jiang"", ""Yuan Qi"", ""Le Song""]","[""Counterfactual Regret Minimization"", ""Imperfect Information game""]",We proposed a double neural CFR which can match the performance of tabular based CFR and opens up the possibility for a purely neural approach to directly solve large imperfect information game.,1812.10607,cs.AI,2018-12-27 03:31:33+00:00,2018-12-27 03:31:33+00:00
BkevoJSYPB,2020,Accept (Spotlight),False,Differentiation of Blackbox Combinatorial Solvers,"[""Marin Vlastelica Pogan\u010di\u0107"", ""Anselm Paulus"", ""Vit Musil"", ""Georg Martius"", ""Michal Rolinek""]","[""combinatorial algorithms"", ""deep learning"", ""representation learning"", ""optimization""]"," In this work, we present a method that implements an efficient backward pass through blackbox implementations of combinatorial solvers with linear objective functions.",,,,
BkewX2C9tX,2019,Reject,False,Analyzing Federated Learning through an Adversarial Lens,"[""Arjun Nitin Bhagoji"", ""Supriyo Chakraborty"", ""Seraphin Calo"", ""Prateek Mittal""]","[""federated learning"", ""model poisoning""]",Effective model poisoning attacks on federated learning able to cause high-confidence targeted misclassification of desired inputs,,,,
BkexaxBKPB,2020,Reject,False,Generative Adversarial Nets for Multiple Text Corpora,"[""Diego Klabjan"", ""Baiyang Wang""]","[""GAN"", ""NLP"", ""embeddings""]",Constructing robust embeddings by means of GANs from multiple corpora,,,,
BkeyOxrYwH,2020,Reject,True,Imagine That! Leveraging Emergent Affordances for Tool Synthesis in Reaching Tasks,"[""Yizhe Wu"", ""Sudhanshu Kasewa"", ""Oliver Groth"", ""Sasha Salter"", ""Li Sun"", ""Oiwi Parker Jones"", ""Ingmar Posner""]","[""Affordance Learning"", ""Imagination"", ""Generative Models"", ""Activation Maximisation""]",We demonstrate that a task-driven traversal of a structured latent space leads to object affordances emerging naturally as directions in this space accessible via optimisation.,1909.13561,cs.LG,2019-09-30 09:55:33+00:00,2020-10-07 04:05:19+00:00
Bkf1tjR9KQ,2019,Reject,False,DVOLVER: Efficient Pareto-Optimal Neural Network Architecture Search,"[""Guillaume Michel"", ""Mohammed Amine Alaoui"", ""Alice Lebois"", ""Amal Feriani"", ""Mehdi Felhi""]","[""architecture search"", ""Pareto optimality"", ""multi-objective"", ""optimization"", ""cnn"", ""deep learning""]",Multi-objective Neural architecture search as an efficient way to find fast and accurate architecture for mobile devices.,,,,
Bkf4XgrKvS,2020,Reject,False,Unsupervised Learning of Graph Hierarchical Abstractions with Differentiable Coarsening and Optimal Transport,"[""Tengfei Ma"", ""Jie Chen""]","[""Unsupervised learning"", ""hierarchical representation learning"", ""graph neural networks""]",,1912.11176,cs.LG,2019-12-24 02:40:32+00:00,2020-12-06 20:04:15+00:00
BkfEzz-0-,2018,Invite to Workshop Track,False,Neuron as an Agent,"[""Shohei Ohsawa"", ""Kei Akuzawa"", ""Tatsuya Matsushima"", ""Gustavo Bezerra"", ""Yusuke Iwasawa"", ""Hiroshi Kajino"", ""Seiya Takenaka"", ""Yutaka Matsuo""]","[""Multi-agent Reinforcement Learning"", ""Communication"", ""Reward Distribution"", ""Trusted Third Party"", ""Auction Theory""]",Neuron as an Agent (NaaA) enable us to train multi-agent communication without a trusted third party.,,,,
BkfPnoActQ,2019,Reject,False,Towards Consistent Performance on Atari using Expert Demonstrations,"[""Tobias Pohlen"", ""Bilal Piot"", ""Todd Hester"", ""Mohammad Gheshlaghi Azar"", ""Dan Horgan"", ""David Budden"", ""Gabriel Barth-Maron"", ""Hado van Hasselt"", ""John Quan"", ""Mel Ve\u010der\u00edk"", ""Matteo Hessel"", ""R\u00e9mi Munos"", ""Olivier Pietquin""]","[""Reinforcement Learning"", ""Atari"", ""RL"", ""Demonstrations""]",Ape-X DQfD = Distributed (many actors + one learner + prioritized replay) DQN with demonstrations optimizing the unclipped 0.999-discounted return on Atari.,,,,
BkfbpsAcF7,2019,Accept (Poster),False,Excessive Invariance Causes Adversarial Vulnerability,"[""Joern-Henrik Jacobsen"", ""Jens Behrmann"", ""Richard Zemel"", ""Matthias Bethge""]","[""Generalization"", ""Adversarial Examples"", ""Invariance"", ""Information Theory"", ""Invertible Networks""]","We show deep networks are not only too sensitive to task-irrelevant changes of their input, but also too invariant to a wide range of task-relevant changes, thus making vast regions in input space vulnerable to adversarial attacks.",,,,
BkfhZnC9t7,2019,Reject,False,Zero-shot Learning for Speech Recognition with Universal Phonetic Model,"[""Xinjian Li"", ""Siddharth Dalmia"", ""David R. Mortensen"", ""Florian Metze"", ""Alan W Black""]","[""zero-shot learning"", ""speech recognition"", ""acoustic modeling""]",We apply zero-shot learning for speech recognition to recognize unseen phonemes,,,,
BkfiXiUlg,2017,Reject,False,Learning Efficient Algorithms with Hierarchical Attentive Memory,"[""Marcin Andrychowicz"", ""Karol Kurach""]",[],fast attention in O(log n); learned sorting algorithm that generalizes,,,,
Bkfwyw5xg,2017,Reject,False,Investigating Different Context Types and Representations for Learning Word Embeddings,"[""Bofang Li"", ""Tao Liu"", ""Zhe Zhao"", ""Buzhou Tang"", ""Xiaoyong Du""]","[""Unsupervised Learning"", ""Natural language processing""]",This paper investigate different context types and representations for learning word embeddings.,,,,
BkfxKj09Km,2019,Reject,False,DiffraNet: Automatic Classification of Serial Crystallography Diffraction Patterns,"[""Artur Souza"", ""Leonardo B. Oliveira"", ""Sabine Hollatz"", ""Matt Feldman"", ""Kunle Olukotun"", ""James M. Holton"", ""Aina E. Cohen"", ""Luigi Nardi""]","[""Serial Crystallography"", ""Deep Learning"", ""Image Classification""]",We introduce a new synthetic dataset for serial crystallography that can be used to train image classification models and explore computer vision and deep learning approaches to classify them.,,,,
Bkg0u3Etwr,2020,Accept (Poster),False,Maxmin Q-learning: Controlling the Estimation Bias of Q-learning,"[""Qingfeng Lan"", ""Yangchen Pan"", ""Alona Fyshe"", ""Martha White""]","[""reinforcement learning"", ""bias and variance reduction""]",We propose a new variant of Q-learning algorithm called Maxmin Q-learning which provides a parameter-tuning mechanism to flexibly control bias.,2002.06487,cs.LG,2020-02-16 02:02:23+00:00,2021-08-07 18:51:37+00:00
Bkg2viA5FQ,2019,Accept (Poster),False,Hindsight policy gradients,"[""Paulo Rauber"", ""Avinash Ummadisingu"", ""Filipe Mutz"", ""J\u00fcrgen Schmidhuber""]","[""reinforcement learning"", ""policy gradients"", ""multi-goal reinforcement learning""]",We introduce the capacity to exploit information about the degree to which an arbitrary goal has been achieved while another goal was intended to policy gradient methods.,,,,
Bkg3g2R9FX,2019,Accept (Poster),False,Adaptive Gradient Methods with Dynamic Bound of Learning Rate,"[""Liangchen Luo"", ""Yuanhao Xiong"", ""Yan Liu"", ""Xu Sun""]","[""Optimization"", ""SGD"", ""Adam"", ""Generalization""]",Novel variants of optimization methods that combine the benefits of both adaptive and non-adaptive methods.,,,,
Bkg5LgrYwS,2020,Reject,False,"Imitation Learning of Robot Policies using Language, Vision and Motion","[""Simon Stepputtis"", ""Joseph Campbell"", ""Mariano Phielipp"", ""Chitta Baral"", ""Heni Ben Amor""]","[""robot learning"", ""imitation learning"", ""natural language processing""]","In this paper, we present an imitation learning approach that combines language, vision, and motion in order to synthesize natural language-conditioned control policies.",,,,
Bkg5aoAqKm,2019,Reject,False,Fast Binary Functional Search on Graph,"[""Shulong Tan"", ""Zhixin Zhou"", ""Zhaozhuo Xu"", ""Ping Li""]","[""Binary Functional Search"", ""Large-scale Search"", ""Approximate Nearest Neighbor Search""]",Efficient Search by Neural Network based searching measures.,,,,
Bkg6RiCqY7,2019,Accept (Poster),False,Decoupled Weight Decay Regularization,"[""Ilya Loshchilov"", ""Frank Hutter""]","[""optimization"", ""regularization"", ""weight decay"", ""Adam""]",,,,,
Bkg75aVKDH,2020,Reject,False,Training Provably Robust Models by Polyhedral Envelope Regularization,"[""Chen Liu"", ""Mathieu Salzmann"", ""Sabine S\u00fcsstrunk""]","[""deep learning"", ""adversarial attack"", ""robust certification""]",,1912.04792,cs.LG,2019-12-10 16:05:20+00:00,2021-09-20 12:12:03+00:00
Bkg8jjC9KQ,2019,Accept (Poster),False,Optimistic mirror descent in saddle-point problems: Going the extra (gradient) mile,"[""Panayotis Mertikopoulos"", ""Bruno Lecouat"", ""Houssam Zenati"", ""Chuan-Sheng Foo"", ""Vijay Chandrasekhar"", ""Georgios Piliouras""]","[""Mirror descent"", ""extra-gradient"", ""generative adversarial networks"", ""saddle-point problems""]",We show how the inclusion of an extra-gradient step in first-order GAN training methods can improve stability and lead to improved convergence results.,,,,
Bkg93jC5YX,2019,Reject,False,BLISS in Non-Isometric Embedding Spaces,"[""Barun Patra"", ""Joel Ruben Antony Moniz"", ""Sarthak Garg"", ""Matthew R Gormley"", ""Graham Neubig""]","[""bilingual lexicon induction"", ""semi-supervised methods"", ""embeddings""]","A novel method to test for isometry between word embedding spaces, and a semi-supervised method for learning better mappings between them",,,,
BkgBvsC9FQ,2019,Accept (Poster),False,DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder,"[""Xiaodong Gu"", ""Kyunghyun Cho"", ""Jung-Woo Ha"", ""Sunghun Kim""]","[""dialogue"", ""GAN"", ""VAE"", ""WAE"", ""chatbot""]",,,,,
BkgCv1HYvB,2020,Reject,True,Generating Multi-Sentence Abstractive Summaries of Interleaved Texts,"[""Sanjeev Kumar Karn"", ""Francine Chen"", ""Yan-Ying Chen"", ""Ulli Waltinger"", ""Hinrich Sch\u00fctze""]",[],,1906.01973,cs.CL,2019-06-05 12:28:00+00:00,2020-04-09 16:26:52+00:00
BkgF4kSFPB,2020,Reject,False,Hallucinative Topological Memory for Zero-Shot Visual Planning,"[""Kara Liu"", ""Thanard Kurutach"", ""Pieter Abbeel"", ""Aviv Tamar""]","[""Visual Planning"", ""Model-Based RL"", ""Representation Learning""]","We propose Hallucinative Topological Memory (HTM), a visual planning algorithm that can perform zero-shot long horizon planning in new environments. ",,,,
BkgFqiAqFX,2019,Reject,False,Recovering the Lowest Layer of Deep Networks with High Threshold Activations,"[""Surbhi Goel"", ""Rina Panigrahy""]","[""Deep Learning"", ""Parameter Recovery"", ""Non-convex optimization"", ""high threshold activation""]","We provably recover the lowest layer in a deep neural network assuming that the lowest layer uses a ""high threshold"" activation and the above network is a ""well-behaved"" polynomial.",,,,
BkgGJlBFPS,2020,Reject,False,Unsupervised Hierarchical Graph Representation Learning with Variational Bayes,"[""Shashanka Ubaru"", ""Jie Chen""]","[""Hierarchical Graph Representation"", ""Unsupervised Graph Learning"", ""Variational Bayes"", ""Graph classification""]",Bayespool: An unsupervised hierarchical graph representation learning method based on Variational Bayes.,,,,
BkgGmh09FQ,2019,Reject,False,Understanding Opportunities for Efficiency in Single-image Super Resolution Networks,"[""Royson Lee"", ""Nic Lane"", ""Marko Stankovic"", ""Sourav Bhattacharya""]","[""Super-Resolution"", ""Resource-Efficiency""]",We build an understanding of resource-efficient techniques on Super-Resolution,,,,
BkgHWkrtPB,2020,Reject,False,Where is the Information in a Deep Network?,"[""Alessandro Achille"", ""Stefano Soatto""]","[""Information"", ""Learning Dynamics"", ""PAC-Bayes"", ""Deep Learning""]",,,,,
BkgM7xHYwH,2020,Reject,False,Autoencoder-based Initialization for Recurrent Neural Networks with a Linear Memory,"[""Antonio Carta"", ""Alessandro Sperduti"", ""Davide Bacciu""]","[""recurrent neural networks"", ""autoencoders"", ""orthogonal RNNs""]",We show how to initialize recurrent architectures with the closed-form solution of a linear autoencoder for sequences. We show the advantages of this approach compared to orthogonal RNNs.,,,,
BkgMbCVFvr,2020,Reject,False,Pretraining boosts out-of-domain robustness for pose estimation,"[""Alexander Mathis"", ""Mert Y\u00fcksekg\u00f6n\u00fcl"", ""Byron Rogers"", ""Matthias Bethge"", ""Mackenzie W. Mathis""]","[""pose estimation"", ""robustness"", ""out-of-domain"", ""transfer learning""]",Transfer learning boosts out-of-domain robustness for pose estimation.,,,,
BkgNqkHFPr,2020,Reject,False,Enhanced Convolutional Neural Tangent Kernels,"[""Dingli Yu"", ""Ruosong Wang"", ""Zhiyuan Li"", ""Wei Hu"", ""Ruslan Salakhutdinov"", ""Sanjeev Arora"", ""Simon S. Du""]","[""neural tangent kernel"", ""data augmentation"", ""global average pooling"", ""kernel regression"", ""deep learning theory"", ""kernel design""]",New techniques to enhance the convolutional neural tangent kernel which can match the performance of AlexNet on CIFAR-10.,,,,
BkgOM1rKvr,2020,Reject,False,The Surprising Behavior Of Graph Neural Networks,"[""Vivek Kothari"", ""Catherine Tong"", ""Nicholas Lane""]","[""Graph Neural Networks"", ""Graph Toplogy"", ""Noise"", ""Attributed Networks""]",The paper presents a set of experiements which highlight the gap in our intuitive understanding of Graph Neural Networks.,,,,
BkgPajAcY7,2019,Accept (Poster),False,No Training Required: Exploring Random Encoders for Sentence Classification,"[""John Wieting"", ""Douwe Kiela""]","[""sentence embeddings""]",,,,,
BkgRe1SFDS,2020,Reject,False,Learning World Graph Decompositions To Accelerate Reinforcement Learning,"[""Wenling Shang"", ""Alex Trott"", ""Stephan Zheng"", ""Caiming Xiong"", ""Richard Socher""]","[""environment decomposition"", ""subgoal discovery"", ""generative modeling"", ""reinforcement learning"", ""unsupervised learning""]",We learn a task-agnostic world graph abstraction of the environment and show how using it for structured exploration can significantly accelerate downstream task-specific RL.,,,,
BkgStySKPB,2020,Reject,False,Contrastive Multiview Coding,"[""Yonglong Tian"", ""Dilip Krishnan"", ""Phillip Isola""]","[""Representation Learning"", ""Unsupervised Learning"", ""Self-supervsied Learning"", ""Multiview Learning""]",An unsupervised/self-supervised framework for learning representations from multiple views,,,,
BkgTwRNtPB,2020,Reject,False,Solving Packing Problems by Conditional Query Learning,"[""Dongda Li"", ""Changwei Ren"", ""Zhaoquan Gu"", ""Yuexuan Wang"", ""Francis Lau""]","[""Neural Combinatorial Optimization"", ""Reinforcement Learning"", ""Packing Problem""]",,,,,
BkgUB1SYPS,2020,Reject,False,Interpretable Network Structure for Modeling Contextual Dependency,"[""Xindian Ma"", ""Peng Zhang"", ""Xiaoliu Mao"", ""Yehua Zhang"", ""Nan Duan"", ""Yuexian Hou"", ""Ming Zhou.""]","[""Language Model"", ""Recurrent Neural Network"", ""Separation Rank""]",,,,,
BkgVx3A9Km,2019,Reject,True,A More Globally Accurate Dimensionality Reduction Method Using Triplets,"[""Ehsan Amid"", ""Manfred K. Warmuth""]","[""Dimensionality Reduction"", ""Visualization"", ""Triplets"", ""t-SNE"", ""LargeVis""]",A new dimensionality reduction method using triplets which is significantly faster than t-SNE and provides more accurate results globally,1803.00854,cs.LG,2018-03-01 06:35:02+00:00,2018-03-01 06:35:02+00:00
BkgWHnR5tm,2019,Accept (Poster),False,Neural Graph Evolution: Towards Efficient Automatic Robot Design,"[""Tingwu Wang"", ""Yuhao Zhou"", ""Sanja Fidler"", ""Jimmy Ba""]","[""Reinforcement learning"", ""graph neural networks"", ""robotics"", ""deep learning"", ""transfer learning""]",Automatic robotic design search with graph neural networks,,,,
BkgWahEFvr,2020,Accept (Poster),True,Enhancing Transformation-Based Defenses Against Adversarial Attacks with a Distribution Classifier,"[""Connie Kou"", ""Hwee Kuan Lee"", ""Ee-Chien Chang"", ""Teck Khim Ng""]","[""adversarial attack"", ""transformation defenses"", ""distribution classifier""]",We enhance existing transformation-based defenses by using a distribution classifier on the distribution of softmax obtained from transformed images.,1906.00258,cs.LG,2019-06-01 16:59:17+00:00,2020-01-30 05:34:00+00:00
BkgXHTNtvS,2020,Accept (Poster),False,Bounds on Over-Parameterization for Guaranteed Existence of Descent Paths in Shallow ReLU Networks,"[""Arsalan Sharifnassab"", ""Saber Salehkaleybar"", ""S. Jamaloddin Golestani""]","[""Spurious local minima"", ""Loss landscape"", ""Over-parameterization"", ""Theory of deep learning"", ""Optimization"", ""Descent path""]",,,,,
BkgXT24tDS,2020,Accept (Poster),True,Additive Powers-of-Two Quantization: An Efficient Non-uniform Discretization for Neural Networks,"[""Yuhang Li"", ""Xin Dong"", ""Wei Wang""]","[""Quantization"", ""Efficient Inference"", ""Neural Networks""]",,1909.13144,cs.LG,2019-09-28 20:14:11+00:00,2020-02-02 14:15:07+00:00
BkgYIiAcFQ,2019,Reject,False,DecayNet: A Study on the Cell States of Long Short Term Memories,"[""Nicholas I.H. Kuo"", ""Mehrtash T. Harandi"", ""Hanna Suominen"", ""Nicolas Fourrier"", ""Christian Walder"", ""Gabriela Ferraro""]","[""Long short term memory"", ""Recurrent neural network"", ""Dynamical systems"", ""Difference equation""]",We present a LSTM reformulation with a monotonically decreasing forget gate to increase LSTM interpretability and modelling power without introducing new learnable parameters.,,,,
BkgYPREtPr,2020,Accept (Spotlight),True,Symplectic Recurrent Neural Networks,"[""Zhengdao Chen"", ""Jianyu Zhang"", ""Martin Arjovsky"", ""L\u00e9on Bottou""]","[""Hamiltonian systems"", ""learning physical laws"", ""symplectic integrators"", ""recurrent neural networks"", ""inverse problems""]",,1909.13334,cs.LG,2019-09-29 18:04:07+00:00,2020-04-25 16:32:53+00:00
BkgZSCEtvr,2020,Reject,True,Continuous Graph Flow,"[""Zhiwei Deng"", ""Megha Nawhal"", ""Lili Meng"", ""Greg Mori""]","[""graph flow"", ""normalizing flow"", ""continuous message passing"", ""reversible graph neural networks""]",Graph generative models based on generalization of message passing to continuous time using ordinary differential equations ,1908.02436,cs.LG,2019-08-07 04:24:48+00:00,2019-09-28 04:34:55+00:00
BkgZxpVFvH,2020,Reject,False,LSTOD: Latent Spatial-Temporal Origin-Destination prediction model and its applications in ride-sharing platforms,"[""Fan Zhou"", ""Haibo Zhou"", ""Hongtu Zhu""]","[""Origin-Destination Flow"", ""Spatial Adjacent Convolution Network"", ""Periodically Shift Attention Mechanism""]",We propose a purely convolutional CNN model with attention mechanism to predict spatial-temporal origin-destination flows. ,,,,
Bkga90VKDB,2020,Reject,True,Distilled embedding: non-linear embedding factorization using knowledge distillation,"[""Vasileios Lioutas"", ""Ahmad Rashid"", ""Krtin Kumar"", ""Md Akmal Haidar"", ""Mehdi Rezagholizadeh""]","[""Model Compression"", ""Embedding Compression"", ""Low Rank Approximation"", ""Machine Translation"", ""Natural Language Processing"", ""Deep Learning""]",We present an embedding decomposition and distillation technique for NLP model compression which is state-of-the-art in machine translation and simpler than existing methods,1910.06720,cs.CL,2019-10-02 16:40:03+00:00,2020-11-10 22:59:44+00:00
BkgeQ1BYwS,2020,Reject,False,Implicit Generative Modeling for Efficient Exploration,"[""Neale Ratzlaff"", ""Qinxun Bai"", ""Li Fuxin"", ""Wei Xu""]","[""Reinforcement Learning"", ""Exploration"", ""Intrinsic Reward"", ""Implicit Generative Models""]",We efficiently explore by modeling uncertainty in the environment dynamics with an implicit generative model. ,1911.08017,cs.LG,2019-11-19 00:37:23+00:00,2020-07-14 19:21:32+00:00
BkggGREKvS,2020,Reject,False,Promoting Coordination through Policy Regularization in Multi-Agent Deep Reinforcement Learning,"[""Paul Barde"", ""Julien Roy"", ""F\u00e9lix G. Harvey"", ""Derek Nowrouzezahrai"", ""Christopher Pal""]","[""Reinforcement Learning"", ""Multi-Agent"", ""Continuous Control"", ""Regularization"", ""Coordination"", ""Inductive biases""]",We propose regularization objectives for multi-agent RL algorithms that foster coordination on cooperative tasks.,,,,
BkghKgStPH,2020,Reject,False,Continual Learning using the SHDL Framework with Skewed Replay Distributions,"[""Amarjot Singh"", ""Jay McClelland""]","[""Continual Learning"", ""Catastrophic Forgetting"", ""SHDL"", ""CIFAR-100""]",,,,,
BkgiM20cYX,2019,Reject,False,A Self-Supervised Method for Mapping Human Instructions to Robot Policies,"[""Hsin-Wei Yu"", ""Po-Yu Wu"", ""Chih-An Tsao"", ""You-An Shen"", ""Shih-Hsuan Lin"", ""Zhang-Wei Hong"", ""Yi-Hsiang Chang"", ""Chun-Yi Lee""]",[],,,,,
Bkgk624KDB,2020,Reject,True,Learning Effective Exploration Strategies For Contextual Bandits,"[""Amr Sharaf"", ""Hal Daum\u00e9 III""]","[""meta-learning"", ""contextual bandits"", ""imitation learning""]","We develop a meta-learning algorithm, MELEE, that learns an exploration policy based on simulated, synthetic contextual bandit tasks.",1901.08159,cs.LG,2019-01-23 22:52:13+00:00,2019-01-23 22:52:13+00:00
BkglSTNFDB,2020,Accept (Poster),False,Q-learning with UCB Exploration is Sample Efficient for Infinite-Horizon MDP,"[""Yuanhao Wang"", ""Kefan Dong"", ""Xiaoyu Chen"", ""Liwei Wang""]","[""theory"", ""reinforcement learning"", ""sample complexity""]","We adapt Q-learning with UCB-exploration bonus to infinite-horizon MDP with discounted rewards without accessing a generative model, and improves the previously best known result.",,,,
BkgnhTEtDS,2020,Accept (Poster),False,Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection,"[""Michael Tsang"", ""Dehua Cheng"", ""Hanpeng Liu"", ""Xue Feng"", ""Eric Zhou"", ""Yan Liu""]","[""Feature Interaction"", ""Interpretability"", ""Black Box"", ""AutoML""]",Proposed methods to extract and leverage interpretations of feature interactions,2006.10966,stat.ML,2020-06-19 05:14:34+00:00,2020-06-19 05:14:34+00:00
BkgosiRcKm,2019,Reject,False,Deep Recurrent Gaussian Process with Variational Sparse Spectrum Approximation,"[""Roman F\u00f6ll"", ""Bernard Haasdonk"", ""Markus Hanselmann"", ""Holger Ulmer""]","[""Deep Gaussian Process Model"", ""Recurrent Model"", ""State-Space Model"", ""Nonlinear system identification"", ""Dynamical modeling""]",Modeling time-series with several Gaussian Processes in a row via a specific Variational Sparse Spectrum Approximation,,,,
Bkgq9ANKvB,2020,Reject,True,Peer Loss Functions: Learning from Noisy Labels without Knowing Noise Rates,"[""Yang Liu"", ""Hongyi Guo""]","[""learning with noisy labels"", ""empirical risk minimization"", ""peer loss""]","This paper introduces peer loss, a family of loss functions that enables training a classifier over noisy labels, but without using explicit knowledge of the noise rates of labels.",1910.03231,cs.LG,2019-10-08 06:34:11+00:00,2020-08-14 20:28:47+00:00
BkgqExrYvS,2020,Reject,False,PopSGD: Decentralized Stochastic Gradient Descent in the Population Model,"[""Giorgi Nadiradze"", ""Amirmojtaba Sabour"", ""Aditya Sharma"", ""Ilia Markov"", ""Vitaly Aksenov"", ""Dan Alistarh.""]","[""Distributed machine learning"", ""distributed optimization"", ""decentralized parallel SGD"", ""population protocols""]",We show that large-scale distributed optimization can be performed efficiently in the population model of distributed computing. ,,,,
BkgqL0EtPH,2020,Reject,False,{COMPANYNAME}11K: An Unsupervised Representation Learning Dataset for Arrhythmia Subtype Discovery,"[""Shawn Tan"", ""Guillaume Androz"", ""Ahmad Chamseddine"", ""Pierre Fecteau"", ""Aaron Courville"", ""Yoshua Bengio"", ""Joseph Paul Cohen""]","[""representation learning"", ""healthcare"", ""medical"", ""clinical"", ""dataset"", ""ecg"", ""cardiology"", ""heart"", ""discovery"", ""anomaly detection"", ""out of distribution""]","We release a dataset constructed from single-lead ECG data from 11,000 patients who were prescribed to use the {DEVICENAME}(TM) device.",,,,
BkgrBgSYDS,2020,Accept (Spotlight),False,"Kaleidoscope: An Efficient, Learnable Representation For All Structured Linear Maps","[""Tri Dao"", ""Nimit Sohoni"", ""Albert Gu"", ""Matthew Eichhorn"", ""Amit Blonder"", ""Megan Leszczynski"", ""Atri Rudra"", ""Christopher R\u00e9""]","[""structured matrices"", ""efficient ML"", ""algorithms"", ""butterfly matrices"", ""arithmetic circuits""]","We propose a differentiable family of ""kaleidoscope matrices,"" prove that all structured matrices can be represented in this form, and use them to replace hand-crafted linear maps in deep learning models.",,,,
BkgtDsCcKQ,2019,Accept (Poster),False,Function Space Particle Optimization for Bayesian Neural Networks,"[""Ziyu Wang"", ""Tongzheng Ren"", ""Jun Zhu"", ""Bo Zhang""]","[""Bayesian neural networks"", ""uncertainty estimation"", ""variational inference""]",,,,,
Bkgwp3NtDH,2020,Reject,False,Programmable Neural Network Trojan for Pre-trained Feature Extractor,"[""Yu Ji"", ""Zinxin Liu"", ""Xing Hu"", ""Peiqi Wang"", ""Youhui Zhang""]","[""Neural Network"", ""Trojan"", ""Security""]",We present a more powerful NN trojaning attack that can support outer-scope targets and dynamic targets,,,,
BkgzMCVtPB,2020,Accept (Talk),False,Optimal Strategies Against Generative Attacks,"[""Roy Mor"", ""Erez Peterfreund"", ""Matan Gavish"", ""Amir Globerson""]",[],,,,,
BkgzniCqY7,2019,Accept (Poster),False,Structured Adversarial Attack:  Towards General Implementation and Better Interpretability,"[""Kaidi Xu"", ""Sijia Liu"", ""Pu Zhao"", ""Pin-Yu Chen"", ""Huan Zhang"", ""Quanfu Fan"", ""Deniz Erdogmus"", ""Yanzhi Wang"", ""Xue Lin""]",[],,,,,
BkgzqRVFDr,2020,Reject,False,Reinforcement Learning with Probabilistically Complete Exploration,"[""Philippe Morere"", ""Tom Blau"", ""Gilad Francis"", ""Fabio Ramos""]","[""Reinforcement Learning"", ""Exploration"", ""sparse rewards"", ""learning from demonstration""]",Enhancing reinforcement learning exploration with planning algorithms,,,,
Bki1Ct1AW,2018,Reject,False,Baseline-corrected space-by-time non-negative matrix factorization for decoding single trial population spike trains,"[""Arezoo Alizadeh"", ""Marion Mutter"", ""Thomas M\u00fcnch"", ""Arno Onken"", ""Stefano Panzeri""]","[""Space-by-time non-negative matrix factorization"", ""dimensionality reduction"", ""baseline correction"", ""neuronal decoding"", ""mutual information""]",We extended single-trial space-by-time tensor decomposition based on non-negative matrix factorization to efficiently discount pre-stimulus baseline activity that improves decoding performance on data with non-negligible baselines.,,,,
Bki4EfWCb,2018,Invite to Workshop Track,False,Inference Suboptimality in Variational Autoencoders,"[""Chris Cremer"", ""Xuechen Li"", ""David Duvenaud""]","[""Approximate Inference"", ""Amortization"", ""Posterior Approximations"", ""Variational Autoencoder""]",We decompose the gap between the marginal log-likelihood and the evidence lower bound and study the effect of the approximate posterior on the true posterior distribution in VAEs.,,,,
BkiIkBJ0b,2018,Reject,False,Do Deep Reinforcement Learning Algorithms really Learn to Navigate?,"[""Shurjo Banerjee"", ""Vikas Dhiman"", ""Brent Griffin"", ""Jason J. Corso""]","[""deep reinforcement learning"", ""navigation"", ""path-planning"", ""mapping""]",We quantitatively and qualitatively evaluate deep reinforcement learning based navigation methods under a variety of conditions to answer the question of how close they are to replacing classical path planners and mapping algorithms.,,,,
BkisuzWRW,2018,Accept (Oral),False,Zero-Shot Visual Imitation,"[""Deepak Pathak"", ""Parsa Mahmoudieh"", ""Guanghao Luo"", ""Pulkit Agrawal"", ""Dian Chen"", ""Yide Shentu"", ""Evan Shelhamer"", ""Jitendra Malik"", ""Alexei A. Efros"", ""Trevor Darrell""]","[""imitation"", ""zero-shot"", ""self-supervised"", ""robotics"", ""skills"", ""navigation"", ""manipulation"", ""vizdoom"", ""reinforcement""]",Agents can learn to imitate solely visual demonstrations (without actions) at test time after learning from their own experience without any form of supervision at training time.,,,,
BkjLkSqxg,2017,Reject,False,LipNet: End-to-End Sentence-level Lipreading,"[""Yannis M. Assael"", ""Brendan Shillingford"", ""Shimon Whiteson"", ""Nando de Freitas""]","[""Computer vision"", ""Deep learning""]",LipNet is the first end-to-end sentence-level lipreading model to simultaneously learn spatiotemporal visual features and a sequence model.,,,,
Bkl-43C9FQ,2019,Accept (Poster),False,Spherical CNNs on Unstructured Grids,"[""Chiyu Max Jiang"", ""Jingwei Huang"", ""Karthik Kashinath"", ""Prabhat"", ""Philip Marcus"", ""Matthias Niessner""]","[""Spherical CNN"", ""unstructured grid"", ""panoramic"", ""semantic segmentation"", ""parameter efficiency""]","We present a new CNN kernel for unstructured grids for spherical signals, and show significant accuracy and parameter efficiency gain on tasks such as 3D classfication and omnidirectional image segmentation.",,,,
Bkl086VYvH,2020,Reject,False,Feature-map-level Online Adversarial Knowledge Distillation,"[""Inseop Chung"", ""SeongUk Park"", ""Jangho Kim"", ""Nojun Kwak""]","[""Computer vision"", ""Image classification"", ""Knowledge distillation"", ""Deep Learning""]",Online knowledge distillation method using feature map information.,2002.01775,cs.LG,2020-02-05 13:16:37+00:00,2020-06-05 18:15:40+00:00
Bkl1uWb0Z,2018,Reject,False,Inducing Grammars with and for Neural Machine Translation,"[""Ke Tran"", ""Yonatan Bisk""]","[""structured attention"", ""neural machine translation"", ""grammar induction""]",improve NMT with latent trees,,,,
Bkl2SjCcKQ,2019,Reject,False,TequilaGAN: How To Easily Identify GAN Samples,"[""Rafael Valle"", ""Wilson Cai"", ""Anish P. Doshi""]","[""Generative Adversarial Networks"", ""Deep Learning""]",We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.,,,,
Bkl2UlrFwr,2020,Reject,False,Iterative Deep Graph Learning for Graph Neural Networks,"[""Yu Chen"", ""Lingfei Wu"", ""Mohammed J. Zaki""]","[""deep learning"", ""graph neural networks"", ""graph learning""]",,1912.07832,cs.LG,2019-12-17 06:02:59+00:00,2019-12-17 06:02:59+00:00
Bkl5kxrKDr,2020,Accept (Talk),False,A Generalized Training Approach for Multiagent Learning,"[""Paul Muller"", ""Shayegan Omidshafiei"", ""Mark Rowland"", ""Karl Tuyls"", ""Julien Perolat"", ""Siqi Liu"", ""Daniel Hennes"", ""Luke Marris"", ""Marc Lanctot"", ""Edward Hughes"", ""Zhe Wang"", ""Guy Lever"", ""Nicolas Heess"", ""Thore Graepel"", ""Remi Munos""]","[""multiagent learning"", ""game theory"", ""training"", ""games""]",,,,,
Bkl7bREtDr,2020,Accept (Poster),False,AMRL: Aggregated Memory For Reinforcement Learning,"[""Jacob Beck"", ""Kamil Ciosek"", ""Sam Devlin"", ""Sebastian Tschiatschek"", ""Cheng Zhang"", ""Katja Hofmann""]","[""deep learning"", ""reinforcement learning"", ""rl"", ""memory"", ""noise"", ""machine learning""]","In Deep RL, order-invariant functions can be used in conjunction with standard memory modules to improve gradient decay and resilience to noise.",,,,
Bkl87h09FX,2019,Reject,False,Looking for ELMo's friends: Sentence-Level Pretraining Beyond Language Modeling,"[""Samuel R. Bowman"", ""Ellie Pavlick"", ""Edouard Grave"", ""Benjamin Van Durme"", ""Alex Wang"", ""Jan Hula"", ""Patrick Xia"", ""Raghavendra Pappagari"", ""R. Thomas McCoy"", ""Roma Patel"", ""Najoung Kim"", ""Ian Tenney"", ""Yinghui Huang"", ""Katherin Yu"", ""Shuning Jin"", ""Berlin Chen""]","[""natural language processing"", ""transfer learning"", ""multitask learning""]","We compare many tasks and task combinations for pretraining sentence-level BiLSTMs for NLP tasks. Language modeling is the best single pretraining task, but simple baselines also do well.",,,,
Bkl8YR4YDB,2020,Reject,True,Large-scale Pretraining for Neural Machine Translation with Tens of Billions of Sentence Pairs,"[""Yuxian Meng"", ""Xiangyuan Ren"", ""Zijun Sun"", ""Xiaoya Li"", ""Arianna Yuan"", ""Fei Wu"", ""Jiwei Li""]",[],,1909.11861,cs.CL,2019-09-26 03:06:47+00:00,2019-10-06 04:01:39+00:00
BklACjAqFm,2019,Reject,False,Successor Uncertainties: exploration and uncertainty in temporal difference learning,"[""David Janz"", ""Jiri Hron"", ""Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"", ""Katja Hofmann"", ""Sebastian Tschiatschek""]",[],,,,,
BklAEsR5t7,2019,Reject,False,Large-scale classification of structured objects using a CRF with deep class embedding,"[""Eran Goldman"", ""Jacob Goldberger""]","[""large-scale structure prediction"", ""likelihood approximation"", ""deep class embedding""]","We present a  technique for ultrafine-grained, large-scale structured classification, based on CRF modeling with factorized pairwise potentials, learned as neighboring class embedding in a whitened space.",,,,
BklBp6EYvB,2020,Reject,False,Task-Based Top-Down Modulation Network for Multi-Task-Learning Applications,"[""Hila Levi"", ""Shimon Ullman""]","[""deep learning"", ""multi-task learning""]",We propose a top-down modulation network for multi-task learning applications with several advantages over current schemes.    ,,,,
BklC2RNKDS,2020,Reject,False,Scalable Neural Learning for Verifiable Consistency with Temporal Specifications,"[""Sumanth Dathathri"", ""Johannes Welbl"", ""Krishnamurthy (Dj) Dvijotham"", ""Ramana Kumar"", ""Aditya Kanade"", ""Jonathan Uesato"", ""Sven Gowal"", ""Po-Sen Huang"", ""Pushmeet Kohli""]","[""Verification"", ""Recurrent Neural Networks"", ""Reinforcement Learning"", ""Temporal Logic"", ""Adversarial Robustness""]",Neural Network Verification for Temporal Properties and Sequence Generation Models,,,,
BklCusRct7,2019,Accept (Poster),False,Optimal Transport Maps For Distribution Preserving Operations on Latent Spaces of Generative Models,"[""Eirikur Agustsson"", ""Alexander Sage"", ""Radu Timofte"", ""Luc Van Gool""]","[""generative models"", ""optimal transport"", ""distribution preserving operations""]",We propose a framework for modifying the latent space operations such that the distribution mismatch between the resulting outputs and the prior distribution the generative model was trained on is fully eliminated.,,,,
BklDO1HYPS,2020,Reject,False,Accelerated Variance Reduced Stochastic Extragradient Method for Sparse Machine Learning Problems,"[""Fanhua Shang"", ""Lin Kong"", ""Yuanyuan Liu"", ""Hua Huang"", ""Hongying Liu""]","[""non-smooth optimization"", ""SVRG"", ""proximal operator"", ""extragradient descent"", ""momentum acceleration""]",,,,,
BklEF3VFPB,2020,Reject,False,Towards Stable and comprehensive Domain Alignment: Max-Margin Domain-Adversarial Training,"[""Jianfei Yang"", ""Han Zou"", ""Yuxun Zhou"", ""Lihua Xie""]","[""domain adaptation"", ""transfer learning"", ""adversarial training""]",A stable domain-adversarial training approach for robust and comprehensive domain adaptation,2003.13249,cs.LG,2020-03-30 07:48:52+00:00,2020-03-30 07:48:52+00:00
BklEFpEYwS,2020,Accept (Spotlight),False,Meta-Learning without Memorization,"[""Mingzhang Yin"", ""George Tucker"", ""Mingyuan Zhou"", ""Sergey Levine"", ""Chelsea Finn""]","[""meta-learning"", ""memorization"", ""regularization"", ""overfitting"", ""mutually-exclusive""]","We identify and formalize the memorization problem in meta-learning and solve this problem with novel meta-regularization method, which greatly expand the domain that meta-learning can be  applicable to and effective on.",1912.03820,cs.LG,2019-12-09 02:30:46+00:00,2020-04-27 22:33:53+00:00
BklHF6VtPB,2020,Reject,True,Modeling Winner-Take-All Competition in Sparse Binary Projections,"[""Wenye Li""]","[""Sparse Representation"", ""Sparse Binary Projection"", ""Winner-Take-All""]","We developed a Winner-Take-All model that learns a sparse binary representation for input samples, with significantly improved speed and accuracy.",1907.11959,cs.LG,2019-07-27 18:23:48+00:00,2020-01-27 03:51:07+00:00
BklHpjCqKm,2019,Accept (Poster),False,Deep Lagrangian Networks: Using Physics as Model Prior for Deep Learning,"[""Michael Lutter"", ""Christian Ritter"", ""Jan Peters""]","[""Deep Model Learning"", ""Robot Control""]",This paper introduces a physics prior for Deep Learning and applies the resulting network topology for model-based control.,,,,
BklIxyHKDr,2020,Reject,False,Deep k-NN for Noisy Labels,"[""Dara Bahri"", ""Heinrich Jiang"", ""Maya Gupta""]",[],,,,,
BklKFo09YX,2019,Reject,False,Mol-CycleGAN - a generative model for molecular optimization,"[""\u0141ukasz Maziarka"", ""Agnieszka Pocha"", ""Jan Kaczmarczyk"", ""Micha\u0142 Warcho\u0142""]","[""generative adversarial networks"", ""drug design"", ""deep learning"", ""molecule optimization""]",We introduce Mol-CycleGAN - a new generative model for optimization of molecules to augment drug design.,,,,
BklLVAEKvH,2020,Reject,True,Generalized Clustering by Learning to Optimize Expected Normalized Cuts,"[""Azade Nazi"", ""Will Hang"", ""Anna Goldie"", ""Sujith Ravi"", ""Azalia Mirhoseini""]","[""Clustering"", ""Normalized cuts"", ""Generalizability""]",We introduce a novel end-to-end approach for learning to cluster in the absence of labeled examples. We define a differentiable loss function equivalent to the expected normalized cuts.,1910.07623,cs.LG,2019-10-16 21:28:51+00:00,2019-10-16 21:28:51+00:00
BklMDCVtvr,2020,Reject,True,Discovering the compositional structure of vector representations with Role Learning Networks,"[""Paul Soulos"", ""Tom McCoy"", ""Tal Linzen"", ""Paul Smolensky""]","[""compositionality"", ""generalization"", ""neurosymbolic"", ""symbolic structures"", ""interpretability"", ""tensor product representations""]",We introduce a new analysis technique that discovers interpretable compositional structure in notoriously hard-to-interpret recurrent neural networks.,1910.09113,cs.LG,2019-10-21 02:12:51+00:00,2020-11-16 20:23:51+00:00
BklMYjC9FQ,2019,Reject,False,microGAN: Promoting Variety through Microbatch Discrimination,"[""Goncalo Mordido"", ""Haojin Yang"", ""Christoph Meinel""]","[""adversarial training"", ""gans""]",We use microbatch discrimination on multi-adversarial GANs to mitigate mode collapse.,,,,
BklMjsRqY7,2019,Accept (Poster),False,Accumulation Bit-Width Scaling For Ultra-Low Precision Training Of Deep Networks,"[""Charbel Sakr"", ""Naigang Wang"", ""Chia-Yu Chen"", ""Jungwook Choi"", ""Ankur Agrawal"", ""Naresh Shanbhag"", ""Kailash Gopalakrishnan""]","[""reduced precision floating-point"", ""partial sum accumulation bit-width"", ""deep learning"", ""training""]",We present an analytical framework to determine accumulation bit-width requirements in all three deep learning training GEMMs and verify the validity and tightness of our method via benchmarking experiments.,,,,
BklOXeBFDS,2020,Reject,False,Transfer Active Learning For Graph Neural Networks,"[""Shengding Hu"", ""Meng Qu"", ""Zhiyuan Liu"", ""Jian Tang""]","[""Active Learning"", ""Graph Neural Networks"", ""Transfer Learning"", ""Reinforcement Learning""]",We propose a novel method to learn a transferable active learning policy for Graph Neural Networks via reinforcement learning and  policy distillation.,,,,
BklRFpVKPH,2020,Reject,False,Demonstration Actor Critic,"[""Guoqing Liu"", ""Li Zhao"", ""Pushi Zhang"", ""Jiang Bian"", ""Tao Qin"", ""Nenghai Yu"", ""Tie-Yan Liu""]","[""Deep Reinforcement Learning"", ""Reinforcement Learning from Demonstration""]",,,,,
BklSv34KvB,2020,Reject,False,"Carpe Diem, Seize the Samples Uncertain ""at the Moment"" for Adaptive Batch Selection","[""Hwanjun Song"", ""Minseok Kim"", ""Sundong Kim"", ""Jae-Gil Lee""]","[""batch selection"", ""uncertain sample"", ""acceleration"", ""convergence""]",We explore the issue of truly uncertain samples for more effective batch selection.,1911.08050,cs.LG,2019-11-19 02:28:07+00:00,2020-12-23 01:15:51+00:00
BklSwn4tDH,2020,Reject,False,Prestopping: How Does Early Stopping Help Generalization Against Label Noise?,"[""Hwanjun Song"", ""Minseok Kim"", ""Dongmin Park"", ""Jae-Gil Lee""]","[""noisy label"", ""label noise"", ""robustness"", ""deep learning"", ""early stopping""]","We propose a novel two-phase training approach based on ""early stopping"" for robust training on noisy labels.",1911.08059,cs.LG,2019-11-19 02:51:15+00:00,2020-09-08 06:23:48+00:00
BklTQCEtwH,2020,Reject,True,Curriculum Learning for Deep Generative Models with Clustering,"[""Deli Zhao"", ""Jiapeng Zhu"", ""Zhenfang Guo"", ""Bo Zhang""]","[""curriculum learning"", ""generative adversarial network""]",A novel cluster-based algorithm of curriculum learning is proposed to solve the robust training of generative models.,1906.11594,cs.LG,2019-06-27 12:44:09+00:00,2019-09-26 03:04:58+00:00
BklUAoAcY7,2019,Reject,False,Unsupervised Learning  of Sentence Representations Using Sequence Consistency,"[""Siddhartha Brahma""]","[""sentence representation"", ""unsupervised learning"", ""LSTM""]",Good sentence encoders can be learned by training them to distinguish between consistent and inconsistent (pairs of) sequences that are generated in an unsupervised manner.,,,,
BklVA2NYvH,2020,Reject,False,Adversarially Robust Neural Networks via Optimal Control: Bridging Robustness with Lyapunov Stability,"[""Zhiyang Chen"", ""Hang Su""]","[""adversarial defense"", ""optimal control"", ""Lyapunov stability""]",An adversarial defense method bridging robustness of deep neural nets with Lyapunov stability,,,,
BklWt24tvH,2020,Reject,False,Learning Structured Communication for Multi-agent Reinforcement Learning,"[""Junjie Sheng"", ""Xiangfeng Wang"", ""Bo Jin"", ""Junchi Yan"", ""Wenhao Li"", ""Tsung-Hui Chang"", ""Jun Wang"", ""Hongyuan Zha""]","[""Learning to communicate"", ""Multi-agent reinforcement learning"", ""Hierarchical communication network""]",,,,,
BklXkCNYDB,2020,Reject,True,Fast Training of Sparse Graph Neural Networks on Dense Hardware,"[""Matej Balog"", ""Bart van Merri\u00ebnboer"", ""Subhodeep Moitra"", ""Yujia Li"", ""Daniel Tarlow""]",[],Is sparse hardware necessary for training sparse GNNs? No. Does large-batch training work for sparse GNNs? Yes. So what? We can train a model in 13 minutes that previously took almost a day.,1906.11786,stat.ML,2019-06-27 16:48:29+00:00,2019-06-27 16:48:29+00:00
Bkle6T4YvB,2020,Reject,False,From English to Foreign Languages: Transferring Pre-trained Language Models,"[""Ke Tran""]","[""pretrained language model"", ""zero-shot transfer"", ""parsing"", ""natural language inference""]",How to train non-English BERT within one day on using a single GPU,2002.07306,cs.CL,2020-02-18 00:22:54+00:00,2020-04-29 01:16:24+00:00
BkleBaVFwB,2020,Reject,True,Scalable Generative Models for Graphs with Graph Attention Mechanism,"[""Wataru Kawai"", ""Yusuke Mukuta"", ""Tatsuya Harada""]","[""Graph Generative Model"", ""Attention Mechanism""]","We proposed a generative model for graphs that is scalable in terms of the number of nodes, dataset size, and the number of node/edge labels utilizing graph attention mechanism. ",1906.01861,cs.LG,2019-06-05 07:33:06+00:00,2019-10-03 12:07:53+00:00
BklekANtwr,2020,Reject,False,Unsupervised Learning of Automotive 3D Crash Simulations using LSTMs,"[""Amin Abbasloo"", ""Jochen Garcke"", ""Rodrigo Iza-Teran""]","[""LSTM"", ""surface data"", ""geometric deep learning"", ""numerical simulation""]",A two branch LSTM based network architecture learns the representation and dynamics of 3D meshes of numerical crash simulations.,,,,
BklfR3EYDH,2020,Reject,False,Keyframing the Future: Discovering Temporal Hierarchy with Keyframe-Inpainter Prediction,"[""Karl Pertsch"", ""Oleh Rybkin"", ""Jingyun Yang"", ""Konstantinos G. Derpanis"", ""Kostas Daniilidis"", ""Joseph J. Lim"", ""Andrew Jaegle""]","[""representation learning"", ""variational inference"", ""video generation"", ""temporal hierarchy""]",We propose a model that learns to discover informative frames in a future video sequence and represent the video via its keyframes.,,,,
Bklfsi0cKm,2019,Accept (Poster),False,Deep Convolutional Networks as shallow Gaussian Processes,"[""Adri\u00e0 Garriga-Alonso"", ""Carl Edward Rasmussen"", ""Laurence Aitchison""]","[""Gaussian process"", ""CNN"", ""ResNet"", ""Bayesian""]",We show that CNNs and ResNets with appropriate priors on the parameters are Gaussian processes in the limit of infinitely many convolutional filters.,,,,
Bklg1grtDr,2020,Reject,False,Neural Design of Contests and All-Pay Auctions using Multi-Agent Simulation,"[""Thomas Anthony"", ""Ian Gemp"", ""Janos Kramar"", ""Tom Eccles"", ""Andrea Tacchetti"", ""Yoram Bachrach""]","[""Auctions"", ""Mechanism Design"", ""Multi-Agent"", ""Fictitious Play""]","We propose a multi-agent learning approach to designing all-pay auctions, which works even in settings where computing the Nash equilibrium bidding strategies is intractable. ",,,,
BklhAj09K7,2019,Accept (Poster),False,Unsupervised Domain Adaptation for Distance Metric Learning,"[""Kihyuk Sohn"", ""Wenling Shang"", ""Xiang Yu"", ""Manmohan Chandraker""]","[""domain adaptation"", ""distance metric learning"", ""face recognition""]",A new theory of unsupervised domain adaptation for distance metric learning and its application to face recognition across diverse ethnicity variations.,,,,
BklhsgSFvB,2020,Reject,False,Learning to Transfer via Modelling Multi-level Task Dependency,"[""Haonan Wang"", ""Zhenbang Wu"", ""Ziniu Hu"", ""Yizhou Sun""]","[""multi-task learning"", ""attention mechanism""]",We propose a novel multi-task learning framework which extracts multi-view dependency relationship automatically and use it to guide the knowledge transfer among different tasks.,,,,
BkljIlHtvS,2020,Reject,False,Decoupling Adaptation from Modeling with Meta-Optimizers for Meta Learning,"[""S\u00e9bastien M.R. Arnold"", ""Shariq Iqbal"", ""Fei Sha""]","[""meta-learning"", ""MAML"", ""analysis"", ""depth"", ""meta-optimizers""]",We find that deep models are crucial for MAML to work and propose a method which enables effective meta-learning in smaller models.,,,,
BkllBpEKDH,2020,Reject,False,Continuous Adaptation in Multi-agent Competitive Environments,"[""Kuei-Tso Lee"", ""Sheng-Jyh Wang""]","[""multi-agent environment"", ""continuous adaptation"", ""Nash equilibrium"", ""deep counterfactual regret minimization"", ""reinforcement learning"", ""stochastic game"", ""baseball""]",We construct a simplified baseball game scenario to develop and evaluate the adaptation capability of learning agents.,,,,
BklmtJBKDB,2020,Reject,False,Conditional Flow Variational Autoencoders for Structured Sequence Prediction,"[""Apratim Bhattacharyya"", ""Michael Hanselmann"", ""Mario Fritz"", ""Bernt Schiele"", ""Christoph-Nikolas Straehle""]","[""Variational Inference"", ""Normalizing Flows"", ""Trajectories""]",We propose a conditional flow prior based CF-VAE for generative modelling of conditional distributions and effective regularisation schemes.,,,,
Bkln2a4tPB,2020,Reject,True,Customizing Sequence Generation with Multi-Task Dynamical Systems,"[""Alex Bird"", ""Christopher K. I. Williams""]","[""Time-series modelling"", ""Dynamical systems"", ""RNNs"", ""Multi-task learning""]",Tailoring predictions from sequence models (such as LDSs and RNNs) via an explicit latent code.,1910.05026,cs.LG,2019-10-11 08:32:13+00:00,2019-10-11 08:32:13+00:00
BkloRs0qK7,2019,Accept (Poster),False,"A comprehensive, application-oriented study of catastrophic forgetting in DNNs","[""B. Pf\u00fclb"", ""A. Gepperth""]","[""incremental learning"", ""deep neural networks"", ""catatrophic forgetting"", ""sequential learning""]","We check DNN models for catastrophic forgetting using a new evaluation scheme that reflects typical application conditions, with surprising results.",,,,
BklpOo09tQ,2019,Reject,True,EFFICIENT TWO-STEP ADVERSARIAL DEFENSE FOR DEEP NEURAL NETWORKS,"[""Ting-Jui Chang"", ""Yukun He"", ""Peng Li""]","[""Adversarial Examples"", ""Adversarial Training"", ""FGSM"", ""IFGSM"", ""Robustness""]",We proposed a time-efficient defense method against one-step and iterative adversarial attacks.,1810.03739,cs.LG,2018-10-08 23:00:06+00:00,2018-10-08 23:00:06+00:00
Bklr0kBKvB,2020,Reject,False,Geometry-aware Generation of Adversarial and Cooperative Point Clouds,"[""Yuxin Wen"", ""Jiehong Lin"", ""Ke Chen"", ""Kui Jia""]","[""Adversarial attack"", ""Point cloud classification""]",,,,,
Bklr3j0cKX,2019,Accept (Oral),False,Learning deep representations by mutual information estimation and maximization,"[""R Devon Hjelm"", ""Alex Fedorov"", ""Samuel Lavoie-Marchildon"", ""Karan Grewal"", ""Phil Bachman"", ""Adam Trischler"", ""Yoshua Bengio""]","[""representation learning"", ""unsupervised learning"", ""deep learning""]","We learn deep representation by maximizing mutual information, leveraging structure in the objective, and are able to compute with fully supervised classifiers with comparable architectures",,,,
Bklrea4KwS,2020,Reject,False,Deep Multiple Instance Learning with Gaussian Weighting,"[""Basura Fernando"", ""Hakan Bilen""]","[""Multiple instance learning"", ""deep learning""]",,,,,
BklsagBYPS,2020,Reject,False,A GOODNESS OF FIT MEASURE FOR GENERATIVE NETWORKS,"[""Lorenzo Luzi"", ""Randall Balestriero"", ""Richard Baraniuk""]","[""generative adversarial networks"", ""goodness of fit"", ""inception score"", ""empirical approximation error"", ""validation metric"", ""frechet inception score""]",,,,,
BkltNhC9FX,2019,Accept (Poster),False,Posterior Attention Models for Sequence to Sequence Learning,"[""Shiv Shankar"", ""Sunita Sarawagi""]","[""posterior inference"", ""attention"", ""seq2seq learning"", ""translation""]",Computing attention based on posterior distribution leads to more meaningful attention and better performance,,,,
Bklu2grKwB,2020,Reject,False,Learning RNNs with Commutative State Transitions,"[""Edo Cohen-Karlik"", ""Amir Globerson""]",[],,,,,
BkluqlSFDS,2020,Accept (Talk),False,Federated Learning with Matched Averaging,"[""Hongyi Wang"", ""Mikhail Yurochkin"", ""Yuekai Sun"", ""Dimitris Papailiopoulos"", ""Yasaman Khazaeni""]","[""federated learning""]",Communication efficient federated learning with layer-wise matching,2002.06440,cs.LG,2020-02-15 20:09:24+00:00,2020-02-15 20:09:24+00:00
BklxI0VtDB,2020,Reject,False,ROS-HPL: Robotic Object Search with Hierarchical Policy Learning and Intrinsic-Extrinsic Modeling,"[""Xin Ye"", ""Shibin Zheng"", ""Yezhou Yang""]","[""Robotic Object Search"", ""Hierarchical Reinforcement Learning""]","In this paper, we present a novel two-layer hierarchical policy learning framework that builds on intrinsic and extrinsic rewards for the task of robotic object search.",,,,
BklxN0NtvB,2020,Reject,False,Noisy Machines: Understanding noisy neural networks and enhancing robustness to analog hardware errors using distillation,"[""Chuteng Zhou"", ""Prad Kadambi"", ""Matthew Mattina"", ""Paul N. Whatmough""]","[""network noise robustness"", ""analog accelerator"", ""noise injection"", ""distillation"", ""error rate""]","We present a novel training method enhancing neural network robustness to random noise in weights, making it more practical to deploy neural networks on analog accelerators.",,,,
Bklzkh0qFm,2019,Reject,False,Relational Graph Attention Networks,"[""Dan Busbridge"", ""Dane Sherburn"", ""Pietro Cavallo"", ""Nils Y. Hammerla""]","[""RGCN"", ""attention"", ""graph convolutional networks"", ""semi-supervised learning"", ""graph classification"", ""molecules""]",We propose a new model for relational graphs and evaluate it on relational transductive and inductive tasks.,,,,
BkmM8Dceg,2017,Reject,False,Warped Convolutions: Efficient Invariance to Spatial Transformations,"[""Joao F. Henriques"", ""Andrea Vedaldi""]",[],,,,,
BkoCeqgR-,2018,Reject,False,On the Construction and Evaluation of Color Invariant Networks,"[""Konrad Groh""]","[""deep learning"", ""invariance"", ""data set"", ""evaluation""]",We construct and evaluate color invariant neural nets on a novel realistic data set,,,,
BkoXnkWAb,2018,Invite to Workshop Track,False,Shifting Mean Activation Towards Zero with Bipolar Activation Functions,"[""Lars Hiller Eidnes"", ""Arild N\u00f8kland""]",[],,,,,
BkpXqwUTZ,2018,Reject,False,Iterative temporal differencing with fixed random feedback alignment support spike-time dependent plasticity in vanilla backpropagation for deep learning,"[""Aras Dargazany"", ""Kunal Mankodiya""]","[""Iterative temporal differencing"", ""feedback alignment"", ""spike-time dependent plasticity"", ""vanilla backpropagation"", ""deep learning""]",Iterative temporal differencing with fixed random feedback alignment support spike-time dependent plasticity in vanilla backpropagation for deep learning.,,,,
Bkp_y7qxe,2017,Reject,False,Unsupervised Deep Learning of State Representation Using Robotic Priors ,"[""Timothee LESORT"", ""David FILLIAT""]","[""Deep learning"", ""Computer vision"", ""Unsupervised Learning""]",This paper introduces a method for training a deep neural network to learn a  representation of a robot's environment state using a priori knowledge.,,,,
BkpiPMbA-,2018,Accept (Poster),False,Decision Boundary Analysis of Adversarial Examples,"[""Warren He"", ""Bo Li"", ""Dawn Song""]","[""adversarial machine learning"", ""supervised representation learning"", ""decision regions"", ""decision boundaries""]",Looking at decision boundaries around an input gives you more information than a fixed small neighborhood,,,,
BkrSv0lA-,2018,Accept (Poster),False,Loss-aware Weight Quantization of Deep Networks,"[""Lu Hou"", ""James T. Kwok""]","[""deep learning"", ""network quantization""]",A loss-aware weight quantization algorithm that directly considers its effect on the loss is proposed.,,,,
BkrsAzWAb,2018,Accept (Poster),True,Online Learning Rate Adaptation with Hypergradient Descent,"[""Atilim Gunes Baydin"", ""Robert Cornish"", ""David Martinez Rubio"", ""Mark Schmidt"", ""Frank Wood""]",[],,1703.04782,cs.LG,2017-03-14 22:28:27+00:00,2018-02-26 01:36:49+00:00
Bks8cPcxe,2017,Accept (Poster),False,DeepDSL: A Compilation-based Domain-Specific Language for Deep Learning,"[""Tian Zhao"", ""Xiao Bing Huang"", ""Yu Cao""]","[""Deep learning"", ""Applications"", ""Optimization""]","DeepDSL(a DSL embedded in Scala) that compiles deep learning networks written in DeepDSL to Java source code, which runs on any GPU equipped machines with competitive efficiency as existing state-of-the-art tools (e.g. Caffe and Tensorflow)",,,,
Bkul3t9ee,2017,Invite to Workshop Track,False,Unsupervised Perceptual Rewards for Imitation Learning,"[""Pierre Sermanet"", ""Kelvin Xu"", ""Sergey Levine""]","[""Computer vision"", ""Deep learning"", ""Unsupervised Learning"", ""Reinforcement Learning"", ""Transfer Learning""]",Real robots learn new tasks from observing a few human demonstrations.,,,,
BkwHObbRZ,2018,Accept (Poster),False,Learning One-hidden-layer Neural Networks with Landscape Design,"[""Rong Ge"", ""Jason D. Lee"", ""Tengyu Ma""]","[""theory"", ""non-convex optimization"", ""loss surface""]",The paper analyzes the optimization landscape of one-hidden-layer neural nets and designs a new objective that provably has no spurious local minimum. ,,,,
Bkx0RjA9tX,2019,Accept (Poster),False,Generative Question Answering: Learning to Answer the Whole Question,"[""Mike Lewis"", ""Angela Fan""]","[""Question answering"", ""question generation"", ""reasoning"", ""squad"", ""clevr""]",Question answering models that model the joint distribution of questions and answers can learn more than discriminative models,,,,
Bkx1mxSKvB,2020,Reject,False,Disentangling Trainability and Generalization in Deep Learning,"[""Lechao Xiao"", ""Jeffrey Pennington"", ""Sam Schoenholz""]","[""NTK"", ""NNGP"", ""mean field theory"", ""CNN"", ""trainability and generalization"", ""Gaussian process""]",Disentangling Trainability and Generalization in Deep Learning via the Evolution of the Neural Tangent Kernels,,,,
Bkx29TVFPr,2020,Reject,False,An implicit function learning approach for parametric modal regression,"[""Yangchen Pan"", ""Martha White"", ""Amir-massoud Farahmand""]","[""regression"", ""modal regression"", ""implicit function theorem"", ""multivalue function""]",We introduce a simple and novel modal regression algorithm which is easy to scale to large problems. ,,,,
Bkx4AJSFvB,2020,Reject,False,Efficient Bi-Directional Verification of ReLU Networks via Quadratic Programming,"[""Aleksei Kuvshinov"", ""Stephan Guennemann""]",[],,,,,
Bkx5XyrtPS,2020,Reject,True,Depth creates no more spurious local minima in linear networks,"[""Li Zhang""]","[""local minimum"", ""deep linear network""]",We show that a deep linear network has no spurious local minima as long as it is true for the two layer case. ,1901.09827,cs.LG,2019-01-28 17:25:27+00:00,2020-01-06 00:44:57+00:00
Bkx8OiRcYX,2019,Reject,False,Countdown Regression: Sharp and Calibrated Survival Predictions,"[""Anand Avati"", ""Tony Duan"", ""Sharon Zhou"", ""Kenneth Jung"", ""Nigam Shah"", ""Andrew Ng""]",[],,,,,
BkxA5lBFvH,2020,Reject,False,Hope For The Best But Prepare For The Worst: Cautious Adaptation In RL Agents,"[""Jesse Zhang"", ""Brian Cheung"", ""Chelsea Finn"", ""Dinesh Jayaraman"", ""Sergey Levine""]","[""safety"", ""risk"", ""uncertainty"", ""adaptation""]",Adaptation of an RL agent in a target environment with unknown dynamics is fast and safe when we transfer prior experience in a variety of environments and then select risk-averse actions during adaptation.,,,,
BkxAUjRqY7,2019,Reject,False,An Information-Theoretic Metric of Transferability for Task Transfer Learning,"[""Yajie Bao"", ""Yang Li"", ""Shao-Lun Huang"", ""Lin Zhang"", ""Amir R. Zamir"", ""Leonidas J. Guibas""]","[""transfer learning"", ""task transfer learning"", ""H-score"", ""transferability""]",We present a provable and easily-computable evaluation function that estimates the performance of transferred representations from one learning task to another in task transfer learning.,,,,
BkxDthVtvS,2020,Reject,True,Equivariant neural networks and equivarification,"[""Erkao Bao"", ""Linqi Song""]","[""equivariant"", ""invariant"", ""neural network"", ""equivarification""]",,1906.07172,cs.LG,2019-06-16 23:26:03+00:00,2020-03-22 04:28:55+00:00
BkxDxJHFDr,2020,Reject,True,Power up! Robust Graph Convolutional Network based on Graph Powering,"[""Ming Jin"", ""Heng Chang"", ""Wenwu Zhu"", ""Somayeh Sojoudi""]","[""graph mining"", ""graph neural network"", ""adversarial robustness""]",We propose a framework for robust graph neural networks based on graph powering,1905.10029,cs.LG,2019-05-24 04:43:38+00:00,2021-09-21 05:10:32+00:00
BkxFi2VYvS,2020,Reject,False,Semi-supervised Semantic Segmentation using Auxiliary Network,"[""Wei-Hsu Chen"", ""Hsueh-Ming Hang""]","[""deep learning"", ""semi-supervised segmentation"", ""semantic segmentation"", ""CNN""]",We design a two-branch semi-supervised segmentation system consisting of a segmentation network and an auxiliary CNN network that validates labels (ground-truth) on the unlabeled images,,,,
BkxGAREYwB,2020,Reject,False,Deep Expectation-Maximization in Hidden Markov Models via Simultaneous Perturbation Stochastic Approximation,"[""Chong Li"", ""Dan Shen"", ""C.J. Richard Shi"", ""Hongxia Yang""]","[""recommender system"", ""gradient approximation"", ""Hidden Markov Model""]",We rendered Expectation-Maximization iteration as a network layer by approximating its gradient.,,,,
BkxREeHKPS,2020,Reject,False,On the Parameterization of Gaussian Mean Field Posteriors in Bayesian Neural Networks,"[""Jakub \u015awi\u0105tkowski"", ""Kevin Roth"", ""Bastiaan S. Veeling"", ""Linh Tran"", ""Joshua V. Dillon"", ""Jasper Snoek"", ""Stephan Mandt"", ""Tim Salimans"", ""Rodolphe Jenatton"", ""Sebastian Nowozin""]","[""variational Bayes"", ""Bayesian neural networks"", ""mean field""]","Mean field VB uses twice as many parameters; we tie variance parameters in mean field VB without any loss in ELBO, gaining speed and lower variance gradients.",,,,
BkxRRkSKwr,2020,Accept (Spotlight),False,Towards Hierarchical Importance Attribution: Explaining Compositional Semantics for Neural Sequence Models,"[""Xisen Jin"", ""Zhongyu Wei"", ""Junyi Du"", ""Xiangyang Xue"", ""Xiang Ren""]","[""natural language processing"", ""interpretability""]",We propose measurement of phrase importance and algorithms for hierarchical explanation of neural sequence model predictions,1911.06194,cs.CL,2019-11-08 03:25:04+00:00,2020-06-15 05:47:05+00:00
BkxSHsC5FQ,2019,Reject,False,SupportNet: solving catastrophic forgetting in class incremental learning with support data,"[""Yu Li"", ""Zhongxiao Li"", ""Lizhong Ding"", ""Yijie Pan"", ""Chao Huang"", ""Yuhui Hu"", ""Wei Chen"", ""Xin Gao""]",[],,,,,
BkxSmlBFvr,2020,Accept (Poster),False,You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings,"[""Daniel Ruffinelli"", ""Samuel Broscheit"", ""Rainer Gemulla""]","[""knowledge graph embeddings"", ""hyperparameter optimization""]",We study the impact of training strategies on the performance of knowledge graph embeddings.,,,,
BkxUvnEYDH,2020,Accept (Spotlight),False,Program Guided Agent,"[""Shao-Hua Sun"", ""Te-Lin Wu"", ""Joseph J. Lim""]","[""Program Execution"", ""Program Executor"", ""Program Understanding"", ""Program Guided Agent"", ""Learning to Execute"", ""Deep Learning""]",We propose a modular framework that can accomplish tasks specified by programs and achieve zero-shot generalization to more complex tasks.,,,,
BkxWJnC9tX,2019,Accept (Poster),False,Diversity and Depth in Per-Example Routing Models,"[""Prajit Ramachandran"", ""Quoc V. Le""]","[""conditional computation"", ""routing models"", ""depth""]","Per-example routing models benefit from architectural diversity, but still struggle to scale to a large number of routing decisions.",,,,
BkxX30EFPS,2020,Reject,False,Perceptual Generative Autoencoders,"[""Zijun Zhang"", ""Ruixiang Zhang"", ""Zongpeng Li"", ""Yoshua Bengio"", ""Liam Paull""]",[],,,,,
BkxXe0Etwr,2020,Accept (Poster),True,CAQL: Continuous Action Q-Learning,"[""Moonkyung Ryu"", ""Yinlam Chow"", ""Ross Anderson"", ""Christian Tjandraatmadja"", ""Craig Boutilier""]","[""Reinforcement learning (RL)"", ""DQN"", ""Continuous control"", ""Mixed-Integer Programming (MIP)""]",A general framework of value-based reinforcement learning for continuous control,1909.12397,cs.LG,2019-09-26 21:16:17+00:00,2020-02-28 19:29:14+00:00
Bkx_Dj09tQ,2019,Reject,False,Causal importance of orientation selectivity for generalization in image recognition,"[""Jumpei Ukita""]","[""deep learning"", ""generalization"", ""selectivity"", ""neuroscience""]",,,,,
BkxackSKvH,2020,Reject,False,Learning Entailment-Based Sentence Embeddings from Natural Language Inference,"[""Rabeeh Karimi Mahabadi*"", ""Florian Mai*"", ""James Henderson""]","[""sentence embeddings"", ""textual entailment"", ""natural language inference"", ""interpretability""]",We propose a natural language inference model whose interaction layer imposes a direct interpretation of the induced sentence embeddings in terms of entailment and contradiction.,,,,
BkxadR4KvS,2020,Reject,False,Insights on Visual Representations for Embodied Navigation Tasks,"[""Erik Wijmans"", ""Julian Straub"", ""Irfan Essa"", ""Dhruv Batra"", ""Judy Hoffman"", ""Ari Morcos""]",[],,,,,
Bkxbrn0cYX,2019,Accept (Poster),False,Selfless Sequential Learning,"[""Rahaf Aljundi"", ""Marcus Rohrbach"", ""Tinne Tuytelaars""]","[""Lifelong learning"", ""Continual Learning"", ""Sequential learning"", ""Regularization""]",A regularization strategy for improving the performance of sequential learning,,,,
Bkxd9JBYPH,2020,Reject,False,Representing Model Uncertainty of Neural Networks in Sparse Information Form,"[""Jongseok Lee"", ""Rudolph Triebel""]","[""Model Uncertainty"", ""Neural Networks"", ""Sparse representation""]",An approximate inference algorithm for deep learning,,,,
BkxdqA4tvB,2020,Reject,True,Collapsed amortized variational inference for switching nonlinear dynamical systems,"[""Zhe Dong"", ""Bryan A. Seybold"", ""Kevin P. Murphy"", ""Hung H. Bui""]",[],,1910.09588,cs.LG,2019-10-21 18:28:10+00:00,2020-02-10 20:02:27+00:00
Bkxdqj0cFQ,2019,Reject,False,Calibration of neural network logit vectors to combat adversarial attacks,"[""Oliver Goldstein""]","[""Adversarial attacks"", ""calibration"", ""probability"", ""adversarial defence""]",This paper uses principles from the field of calibration in machine learning on the logits of a neural network to defend against adversarial attacks,,,,
Bkxe2AVtPS,2020,Accept (Poster),False,Shifted and Squeezed 8-bit Floating Point format for Low-Precision Training of Deep Neural Networks,"[""Leopold Cambier"", ""Anahita Bhiwandiwalla"", ""Ting Gong"", ""Oguz H. Elibol"", ""Mehran Nekuii"", ""Hanlin Tang""]","[""Low-precision training"", ""numerics"", ""deep learning""]","We propose a novel 8-bit format that eliminates the need for loss scaling, stochastic rounding, and other low precision techniques",,,,
BkxfaTVFwH,2020,Accept (Poster),True,GENESIS: Generative Scene Inference and Sampling with Object-Centric Latent Representations,"[""Martin Engelcke"", ""Adam R. Kosiorek"", ""Oiwi Parker Jones"", ""Ingmar Posner""]","[""Generative modelling"", ""object-centric representations"", ""scene generation"", ""variational inference""]",We present the first object-centric generative model of 3D visual scenes capable of both decomposing and generating scenes.,1907.13052,cs.LG,2019-07-30 16:22:39+00:00,2020-11-23 10:31:22+00:00
BkxfshNYwB,2020,Reject,False,Mincut Pooling in Graph Neural Networks,"[""Filippo Maria Bianchi"", ""Daniele Grattarola"", ""Cesare Alippi""]","[""Graph Neural Networks"", ""Pooling"", ""Graph Cuts"", ""Spectral Clustering""]","A new pooling layer for GNNs that learns how to pool nodes, according to their features, the graph connectivity, and the dowstream task objective.",,,,
BkxgbhCqtQ,2019,Reject,False,Predictive Uncertainty through Quantization,"[""Bastiaan S. Veeling"", ""Rianne van den Berg"", ""Max Welling""]","[""variational inference"", ""information bottleneck"", ""bayesian deep learning"", ""latent variable models"", ""amortized variational inference"", ""uncertainty"", ""learning non-linearities""]","A novel tractable and flexible variational distribution through quantization of latent variables, applied to the deep variational information bottleneck objective for improved uncertainty.",,,,
BkxgrAVFwH,2020,Reject,False,Wasserstein-Bounded Generative Adversarial Networks,"[""Peng Zhou"", ""Bingbing Ni"", ""Lingxi Xie"", ""Xiaopeng Zhang"", ""Hang Wang"", ""Cong Geng"", ""Qi Tian""]","[""GAN"", ""WGAN"", ""GENERATIVE ADVERSARIAL NETWORKS""]",Propose an improved framework for WGANs and demonstrate its better performance in theory and practice.,,,,
BkxkH30cFm,2019,Reject,False,Object-Oriented Model Learning through Multi-Level Abstraction,"[""Guangxiang Zhu"", ""Jianhao Wang"", ""ZhiZhou Ren"", ""Chongjie Zhang""]","[""action-conditioned dynamics learning"", ""deep learning"", ""generalization"", ""interpretability"", ""sample efficiency""]",,,,,
BkxoglrtvH,2020,Reject,False,Layerwise Learning Rates for Object Features in Unsupervised and Supervised Neural Networks And Consequent Predictions for the Infant Visual System,"[""Rhodri Cusack"", ""Cliona O'Doherty"", ""Anna Birbeck"", ""Anna Truzzi""]","[""deep learning"", ""unsupervised"", ""supervised"", ""infant learning"", ""age of acquisition"", ""DeepCluster"", ""CORnet"", ""AlexNet""]",Unsupervised networks learn from bottom up; machines and infants acquire visual classes in different orders,,,,
Bkxonh4Ywr,2020,Reject,False,Localizing and Amortizing: Efficient Inference for Gaussian Processes,"[""Linfeng Liu"", ""Liping Liu""]","[""Gaussian Processes"", ""Variational Inference"", ""Amortized Inference"", ""Nearest Neighbors""]",A scalable variational inference for GP leveraging nearest neighbors and amortization.,,,,
BkxpMTEtPB,2020,Accept (Poster),False,GLAD: Learning Sparse Graph Recovery,"[""Harsh Shrivastava"", ""Xinshi Chen"", ""Binghong Chen"", ""Guanghui Lan"", ""Srinivas Aluru"", ""Han Liu"", ""Le Song""]","[""Meta learning"", ""automated algorithm design"", ""learning structure recovery"", ""Gaussian graphical models""]",A data-driven learning algorithm based on unrolling the Alternating Minimization optimization for sparse graph recovery.,,,,
BkxtNaEYDr,2020,Reject,True,Learning Boolean Circuits with Neural Networks,"[""Eran Malach"", ""Shai Shalev-Shwartz""]","[""neural-networks"", ""deep learning theory""]",,1910.11923,cs.LG,2019-10-25 20:26:13+00:00,2020-01-18 11:51:02+00:00
BkxthxHYvr,2020,Reject,False,Conditional generation of molecules from disentangled representations,"[""Amina Mollaysa"", ""Brooks Paige"", ""Alexandros  Kalousis""]","[""molecule generation"", ""disentangling""]",,,,,
Bkxv90EKPB,2020,Accept (Poster),False,Bayesian Meta Sampling for Fast Uncertainty Adaptation,"[""Zhenyi Wang"", ""Yang Zhao"", ""Ping Yu"", ""Ruiyi Zhang"", ""Changyou Chen""]","[""Bayesian Sampling"", ""Uncertainty Adaptation"", ""Meta Learning"", ""Variational Inference""]",We proposed a Bayesian meta sampling method for adapting the model uncertainty in meta learning,,,,
BkxzsT4Yvr,2020,Reject,True,Deep Gradient Boosting -- Layer-wise Input Normalization of Neural Networks,"[""Erhan Bilal""]","[""sgd"", ""dgb"", ""boosting"", ""batch norm"", ""input norm""]",What can we learn about training neural networks if we treat each layer as a gradient boosting problem?,1907.12608,cs.LG,2019-07-29 19:24:40+00:00,2020-07-02 17:03:26+00:00
BkzeUiRcY7,2019,Accept (Poster),False,M^3RL: Mind-aware Multi-agent Management Reinforcement Learning,"[""Tianmin Shu"", ""Yuandong Tian""]","[""Multi-agent Reinforcement Learning"", ""Deep Reinforcement Learning""]",We propose Mind-aware Multi-agent Management Reinforcement Learning (M^3RL) for training a manager to motivate self-interested workers to achieve optimal collaboration by assigning suitable contracts to them.,,,,
Bl8CQrx2Up4,2022,Accept (Poster),False,cosFormer: Rethinking Softmax In Attention,"['Qin Zhen', 'Weixuan Sun', 'Hui Deng', 'Dongxu Li', 'Yunshen Wei', 'Baohong Lv', 'Junjie Yan', 'Lingpeng Kong', 'Yiran Zhong']","[""Linear Transformer"", ""softmax attention""]",A new linear transformer.,,,,
BlyXYc4wF2-,2022,Reject,False,Multi-Agent Constrained Policy Optimisation ,"['Shangding Gu', 'Jakub Grudzien Kuba', 'Muning Wen', 'Ruiqing Chen', 'Ziyan Wang', 'Zheng Tian', 'Jun Wang', 'Alois Knoll', 'Yaodong Yang']","[""Safe Multi-Agent Reinforcement Learning"", ""Safe Multi-Agent Trust Region Policy Optimisation"", ""Safe Multi-Agent Proximal Policy Optimisation"", ""Constrained Policy Optimisation""]",,,,,
BmJV7kyAmg,2022,Accept (Poster),False,Towards Understanding the Robustness Against Evasion Attack on Categorical Data,"['Hongyan Bao', 'Yufei Han', 'Yujun Zhou', 'Yun Shen', 'Xiangliang Zhang']","[""robustness certification"", ""adversarial learning"", ""categorical data""]",This paper explores the characterization and certification of the robustness against evasion attack with categorical input.,,,,
Bn09TnDngN,2022,Accept (Poster),True,How to Inject Backdoors with Better Consistency: Logit Anchoring on Clean Data,"['Zhiyuan Zhang', 'Lingjuan Lyu', 'Weiqiang Wang', 'Lichao Sun', 'Xu Sun']","[""backdoor learning"", ""weight perturbation"", ""consistency""]",We propose a novel logit anchoring approach for better global and instance-wise consistency in backdoor learning.,2109.01300,cs.LG,2021-09-03 03:59:10+00:00,2021-09-03 03:59:10+00:00
BnQhMqDfcKG,2022,Accept (Spotlight),False,Probabilistic Implicit Scene Completion,"['Dongsu Zhang', 'Changwoon Choi', 'Inbum Park', 'Young Min Kim']","[""3D shape completion"", ""3D generative model""]",We propose a scalable generative model for multi-modal completion of 3D scenes in implicit representation.,,,,
BnokSKnhC7F,2021,Reject,False,Maximum Reward Formulation In Reinforcement Learning,"[""SaiKrishna Gottipati"", ""Yashaswi Pathak"", ""Rohan Nuttall"", "". Sahir"", ""Raviteja Chunduru"", ""Ahmed Touati"", ""Sriram Ganapathi Subramanian"", ""Matthew E. Taylor"", ""Sarath Chandar""]","[""Reinforcement Learning"", ""Theoretical Reinforcement Learning"", ""Drug Discovery"", ""Molecule Generation"", ""de novo drug design""]","Introduces a new functional form of bellman equation, provides convergence proof, and demonstrates state-of-the-art results on the task of molecule generation.",,,,
BntruCi1uvF,2021,Reject,False,Truly Deterministic Policy Optimization,"[""Ehsan Saleh"", ""Saba Ghaffari"", ""Matthew West"", ""Tim Bretl""]","[""Deterministic Policy Gradient"", ""Deterministic Exploration"", ""Reinforcement Learning""]","We introduce a policy gradient method capable of fully deterministic policy search (i.e., without injection of noise), and show its supremacy on two novel tasks involving frequency-based rewards and long horizons.",,,,
Bpw_O132lWT,2021,Reject,False,Dynamic of Stochastic Gradient Descent with State-dependent Noise,"[""Qi Meng"", ""Shiqi Gong"", ""Wei Chen"", ""Zhi-Ming Ma"", ""Tie-Yan Liu""]","[""state-dependent noise"", ""power-law dynamic"", ""stochastic gradient descent"", ""generalization"", ""deep neural network"", ""heavy-tailed"", ""escape time""]","We propose a novel power-law dynamic with state-dependent diffusion to approximate the dynamic of SGD, and analyze escaping efficiency and PAC-Bayesian generalization bound for it.",,,,
BrFIKuxrZE,2022,Accept (Poster),False,Fair Normalizing Flows,"['Mislav Balunovic', 'Anian Ruoss', 'Martin Vechev']","[""fairness"", ""fair representation learning"", ""adversarial fairness"", ""trustworthy machine learning""]",We propose a new fair representation learning method based on normalizing flows which can bound the accuracy of any adversary trying to predict sensitive attributes. ,,,,
BrPdX1bDZkQ,2022,Accept (Poster),False,DemoDICE: Offline Imitation Learning with Supplementary Imperfect Demonstrations,"['Geon-Hyeong Kim', 'Seokin Seo', 'Jongmin Lee', 'Wonseok Jeon', 'HyeongJoo Hwang', 'Hongseok Yang', 'Kee-Eung Kim']","[""imitation learning"", ""offline imitation learning"", ""imperfect demonstration"", ""non-expert demonstration""]",,,,,
BrfHcL-99sy,2022,Reject,False,Defending Graph Neural Networks via Tensor-Based Robust Graph Aggregation,"['Jianfu Zhang', 'Yan Hong', 'Dawei Cheng', 'Liqing Zhang', 'Qibin Zhao']","[""Graph Neural Networks"", ""Adversarial Attacks"", ""Robustness"", ""Tensor Decomposition""]",A tensor-based method to improve robustness of graph neural network models against adversarial attacks.,,,,
BsDYmsrCjr,2022,Reject,False,Scalable Robust Federated Learning with Provable Security Guarantees,"['Andrew Liu', 'Jacky Y. Zhang', 'Nishant Kumar', 'Dakshita Khurana', 'Oluwasanmi O Koyejo']","[""Federated Learning"", ""Robustness"", ""MPC"", ""Privacy Preserving ML""]",Private and Robust Federated Learning that uses Approximate Median heuristic.,,,,
BtZhsSGNRNi,2021,Accept (Poster),False,Coping with Label Shift via Distributionally Robust Optimisation,"[""Jingzhao Zhang"", ""Aditya Krishna Menon"", ""Andreas Veit"", ""Srinadh Bhojanapalli"", ""Sanjiv Kumar"", ""Suvrit Sra""]","[""Label shift"", ""distributional robust optimization""]","We propose an objective to cope with label shift, and provide an adversarial algorithm to effectively optimize it.",,,,
BvrKnFq_454,2021,Reject,False,Expectigrad: Fast Stochastic Optimization with Robust Convergence Properties,"[""Brett Daley"", ""Christopher Amato""]","[""deep learning"", ""gradient descent"", ""optimization""]",Expectigrad is an adaptive method that converges on a wider class of optimization problems and performs well in practice.,,,,
Bw7VC-DJUM,2021,Reject,True,Learning Spatiotemporal Features via Video and Text Pair Discrimination,"[""Tianhao Li"", ""Limin Wang""]","[""Spatiotemporal Feature Learning"", ""Video and Text Pair Discrimination"", ""Self-/Weakly Supervised Learning""]",An efficient spatiotemporal feature learning method via video and text discrimination.,2001.05691,cs.CV,2020-01-16 08:28:57+00:00,2021-01-28 01:43:34+00:00
BwPaPxwgyQb,2022,Accept (Poster),False,Provable Learning-based Algorithm For Sparse Recovery,"['Xinshi Chen', 'Haoran Sun', 'Le Song']","[""learning to learn"", ""sparse parameter estimation"", ""learning to optimize"", ""algorithm unrolling"", ""generalization bound""]",,,,,
Bx05YH2W8bE,2021,Reject,False,DyHCN: Dynamic Hypergraph Convolutional Networks,"[""Nan Yin"", ""zhigang luo"", ""wenjie wang"", ""Fuli Feng"", ""Xiang Zhang""]",[],,,,,
By-7dz-AZ,2018,Accept (Poster),False,A Framework for the Quantitative Evaluation of Disentangled Representations,"[""Cian Eastwood"", ""Christopher K. I. Williams""]",[],,,,,
By-IifZRW,2018,Reject,False,Gaussian Process Neurons,"[""Sebastian Urban"", ""Patrick van der Smagt""]","[""gaussian process neuron activation function stochastic transfer function learning variational bayes probabilistic""]",We model the activation function of each neuron as a Gaussian Process and learn it alongside the weight with Variational Inference.,,,,
By0ANxbRW,2018,Reject,False,DNN Model Compression Under Accuracy Constraints,"[""Soroosh Khoram"", ""Jing Li""]","[""DNN Compression"", ""Weigh-sharing"", ""Model Compression""]",Compressing trained DNN models by minimizing their complexity while constraining their loss.,,,,
By14kuqxx,2017,Invite to Workshop Track,False,Bit-Pragmatic Deep Neural Network Computing,"[""Jorge Albericio"", ""Patrick Judd"", ""Alberto Delmas"", ""Sayeh Sharify"", ""Andreas Moshovos""]","[""Deep learning"", ""Applications""]",A hardware accelerator for DNNs whose execution time for convolutional layers is proportional to the number of activation *bits* that are 1.,,,,
By1snw5gl,2017,Reject,False,L-SR1: A Second Order Optimization Method for Deep Learning,"[""Vivek Ramamurthy"", ""Nigel Duffy""]",[],"We describe L-SR1, a new second order method to train deep neural networks.",,,,
By3VrbbAb,2018,Reject,False,Realtime query completion via deep language models,"[""Po-Wei Wang"", ""J. Zico Kolter"", ""Vijai Mohan"", ""Inderjit S. Dhillon""]","[""query completion"", ""realtime"", ""error correction"", ""recurrent network"", ""beam search""]",realtime search query completion using character-level LSTM language models,,,,
By3v9k-RZ,2018,Invite to Workshop Track,False,LEARNING TO ORGANIZE KNOWLEDGE WITH N-GRAM MACHINES,"[""Fan Yang"", ""Jiazhong Nie"", ""William W. Cohen"", ""Ni Lao""]","[""neuro-symbolic reasoning"", ""information extraction"", ""learn to search""]",We propose a framework that learns to encode knowledge symbolically and generate programs to reason about the encoded knowledge.,,,,
By40DoAqtX,2019,Reject,False,Learning Discriminators as Energy Networks in Adversarial Learning,"[""Pingbo Pan"", ""Yan Yan"", ""Tianbao Yang"", ""Yi Yang""]","[""adversarial learning"", ""structured prediction"", ""energy networks""]","We propose a novel adversarial learning framework for structured prediction, in which discriminative models can be used to refine structured prediction models at the inference stage. ",,,,
By41BjA9YQ,2019,Reject,False,Laplacian Smoothing Gradient Descent,"[""Stanley J. Osher"", ""Bao Wang"", ""Penghang Yin"", ""Xiyang Luo"", ""Minh Pham"", ""Alex T. Lin""]","[""Laplacian Smoothing"", ""Nonconvex Optimization"", ""Deep Learning""]",We proposal a simple surrogate for gradient descent to improve training of deep neural nets and other optimization problems.,,,,
By4HsfWAZ,2018,Accept (Poster),False,Deep Learning for Physical Processes: Incorporating Prior Scientific Knowledge,"[""Emmanuel de Bezenac"", ""Arthur Pajot"", ""Patrick Gallinari""]","[""deep learning"", ""physical processes"", ""forecasting"", ""spatio-temporal""]",,,,,
By5SY2gA-,2018,Reject,False,Towards Building Affect sensitive Word Distributions,"[""Kushal Chawla"", ""Sopan Khosla"", ""Niyati Chhaya"", ""Kokil Jaidka""]","[""Affect lexicon"", ""word embeddings"", ""Word2Vec"", ""GloVe"", ""WordNet"", ""joint learning"", ""sentiment analysis"", ""word similarity"", ""outlier detection"", ""affect prediction""]",Enriching word embeddings with affect information improves their performance on sentiment prediction tasks.,,,,
By5Uwd_xzNF,2022,Reject,False,Neural Structure Mapping For Learning Abstract Visual Analogies,"['Shashank Shekhar', 'Graham W. Taylor']","[""cognitive science"", ""analogy"", ""psychology"", ""cognitive theory"", ""cognition"", ""abstraction"", ""abstract reasoning"", ""generalization"", ""systematic generalization""]",We introduce a two-stage Neural Structure Mapping framework for systematic analogical reasoning,,,,
By5e2L9gl,2017,Accept (Poster),False,Trusting SVM for Piecewise Linear CNNs,"[""Leonard Berrada"", ""Andrew Zisserman"", ""M. Pawan Kumar""]",[],Formulating CNN layerwise optimization as an SVM problem,,,,
By5ugjyCb,2018,Reject,False,PACT: Parameterized Clipping Activation for Quantized Neural Networks,"[""Jungwook Choi"", ""Zhuo Wang"", ""Swagath Venkataramani"", ""Pierce I-Jen Chuang"", ""Vijayalakshmi Srinivasan"", ""Kailash Gopalakrishnan""]","[""deep learning"", ""quantized deep neural network"", ""activation quantization""]",A new way of quantizing activation of Deep Neural Network via parameterized clipping which optimizes the quantization scale via stochastic gradient descent.,,,,
By9iRkWA-,2018,Reject,False,Phase Conductor on Multi-layered Attentions for Machine Comprehension,"[""Rui Liu"", ""Wei Wei"", ""Weiguang Mao"", ""Maria Chikina""]","[""Attention Model"", ""Machine Comprehension"", ""Question Answering""]",,,,,
ByBAl2eAZ,2018,Accept (Poster),False,Parameter Space Noise for Exploration,"[""Matthias Plappert"", ""Rein Houthooft"", ""Prafulla Dhariwal"", ""Szymon Sidor"", ""Richard Y. Chen"", ""Xi Chen"", ""Tamim Asfour"", ""Pieter Abbeel"", ""Marcin Andrychowicz""]","[""reinforcement learning"", ""exploration"", ""parameter noise""]","Parameter space noise allows reinforcement learning algorithms to explore by perturbing parameters instead of actions, often leading to significantly improved exploration performance.",,,,
ByBwSPcex,2017,Invite to Workshop Track,False,Song From PI: A Musically Plausible Network for Pop Music Generation,"[""Hang Chu"", ""Raquel Urtasun"", ""Sanja Fidler""]","[""Applications""]","We present a novel hierarchical RNN for generating pop music, where the layers and the structure of the hierarchy encode our prior knowledge about how pop music is composed.",,,,
ByC7ww9le,2017,Reject,False,Gaussian Attention Model and Its Application to Knowledge Base Embedding and Question Answering,"[""Liwen Zhang"", ""John Winn"", ""Ryota Tomioka""]","[""Natural language processing"", ""Supervised Learning"", ""Deep learning""]",We make (simple) knowledge base queries differentiable using the Gaussian attention model.,,,,
ByCPHrgCW,2018,Reject,False,Deep Learning Inferences with Hybrid Homomorphic Encryption,"[""Anthony Meehan"", ""Ryan K L Ko"", ""Geoff Holmes""]","[""deep learning"", ""homomorphic encryption"", ""hybrid homomorphic encryption"", ""privacy preserving"", ""representation learning"", ""neural networks""]","We made a feature-rich system for deep learning with encrypted inputs, producing encrypted outputs, preserving privacy.",,,,
ByED-X-0W,2018,Reject,False,Parametric Information Bottleneck to Optimize Stochastic Neural Networks,"[""Thanh T. Nguyen"", ""Jaesik Choi""]","[""Information Bottleneck"", ""Deep Neural Networks""]",Learning a better neural networks' representation with Information Bottleneck principle,,,,
ByEPMj5el,2017,Reject,False,Out-of-class novelty generation: an experimental foundation,"[""Mehdi Cherti"", ""Bal\u00e1zs K\u00e9gl"", ""Ak\u0131n Kazak\u00e7\u0131""]","[""Deep learning"", ""Unsupervised Learning""]",,,,,
ByEtPiAcY7,2019,Reject,False,Characterizing the Accuracy/Complexity Landscape of Explanations of Deep Networks through Knowledge Extraction,"[""Simon Odense"", ""Artur d'Avila Garcez""]","[""Deep Networks"", ""Explainability"", ""Knowledge Extraction""]",Systematically examines how well we can explain the hidden features of a deep network in terms of logical rules.,,,,
ByG4hz5le,2017,Invite to Workshop Track,False,Adaptive Feature Abstraction for Translating Video to Language,"[""Yunchen Pu"", ""Martin Renqiang Min"", ""Zhe Gan"", ""Lawrence Carin""]","[""Computer vision"", ""Deep learning""]",,,,,
ByG8A7cee,2017,Reject,False,Reference-Aware Language Models,"[""Zichao Yang"", ""Phil Blunsom"", ""Chris Dyer"", ""Wang Ling""]","[""Natural language processing"", ""Deep learning""]",reference-aware language models,,,,
ByGOuo0cYm,2019,Reject,False,Meta-Learning with Domain Adaptation for Few-Shot Learning under Domain Shift,"[""Doyen Sahoo"", ""Hung Le"", ""Chenghao Liu"", ""Steven C. H. Hoi""]","[""Meta-Learning"", ""Few-Shot Learning"", ""Domain Adaptation""]",Meta Learning for Few Shot learning assumes that training tasks and test tasks are drawn from the same distribution. What do you do if they are not? Meta Learning with task-level Domain Adaptation!,,,,
ByGUFsAqYm,2019,Reject,False,Downsampling leads to Image Memorization in Convolutional Autoencoders,"[""Adityanarayanan Radhakrishnan"", ""Caroline Uhler"", ""Mikhail Belkin""]","[""Memorization in Deep Learning"", ""Convolutional Autoencoders""]",We identify downsampling as a mechansim for memorization in convolutional autoencoders.,,,,
ByGVui0ctm,2019,Reject,False,Three continual learning scenarios and a case for generative replay,"[""Gido M. van de Ven"", ""Andreas S. Tolias""]","[""continual learning"", ""generative models"", ""replay"", ""distillation"", ""variational autoencoder""]",A newly introduced structured comparison of recent methods for continual learning that turns into an argument for and extension of generative replay.,,,,
ByG_3s09KX,2019,Reject,False,Dopamine: A Research Framework for Deep Reinforcement Learning,"[""Pablo Samuel Castro"", ""Subhodeep Moitra"", ""Carles Gelada"", ""Saurabh Kumar"", ""Marc G. Bellemare""]","[""reinforcement learning"", ""software"", ""framework"", ""reproducibility""]","In this paper we introduce Dopamine, a new research framework for deep RL that is open-source, TensorFlow-based, and provides compact yet reliable implementations of some state-of-the-art deep RL agents.",1812.06110,cs.LG,2018-12-14 19:03:38+00:00,2018-12-14 19:03:38+00:00
ByGq7hRqKX,2019,Reject,False,Cross-Task Knowledge Transfer for Visually-Grounded Navigation,"[""Devendra Singh Chaplot"", ""Lisa Lee"", ""Ruslan Salakhutdinov"", ""Devi Parikh"", ""Dhruv Batra""]",[],,1902.01385,cs.LG,2019-02-04 18:53:14+00:00,2019-02-04 18:53:14+00:00
ByGuynAct7,2019,Accept (Poster),False,The Deep Weight Prior,"[""Andrei Atanov"", ""Arsenii Ashukha"", ""Kirill Struminsky"", ""Dmitriy Vetrov"", ""Max Welling""]","[""deep learning"", ""variational inference"", ""prior distributions""]","The generative model for kernels of convolutional neural networks, that acts as a prior distribution while training on new datasets.",,,,
ByIAPUcee,2017,Accept (Poster),False,Frustratingly Short Attention Spans in Neural Language Modeling,"[""Micha\u0142 Daniluk"", ""Tim Rockt\u00e4schel"", ""Johannes Welbl"", ""Sebastian Riedel""]","[""Natural language processing"", ""Deep learning""]",We investigate various memory-augmented neural language models and compare them against state-of-the-art architectures.,,,,
ByJ7obb0b,2018,Reject,False,Understanding and Exploiting the Low-Rank Structure of Deep Networks,"[""Craig Bakker"", ""Michael J. Henry"", ""Nathan O. Hodas""]","[""Deep Learning"", ""Derivative Calculations"", ""Optimization Algorithms""]","We show that deep learning network derivatives have a low-rank structure, and this structure allows us to use second-order derivative information to calculate learning rates adaptively and in a computationally feasible manner.",,,,
ByJDAIe0b,2018,Reject,False,Integrating Episodic Memory into a Reinforcement Learning Agent Using Reservoir Sampling,"[""Kenny J. Young"", ""Shuo Yang"", ""Richard S. Sutton""]","[""reinforcement learning"", ""external memory"", ""deep learning"", ""policy gradient"", ""online learning""]",External memory for online reinforcement learning based on estimating gradients over a novel reservoir sampling technique.,,,,
ByJHuTgA-,2018,Accept (Poster),False,On the State of the Art of Evaluation in Neural Language Models,"[""G\u00e1bor Melis"", ""Chris Dyer"", ""Phil Blunsom""]","[""rnn"", ""language modelling""]",Show that LSTMs are as good or better than recent innovations for LM and that model evaluation is often unreliable.,,,,
ByJIWUnpW,2018,Accept (Poster),False,Automatically Inferring Data Quality for Spatiotemporal Forecasting,"[""Sungyong Seo"", ""Arash Mohegh"", ""George Ban-Weiss"", ""Yan Liu""]","[""spatiotemporal data"", ""graph convolutional network"", ""data quality""]",We propose a method that infers the time-varying data quality level for spatiotemporal forecasting without explicitly assigned labels.,,,,
ByJWeR1AW,2018,Reject,False,Data augmentation instead of explicit regularization,"[""Alex Hern\u00e1ndez-Garc\u00eda"", ""Peter K\u00f6nig""]","[""deep learning"", ""data augmentation"", ""regularization""]","In a deep convolutional neural network trained with sufficient level of data augmentation, optimized by SGD, explicit regularizers (weight decay and dropout) might not provide any additional generalization improvement.",,,,
ByJbJwxCW,2018,Reject,False,Relational Multi-Instance Learning for Concept Annotation from Medical Time Series,"[""Sanjay Purushotham"", ""Zhengping Che"", ""Bo Jiang"", ""Tanachat Nilanon"", ""Yan Liu""]","[""Multi-instance learning"", ""Medical Time Series"", ""Concept Annotation""]",We propose a deep Multi Instance Learning framework based on recurrent neural networks which uses pooling functions and attention mechanisms for the concept annotation tasks.,,,,
ByKWUeWA-,2018,Accept (Poster),False,GANITE: Estimation of Individualized Treatment Effects using Generative Adversarial Nets,"[""Jinsung Yoon"", ""James Jordon"", ""Mihaela van der Schaar""]","[""Individualized Treatment Effects"", ""Counterfactual Estimation"", ""Generative Adversarial Nets""]",,,,,
ByL48G-AW,2018,Reject,False,Simple Nearest Neighbor Policy Method for Continuous Control Tasks,"[""Elman Mansimov"", ""Kyunghyun Cho""]","[""nearest neighbor"", ""reinforcement learning"", ""policy"", ""continuous control""]",,,,,
ByME42AqK7,2019,Accept (Poster),True,Efficient Multi-Objective Neural Architecture Search via Lamarckian Evolution,"[""Thomas Elsken"", ""Jan Hendrik Metzen"", ""Frank Hutter""]","[""Neural Architecture Search"", ""AutoML"", ""AutoDL"", ""Deep Learning"", ""Evolutionary Algorithms"", ""Multi-Objective Optimization""]",We propose a method for efficient Multi-Objective Neural Architecture Search based on Lamarckian inheritance and evolutionary algorithms.,1804.09081,stat.ML,2018-04-24 15:01:07+00:00,2019-02-26 16:06:36+00:00
ByMHvs0cFQ,2019,Accept (Poster),False,Quaternion Recurrent Neural Networks,"[""Titouan Parcollet"", ""Mirco Ravanelli"", ""Mohamed Morchid"", ""Georges Linar\u00e8s"", ""Chiheb Trabelsi"", ""Renato De Mori"", ""Yoshua Bengio""]","[""Quaternion recurrent neural networks"", ""quaternion numbers"", ""recurrent neural networks"", ""speech recognition""]",,,,,
ByMVTsR5KQ,2019,Accept (Poster),False,Adversarial Audio Synthesis,"[""Chris Donahue"", ""Julian McAuley"", ""Miller Puckette""]","[""audio"", ""waveform"", ""spectrogram"", ""GAN"", ""adversarial"", ""WaveGAN"", ""SpecGAN""]",Learning to synthesize raw waveform audio with GANs,,,,
ByN7Yo05YX,2019,Reject,False,Adaptive Neural Trees,"[""Ryutaro Tanno"", ""Kai Arulkumaran"", ""Daniel C. Alexander"", ""Antonio Criminisi"", ""Aditya Nori""]","[""neural networks"", ""decision trees"", ""computer vision""]","We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.",,,,
ByOExmWAb,2018,Accept (Poster),False,MaskGAN: Better Text Generation via Filling in the _______,"[""William Fedus"", ""Ian Goodfellow"", ""Andrew M. Dai""]","[""Deep learning"", ""GAN""]",Natural language GAN for filling in the blank,,,,
ByOK0rwlx,2017,Reject,False,Ternary Weight Decomposition and Binary Activation Encoding for Fast and Compact Neural Network,"[""Mitsuru Ambai"", ""Takuya Matsumoto"", ""Takayoshi Yamashita"", ""Hironobu Fujiyoshi""]","[""Deep learning""]",,,,,
ByOfBggRZ,2018,Accept (Poster),False,Detecting Statistical Interactions from Neural Network Weights,"[""Michael Tsang"", ""Dehua Cheng"", ""Yan Liu""]","[""statistical interaction detection"", ""multilayer perceptron"", ""generalized additive model""]",We detect statistical interactions captured by a feedforward multilayer neural network by directly interpreting its learned weights.,,,,
ByOnmlWC-,2018,Accept (Poster),False,Policy Optimization by Genetic Distillation ,"[""Tanmay Gangwani"", ""Jian Peng""]","[""Genetic algorithms"", ""deep reinforcement learning"", ""imitation learning""]",Genetic algorithms based approach for optimizing deep neural network policies,,,,
ByOvsIqeg,2017,Accept (Poster),False,Regularizing CNNs with Locally Constrained Decorrelations,"[""Pau Rodr\u00edguez"", ""Jordi Gonz\u00e0lez"", ""Guillem Cucurull"", ""Josep M. Gonfaus"", ""Xavier Roca""]","[""Computer vision"", ""Deep learning"", ""Optimization""]",We show that that models regularized with local feature decorrelation have lower overfitting.,,,,
ByQPVFull,2017,Reject,False,Training Group Orthogonal Neural Networks with Privileged Information,"[""Yunpeng Chen"", ""Xiaojie Jin"", ""Jiashi Feng"", ""Shuicheng Yan""]","[""Deep learning"", ""Computer vision"", ""Supervised Learning""]",A convolutional neural network for image classification which encourages learning more diverse feature representations by using image segmentations as privileged information.,,,,
ByQZjx-0-,2018,Invite to Workshop Track,False,Faster Discovery of Neural Architectures by Searching for Paths in a Large Model,"[""Hieu Pham"", ""Melody Y. Guan"", ""Barret Zoph"", ""Quoc V. Le"", ""Jeff Dean""]","[""neural architecture search""]","An approach that speeds up neural architecture search by 10x, whilst using 100x less computing resource.",,,,
ByQpn1ZA-,2018,Accept (Poster),False,Many Paths to Equilibrium: GANs Do Not Need to Decrease a Divergence At Every Step,"[""William Fedus*"", ""Mihaela Rosca*"", ""Balaji Lakshminarayanan"", ""Andrew M. Dai"", ""Shakir Mohamed"", ""Ian Goodfellow""]","[""Deep learning"", ""GAN""]",We find evidence that divergence minimization may not be an accurate characterization of GAN training.,,,,
ByRWCqvT-,2018,Accept (Poster),False,Learning to cluster in order to transfer across domains and tasks,"[""Yen-Chang Hsu"", ""Zhaoyang Lv"", ""Zsolt Kira""]","[""transfer learning"", ""similarity prediction"", ""clustering"", ""domain adaptation"", ""unsupervised learning"", ""computer vision"", ""deep learning"", ""constrained clustering""]",A learnable clustering objective to facilitate transfer learning across domains and tasks,,,,
ByS1VpgRZ,2018,Accept (Poster),False,cGANs with Projection Discriminator,"[""Takeru Miyato"", ""Masanori Koyama""]","[""Generative Adversarial Networks"", ""GANs"", ""conditional GANs"", ""Generative models"", ""Projection""]","We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model.",,,,
BySRH6CpW,2018,Accept (Poster),False,Learning Discrete Weights Using the Local Reparameterization Trick,"[""Oran Shayer"", ""Dan Levi"", ""Ethan Fetaya""]","[""deep learning"", ""discrete weight network""]",Training binary/ternary networks using local reparameterization with the CLT approximation,,,,
ByToKu9ll,2017,Reject,False,Evaluation of Defensive Methods for DNNs against Multiple Adversarial Evasion Models,"[""Xinyun Chen"", ""Bo Li"", ""Yevgeniy Vorobeychik""]","[""Deep learning""]",robust adversarial retraining,,,,
ByUEelW0-,2018,Reject,False,Modifying memories in a Recurrent Neural Network Unit,"[""Vlad Velici"", ""Adam Pr\u00fcgel-Bennett""]","[""LSTM"", ""RNN"", ""rotation matrix"", ""long-term memory"", ""natural language processing""]",Adding a new set of weights to the LSTM that rotate the cell memory improves performance on some bAbI tasks.,,,,
ByW2Avqgg,2017,Reject,False,Neural Causal Regularization under the Independence of Mechanisms Assumption,"[""Mohammad Taha Bahadori"", ""Krzysztof Chalupka"", ""Edward Choi"", ""Robert Chen"", ""Walter F. Stewart"", ""Jimeng Sun""]","[""Deep learning"", ""Applications""]",We designed a neural causal regularizer to encourage predictive models to be more causal.,,,,
ByW5yxgA-,2018,Reject,False,Multiscale Hidden Markov Models For Covariance Prediction,"[""Jo\u00e3o Sedoc"", ""Jordan Rodu"", ""Dean Foster"", ""Lyle Ungar""]","[""multiscale models"", ""hidden Markov model"", ""covariance prediction""]",,,,,
ByYPLJA6W,2018,Reject,False,Distribution Regression Network,"[""Connie Kou"", ""Hwee Kuan Lee"", ""Teck Khim Ng""]","[""distribution regression"", ""supervised learning"", ""regression analysis""]",A learning network which generalizes the MLP framework to perform distribution-to-distribution regression,,,,
ByZmGjkA-,2018,Reject,False,Understanding Grounded Language Learning Agents,"[""Felix Hill"", ""Karl Moritz Hermann"", ""Phil Blunsom"", ""Stephen Clark""]","[""Language AI Learning Reinforcement Deep""]",Analysing and understanding how neural network agents learn to understand simple grounded language,,,,
ByZvfijeg,2017,Reject,False,Higher Order Recurrent Neural Networks,"[""Rohollah Soltani"", ""Hui Jiang""]","[""Deep learning"", ""Natural language processing""]",we study novel neural network structures to better model long term dependency in sequential data,,,,
Bya8fGWAZ,2018,Invite to Workshop Track,False,Value Propagation Networks,"[""Nantas Nardelli"", ""Gabriel Synnaeve"", ""Zeming Lin"", ""Pushmeet Kohli"", ""Nicolas Usunier""]","[""Learning to plan"", ""Reinforcement Learning"", ""Value Iteration"", ""Navigation"", ""Convnets""]","We propose Value Propagation, a novel end-to-end planner which can learn to solve 2D navigation tasks via Reinforcement Learning, and that generalizes to larger and dynamic environments.",,,,
ByaQIGg0-,2018,Invite to Workshop Track,False,AUTOMATED DESIGN USING NEURAL NETWORKS AND GRADIENT DESCENT,"[""Oliver Hennigh""]","[""Deep Learning"", ""Automated Design"", ""Gradient Descent""]",A method for performing automated design on real world objects such as heat sinks and wing airfoils that makes use of neural networks and gradient descent.,,,,
BybQ7zWCb,2018,Reject,False,âStyleâ Transfer for Musical Audio Using Multiple Time-Frequency Representations,"[""Shaun Barry"", ""Youngmoo Kim""]","[""Musical audio"", ""neural style transfer"", ""Time-Frequency"", ""Spectrogram""]","We present a long time-scale musical audio style transfer algorithm which synthesizes audio in the time-domain, but uses Time-Frequency representations of audio.",,,,
BybtVK9lg,2017,Accept (Poster),False,Autoencoding Variational Inference For Topic Models,"[""Akash Srivastava"", ""Charles Sutton""]","[""Deep learning"", ""Unsupervised Learning"", ""Applications"", ""Optimization""]",We got autoencoding variational bayes to work for latent Dirichlet  allocation using one weird trick. The new inference method then made it  easy to make a new topic model that works even better than LDA.,,,,
BycCx8qex,2017,Reject,False,DRAGNN: A Transition-Based Framework for Dynamically Connected Neural Networks,"[""Lingpeng Kong"", ""Chris Alberti"", ""Daniel Andor"", ""Ivan Bogatyy"", ""David Weiss""]","[""Natural language processing"", ""Deep learning"", ""Multi-modal learning"", ""Structured prediction""]",Modular framework for dynamically unrolled neural architectures improves structured prediction tasks,,,,
Byd-EfWCb,2018,Invite to Workshop Track,False,Decoding Decoders: Finding Optimal Representation Spaces for Unsupervised Similarity Tasks,"[""Vitalii Zhelezniak"", ""Dan Busbridge"", ""April Shen"", ""Samuel L. Smith"", ""Nils Y. Hammerla""]","[""distributed representations"", ""sentence embedding"", ""representation learning"", ""unsupervised learning"", ""encoder-decoder"", ""RNN""]","By introducing the notion of an optimal representation space, we provide a theoretical argument and experimental validation that an unsupervised model for sentences can perform well on both supervised similarity and unsupervised transfer tasks.",,,,
BydARw9ex,2017,Accept (Poster),False,Capacity and Trainability in Recurrent Neural Networks,"[""Jasmine Collins"", ""Jascha Sohl-Dickstein"", ""David Sussillo""]","[""Deep learning""]",,,,,
BydLzGb0Z,2018,Accept (Poster),False,Twin Networks: Matching the Future for Sequence Generation,"[""Dmitriy Serdyuk"", ""Nan Rosemary Ke"", ""Alessandro Sordoni"", ""Adam Trischler"", ""Chris Pal"", ""Yoshua Bengio""]","[""generative rnns"", ""long term dependencies"", ""speech recognition"", ""image captioning""]",The paper introduces a method of training generative recurrent networks that helps to plan ahead. We run a second RNN in a reverse direction and make a soft constraint between cotemporal forward and backward states.,,,,
BydjJte0-,2018,Accept (Poster),False,Towards Reverse-Engineering Black-Box Neural Networks,"[""Seong Joon Oh"", ""Max Augustin"", ""Mario Fritz"", ""Bernt Schiele""]","[""black box"", ""security"", ""privacy"", ""attack"", ""metamodel"", ""adversarial example"", ""reverse-engineering"", ""machine learning""]","Querying a black-box neural network reveals a lot of information about it; we propose novel ""metamodels"" for effectively extracting information from a black box.",,,,
BydrOIcle,2017,Accept (Poster),False,Unrolled Generative Adversarial Networks,"[""Luke Metz"", ""Ben Poole"", ""David Pfau"", ""Jascha Sohl-Dickstein""]","[""Deep learning"", ""Unsupervised Learning"", ""Optimization""]",We introduce a method to stabilize Generative Adversarial Networks by defining the generator objective with respect to an unrolled optimization of the discriminator. ,,,,
Bye-sxHFwB,2020,Reject,False,A Gradient-Based Approach to Neural Networks Structure Learning,"[""Amir Ali Moinfar"", ""Amirkeivan Mohtashami"", ""Mahdieh Soleymani"", ""Ali Sharifi-Zarchi""]",[],,,,,
Bye2uJHYwr,2020,Reject,False,Weighted Empirical Risk Minimization: Transfer Learning based on Importance Sampling,"[""Robin Vogel"", ""Mastane Achab"", ""Charles Tillier"", ""St\u00e9phan Cl\u00e9men\u00e7on""]","[""statistical learning theory"", ""importance sampling"", ""positive unlabeled (PU) learning"", ""selection bias""]","When training and testing distributions are different, importance sampling works for many common practical cases.",,,,
Bye3P1BYwr,2020,Reject,False,Deep End-to-end Unsupervised Anomaly Detection ,"[""Li Tangqing"", ""Wang Zheng"", ""Liu Siying"", ""Daniel Lin Wen-Yan""]",[],,,,,
Bye4iaEFwr,2020,Reject,False,Improving Dirichlet Prior Network for Out-of-Distribution Example Detection,"[""Jay Nandy""]","[""predictive uncertainty"", ""distributional uncertainty"", ""Dirichlet distribution"", ""out-of-distribution detection"", ""deep learning""]",An improved framework for Dirichlet Prior Network for efficient training and detecting OOD examples along with identifying distributional uncertainty.,,,,
Bye5OiR5F7,2019,Reject,False,Wasserstein proximal of GANs,"[""Alex Tong Lin"", ""Wuchen Li"", ""Stanley Osher"", ""Guido Montufar""]","[""Optimal transport"", ""Wasserstein gradient"", ""Generative adversarial network"", ""Unsupervised learning""]",We propose the Wasserstein proximal method for training GANs. ,,,,
Bye5SiAqKX,2019,Accept (Poster),False,Preconditioner on Matrix Lie Group for SGD,"[""Xi-Lin Li""]","[""preconditioner"", ""stochastic gradient descent"", ""Newton method"", ""Fisher information"", ""natural gradient"", ""Lie group""]","We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.",,,,
Bye6weHFvB,2020,Reject,False,Plan2Vec: Unsupervised Representation Learning by Latent Plans,"[""Ge Yang"", ""Amy Zhang"", ""Ari Morcos"", ""Joelle Pineau"", ""Pieter Abbeel"", ""Roberto Calandra""]","[""Unsupervised Learning"", ""Reinforcement Learning"", ""Manifold Learning""]","Plan2Vec poses unsupervised representation learning as an RL problem, to extend local information to a consistent global embedding",,,,
Bye8hREtvB,2020,Reject,False,Natural Image Manipulation for Autoregressive Models Using Fisher Scores,"[""Wilson Yan"", ""Jonathan Ho"", ""Pieter Abbeel""]","[""fisher score"", ""generative models"", ""image interpolation""]",We develop a novel method to perform image interpolation and semantic manipulation using autoregressive models through fisher scores,,,,
Bye9LiR9YX,2019,Reject,True,Remember and Forget for Experience Replay,"[""Guido Novati"", ""Petros Koumoutsakos""]","[""reinforcement learning"", ""experience replay"", ""policy gradients""]",ReF-ER is an Experience Replay algorithm to regulate the pace at which the control policy is allowed to deviate from past behaviors; it is shown to enhance the stability and performance of off-policy RL methods.,1807.05827,cs.LG,2018-07-16 12:57:04+00:00,2019-05-20 10:22:43+00:00
ByeAK1BKPB,2020,Reject,False,Projected Canonical Decomposition for Knowledge Base Completion,"[""Timoth\u00e9e Lacroix"", ""Guillaume Obozinski"", ""Joan Bruna"", ""Nicolas Usunier""]","[""knowledge base completion"", ""adagrad""]","We diagnose and fix an optimization issue with Adagrad applied to the Tucker decomposition, yielding better performances for knowledge base completion at small embedding sizes.",,,,
ByeDl1BYvH,2020,Reject,False,Global graph curvature,"[""Liudmila Prokhorenkova"", ""Egor Samosvat"", ""Pim van der Hoorn""]","[""graph curvature"", ""graph embedding"", ""hyperbolic space"", ""distortion"", ""Ollivier curvature"", ""Forman curvature""]",Introduce a concept of global graph curvature specifically catered to the problem of embedding graphs and find its connection with popular local graph curvatures.,,,,
ByeDojRcYQ,2019,Reject,False,COLLABORATIVE MULTIAGENT REINFORCEMENT LEARNING  IN HOMOGENEOUS SWARMS,"[""Arbaaz Khan"", ""Clark Zhang"", ""Vijay Kumar"", ""Alejandro Ribeiro""]","[""Reinforcement Learning"", ""Multi Agent"", ""policy gradient""]",Novel policy gradient for multiagent systems via distributed learning. ,,,,
ByeGzlrKwH,2020,Accept (Spotlight),True,Compression based bound for non-compressed network: unified generalization error analysis of large compressible deep neural network,"[""Taiji Suzuki"", ""Hiroshi Abe"", ""Tomoaki Nishimura""]","[""Generalization error"", ""compression based bound"", ""local Rademacher complexity""]",,1909.11274,cs.LG,2019-09-25 03:43:14+00:00,2020-06-21 16:39:16+00:00
ByeL1R4FvS,2020,Reject,False,Unsupervised Data Augmentation for Consistency Training,"[""Qizhe Xie"", ""Zihang Dai"", ""Eduard Hovy"", ""Minh-Thang Luong"", ""Quoc V. Le""]","[""Semi-supervised learning"", ""computer vision"", ""natural language processing""]",A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.,,,,
ByeLBj0qFQ,2019,Reject,False,Unsupervised Image to Sequence Translation with Canvas-Drawer Networks,"[""Kevin Frans"", ""Chin-Yi Cheng""]","[""image"", ""translation"", ""unsupervised"", ""model-based""]",Recreate images as interpretable high-level sequences without the need for paired data.,,,,
ByeLmn0qtX,2019,Reject,False,Variational Domain Adaptation,"[""Hirono Okamoto"", ""Shohei Ohsawa"", ""Itto Higuchi"", ""Haruka Murakami"", ""Mizuki Sango"", ""Zhenghang Cui"", ""Masahiro Suzuki"", ""Hiroshi Kajino"", ""Yutaka Matsuo""]","[""domain adaptation"", ""variational inference"", ""multi-domain""]","This paper proposes variational domain adaptation, a uniï¬ed, scalable, simple framework for learning multiple distributions through variational inference",,,,
ByeMB3Act7,2019,Accept (Poster),False,Learning to Screen for Fast Softmax  Inference on Large Vocabulary Neural Networks,"[""Patrick Chen"", ""Si Si"", ""Sanjiv Kumar"", ""Yang Li"", ""Cho-Jui Hsieh""]","[""fast inference"", ""softmax computation"", ""natural language processing""]",,,,,
ByeMPlHKPH,2020,Accept (Poster),False,Lite Transformer with Long-Short Range Attention,"[""Zhanghao Wu*"", ""Zhijian Liu*"", ""Ji Lin"", ""Yujun Lin"", ""Song Han""]","[""efficient model"", ""transformer""]",,,,,
ByeNFoRcK7,2019,Reject,False,PA-GAN: Improving GAN Training by Progressive Augmentation,"[""Dan Zhang"", ""Anna Khoreva""]","[""Deep Learning"", ""GANs"", ""Augmentation"", ""Generative Modelling""]",We introduce a new technique - progressive augmentation of GANs (PA-GAN) - that helps to improve the overall stability of GAN training.,,,,
ByeNra4FDB,2020,Accept (Poster),False,Novelty Detection Via Blurring,"[""Sungik Choi"", ""Sae-Young Chung""]","[""novelty"", ""anomaly"", ""uncertainty""]",We propose a novel OOD detector that employ blurred images as adversarial examples . Our model achieve significant OOD detection performance in various domains.,1911.11943,cs.LG,2019-11-27 04:10:18+00:00,2020-03-03 06:39:00+00:00
ByePEC4KDS,2020,Reject,True,Situating Sentence Embedders with Nearest Neighbor Overlap,"[""Lucy H. Lin"", ""Noah A. Smith""]","[""sentence embeddings"", ""nearest neighbors"", ""semantic similarity""]","We propose nearest neighbor overlap, a procedure which quantifies similarity between embedders in a task-agnostic manner, and use it to compare 21 sentence embedders.",1909.10724,cs.CL,2019-09-24 06:03:35+00:00,2019-09-24 06:03:35+00:00
ByePUo05K7,2019,Reject,False,What a difference a pixel makes: An empirical examination of features used by CNNs for categorisation,"[""Gaurav Malhotra"", ""Jeffrey Bowers""]","[""deep learning"", ""shape bias"", ""vision"", ""feature selection""]","This study highlights a key difference between human vision and CNNs: while object recognition in humans relies on analysing shape, CNNs do not have such a shape-bias.",,,,
ByeSYa4KPS,2020,Reject,True,Sparse Networks from Scratch: Faster Training without Losing Performance,"[""Tim Dettmers"", ""Luke Zettlemoyer""]","[""sparse learning"", ""sparse networks"", ""sparsity"", ""efficient deep learning"", ""efficient training""]",Redistributing and growing weights according to the momentum magnitude enables the training of sparse networks from random initializations that can reach dense performance levels with 5% to 50% weights while accelerating training by up to 5.6x.,1907.04840,cs.LG,2019-07-10 17:40:20+00:00,2019-08-23 18:30:16+00:00
ByeSdsC9Km,2019,Accept (Poster),False,Adaptive Posterior Learning: few-shot learning with a surprise-based memory module,"[""Tiago Ramalho"", ""Marta Garnelo""]","[""metalearning"", ""memory"", ""few-shot"", ""relational"", ""self-attention"", ""classification"", ""sequential"", ""reasoning"", ""working memory"", ""episodic memory""]",We introduce a model which generalizes quickly from few observations by storing surprising information and attending over the most relevant data at each time point.,,,,
ByeTHsAqtX,2019,Reject,False,Gradient Descent Happens in a Tiny Subspace,"[""Guy Gur-Ari"", ""Daniel A. Roberts"", ""Ethan Dyer""]","[""Gradient Descent"", ""Hessian"", ""Deep Learning""]","For classification problems with k classes, we show that the gradient tends to live in a tiny, slowly-evolving subspace spanned by the eigenvectors corresponding to the k-largest eigenvalues of the Hessian.",,,,
ByeUBANtvB,2020,Accept (Poster),False,Learning to solve the credit assignment problem,"[""Benjamin James Lansdell"", ""Prashanth Ravi Prakash"", ""Konrad Paul Kording""]","[""biologically plausible deep learning"", ""node perturbation"", ""REINFORCE"", ""synthetic gradients"", ""feedback alignment""]",Perturbations can be used to train feedback weights to learn in fully connected and convolutional neural networks,,,,
ByeVWkBYPH,2020,Reject,False,Neural Networks for Principal Component Analysis: A New Loss Function Provably Yields Ordered Exact Eigenvectors ,"[""Reza Oftadeh"", ""Jiayi Shen"", ""Zhangyang Wang"", ""Dylan Shell""]","[""Principal Component Analysis"", ""Autoencoder"", ""Neural Network""]",A new loss function for PCA with linear autoencoders that provably yields ordered exact eigenvectors ,,,,
ByeWdiR5Ym,2019,Reject,False,Adaptive Convolutional Neural Networks,"[""Julio Cesar Zamora"", ""Jesus Adan Cruz Vargas"", ""Omesh Tickoo""]","[""Adaptive kernels"", ""Dynamic kernels"", ""Pattern recognition"", ""low memory CNNs""]","An adaptve convolutional kernel, that includes non-linear transformations obtaining similar results as the state of the art algorithms, while yielding a reduction in required memory up to 16x in the CIFAR10",,,,
ByeWogStDS,2020,Accept (Poster),False,Sub-policy Adaptation for Hierarchical Reinforcement Learning,"[""Alexander Li"", ""Carlos Florensa"", ""Ignasi Clavera"", ""Pieter Abbeel""]","[""Hierarchical Reinforcement Learning"", ""Transfer"", ""Skill Discovery""]","We propose HiPPO, a stable Hierarchical Reinforcement Learning algorithm that can train several levels of the hierarchy simultaneously, giving good performance both in skill discovery and adaptation.",,,,
ByeZ5jC5YQ,2019,Accept (Oral),False,KnockoffGAN: Generating Knockoffs for Feature Selection using Generative Adversarial Networks,"[""James Jordon"", ""Jinsung Yoon"", ""Mihaela van der Schaar""]","[""Knockoff model"", ""Feature selection"", ""False discovery rate control"", ""Generative Adversarial networks""]",,,,,
ByeaXeBFvH,2020,Reject,False,Hydra: Preserving Ensemble Diversity for Model Distillation,"[""Linh Tran"", ""Bastiaan S. Veeling"", ""Kevin Roth"", ""Jakub \u015awi\u0105tkowski"", ""Joshua V. Dillon"", ""Jasper Snoek"", ""Stephan Mandt"", ""Tim Salimans"", ""Sebastian Nowozin"", ""Rodolphe Jenatton""]","[""model distillation"", ""ensemble models""]","We distill ensemble models using a shared body network and many heads, preserving ensemble diversity.",,,,
ByeadyrtPB,2020,Reject,False,Learning Deep-Latent Hierarchies by Stacking Wasserstein Autoencoders,"[""Benoit Gaujac"", ""Ilya Feige"", ""David Barber""]","[""Generative modelling"", ""Optimal Transport""]",We train a deep-hierarchical-latent-variable model based on Optimal Transport.,2010.03467,stat.ML,2020-10-07 15:04:20+00:00,2020-10-07 15:04:20+00:00
ByecAoAqK7,2019,Reject,False,Zero-shot Dual Machine Translation,"[""Lierni Sestorain"", ""Massimiliano Ciaramita"", ""Christian Buck"", ""Thomas Hofmann""]","[""unsupervised"", ""machine translation"", ""dual learning"", ""zero-shot""]",A multilingual NMT model with reinforcement learning (dual learning) aiming to improve zero-shot translation directions.,,,,
ByedzkrKvH,2020,Accept (Poster),False,Double Neural Counterfactual Regret Minimization,"[""Hui Li"", ""Kailiang Hu"", ""Shaohua Zhang"", ""Yuan Qi"", ""Le Song""]","[""Counterfactual Regret Minimization"", ""Imperfect Information game"", ""Neural Strategy"", ""Deep Learning"", ""Robust Sampling""]",We proposed a double neural framework to solve large-scale imperfect information game. ,,,,
Byekm0VtwS,2020,Reject,False,A Training Scheme for the Uncertain Neuromorphic Computing Chips,"[""Qingtian Zhang"", ""Bin Gao"", ""Huaqiang Wu""]","[""deep learning"", ""neuromorphic computing"", ""uncertainty"", ""training""]",A training method that can make deep learning algorithms work better on neuromorphic computing chips with uncertainty,,,,
ByeqORgAW,2018,Accept (Poster),False,Proximal Backpropagation,"[""Thomas Frerix"", ""Thomas M\u00f6llenhoff"", ""Michael Moeller"", ""Daniel Cremers""]",[],,,,,
Byeq_xHtwS,2020,Reject,False,Neural Video Encoding,"[""Abel Brown"", ""Robert DiPietro""]","[""Kolmogorov complexity"", ""differentiable programming"", ""convolutional neural networks""]",We explore applications of differentiable programming to Kolmogorov complexity in order to realize efficient programs that encode data.,,,,
ByeqyxBKvS,2020,Reject,False,Quantum Semi-Supervised Kernel Learning,"[""Seyran Saeedi"", ""Aliakbar Panahi"", ""Tom Arodz""]","[""quantum machine learning"", ""semi-supervised learning"", ""support vector machines""]","We extend quantum SVMs to semi-supervised setting, to deal with the likely problem of many missing class labels in huge datasets.",,,,
Byes0TNFDS,2020,Reject,False,Entropy Penalty: Towards Generalization Beyond the IID Assumption,"[""Devansh Arpit"", ""Caiming Xiong"", ""Richard Socher""]","[""domain shift"", ""information bottleneck"", ""entropy penalty"", ""out of distribution generalization""]","We show that models are sensitive to all correlations when training using vanilla maximum likelihood, thus perform poorly under distribution shift. Information bottleneck can potentially address this.",,,,
ByetGn0cYX,2019,Accept (Poster),False,Probabilistic Planning with Sequential Monte Carlo methods,"[""Alexandre Piche"", ""Valentin Thomas"", ""Cyril Ibrahim"", ""Yoshua Bengio"", ""Chris Pal""]","[""control as inference"", ""probabilistic planning"", ""sequential monte carlo"", ""model based reinforcement learning""]","Leveraging control as inference and Sequential Monte Carlo methods, we proposed a probabilistic planning algorithm.",,,,
ByexElSYDr,2020,Accept (Poster),True,Fair Resource Allocation in Federated Learning,"[""Tian Li"", ""Maziar Sanjabi"", ""Ahmad Beirami"", ""Virginia Smith""]","[""federated learning"", ""fairness"", ""distributed optimization""]","We propose a novel optimization objective that encourages fairness in heterogeneous federated networks, and develop a scalable method to solve it.",1905.10497,cs.LG,2019-05-25 01:47:41+00:00,2020-02-14 22:48:28+00:00
Byey7n05FQ,2019,Accept (Poster),False,"Plan Online, Learn Offline: Efficient Learning and Exploration via Model-Based Control","[""Kendall Lowrey"", ""Aravind Rajeswaran"", ""Sham Kakade"", ""Emanuel Todorov"", ""Igor Mordatch""]","[""deep reinforcement learning"", ""exploration"", ""model-based""]",We propose a framework that incorporates planning for efficient exploration and learning in complex environments.,,,,
ByezgnA5tm,2019,Reject,False,Constraining Action Sequences with Formal Languages for Deep Reinforcement Learning,"[""Dong Xu"", ""Eleanor Quint"", ""Zeynep Hakguder"", ""Haluk Dogan"", ""Stephen Scott"", ""Matthew Dwyer""]","[""reinforcement learning"", ""constraints"", ""finite state machines""]","We constrain an agent's actions during reinforcement learning, for safety or to enhance exploration.",,,,
Byf5-30qFX,2019,Accept (Poster),False,DHER: Hindsight Experience Replay for Dynamic Goals,"[""Meng Fang"", ""Cheng Zhou"", ""Bei Shi"", ""Boqing Gong"", ""Jia Xu"", ""Tong Zhang""]","[""Sparse rewards"", ""Dynamic goals"", ""Experience replay""]",,,,,
ByfXe2C5tm,2019,Reject,False,NLProlog: Reasoning with Weak Unification for Natural Language Question Answering,"[""Leon Weber"", ""Pasquale Minervini"", ""Ulf Leser"", ""Tim Rockt\u00e4schel""]","[""symbolic reasoning"", ""neural networks"", ""natural language processing"", ""question answering"", ""sentence embeddings"", ""evolution strategies""]","We introduce NLProlog, a system that performs rule-based reasoning on natural language by leveraging pretrained sentence embeddings and fine-tuning with Evolution Strategies, and apply it to two multi-hop Question Answering tasks.",,,,
ByfbnsA9Km,2019,Reject,False,Cross-Entropy Loss Leads To Poor Margins,"[""Kamil Nar"", ""Orhan Ocal"", ""S. Shankar Sastry"", ""Kannan Ramchandran""]","[""Cross-entropy loss"", ""Binary classification"", ""Low-rank features"", ""Adversarial examples"", ""Differential training""]",We show that minimizing the cross-entropy loss by using a gradient method could lead to a very poor margin if the features of the dataset lie on a low-dimensional subspace.,,,,
ByftGnR9KX,2019,Accept (Poster),False,FlowQA: Grasping Flow in History for Conversational Machine Comprehension,"[""Hsin-Yuan Huang"", ""Eunsol Choi"", ""Wen-tau Yih""]","[""Machine Comprehension"", ""Conversational Agent"", ""Natural Language Processing"", ""Deep Learning""]","We propose the Flow mechanism and an end-to-end architecture, FlowQA, that achieves SotA on two conversational QA datasets and a sequential instruction understanding task.",,,,
ByfyHh05tQ,2019,Accept (Poster),False,Learning to Design RNA,"[""Frederic Runge"", ""Danny Stoll"", ""Stefan Falkner"", ""Frank Hutter""]","[""matter engineering"", ""bioinformatics"", ""rna design"", ""reinforcement learning"", ""meta learning"", ""neural architecture search"", ""hyperparameter optimization""]",We learn to solve the RNA Design problem with reinforcement learning using meta learning and autoML approaches.,,,,
Byg-An4tPr,2020,Reject,False,Differential Privacy in Adversarial Learning with Provable Robustness,"[""NhatHai Phan"", ""My T. Thai"", ""Ruoming Jin"", ""Han Hu"", ""Dejing Dou""]","[""differential privacy"", ""adversarial learning"", ""robustness bound"", ""adversarial example""]",Preserving Differential Privacy in Adversarial Learning with Provable Robustness to Adversarial Examples,,,,
Byg-wJSYDS,2020,Accept (Poster),False,Discrepancy Ratio: Evaluating Model Performance When Even Experts Disagree on the Truth,"[""Igor Lovchinsky"", ""Alon Daks"", ""Israel Malkin"", ""Pouya Samangouei"", ""Ardavan Saeedi"", ""Yang Liu"", ""Swami Sankaranarayanan"", ""Tomer Gafner"", ""Ben Sternlieb"", ""Patrick Maher"", ""Nathan Silberman""]","[""Evaluation Metrics"", ""Medical Imaging""]",A framework for evaluating model performance when even experts disagree on what the ground truth is.,,,,
Byg0DsCqYQ,2019,Accept (Poster),False,Robust Conditional Generative Adversarial Networks,"[""Grigorios G. Chrysos"", ""Jean Kossaifi"", ""Stefanos Zafeiriou""]","[""conditional GAN"", ""unsupervised pathway"", ""autoencoder"", ""robustness""]","We introduce a new type of conditional GAN, which aims to leverage structure in the target space of the generator. We augment the generator with a new, unsupervised pathway to learn the target structure. ",,,,
Byg1v1HKDB,2020,Accept (Poster),False,Abductive Commonsense Reasoning,"[""Chandra Bhagavatula"", ""Ronan Le Bras"", ""Chaitanya Malaviya"", ""Keisuke Sakaguchi"", ""Ari Holtzman"", ""Hannah Rashkin"", ""Doug Downey"", ""Wen-tau Yih"", ""Yejin Choi""]","[""Abductive Reasoning"", ""Commonsense Reasoning"", ""Natural Language Inference"", ""Natural Language Generation""]",,,,,
Byg3y3C9Km,2019,Accept (Oral),False,Learning Protein Structure with a Differentiable Simulator,"[""John Ingraham"", ""Adam Riesselman"", ""Chris Sander"", ""Debora Marks""]","[""generative models"", ""simulators"", ""molecular modeling"", ""proteins"", ""structured prediction""]",We use an unrolled simulator as an end-to-end differentiable model of protein structure and show it can (sometimes) hierarchically generalize to unseen fold topologies.,,,,
Byg5KyHYwr,2020,Reject,False,Self-Imitation Learning via Trajectory-Conditioned Policy for Hard-Exploration Tasks,"[""Yijie Guo"", ""Jongwook Choi"", ""Marcin Moczulski"", ""Samy Bengio"", ""Mohammad Norouzi"", ""Honglak Lee""]","[""imitation learning"", ""hard-exploration tasks"", ""exploration and exploitation""]",Self-imitation learning of diverse trajectories with trajectory-conditioned policy,,,,
Byg5QhR5FQ,2019,Accept (Poster),False,Top-Down Neural Model For Formulae,"[""Karel Chvalovsk\u00fd""]","[""logic"", ""formula"", ""recursive neural networks"", ""recurrent neural networks""]",A top-down approach how to recursively represent propositional formulae by neural networks is presented.,,,,
Byg5ZANtvH,2020,Accept (Poster),True,Short and Sparse Deconvolution --- A Geometric Approach,"[""Yenson Lau"", ""Qing Qu"", ""Han-Wen Kuo"", ""Pengcheng Zhou"", ""Yuqian Zhang"", ""John Wright""]",[],,1908.10959,eess.SP,2019-08-28 21:52:28+00:00,2019-10-01 05:25:59+00:00
Byg5flHFDr,2020,Reject,False,EvoNet: A Neural Network for Predicting the Evolution of Dynamic Graphs,"[""Changmin Wu"", ""Giannis Nikolentzos"", ""Michalis Vazirgiannis""]","[""temporal graphs"", ""graph neural network"", ""graph generative model"", ""graph topology prediction""]","Combining graph neural networks and the RNN graph generative model, we propose a novel architecture that is able to learn from a sequence of evolving graphs and predict the graph topology evolution for the future timesteps",2003.00842,cs.LG,2020-03-02 12:59:05+00:00,2020-03-02 12:59:05+00:00
Byg79h4tvB,2020,Reject,False,PROTOTYPE-ASSISTED ADVERSARIAL LEARNING FOR UNSUPERVISED DOMAIN ADAPTATION,"[""Dapeng Hu"", ""Jian Liang*"", ""Qibin Hou"", ""Hanshu Yan"", ""Jiashi Feng""]","[""Domain Adaptation"", ""Transfer Learning"", ""Adversarial Learning""]","We propose a reliable conditional adversarial learning scheme along with a simple, generic yet effective framework for UDA tasks.",,,,
Byg9A24tvB,2020,Accept (Poster),True,Rethinking Softmax Cross-Entropy Loss for Adversarial Robustness,"[""Tianyu Pang"", ""Kun Xu"", ""Yinpeng Dong"", ""Chao Du"", ""Ning Chen"", ""Jun Zhu""]","[""Trustworthy Machine Learning"", ""Adversarial Robustness"", ""Training Objective"", ""Sample Density""]",Applying the softmax function in training leads to indirect and unexpected supervision on features. We propose a new training objective to explicitly induce dense feature regions for locally sufficient samples to benefit adversarial robustness.,1905.10626,cs.LG,2019-05-25 16:11:14+00:00,2020-02-20 08:50:47+00:00
Byg9AR4YDB,2020,Reject,False,Exploring Cellular Protein Localization Through Semantic Image Synthesis,"[""Daniel Li"", ""Qiang Ma"", ""Andrew Liu"", ""Justin Cheung"", ""Dana Pe\u2019er"", ""Itsik Pe\u2019er""]","[""Computational biology"", ""image synthesis"", ""GANs"", ""exploring multiplex images"", ""attention"", ""interpretability""]","We explore cell-cell interactions across tumor environment contexts observed in highly multiplexed images, by image synthesis using a novel attention GAN architecture.",,,,
Byg9bxrtwS,2020,Reject,True,Kernel and Rich Regimes in Overparametrized Models,"[""Blake Woodworth"", ""Suriya Gunasekar"", ""Pedro Savarese"", ""Edward Moroshko"", ""Itay Golan"", ""Jason Lee"", ""Daniel Soudry"", ""Nathan Srebro""]","[""Overparametrized"", ""Implicit"", ""Bias"", ""Regularization"", ""Kernel"", ""Rich"", ""Adaptive"", ""Regime""]","We study the transition between the kernel and non-kernel/rich regimes in overparametrized models, analytically for simple models, and experimentally for more complex ones. ",1906.05827,cs.LG,2019-06-13 17:16:12+00:00,2020-02-25 17:33:47+00:00
BygANhA9tQ,2019,Accept (Poster),False,Cost-Sensitive Robustness against Adversarial Examples,"[""Xiao Zhang"", ""David Evans""]","[""Certified robustness"", ""Adversarial examples"", ""Cost-sensitive learning""]",A general method for training certified cost-sensitive robust classifier against adversarial perturbations,,,,
BygANjA5FX,2019,Reject,False,IEA: Inner Ensemble Average within a convolutional neural network,"[""Abduallah Mohamed"", ""Xinrui Hua"", ""Xianda Zhou"", ""Christian Claudel""]","[""Ensemble Convolutional Neural Networks""]","We inner ensemble the features of a convolutional neural layer, it increases the network accuracy and generates distinct features.",,,,
BygFVAEKDH,2020,Accept (Poster),False,Understanding Knowledge Distillation in Non-autoregressive Machine Translation,"[""Chunting Zhou"", ""Jiatao Gu"", ""Graham Neubig""]","[""knowledge distillation"", ""non-autoregressive neural machine translation""]","We systematically examine why knowledge distillation is crucial to the training of non-autoregressive translation (NAT) models, and propose methods to further improve the distilled data to best match the capacity of an NAT model.",,,,
BygGNnCqKQ,2019,Reject,False,Architecture Compression,"[""Anubhav Ashok""]","[""compression"", ""architecture search""]",Novel gradient descent approach to perform model compression in architecture space,,,,
BygIV2CcKm,2019,Reject,False,Learning to Augment Influential Data,"[""Donghoon Lee"", ""Chang D. Yoo""]","[""data augmentation"", ""influence function"", ""generative adversarial network""]",,,,,
BygIjTNtPr,2020,Reject,True,ODE Analysis of Stochastic Gradient Methods with Optimism and Anchoring  for Minimax Problems and GANs,"[""Ernest K. Ryu"", ""Kun Yuan"", ""Wotao Yin""]","[""GAN"", ""minimax problems"", ""stochastic gradients""]",Convergence proof of stochastic sub-gradients method and variations on convex-concave minimax problems,1905.10899,cs.LG,2019-05-26 23:05:13+00:00,2020-10-12 01:00:58+00:00
BygJKn4tPr,2020,Reject,False,Effective Mechanism to Mitigate Injuries During NFL Plays ,"[""Arraamuthan Arulanantham"", ""Ahamed Arshad Ahamed Anzar"", ""Gowshalini Rajalingam"", ""Krusanth Ingran"", ""Prasanna S. Haddela""]","[""Concussion"", ""American football"", ""Predictive modelling"", ""Injuries"", ""NFL Plays"", ""Optimization""]",Mitigate concussions in American Football using Machine learning and Optimization techniques,,,,
BygKZkBtDH,2020,Reject,False,Balancing Cost and Benefit with Tied-Multi Transformers,"[""Raj Dabre"", ""Raphael Rubino"", ""Atsushi Fujita""]","[""tied models"", ""encoder-decoder"", ""multi-layer softmaxing"", ""depth prediction"", ""model compression""]","Training multiple transformers with tied parameters, depth selection, and further compression",2002.08614,cs.CL,2020-02-20 08:20:52+00:00,2020-02-20 08:20:52+00:00
BygMAiRqK7,2019,Reject,False,Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs,"[""Yogesh Balaji"", ""Hamed Hasani"", ""Rama Chellappa"", ""Soheil Feizi""]","[""GAN"", ""VAE"", ""likelihood estimation"", ""statistical inference""]",A statistical approach to compute sample likelihoods in Generative Adversarial Networks,,,,
BygMreSYPB,2020,Reject,True,Learning Latent Dynamics for Partially-Observed Chaotic Systems,"[""Said ouala"", ""Duong Nguyen"", ""Lucas Drumetz"", ""Bertrand Chapron"", ""Ananda Pascual"", ""Fabrice Collard"", ""Lucile Gaultier"", ""Ronan Fablet""]","[""Dynamical systems"", ""Neural networks"", ""Embedding"", ""Partially observed systems"", ""Forecasting"", ""chaos""]",Data driven identification of ODE representations for partially observed chaotic systems,1907.02452,stat.ML,2019-07-04 15:23:12+00:00,2019-07-04 15:23:12+00:00
BygNAa4YPH,2020,Reject,False,Out-of-distribution Detection in Few-shot Classification,"[""Kuan-Chieh Wang"", ""Paul Vicol"", ""Eleni Triantafillou"", ""Chia-Cheng Liu"", ""Richard Zemel""]","[""few-shot classification"", ""out-of-distribution detection"", ""uncertainty estimate""]","We quantitatively study out-of-distribution detection in few-shot setting, establish baseline results with ProtoNet, MAML, ABML, and improved upon them.",,,,
BygNqoR9tm,2019,Reject,False,Sinkhorn AutoEncoders,"[""Giorgio Patrini"", ""Marcello Carioni"", ""Patrick Forr\u00e9"", ""Samarth Bhargav"", ""Max Welling"", ""Rianne van den Berg"", ""Tim Genewein"", ""Frank Nielsen""]","[""generative models"", ""autoencoders"", ""optimal transport"", ""sinkhorn algorithm""]",,,,,
BygPO2VKPH,2020,Accept (Spotlight),False,Sparse Coding with Gated Learned ISTA,"[""Kailun Wu"", ""Yiwen Guo"", ""Ziang Li"", ""Changshui Zhang""]","[""Sparse coding"", ""deep learning"", ""learned ISTA"", ""convergence analysis""]","We propose gated mechanisms to enhance learned ISTA for sparse coding, with theoretical guarantees on the superiority of the method. ",,,,
BygPq6VFvS,2020,Reject,False,Enhancing Attention with Explicit Phrasal Alignments,"[""Xuan-Phi Nguyen"", ""Shafiq Joty"", ""Thanh-Tung Nguyen""]","[""NMT"", ""Phrasal Attention"", ""Machine Translation"", ""Language Modeling""]",,,,,
BygREjC9YQ,2019,Reject,False,A unified theory of adaptive stochastic gradient descent as Bayesian filtering,"[""Laurence Aitchison""]","[""SGD"", ""Bayesian"", ""RMSprop"", ""Adam""]","We formulated SGD as a Bayesian filtering problem, and show that this gives rise to RMSprop, Adam, AdamW, NAG and other features of state-of-the-art adaptive methods",,,,
BygRNn0qYX,2019,Reject,False,P^2IR: Universal Deep Node Representation via Partial Permutation Invariant Set Functions,"[""Shupeng Gui"", ""Xiangliang Zhang"", ""Shuang Qiu"", ""Mingrui Wu"", ""Jieping Ye"", ""Ji Liu""]","[""graph embedding"", ""set function"", ""representation learning""]",,,,,
BygSP6Vtvr,2020,Accept (Poster),True,Ensemble Distribution Distillation,"[""Andrey Malinin"", ""Bruno Mlodozeniec"", ""Mark Gales""]","[""Ensemble Distillation"", ""Knowledge Distillation"", ""Uncertainty Estimation"", ""Density Estimation""]","We distill an ensemble of models into a single model, capturing both the improved classification performance and information about the diversity of the ensemble, which is useful for uncertainty estimation.",1905.00076,stat.ML,2019-04-30 19:46:28+00:00,2019-11-25 21:27:46+00:00
BygSXCNFDB,2020,Reject,False,Exploration Based Language Learning for Text-Based Games,"[""Andrea Madotto"", ""Mahdi Namazifar"", ""Joost Huizinga"", ""Piero Molino"", ""Adrien Ecoffet"", ""Huaixiu Zheng"", ""Alexandros Papangelis"", ""Dian Yu"", ""Chandra Khatri"", ""Gokhan Tur""]","[""Text-Based Games"", ""Exploration"", ""Language Learning""]",This work presents an exploration and imitation-learning-based agent capable of state-of-the-art performance in playing text-based computer games. ,2001.08868,cs.CL,2020-01-24 03:03:51+00:00,2020-06-08 02:27:49+00:00
BygSZAVKvr,2020,Reject,True,Energy-Aware Neural Architecture Optimization with Fast Splitting Steepest Descent,"[""Dilin Wang"", ""Meng Li"", ""Lemeng Wu"", ""Vikas Chandra"", ""Qiang Liu""]","[""Neural architecture optimization"", ""splitting steepest descent""]",,1910.03103,cs.LG,2019-10-07 21:45:17+00:00,2020-07-08 20:58:06+00:00
BygWRaVYwH,2020,Reject,False,Generalized Inner Loop Meta-Learning,"[""Edward Grefenstette"", ""Brandon Amos"", ""Denis Yarats"", ""Phu Mon Htut"", ""Artem Molchanov"", ""Franziska Meier"", ""Douwe Kiela"", ""Kyunghyun Cho"", ""Soumith Chintala""]","[""meta-learning""]","Lots of meta-learning problems follow the same general pattern, so we formalized it, proved stuff about it, turned it into an algorithm, and subsequently a pytorch library.",,,,
BygXFkSYDH,2020,Accept (Talk),False,Target-Embedding Autoencoders for Supervised Representation Learning,"[""Daniel Jarrett"", ""Mihaela van der Schaar""]","[""autoencoders"", ""supervised learning"", ""representation learning"", ""target-embedding"", ""label-embedding""]",,2001.08345,stat.ML,2020-01-23 02:37:10+00:00,2020-01-23 02:37:10+00:00
BygY4grYDr,2020,Reject,False,The divergences minimized by non-saturating GAN training,"[""Matt Shannon""]","[""GAN""]",Non-saturating GAN training effectively minimizes a reverse KL-like f-divergence.,,,,
BygZARVFDH,2020,Reject,False,Compositional Visual Generation with Energy Based Models,"[""Yilun Du"", ""Shuang Li"", ""Igor Mordatch""]","[""Compositional Generation"", ""Energy Based Model"", ""Compositionality"", ""Generative Models""]","""We present flexible compositional image generation and its applications to continual learning and generalization""?",2004.06030,cs.CV,2020-04-13 16:01:40+00:00,2020-12-17 09:26:00+00:00
BygZK2VYvB,2020,Reject,False,Utilizing Edge Features in Graph Neural Networks via Variational Information Maximization,"[""Pengfei Chen"", ""Weiwen Liu"", ""Chang-Yu Hsieh"", ""Guangyong Chen"", ""Pheng Ann Heng""]","[""Graph Neural Network"", ""Edge Feature"", ""Mutual Information""]",We use a principled variational approach to preserve edge information in graph neural networks and show the importance of edge features and the superior of our method in extensive benchmarks.,,,,
Byg_vREtvB,2020,Reject,False,Generalized Bayesian Posterior Expectation Distillation for Deep Neural Networks,"[""Meet P. Vadera"", ""Benjamin M. Marlin""]","[""Bayesian Neural Networks"", ""Distillation""]",A general framework for distilling Bayesian posterior expectations for deep neural networks.,,,,
BygacxrFwS,2020,Reject,False,Fractional Graph Convolutional Networks (FGCN) for Semi-Supervised Learning,"[""Yuzhou Chen"", ""Yulia R. Gel"", ""Konstantin Avrachenkov""]","[""convolutional networks"", ""node classification"", ""Levy flight"", ""graph-based semi-supervised learning"", ""local graph topology""]",A new Fractional Generalized Graph Convolutional Networks (FGCN) method for semi-supervised learning,,,,
Bygadh4tDB,2020,Reject,False,Low Bias Gradient Estimates for Very Deep Boolean Stochastic Networks,"[""Adeel Pervez"", ""Taco Cohen"", ""Efstratios Gavves""]",[],We present a low-bias estimator for Boolean stochastic variable models with many stochastic layers.,,,,
BygdyxHFDS,2020,Accept (Poster),False,Meta-learning curiosity algorithms,"[""Ferran Alet*"", ""Martin F. Schneider*"", ""Tomas Lozano-Perez"", ""Leslie Pack Kaelbling""]","[""meta-learning"", ""exploration"", ""curiosity""]",Meta-learning curiosity algorithms by searching through a rich space of programs yields novel designs that generalize across very different reinforcement-learning domains.,,,,
BygfghAcYX,2019,Accept (Poster),False,The role of over-parametrization in generalization of neural networks,"[""Behnam Neyshabur"", ""Zhiyuan Li"", ""Srinadh Bhojanapalli"", ""Yann LeCun"", ""Nathan Srebro""]","[""Generalization"", ""Over-Parametrization"", ""Neural Networks"", ""Deep Learning""]",We suggest a generalization bound that could partly explain the improvement in generalization with over-parametrization.,,,,
BygfiAEtwS,2020,Reject,False,Inducing Stronger Object Representations in Deep Visual Trackers,"[""Ross Goroshin"", ""Jonathan Tompson"", ""Debidatta Dwibedi""]","[""Object Tracking"", ""Computer Vision"", ""Deep Learning""]",,2001.02593,cs.CV,2020-01-08 16:03:57+00:00,2020-01-08 16:03:57+00:00
BygfrANKvB,2020,Reject,True,Learning to Make Generalizable and Diverse Predictions for Retrosynthesis,"[""Benson Chen"", ""Tianxiao Shen"", ""Tommi S. Jaakkola"", ""Regina Barzilay""]","[""Chemistry"", ""Retrosynthesis"", ""Transformer"", ""Pre-training"", ""Diversity""]",We propose a new model for making generalizable and diverse retrosynthetic reaction predictions.,1910.09688,cs.LG,2019-10-21 23:03:21+00:00,2019-10-21 23:03:21+00:00
ByggpyrFPS,2020,Reject,False,Bayesian Variational Autoencoders for Unsupervised Out-of-Distribution Detection,"[""Erik Daxberger"", ""Jos\u00e9 Miguel Hern\u00e1ndez-Lobato""]","[""variational autoencoders"", ""out-of-distribution detection"", ""stochastic gradient MCMC""]",We do unsupervised out-of-distribution detection by estimating a posterior distribution over the parameters of a VAE using SG-MCMC and using information-theoretic measures.,1912.05651,cs.LG,2019-12-11 21:37:54+00:00,2020-07-15 07:07:28+00:00
Bygh9j09KX,2019,Accept (Oral),False,ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness,"[""Robert Geirhos"", ""Patricia Rubisch"", ""Claudio Michaelis"", ""Matthias Bethge"", ""Felix A. Wichmann"", ""Wieland Brendel""]","[""deep learning"", ""psychophysics"", ""representation learning"", ""object recognition"", ""robustness"", ""neural networks"", ""data augmentation""]",ImageNet-trained CNNs are biased towards object texture (instead of shape like humans). Overcoming this major difference between human and machine vision yields improved detection performance and previously unseen robustness to image distortions.,,,,
ByghKiC5YX,2019,Reject,False,Greedy Attack and Gumbel Attack: Generating Adversarial Examples for Discrete Data,"[""Puyudi Yang"", ""Jianbo Chen"", ""Cho-Jui Hsieh"", ""Jane-Ling Wang"", ""Michael I. Jordan""]","[""Adversarial Examples""]",We develop two methods for generating adversarial examples on discrete data under a probabilistic framework.,,,,
BygkQeHKwB,2020,Reject,False,"Walking on the Edge: Fast, Low-Distortion Adversarial Examples","[""Hanwei Zhang"", ""Teddy Furon"", ""Yannis Avrithis"", ""Laurent Amsaleg""]","[""Deep learning"", ""adversarial attack""]",,,,,
Bygka64KPH,2020,Reject,False,Semi-Supervised Few-Shot Learning with Prototypical Random Walks,"[""Ahmed Ayyad"", ""Nassir Navab"", ""Mohamed Elhoseiny"", ""Shadi Albarqouni""]","[""Few-Shot Learning"", ""Semi-Supervised Learning"", ""Random Walks""]",,,,,
ByglLlHFDS,2020,Accept (Poster),False,Expected Information Maximization: Using the I-Projection for Mixture Density Estimation,"[""Philipp Becker"", ""Oleg Arenz"", ""Gerhard Neumann""]","[""density estimation"", ""information projection"", ""mixture models"", ""generative learning"", ""multimodal modeling""]","A novel, non-adversarial, approach to learn latent variable models in general and mixture models in particular by computing the I-Projection solely based on samples.",2001.08682,cs.LG,2020-01-23 17:24:50+00:00,2020-01-23 17:24:50+00:00
BygmRoA9YQ,2019,Reject,False,Mixture of Pre-processing Experts Model for Noise Robust Deep Learning on Resource Constrained Platforms,"[""Taesik Na"", ""Minah Lee"", ""Burhan A. Mudassar"", ""Priyabrata Saha"", ""Jong Hwan Ko"", ""Saibal Mukhopadhyay""]","[""noise robust"", ""object detection""]",,,,,
BygpAp4Ywr,2020,Reject,False,Defending Against Adversarial Examples by Regularized Deep Embedding,"[""Yao Li"", ""Martin Renqiang Min"", ""Wenchao Yu"", ""Cho-Jui Hsieh"", ""Thomas Lee"", ""Erik Kruus""]",[],A general and easy-to-use framework that improves the adversarial robustness of deep classification models through embedding regularization.,,,,
BygpQlbA-,2018,Invite to Workshop Track,False,Towards Provable Control for Unknown Linear Dynamical Systems,"[""Sanjeev Arora"", ""Elad Hazan"", ""Holden Lee"", ""Karan Singh"", ""Cyril Zhang"", ""Yi Zhang""]","[""optimal control"", ""reinforcement learning""]","Using a novel representation of symmetric linear dynamical systems with a latent state, we formulate optimal control as a convex program, giving the first polynomial-time algorithm that solves optimal control with sample complexity only polylogarithmic in the time horizon.",,,,
Bygq-H9eg,2017,Reject,False,An Analysis of Deep Neural Network Models for Practical Applications,"[""Alfredo Canziani"", ""Adam Paszke"", ""Eugenio Culurciello""]","[""Computer vision"", ""Deep learning"", ""Applications""]","Analysis of ImageNet winning architectures in terms of accuracy, memory footprint, parameters, operations count, inference time and power consumption.",,,,
BygqBiRcFQ,2019,Accept (Poster),False,Diffusion Scattering Transforms on Graphs,"[""Fernando Gama"", ""Alejandro Ribeiro"", ""Joan Bruna""]","[""graph neural networks"", ""deep learning"", ""stability"", ""scattering transforms"", ""convolutional neural networks""]",Stability of scattering transform representations of graph data to deformations of the underlying graph support.,,,,
Bygre3R9Fm,2019,Reject,False,DEFactor: Differentiable Edge Factorization-based Probabilistic Graph Generation,"[""Rim Assouel"", ""Mohamed Ahmed"", ""Marwin Segler"", ""Amir Saffari"", ""Yoshua Bengio""]","[""molecular graphs"", ""conditional autoencoder"", ""graph autoencoder""]",New scalable graph decoding scheme that allows to perform direct molecular graph conditional generation.,,,,
BygrtoC9Km,2019,Reject,False,Meta-Learning with Individualized Feature Space for Few-Shot Classification,"[""Chunrui Han"", ""Shiguang Shan"", ""Meina Kan"", ""Shuzhe Wu"", ""Xilin Chen""]","[""few-shot classification"", ""meta-learning"", ""individualized feature space""]",,,,,
BygzbyHFvB,2020,Accept (Spotlight),True,FreeLB: Enhanced Adversarial Training for Natural Language Understanding,"[""Chen Zhu"", ""Yu Cheng"", ""Zhe Gan"", ""Siqi Sun"", ""Tom Goldstein"", ""Jingjing Liu""]",[],,1909.11764,cs.CL,2019-09-25 20:50:32+00:00,2020-04-23 07:19:00+00:00
Byht0GbRZ,2018,Reject,False,STRUCTURED ALIGNMENT NETWORKS,"[""Yang Liu"", ""Matt Gardner""]","[""structured attention"", ""sentence matching""]",Matching sentences by learning the latent constituency tree structures with a variant of the inside-outside algorithm embedded as a neural network layer.,,,,
ByhthReRb,2018,Reject,False,A Neural Method for Goal-Oriented Dialog Systems to interact with Named Entities,"[""Janarthanan Rajendran"", ""Jatin Ganhotra"", ""Xiaoxiao Guo"", ""Mo Yu"", ""Satinder Singh""]","[""Named Entities"", ""Neural methods"", ""Goal oriented dialog""]",,,,,
Byiy-Pqlx,2017,Accept (Poster),False,Lie-Access Neural Turing Machines,"[""Greg Yang"", ""Alexander Rush""]","[""Natural language processing"", ""Deep learning"", ""Supervised Learning""]",We generalize Turing machines to the continuous setting using Lie group actions on manifolds.,,,,
Byj54-bAW,2018,Reject,False,A Tensor Analysis on Dense Connectivity via Convolutional Arithmetic Circuits,"[""Emilio Rafael Balda"", ""Arash Behboodi"", ""Rudolf Mathar""]","[""DenseNets"", ""Tensor Analysis"", ""Convolutional Arithmetic Circuits""]",We analyze the expressive power of the connections used in DenseNets via tensor decompositions.,,,,
Byj72udxe,2017,Accept (Poster),False,Pointer Sentinel Mixture Models,"[""Stephen Merity"", ""Caiming Xiong"", ""James Bradbury"", ""Richard Socher""]","[""Natural language processing"", ""Deep learning""]","Pointer sentinel mixture models provide a method to combine a traditional vocabulary softmax with a pointer network, providing state of the art results in language modeling on PTB and the newly introduced WikiText with few extra parameters.",,,,
Byk-VI9eg,2017,Accept (Poster),False,Generative Multi-Adversarial Networks,"[""Ishan Durugkar"", ""Ian Gemp"", ""Sridhar Mahadevan""]","[""Deep learning"", ""Unsupervised Learning"", ""Games""]",GANs with multiple discriminators accelerate training to more robust performance.,,,,
Byk4My-RZ,2018,Reject,False,Flexible Prior Distributions for Deep Generative Models,"[""Yannic Kilcher"", ""Aurelien Lucchi"", ""Thomas Hofmann""]","[""Deep Generative Models"", ""GANs""]",,,,,
Byl-264tvr,2020,Reject,False,Improving End-to-End Object Tracking Using Relational Reasoning,"[""Fabian B. Fuchs"", ""Adam R. Kosiorek"", ""Li Sun"", ""Oiwi Parker Jones"", ""Ingmar Posner""]","[""Relational Reasoning"", ""Tracking"", ""Intuitive Physics"", ""Real-World Application"", ""Permutation Invariance""]",MOHART uses a self-attention mechanism to perform relational reasoning in multi-object tracking.,,,,
Byl1W1rtvH,2020,Reject,False,Recurrent Hierarchical Topic-Guided Neural Language Models,"[""Dandan Guo"", ""Bo Chen"", ""Ruiying Lu"", ""Mingyuan Zhou""]","[""Bayesian deep learning"", ""recurrent gamma belief net"", ""larger-context language model"", ""variational inference"", ""sentence generation"", ""paragraph generation""]","We introduce a novel larger-context language model to simultaneously captures syntax and semantics, making it capable of generating highly interpretable sentences and paragraphs",1912.10337,cs.CL,2019-12-21 21:11:35+00:00,2020-06-27 22:22:58+00:00
Byl28eBtwH,2020,Reject,True,Learning Cluster Structured Sparsity by Reweighting,"[""Yulun Jiang"", ""Lei Yu"", ""Haijian Zhang"", ""Zhou Liu""]","[""Sparse Recovery"", ""Sparse Representation"", ""Structured Sparsity""]",,1910.05303,cs.LG,2019-10-11 16:56:36+00:00,2019-10-11 16:56:36+00:00
Byl3HxBFwH,2020,Reject,False,Efficient Deep Representation Learning by Adaptive Latent Space Sampling,"[""Yuanhan Mo"", ""Shuo Wang"", ""Chengliang Dai"", ""Rui Zhou"", ""Zhongzhao Teng"", ""Wenjia Bai"", ""Yike Guo""]","[""Deep learning"", ""Data efficiency""]",This paper introduces a framework for data-efficient representation learning by adaptive sampling in latent space.,2004.02757,cs.CV,2020-03-19 22:17:02+00:00,2020-04-12 18:25:55+00:00
Byl3K2VtwB,2020,Reject,False,Unsupervised Learning of Node Embeddings by Detecting Communities,"[""Chi Thang Duong"", ""Dung Hoang"", ""Truong Giang Le Ba"", ""Thanh Le Cong"", ""Hongzhi Yin"", ""Matthias Weidlich"", ""Quoc Viet Hung Nguyen"", ""Karl Aberer""]","[""Unsupervised Learning"", ""Graph Embedding"", ""Community Detection"", ""Mincut"", ""Normalized cut"", ""Deep Learning""]","A neural network approach for unsupervised learning of node embeddings of a graph, while at the same time learning structural characteristics in terms of communities of nodes",,,,
Byl5NREFDr,2020,Accept (Poster),True,Thieves on Sesame Street! Model Extraction of BERT-based APIs,"[""Kalpesh Krishna"", ""Gaurav Singh Tomar"", ""Ankur P. Parikh"", ""Nicolas Papernot"", ""Mohit Iyyer""]","[""model extraction"", ""BERT"", ""natural language processing"", ""pretraining language models"", ""model stealing"", ""deep learning security""]","Outputs of modern NLP APIs on nonsensical text provide strong signals about model internals, allowing adversaries to steal the APIs.",1910.12366,cs.CL,2019-10-27 22:09:13+00:00,2020-10-12 12:14:05+00:00
Byl8BnRcYm,2019,Accept (Poster),False,Capsule Graph Neural Network,"[""Zhang Xinyi"", ""Lihui Chen""]","[""CapsNet"", ""Graph embedding"", ""GNN""]","Inspired by CapsNet, we propose a novel architecture for graph embeddings on the basis of node features extracted from GNN.",,,,
Byl8hhNYPS,2020,Accept (Spotlight),False,Neural Machine Translation with Universal Visual Representation,"[""Zhuosheng Zhang"", ""Kehai Chen"", ""Rui Wang"", ""Masao Utiyama"", ""Eiichiro Sumita"", ""Zuchao Li"", ""Hai Zhao""]","[""Neural Machine Translation"", ""Visual Representation"", ""Multimodal Machine Translation"", ""Language Representation""]","This work proposed a universal visual representation for neural machine translation (NMT) using retrieved images with similar topics to source sentence,  extending image applicability in NMT.",,,,
BylA_C4tPr,2020,Accept (Poster),False,Composition-based Multi-Relational Graph Convolutional Networks,"[""Shikhar Vashishth"", ""Soumya Sanyal"", ""Vikram Nitin"", ""Partha Talukdar""]","[""Graph Convolutional Networks"", ""Multi-relational Graphs"", ""Knowledge Graph Embeddings"", ""Link Prediction""]",A Composition-based Graph Convolutional framework for multi-relational graphs.,1911.03082,cs.LG,2019-11-08 06:48:40+00:00,2020-01-18 22:50:01+00:00
BylB4kBtwB,2020,Reject,False,Retrieving Signals in the Frequency Domain with Deep Complex Extractors,"[""Chiheb Trabelsi"", ""Olexa Bilaniuk"", ""Ousmane Dia"", ""Ying Zhang"", ""Mirco Ravanelli"", ""Jonathan Binas"", ""Negar Rostamzadeh"", ""Christopher  J Pal""]","[""Deep Complex Networks"", ""Signal Extraction""]",New Signal Extraction Method in the Fourier Domain,,,,
BylBfnRqFm,2019,Reject,False,CAML: Fast Context Adaptation via Meta-Learning,"[""Luisa M Zintgraf"", ""Kyriacos Shiarlis"", ""Vitaly Kurin"", ""Katja Hofmann"", ""Shimon Whiteson""]",[],,,,,
BylBns0qtX,2019,Reject,False,On Learning Heteroscedastic Noise Models within Differentiable Bayes Filters,"[""Alina Kloss"", ""Jeannette Bohg""]","[""bayesian filtering"", ""heteroscedastic noise"", ""deep learning""]",We evaluate learning heteroscedastic noise models within different Differentiable Bayes Filters,,,,
BylBr3C9K7,2019,Accept (Poster),False,Energy-Constrained Compression for Deep Neural Networks via Weighted Sparse Projection and Layer Input Masking,"[""Haichuan Yang"", ""Yuhao Zhu"", ""Ji Liu""]","[""model compression"", ""inference energy saving"", ""deep neural network pruning""]",,,,,
BylD9eSYPS,2020,Reject,False,Clustered Reinforcement Learning,"[""Xiao Ma"", ""Shen-Yi Zhao"", ""Zhao-Heng Yin"", ""Wu-Jun Li""]",[],,,,,
BylDrRNKvH,2020,Reject,False,Understanding Attention Mechanisms,"[""Bingyuan Liu"", ""Yogesh Balaji"", ""Lingzhou Xue"", ""Martin Renqiang Min""]","[""Attention"", ""deep learning"", ""sample complexity"", ""self-attention""]",We analyze the loss landscape of neural networks with attention and explain why attention is helpful in training neural networks to achieve good performance.,,,,
BylE1205Fm,2019,Accept (Poster),False,Emerging Disentanglement in Auto-Encoder Based Unsupervised Image Content Transfer,"[""Ori Press"", ""Tomer Galanti"", ""Sagie Benaim"", ""Lior Wolf""]","[""Image-to-image Translation"", ""Disentanglement"", ""Autoencoders"", ""Faces""]",An image to image translation method which adds to one image the content of another thereby creating a new image.,,,,
BylEqnVFDB,2020,Accept (Poster),False,Curvature Graph Network,"[""Ze Ye"", ""Kin Sum Liu"", ""Tengfei Ma"", ""Jie Gao"", ""Chao Chen""]","[""Deep Learning"", ""Graph Convolution"", ""Ricci Curvature.""]",,,,,
BylIciRcYQ,2019,Accept (Poster),False,SGD Converges to Global Minimum in Deep Learning via Star-convex Path,"[""Yi Zhou"", ""Junjie Yang"", ""Huishuai Zhang"", ""Yingbin Liang"", ""Vahid Tarokh""]","[""SGD"", ""deep learning"", ""global minimum"", ""convergence""]",,,,,
BylJUTEKvB,2020,Reject,False,Cross-Iteration Batch Normalization,"[""Zhuliang Yao"", ""Yue Cao"", ""Shuxin Zheng"", ""Gao Huang"", ""Stephen Lin"", ""Jifeng Dai""]","[""batch normalization"", ""small batch size""]","We propose to borrow and compensate the statistics from previous iterations, to enhance statistics estimation quality in current iteration for batch normalization.",,,,
BylKL1SKvr,2020,Reject,True,Towards Understanding the Transferability of Deep Representations,"[""Hong Liu"", ""Mingsheng Long"", ""Jianmin Wang"", ""Michael I. Jordan""]","[""Transfer Learning"", ""Fine-tuning"", ""Deep Neural Networks""]","Understand transferability from the perspectives of improved generalization, optimization and the feasibility of transferability.",1909.12031,cs.LG,2019-09-26 11:23:34+00:00,2019-09-26 11:23:34+00:00
BylKwnEYvS,2020,Reject,False,Star-Convexity in Non-Negative Matrix Factorization,"[""Johan Bjorck"", ""Carla Gomes"", ""Kilian Weinberger""]","[""nmf"", ""convexity"", ""nonconvex optimization"", ""average-case-analysis""]",,,,,
BylNoaVYPS,2020,Reject,False,Variational Autoencoders for Opponent Modeling in Multi-Agent Systems,"[""Georgios Papoudakis"", ""Stefano V. Albrecht""]","[""reinforcement learning"", ""multi-agent systems"", ""representation learning""]",,2001.10829,cs.LG,2020-01-29 13:38:59+00:00,2020-01-29 13:38:59+00:00
BylPSkHKvB,2020,Reject,True,Natural- to formal-language generation using Tensor Product Representations,"[""Kezhen Chen"", ""Qiuyuan Huang"", ""Hamid Palangi"", ""Paul Smolensky"", ""Kenneth D. Forbus"", ""Jianfeng Gao""]","[""Neural Symbolic Reasoning"", ""Deep Learning"", ""Natural Language Processing"", ""Structural Representation"", ""Interpretation of Learned Representations""]","In this paper, we propose a new encoder-decoder model based on Tensor Product Representations for Natural- to Formal-language generation, called TP-N2F.",1910.02339,cs.CL,2019-10-05 22:57:04+00:00,2020-08-02 03:18:59+00:00
BylQSxHFwr,2020,Accept (Poster),False,AtomNAS: Fine-Grained End-to-End Neural Architecture Search,"[""Jieru Mei"", ""Yingwei Li"", ""Xiaochen Lian"", ""Xiaojie Jin"", ""Linjie Yang"", ""Alan Yuille"", ""Jianchao Yang""]","[""Neural Architecture Search"", ""Image Classification""]",A new state-of-the-art on Imagenet for mobile setting,1912.09640,cs.CV,2019-12-20 04:42:43+00:00,2020-02-23 13:08:53+00:00
BylQV305YQ,2019,Accept (Poster),False,Toward Understanding the Impact of Staleness in Distributed Machine Learning,"[""Wei Dai"", ""Yi Zhou"", ""Nanqing Dong"", ""Hao Zhang"", ""Eric Xing""]",[],Empirical and theoretical study of the effects of staleness in non-synchronous execution on machine learning algorithms.,,,,
BylQm1HKvB,2020,Reject,False,CONTRIBUTION OF INTERNAL REFLECTION IN LANGUAGE EMERGENCE WITH AN UNDER-RESTRICTED SITUATION,"[""Kense Todo"", ""Masayuki Yamamura""]","[""Language emergence"", ""Conceptual grounding"", ""Reflection"", ""Cognitive bias""]",,,,,
BylRVjC9K7,2019,Reject,False,Explaining Adversarial Examples with Knowledge Representation,"[""Xingyu Zhou"", ""Tengyu Ma"", ""Huahong Zhang""]","[""adversarial example"", ""knowledge representation"", ""distribution imitation""]",Hybird storage and representation of learned knowledge may be a reason for adversarial examples.,,,,
BylRkAEKDH,2020,Reject,True,TabNet: Attentive Interpretable Tabular Learning,"[""Sercan O. Arik"", ""Tomas Pfister""]","[""Tabular data"", ""interpretable neural networks"", ""attention models""]",We propose a novel high-performance interpretable deep tabular data learning network. ,1908.07442,cs.LG,2019-08-20 15:46:53+00:00,2020-12-09 05:00:33+00:00
BylSPv9gx,2017,Accept (Poster),False,Exploring Sparsity in Recurrent Neural Networks,"[""Sharan Narang"", ""Greg Diamos"", ""Shubho Sengupta"", ""Erich Elsen""]","[""Speech"", ""Deep learning"", ""Supervised Learning""]",Reduce parameter count in recurrent neural networks to create smaller models for faster deployment,,,,
BylT8RNKPH,2020,Reject,False,A Base Model Selection Methodology for Efficient Fine-Tuning,"[""Yosuke Ueno"", ""Masaaki Kondo""]","[""transfer learning"", ""fine-tuning"", ""parameter transfer""]", We propose several metrics to estimate the transferability of pre-trained CNN models for a given target task.,,,,
BylTta4YvB,2020,Reject,False,How Well Do WGANs Estimate the Wasserstein Metric?,"[""Anton Mallasto"", ""Guido Mont\u00fafar"", ""Augusto Gerolin""]","[""Optimal Transport"", ""Wasserstein Metric"", ""Generative Adversial Networks""]",A study of how well different methods used to compute the 1-Wasserstein distance in the GAN setting actually perform.,,,,
BylTy1HFDS,2020,Reject,False,Deep unsupervised feature selection,"[""Ian Covert"", ""Uygar Sumbul"", ""Su-In Lee""]","[""Single cell rna"", ""microarray"", ""feature selection"", ""feature ranking""]","To perform well in downstream prediction tasks, features are selected by learning a ""restricted autoencoder"" that iteratively eliminates features that aren't necessary for accurate reconstruction.",,,,
BylUMxSFwS,2020,Reject,False,Disentangled Cumulants Help Successor Representations Transfer to New Tasks,"[""Chris Grimm"", ""Irina Higgins"", ""Andre Barreto"", ""Denis Teplyashin"", ""Markus Wulfmeier"", ""Tim Hertweck"", ""Raia Hadsell"", ""Satinder Singh""]","[""reinforcement learning"", ""representation learning"", ""intrinsic reward"", ""intrinsic control"", ""endogenous"", ""generalized policy improvement"", ""successor features"", ""variational"", ""monet"", ""disentangled""]",We show in the absence of external reward that agents can leverage knowledge from unsupervised control of latent features to solve downstream tasks and that when these latent features are disentangled superior performance is achieved.,,,,
BylVcTNtDS,2020,Accept (Poster),True,A Target-Agnostic Attack on Deep Models: Exploiting Security Vulnerabilities of Transfer Learning,"[""Shahbaz Rezaei"", ""Xin Liu""]","[""Machine learning security"", ""Transfer learning"", ""deep learning security"", ""Softmax Vulnerability"", ""Transfer learning Security""]",,1904.04334,cs.LG,2019-04-08 20:03:28+00:00,2020-01-29 06:51:13+00:00
BylWYC4KwH,2020,Reject,False,On Concept-Based Explanations in Deep Neural Networks,"[""Chih-Kuan Yeh"", ""Been Kim"", ""Sercan Arik"", ""Chun-Liang Li"", ""Pradeep Ravikumar"", ""Tomas Pfister""]","[""concept-based explanations"", ""interpretability""]",we propose a concept-based explanation for DNNs that is both sufficient for prediction (complete) and interpretable,,,,
BylWglrYPH,2020,Reject,False,Symmetry and Systematicity,"[""Jeff Mitchell"", ""Jeff Bowers""]","[""symmetry"", ""systematicity"", ""convolution"", ""symbols"", ""generalisation""]",We use convolution to make neural networks behave more like symbolic systems.,,,,
BylXi3NKvS,2020,Reject,False,FALCON: Fast and Lightweight Convolution for Compressing and Accelerating CNN,"[""Chun Quan"", ""Jun-Gi Jang"", ""Hyun Dong Lee"", ""U Kang""]","[""CNN compression"", ""CNN acceleration"", ""model compression""]",FALCON is an accurate and lightweight method for compressing CNNs based on depthwise separable convolution.,,,,
Byl_ciRcY7,2019,Reject,False,ON BREIMANâS DILEMMA IN NEURAL NETWORKS: SUCCESS AND FAILURE OF NORMALIZED MARGINS,"[""Yifei HUANG"", ""Yuan YAO"", ""Weizhi ZHU""]","[""Bregman's Dilemma"", ""Generalization Error"", ""Margin"", ""Spectral normalization""]","Bregman's dilemma is shown in deep learning that improvement of margins of over-parameterized models may result in overfitting, and dynamics of normalized margin distributions are proposed to predict generalization error and identify such a dilemma. ",,,,
Byla224KPr,2020,Reject,True,An Empirical Study on Post-processing Methods for Word Embeddings,"[""Shuai Tang"", ""Mahta Mousavi"", ""Virginia R. de Sa""]","[""word vectors"", ""post-processing method"", ""centralised kernel alignment"", ""shrinkage""]",,1905.10971,cs.LG,2019-05-27 04:49:45+00:00,2019-10-23 20:21:49+00:00
BylaUTNtPS,2020,Reject,False,Recurrent Independent Mechanisms,"[""Anirudh Goyal"", ""Alex Lamb"", ""Shagun Sodhani"", ""Jordan Hoffmann"", ""Sergey Levine"", ""Yoshua Bengio"", ""Bernhard Scholkopf""]","[""modular representations"", ""better generalization"", ""learning mechanisms""]","Learning recurrent mechanisms which operate independently, and sparingly interact  can lead to better generalization to out of distribution samples.",,,,
BylalAEtvB,2020,Reject,False,Lipschitz Lifelong Reinforcement Learning,"[""Erwan Lecarpentier"", ""David Abel"", ""Kavosh Asadi"", ""Yuu Jinnai"", ""Emmanuel Rachelson"", ""Michael L. Littman""]","[""Reinforcement Learning"", ""Lifelong Learning""]",We analyze theoretically how the optimal value function changes across tasks and derive a method for non-negative transfer of value functions in Lifelong Reinforcement Learning.,,,,
BylctiCctX,2019,Reject,False,Guiding Physical Intuition with Neural Stethoscopes,"[""Fabian Fuchs"", ""Oliver Groth"", ""Adam Kosiorek"", ""Alex Bewley"", ""Markus Wulfmeier"", ""Andrea Vedaldi"", ""Ingmar Posner""]","[""Deep Learning"", ""Intuitive Physics"", ""Stability Prediction"", ""Adversarial Training"", ""Auxiliary Training"", ""Multi-Task Learning""]",Combining auxiliary and adversarial training to interrogate and help physical understanding.,,,,
ByldLrqlx,2017,Accept (Poster),False,DeepCoder: Learning to Write Programs,"[""Matej Balog"", ""Alexander L. Gaunt"", ""Marc Brockschmidt"", ""Sebastian Nowozin"", ""Daniel Tarlow""]","[""Deep learning"", ""Supervised Learning"", ""Applications"", ""Structured prediction""]",,,,,
ByldlhAqYQ,2019,Accept (Poster),False,Transfer Learning for Sequences via Learning to Collocate,"[""Wanyun Cui"", ""Guangyu Zheng"", ""Zhiqiang Shen"", ""Sihang Jiang"", ""Wei Wang""]","[""transfer learning"", ""recurrent neural network"", ""attention"", ""natural language processing""]",Transfer learning for sequence via learning to align cell-level information across domains.,,,,
Byldr3RqKX,2019,Reject,False,Tinkering with black boxes: counterfactuals uncover modularity in generative models,"[""Michel Besserve"", ""Remy Sun"", ""Bernhard Schoelkopf""]","[""generatice models"", ""causality"", ""disentangled representations""]",We investigate the modularity of deep generative models.,,,,
ByleB2CcKm,2019,Accept (Poster),False,Learning Procedural Abstractions and Evaluating Discrete Latent Temporal Structure,"[""Karan Goel"", ""Emma Brunskill""]","[""learning procedural abstractions"", ""latent variable modeling"", ""evaluation criteria""]",,,,,
BylfTySYvB,2020,Reject,False,GATO: Gates Are Not the Only Option,"[""Mark Goldstein*"", ""Xintian Han*"", ""Rajesh Ranganath""]","[""Sequence Models"", ""Vanishing Gradients"", ""Recurrent neural networks"", ""Long-term dependence""]","Recurrent neural networks can avoid vanishing gradients by not using all of their hidden state in recurrences, together with a residual structure.",,,,
Bylh2krYPr,2020,Reject,False,Probing Emergent Semantics in Predictive Agents via Question Answering,"[""Abhishek Das"", ""Federico Carnevale"", ""Hamza Merzic"", ""Laura Rimell"", ""Rosalia Schneider"", ""Alden Hung"", ""Josh Abramson"", ""Arun Ahuja"", ""Stephen Clark"", ""Greg Wayne"", ""Felix Hill""]","[""question-answering"", ""predictive models""]",We use question-answering to evaluate how much knowledge about the environment can agents learn by self-supervised prediction.,,,,
ByliZgBKPH,2020,Reject,False,Policy path programming,"[""Daniel McNamee""]","[""markov decision process"", ""planning"", ""hierarchical"", ""reinforcement learning""]",A normative theory of hierarchical model-based policy optimization,,,,
ByljMaNKwB,2020,Reject,False,Domain Aggregation Networks for Multi-Source Domain Adaptation,"[""Junfeng Wen"", ""Russell Greiner"", ""Dale Schuurmans""]","[""Domain Adaptation"", ""Transfer Learning"", ""Deep Learning""]",,,,,
BylkG20qYm,2019,Reject,False,On Meaning-Preserving Adversarial Perturbations for Sequence-to-Sequence Models,"[""Paul Michel"", ""Graham Neubig"", ""Xian Li"", ""Juan Miguel Pino""]","[""Sequence-to-sequence"", ""adversarial attacks"", ""evaluation"", ""meaning preservation"", ""machine translation""]",How you should evaluate adversarial attacks on seq2seq,,,,
Bylkd0EFwr,2020,Reject,False,Bio-Inspired Hashing for Unsupervised Similarity Search,"[""Chaitanya K. Ryali"", ""John J. Hopfield"", ""Dmitry Krotov""]","[""unsupervised learning"", ""similarity search"", ""neuroscience""]",We propose a biologically motivated hashing algorithm that demonstrates good empirical performance.,,,,
BylldnNFwS,2020,Reject,False,On the Decision Boundaries of Deep Neural Networks: A Tropical Geometry Perspective,"[""Motasem Alfarra"", ""Adel Bibi"", ""Hasan Hammoud"", ""Mohamed Gaafar"", ""Bernard Ghanem""]","[""Decision boundaries"", ""Neural Network"", ""Tropical Geometry"", ""Network Pruning"", ""Adversarial Attacks"", ""Lottery Ticket Hypothesis""]",Tropical geometry can be leveraged to represent the decision boundaries of neural networks and bring to light interesting insights.,2002.08838,cs.LG,2020-02-20 16:22:44+00:00,2021-02-10 17:03:45+00:00
BylldxBYwH,2020,Reject,False,Physics-Aware Flow Data Completion Using Neural Inpainting,"[""Sebastien Foucher"", ""Jingwei Tang"", ""Vinicius da Costa de Azevedo"", ""Byungsoo Kim"", ""Markus Gross"", ""Barbara Solenthaler""]","[""neural inpainting"", ""fluid dynamics"", ""flow data completion"", ""physics-aware network""]",We present a network architecture and loss functions for inpainting fluid flow data that considers physical properties and constraints.,,,,
Bylmkh05KX,2019,Accept (Poster),False,Unsupervised Speech Recognition via Segmental Empirical Output Distribution Matching,"[""Chih-Kuan Yeh"", ""Jianshu Chen"", ""Chengzhu Yu"", ""Dong Yu""]","[""Unsupervised speech recognition"", ""unsupervised learning"", ""phoneme classification""]",,,,,
Bylnx209YX,2019,Accept (Poster),False,Adversarial Attacks on Graph Neural Networks via Meta Learning,"[""Daniel Z\u00fcgner"", ""Stephan G\u00fcnnemann""]","[""graph mining"", ""adversarial attacks"", ""meta learning"", ""graph neural networks"", ""node classification""]",We use meta-gradients to attack the training procedure of deep neural networks for graphs.,,,,
ByloIiCqYQ,2019,Accept (Poster),False,Maximal Divergence Sequential Autoencoder for Binary Software Vulnerability Detection,"[""Tue Le"", ""Tuan Nguyen"", ""Trung Le"", ""Dinh Phung"", ""Paul Montague"", ""Olivier De Vel"", ""Lizhen Qu""]","[""Vulnerabilities Detection"", ""Sequential Auto-Encoder"", ""Separable Representation""]",We propose a novel method named Maximal Divergence Sequential Auto-Encoder that leverages Variational AutoEncoder representation for binary code vulnerability detection.,,,,
ByloJ20qtm,2019,Accept (Poster),False,Neural Program Repair by Jointly Learning to Localize and Repair,"[""Marko Vasic"", ""Aditya Kanade"", ""Petros Maniatis"", ""David Bieber"", ""Rishabh Singh""]","[""neural program repair"", ""neural program embeddings"", ""pointer networks""]",Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs,,,,
Bylp62EKDH,2020,Reject,False,Extreme Triplet Learning: Effectively Optimizing Easy Positives and Hard Negatives,"[""Hong Xuan"", ""Robert Pless""]","[""Triplet Learning"", ""Easy Positive"", ""Hard Negatives""]",,,,,
BylsKkHYvH,2020,Accept (Poster),True,Why Not to Use Zero Imputation? Correcting Sparsity Bias in Training Neural Networks,"[""Joonyoung Yi"", ""Juhyuk Lee"", ""Kwang Joon Kim"", ""Sung Ju Hwang"", ""Eunho Yang""]","[""Missing Data"", ""Collaborative Filtering"", ""Health Care"", ""Tabular Data"", ""High Dimensional Data"", ""Deep Learning"", ""Neural Networks""]",,1906.00150,cs.LG,2019-06-01 04:03:53+00:00,2020-02-06 08:43:31+00:00
Bylthp4Yvr,2020,Reject,False,Dropout: Explicit Forms and Capacity Control,"[""Raman Arora"", ""Peter L. Bartlett"", ""Poorya Mianjy"", ""Nathan Srebro""]",[],,,,,
Bylx-TNKvH,2020,Accept (Poster),False,Functional vs. parametric equivalence of ReLU networks,"[""Mary Phuong"", ""Christoph H. Lampert""]","[""ReLU networks"", ""symmetry"", ""functional equivalence"", ""over-parameterization""]",We prove that there exist ReLU networks whose parameters are almost uniquely determined by the function they implement.,,,,
BylyV1BtDB,2020,Reject,False,FR-GAN: Fair and Robust Training,"[""Yuji Roh"", ""Kangwook Lee"", ""Gyeong Jo Hwang"", ""Steven Euijong Whang"", ""Changho Suh""]","[""generative adversarial networks"", ""model fairness"", ""model robustness""]","We propose FR-GAN, which holistically performs fair and robust model training using generative adversarial networks. ",,,,
Bym0cU1CZ,2018,Reject,False,Towards Interpretable Chit-chat: Open Domain Dialogue Generation with Dialogue Acts,"[""Wei Wu"", ""Can Xu"", ""Yu Wu"", ""Zhoujun Li""]","[""dialogue generation"", ""dialogue acts"", ""open domain conversation"", ""supervised learning"", ""reinforcement learning""]",open domain dialogue generation with dialogue acts,,,,
BymIbLKgl,2017,Accept (Poster),False,Learning Invariant Representations Of Planar Curves ,"[""Gautam Pai"", ""Aaron Wetzler"", ""Ron Kimmel""]","[""Computer vision"", ""Deep learning"", ""Supervised Learning"", ""Applications""]",,,,,
ByqFhGZCW,2018,Reject,False,MACHINE VS MACHINE: MINIMAX-OPTIMAL DEFENSE AGAINST ADVERSARIAL EXAMPLES,"[""Jihun Hamm""]",[],A game-theoretic solution to adversarial attacks and defenses.,,,,
ByqiJIqxg,2017,Accept (Poster),False,Online Bayesian Transfer Learning for Sequential Data Modeling,"[""Priyank Jaini"", ""Zhitang Chen"", ""Pablo Carbajal"", ""Edith Law"", ""Laura Middleton"", ""Kayla Regan"", ""Mike Schaekermann"", ""George Trimponias"", ""James Tung"", ""Pascal Poupart""]","[""Unsupervised Learning"", ""Transfer Learning"", ""Applications""]",,,,,
ByquB-WC-,2018,Reject,False,Finding ReMO (Related Memory Object): A Simple neural architecture for Text based Reasoning,"[""Jihyung Moon"", ""Hyochang Yang"", ""Sungzoon Cho""]","[""Natural Language Processing"", ""Deep Learning"", ""Reasoning""]","A simple reasoning architecture based on the memory network (MemNN) and relation network (RN), reducing the time complexity compared to the RN and achieving state-of-the-are result on bAbI story based QA and bAbI dialog.",,,,
ByrZyglCb,2018,Accept (Poster),False,Robustness of Classifiers to Universal Perturbations: A Geometric Perspective,"[""Seyed-Mohsen Moosavi-Dezfooli"", ""Alhussein Fawzi"", ""Omar Fawzi"", ""Pascal Frossard"", ""Stefano Soatto""]","[""Universal perturbations"", ""robustness"", ""curvature""]",Analysis of vulnerability of classifiers to universal perturbations and relation to the curvature of the decision boundary.,,,,
Bys4ob-Rb,2018,Accept (Poster),False,Certified Defenses against Adversarial Examples ,"[""Aditi Raghunathan"", ""Jacob Steinhardt"", ""Percy Liang""]","[""adversarial examples"", ""certificate of robustness"", ""convex relaxations""]","We demonstrate a certifiable, trainable, and scalable method for defending against adversarial examples.",,,,
BysZhEqee,2017,Reject,False,Marginal Deep Architectures: Deep learning for Small and Middle Scale Applications,"[""Yuchen Zheng"", ""Guoqiang Zhong"", ""Junyu Dong""]",[],,,,,
Bys_NzbC-,2018,Reject,False,Achieving Strong Regularization for Deep Neural Networks,"[""Dae Hoon Park"", ""Chiu Man Ho"", ""Yi Chang""]","[""deep learning"", ""regularization""]",We investigate how and why strong L1/L2 regularization fails and propose a method than can achieve strong regularization.,,,,
BysvGP5ee,2017,Accept (Poster),False,Variational Lossy Autoencoder,"[""Xi Chen"", ""Diederik P. Kingma"", ""Tim Salimans"", ""Yan Duan"", ""Prafulla Dhariwal"", ""John Schulman"", ""Ilya Sutskever"", ""Pieter Abbeel""]","[""Deep learning"", ""Unsupervised Learning""]",A VAE that provably learns global structure of images with a local PixelCNN decoder.,,,,
Byt3oJ-0W,2018,Accept (Poster),False,Learning Latent Permutations with Gumbel-Sinkhorn Networks,"[""Gonzalo Mena"", ""David Belanger"", ""Scott Linderman"", ""Jasper Snoek""]","[""Permutation"", ""Latent"", ""Sinkhorn"", ""Inference"", ""Optimal Transport"", ""Gumbel"", ""Softmax"", ""Sorting""]","A new method for gradient-descent inference of permutations, with applications to latent matching inference and supervised learning of permutations with neural networks",,,,
ByuI-mW0W,2018,Reject,False,Towards a Testable Notion of Generalization for Generative Adversarial Networks,"[""Robert Cornish"", ""Hongseok Yang"", ""Frank Wood""]","[""generative adversarial networks"", ""Wasserstein"", ""GAN"", ""generalization"", ""theory""]",Assess whether or not your GAN is actually doing something other than memorizing the training data.,,,,
ByuP8yZRb,2018,Reject,False,Censoring Representations with Multiple-Adversaries over Random Subspaces,"[""Yusuke Iwasawa"", ""Kotaro Nakayama"", ""Yutaka Matsuo""]","[""Adversarial Training"", ""Privacy Protection"", ""Random Subspace""]","This paper improves the quality of the recently proposed adversarial feature leaning (AFL) approach for incorporating explicit constrains to representations, by introducing the concept of the {\em vulnerableness} of the adversary. ",,,,
ByvJuTigl,2017,Reject,False,End-to-End Learnable Histogram Filters,"[""Rico Jonschkowski"", ""Oliver Brock""]","[""Deep learning"", ""Unsupervised Learning""]",a way to combine the algorithmic structure of Bayes filters with the end-to-end learnability of neural networks,,,,
BywyFQlAW,2018,Accept (Poster),False,Minimax Curriculum Learning: Machine Teaching with Desirable Difficulties and Scheduled Diversity,"[""Tianyi Zhou"", ""Jeff Bilmes""]","[""machine teaching"", ""deep learning"", ""minimax"", ""curriculum learning"", ""submodular"", ""diversity""]",Minimax Curriculum Learning is a machine teaching method involving increasing desirable hardness and scheduled reducing diversity.,,,,
Byx0PREtDH,2020,Reject,False,BEYOND SUPERVISED LEARNING: RECOGNIZING UNSEEN ATTRIBUTE-OBJECT PAIRS WITH VISION-LANGUAGE FUSION AND ATTRACTOR NETWORKS,"[""Hui Chen"", ""Zhixiong Nan"", ""Nanning Zheng""]","[""image understanding""]",,,,,
Byx0iAEYPH,2020,Reject,False,Fully Polynomial-Time Randomized Approximation Schemes for Global Optimization of High-Dimensional Folded Concave Penalized Generalized Linear Models,"[""Charles Hernandez"", ""Hungyi Lee"", ""Hongchen Liu""]","[""statistical learning"", ""FPRAS"", ""global optimization"", ""folded concave penalty"", ""GLM"", ""high dimensional learning""]",This paper primarily demonstrates a technique to find the global optima of FCP regularized GLMs which is to our knowledge the first of its kind.,,,,
Byx1VnR9K7,2019,Reject,False,Trajectory VAE for multi-modal imitation,"[""Xiaoyu Lu"", ""Jan Stuehmer"", ""Katja Hofmann""]","[""imitation learning"", ""latent variable model"", ""variational autoencoder"", ""diverse behaviour""]",A trajectory-VAE method for imitating multi-modal expert demonstrations in sequential decision making problems.,,,,
Byx4NkrtDS,2020,Accept (Poster),False,Implementing Inductive bias for different navigation tasks through diverse RNN attrractors,"[""Tie XU"", ""Omri Barak""]","[""navigation"", ""Recurrent Neural Networks"", ""dynamics"", ""inductive bias"", ""pre-training"", ""reinforcement learning""]","Task agnostic pre-training can shape RNN's attractor landscape, and form diverse inductive bias for different navigation tasks   ",2002.02496,q-bio.NC,2020-02-06 20:05:13+00:00,2020-02-06 20:05:13+00:00
Byx55pVKDB,2020,Reject,False,How the Softmax Activation Hinders the Detection of Adversarial and Out-of-Distribution Examples in Neural Networks,"[""Jonathan Aigrain"", ""Marcin Detyniecki""]","[""Adversarial examples"", ""out-of-distribution"", ""detection"", ""softmax"", ""logits""]"," The softmax activation hinders the detection of adversarial and out-of-distribution examples, as it masks a significant part of the relevant information present in the logits.",,,,
Byx5BTilg,2017,Reject,False,Exploring the Application of Deep Learning for Supervised Learning Problems,"[""Jose Rozanec"", ""Gilad Katz"", ""Eui Chul Richard Shin"", ""Dawn Song""]","[""Deep learning"", ""Supervised Learning""]",We explore the multiple DNN architectures on a large set of general supervised datasets. We also propose a meta-learning approach for DNN performance prediciton and ranking,,,,
Byx5R0NKPr,2020,Reject,True,Learning Calibratable Policies using Programmatic Style-Consistency,"[""Eric Zhan"", ""Albert Tseng"", ""Yisong Yue"", ""Adith Swaminathan"", ""Matthew Hausknecht""]","[""imitation learning"", ""conditional generation"", ""data programming""]",We introduce a framework for style-consistent imitation of diverse behaviors.,1910.01179,cs.LG,2019-10-02 19:34:51+00:00,2020-07-16 04:42:13+00:00
Byx7LjRcYm,2019,Reject,False,Human Action Recognition Based on Spatial-Temporal Attention,"[""Wensong Chan"", ""Zhiqiang Tian"", ""Xuguang Lan""]",[],,,,,
Byx83s09Km,2019,Accept (Poster),False,Information-Directed Exploration for Deep Reinforcement Learning,"[""Nikolay Nikolov"", ""Johannes Kirschner"", ""Felix Berkenkamp"", ""Andreas Krause""]","[""reinforcement learning"", ""exploration"", ""information directed sampling""]","We develop a practical extension of Information-Directed Sampling for Reinforcement Learning, which accounts for parametric uncertainty and heteroscedasticity in the return distribution for exploration.",,,,
Byx91R4twB,2020,Reject,True,Adversarial Video Generation on Complex Datasets,"[""Aidan Clark"", ""Jeff Donahue"", ""Karen Simonyan""]","[""GAN"", ""generative model"", ""generative adversarial network"", ""video prediction""]","We propose DVD-GAN, a large video generative model that is state of the art on several tasks and produces highly complex videos when trained on large real world datasets.",1907.06571,cs.CV,2019-07-15 16:27:04+00:00,2019-09-25 16:37:55+00:00
Byx93sC9tm,2019,Reject,False,Deep Ensemble Bayesian Active Learning : Adressing the Mode Collapse issue in Monte Carlo dropout via Ensembles,"[""Remus Pop"", ""Patric Fulop""]","[""Active Learning"", ""Deep Learning"", ""Bayesian Neural Networks"", ""Bayesian Deep Learning"", ""Ensembles""]",We present a method for Deep Bayesian Active Learning combining MC-Dropout with Ensemble Models,,,,
Byx9p2EtDH,2020,Reject,True,MULTIPOLAR: Multi-Source Policy Aggregation for Transfer Reinforcement Learning between Diverse Environmental Dynamics,"[""Mohammadamin Barekatain"", ""Ryo Yonetani"", ""Masashi Hamaya""]","[""reinforcement learning"", ""transfer learning"", ""policy aggregation"", ""residual policy learning""]","We propose MULTIPOLAR, a transfer RL method that leverages a set of source policies collected under unknown diverse environmental dynamics to efficiently learn a target policy in another dynamics.",1909.13111,cs.LG,2019-09-28 15:13:46+00:00,2020-12-10 00:21:32+00:00
ByxAOoR5K7,2019,Reject,False,Policy Generalization In Capacity-Limited Reinforcement Learning,"[""Rachel A. Lerch"", ""Chris R. Sims""]","[""reinforcement learning"", ""generalization"", ""capacity constraints"", ""information theory""]",This paper describes the application of rate-distortion theory to the learning of efficient (capacity limited) policy representations in the reinforcement learning setting.,,,,
ByxAcjCqt7,2019,Reject,False,Point Cloud GAN,"[""Chun-Liang Li"", ""Manzil Zaheer"", ""Yang Zhang"", ""Barnab\u00e1s P\u00f3czos"", ""Ruslan Salakhutdinov""]","[""Point Cloud"", ""GAN""]","We propose a GAN variant which learns to generate point clouds. Different studies have been explores, including tighter Wasserstein distance estimate,  conditional generation, generalization to unseen point clouds and image to point cloud.",,,,
ByxBFsRqYm,2019,Accept (Poster),False,"Attention, Learn to Solve Routing Problems!","[""Wouter Kool"", ""Herke van Hoof"", ""Max Welling""]","[""learning"", ""routing problems"", ""heuristics"", ""attention"", ""reinforce"", ""travelling salesman problem"", ""vehicle routing problem"", ""orienteering problem"", ""prize collecting travelling salesman problem""]",Attention based model trained with REINFORCE with greedy rollout baseline to learn heuristics with competitive results on TSP and other routing problems,,,,
ByxCrerKvS,2020,Reject,False,Set Functions for Time Series,"[""Max Horn"", ""Michael Moor"", ""Christian Bock"", ""Bastian Rieck"", ""Karsten Borgwardt""]","[""Time Series"", ""Set functions"", ""Irregularly sampling"", ""Medical Time series"", ""Dynamical Systems"", ""Time series classification""]",We propose a novel method for the scalable and interpretable classification of irregularly sampled time series.,,,,
ByxF-nAqYX,2019,Reject,False,Locally Linear Unsupervised Feature Selection,"[""Guillaume DOQUET"", ""Mich\u00e8le SEBAG""]","[""Unsupervised Learning"", ""Feature Selection"", ""Dimension Reduction""]",Unsupervised feature selection through capturing the local linear structure of the data,,,,
ByxGSsR9FQ,2019,Accept (Poster),False,L2-Nonexpansive Neural Networks,"[""Haifeng Qian"", ""Mark N. Wegman""]","[""adversarial defense"", ""regularization"", ""robustness"", ""generalization""]",,,,,
ByxGkySKwH,2020,Accept (Poster),True,Towards neural networks that provably know when they don't know,"[""Alexander Meinke"", ""Matthias Hein""]",[],,1909.12180,cs.LG,2019-09-26 15:20:08+00:00,2020-02-21 09:27:11+00:00
ByxHJeBYDB,2020,Reject,False,Forecasting Deep Learning Dynamics with Applications to Hyperparameter Tuning,"[""Piotr Kozakowski"", ""\u0141ukasz Kaiser"", ""Afroz Mohiuddin""]",[],,,,,
ByxHb3R5tX,2019,Reject,False,Universal Successor Features for Transfer Reinforcement Learning,"[""Chen Ma"", ""Dylan R. Ashley"", ""Junfeng Wen"", ""Yoshua Bengio""]","[""Reinforcement Learning"", ""Successor Features"", ""Successor Representations"", ""Transfer Learning"", ""Representation Learning""]",,,,,
ByxJO3VFwB,2020,Reject,True,Probabilistic modeling the hidden layers of deep neural networks,"[""Xinjie Lan"", ""Kenneth E. Barner""]","[""Neural Networks"", ""Gaussian Process"", ""Probabilistic Representation for Deep Learning""]","The Gaussian Process cannot correctly explain all the hidden layers of neural networks. Alternatively, we propose a novel probabilistic representation for deep learning ",1908.09772,cs.LG,2019-08-26 16:18:22+00:00,2019-08-26 16:18:22+00:00
ByxJjlHKwr,2020,Reject,False,Learning Latent State Spaces for Planning through Reward Prediction,"[""Aaron Havens"", ""Yi Ouyang"", ""Prabhat Nagarajan"", ""Yasuhiro Fujita""]","[""Deep Reinforcement Learning"", ""Representation Learning"", ""Model Based Reinforcement Learning""]",A latent reward prediction model is learned to achieve concise representation and plan efficiently using MPC.,1912.04201,cs.LG,2019-12-09 17:32:51+00:00,2019-12-09 17:32:51+00:00
ByxKo04tvr,2020,Reject,True,Multigrid Neural Memory,"[""Tri Huynh"", ""Michael Maire"", ""Matthew R. Walter""]","[""multigrid architecture"", ""memory network"", ""convolutional neural network""]","A novel neural memory architecture that co-locates memory and computation throughout the network structure, providing addressable, scalable, long-term and large capacity neural memory.",1906.05948,cs.LG,2019-06-13 22:10:01+00:00,2020-08-15 21:12:15+00:00
ByxLBMZCb,2018,Invite to Workshop Track,False,Learning Deep Models: Critical Points and Local Openness,"[""Maher Nouiehed"", ""Meisam Razaviyayn""]","[""Training Deep Models"", ""Non-convex Optimization"", ""Local and Global Equivalence"", ""Local Openness""]",,,,,
ByxLl309Ym,2019,Reject,False,Conditional Inference in Pre-trained Variational Autoencoders via Cross-coding,"[""Ga Wu"", ""Justin Domke"", ""Scott Sanner""]",[],,,,,
ByxODxHYwB,2020,Reject,False,Multi-source Multi-view Transfer Learning in Neural Topic Modeling with Pretrained Topic and Word Embeddings,"[""Pankaj Gupta"", ""Yatin Chaudhary"", ""Hinrich Sch\u00fctze""]","[""Neural Topic Modeling"", ""Transfer Learning"", ""Unsupervised learning"", ""Natural Language Processing""]",Transfer learning in Neural Topic Modeling using Pretrained Word and Topic Embeddings jointly from one or many sources to improve quality of topics and document representations in sparse-data settings ,,,,
ByxPYjC5KQ,2019,Accept (Poster),False,Improving Generalization and Stability of Generative Adversarial Networks,"[""Hoang Thanh-Tung"", ""Truyen Tran"", ""Svetha Venkatesh""]","[""GAN"", ""generalization"", ""gradient penalty"", ""zero centered"", ""convergence""]",We propose a zero-centered gradient penalty for improving generalization and stability of GANs,1902.03984,cs.LG,2019-02-11 16:44:16+00:00,2019-02-11 16:44:16+00:00
ByxQB1BKwH,2020,Accept (Poster),False,Abstract Diagrammatic Reasoning with Multiplex Graph Networks,"[""Duo Wang"", ""Mateja Jamnik"", ""Pietro Lio""]","[""reasoning"", ""Raven Progressive Matrices"", ""graph neural networks"", ""multiplex graphs""]","MXGNet is a multilayer, multiplex graph based architecture which achieves good performance on various diagrammatic reasoning tasks.",2006.11197,cs.LG,2020-06-19 15:50:25+00:00,2020-06-19 15:50:25+00:00
ByxRM0Ntvr,2020,Accept (Poster),False,Are Transformers universal approximators of sequence-to-sequence functions?,"[""Chulhee Yun"", ""Srinadh Bhojanapalli"", ""Ankit Singh Rawat"", ""Sashank Reddi"", ""Sanjiv Kumar""]","[""Transformer"", ""universal approximation"", ""contextual mapping"", ""expressive power"", ""permutation equivariance""]",We prove that Transformer networks are universal approximators of sequence-to-sequence functions.,,,,
ByxT7TNFvH,2020,Accept (Poster),False,Semantically-Guided Representation Learning for Self-Supervised Monocular Depth,"[""Vitor Guizilini"", ""Rui Hou"", ""Jie Li"", ""Rares Ambrus"", ""Adrien Gaidon""]","[""computer vision"", ""machine learning"", ""deep learning"", ""monocular depth estimation"", ""self-supervised learning""]",We propose a novel semantically-guided architecture for self-supervised monocular depth estimation,2002.12319,cs.CV,2020-02-27 18:40:10+00:00,2020-02-27 18:40:10+00:00
ByxXZpVtPB,2020,Reject,False,Homogeneous Linear Inequality Constraints for Neural Network Activations,"[""Thomas Frerix"", ""Matthias Nie\u00dfner"", ""Daniel Cremers""]","[""deep learning"", ""constrained optimization""]","We enforce homogeneous linear inequality constraints on neural network activations by directly incorporating these constraints into the architecture, which yields a significant speed-up at test time.",,,,
ByxY8CNtvr,2020,Accept (Poster),False,Improving Neural Language Generation with Spectrum Control,"[""Lingxiao Wang"", ""Jing Huang"", ""Kevin Huang"", ""Ziniu Hu"", ""Guangtao Wang"", ""Quanquan Gu""]",[],,,,,
ByxZX20qFQ,2019,Accept (Poster),False,Adaptive Input Representations for Neural Language Modeling,"[""Alexei Baevski"", ""Michael Auli""]","[""Neural language modeling""]","Variable capacity input word embeddings and SOTA on WikiText-103, Billion Word benchmarks.",,,,
ByxZdj09tX,2019,Reject,False,"FROM DEEP LEARNING TO DEEP DEDUCING: AUTOMATICALLY TRACKING DOWN NASH EQUILIBRIUM THROUGH AUTONOMOUS NEURAL AGENT, A POSSIBLE MISSING STEP TOWARD GENERAL A.I.","[""Brown Wang""]","[""Reinforcement Learning"", ""Deep Feed-forward Neural Network"", ""Recurrent Neural Network"", ""Game Theory"", ""Control Theory"", ""Nash Equilibrium"", ""Optimization""]",FROM DEEP LEARNING TO DEEP DEDUCING,,,,
Byx_YAVYPH,2020,Accept (Poster),False,Jelly Bean World: A Testbed for Never-Ending Learning,"[""Emmanouil Antonios Platanios"", ""Abulhair Saparov"", ""Tom Mitchell""]",[],,2002.06306,cs.LG,2020-02-15 02:43:16+00:00,2020-02-15 02:43:16+00:00
ByxaUgrFvH,2020,Accept (Poster),False,Mutual Information Gradient Estimation for  Representation Learning,"[""Liangjian Wen"", ""Yiji Zhou"", ""Lirong He"", ""Mingyuan Zhou"", ""Zenglin Xu""]","[""Mutual Information"", ""Score Estimation"", ""Representation Learning"", ""Information Bottleneck""]",,2005.01123,stat.ML,2020-05-03 16:05:58+00:00,2020-05-03 16:05:58+00:00
ByxdUySKvS,2020,Accept (Poster),False,Adversarial AutoAugment,"[""Xinyu Zhang"", ""Qiang Wang"", ""Jian Zhang"", ""Zhao Zhong""]","[""Automatic Data Augmentation"", ""Adversarial Learning"", ""Reinforcement Learning""]",We introduce the idea of adversarial learning into automatic data augmentation to improve the generalization  of a targe network.,1912.11188,cs.CV,2019-12-24 03:17:17+00:00,2019-12-24 03:17:17+00:00
ByxduJBtPB,2020,Reject,False,When Covariate-shifted Data Augmentation Increases Test Error And How to Fix It,"[""Sang Michael Xie*"", ""Aditi Raghunathan*"", ""Fanny Yang"", ""John C. Duchi"", ""Percy Liang""]","[""data augmentation"", ""adversarial training"", ""interpolation"", ""overparameterized""]",,,,,
ByxhOyHYwH,2020,Reject,False,Fast Task Adaptation for Few-Shot Learning,"[""Yingying Zhang"", ""Qiaoyong Zhong"", ""Di Xie"", ""Shiliang Pu""]","[""Few-Shot Learning"", ""Metric-Softmax Loss"", ""Fast Task Adaptation""]",We propose a novel Metric-Softmax loss to learn task-agnostic feature and adapt the classifier to each few-shot task using a task-adaptive transformation.,,,,
ByxkCj09Fm,2019,Reject,False,DEEP HIERARCHICAL MODEL FOR HIERARCHICAL SELECTIVE CLASSIFICATION AND ZERO SHOT LEARNING,"[""Eliyahu Sason"", ""Koby Crammer""]","[""deep learning"", ""large-scale classificaion"", ""heirarchical classification"", ""zero-shot learning""]","We propose a new hierarchical probability based loss function which yields a significantly better semantic classifier for large scale classification scenario. Moreover, we show the importance of such a model in two applications.",,,,
ByxkijC5FQ,2019,Accept (Poster),False,Neural Persistence: A Complexity Measure for Deep Neural Networks Using Algebraic Topology,"[""Bastian Rieck"", ""Matteo Togninalli"", ""Christian Bock"", ""Michael Moor"", ""Max Horn"", ""Thomas Gumbsch"", ""Karsten Borgwardt""]","[""Algebraic topology"", ""persistent homology"", ""network complexity"", ""neural network""]",We develop a new topological complexity measure for deep neural networks and demonstrate that it captures their salient properties.,,,,
Byxl-04KvH,2020,Reject,False,NESTED LEARNING FOR MULTI-GRANULAR TASKS,"[""Rapha\u00ebl Achddou"", ""J. Matias Di Martino"", ""Guillermo Sapiro""]","[""Nested learning""]",DNNs can learn nested representations and output different quality of predictions with their respective confidence.,,,,
ByxloeHFPS,2020,Reject,False,PROVABLY BENEFITS OF DEEP HIERARCHICAL RL,"[""Zeyu Jia"", ""Simon S. Du"", ""Ruosong Wang"", ""Mengdi Wang"", ""Lin F. Yang""]","[""hierarchical model"", ""reinforcement learning"", ""low regret"", ""online learning"", ""tabular reinforcement learning""]",We theoretically show an exponential improvement using Deep HRL comparing to standard RL framework.,,,,
ByxmXnA9FQ,2019,Reject,False,A Variational Dirichlet Framework for Out-of-Distribution Detection,"[""Wenhu Chen"", ""Yilin Shen"", ""William Wang"", ""Hongxia Jin""]","[""out-of-distribution detection"", ""variational inference"", ""Dirichlet distribution"", ""deep learning"", ""uncertainty measure""]",A new framework based variational inference for out-of-distribution detection,,,,
ByxoqJrtvr,2020,Reject,False,Learning to Reach Goals Without Reinforcement Learning,"[""Dibya Ghosh"", ""Abhishek Gupta"", ""Justin Fu"", ""Ashwin Reddy"", ""Coline Devin"", ""Benjamin Eysenbach"", ""Sergey Levine""]","[""Reinforcement Learning"", ""Goal Reaching"", ""Imitation Learning""]",Learning how to reach goals from scratch by using imitation learning with data relabeling,,,,
ByxpMd9lx,2017,Accept (Poster),False,Transfer Learning for Sequence Tagging with Hierarchical Recurrent Networks,"[""Zhilin Yang"", ""Ruslan Salakhutdinov"", ""William W. Cohen""]","[""Natural language processing"", ""Deep learning"", ""Transfer Learning""]",,,,,
Byxpfh0cFm,2019,Accept (Poster),False,Efficient Augmentation via Data Subsampling,"[""Michael Kuchnik"", ""Virginia Smith""]","[""data augmentation"", ""invariance"", ""subsampling"", ""influence""]",Selectively augmenting difficult to classify points results in efficient training.,,,,
Byxr73R5FQ,2019,Reject,False,Successor Options : An Option Discovery Algorithm for Reinforcement Learning,"[""Manan Tomar*"", ""Rahul Ramesh*"", ""Balaraman Ravindran""]","[""Hierarchical Reinforcement Learning""]",An option discovery method for Reinforcement Learning using the Successor Representation,,,,
ByxtC2VtPB,2020,Accept (Poster),False,Mixup Inference: Better Exploiting Mixup to Defend Adversarial Attacks,"[""Tianyu Pang*"", ""Kun Xu*"", ""Jun Zhu""]","[""Trustworthy Machine Learning"", ""Adversarial Robustness"", ""Inference Principle"", ""Mixup""]",We exploit the global linearity of the mixup-trained models in inference to break the locality of the adversarial perturbations.,,,,
ByxtHCVKwB,2020,Reject,False,Targeted sampling of enlarged neighborhood via Monte Carlo tree search for TSP,"[""Zhang-Hua Fu"", ""Kai-Bin Qiu"", ""Meng Qiu"", ""Hongyuan Zha""]","[""Travelling salesman problem"", ""Monte Carlo tree search"", ""Reinforcement learning"", ""Variable neighborhood search""]",This paper combines Monte Carlo tree search with 2-opt local search in a variable neighborhood mode to solve the TSP effectively.,,,,
Byxv2pEKPH,2020,Reject,False,"Farkas layers: don't shift the data, fix the geometry","[""Aram-Alexandre Pooladian"", ""Chris Finlay"", ""Adam M Oberman""]","[""initialization"", ""deep networks"", ""residual networks"", ""batch normalization"", ""training"", ""optimization""]",Geometric approach to mimicking effect of batch norm; can still train DNNs at large learning rate in the absence of all normalization,,,,
ByxxgCEYDS,2020,Accept (Spotlight),True,Inductive Matrix Completion Based on Graph Neural Networks,"[""Muhan Zhang"", ""Yixin Chen""]","[""matrix completion"", ""graph neural network""]",,1904.12058,cs.IR,2019-04-26 21:58:46+00:00,2020-02-16 04:27:14+00:00
Byxz4n09tQ,2019,Reject,False,Model Compression with Generative Adversarial Networks,"[""Ruishan Liu"", ""Nicolo Fusi"", ""Lester Mackey""]","[""Model compression"", ""distillation"", ""generative adversarial network"", ""GAN"", ""deep neural network"", ""random forest"", ""ensemble"", ""decision tree"", ""convolutional neural network""]",,,,,
ByzcS3AcYX,2019,Accept (Poster),False,Neural TTS Stylization with Adversarial and Collaborative Games,"[""Shuang Ma"", ""Daniel Mcduff"", ""Yale Song""]","[""Text-To-Speech synthesis"", ""GANs""]",a generative adversarial network for style modeling in a text-to-speech system,,,,
ByzvHagA-,2018,Reject,False,Disentangled activations in deep networks,"[""Mikael K\u00e5geb\u00e4ck"", ""Olof Mogren""]","[""representation learning"", ""disentanglement"", ""regularization""]",We propose a novel regularization method that penalize covariance between dimensions of the hidden layers in a network.,,,,
C03Ajc-NS5W,2022,Accept (Poster),False,An Autoregressive Flow Model for 3D Molecular Geometry Generation from Scratch,"['Youzhi Luo', 'Shuiwang Ji']","[""3D molecular geometry generation"", ""flow models"", ""SphereNet""]",We present a novel method for 3D molecular geometry generation from scratch.,,,,
C0qJUx5dxFb,2021,Accept (Poster),False,Neural networks with late-phase weights,"[""Johannes Von Oswald"", ""Seijin Kobayashi"", ""Joao Sacramento"", ""Alexander Meulemans"", ""Christian Henning"", ""Benjamin F Grewe""]",[],,,,,
C1VUD8RZ5wq,2021,Reject,False,A Closer Look at Codistillation for Distributed Training,"[""Shagun Sodhani"", ""Olivier Delalleau"", ""Mido Assran"", ""Koustuv Sinha"", ""Nicolas Ballas"", ""Michael Rabbat""]","[""Distributed Training"", ""Distillation"", ""Neural Networks"", ""Deep Learning"", ""Large-scale Learning""]","We develop new insights about codistillation (a.k.a., ""online distillation"") and leverage them to show that codistillation can perform as well as models trained with synchronous data-parallel methods, even at moderate batch sizes.",,,,
C1_esHN6AVn,2022,Accept (Poster),False,Learning Synthetic Environments and Reward Networks for Reinforcement Learning,"['Fabio Ferreira', 'Thomas Nierhoff', 'Andreas SÃ¤linger', 'Frank Hutter']","[""Synthetic Environments"", ""Synthetic Data"", ""Meta-Learning"", ""Reinforcement Learning"", ""Evolution Strategies"", ""Reward Shaping""]",We propose an evolution-based approach to meta-learn synthetic neural environments and reward neural networks for reinforcement learning.,,,,
C3qvk5IQIJY,2021,Accept (Poster),False,Understanding Over-parameterization in Generative Adversarial Networks,"[""Yogesh Balaji"", ""Mohammadmahdi Sajedi"", ""Neha Mukund Kalibhat"", ""Mucong Ding"", ""Dominik St\u00f6ger"", ""Mahdi Soltanolkotabi"", ""Soheil Feizi""]","[""GAN"", ""Over-parameterization"", ""min-max optimization""]",We present an analysis of over-parameterization in GANs both theoretically and empirically.,,,,
C4-QQ1EHNcI,2021,Reject,False,Expressive yet Tractable Bayesian Deep Learning via Subnetwork Inference,"[""Erik Daxberger"", ""Eric Nalisnick"", ""James Allingham"", ""Javier Antoran"", ""Jos\u00e9 Miguel Hern\u00e1ndez-Lobato""]",[],"We propose a Bayesian deep learning method that does expressive inference over a carefully chosen _subnetwork_ within a neural network, and show that this works better than doing crude inference over the full network.",,,,
C4o-EEUx-6,2022,Reject,False,Flashlight: Enabling Innovation in Tools for Machine Learning,"['Jacob Kahn', 'Vineel Pratap', 'Tatiana Likhomanenko', 'Qiantong Xu', 'Awni Hannun', 'Jeff Cai', 'Paden Tomasello', 'Ann Lee', 'Edouard Grave', 'Gilad Avidov', 'Benoit Steiner', 'Vitaliy Liptchinsky', 'Gabriel Synnaeve', 'Ronan Collobert']","[""machine learning"", ""deep learning"", ""systems"", ""frameworks"", ""autograd library"", ""tensor library""]","We introduce Flashlight, a lightweight machine learning library built for internal customizability and framework research.",,,,
C54V-xTWfi,2022,Accept (Poster),False,MonoDistill: Learning Spatial Features for Monocular 3D Object Detection,"['Zhiyu Chong', 'Xinzhu Ma', 'Hong Zhang', 'Yuxin Yue', 'Haojie Li', 'Zhihui Wang', 'Wanli Ouyang']","[""3D object detection"", ""monocular images""]","We propose the MonoDistill, which introduces spatial cues to the monocular 3D detector based on the knowledge distillation mechanism.",2201.10830,cs.CV,2022-01-26 09:21:41+00:00,2022-01-26 09:21:41+00:00
C5Q04gnc4f,2022,Reject,False,An object-centric sensitivity analysis of deep learning based instance segmentation,"['Johannes Theodoridis', 'Jessica Hofmann', 'Johannes Maucher', 'Andreas Schilling']","[""robust vision"", ""instance segmentation"", ""deep learning"", ""object-centric"", ""robustness"", ""sensitivity analysis""]",A comprehensive sensitivity analysis regarding the object-centric robustness of deep learning based instance segmentation,,,,
C5kn825mU19,2021,Reject,False,A Coach-Player Framework for Dynamic Team Composition,"[""Bo Liu"", ""qiang liu"", ""Peter Stone"", ""Animesh Garg"", ""Yuke Zhu"", ""Anima Anandkumar""]","[""Multiagent reinforcement learning""]",We design a coach-player hierarchy with mixed observability to tackle the multi-agent coordination problem where both the number of team members as well as their capabilities are subject to change.,,,,
C5th0zC9NPQ,2021,Reject,False,Sensory Resilience based on Synesthesia,"[""Eric Platon"", ""Tom Sonoda""]","[""perception"", ""resilience"", ""robotics"", ""synesthesia""]",An artificial neural component inspired by synesthesia for agents to deal with sensory failures.,,,,
C5u6Z9voQ1,2022,Reject,False,Evaluating the Robustness of Time Series Anomaly and Intrusion Detection Methods against Adversarial Attacks,"['Shahroz Tariq', 'Simon S. Woo']","[""Time series"", ""Anomaly Detection"", ""Intrusion Detection"", ""Adversarial Attack""]"," We evaluate state-of-the-art deep neural networks (DNNs) and graph neural networks (GNNs) methods, which claim to be robust against anomalies and intrusions, and find their performance can drop to as low as 0% under adversarial attacks.",,,,
C70cp4Cn32,2021,Accept (Poster),True,Multi-Level Local SGD: Distributed SGD for Heterogeneous Hierarchical Networks,"[""Timothy Castiglia"", ""Anirban Das"", ""Stacy Patterson""]","[""Machine Learning"", ""Stochastic Gradient Descent"", ""Federated Learning"", ""Hierarchical Networks"", ""Distributed"", ""Heterogeneous"", ""Convergence Analysis""]","We propose Multi-Level Local SGD, a distributed stochastic gradient method for learning a smooth, non-convex objective in a multi-level communication network with heterogeneous workers.",2007.13819,cs.LG,2020-07-27 19:14:23+00:00,2021-03-16 21:17:04+00:00
C81udlH5yMv,2022,Reject,False,Invariant Causal Mechanisms through Distribution Matching,"['Mathieu Chevalley', 'Charlotte Bunne', 'Andreas Krause', 'Stefan Bauer']","[""representation learning"", ""causality"", ""invariance"", ""distribution matching""]",This work provides a causal perspective on new algorithm for invariant representation learning. ,,,,
C8Ltz08PtBp,2022,Accept (Poster),False,Distributional Reinforcement Learning with Monotonic Splines,"['Yudong Luo', 'Guiliang Liu', 'Haonan Duan', 'Oliver Schulte', 'Pascal Poupart']","[""Distributional RL""]",,,,,
CALFyKVs87,2022,Accept (Spotlight),False,Dynamics-Aware Comparison of Learned Reward Functions,"['Blake Wulfe', 'Logan Michael Ellis', 'Jean Mercat', 'Rowan Thomas McAllister', 'Adrien Gaidon']","[""Reward Learning"", ""Inverse Reinforcement Learning"", ""Reinforcement Learning"", ""Comparing Reward Functions""]",We propose a method for quantifying the similarity of learned reward functions without performing policy learning and evaluation.,,,,
CAjxVodl_v,2022,Accept (Spotlight),False,Distributional Decision Transformer for Hindsight Information Matching,"['Hiroki Furuta', 'Yutaka Matsuo', 'Shixiang Shane Gu']","[""Hindsight Information Matching"", ""Decision Transformer"", ""State-Marginal Matching"", ""Hindsight Experience Replay"", ""Reinforcement Learning""]","We generalize hindsight algorithms in RL, and propose Distributional Decision Transformer for information matching.",2111.10364,cs.LG,2021-11-19 18:56:13+00:00,2022-02-04 14:03:07+00:00
CBchIgBBrwj,2022,Reject,False,Objective Evaluation of Deep Visual Interpretations on Time Series Data,"['Christoffer LÃ¶ffler', 'Wei-Cheng Lai', 'Lukas M Schmidt', 'Dario Zanca', 'Bjoern Eskofier', 'Christopher Mutschler']","[""explainable ai"", ""deep learning"", ""time series"", ""visual interpretation"", ""evaluation metrics"", ""classification"", ""segmentation""]",We propose orthogonal evaluation metrics for deep visual interpretations on time series.,,,,
CBmJwzneppz,2021,Accept (Poster),False,Optimism in Reinforcement Learning with Generalized Linear Function Approximation,"[""Yining Wang"", ""Ruosong Wang"", ""Simon Shaolei Du"", ""Akshay Krishnamurthy""]","[""reinforcement learning"", ""optimism"", ""exploration"", ""function approximation"", ""theory"", ""regret analysis"", ""provable sample efficiency""]",A provably efficient (statistically and computationally) algorithm for reinforcement learning with generalized linear function approximation and no explicit dynamics assumptions.,,,,
CC-BbehJKTe,2022,Reject,False,Building the Building Blocks: From Simplification to Winning Trees in Genetic Programming,"['Lucija PlaniniÄ', 'Marko ÄuraseviÄ', 'Stjepan Picek', 'Domagoj Jakobovic']","[""Genetic Programming"", ""Building Blocks"", ""Regression"", ""Bloat"", ""Experimental evaluation""]",Is there a winning ticket in GP?,,,,
CCu6RcUMwK0,2022,Accept (Poster),True,Neural Link Prediction with Walk Pooling,"['Liming Pan', 'Cheng Shi', 'Ivan DokmaniÄ']","[""Graph neural network"", ""Link prediction"", ""Random walk"", ""Graph topology.""]",,2110.04375,cs.LG,2021-10-08 20:52:12+00:00,2021-10-08 20:52:12+00:00
CES-KyrKcTM,2022,Reject,False,The weighted mean trick â optimization strategies for robustness,"['Valeriu Balaban', 'Paul Bogdan']",[],New method to penalize central moments of the loss while preserving convexity.,,,,
CF-ZIuSMXRz,2021,Accept (Poster),False,Spatio-Temporal Graph Scattering Transform,"[""Chao Pan"", ""Siheng Chen"", ""Antonio Ortega""]","[""scattering transform"", ""spatio-temporal graph"", ""graph neural networks"", ""skeleton-based action recognition""]","We put forth a novel mathematically designed framework ""ST-GST"" to analyze spatio-temporal data.",,,,
CGFN_nV1ql,2021,Reject,True,Non-Attentive Tacotron: Robust and controllable neural TTS synthesis including unsupervised duration modeling,"[""Jonathan Shen"", ""Ye Jia"", ""Mike Chrzanowski"", ""Yu Zhang"", ""Isaac Elias"", ""Heiga Zen"", ""Yonghui Wu""]","[""tts"", ""text-to-speech""]","Non-Attentive Tacotron replaces the attention mechanism in Tacotron 2 with a duration predictor leading to improved robustness, and can be trained with reasonable performance even without duration labels.",2010.04301,cs.SD,2020-10-08 23:41:39+00:00,2021-05-11 04:12:14+00:00
CGQ6ENUMX6,2021,Accept (Poster),False,Task-Agnostic Morphology Evolution,"[""Donald Joseph Hejna III"", ""Pieter Abbeel"", ""Lerrel Pinto""]","[""morphology"", ""unsupervised"", ""evolution"", ""information theory"", ""empowerment""]","We introduce TAME, a novel method for optimizing agent morphology using only  randomly sampled action primitives and no task driven reward signals.",,,,
CHLhSw9pSw8,2021,Accept (Poster),False,Single-Photon Image Classification,"[""Thomas Fischbacher"", ""Luciano Sbaiz""]","[""quantum mechanics"", ""image classification"", ""quantum machine learning"", ""theoretical limits""]",Mathematical proof that the classical accuracy limit for single-photon image classification can be exceeded very substantially by employing a problem-tailored quantum transformation on the photon state.,,,,
CHTHamtufWN,2021,Reject,False,Continual Invariant Risk Minimization,"[""Francesco Alesiani"", ""Shujian Yu"", ""Mathias Niepert""]","[""Supervised Learning"", ""Causal Learning"", ""Invariant Risk Minimization"", ""Continual Learning""]",We study the extension of Invariant Risk Minimization in sequential environments,,,,
CI-xXX9dg9l,2022,Accept (Poster),False,On Distributed Adaptive Optimization with Gradient Compression,"['Xiaoyun Li', 'Belhal Karimi', 'Ping Li']",[],,,,,
CIaQKbTBwtU,2022,Accept (Poster),False,Learning to Generalize across Domains on Single Test Samples,"['Zehao Xiao', 'Xiantong Zhen', 'Ling Shao', 'Cees G. M. Snoek']","[""domain generalization"", ""single test sample generalization"", ""meta learning"", ""variational inference""]",We leverage a meta-learning paradigm to learn our model to acquire the ability of adaptation with single samples at training time so as to further adapt itself to each single test sample at test time.,,,,
CJmMqnXthgX,2021,Reject,False,An Empirical Study of the Expressiveness of Graph Kernels and Graph Neural Networks,"[""Giannis Nikolentzos"", ""George Panagopoulos"", ""Michalis Vazirgiannis""]",[],,,,,
CJzi3dRlJE-,2022,Accept (Poster),False,Connectome-constrained Latent Variable Model of Whole-Brain Neural Activity,"['Lu Mi', 'Richard Xu', 'Sridhama Prakhya', 'Albert Lin', 'Nir Shavit', 'Aravinthan Samuel', 'Srinivas C Turaga']","[""connectome"", ""latent-variable model"", ""variational autoencoder"", ""biophysics"", ""whole-brain"", ""neural activity"", ""calcium imaging"", ""caenorhabditis elegans"", ""voltage"", ""generative model"", ""inference network""]",Connectome-constrained Latent Variable Model of Whole-Brain Neural Activity.,,,,
CLYe1Yke1r,2021,Reject,False,Box-To-Box Transformation for Modeling Joint Hierarchies,"[""Shib Sankar Dasgupta"", ""Xiang Li"", ""Michael Boratko"", ""Dongxu Zhang"", ""Andrew McCallum""]","[""Box embeddings"", ""Representation Learning"", ""Joint Hierarchy"", ""transitive relations"", ""knowledge graph embedding"", ""relational learning.""]",Learning transformation on box embedding space to generalize over multiple hierarchies ,,,,
CLnj31GZ4cI,2021,Reject,True,K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters,"[""Ruize Wang"", ""Duyu Tang"", ""Nan Duan"", ""zhongyu wei"", ""Xuanjing Huang"", ""Jianshu Ji"", ""Guihong Cao"", ""Daxin Jiang"", ""Ming Zhou""]",[],,2002.01808,cs.CL,2020-02-05 14:30:49+00:00,2020-12-28 06:07:06+00:00
CLpxpXqqBV,2022,Accept (Poster),False,Learning State Representations via Retracing in Reinforcement Learning,"['Changmin Yu', 'Dong Li', 'Jianye HAO', 'Jun Wang', 'Neil Burgess']","[""Representation learning"", ""model-based reinforcement learning""]","We introduce Learning via Retracing, a novel self-supervised framework based on temporal cycle-consistency assumption of the transition dynamics, for improved learning of the representation (and the dynamics model) in RL tasks.",2111.12600,cs.LG,2021-11-24 16:19:59+00:00,2021-11-24 16:19:59+00:00
CMsvjAnW1zE,2021,Reject,True,"Spherical Motion Dynamics: Learning Dynamics of Neural Network with Normalization, Weight Decay, and SGD","[""Ruosi Wan"", ""Zhanxing Zhu"", ""Xiangyu Zhang"", ""Jian Sun""]","[""Normalization"", ""Weight decay"", ""SGD"", ""Momentum""]",Theoretical analysis on joint effect of normalization and weight decay.,2006.08419,stat.ML,2020-06-15 14:16:33+00:00,2020-11-27 06:10:50+00:00
CNA6ZrpNDar,2021,Reject,False,On the Decision Boundaries of Neural Networks. A Tropical Geometry Perspective,"[""Motasem Alfarra"", ""Adel Bibi"", ""Hasan Abed Al Kader Hammoud"", ""Mohamed Gaafar"", ""Bernard Ghanem""]","[""Tropical Geometry"", ""Decision Boundaries"", ""Neural Networks""]","This paper characterizes the decision boundaries of neural networks using tropical geometry, and leverages this characterization into several applications.",,,,
CNY9h3uyfiO,2022,Reject,False,Reward Shifting for Optimistic Exploration and Conservative Exploitation,"['Hao Sun', 'Lei Han', 'Jian Guo', 'Bolei Zhou']","[""Reward Shift"", ""Reinforcement Learning"", ""Batch RL"", ""Offline RL"", ""Online RL"", ""Curiosity-Driven Method""]",Linear reward transformations are equivalent to different initializations the $Q$-function for value-based RL and can be used for conservative exploitation as well as curiosity-driven exploration.,,,,
CO0ZuH5vaMu,2022,Reject,False,Using Document Similarity Methods to create Parallel Datasets for Code Translation,"['Mayank Agarwal', 'Kartik Talamadupula', 'Fernando Martinez', 'Stephanie Houde', 'Michael Muller', 'John Richards', 'Steven I Ross', 'Justin D. Weisz']","[""code translation"", ""machine translation"", ""document similarity""]",We show that document similarity methods can be used to parallel datasets for code translation thus alleviating the paucity of such data in this domain,,,,
CPfjKI8Yzx,2021,Reject,False,Robust Imitation via Decision-Time Planning,"[""Carl Qi"", ""Pieter Abbeel"", ""Aditya Grover""]","[""imitation learning"", ""reinforcement learning"", ""inverse reinforcement learning""]",,,,,
CQzlxFVcmw1,2022,Reject,False,Message Function Search for Hyper-relational Knowledge Graph,"['Shimin Di', 'Lei Chen']","[""Graph Neural Network"", ""Hyper-relational Knowledge Graph"", ""Knowledge Base Embedding""]",This paper proposes to search the message function in Graph Neural Networks to embed Hyper-relational Knowledge Graph.,,,,
CR1XOQ0UTh-,2021,Accept (Poster),False,Contrastive Learning with Hard Negative Samples,"[""Joshua David Robinson"", ""Ching-Yao Chuang"", ""Suvrit Sra"", ""Stefanie Jegelka""]","[""contrastive learning"", ""unsupervised representation learning"", ""hard negative sampling""]","We introduce an unsupervised method for sampling hard negatives for contrastive learning: the resulting embeddings have desirable theoretical properties, and have improved downstream performance on multiple different data modalities. ",,,,
CS4463zx6Hi,2022,Accept (Poster),True,Geometric Transformers for Protein Interface Contact Prediction,"['Alex Morehead', 'Chen Chen', 'Jianlin Cheng']","[""Geometric Deep Learning"", ""Graph Transformers"", ""Protein Bioinformatics"", ""Invariance""]",We introduce a geometry-evolving graph transformer for 3D protein structures and employ it to achieve state-of-the-art precision for predicting inter-protein residue-residue contacts in challenging protein complex targets.,2110.02423,cs.LG,2021-10-06 00:12:15+00:00,2022-02-05 16:33:26+00:00
CSfcOznpDY,2022,Accept (Poster),False,Recursive Disentanglement Network,"['Yixuan Chen', 'Yubin Shi', 'Dongsheng Li', 'Yujiang Wang', 'Mingzhi Dong', 'Yingying Zhao', 'Robert Dick', 'Qin Lv', 'Fan Yang', 'Li Shang']","[""disentanglement"", ""representation learning"", ""compositional""]",This paper has described a solution to the compositional disentangled representation learning problem. ,,,,
CSw5zgTjXyb,2022,Reject,False,Learning to Collaborate,"['Sen Cui', 'Jian Liang', 'Weishen Pan', 'Kun Chen', 'Changshui Zhang', 'Fei Wang']","[""collaboration equilibrium""]",We propose a learning to collaborate framework to realize a collaboration equilibrium.,,,,
CTOJRqLMsl,2022,Reject,False,On the Convergence of Nonconvex Continual Learning with Adaptive Learning Rate,"['Sungyeob Han', 'Yeongmo Kim', 'Jungwoo Lee']",[],,,,,
CU0APx9LMaL,2021,Accept (Poster),False,NAS-Bench-ASR: Reproducible Neural Architecture Search for Speech Recognition,"[""Abhinav Mehrotra"", ""Alberto Gil C. P. Ramos"", ""Sourav Bhattacharya"", ""\u0141ukasz Dudziak"", ""Ravichander Vipperla"", ""Thomas Chau"", ""Mohamed S Abdelfattah"", ""Samin Ishtiaq"", ""Nicholas Donald Lane""]","[""NAS"", ""ASR"", ""Benchmark""]","The first NAS benchmark for ASR comprising of 8,242 unique models trained on the TIMIT audio dataset.",,,,
CVfLvQq9gLo,2022,Accept (Poster),False,ARTEMIS: Attention-based Retrieval with Text-Explicit Matching and Implicit Similarity,"['Ginger Delmas', 'Rafael S. Rezende', 'Gabriela Csurka', 'Diane Larlus']",[],,,,,
CYHMIhbuLFl,2021,Reject,False,Contextual HyperNetworks  for Novel Feature Adaptation,"[""Angus Lamb"", ""Evgeny Saveliev"", ""Yingzhen Li"", ""Sebastian Tschiatschek"", ""Camilla Longden"", ""Simon Woodhead"", ""Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"", ""Richard E Turner"", ""Pashmina Cameron"", ""Cheng Zhang""]","[""Meta learning"", ""few-shot learning"", ""continual learning"", ""recommender systems"", ""deep learning""]","We introduce an auxiliary neural network to extend existing neural networks to make accurate predictions for new features in the few-shot learning regime, given a small number of observations and/or metadata for the new feature.",,,,
CYO5T-YjWZV,2021,Accept (Poster),False,Simple Spectral Graph Convolution,"[""Hao Zhu"", ""Piotr Koniusz""]","[""Graph Convolutional Network"", ""Oversmoothing""]","A simple and efficient method for graph convolution based on the Markov Diffusion Kernel, which works well on different tasks under unsupervised, semi-supervised and supervised settings.",,,,
CZ8Y3NzuVzO,2021,Accept (Poster),False,What Should Not Be Contrastive in Contrastive Learning,"[""Tete Xiao"", ""Xiaolong Wang"", ""Alexei A Efros"", ""Trevor Darrell""]","[""Self-supervised learning"", ""Contrastive learning"", ""Representation learning""]",,,,,
CZZ7KWOP0-M,2022,Reject,False,ShiftAddNAS: Hardware-Inspired Search for More Accurate and Efficient Neural Networks,"['Haoran You', 'Baopu Li', 'Huihong Shi', 'Yingyan Lin']","[""Neural Architecture Search"", ""Bit-wise Shift and Add"", ""Hardware Acceleration"", ""Multiplication-Reduced Networks""]",We propose a hardware-inspired NAS for searching multiplication-reduced networks to boost the performance-efficiency trade-offs.,,,,
C_p3TDhOXW_,2021,Reject,False,Prior Preference Learning From Experts: Designing A Reward with Active Inference,"[""Jin Young Shin"", ""Cheolhyeong Kim"", ""Hyung Ju Hwang""]","[""Active Inference"", ""Free Energy Principle"", ""Reinforcement Learning"", ""Reward Design""]",We propose a new method to design a reward from experts' simulations based on a concept of active inference.,,,,
C_vsGwEIjAr,2022,Accept (Poster),True,Trivial or Impossible --- dichotomous data difficulty masks model differences (on ImageNet and beyond),"['Kristof Meding', 'Luca M. Schulze Buschoff', 'Robert Geirhos', 'Felix A. Wichmann']","[""CNNs"", ""Cognitive Science"", ""Vision Science"", ""Psychophysics"", ""Neuroscience"", ""Visual perception"", ""Inductive bias"", ""ImageNet"", ""CIFAR"", ""RSA"", ""Representation similarity analysis"", ""Error consistency"", ""Datasets""]",All CNNs make similar decisions since data difficulty is dichotomous. ,2110.05922,cs.CV,2021-10-12 12:09:59+00:00,2021-10-12 12:09:59+00:00
CaCHjsqCBJV,2021,Reject,False,Differentiable Optimization of Generalized Nondecomposable Functions using Linear Programs,"[""Zihang Meng"", ""Lopamudra Mukherjee"", ""Vikas Singh"", ""Sathya N. Ravi""]","[""linear programming"", ""nondecomposable functions"", ""differentiable"", ""AUC"", ""Fscore""]",We propose a framework which makes it feasible to directly train deep neural networks with respect to popular families of task-specific non-decomposable performance measures.,,,,
Cb54AMqHQFP,2021,Accept (Poster),False,Network Pruning That Matters:  A Case Study on Retraining Variants,"[""Duong Hoang Le"", ""Binh-Son Hua""]","[""Network Pruning""]",We study the effective of different retraining mechanisms while doing pruning,,,,
CgIEctmcXx1,2022,Accept (Poster),True,ADAVI: Automatic Dual Amortized Variational Inference Applied To Pyramidal Bayesian Models,"['Louis Rouillard', 'Demian Wassermann']","[""Bayesian inference"", ""Hierarchical Bayesian Models"", ""structured Variational Inference"", ""Simulation Based Inference"", ""Inference amortization"", ""Neuroimaging""]",We automatically derive a variational family dual to a plate-enriched Hierarchical Bayesian Network and perform amortized inference.,2106.12248,cs.LG,2021-06-23 09:09:01+00:00,2021-10-15 07:50:42+00:00
CgV7NVOgDJZ,2022,Reject,False,Guided-TTS:Text-to-Speech with Untranscribed Speech,"['Heeseung Kim', 'Sungwon Kim', 'Sungroh Yoon']","[""Text-to-Speech"", ""Speech Synthesis"", ""DDPM"", ""TTS"", ""Untranscribed speech""]",Text-to-Speech with untranscribed speech data via phoneme classification,2111.11755,cs.SD,2021-11-23 10:05:05+00:00,2022-01-29 01:34:24+00:00
ChKNCDB0oYj,2022,Reject,False,Mistake-driven Image Classification with FastGAN and SpinalNet,"['Mohit Kumar Ahuja', 'Sahil Sahil', 'Helge Spieker']","[""Deep Learning"", ""Data Augmentation"", ""Image Classification"", ""Supervised Learning"", ""Generative models""]",A data-efficient training method with GAN-based augmentation that focuses on the weakest classes after the initial training and boosts final model accuracy.,,,,
ChMLTGRjFcU,2022,Accept (Poster),False,How many degrees of freedom do we need to train deep networks: a loss landscape perspective,"['Brett W Larsen', 'Stanislav Fort', 'Nic Becker', 'Surya Ganguli']","[""loss landscape"", ""high-dimensional geometry"", ""random hyperplanes"", ""optimization""]",,,,,
Ck_iw4jMC4l,2022,Reject,False,Logical Activation Functions: Logit-space equivalents of Boolean Operators,"['Scott C Lowe', 'Robert Earle', ""Jason d'Eon"", 'Thomas Trappenberg', 'Sageev Oore']","[""activation functions"", ""logits""]","We motivate novel activation functions which are logit-space equivalents to boolean operations, and find they work well on a wide variety of tasks.",,,,
ClZ4IcqnFXB,2021,Reject,False,Active Feature Acquisition with Generative Surrogate Models,"[""Yang Li"", ""Junier Oliva""]","[""Reinforcement Learning"", ""Active Feature Acquisition"", ""Feature Selection""]",We propose models that actively acquire features at evaluation time to maximize the prediction performance as well as minimize the acquisition cost.,,,,
Clre-Prt128,2022,Reject,True,Complex-valued deep learning with differential privacy,"['Alexander Ziller', 'Dmitrii Usynin', 'Moritz Knolle', 'Kerstin Hammernik', 'Daniel Rueckert', 'Georgios Kaissis']","[""Differential privacy"", ""complex-valued deep learning""]",,2110.03478,cs.CR,2021-10-07 14:03:00+00:00,2021-10-07 14:03:00+00:00
Cm08egNmrl3,2022,Reject,False,BLOOD: Bi-level Learning Framework for Out-of-distribution Generalization,"['Jun-Hyun Bae', 'Inchul Choi', 'Minho Lee']","[""Out-of-Distribution Generalization"", ""Generalization"", ""Spurious Correlations"", ""Bi-level Optimization""]","In this paper, we propose a novel bi-level learning framework for out-of-distribution generalization, which aims to eliminate multiple types of unknown biases.",,,,
CmsfC7u054S,2022,Accept (Poster),False,Reinforcement Learning in Presence of Discrete Markovian Context Evolution ,"['Hang Ren', 'Aivar Sootla', 'Taher Jafferjee', 'Junxiao Shen', 'Jun Wang', 'Haitham Bou Ammar']","[""context-dependent Reinforcement Learning"", ""model-based reinforcement learning"", ""hierarchical Dirichlet process""]",,,,,
Cn706AbJaKW,2021,Reject,False,An Open Review of OpenReview: A Critical Analysis of the Machine Learning Conference Review Process,"[""David Tran"", ""Alexander V Valtchanov"", ""Keshav R Ganapathy"", ""Raymond Feng"", ""Eric Victor Slud"", ""Micah Goldblum"", ""Tom Goldstein""]","[""Conference Review"", ""OpenReview"", ""Gender"", ""Bias"", ""Reproducibility"", ""Fairness""]",We study the conference review process to quantify reproducibility and bias.,,,,
Cnon5ezMHtu,2021,Accept (Poster),False,Neural Architecture Search on ImageNet in Four GPU Hours: A Theoretically Inspired Perspective,"[""Wuyang Chen"", ""Xinyu Gong"", ""Zhangyang Wang""]","[""Neural Architecture Search"", ""neural tangent kernel"", ""number of linear regions""]","Our TE-NAS framework analyzes the spectrum of the neural tangent kernel (NTK) and the number of linear regions in the input space, achieving high-quality architecture search while dramatically reducing the search cost to four hours on ImageNet.",2102.11535,cs.CV,2021-02-23 07:50:44+00:00,2021-03-16 00:59:19+00:00
CoMOKHYWf2,2022,Reject,False,AdaFocal: Calibration-aware Adaptive Focal Loss,"['Arindam Ghosh', 'Thomas Schaaf', 'Matthew R. Gormley']","[""neural networks"", ""uncertainity calibration"", ""out of distribution detection""]",Our paper proposes a modification to focal loss which results in improved calibration of neural networks without any loss of accuracy.,,,,
CpTuR2ECuW,2022,Accept (Poster),False,LIGS: Learnable Intrinsic-Reward Generation Selection for Multi-Agent Learning ,"['David Henry Mguni', 'Taher Jafferjee', 'Jianhong Wang', 'Nicolas Perez-Nieves', 'Oliver Slumbers', 'Feifei Tong', 'Yang Li', 'Jiangcheng Zhu', 'Yaodong Yang', 'Jun Wang']","[""multi-agent"", ""reinforcement learning"", ""intrinsic rewards"", ""exploration""]",,2112.02618,cs.MA,2021-12-05 16:50:23+00:00,2021-12-05 16:50:23+00:00
CpgtwW8GBxe,2022,Reject,False,Label Refining: a semi-supervised method to extract voice characteristics without ground truth,"['Mathias Quillot', 'Richard Dufour', 'Jean-franÃ§ais Bonastre']","[""characteristics"", ""characteristics extraction"", ""characteristics evaluation"", ""voice characteristics"", ""label refining"", ""refined labels"", ""semi-supervision""]",We propose in this work a new semi-supervised method entitled Label Refining that consists in extracting characteristics without a priori knowledge.,,,,
CrCvGNHAIrz,2022,Accept (Poster),False,Explainable GNN-Based Models over Knowledge Graphs,"['David Jaime Tena Cucala', 'Bernardo Cuenca Grau', 'Egor V. Kostylev', 'Boris Motik']",[],We propose a new family of graph neural network-based transformations of graph data that can be trained effectively and where all predictions can be explained symbolically as logical inferences in Datalog.,,,,
Cri3xz59ga,2021,Accept (Spotlight),False,Deciphering and Optimizing Multi-Task Learning: a Random Matrix Approach,"[""Malik Tiomoko"", ""Hafiz Tiomoko Ali"", ""Romain Couillet""]","[""Transfer Learning"", ""Multi Task Learning"", ""Random Matrix Theory""]",This paper provides a theoretical analysis of Multi Task Learning schemes for large dimensional data,,,,
Ctjb37IOldV,2022,Reject,False,A Variance Principle Explains why Dropout Finds Flatter Minima,"['Zhongwang Zhang', 'Hanxu Zhou', 'Zhiqin Xu']","[""dropout"", ""stochastic gradient descent"", ""loss landscape"", ""flatness"", ""neural network""]","The noise induced by the dropout satisfies the variance principle, which explains why dropout finds flatter minima.",,,,
CuV_qYkmKb3,2022,Accept (Spotlight),True,Scarf: Self-Supervised Contrastive Learning using Random Feature Corruption,"['Dara Bahri', 'Heinrich Jiang', 'Yi Tay', 'Donald Metzler']","[""self-supervised learning"", ""tabular data"", ""pre-training"", ""contrastive learning"", ""openML""]","Scarf is a self-supervised, contrastive pre-training method for neural networks applied to tabular classification tasks that boosts performance, even when labeled data is limited or noisy.",2106.15147,cs.LG,2021-06-29 08:08:33+00:00,2021-06-29 08:08:33+00:00
Cue2ZEBf12,2021,Reject,False,Towards Adversarial Robustness of Bayesian Neural Network through Hierarchical Variational Inference,"[""Byung-Kwan Lee"", ""Youngjoon Yu"", ""Yong Man Ro""]",[],,,,,
CxGPf2BPVA,2021,Reject,False,Regularization Shortcomings for Continual Learning,"[""Timothee LESORT"", ""Andrei Stoian""]","[""Continual Learning"", ""Regularization""]",This paper present how regularization approaches fail in simple continual learning settings.,,,,
CxebB5Psl1,2022,Reject,False,Graph Similarities and Dual Approach for Sequential Text-to-Image Retrieval,"['Keonwoo Kim', 'Sihyeon Jo', 'Seong-Woo Kim']","[""sequential text-to-image retrieval"", ""story-to-image retrieval"", ""scene graph embedding"", ""dual learning""]",Using scene graph embedding and a dual learning to improve story-to-image retrieval.,,,,
CyKHoKyvgnp,2022,Accept (Spotlight),False,Transition to Linearity of Wide Neural Networks is an Emerging Property of Assembling Weak Models,"['Chaoyue Liu', 'Libin Zhu', 'Misha Belkin']","[""Assembling"", ""linearity"", ""Transition to linearity"", ""wide neural networks""]",Transition to linearity of wide neural networks is an emerging property of assembling weak models corresponding to individual neurons,,,,
CyKQiiCPBEv,2022,Reject,False,Stepping Back to SMILES Transformers for Fast Molecular Representation Inference,"['Wenhao Zhu', 'Ziyao Li', 'Lingsheng Cai', 'Guojie Song']","[""molecular representation learning"", ""knowledge distillation""]",SMILES Transformer for fast molecular representation inference with knowledge distillation.,2112.13305,cs.CE,2021-12-26 01:35:54+00:00,2021-12-26 01:35:54+00:00
Cz3dbFm5u-,2021,Accept (Poster),False,"SAFENet: A Secure, Accurate and Fast Neural Network Inference","[""Qian Lou"", ""Yilin Shen"", ""Hongxia Jin"", ""Lei Jiang""]","[""Cryptographic inference"", ""Channel-Wise Approximated Activation"", ""Hyper-Parameter Optimization"", ""Garbled Circuits""]","We propose SAFENet that supports automatic channel-wise activation approximation to enable a Secure, Accurate and Fast nEural Network inference service.",,,,
CzRSsOG6JDw,2021,Reject,False,The impacts of known and unknown demonstrator irrationality on reward inference,"[""Lawrence Chan"", ""Andrew Critch"", ""Anca Dragan""]","[""irrationality"", ""reward learning"", ""irl""]",,,,,
CzceR82CYc,2022,Accept (Spotlight),False,Score-Based Generative Modeling with Critically-Damped Langevin Diffusion,"['Tim Dockhorn', 'Arash Vahdat', 'Karsten Kreis']","[""Score-based generative modeling"", ""denoising diffusion models"", ""image synthesis""]","In this work, we propose a novel diffusion process ideally suited for score-based generative models and provide new insights into score-based denoising diffusion models.",2112.07068,stat.ML,2021-12-14 00:01:34+00:00,2021-12-30 14:17:44+00:00
Czsdv-S4-w9,2022,Accept (Poster),False,Generating Videos with Dynamics-aware Implicit Generative Adversarial Networks,"['Sihyun Yu', 'Jihoon Tack', 'Sangwoo Mo', 'Hyunsu Kim', 'Junho Kim', 'Jung-Woo Ha', 'Jinwoo Shin']","[""video generation"", ""implicit neural representations"", ""generative adversarial networks""]",We make video generation scalable leveraging implicit neural representations.,,,,
D04TGKz5rfF,2021,Reject,False,A frequency domain analysis of gradient-based adversarial examples,"[""Bochen Lv"", ""Pu Yang"", ""Zehao Wang"", ""Zhanxing Zhu""]",[],,,,,
D1E1h-K3jso,2021,Reject,False,Learning from Noisy Data with Robust Representation Learning,"[""Junnan Li"", ""Caiming Xiong"", ""Steven Hoi""]","[""label noise"", ""out-of-distribution noise"", ""contrastive learning""]",We propose a new contrastive learning framework for robust learning from noisy data.,,,,
D1TYemnoRN,2022,Reject,False,Short optimization paths lead to good generalization,"['Fusheng Liu', 'Haizhao Yang', 'Qianxiao Li']","[""optimization"", ""generalization"", ""machine learning theory""]",We propose a framework to connect optimization and generalization and use it to obtain generalization estimates on three machine learning models.,,,,
D2Fp_qheYu,2021,Reject,False,Max-sliced Bures Distance for Interpreting Discrepancies,"[""Austin J. Brockmeier"", ""Claudio Cesar Claros"", ""Carlos H. Mendoza-Cardenas"", ""Y\u00fcksel Karahan"", ""Matthew S. Emigh"", ""Luis Gonzalo Sanchez Giraldo""]","[""covariance"", ""covariate shift"", ""distance metrics"", ""divergence"", ""generative adversarial networks"", ""interpretable approaches"", ""kernel methods"", ""probability metric"", ""RKHS""]","The paper describes a novel divergence between two distributions based on optimizing an interpretable witness function, which enables both localizing and correcting the discrepancies between two samples.",,,,
D2TE6VTJG9,2021,Reject,True,Predicting What You Already Know Helps: Provable Self-Supervised Learning,"[""Jason D. Lee"", ""Qi Lei"", ""Nikunj Saunshi"", ""Jiacheng Zhuo""]","[""theory"", ""self-supervised learning"", ""representation learning"", ""unsupervised learning"", ""conditional independence""]",We prove the sample efficiency of representations learned using reconstruction-based self-supervised learning on downstream tasks under an approximate conditional independence assumption.,2008.01064,cs.LG,2020-08-03 17:56:13+00:00,2021-11-14 04:26:31+00:00
D3PcGLdMx0,2021,Accept (Poster),False,MELR: Meta-Learning via Modeling Episode-Level Relationships for Few-Shot Learning,"[""Nanyi Fei"", ""Zhiwu Lu"", ""Tao Xiang"", ""Songfang Huang""]","[""few-shot learning"", ""episodic training"", ""cross-episode attention""]",This is the first work on explicitly modeling episode-level relationships for few-shot learning.,,,,
D3TNqCspFpM,2021,Reject,False,Identifying Treatment Effects under Unobserved Confounding by Causal Representation Learning,"[""Pengzhou Abel Wu"", ""Kenji Fukumizu""]","[""VAE"", ""variational autoencoder"", ""Representation Learning"", ""treatment effects"", ""causal inference"", ""Unobserved Confounding"", ""identifiability"", ""CATE"", ""ATE""]","A new VAE architecture is proposed for estimating causal effects under unobserved confounding, with theoretical analysis and state-of-the-art performance.",,,,
D4A-v0kltaX,2021,Reject,False,Neural Partial Differential Equations with Functional Convolution,"[""Ziqian Wu"", ""Xingzhe He"", ""Michael Zhang"", ""Yijun Li"", ""Cheng Yang"", ""Rui Liu"", ""Shiying Xiong"", ""Bo Zhu""]","[""neural PDE"", ""functional convolution"", ""adjoint method""]",We developed a new family of neural networks to efficiently extract hidden structures of a nonlinear PDE based on sparse observation. ,,,,
D4QFCXGe_z2,2021,Reject,False,R-LAtte: Attention Module for Visual Control via Reinforcement Learning,"[""Mandi Zhao"", ""Qiyang Li"", ""Aravind Srinivas"", ""Ignasi Clavera"", ""Kimin Lee"", ""Pieter Abbeel""]",[],We propose and study the effectiveness of augmenting a simple attention module in the convolutional encoder of an RL agent,,,,
D51irFX8UOG,2021,Reject,False,HALMA: Humanlike Abstraction Learning Meets Affordance in Rapid Problem Solving,"[""Sirui Xie"", ""Xiaojian Ma"", ""Peiyu Yu"", ""Yixin Zhu"", ""Ying Nian Wu"", ""Song-Chun Zhu""]","[""Visual Concept Development"", ""Rapid Problem Solving"", ""Abstract Reasoning""]","We present a new testbed and benchmark, HALMA, with three levels of generalization in visual concept development and rapid problem solving.",2102.11344,cs.LG,2021-02-22 20:37:01+00:00,2021-02-22 20:37:01+00:00
D5Wt3FtvCF,2021,Reject,False,PURE: An Uncertainty-aware Recommendation Framework for Maximizing Expected Posterior Utility of Platform,"[""Haokun Chen"", ""Zhaoyang Liu"", ""Chen Xu"", ""Ziqian Chen"", ""Jinyang Gao"", ""Bolin Ding""]","[""commercial recommendation"", ""maximizing platform benefits"", ""uncertainty-aware"", ""influence of display policy"", ""non-convex optimization""]","In the paper, we propose a novel recommendation framework to maximize the platform's expected posterior utility, taking into consideration the user uncertainty over different item dimensions and the influence of display policy over user.",,,,
D62nJAdpijt,2021,Reject,False,Trojans and Adversarial Examples: A Lethal Combination,"[""Guanxiong Liu"", ""Issa Khalil"", ""Abdallah Khreishah"", ""Hai Phan""]",[],,,,,
D637S6zBRLD,2022,Reject,False,Learning Symmetric Representations for Equivariant World Models,"['Jung Yeon Park', 'Ondrej Biza', 'Linfeng Zhao', 'Jan-Willem van de Meent', 'Robin Walters']","[""equivariant"", ""symmetry"", ""contrastive loss"", ""world models"", ""transition"", ""representation theory"", ""generalization""]",Non-equivariant networks can be used to learn symmetric features to use with equivariant neural networks in domains with unclear symmetry.,,,,
D6nH3719vZy,2022,Accept (Spotlight),False,On Improving Adversarial Transferability of Vision Transformers ,"['Muzammal Naseer', 'Kanchana Ranasinghe', 'Salman Khan', 'Fahad Khan', 'Fatih Porikli']","[""Vision Transformers"", ""Adversarial Perturbations""]",Novel approach to improve transferability of adversarial perturbations found in vision transformers via self-ensemble and token refinement.,,,,
D78Go4hVcxO,2022,Accept (Spotlight),False,How Do Vision Transformers Work?,"['Namuk Park', 'Songkuk Kim']","[""vision transformer"", ""self-attention"", ""multi-head self-attention"", ""loss landscape""]","We show that (1) multi-head self-attentions (MSAs) for computer vision flatten the loss landscapes, (2) MSAs are low-pass filters as opposed to Convs, and (3) MSAs at the end of a stage significantly improve the accuracy.",,,,
D8njK_Ix5dJ,2022,Reject,False,Maximum Mean Discrepancy for Generalization in the Presence of Distribution and Missingness Shift,"['Liwen Ouyang', 'Aaron Key']","[""maximum mean discrepancy"", ""data shift"", ""covariate shift"", ""representation learning"", ""missing data""]",This paper develops a novel approach to train a more robust machine learning model when distribution shift and/or missingness shift exist between train and test data.,,,,
D8pn0BlHaGe,2022,Reject,False,Single-Cell Capsule Attention : an interpretable method of cell type classification for single-cell RNA-sequencing data,"['Tianxu Wang', 'Xiuli Ma']","[""Single-Cell RNA-sequencing"", ""cell type classification"", ""capsule network"", ""attention"", ""interpretable model""]",We present a interpretable cell type classification method single-cell capsule attention(scCA) which assigns cells to different cell types based on their different feature patterns for single-cell sequencing data.,,,,
D9E8MKsfhw,2022,Reject,False,An Empirical Investigation of the Role of Pre-training in Lifelong Learning,"['Sanket Vaibhav Mehta', 'Darshan Patil', 'Sarath Chandar', 'Emma Strubell']","[""Lifelong Learning"", ""Continual Learning"", ""Catastrophic Forgetting"", ""Pre-training""]","Generic pre-training alleviates the effects of catastrophic forgetting when learning multiple tasks sequentially compared to randomly initialized models, and it's due to finding flatter minima.",2112.09153,cs.LG,2021-12-16 19:00:55+00:00,2021-12-16 19:00:55+00:00
D9I3drBz4UC,2021,Accept (Spotlight),False,Long-tailed Recognition by Routing Diverse Distribution-Aware Experts,"[""Xudong Wang"", ""Long Lian"", ""Zhongqi Miao"", ""Ziwei Liu"", ""Stella Yu""]","[""Long-tailed Recognition"", ""Bias-variance Decomposition""]",,,,,
D9SuLzhgK9,2022,Reject,False,Adam is no better than normalized SGD:  Dissecting how adaptivity improves GAN performance,"['Samy Jelassi', 'Arthur Mensch', 'Gauthier Gidel', 'Yuanzhi Li']","[""Generative adversarial networks"", ""non-convex optimization""]",,,,,
D9pSaTGUemb,2021,Reject,False,Implicit Acceleration of Gradient Flow in Overparameterized Linear Models,"[""Salma Tarmoun"", ""Guilherme Fran\u00e7a"", ""Benjamin David Haeffele"", ""Rene Vidal""]",[],,,,,
DAaaaqPv9-q,2021,Reject,False,Self-supervised Graph-level Representation Learning with Local and Global Structure,"[""Minghao Xu"", ""Hang Wang"", ""Bingbing Ni"", ""Hongyu Guo"", ""Jian Tang""]","[""Self-supervised Representation Learning"", ""Graph Representation Learning"", ""Hierarchical Semantic Learning""]",This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.,2106.04113,cs.LG,2021-06-08 05:25:38+00:00,2021-06-08 05:25:38+00:00
DBOibe1ISzB,2022,Reject,False,SiT: Simulation Transformer for Particle-based Physics Simulation,"['Yidi Shao', 'Chen Change Loy', 'Bo Dai']",[],We propose Simulation Transformer (SiT) to simulate particle-based systems and achieve superior performance with less parameters in both validation and generalizations.,,,,
DBiQQYWykyy,2022,Accept (Poster),False,Environment Predictive Coding for Visual Navigation,"['Santhosh Kumar Ramakrishnan', 'Tushar Nagarajan', 'Ziad Al-Halah', 'Kristen Grauman']","[""Self-supervised learning"", ""visual navigation"", ""representation learning""]","We introduce environment predicting coding, a self-supervised approach for learning environment-level representations for navigation-like tasks.",,,,
DC1Im3MkGG,2021,Reject,False,Exchanging Lessons Between Algorithmic Fairness and Domain Generalization,"[""Elliot Creager"", ""Joern-Henrik Jacobsen"", ""Richard Zemel""]","[""algorithmic fairness"", ""domain generalization"", ""representation learning"", ""invariance""]","Drawing inspiration from recent fairness approaches, we propose a novel domain generalization method that outperforms IRM on the CMNIST dataset without requiring knowledge of the environment splits.",,,,
DE0MSwKv32y,2021,Reject,False,"Trust, but verify: model-based exploration in sparse reward environments","[""Konrad Czechowski"", ""Tomasz Odrzyg\u00f3\u017ad\u017a"", ""Micha\u0142 Izworski"", ""Marek Zbysi\u0144ski"", ""\u0141ukasz Kuci\u0144ski"", ""Piotr Mi\u0142o\u015b""]","[""reinforcement learning"", ""model-based"", ""exploration"", ""on-line planning"", ""imperfect environment model""]",We address exploration problems arising from on-line planning with learned environment models.,,,,
DEa4JdMWRHp,2021,Accept (Poster),False,Interpretable Models for Granger Causality Using Self-explaining Neural Networks,"[""Ri\u010dards Marcinkevi\u010ds"", ""Julia E Vogt""]","[""time series"", ""Granger causality"", ""interpretability"", ""inference"", ""neural networks""]",We propose an interpretable framework for inferring Granger causality based on self-explaining neural networks.,,,,
DFIoGDZejIB,2021,Reject,False,Benefits of Assistance over Reward Learning,"[""Rohin Shah"", ""Pedro Freire"", ""Neel Alex"", ""Rachel Freedman"", ""Dmitrii Krasheninnikov"", ""Lawrence Chan"", ""Michael D Dennis"", ""Pieter Abbeel"", ""Anca Dragan"", ""Stuart Russell""]","[""assistance"", ""reward learning"", ""preference learning"", ""active learning""]",Illustrate qualitative advantages of assistive agents over agents that use reward learning,,,,
DFYtZFo_1u,2022,Reject,False,Federated Inference through Aligning Local Representations and Learning a Consensus Graph,"['Tengfei Ma', 'Trong Nghia Hoang', 'Jie Chen']","[""Federated inference"", ""local latent representation"", ""feature alignment"", ""graph structure learning"", ""Gumbel softmax""]","A novel setting is considered and a method is proposed for training and inference with distributed data, where inference is conducted jointly by data owners without data sharing and coordinated training",,,,
DGIXvEAJVd,2021,Reject,False,Learning Chess Blindfolded,"[""Shubham Toshniwal"", ""Sam Wiseman"", ""Karen Livescu"", ""Kevin Gimpel""]","[""Chess"", ""Transformers"", ""Language Modeling"", ""World State""]",Language modeling for Chess with Transformers,2102.13249,cs.CL,2021-02-26 01:16:23+00:00,2021-02-26 01:16:23+00:00
DGttsPh502x,2021,Reject,False,Unsupervised Discovery of Interpretable Latent Manipulations in Language VAEs,"[""Max Ryabinin"", ""Artem Babenko"", ""Elena Voita""]","[""interpretability"", ""unsupervised interpretable directions"", ""controllable text generation""]","We propose the first method for unsupervised discovery of interpretable attribute manipulations in text variational autoencoders; this method is very simple, fast, and outperforms the baselines by a large margin.",,,,
DHLngM1mR3W,2022,Reject,False,AAVAE: Augmentation-Augmented Variational Autoencoders,"['William Alejandro Falcon', 'Ananya Harsh Jha', 'Teddy Koker', 'Kyunghyun Cho']","[""Self-Supervised Learning"", ""Autoencoders"", ""Variational Autoencoders"", ""Data Augmentation""]","We show the inadequacy of KL-divergence as a regularizer for learning representations with VAEs. Instead, autoencoders with a data augmentation pipeline, sampling in the latent space, and the absence of a KL-divergence term prove to be better.",,,,
DHSNrGhAY7W,2021,Reject,False,The Lipschitz Constant of Self-Attention,"[""Hyunjik Kim"", ""George Papamakarios"", ""Andriy Mnih""]","[""Lipschitz constant"", ""self-attention"", ""theory""]",Theoretical work showing that standard dot-product self-attention is *not* lipschitz and providing an alternative formulation of self-attention based on L2 distance that *is* Lipschitz.,,,,
DILxQP08O3B,2021,Accept (Poster),False,VTNet: Visual Transformer Network for Object Goal Navigation,"[""Heming Du"", ""Xin Yu"", ""Liang Zheng""]",[],,2105.09447,cs.CV,2021-05-20 01:23:15+00:00,2021-05-20 01:23:15+00:00
DIjCrlsu6Z,2022,Accept (Spotlight),False,Controlling Directions Orthogonal to a Classifier,"['Yilun Xu', 'Hao He', 'Tianxiao Shen', 'Tommi S. Jaakkola']","[""orthogonal classifier"", ""invariance""]","We develop a notion of orthogonality in classifier, and the corresponding construction and utility.",,,,
DIsWHvtU7lF,2022,Reject,False,Composing Partial Differential Equations with Physics-Aware Neural Networks,"['Matthias Karlbauer', 'Timothy Praditia', 'Sebastian Otte', 'Sergey Oladyshkin', 'Wolfgang Nowak', 'Martin V. Butz']","[""physics-aware neural networks"", ""partial differential equations"", ""advection-diffusion equations"", ""learning constituents"", ""out-of-distribution generalization""]",A physics-aware neural network for compositional learning of constituents of partial differential equations demonstrating eminent generalization abilities.,2111.11798,cs.LG,2021-11-23 11:27:13+00:00,2021-11-23 11:27:13+00:00
DM6KlL7GeB,2021,Reject,False,Semi-Relaxed Quantization with DropBits: Training Low-Bit Neural Networks via Bitwise Regularization,"[""Jung Hyun Lee"", ""Jihun Yun"", ""Sung Ju Hwang"", ""Eunho Yang""]","[""Quantization"", ""Compression"", ""Efficient Inference"", ""Deep Learning""]",,,,,
DMxOBm06HUx,2021,Reject,False,AMBERT: A Pre-trained Language Model with Multi-Grained Tokenization,"[""Xinsong Zhang"", ""Hang Li""]","[""Pre-trained Language Model"", ""Multi-Grained Tokenization""]",We propose a novel pre-trained language model with multi-grained tokenization which can sufficiently utilize advantages of both fine-grained tokenization and coarse-grained tokenization.,,,,
DNRADop4ksB,2022,Accept (Spotlight),True,On the Importance of Firth Bias Reduction in Few-Shot Classification,"['Saba Ghaffari', 'Ehsan Saleh', 'David Forsyth', 'Yu-Xiong Wang']","[""Few-shot Classification"", ""Firth Regularization"", ""MLE Bias""]",,2110.02529,cs.CV,2021-10-06 06:32:37+00:00,2021-10-06 06:32:37+00:00
DNl5s5BXeBn,2021,Accept (Poster),False,Fair Mixup: Fairness via Interpolation,"[""Ching-Yao Chuang"", ""Youssef Mroueh""]","[""fairness"", ""data augmentation""]",,2103.06503,cs.LG,2021-03-11 06:57:26+00:00,2021-03-11 06:57:26+00:00
DQpwoZgqyZ,2021,Reject,False,Model information as an analysis tool in deep learning,"[""Xiao Zhang"", ""Di Hu"", ""Xingjian Li"", ""Dejing Dou"", ""Ji Wu""]",[],,,,,
DSCsslei9r,2022,Reject,False,Multi-modal Self-supervised Pre-training for Regulatory Genome Across Cell Types,"['Shentong Mo', 'Xi Fu', 'Chenyang Hong', 'Yizhen Chen', 'Yuxuan Zheng', 'Xiangru Tang', 'Yanyan Lan', 'Zhiqiang Shen', 'Eric Xing']",[],,,,,
DSQHjibtgKR,2022,Accept (Poster),False,Online Facility Location with Predictions,"['Shaofeng H.-C. Jiang', 'Erzhi Liu', 'You Lyu', 'Zhihao Gavin Tang', 'Yubo Zhang']","[""online algorithms"", ""facility location"", ""prediction"", ""learning-augmented""]",We give a nearly optimal robust algorithm for online facility location with predictions.,,,,
DTXZqTNV5nW,2022,Accept (Poster),False,Actor-Critic Policy Optimization in a Large-Scale Imperfect-Information Game,"['Haobo Fu', 'Weiming Liu', 'Shuang Wu', 'Yijia Wang', 'Tao Yang', 'Kai Li', 'Junliang Xing', 'Bin Li', 'Bo Ma', 'QIANG FU', 'Yang Wei']","[""Policy Optimization"", ""Nash Equilibrium"", ""Mahjong AI""]",A new actor-critic algorithm for approximating a Nash Equilibrium in the large-scale imperfect-information game 1v1 Mahjong.,,,,
DTkEfj0Ygb8,2022,Accept (Spotlight),False,Learning meta-features for AutoML,"['Herilalaina Rakotoarison', 'Louisot Milijaona', 'Andry RASOANAIVO', 'Michele Sebag', 'Marc Schoenauer']","[""AutoML"", ""Meta-features"", ""Hyper-parameter Optimization"", ""Optimal Transport""]",We propose a novel approach to learn dataset meta-features for AutoML.,,,,
DXPftn5kjQK,2022,Accept (Poster),True,The Rich Get Richer: Disparate Impact of Semi-Supervised Learning,"['Zhaowei Zhu', 'Tianyi Luo', 'Yang Liu']","[""semi-supervised learning"", ""fairness"", ""disparate impact"", ""Matthew effect"", ""consistency regularization""]","We reveal the disparate impacts of deploying SSL: the ""rich"" sub-population (higher baseline accuracy without SSL) benefits more from SSL; while the ""poor"" sub-population (low baseline accuracy) might even observe a performance drop after SSL.",2110.06282,cs.LG,2021-10-12 19:05:06+00:00,2021-10-12 19:05:06+00:00
DXRwVRh4i8g,2022,Reject,False,Reachability Traces for Curriculum Design in Reinforcement Learning,"['Thommen Karimpanal George', 'Majid Abdolshah', 'Hung Le', 'Santu Rana', 'Sunil Gupta', 'Truyen Tran', 'Svetha Venkatesh']","[""reinforcement learning"", ""curriculum learning"", ""sparse rewards""]","We propose the idea of reachability traces, which provides an indication of closeness to a goal state, and use this as a basis for designing a curriculum for goal-based tasks in reinforcement learning.",,,,
DXU0DQUDWLA,2022,Reject,False,Disentangling One Factor at a Time,"['Vaishnavi S Patil', 'Matthew S Evanusa', 'Joseph JaJa']","[""unsupervised representation learning"", ""disentanglement"", ""Variational Autoencoders"", ""Generative Adversarial Networks""]",Unsupervised disentanglement of one factor at a time from the entangled representations,,,,
DYaFB19z1ig,2022,Reject,False,Self-Distribution Distillation: Efficient Uncertainty Estimation,"['Yassir Fathullah', 'Mark Gales']","[""distillation"", ""self-distillation"", ""distribution distillation"", ""uncertainty"", ""robustness""]",Novel approaches for efficient and robust uncertainty estimation,,,,
DYypjaRdph2,2022,Accept (Poster),False,Inverse Online Learning: Understanding Non-Stationary and Reactionary Policies,"['Alex Chan', 'Alicia Curth', 'Mihaela van der Schaar']","[""Decision Modelling"", ""Imitation Learning"", ""Inverse Online Learning""]",,,,,
D_KeYoqCYC,2021,Accept (Poster),False,Sparse encoding for more-interpretable feature-selecting representations in probabilistic matrix factorization,"[""Joshua C Chang"", ""Patrick Fletcher"", ""Jungmin Han"", ""Ted L Chang"", ""Shashaank Vattikuti"", ""Bart Desmet"", ""Ayah Zirikly"", ""Carson C Chow""]","[""poisson matrix factorization"", ""generalized additive model"", ""probabilistic matrix factorization"", ""bayesian"", ""sparse coding"", ""interpretability"", ""factor analysis""]",We introduce a simple modification to existing sparse matrix factorization methods to rectify widespread erroneous interpretation of the factors.,,,,
Da3ZcbjRWy,2022,Reject,False,Self-Supervised Representation Learning via Latent Graph Prediction,"['Yaochen Xie', 'Zhao Xu', 'Shuiwang Ji']","[""Self-supervised learning"", ""representation learning"", ""graph neural networks""]",,,,,
DaQVj6qY2-s,2022,Reject,False,Understanding Graph Learning with Local Intrinsic Dimensionality,"['Xiaojun Guo', 'Xingjun Ma', 'Yisen Wang']","[""Local Intrinsic Dimensionality"", ""Graph Neural Networks""]",,,,,
Db4yerZTYkz,2021,Accept (Poster),False,Shape-Texture Debiased Neural Network Training,"[""Yingwei Li"", ""Qihang Yu"", ""Mingxing Tan"", ""Jieru Mei"", ""Peng Tang"", ""Wei Shen"", ""Alan Yuille"", ""cihang xie""]","[""data augmentation"", ""representation learning"", ""debiased training""]",Training CNNs to acquire a debiased shape-texture representation improves image recognition.,,,,
DdGCxq9C_Gr,2021,Reject,False,Dropout's Dream Land: Generalization from Learned Simulators to Reality,"[""Zac Wellmer"", ""James Kwok""]","[""Reinforcement Learning""]",A simple technique to bridge the sim2real gap between learned artificial neural network simulators and reality,,,,
DegtqJSbxo,2021,Reject,False,Adversarial and Natural Perturbations for General Robustness,"[""Sadaf Gulshad"", ""Jan Hendrik Metzen"", ""Arnold W.M. Smeulders""]","[""Robustness"", ""Adversarial Examples"", ""Natural Perturbations"", ""General Robustness""]",,,,,
DesNW4-5ai9,2022,Accept (Poster),False,Transferable Adversarial Attack based on Integrated Gradients,"['Yi Huang', 'Adams Wai-Kin Kong']",[],,,,,
DfMqlB0PXjM,2022,Accept (Spotlight),True,Interpretable Unsupervised Diversity Denoising and Artefact Removal,"['Mangal Prakash', 'Mauricio Delbracio', 'Peyman Milanfar', 'Florian Jug']","[""Interpretable Unsupervised Image Restoration"", ""Diversity Image Restoration"", ""Unsupervised Image Denoising"", ""Unsupervised Artefact Removal""]","This work proposes a new architecture for unsupervised, interpretable and diverse image restoration while achieving state-of-the-art results on numerous commonly used benchmarks across multiple image domains.",2104.01374,eess.IV,2021-04-03 11:00:21+00:00,2021-04-03 11:00:21+00:00
DfUjyyRW90,2022,Accept (Poster),False,Information Prioritization through Empowerment in Visual Model-based RL,"['Homanga Bharadhwaj', 'Mohammad Babaeizadeh', 'Dumitru Erhan', 'Sergey Levine']","[""model-based reinforcement learning"", ""visual distractors"", ""empowerment""]",Empowerment along with mutual information maximization helps learn functionally relevant factors in visual model-based RL,,,,
Dh29CAlnMW,2021,Reject,False,Parsed Categoric Encodings with Automunge,"[""Nicholas Teague""]","[""tabular"", ""feature engineering""]",String parsed encoding aggregations for tabular data categoric feature sets.,,,,
DhP9L8vIyLc,2022,Accept (Poster),True,PAC Prediction Sets Under Covariate Shift,"['Sangdon Park', 'Edgar Dobriban', 'Insup Lee', 'Osbert Bastani']","[""probably approximately correct"", ""prediction set"", ""covariate shift"", ""importance weight"", ""calibration"", ""Clopper-Pearson binomial interval"", ""rejection sampling""]","We propose a novel algorithm that constructs a prediction set with probably approximated correct (PAC) guarantee under covariate shift, while minimizing the expected prediction set size. ",2106.09848,cs.LG,2021-06-17 23:28:42+00:00,2021-06-17 23:28:42+00:00
DhzIU48OcZh,2022,Accept (Poster),True,P-Adapters: Robustly Extracting Factual Information from Language Models with Diverse Prompts,"['Benjamin Newman', 'Prafulla Kumar Choubey', 'Nazneen Rajani']","[""NLP"", ""Prompting"", ""Commonsense"", ""information extraction"", ""factual extraction"", ""Large Language Models""]",We make prompting large language models for factual information more robust by introducing P-Adapter models.,2110.07280,cs.CL,2021-10-14 11:32:22+00:00,2021-10-14 11:32:22+00:00
DiQD7FWL233,2021,Accept (Poster),True,Improving Relational Regularized Autoencoders with Spherical Sliced Fused Gromov Wasserstein,"[""Khai Nguyen"", ""Son Nguyen"", ""Nhat Ho"", ""Tung Pham"", ""Hung Bui""]","[""Relational regularized autoencoder"", ""deep generative model"", ""sliced fused Gromov Wasserstein"", ""spherical distributions""]",Improving relational regularized autoencoder by introducing new sliced optimal transport discrepancies between the prior and aggregated posterior distributions.,2010.01787,stat.ML,2020-10-05 05:26:50+00:00,2020-10-05 05:26:50+00:00
DigrnXQNMTe,2021,Reject,False,A generalized probability kernel on discrete distributions and its application in two-sample test,"[""Le Niu""]","[""maximum mean discrepancy"", ""RKHS"", ""two-sample test"", ""empirical estimator"", ""discrete distributions""]",,,,,
DkeCkhLIVGZ,2022,Reject,False,Understanding Metric Learning on Unit Hypersphere and Generating Better Examples for Adversarial Training,"['Yihan Wu', 'Heng Huang']","[""Metric learning"", ""Adversarial learning""]",We study tuple-based metric learning models on unit hypersphere and design adversarial DML models based on our theoretical results.,,,,
DktZb97_Fx,2021,Accept (Oral),True,SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness,"[""Mikhail Yurochkin"", ""Yuekai Sun""]","[""Algorithmic fairness"", ""invariance""]",We propose a new invariance-enforcing regularizer for training individually fair ML systems.,2006.14168,cs.LG,2020-06-25 04:31:57+00:00,2021-04-01 03:24:44+00:00
Dl4LetuLdyK,2022,Accept (Oral),False,A Fine-Grained Analysis on Distribution Shift,"['Olivia Wiles', 'Sven Gowal', 'Florian Stimberg', 'Sylvestre-Alvise Rebuffi', 'Ira Ktena', 'Krishnamurthy Dj Dvijotham', 'Ali Taylan Cemgil']","[""robustness"", ""distribution shifts""]",We investigate and analyse the robustness of a variety of methods under distribution shifts using our flexible experimental framework.,,,,
DlPnp5_1JMI,2021,Reject,False,PDE-regularized Neural Networks for Image Classification,"[""Jungeun Kim"", ""Seunghyun Hwang"", ""Jihyun Hwang"", ""Kookjin Lee"", ""Dongeun Lee"", ""Noseong Park""]","[""Neural ODE"", ""Partial Differential Equations"", ""Image Classification""]",Use partial differential equations to regularize neural networks,,,,
DmpCfq6Mg39,2022,Accept (Spotlight),False,Omni-Dimensional Dynamic Convolution,"['Chao Li', 'Aojun Zhou', 'Anbang Yao']","[""Convolutional Neural Networks"", ""Dynamic Convolution"", ""Attention"", ""Image Classification""]",This paper presents Omni-dimensional Dynamic Convolution (ODConv) to advance the research in dynamic convolution.,,,,
Dmpi13JiqcX,2021,Reject,False,Disentangling Representations of Text by Masking Transformers,"[""Xiongyi Zhang"", ""Jan-Willem van de Meent"", ""Byron C Wallace""]","[""disentanglement"", ""model pruning"", ""representation learning"", ""transformers""]",Learning disentangled representations by identifying subnetworks in pre-trained transformer models.,,,,
DnG75_KyHjX,2022,Accept (Poster),False,MoReL: Multi-omics Relational Learning,"['Arman Hasanzadeh', 'Ehsan Hajiramezanali', 'Nick Duffield', 'Xiaoning Qian']","[""relational learning"", ""data integration"", ""multi-view learning"", ""Bayesian generative model""]",,,,,
DrCsriMQ1o,2022,Reject,False,Gradient-based Counterfactual Explanations using Tractable Probabilistic Models,"['Xiaoting Shao', 'Kristian Kersting']","[""Counterfactual example"", ""Sum product networks"", ""tractable probabilistic models"", ""counterfactual explanation.""]",Generating counterfactual examples using tractable probabilistic models. ,,,,
DrZXuTGg2A-,2022,Accept (Poster),True,Shuffle Private Stochastic Convex Optimization,"['Albert Cheu', 'Matthew Joseph', 'Jieming Mao', 'Binghui Peng']","[""shuffle privacy"", ""stochastic convex optimization"", ""differential privacy""]",The first analysis of shuffle private stochastic convex optimization.,2106.09805,cs.LG,2021-06-17 20:44:00+00:00,2021-06-17 20:44:00+00:00
DrpKmCmPMSC,2022,Reject,False,Meta-free few-shot learning via representation learning with weight averaging,"['Kuilin Chen', 'Chi-Guhn Lee']","[""few-shot learning"", ""representation learning""]",,,,,
Drynvt7gg4L,2021,Accept (Poster),False,AdaSpeech: Adaptive Text to Speech for Custom Voice,"[""Mingjian Chen"", ""Xu Tan"", ""Bohan Li"", ""Yanqing Liu"", ""Tao Qin"", ""sheng zhao"", ""Tie-Yan Liu""]","[""Text to speech"", ""adaptation"", ""fine-tuning"", ""custom voice"", ""acoustic condition modeling"", ""conditional layer normalization""]","We propose AdaSpeech, an adaptive TTS system for high-quality and efficient adaptation of new speaker in custom voice.",2103.00993,eess.AS,2021-03-01 13:28:59+00:00,2021-03-01 13:28:59+00:00
Dtahsj2FkrK,2021,Reject,True,A REINFORCEMENT LEARNING FRAMEWORK FOR TIME DEPENDENT CAUSAL EFFECTS EVALUATION IN A/B TESTING,"[""Chengchun Shi"", ""Xiaoyu Wang"", ""Shikai Luo"", ""Rui Song"", ""Hongtu Zhu"", ""Jieping Ye""]","[""reinforcement learning"", ""A/B testing"", ""causal inference"", ""sequential testing""]",We introduce a reinforcement learning framework to evaluate time dependent causal effects in A/B testing.,2002.01711,cs.LG,2020-02-05 10:25:02+00:00,2020-02-10 08:49:39+00:00
DtfrnB1fiX,2022,Reject,False,Squeezing SGD Parallelization Performance in Distributed Training Using Delayed Averaging,"['Pengcheng Li', 'Yixin Guo', 'Yawen Zhang', 'Qinggang Zhou']","[""SGD"", ""distributed training"", ""hide communication cost"", ""convergence""]",,,,,
Du7s5ukNKz,2021,Reject,True,Policy Learning Using Weak Supervision,"[""Jingkang Wang"", ""Hongyi Guo"", ""Zhaowei Zhu"", ""Yang Liu""]","[""Weak Supervision"", ""Policy Learning"", ""Correlated Agreement""]","We introduce a novel framework to handle the common ""weakly supervision"" problem in policy learning based on a correlated agreement.",2010.01748,cs.LG,2020-10-05 02:26:08+00:00,2021-11-02 13:59:27+00:00
Dup_dDqkZC5,2022,Accept (Spotlight),True,Latent Variable Sequential Set Transformers for Joint Multi-Agent Motion Prediction,"['Roger Girgis', 'Florian Golemo', 'Felipe Codevilla', 'Martin Weiss', ""Jim Aldon D'Souza"", 'Samira Ebrahimi Kahou', 'Felix Heide', 'Christopher Pal']","[""trajectory prediction"", ""motion forecasting"", ""transformers"", ""latent variable models""]",New Transformer-based architecture for socially consistent motion forecasting. Achieves SotA performance on NuScenes at a fraction of the compute of competing methods.,2104.00563,cs.RO,2021-02-19 18:53:26+00:00,2022-02-11 04:59:43+00:00
DvcMMKmDJ3q,2022,Reject,True,Generating Symbolic Reasoning Problems with Transformer GANs,"['Jens U. Kreber', 'Christopher Hahn']","[""Transformer"", ""GAN"", ""symbolic reasoning"", ""temporal logic""]",Transformer GANs generate useful problem instances for symbolic reasoning.,2110.10054,cs.LG,2021-10-19 15:30:24+00:00,2021-10-19 15:30:24+00:00
Dw8vAUKYq8C,2021,Reject,True,Near-Optimal Glimpse Sequences for Training Hard Attention Neural Networks,"[""William Harvey"", ""Michael Teng"", ""Frank Wood""]","[""attention"", ""hard attention"", ""variational inference"", ""bayesian optimal experimental design""]",We use Bayesian experimental design to produce sequences which are later used to provide a supervision signal for a hard attention network and greatly speed up its training.,1906.05462,cs.LG,2019-06-13 03:01:04+00:00,2020-06-14 18:49:31+00:00
Dy8gq-LuckD,2022,Reject,False,Recognizing and overcoming the greedy nature of learning in multi-modal deep neural networks,"['Nan Wu', 'Stanislaw Kamil Jastrzebski', 'Kyunghyun Cho', 'Krzysztof J. Geras']","[""multi-modal learning"", ""deep neural networks"", ""multi-view learning""]",,,,,
DzBDB7y8UOy,2022,Reject,False,CoLLIE: Continual Learning of Language Grounding from Language-Image Embeddings,"['Gabriel Skantze', 'Bram Willemsen']","[""Continual Learning"", ""Language Grounding"", ""Language-Image Embeddings"", ""Multimodal Distributional Semantics"", ""Reference Resolution""]","We present a new model for continual learning of how language is grounded in vision, through multimodal embeddings. ",2111.07993,cs.CL,2021-11-15 18:54:58+00:00,2021-11-15 18:54:58+00:00
DzKPXXr-CLK,2022,Reject,False,Abelian Neural Networks,"['Kenshin Abe', 'Takanori Maehara', 'Issei Sato']","[""algebra"", ""Abelian group"", ""word analogy"", ""invertible neural networks"", ""permutation invariant"", ""size generalization""]",We propose a neural network architecture for modeling Abelian groups.,,,,
Dzpe9C1mpiv,2022,Accept (Poster),False,A Unified Wasserstein Distributional Robustness Framework for Adversarial Training,"['Anh Tuan Bui', 'Trung Le', 'Quan Hung Tran', 'He Zhao', 'Dinh Phung']","[""Adversarial Machine Learning"", ""Distributional Robustness""]",A Unified Wasserstein Distributional Robustness Framework for Adversarial Training,,,,
E-dq2kN8lt,2022,Reject,False,FedPAGE: A Fast Local Stochastic Gradient Method for Communication-Efficient Federated Learning,"['Haoyu Zhao', 'Zhize Li', 'Peter RichtÃ¡rik']","[""federated learning"", ""nonconvex optimization"", ""convex optimization"", ""local gradient method""]","We propose a new federated learning algorithm, FedPAGE, providing much better state-of-the-art communication complexity for both federated convex and nonconvex optimization. ",,,,
E0zOKxQsZhN,2022,Reject,False,Recurrent Model-Free RL is a Strong Baseline for Many POMDPs,"['Tianwei Ni', 'Benjamin Eysenbach', 'Sergey Levine', 'Ruslan Salakhutdinov']","[""POMDP"", ""RNN"", ""recurrent model-free RL"", ""baseline"", ""meta RL"", ""robust RL"", ""generalization in RL""]","Recurrent model-free RL is competitive with more sophisticated methods on partially-observed tasks, provided that some design decisions are made carefully.",,,,
E3UZoJKHxuk,2021,Reject,False,Latent Causal Invariant Model,"[""Xinwei Sun"", ""Botong Wu"", ""Chang Liu"", ""Xiangyu Zheng"", ""Wei Chen"", ""Tao Qin"", ""Tie-Yan Liu""]","[""invariance"", ""causality"", ""spurious correlation"", ""out-of-distribution generalization"", ""interpretability"", ""variational auto-encoder""]","We leverage causal invariance to avoid spurious correlation for better out-of-distribution generalization, interpretability and robustness.",,,,
E3Ys6a1NTGT,2021,Accept (Poster),False,The Importance of Pessimism in Fixed-Dataset Policy Optimization,"[""Jacob Buckman"", ""Carles Gelada"", ""Marc G Bellemare""]","[""deep learning"", ""reinforcement learning"", ""offline reinforcement learning""]","A unified conceptual and mathematical framework for fixed-dataset policy optimization algorithms, revealing the importance of uncertainty and pessimism.",,,,
E4EE_ohFGz,2022,Accept (Poster),False,Diurnal or Nocturnal? Federated Learning of Multi-branch Networks from Periodically Shifting Distributions,"['Chen Zhu', 'Zheng Xu', 'Mingqing Chen', 'Jakub KoneÄnÃ½', 'Andrew Hard', 'Tom Goldstein']","[""Federated Learning"", ""Peroredical Distribution Shift""]","We study a better modeling assumption for the periodical distribution shift in FL, and propose algorithms that learn better from the shifting distribution.",,,,
E4PK0rg2eP,2021,Reject,False,Parameter-Efficient Transfer Learning with Diff Pruning,"[""Demi Guo"", ""Alexander M Rush"", ""Yoon Kim""]","[""transfer learning"", ""parameter efficiency""]",Parameter-efficient transfer learning for NLP by learning to finetune only a few parameters for each task,,,,
E6fb6ehhLh8,2021,Reject,False,Unified Principles For Multi-Source Transfer Learning Under Label Shifts,"[""changjian shui"", ""Zijian Li"", ""jiaqi li"", ""Christian Gagn\u00e9"", ""Charles Ling"", ""Boyu Wang""]",[],,,,,
E8fmaZwzEj,2021,Reject,True,Defective Convolutional Networks,"[""Tiange Luo"", ""Tianle Cai"", ""Mengxiao Zhang"", ""Siyu Chen"", ""Di He"", ""Liwei Wang""]","[""Representation Learning"", ""Robustness""]","A new kind of CNNs that makes predictions relying less on textural information but more on shape information. Compared to standard CNNs, the proposed ones show better defense performance against black-box attacks.",1911.08432,cs.CV,2019-11-19 17:56:22+00:00,2020-04-06 20:47:57+00:00
E9W0QPxtZ_u,2021,Reject,False,not-so-big-GAN: Generating High-Fidelity Images on Small Compute with Wavelet-based Super-Resolution,"[""Seungwook Han"", ""Akash Srivastava"", ""Cole Lincoln Hurwitz"", ""Prasanna Sattigeri"", ""David Daniel Cox""]","[""deep generative modeling"", ""GAN"", ""super-resolution"", ""wavelet transformation"", ""energy efficient""]","Energy-efficient framework for generating high-fidelity, high-resolution images using wavelet-based super-resolution",,,,
E9e18Ms5TeV,2022,Reject,False,"A Large Batch Optimizer Reality Check: Traditional, Generic Optimizers Suffice Across Batch Sizes","['Zachary Nado', 'Justin Gilmer', 'Christopher J Shallue', 'Rohan Anil', 'George Edward Dahl']","[""neural networks"", ""deep learning"", ""neural network optimization"", ""hyperparameter tuning"", ""optimizer comparison""]","We retune the Nesterov/Adam optimizers on pipelines where LARS/LAMB are commonly used and achieve similar or better performance, providing competitive baselines for the large batch training setting.",,,,
E9z2A1-O7e,2022,Reject,False,HyperTransformer: Attention-Based CNN Model Generation from Few Samples,"['Andrey Zhmoginov', 'Max Vladymyrov', 'Mark Sandler']","[""few-shot learning"", ""transformer model"", ""weight generation"", ""supervised learning"", ""semi-supervised learning""]",,,,,
EArH-0iHhIq,2021,Reject,False,ON NEURAL NETWORK GENERALIZATION VIA PROMOTING WITHIN-LAYER ACTIVATION DIVERSITY,"[""Firas Laakom"", ""Jenni Raitoharju"", ""Alexandros Iosifidis"", ""Moncef Gabbouj""]","[""Deep learning""]",We propose an additional loss for neural network training promoting within-layer neurons' diversity and provide a theoretical analysis of its impact on the generalization error.,2106.06012,cs.LG,2021-06-10 19:14:45+00:00,2021-06-10 19:14:45+00:00
EAy7C1cgE1L,2022,Accept (Spotlight),False,Increasing the Cost of Model Extraction with Calibrated Proof of Work,"['Adam Dziedzic', 'Muhammad Ahmad Kaleem', 'Yu Shen Lu', 'Nicolas Papernot']","[""model extraction"", ""model stealing"", ""model functionality stealing"", ""proof-of-work"", ""adversarial machine learning"", ""trustworthy machine learning"", ""deep learning""]",We propose to make model extraction more difficult by requiring users to complete a callibrated proof-of-work before they can read predictions from a machine learning model exposed via a public API.,2201.09243,cs.CR,2022-01-23 12:21:28+00:00,2022-01-23 12:21:28+00:00
EBRTjOm_sl1,2021,Reject,False,Learning Active Learning in the Batch-Mode Setup with Ensembles of Active Learning Agents,"[""Malte Ebner"", ""Bernhard Kratzwald"", ""Stefan Feuerriegel""]","[""active learning"", ""ensembles""]",This paper proposes to perform active learning with a parametrised ensemble of agents and evaluates the approach in the batch-mode setting.,,,,
EBn0uInJZWh,2022,Accept (Poster),False,Model-Based Offline Meta-Reinforcement Learning with Regularization,"['Sen Lin', 'Jialin Wan', 'Tengyu Xu', 'Yingbin Liang', 'Junshan Zhang']","[""offline reinforcement learning"", ""model-based reinforcement learning"", ""behavior policy"", ""Meta-reinforcement learning""]","This paper proposes a novel offline Meta-RL algorithm with regularization, which has provable performance improvement and outperforms the existing baselines empirically.",2202.02929,cs.LG,2022-02-07 04:15:20+00:00,2022-02-07 04:15:20+00:00
ECuvULjFQia,2021,Accept (Poster),False,A teacher-student framework to distill future trajectories,"[""Alexander Neitz"", ""Giambattista Parascandolo"", ""Bernhard Sch\u00f6lkopf""]","[""meta-learning"", ""privileged information""]",We explore meta-learning a teacher network to efficiently incorporate privileged information such as trajectories.,,,,
ECvgmYVyeUz,2022,Accept (Poster),False,Chaos is a Ladder: A New Understanding of Contrastive Learning,"['Yifei Wang', 'Qi Zhang', 'Yisen Wang', 'Jiansheng Yang', 'Zhouchen Lin']","[""Contrastive Learning"", ""Representation Learning"", ""Self-supervised Learning""]",,,,,
EDeVYpT42oS,2022,Accept (Spotlight),False,Deconstructing the Inductive Biases of Hamiltonian Neural Networks,"['Nate Gruver', 'Marc Anton Finzi', 'Samuel Don Stanton', 'Andrew Gordon Wilson']",[],,,,,
EFSctTwY4xn,2022,Reject,False,Towards Generalizable Personalized Federated Learning with Adaptive Local Adaptation,"['Sijia Chen', 'Baochun Li']","[""Personalized federated learning"", ""Meta-learning"", ""Information theory""]",Our work analyzed the personalized federated learning through the information theory and achieved the generalizable personalized federated learning by proposing the adaptive local adaptation.,,,,
EFgzhSJYIj6,2022,Reject,False,RL-DARTS: Differentiable Architecture Search for Reinforcement Learning,"['Yingjie Miao', 'Xingyou Song', 'Daiyi Peng', 'Summer Yue', 'John D Co-Reyes', 'Eugene Brevdo', 'Aleksandra Faust']","[""darts"", ""differentiable"", ""architecture"", ""search"", ""neural"", ""nas"", ""rl"", ""reinforcement"", ""learning"", ""procgen"", ""supernet"", ""softmax"", ""variable"", ""ppo"", ""rainbow"", ""off-policy"", ""on-policy"", ""convolutional"", ""autorl"", ""automated"", ""one-shot"", ""efficient""]","Our work is one of the first to study DARTS optimization in reinforcement learning, a completely different paradigm than supervised learning, and we demonstrate DARTS's ability to find competitive and better architectures efficiently.",,,,
EG5Pgd7-MY,2022,Reject,False,Privacy Auditing of Machine Learning using Membership Inference Attacks,"['Jiayuan Ye', 'Aadyaa Maddi', 'Sasi Kumar Murakonda', 'Reza Shokri']",[],,2111.09679,cs.LG,2021-11-18 13:31:22+00:00,2022-01-22 15:51:32+00:00
EGVxmJKLC2L,2021,Reject,True,Learning not to learn: Nature versus nurture in silico,"[""Robert Tjarko Lange"", ""Henning Sprekeler""]","[""Meta-Learning"", ""Reinforcement Learning""]",We show that meta-learning provides an answer to when it is beneficial to learn an adaptive strategy & when to hard-code a heuristic behavior.,2010.04466,cs.LG,2020-10-09 09:47:40+00:00,2021-03-04 11:27:16+00:00
EGdFhBzmAwB,2021,Accept (Spotlight),False,Generalization bounds via distillation,"[""Daniel Hsu"", ""Ziwei Ji"", ""Matus Telgarsky"", ""Lan Wang""]","[""Generalization"", ""statistical learning theory"", ""theory"", ""distillation""]",This paper provides a suite of mathematical tools to bound the generalization error of networks which possess low-complexity distillations.,2104.05641,cs.LG,2021-04-12 17:03:13+00:00,2021-04-12 17:03:13+00:00
EGtUVDm991w,2022,Reject,False,Token Pooling in Vision Transformers,"['Dmitrii Marin', 'Jen-Hao Rick Chang', 'Anurag Ranjan', 'Anish Prabhu', 'Mohammad Rastegari', 'Oncel Tuzel']","[""Transformer"", ""Pooling"", ""Downsampling"", ""Efficiency""]","We propose Token Pooling, a novel nonuniform data-aware downsampling operator for transformers efficiently exploiting redundancy in features.",,,,
EHaUTlm2eHg,2022,Accept (Poster),True,Policy Gradients Incorporating the Future,"['David Venuto', 'Elaine Lau', 'Doina Precup', 'Ofir Nachum']",[],,2108.02096,cs.LG,2021-08-04 14:57:11+00:00,2021-08-11 21:01:19+00:00
EIm_pvFJx5k,2022,Reject,True,Meta-Forecasting by combining Global Deep Representations with Local Adaptation,"['Riccardo Grazzi', 'Valentin Flunkert', 'David Salinas', 'Tim Januschowski', 'Matthias Seeger', 'Cedric Archambeau']","[""time-series"", ""meta-learning"", ""closed-form"", ""solvers""]",Combining an RNN representation with a close-form adaptation allows to compute accurate forecasts for out of sample time-series,2111.03418,cs.LG,2021-11-05 11:45:02+00:00,2021-11-12 14:35:25+00:00
EJKLVMB_9T,2022,Reject,False,SplitRegex: Faster Regex Synthesis via Neural Example Splitting,"['Su-Hyeon Kim', 'Hyunjoon Cheon', 'Yo-Sub Han', 'Sang-Ki Ko']","[""regular expression"", ""program synthesis"", ""programming by examples"", ""deep learning"", ""neural network""]",We propose an effective regex synthesis framework called 'SplitRegex' that synthesizes subregexes from 'splitted' positive substrings and produces the final regex by concatenating the synthesized subregexes.,,,,
EKV158tSfwv,2021,Accept (Poster),False,Efficient Continual Learning with Modular Networks and Task-Driven Priors,"[""Tom Veniat"", ""Ludovic Denoyer"", ""MarcAurelio Ranzato""]","[""Continual learning"", ""Lifelong learning"", ""Benchmark"", ""Modular network"", ""Neural Network""]",We propose a new benchmark allowing a detailed analysis of the properties of continual learning alogrithms and a new modular neural network leveraging task-based priors to efficiently learn in the CL setting.,,,,
EKb4Z0aSNf,2021,Reject,False,CLOPS: Continual Learning of Physiological Signals,"[""Dani Kiyasseh"", ""Tingting Zhu"", ""David A. Clifton""]","[""Continual learning"", ""physiological signals"", ""healthcare""]",,,,,
EKjUnoX-7M0,2022,Reject,False,A new look at fairness in stochastic multi-armed bandit problems,"['Guanhua Fang', 'Ping Li', 'Gennady Samorodnitsky']",[],Paper has 24 pages,,,,
EKw6nZ4QkJl,2021,Reject,False,EM-RBR: a reinforced framework for knowledge graph completion from reasoning perspective,"[""Bozhou Chen"", ""Zhaochong An"", ""Houde Quan"", ""Qihui Lin"", ""Hongzhi Wang""]","[""knowledge graph completion"", ""bread first search""]",knowledge graph completion from reasoning perspective,,,,
ELiYxj9JlyW,2021,Reject,False,ME-MOMENTUM:  EXTRACTING HARD CONFIDENT EXAMPLES FROM NOISILY LABELED DATA,"[""Yingbin Bai"", ""Tongliang Liu""]","[""label noise"", ""hard confident examples""]","In this work, we try to address the label noise problem by extracting hard confident examples.",,,,
EMHoBG0avc1,2021,Accept (Poster),False,Answering Complex Open-Domain Questions with Multi-Hop Dense Retrieval,"[""Wenhan Xiong"", ""Xiang Li"", ""Srini Iyer"", ""Jingfei Du"", ""Patrick Lewis"", ""William Yang Wang"", ""Yashar Mehdad"", ""Scott Yih"", ""Sebastian Riedel"", ""Douwe Kiela"", ""Barlas Oguz""]","[""multi-hop question answering"", ""recursive dense retrieval"", ""open domain complex question answering""]",We propose a simple yet effective multi-hop dense retrieval approach for answering complex open-domain questions.,,,,
EMLJ_mTz_z,2022,Reject,False,Convolutional Neural Network Dynamics: A Graph Perspective,"['Fatemeh Vahedian', 'Ruiyu Li', 'Puja Trivedi', 'Di Jin', 'Danai Koutra']","[""neural network dynamics"", ""time-evolving graphs"", ""interpretation of neural networks"", ""performance prediction""]",This paper seeks to understand the learning process of NNs and predict their performance from a few epochs by taking a graph perspective: it represents the training process of NNs as a dynamic graph and summarizes it via simple graph statistics.,2111.05410,cs.LG,2021-11-09 20:38:48+00:00,2021-11-09 20:38:48+00:00
EMigfE6ZeS,2022,Accept (Poster),False,Hybrid Random Features,"['Krzysztof Marcin Choromanski', 'Han Lin', 'Haoxian Chen', 'Arijit Sehanobish', 'Yuanzhe Ma', 'Deepali Jain', 'Jake Varley', 'Andy Zeng', 'Michael S Ryoo', 'Valerii Likhosherstov', 'Dmitry Kalashnikov', 'Vikas Sindhwani', 'Adrian Weller']","[""random features"", ""softmax kernel"", ""attention mechanism"", ""compositional kernels""]",We propose a new class of random feature methods for softmax and Gaussian kernel estimation that are adaptable to provide particularly accurate approximation in the desired regions of interest.,,,,
EMxu-dzvJk,2022,Accept (Poster),False,GRAND++: Graph Neural Diffusion with A Source Term,"['Matthew Thorpe', 'Tan Minh Nguyen', 'Hedi Xia', 'Thomas Strohmer', 'Andrea Bertozzi', 'Stanley Osher', 'Bao Wang']","[""graph deep learning"", ""low-labeling rates"", ""diffusion on graphs"", ""random walk""]",We propose GRAND++ for deep graph learning with limited labeled training data,,,,
EQ7A6F7k0r_,2022,Reject,True,QTN-VQC: An End-to-End Learning Framework for Quantum Neural Networks,"['Jun Qi', 'Chao-Han Huck Yang', 'Pin-Yu Chen']","[""quantum neural networks"", ""variational quantum circuits"", ""end-to-end learning framework"", ""tensor-train network""]",An end-to-end learning framework for quantum neural network based on our proposed QTN-VQC model,2110.03861,quant-ph,2021-10-06 14:44:51+00:00,2021-11-22 23:25:39+00:00
EQfpYwF3-b,2021,Accept (Poster),False,Deep Learning meets Projective Clustering,"[""Alaa Maalouf"", ""Harry Lang"", ""Daniela Rus"", ""Dan Feldman""]","[""Compressing Deep Networks"", ""NLP"", ""Matrix Factorization"", ""SVD""]",We suggest a novel technique for compressing a fully connected layer (or an embedding layer).,,,,
EQmAP4F859,2022,Accept (Poster),False,The Three Stages of Learning Dynamics in High-dimensional Kernel Methods,"['Nikhil Ghosh', 'Song Mei', 'Bin Yu']","[""training dynamics"", ""kernels"", ""SGD"", ""deep bootstrap"", ""gradient flow"", ""random features"", ""high-dimensional asymptotics"", ""random matrix theory""]","We study the training dynamics of gradient flows on the population risk and empirical risk of high-dimensional kernel least-squares problems, which we show has three learning stages.",,,,
EQtwFlmq7mx,2021,Reject,False,"Stochastic Proximal Point Algorithm for Large-scale Nonconvex Optimization: Convergence, Implementation, and Application to Neural Networks","[""Aysegul Bumin"", ""Kejun Huang""]",[],,,,,
ES9cpVTyLL,2021,Reject,True,"Weak and Strong Gradient Directions: Explaining Memorization, Generalization, and Hardness of Examples at Scale","[""Piotr Zielinski"", ""Shankar Krishnan"", ""Satrajit Chatterjee""]","[""generalization"", ""deep learning"", ""hardness of examples""]","We present a new algorithm that allows us to test the Coherent Gradient hypothesis for the first time at scale, and also present a fundamentally new test of Coherent Gradients based on hardness of examples.",2003.07422,cs.LG,2020-03-16 19:32:11+00:00,2020-07-21 17:33:03+00:00
ESG-DMKQKsD,2021,Accept (Poster),True,Bowtie Networks: Generative Modeling for Joint Few-Shot Recognition and Novel-View Synthesis,"[""Zhipeng Bao"", ""Yu-Xiong Wang"", ""Martial Hebert""]","[""computer vision"", ""object recognition"", ""few-shot learning"", ""generative models"", ""adversarial training""]","We propose a novel feedback-based bowtie network to learn a shared generative model for joint few-shot recognition and novel-view synthesis, consistently and significantly improving performance for both tasks, especially in the low-data regime.",2008.06981,cs.CV,2020-08-16 19:40:56+00:00,2021-04-06 19:18:51+00:00
ESVGfJM9a7,2021,Reject,False,Neural Point Process for Forecasting Spatiotemporal Events,"[""Zihao Zhou"", ""Xingyi Yang"", ""Xinyi He"", ""Ryan Rossi"", ""Handong Zhao"", ""Rose Yu""]","[""spatiotemporal point process"", ""deep sequence models"", ""time series""]","A novel Neural Spatiotemporal Point Process model for irregularly sampled spatiotemporal event forecasting, which integrates deep neural networks with spatiotemporal point processes.",,,,
ET1UAOYeU42,2022,Reject,False,Edge Partition Modulated Graph Convolutional Networks,"['Yilin He', 'Chaojie Wang', 'Hao Zhang', 'Bo Chen', 'Mingyuan Zhou']","[""Latent Variable Models"", ""Bayesian Methods"", ""Variational Inference"", ""Graph Neural Networks""]",A latent variable framework that jointly learns edge partitioning and GCNs for graph-analytic tasks.,,,,
ETBc_MIMgoX,2021,Accept (Poster),False,Learning with AMIGo: Adversarially Motivated Intrinsic Goals,"[""Andres Campero"", ""Roberta Raileanu"", ""Heinrich Kuttler"", ""Joshua B. Tenenbaum"", ""Tim Rockt\u00e4schel"", ""Edward Grefenstette""]","[""reinforcement learning"", ""exploration"", ""meta-learning""]","A ""constructively adversarial"" teacher-student setup can augment on-policy algorithms to better solve difficult exploration tasks in RL.",,,,
ETiaOyNwJW,2022,Reject,False,Revisiting Virtual Nodes in Graph Neural Networks for Link Prediction,"['EunJeong Hwang', 'Veronika Thost', 'Shib Sankar Dasgupta', 'Tengfei Ma']","[""graph neural network"", ""link prediction"", ""virtual node""]",We propose new methods for extending graph neural networks with virtual nodes for link prediction.,,,,
EUUp9nWXsop,2021,Reject,False,IALE: Imitating Active Learner Ensembles,"[""Christoffer L\u00f6ffler"", ""Christopher Mutschler""]","[""active learning"", ""imitating learning"", ""ensembles""]",IALE uses imitation learning to learn a policy for pool-based active learning (AL) that imitates a set of hard-coded experts that all together outperform state of the art AL baselines,,,,
EVV259WQuFG,2021,Reject,False,Machine Reading Comprehension with Enhanced Linguistic Verifiers,"[""Xianchao Wu""]","[""machine reading comprehension"", ""BERT"", ""linguistic verifiers"", ""hierarchical attention networks""]","Two novel linguistic verifiers for answerable questions in machine reading comprehension, one to judge the linguistic correctness of answer phrases and the other to enrich long paragraph contexts by hierarchical attentions.",,,,
EVVadRFRgL7,2022,Accept (Poster),False,"Bayesian Modeling and Uncertainty Quantification for Learning to Optimize: What, Why, and How","['Yuning You', 'Yue Cao', 'Tianlong Chen', 'Zhangyang Wang', 'Yang Shen']",[],,,,,
EVqFdCB5PfV,2022,Reject,False,Iterative Hierarchical Attention for Answering Complex Questions over Long Documents,"['Haitian Sun', 'William W. Cohen', 'Ruslan Salakhutdinov']","[""Question Answering"", ""Natural Language Processing"", ""Attention Methods""]",We propose a model iteratively attends to different parts of long and hierarchically structured documents to answer complex questions.,,,,
EXHG-A3jlM,2022,Accept (Poster),False,Efficient Token Mixing for Transformers via Adaptive Fourier Neural Operators,"['John Guibas', 'Morteza Mardani', 'Zongyi Li', 'Andrew Tao', 'Anima Anandkumar', 'Bryan Catanzaro']","[""self attention"", ""linear complexity"", ""high-resolution inputs"", ""operator learning"", ""Fourier transform""]",We propose Adaptive Fourier Neural Operators (AFNO) for scaling self-attention to high resolution images in vision transformers by establishing a link between operator learning and token mixing.,2111.13587,cs.CV,2021-11-24 05:44:31+00:00,2021-11-24 05:44:31+00:00
EXe93Md8RqS,2022,Reject,True,Data Quality Matters For Adversarial Training: An Empirical Study,"['Chengyu Dong', 'Liyuan Liu', 'Jingbo Shang']","[""Adversarial training"", ""Data quality"", ""Robust overfitting"", ""Robustness overestimation"", ""Robustness-accuracy trade-off""]",We show that data quality plays an important role in the existing problems of adversarial training.,2102.07437,cs.LG,2021-02-15 10:17:24+00:00,2021-10-07 01:00:51+00:00
EXkD6ZjvJQQ,2021,Reject,True,Provable More Data Hurt in High Dimensional Least Squares Estimator,"[""Zeng Li"", ""Chuanlong Xie"", ""QINWEN WANG""]",[],,2008.06296,stat.ML,2020-08-14 11:33:30+00:00,2020-08-14 11:33:30+00:00
EYCm0AFjaSS,2022,Reject,False,ZerO Initialization: Initializing Residual Networks with only Zeros and Ones,"['Jiawei Zhao', 'Florian Tobias Schaefer', 'Anima Anandkumar']","[""weight initialization"", ""deep residual network"", ""deterministic initialization"", ""optimization""]","We propose a fully deterministic initialization for training residual networks by employing skip connections and Hadamard transforms, resulting in state-of-art performance.",,,,
EZ8aZaCt9k,2021,Reject,True,No Spurious Local Minima: on the Optimization Landscapes of Wide and Deep Neural Networks,"[""Johannes Lederer""]",[],,2010.00885,cs.LG,2020-10-02 09:34:32+00:00,2021-01-13 10:11:53+00:00
EZNOb_uNpJk,2022,Accept (Poster),False,ClimateGAN: Raising Climate Change Awareness by Generating Images of Floods,"['Victor Schmidt', 'Alexandra Luccioni', 'MÃ©lisande Teng', 'Tianyu Zhang', 'Alexia Reynaud', 'Sunand Raghupathi', 'Gautier Cosne', 'Adrien Juraver', 'Vahe Vardanyan', 'Alex HernÃ¡ndez-GarcÃ­a', 'Yoshua Bengio']","[""GAN"", ""Climate Change"", ""Domain Adaptation"", ""Representation Learning"", ""Computer Vision"", ""Application""]","This paper presents a model to robustly produce photo-realistic images of floods for raising climate change awareness, leveraging unsupervised domain adaptation and conditional image generation.",,,,
E_U8Zvx7zrf,2021,Reject,False,Delay-Tolerant Local SGD for Efficient Distributed Training,"[""An Xu"", ""Xiao Yan"", ""Hongchang Gao"", ""Heng Huang""]","[""Delay-tolerant"", ""communication-efficient"", ""distributed learning""]",We propose a delay-tolerant AND communication-efficient training method for distributed learning.,,,,
EbIDjBynYJ8,2021,Accept (Oral),False,Towards Nonlinear Disentanglement in Natural Data with Temporal Sparse Coding,"[""David A. Klindt"", ""Lukas Schott"", ""Yash Sharma"", ""Ivan Ustyuzhaninov"", ""Wieland Brendel"", ""Matthias Bethge"", ""Dylan Paiton""]","[""disentanglement"", ""independent component analysis"", ""natural scene statistics""]",Our work addresses key issues in disentanglement research for moving towards more natural settings. ,,,,
Ec85b0tUwbA,2021,Accept (Poster),True,Hyperbolic Neural Networks++,"[""Ryohei Shimizu"", ""YUSUKE Mukuta"", ""Tatsuya Harada""]","[""Hyperbolic Geometry"", ""Poincar\u00e9 Ball Model"", ""Parameter-Reduced MLR"", ""Geodesic-Aware FC Layer"", ""Convolutional Layer"", ""Attention Mechanism""]","We present novel methods for constructing hyperbolic neural network architectures in the PoincarÃ© ball model, including a parameter-reduced MLR, geodesic-aware FC layers, convolutional layers, and attention mechanisms. ",2006.08210,cs.LG,2020-06-15 08:23:20+00:00,2021-03-17 14:36:34+00:00
EcGGFkNTxdJ,2022,Accept (Poster),False,Trust Region Policy Optimisation in Multi-Agent Reinforcement Learning,"['Jakub Grudzien Kuba', 'Ruiqing Chen', 'Muning Wen', 'Ying Wen', 'Fanglei Sun', 'Jun Wang', 'Yaodong Yang']","[""Multi-Agent Reinforcement Learning"", ""trust-region method"", ""policy gradient method""]",This paper introduces the first trust region method for multi-agent reinforcement learning that enjoys theoretically-justified monotonic improvement guarantee and demonstrates the state-of-the-art performance on Mujoco benchmarks.,,,,
Eceabn-Spyz,2022,Reject,False,Generalizable Learning to Optimize into Wide Valleys,"['Junjie Yang', 'Tianlong Chen', 'Mingkang Zhu', 'Fengxiang He', 'Dacheng Tao', 'Yingbin Liang', 'Zhangyang Wang']","[""L2O"", ""Generalization"", ""Flatness"", ""Entropy-SGD""]",This paper introduces flatness-aware regularizers into L2O which guide optimizee to converge into wide valleys in loss landscape.,,,,
EdXhmWvvQV,2021,Reject,False,Center-wise Local Image Mixture For Contrastive Representation Learning,"[""Hao Li"", ""XIAOPENG ZHANG"", ""Ruoyu Sun"", ""Hongkai Xiong"", ""Qi Tian""]","[""Self-supervised Learning"", ""Data Mixing"", ""Contrastive Learning""]",,,,,
Ee2ugKwgvyy,2022,Reject,False,Graph Information Matters: Understanding Graph Filters from Interaction Probability,"['Zhixian Chen', 'Tengfei Ma', 'Yang Wang']","[""Node classification"", ""graph filters"", ""homophily degree"", ""interaction probability"", ""frequency distribution"", ""filter bank"", ""spectral graph neural networks""]","With the introduction of interaction probability, we develop a theoretical understanding of how graph information matters graph filters and a model to learn the data-specified multi-filters for label prediction.",,,,
EeeOTYhLlVm,2021,Reject,False,EpidemiOptim: A Toolbox for the Optimization of Control Policies in Epidemiological Models,"[""C\u00e9dric Colas"", ""Boris Hejblum"", ""S\u00e9bastien Rouillon"", ""Rodolphe Thiebaut"", ""Pierre-Yves Oudeyer"", ""Cl\u00e9ment Moulin-Frier"", ""M\u00e9lanie Prague""]","[""epidemiology"", ""covid19"", ""reinforcement learning"", ""evolutionary algorithms"", ""multi-objective optimization"", ""decision-making"", ""toolbox""]","We present EpidemiOptim, a toolbox that facilitates collaborations between epidemiologists and optimization practitioners by formulating the search of epidemic control policies as standard optimization problems. ",,,,
Ef1nNHQHZ20,2021,Reject,False,Layer-wise Adversarial Defense: An ODE Perspective,"[""Zonghan Yang"", ""Yang Liu"", ""Chenglong Bao"", ""Zuoqiang Shi""]","[""adversarial training"", ""robustness"", ""ODE""]","We introduce layer-wise adversarial defense to improve adversarial training algorithms, and build up its extended relationship with current approaches from ordinary differential equation perspective.",,,,
EgkZwzEwciE,2022,Reject,False,Adversarial Collaborative Learning on Non-IID Features,"['Qinbin Li', 'Bingsheng He', 'Dawn Song']","[""Federated Learning"", ""Collaborative Learning""]",The paper proposes a new collaborative learning framework on non-IID features.,,,,
EhYjZy6e1gJ,2022,Accept (Oral),False,Contrastive Label Disambiguation for Partial Label Learning,"['Haobo Wang', 'Ruixuan Xiao', 'Sharon Li', 'Lei Feng', 'Gang Niu', 'Gang Chen', 'Junbo Zhao']","[""Partial Label Learning"", ""Contrastive Learning"", ""Prototype-based Disambiguation""]",A synergistic PLL framework that leverages contrastive learning for enhanced representation and improved label disambiguation.,,,,
Ehhk6jyas6v,2022,Reject,False,On The Quality Assurance Of Concept-Based Representations,"['Mateo Espinosa Zarlenga', 'Pietro Barbiero', 'Zohreh Shams', 'Dmitry Kazhdan', 'Umang Bhatt', 'Mateja Jamnik']","[""Concept learning"", ""Disentanglement learning"", ""Explainability"", ""Interpretability""]",This paper proposes metrics and guidelines for comparing the quality of concept representations within and between concept learning and disentanglement learning. ,,,,
EhwEUb2ynIa,2022,Reject,False,How to Adapt Your Large-Scale Vision-and-Language Model,"['Konwoo Kim', 'Michael Laskin', 'Igor Mordatch', 'Deepak Pathak']","[""transfer learning"", ""fine-tuning"", ""layernorm"", ""CLIP"", ""prompt-tuning"", ""adaptation"", ""zero-shot"", ""pretraining""]","We present a thorough analysis of different methods on how to adapt large-scale pretrained vision-and-language models to several downstream classification tasks, and find that just tuning LayerNorm is an effective fine-tuning baseline.",,,,
Ek7PSN7Y77z,2022,Accept (Spotlight),False,Multi-Stage Episodic Control for Strategic Exploration in Text Games,"['Jens Tuyls', 'Shunyu Yao', 'Sham M. Kakade', 'Karthik R Narasimhan']","[""reinforcement learning"", ""language understanding"", ""text-based games""]",We propose a multi-stage approach to playing text games that improves the score on Zork1 from around 40 to 103. ,,,,
Ek7qrYhJMbn,2021,Reject,True,Central Server Free Federated Learning over Single-sided Trust Social Networks,"[""Chaoyang He"", ""Conghui Tan"", ""Hanlin Tang"", ""Shuang Qiu"", ""Ji Liu""]",[],,1910.04956,cs.LG,2019-10-11 03:36:53+00:00,2020-08-01 17:20:53+00:00
El9kZ2caYVy,2022,Reject,False,Noise-Contrastive Variational Information Bottleneck Networks,"['Jannik Schmitt', 'Stefan Roth']","[""uncertainty estimation"", ""variational information bottleneck""]",Novel uncertainty estimation method that retains the benefits of regularization of output and intermediate variables without hurting the entropy-based separability of correct and incorrect predictions.,,,,
EnwCZixjSh,2022,Accept (Poster),False,On Evaluation Metrics for Graph Generative Models,"['Rylee Thompson', 'Boris Knyazev', 'Elahe Ghalebi', 'Jungtaek Kim', 'Graham W. Taylor']",[],,2201.09871,cs.LG,2022-01-24 18:49:27+00:00,2022-01-24 18:49:27+00:00
EoFNy62JGd,2021,Accept (Poster),True,Neural gradients are near-lognormal: improved quantized  and sparse training,"[""Brian Chmiel"", ""Liad Ben-Uri"", ""Moran Shkolnik"", ""Elad Hoffer"", ""Ron Banner"", ""Daniel Soudry""]",[],,2006.08173,cs.CV,2020-06-15 07:00:15+00:00,2020-10-12 14:18:25+00:00
EoVmlONgI9e,2021,Reject,True,The Emergence of Individuality in Multi-Agent Reinforcement Learning,"[""Jiechuan Jiang"", ""Zongqing Lu""]",[],,2006.05842,cs.LG,2020-06-10 14:11:21+00:00,2021-10-18 08:12:57+00:00
Eot1M5o2Zy,2022,Reject,False,AestheticNet: Reducing bias in facial data sets under ethical considerations,"['Michael Danner', 'Muhammad Awais Tanvir Rana', 'Thomas Weber', 'Tobias Gerlach', 'Patrik Huber', 'Matthias RÃ¤tsch', 'Josef Kittler']","[""societal considerations of machine learning"", ""fairness"", ""safety"", ""privacy"", ""responsible AI"", ""discrimination prevention"", ""facial aesthetics"", ""unconscious Bias""]",We propose a new method to generate an unbiased CNN to improve the fairness of machine learning and provide a practical example of how to build a fair and trustable AI.,,,,
Eql5b1_hTE4,2021,Accept (Poster),False,Robust early-learning: Hindering the memorization of noisy labels,"[""Xiaobo Xia"", ""Tongliang Liu"", ""Bo Han"", ""Chen Gong"", ""Nannan Wang"", ""Zongyuan Ge"", ""Yi Chang""]",[],,,,,
EqoXe2zmhrh,2021,Accept (Spotlight),False,Support-set bottlenecks for video-text representation learning,"[""Mandela Patrick"", ""Po-Yao Huang"", ""Yuki Asano"", ""Florian Metze"", ""Alexander G Hauptmann"", ""Joao F. Henriques"", ""Andrea Vedaldi""]","[""video representation learning"", ""multi-modal learning"", ""video-text learning"", ""contrastive learning""]",We use a generative objective to improve the instance discrimination limitations of contrastive learning to set new state-of-the-art results in text-to-video retrieval,,,,
ErX-xMSek2,2022,Reject,False,A Study on Representation Transfer for Few-Shot Learning,"['Chun-Nam Yu', 'Yi Xie']","[""few-shot learning"", ""transfer learning""]","We study different feature representations for transfer with few-shot learning, and also propose new feature selection schemes. ",,,,
ErrNJYcVRmS,2021,Reject,False,F^2ed-Learning: Good Fences Make Good Neighbors,"[""Lun Wang"", ""Qi Pang"", ""Shuai Wang"", ""Dawn Song""]","[""Byzantine-Robust Federated Learning"", ""Secure Aggregation""]","We propose F^2ed-Learning, the first federated learning protocol defending against both semi-honest server and Byzantine malicious clients.",,,,
ErsRrojuPzw,2022,Reject,False,Fast and Efficient Once-For-All Networks for Diverse Hardware Deployment,"['Jun Fang', 'Li Yang', 'Chengyao Shen', 'Hamzah Abdel-Aziz', 'David Thorsley', 'Joseph Hassoun']","[""neural architecture search"", ""computer vision"", ""convolutional neural networks""]","We develop new methods to accelerate once-for-all methods for neural architecture search, reducing the training time below 200 GPU-hours.",,,,
EsA9Nr9JHvy,2021,Reject,False,The Heavy-Tail Phenomenon in SGD,"[""Mert Gurbuzbalaban"", ""Umut Simsekli"", ""Lingjiong Zhu""]","[""heavy tails"", ""stochastic gradient descent"", ""deep learning""]",We obtain a number of theoretical results that can rigorously characterize the empirically observed heavy-tailed behavior of SGD and illustrate through numerical experiments that our results are relevant to deep learning practice.,,,,
EskfH0bwNVn,2022,Accept (Oral),False,Resolving Training Biases via Influence-based Data Relabeling,"['Shuming Kong', 'Yanyan Shen', 'Linpeng Huang']","[""Training bias"", ""influence functions"", ""data relabeling""]",We propose an influence-based relabeling framework for solving training bias with a theoretical guarantee,,,,
Ew0zR07CYRd,2021,Reject,False,Bounded Myopic Adversaries for Deep Reinforcement Learning Agents,"[""Ezgi Korkmaz"", ""Henrik Sandberg"", ""Gyorgy Dan""]","[""deep reinforcement learning"", ""adversarial""]",,,,,
Ew4hVmrrqJE,2022,Reject,False,Sample and Communication-Efficient Decentralized Actor-Critic Algorithms with Finite-Time Analysis,"['Ziyi Chen', 'Yi Zhou', 'Rong-Rong Chen', 'Shaofeng Zou']",[],Develop sample efficient and communication efficient decentralized actor-critic algorithms,,,,
EwqEx5ipbOu,2022,Accept (Poster),False,How Well Does Self-Supervised Pre-Training Perform with Streaming Data?,"['Dapeng Hu', 'Shipeng Yan', 'Qizhengqiu Lu', 'Lanqing HONG', 'Hailin Hu', 'Yifan Zhang', 'Zhenguo Li', 'Xinchao Wang', 'Jiashi Feng']","[""Pre-Training"", ""Representation Learning"", ""Continual Learning"", ""Self-Supervised Learning""]",,,,,
ExJ4lMbZcqa,2022,Reject,True,Learning Audio-Visual Dereverberation,"['Changan Chen', 'Wei Sun', 'David Harwath', 'Kristen Grauman']","[""speech enhancement"", ""audio-visual learning"", ""speech dereverberation"", ""room acoustics""]","We propose to dereverberate speech by leveraging the visual stream, which reveals cues about room geometry, materials, and speaker locations.",2106.07732,cs.SD,2021-06-14 20:01:24+00:00,2021-06-14 20:01:24+00:00
F-mvpFpn_0q,2021,Accept (Poster),False,Rapid Task-Solving in Novel Environments,"[""Samuel Ritter"", ""Ryan Faulkner"", ""Laurent Sartran"", ""Adam Santoro"", ""Matthew Botvinick"", ""David Raposo""]","[""deep reinforcement learning"", ""meta learning"", ""deep learning"", ""exploration"", ""planning""]","Our agents meta-learn to explore, build models on-the-fly, and plan, enabling them to rapidly solve sequences of tasks in unfamiliar environments.",,,,
F0v5uBM-q5K,2022,Reject,False,Beyond Quantization: Power aware neural networks,"['Nurit Spingarn', 'Elad Hoffer', 'Ron Banner', 'Hilla Ben Yaacov', 'Tomer Michaeli']","[""Deep neural networks"", ""weight quantization"", ""model compression"", ""power-accuracy tradeoff"", ""power consumption""]",Power-aware weight quantization which enables multiplier-free DNN and a significant reduction in power.,,,,
F1Z3QH-VjZE,2022,Reject,False,A Fair Generative Model Using Total Variation Distance,"['Soobin Um', 'Changho Suh']","[""trustworthy AI"", ""fairness"", ""generative model"", ""total variation distance""]",We propose a generative model framework that regulates imbalanced representations of demographics via total variation distance measure.,,,,
F1vEjWK-lH_,2021,Accept (Spotlight),True,Gradient Vaccine: Investigating and Improving Multi-task Optimization in Massively Multilingual Models,"[""Zirui Wang"", ""Yulia Tsvetkov"", ""Orhan Firat"", ""Yuan Cao""]","[""Multi-task Learning"", ""Multilingual Modeling""]",,2010.05874,cs.CL,2020-10-12 17:26:34+00:00,2020-10-12 17:26:34+00:00
F2r3wYar3Py,2022,Reject,False,Learning from One and Only One Shot,"['Haizi Yu', 'Igor Mineyev', 'Lav R. Varshney', 'James Evans']",[],,,,,
F2v4aqEL6ze,2021,Accept (Poster),False,CPR: Classifier-Projection Regularization for Continual Learning,"[""Sungmin Cha"", ""Hsiang Hsu"", ""Taebaek Hwang"", ""Flavio Calmon"", ""Taesup Moon""]","[""continual learning"", ""regularization"", ""wide local minima""]",We devise wide local minima promoting regularization term for continual learning.,,,,
F3s69XzWOia,2021,Accept (Oral),True,Coupled Oscillatory Recurrent Neural Network (coRNN): An accurate and (gradient) stable architecture for learning long time dependencies,"[""T. Konstantin Rusch"", ""Siddhartha Mishra""]","[""RNNs"", ""Oscillators"", ""Gradient stability"", ""Long-term dependencies""]","A biologically motivated and discretized ODE based RNN for learning long-term dependencies, with rigorous bounds mitigating the exploding and vanishing gradient problem.",2010.00951,cs.LG,2020-10-02 12:35:04+00:00,2021-03-14 19:12:57+00:00
F438zjb-XaM,2021,Reject,False,Crowd-sourced Phrase-Based Tokenization for Low-Resourced Neural Machine Translation: The case of Fon Language,"[""Bonaventure F. P. Dossou"", ""Chris Chinenye Emezue""]","[""nmt"", ""nlp"", ""neural machine translation"", ""natural language processing"", ""deep learning"", ""machine learning"", ""machine translation"", ""mt""]",Neural Machine Translation for Low-resourced African Languages,,,,
F5Em8ASCosV,2022,Accept (Poster),False,Causal Contextual Bandits with Targeted Interventions,"['Chandrasekar Subramanian', 'Balaraman Ravindran']","[""causality"", ""contextual bandits"", ""causal inference"", ""bandits""]","A new, more realistic, formalism of contextual bandits involving causal side-information and targeted interventions, along with a novel algorithm that exploits features of the new setting such as information leakage to learn good policies quickly.",,,,
F72ximsx7C1,2022,Accept (Poster),True,How Attentive are Graph Attention Networks? ,"['Shaked Brody', 'Uri Alon', 'Eran Yahav']","[""graph attention networks"", ""dynamic attention"", ""GAT"", ""GNN""]",We identify that Graph Attention Networks (GAT) compute a very weak form of attention. We show its empirical implications and propose a fix.,2105.14491,cs.LG,2021-05-30 10:17:58+00:00,2022-01-31 07:20:20+00:00
F7_odJIeQ26,2022,Reject,True,Pretrained Language Models are Symbolic Mathematics Solvers too!,"['Kimia Noorbakhsh', 'Modar Sulaiman', 'Mahdi Sharifi', 'KALLOL ROY', 'Pooyan Jamshidi']",[],,2110.03501,stat.ML,2021-10-07 14:37:06+00:00,2021-11-26 06:50:40+00:00
F8lXvXpZdrL,2021,Reject,True,Reintroducing Straight-Through Estimators as Principled Methods for Stochastic Binary Networks,"[""Alexander Shekhovtsov"", ""Viktor Yanush""]","[""straight-through"", ""binary"", ""stochastic binary"", ""mirror descent""]","Straight-through estimators, wide-spread in the empirical form, are given a proper theoretical treatment for the first time.",2006.06880,stat.ML,2020-06-11 23:58:18+00:00,2021-10-19 14:45:41+00:00
F8whUO8HNbP,2021,Accept (Poster),False,Contrastive Syn-to-Real Generalization,"[""Wuyang Chen"", ""Zhiding Yu"", ""Shalini De Mello"", ""Sifei Liu"", ""Jose M. Alvarez"", ""Zhangyang Wang"", ""Anima Anandkumar""]","[""synthetic-to-real generalization"", ""domain generalization""]",We propose a new contrastive synthetic-to-real generalization framework that achieves state-of-the-art performance on synthetic-to-real generalization problems.,,,,
F8xpAPm_ZKS,2021,Reject,False,Model-Free Counterfactual Credit Assignment,"[""Thomas Mesnard"", ""Theophane Weber"", ""Fabio Viola"", ""Shantanu Thakoor"", ""Alaa Saade"", ""Anna Harutyunyan"", ""Will Dabney"", ""Tom Stepleton"", ""Nicolas Heess"", ""Marcus Hutter"", ""Lars Holger Buesing"", ""Remi Munos""]","[""credit assignment"", ""model-free RL"", ""causality"", ""hindsight""]","Under an appropriate action-independence constraint, future-conditional baselines are valid to use in policy gradients and lead to drastically reduced variance and faster learning in certain environments with difficult credit assignment.",,,,
F9McnN1dITx,2022,Reject,False,Evolving Neural Update Rules for Sequence Learning,"['Karol Gregor', 'Peter Conway Humphreys']","[""Neural Update Rules"", ""Evolution""]",We evolve update rules of weights and activations for online recurrent network on tasks of language modelling and memorization.,,,,
F9sPTWSKznC,2021,Reject,True,DiP Benchmark Tests: Evaluation Benchmarks for Discourse Phenomena in MT,"[""Prathyusha Jwalapuram"", ""Barbara Rychalska"", ""Shafiq Joty"", ""Dominika Basaj""]","[""machine translation"", ""discourse"", ""evaluation"", ""benchmark"", ""testsets"", ""leaderboard""]","We introduce first-of-their-kind discourse benchmark testsets and evaluation procedures aimed at tracking improvement in machine translation quality for phenomena like anaphora, coherence & readability, lexical consistency and discourse connectives.",2004.14607,cs.CL,2020-04-30 07:15:36+00:00,2020-04-30 07:15:36+00:00
FASW5Ed837,2022,Reject,True,Bandwidth-based Step-Sizes for Non-Convex  Stochastic Optimization,"['Xiaoyu Wang', 'Mikael Johansson']","[""Stochastic gradient descent"", ""bandwidth-based step size"", ""non-asymptotic analysis""]","We derive convergence guarantees for bandwidth-based step-sizes, a general class of learning-rates that are allowed to vary in a banded region.",2106.02888,cs.LG,2021-06-05 13:12:15+00:00,2021-10-11 19:51:55+00:00
FCxWzalZp9N,2022,Reject,False,AF$_2$: Adaptive Focus Framework for Aerial Imagery Segmentation,"['Lin Huang', 'Qiyuan Dong', 'Jia Zhang', 'Lijun Wu', 'Jiang Bian', 'Tie-Yan Liu']",[],"In this paper, we propose Adaptive Focus Framework (AF$_2$), which adopts a hierarchical segmentation procedure and focuses on adaptively utilizing multi-scale representations generated by widely adopted neural network architectures. ",,,,
FD8xldQIgdq,2022,Reject,True,Robust Models Are More Interpretable Because Attributions Look Normal,"['Zifan Wang', 'Matt Fredrikson', 'Anupam Datta']","[""Explainability"", ""Decision Boundary"", ""Attribution"", ""Adversarial Robustness""]",Boundary Attributions as a means of providing geometrical-based explanation for deep classifiers,2103.11257,cs.LG,2021-03-20 22:36:39+00:00,2021-10-06 02:21:53+00:00
FEBFJ98FKx,2022,Accept (Poster),False,TPU-GAN: Learning temporal coherence from dynamic point cloud sequences,"['Zijie Li', 'Tianqin Li', 'Amir Barati Farimani']","[""Point cloud super resolution"", ""Temporal learning"", ""Generative Adversarial Networks""]",We propose a GAN framework for super-resolution task on dynamic point cloud sequences.,,,,
FEDfGWVZYIn,2022,Accept (Spotlight),False,RelaxLoss: Defending Membership Inference Attacks without Losing Utility,"['Dingfan Chen', 'Ning Yu', 'Mario Fritz']","[""membership inference attack"", ""defense""]",We propose a novel training scheme that is highly effective in protecting against membership inference attacks while preserving the utility of target models. ,,,,
FFGDKzLasUa,2022,Reject,False,Stochastic Deep Networks with Linear Competing Units for Model-Agnostic Meta-Learning,"['Konstantinos Î. Kalais', 'Sotirios Chatzis']","[""Stochastic Deep Networks"", ""LWTA"", ""Meta-Learning""]",This work addresses meta-learning (ML) by considering deep networks with stochastic local winner-takes-all (LWTA) activations.,,,,
FFM_oJeqZx,2022,Reject,False,Adaptive Pseudo-labeling for Quantum Calculations,"['Kexin Huang', 'Vishnu Sresht', 'Brajesh Rai', 'Mykola Bordyuh']",[],,,,,
FGqiDsBUKL0,2021,Accept (Oral),True,Do 2D GANs Know 3D Shape? Unsupervised 3D Shape Reconstruction from 2D Image GANs,"[""Xingang Pan"", ""Bo Dai"", ""Ziwei Liu"", ""Chen Change Loy"", ""Ping Luo""]","[""Generative Adversarial Network"", ""3D Reconstruction""]",Unsupervised 3D Shape Reconstruction from 2D Image GANs,2011.00844,cs.CV,2020-11-02 09:38:43+00:00,2021-03-12 04:04:05+00:00
FH_mZOKFX-b,2022,Reject,False,Takeuchi's Information Criteria as Generalization Measures for DNNs Close to NTK Regime,"['Hiroki Naganuma', 'Taiji Suzuki', 'Rio Yokota', 'Masahiro Nomura', 'Kohta Ishikawa', 'Ikuro Sato']","[""Generalization"", ""correlation"", ""experiments""]",This paper mainly reports empirical evidences that TIC can well explains generalization gaps of DNN under certain conditions from a very wide range of learning experiments.,,,,
FKotzp6PZJw,2021,Reject,False,On the Estimation Bias in Double Q-Learning,"[""Zhizhou Ren"", ""Guangxiang Zhu"", ""Beining Han"", ""Jianglun Chen"", ""Chongjie Zhang""]","[""Reinforcement learning"", ""Q-learning"", ""Estimation bias""]","We prove that double Q-learning may have multiple non-optimal fixed points, and propose a simple approach to address this issue.",,,,
FKp8-pIRo3y,2022,Accept (Poster),False,Wish you were here: Hindsight Goal Selection for long-horizon dexterous manipulation,"['Todor Davchev', 'Oleg Olegovich Sushkov', 'Jean-Baptiste Regli', 'Stefan Schaal', 'Yusuf Aytar', 'Markus Wulfmeier', 'Jon Scholz']","[""goal-conditioned reinforcement learning"", ""learning from demonstrations"", ""long-horizon dexterous manipulation"", ""bi-manual manipulation""]",,,,,
FLA55mBee6Q,2022,Accept (Spotlight),False,COptiDICE: Offline Constrained Reinforcement Learning via Stationary Distribution Correction Estimation,"['Jongmin Lee', 'Cosmin Paduraru', 'Daniel J Mankowitz', 'Nicolas Heess', 'Doina Precup', 'Kee-Eung Kim', 'Arthur Guez']","[""Offline Reinforcement Learning"", ""Offline Constrained Reinforcement Learning"", ""Stationary Distribution Correction Estimation""]","We present an offline constrained RL algorithm, which estimates the stationary distribution corrections of the optimal policy with respect to returns, while constraining the cost upper bound.",,,,
FLa1RPjpm2L,2022,Reject,False,ED2: An Environment Dynamics Decomposition Framework for World Model Construction,"['Cong Wang', 'Tianpei Yang', 'Jianye HAO', 'YAN ZHENG', 'Hongyao Tang', 'Fazl Barez', 'Jinyi Liu', 'Jiajie Peng', 'haiyin piao', 'Zhixiao Sun']","[""model based reinforcement learning""]",We proposed a new world model construction framework in decomposing manner,2112.02817,cs.LG,2021-12-06 07:11:19+00:00,2021-12-06 07:11:19+00:00
FN7_BUOG78e,2021,Reject,False,Computing Preimages of Deep Neural Networks with Applications to Safety,"[""Kyle Matoba"", ""Fran\u00e7ois Fleuret""]","[""Deep neural networks"", ""verification"", ""interpretation"", ""AI safety"", ""ACAS""]",We show how to progressively invert the layers of deep neural networks to give a much simpler characterization that can be used to answer questions that cannot be addressed otherwise.,,,,
FNSR8Okx8a,2022,Reject,False,Beyond Prioritized Replay: Sampling States in Model-Based Reinforcement Learning via Simulated Priorities,"['Yangchen Pan', 'Jincheng Mei', 'Amir-massoud Farahmand', 'Martha White', 'Hengshuai Yao', 'Mohsen Rohani', 'Jun Luo']","[""experience replay"", ""model-based reinforcement learning"", ""sampling distribution"", ""search-control"", ""Dyna"", ""stochastic gradient Langevin dynamics""]",Understanding prioritized sampling method and mitigating its limitations in a MBRL setting. ,,,,
FOR2VqgJXb,2021,Reject,False,Evaluating representations by the complexity of learning low-loss predictors,"[""William F Whitney"", ""Min Jae Song"", ""David Brandfonbrener"", ""Jaan Altosaar"", ""Kyunghyun Cho""]","[""representation learning"", ""representation evaluation"", ""unsupervised learning"", ""self-supervised learning""]",Good representations allow simpler predictors to achieve low loss.,,,,
FOfKpDnp2P,2022,Reject,False,BIGRoC: Boosting Image Generation via a Robust Classifier,"['Roy Ganz', 'Michael Elad']","[""Image Generation"", ""Adversarial Robustness"", ""Perceptually Aligned Gradients""]",A model-agnostic post-processing that relies on a robust classifier is shown to boost the quality of synthesized images.,,,,
FOyuZ26emy,2021,Accept (Poster),False,A Critique of Self-Expressive Deep Subspace Clustering,"[""Benjamin David Haeffele"", ""Chong You"", ""Rene Vidal""]","[""Subspace clustering"", ""Manifold clustering"", ""Theory of deep learning"", ""Autoencoders""]",Here we show theoretically and experimentally that there are a number of flaws with many existing self-expressive deep subspace clustering models.,,,,
FP9kKyNWwwE,2021,Reject,False,Zero-shot Transfer Learning for Gray-box Hyper-parameter Optimization,"[""Hadi Samer Jomaa"", ""Lars Schmidt-Thieme"", ""Josif Grabocka""]","[""Hyper-parameter Optimization"", ""Transfer Learning"", ""Meta-learning""]",,,,,
FPCMqjI0jXN,2022,Accept (Oral),False,Domino: Discovering Systematic Errors with Cross-Modal Embeddings,"['Sabri Eyuboglu', 'Maya Varma', 'Khaled Kamal Saab', 'Jean-Benoit Delbrouck', 'Christopher Lee-Messer', 'Jared Dunnmon', 'James Zou', 'Christopher Re']","[""robustness"", ""subgroup analysis"", ""error analysis"", ""multimodal"", ""slice discovery""]",,,,,
FPpZrRfz6Ss,2021,Reject,False,To Learn Effective Features: Understanding the Task-Specific Adaptation of MAML,"[""Zhijie Lin"", ""Zhou Zhao"", ""Zhu Zhang"", ""Huai Baoxing"", ""Jing Yuan""]","[""Meta-Learning"", ""Few-Shot Learning"", ""Meta-initialization"", ""Task-specific Adaptation""]",We further study the impact of task-specific adaptation and devise an effective training paradigm with better results but less computation costs.,,,,
FQOC5u-1egI,2022,Accept (Poster),False,Towards Distribution Shift of Node-Level Prediction on Graphs: An Invariance Perspective,"['Qitian Wu', 'Hengrui Zhang', 'Junchi Yan', 'David Wipf']","[""Representation Learning on Graphs"", ""Out-of-Distribution Generalization"", ""Domain Shift"", ""Graph Structure Learning"", ""Invariant Models""]",We formulate out-of-distribution generalization problem for node-level prediction on graphs and propose a new learning approach based on invariant models,,,,
FRxhHdnxt1,2022,Accept (Spotlight),True,Amortized Tree Generation for Bottom-up Synthesis Planning and Synthesizable Molecular Design,"['Wenhao Gao', 'RocÃ­o Mercado', 'Connor W. Coley']","[""molecular design"", ""synthesis planning"", ""tree generation"", ""graph generation""]",We propose a model that address synthesis planning and synthesizable molecular design simultaneously.,2110.06389,cs.LG,2021-10-12 22:43:25+00:00,2021-10-12 22:43:25+00:00
FS0XKbpkdOu,2022,Reject,False,Sphere2Vec: Self-Supervised Location Representation Learning on Spherical Surfaces,"['Gengchen Mai', 'Yao Xuan', 'Wenyun Zuo', 'Yutong He', 'Stefano Ermon', 'Jiaming Song', 'Krzysztof Janowicz', 'Ni Lao']","[""Self-Supervised Learning"", ""Location Representation Learning"", ""Double Fourier Sphere""]",We present Sphere2Vec a self-supervised location representation model on the spherical surface.,,,,
FTit3PiAw4,2021,Reject,False,Training Federated GANs  with Theoretical Guarantees: A Universal Aggregation Approach,"[""Yikai Zhang"", ""Hui Qu"", ""Huidong Liu"", ""Qi Chang"", ""Dimitris N. Metaxas"", ""Chao Chen""]","[""Federated Learning"", ""GAN"", ""Deep Learning""]",We design and analyze a novel framework for training GAN in a federated learning fashion,,,,
FUdBF49WRV1,2021,Reject,False,Directional graph networks,"[""Dominique Beaini"", ""Saro Passaro"", ""Vincent Letourneau"", ""William L. Hamilton"", ""Gabriele Corso"", ""Pietro Li\u00f2""]","[""graph"", ""neural networks"", ""deep learning"", ""spectral theory"", ""directional aggregation"", ""over-smoothing""]",Creating anisotropic graph kernels guided by the gradient of low-frequency eigenvectors to improve graph networks expressiveness.,,,,
FUtMxDTJ_h,2021,Reject,False,Symmetry Control Neural Networks,"[""Marc Syvaeri"", ""Sven Krippendorf""]","[""Inductive (symmetry) Bias"", ""Predictive Models"", ""Hamiltonian Dynamics"", ""Physics""]",We present a framework for neural networks to learn (unknown) symmetries and to use these symmetries for improved performance on predicting the time evolution of the system.,2104.14444,cs.LG,2021-04-29 16:04:13+00:00,2021-04-29 16:04:13+00:00
FWiwSGJ_Bpa,2022,Reject,False,Non-Parametric Neuro-Adaptive Control Subject to Task Specifications,"['Christos Verginis', 'Zhe Xu', 'ufuk topcu']","[""Neural-network-control"", ""nonlinear systems"", ""continuous control"", ""adaptive control"", ""task specification"", ""signal temporal logic""]",We combine off-line neural-network-based controllers with online continuous control policies to guarantee task satisfaction by systems with unknown dynamics.,,,,
FX0vR39SJ5q,2021,Accept (Poster),True,Isometric Transformation Invariant and Equivariant Graph Convolutional Networks,"[""Masanobu Horie"", ""Naoki Morita"", ""Toshiaki Hishinuma"", ""Yu Ihara"", ""Naoto Mitsume""]","[""Machine Learning"", ""Graph Neural Network"", ""Invariance"", ""Equivariance"", ""Simulation"", ""Mesh""]","We developed isometric transformation invariant and equivariant graph convolutional networks, which shows high prediction performance and computational efficiency.",2005.06316,cs.LG,2020-05-13 13:44:44+00:00,2021-03-10 12:41:51+00:00
FYUzzBPh_j,2022,Reject,False,Communicating via Markov Decision Processes,"['Samuel Sokota', 'Christian Schroeder de Witt', 'Maximilian Igl', 'Luisa M Zintgraf', 'Philip Torr', 'J Zico Kolter', 'Shimon Whiteson', 'Jakob Nicolaus Foerster']","[""coding"", ""communication"", ""maximum entropy reinforcement learning"", ""minimum entropy coupling""]",Proposes and investigates a problem setting in which the goal is to communicate exogenous information via MDP trajectories.,,,,
FZ1oTwcXchK,2021,Accept (Poster),False,Optimal Conversion of Conventional Artificial Neural Networks to Spiking Neural Networks,"[""Shikuang Deng"", ""Shi Gu""]","[""spiking neural network"", ""weight balance"", ""second-order approximation""]",We propose and validate an optimal pipeline that efficiently converts conventional artificial neural networks to spiking neural networks with almost no accuracy loss in a fairly short simulation length. ,2103.00476,cs.NE,2021-02-28 12:04:22+00:00,2021-02-28 12:04:22+00:00
FZoZ7a31GCW,2022,Accept (Poster),False,Ancestral protein sequence reconstruction using a tree-structured Ornstein-Uhlenbeck variational autoencoder,"['Lys Sanz Moreta', 'Ola RÃ¸nning', 'Ahmad Salim Al-Sibahi', 'Jotun Hein', 'Douglas Theobald', 'Thomas Hamelryck']","[""biological sequences"", ""variational autoencoders"", ""latent representations"", ""ornstein-uhlenbeck process"", ""evolution""]",Ancestral protein sequence reconstruction using a tree-structured Ornstein-Uhlenbeck variational autoencoder,,,,
FZyZiRYbdK8,2022,Reject,False,Distributionally Robust Learning for Uncertainty Calibration under Domain Shift,"['Haoxuan Wang', 'Anqi Liu', 'Zhiding Yu', 'Junchi Yan', 'Yisong Yue', 'Anima Anandkumar']","[""Domain shift"", ""uncertainty estimation"", ""calibration"", ""distributional robustness"", ""unsupervised domain adaptation"", ""semi-supervised learning""]",We propose a distributionally robust method for uncertainty estimation under domain shift. ,,,,
F_txysyDFbw,2021,Reject,False,Online Limited Memory Neural-Linear Bandits,"[""Tom Zahavy"", ""Ofir Nabati"", ""Leor Cohen"", ""Shie Mannor""]",[],,,,,
Fblk4_Fd7ao,2021,Reject,False,Exploring Zero-Shot Emergent Communication in Embodied Multi-Agent Populations,"[""Kalesha Bullard"", ""Franziska Meier"", ""Douwe Kiela"", ""Joelle Pineau"", ""Jakob Nicolaus Foerster""]","[""emergent communication"", ""multi-agent communication"", ""multi-agent reinforcement learning""]","Initial investigation into the emergence of physical communication protocols for embodied agents (e.g. robots), with analysis on generalization to novel partners.",,,,
FcfH5Pskt2G,2021,Reject,False,Clearing the Path for Truly Semantic Representation Learning,"[""Dominik Zietlow"", ""Michal Rolinek"", ""Georg Martius""]","[""Representation Learning"", ""Disentanglement"", ""Unsupervised Learning"", ""Semantic Representations"", ""VAE"", ""Causal Representations"", ""PCA""]",,,,,
Fh_NyEuejsZ,2022,Reject,False,ZenDet: Revisiting Efficient Object Detection Backbones from Zero-Shot Neural Architecture Search,"['Zhenhong Sun', 'Ming Lin', 'Zhiyu Tan', 'Xiuyu Sun', 'Rong Jin']","[""Object Detection"", ""Detection Backbone"", ""Neural Architecture Search"", ""Zero-Shot NAS""]",This work proposes a novel zero-shot NAS method ZenDet for object detection which designs SOTA detection backbones without parameter training.,,,,
Fia60I79-4B,2022,Reject,False,TS-BERT: A fusion model for Pre-trainning Time Series-Text Representations,"['Jiahao Qin', 'Lu Zong']","[""Time Series-Text Representations"", ""Pre-training"", ""Mutilmodal""]","We apply multimodal learning to financial crisis prediction, creatively treating text and time-series data as different modes of financial crisis.",,,,
Fj1Tpym9KxH,2022,Reject,False,A Closer Look at Smoothness in Domain Adversarial Training,"['Harsh Rangwani', 'Sumukh K Aithal', 'Arihant Jain', 'Venkatesh Babu Radhakrishnan']","[""Domain Adaptation"", ""Optimization""]","In Domain Adversarial Training converging to a smooth minima helps only for ERM terms, smoothing adversarial terms leads to worse performance.",,,,
Fl3Mg_MZR-,2022,Accept (Spotlight),False,On Lottery Tickets and Minimal Task Representations in Deep Reinforcement Learning,"['Marc Vischer', 'Robert Tjarko Lange', 'Henning Sprekeler']","[""Reinforcement Learning"", ""Sparsity"", ""Pruning"", ""Lottery Ticket Hypothesis""]",We investigate the mechanisms underlying the lottery ticket effect in Deep RL and show that the derived mask extracts minimal task representations.,,,,
FlhlcARywRz,2021,Reject,False,Learning a unified label space,"[""Xingyi Zhou"", ""Vladlen Koltun"", ""Philipp Kraehenbuehl""]","[""object detection"", ""image recognition"", ""computer vision""]",We learn to unify the taxonomy of different detection datasets and train a strong detector on all of them.,,,,
FlwzVjfMryn,2022,Accept (Poster),True,Multi-objective Optimization by Learning Space Partition,"['Yiyang Zhao', 'Linnan Wang', 'Kevin Yang', 'Tianjun Zhang', 'Tian Guo', 'Yuandong Tian']","[""Optimization"", ""Machine Learning""]",Multi-objective Optimization by Learning Space Partition,2110.03173,cs.LG,2021-10-07 03:56:19+00:00,2021-10-10 17:10:32+00:00
FmBegXJToY,2022,Accept (Poster),False,Procedural generalization by planning with self-supervised world models,"['Ankesh Anand', 'Jacob C Walker', 'Yazhe Li', 'Eszter VÃ©rtes', 'Julian Schrittwieser', 'Sherjil Ozair', 'Theophane Weber', 'Jessica B Hamrick']","[""Self-Supervised Learning"", ""Model-Based RL"", ""Generalization in RL""]"," We study generalization in model-based agents and find that they excel at procedural generalization, with planning, self-supervision and data-diversity combining to yield SoTA results on Procgen; however, task generalization is more challenging.",,,,
FmMKSO4e8JK,2021,Accept (Poster),False,Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation,"[""Justin Fu"", ""Sergey Levine""]","[""model-based optimization"", ""normalized maximum likelihood""]","Offline, data-driven optimization using normalized maximum likelihood to produce robust function estimates.",2102.07970,cs.LG,2021-02-16 06:04:27+00:00,2021-02-16 06:04:27+00:00
Fmg_fQYUejf,2021,Accept (Poster),True,Linear Mode Connectivity in Multitask and Continual Learning,"[""Seyed Iman Mirzadeh"", ""Mehrdad Farajtabar"", ""Dilan Gorur"", ""Razvan Pascanu"", ""Hassan Ghasemzadeh""]","[""continual learning"", ""catastrophic forgetting"", ""mode connectivity"", ""multitask learning""]",We show that continual and multitask minima are connected by linear low-error paths and design an effective continual learning algorithm that exploits this property.,2010.04495,cs.LG,2020-10-09 10:53:25+00:00,2020-10-09 10:53:25+00:00
Fn5wiAq2SR,2021,Reject,False,Adversarial Training using Contrastive Divergence,"[""Hongjun Wang"", ""Guanbin Li"", ""Liang Lin""]","[""Adversarial Training"", ""Contrastive Divergence""]",We design a new generative method for adversarial training by using Contrastive Divergence to reaches a balance of performance and efficiency.,,,,
Fn7i_r5rR0q,2022,Accept (Poster),False,Do deep networks transfer invariances across classes?,"['Allan Zhou', 'Fahim Tajwar', 'Alexander Robey', 'Tom Knowles', 'George J. Pappas', 'Hamed Hassani', 'Chelsea Finn']","[""invariance"", ""augmentation"", ""nuisance transformation"", ""imbalance"", ""long tail""]","Study how well classifiers learn invariances in the imbalanced setting, and methods for improvement.",,,,
FndDxSz3LxQ,2022,Accept (Poster),False,"Learn Locally, Correct Globally: A Distributed Algorithm for Training Graph Neural Networks","['Morteza Ramezani', 'Weilin Cong', 'Mehrdad Mahdavi', 'Mahmut Kandemir', 'Anand Sivasubramaniam']","[""Graph Neural Networks"", ""GNN"", ""GCN"", ""Distributed Training""]",We propose LLCG a communication efficient distributed algorithm for training GNNs.,,,,
Fo6S5-3Dx_,2021,Reject,False,Deep Evolutionary Learning for Molecular Design,"[""Yifeng Li"", ""Hsu Kiang Ooi"", ""Alain Tchagang""]","[""Deep Evolutionary Learning"", ""Fragment-Based Drug Design"", ""Deep Generative Model"", ""Drug Design"", ""Multi-objective Optimization""]",Population of new molecules designed by our novel deep evolutionary learning process exhibit improved values of properties in comparison with original training molecules.,2102.01011,cs.NE,2020-12-28 03:15:46+00:00,2020-12-28 03:15:46+00:00
FoM-RnF6SNe,2021,Reject,False,Evaluating Agents Without Rewards,"[""Brendon Matusch"", ""Jimmy Ba"", ""Danijar Hafner""]","[""reinforcement learning"", ""task-agnostic"", ""agent evaluation"", ""exploration"", ""information gain"", ""empowerment"", ""curiosity""]",,2012.11538,cs.LG,2020-12-21 18:00:39+00:00,2021-02-09 22:06:26+00:00
FpKgG31Z_i9,2022,Reject,False,Learning Rate Grafting: Transferability of Optimizer Tuning,"['Naman Agarwal', 'Rohan Anil', 'Elad Hazan', 'Tomer Koren', 'Cyril Zhang']","[""Optimization"", ""Learning Rate Schedules"", ""BERT""]","We show implicit learning rate schedules can be transferred between optimization algorithms closing gaps in performance, overall leading to training of a BERT model to SOTA by SGD with no adaptivity. ",,,,
FpnQMmnsE8Y,2022,Reject,False,Recurrent Parameter Generators,"['Jiayun Wang', 'Yubei Chen', 'Stella Yu', 'Brian Cheung', 'Yann LeCun']","[""recurrent"", ""parameters"", ""degrees of freedom""]",A generic method for generate a network with any degrees of freedom via a recurrent parameter generator ,,,,
FqKolXKrQGA,2022,Reject,False,Learning to Infer the Structure of Network Games,"['Emanuele Rossi', 'Federico Monti', 'Yan Leng', 'Michael M. Bronstein', 'Xiaowen Dong']","[""graphs"", ""networks"", ""game theory"", ""graph neural networks""]",We propose a novel transformer-like architecture which is able to infer the underlying structure of a network game by only observing the equilibrium actions and without explicit knowledge of the utility function.,,,,
FqMXxvHquTA,2022,Reject,False,SegTime: Precise Time Series Segmentation without Sliding Window,"['Li Zeng', 'Baifan Zhou', 'Mohammad Al-Rifai', 'Evgeny Kharlamov']","[""time series"", ""time series segmentation"", ""lstm"", ""rnn"", ""architecture"", ""cnn"", ""pyramid pooling"", ""multi-scale pooling"", ""sequence"", ""encoder"", ""decoder"", ""resnet"", ""step-wise""]","We propose a novel neural networks approach, SegTime, tha segments time series for both fast and slow changing labels and avoid sliding windows.",,,,
FqRHeQTDU5N,2022,Reject,False,Learning to Give Checkable Answers with Prover-Verifier Games,"['Cem Anil', 'Guodong Zhang', 'Yuhuai Wu', 'Roger Baker Grosse']","[""AI Safety"", ""verifiable learning"", ""robustness"", ""adversarial learning"", ""proof systems""]","We propose Prover Verifier Networks, a game-theoretic framework inspired by interactive proof systems to encourage neural networks to solve decision problems in a verifiable manner.",,,,
FsLTUzZlsgT,2021,Reject,False,Learning Curves for Analysis of Deep Networks,"[""Derek Hoiem"", ""Tanmay Gupta"", ""Zhizhong Li"", ""Michal M Shlapentokh-Rothman""]","[""learning curve"", ""deep network"", ""analysis"", ""asymptotic error"", ""learning efficiency"", ""power law""]",We revisit learning curves as a tool for analyzing the impact of deep network design on performance.,,,,
FuLL40HLCRn,2022,Reject,False,ST-DDPM: Explore Class Clustering for Conditional Diffusion Probabilistic Models,"['Zhijie Lin', 'Zijian Zhang', 'Zhou Zhao']","[""conditional generation"", ""diffusion models"", ""decoupling"", ""interpretability""]","we devise a novel conditional diffusion probabilistic model by explicitly modeling the class center, and make an elegant modification to the original formulation, which enables controllable generation and gets interpretability.",,,,
FvfV64rovnY,2022,Reject,False,Explaining Scaling Laws of Neural Network Generalization,"['Yasaman Bahri', 'Ethan Dyer', 'Jared Kaplan', 'Jaehoon Lee', 'Utkarsh Sharma']","[""scaling laws"", ""neural networks"", ""generalization"", ""overparameterized models"", ""underparameterized models""]","We propose, derive, and investigate a categorization of scaling laws for generalization in neural networks.",,,,
FxBdFwFjXX,2022,Reject,False,Multi-Task Distribution Learning,['Connor Shorten'],"[""Data Augmentation"", ""Distribution Shift"", ""Multi-Task Learning""]","Multi-Task Learning of different Data Distributions, simulated with Data Augmentation.",,,,
FyucNzzMba-,2021,Reject,False,Forward Prediction for Physical Reasoning,"[""Rohit Girdhar"", ""Laura Gustafson"", ""Aaron B. Adcock"", ""Laurens van der Maaten""]","[""Forward prediction"", ""physical reasoning""]","We experiment with forward prediction models through the lens of a challenging new physical reasoning benchmark, PHYRE. We establish a new state of the art, and report rigorous analysis on where these models work and where future work is needed.",,,,
Fza94Y8VS4a,2022,Accept (Poster),False,The Evolution of Uncertainty of Learning in Games,"['Yun Kuen Cheung', 'Georgios Piliouras', 'Yixin Tao']","[""learning in games"", ""differential entropy""]","We show that the differential entropy of certain learning-in-game systems increases linearly with time, formalizing their increased unpredictability over time.",,,,
G-7GlfTneYg,2022,Reject,True,VoiceFixer: Toward General Speech Restoration with Neural Vocoder,"['Haohe Liu', 'Qiuqiang Kong', 'Qiao Tian', 'Yan Zhao', 'DeLiang Wang', 'Chuanzeng Huang', 'Yuxuan Wang']","[""Speech Restoration"", ""Neural Vocoder"", ""Speech Denoising"", ""Speech Declipping"", ""Speech Dereverberation"", ""Speech Super-resolution""]","VoiceFixer is the first model to achieve general speech restoration by jointly performing speech denoising, dereverberation, declipping, and super-resolution. ",2109.13731,cs.SD,2021-09-28 13:51:16+00:00,2021-10-05 15:52:27+00:00
G0CuTynjgQa,2022,Reject,False,Generalization of GANs and overparameterized models under Lipschitz continuity,"['Khoat Than', 'Nghia Vu']",[],,,,,
G0VouKj9HUG,2021,Reject,False,On Learning Read-once DNFs With Neural Networks,"[""Ido Bronstein"", ""Alon Brutzkus"", ""Amir Globerson""]","[""neural network"", ""DNF"", ""read-once"", ""inductive bias"", ""reconstruction"", ""alignment""]",,,,,
G1J5OYjoiWb,2022,Reject,False,An Attempt to Model Human Trust with Reinforcement Learning,"['Vincent Frey', 'Simon BÃ©cot']","[""Trust"", ""Confidence"", ""Q-learning"", ""Reward Circuit""]","By extending standard Q-learning to recent findings on reward circuits, we were able to develop an algorithm to mimic human trust.",,,,
G33_uTwQiL,2022,Reject,True,Equivariant Vector Field Network for Many-body System Modeling,"['weitao Du', 'He Zhang', 'Yuanqi Du', 'Qi Meng', 'Wei Chen', 'Bin Shao', 'Tie-Yan Liu']","[""equivariant neural network"", ""gradient fields"", ""many-body system"", ""molecular conformation generation""]",,2110.14811,cs.CE,2021-10-26 14:26:25+00:00,2021-10-26 14:26:25+00:00
G67PtYbCImX,2021,Reject,False,Similarity Search for Efficient Active Learning and Search of Rare Concepts,"[""Cody Coleman"", ""Edward Chou"", ""Sean Culatana"", ""Peter Bailis"", ""Alexander C. Berg"", ""Roshan Sumbaly"", ""Matei Zaharia"", ""I. Zeki Yalniz""]","[""active learning"", ""active search""]",We introduce Similarity search for Efficient Active Learning and Search (SEALS) to restrict the candidates considered in each selection round and vastly reduce the computational complexity of active learning and search methods.,,,,
G70Z8ds32C9,2021,Reject,True,Deep Networks from the Principle of Rate Reduction,"[""Kwan Ho Ryan Chan"", ""Yaodong Yu"", ""Chong You"", ""Haozhi Qi"", ""John Wright"", ""Yi Ma""]",[],"This paper provides an interpretation for deep neural networks by explicit construction from the first principles, namely from the principles of maximal rate reduction and translation invariance.",2010.14765,cs.LG,2020-10-27 06:01:43+00:00,2020-10-27 06:01:43+00:00
G7PfyLimZBp,2022,Reject,True,Understanding the Generalization of Adam in Learning Neural Networks with Proper Regularization,"['Difan Zou', 'Yuan Cao', 'Yuanzhi Li', 'Quanquan Gu']",[],This paper theoretically explains the generalization gap between Adam and SGD (with proper regularization) in learning neural networks for image-like dataset.,2108.11371,cs.LG,2021-08-25 17:58:21+00:00,2021-08-25 17:58:21+00:00
G89-1yZLFHk,2022,Accept (Poster),False,Data Efficient Language-Supervised Zero-Shot Recognition with Optimal Transport Distillation,"['Bichen Wu', 'Ruizhe Cheng', 'Peizhao Zhang', 'Tianren Gao', 'Joseph E. Gonzalez', 'Peter Vajda']","[""Zero shot learning"", ""contrastive learning"", ""optimal transport"", ""vision and language""]",We improve the image-text contrastive learning by augmenting InfoNCE with Optimal Transport,,,,
G9JXCpShpni,2022,Reject,False,The guide and the explorer: smart agents for resource-limited iterated batch reinforcement learning,"['Albert Thomas', 'BalÃ¡zs KÃ©gl', 'Othman Gaizi', 'Gabriel Hurtado']","[""Model-based reinforcement learning"", ""Dyna"", ""exploration"", ""planning"", ""DQN""]",Smart agents for resource-limited iterated batch reinforcement learning,,,,
G9M4FU8Ggo,2022,Reject,False,Neural Architecture Search via Ensemble-based Knowledge Distillation,"['Fanxin Li', 'Shixiong Zhao', 'Haowen Pi', 'Yuhao QING', 'Yichao Fu', 'Sen Wang', 'Heming Cui']","[""NAS"", ""Knowledge Distillation"", ""Imagenet""]",We propose an diversity-driven ensemble method to generate teachers that boosts up knowledge distillation for training one-shot NAS.,,,,
GA87kjyd-f,2021,Reject,False,A Unified Paths Perspective for Pruning at Initialization,"[""Thomas Gebhart"", ""Udit Saxena"", ""Paul R. Schrater""]","[""Pruning"", ""Paths"", ""Neural Networks"", ""Neural Tangent Kernel""]",We present a unified paths view of pruning at initialization through a novel decomposition of the Neural Tangent Kernel. ,,,,
GBjukBaBLXK,2021,Reject,False,Conditional Coverage Estimation for High-quality Prediction Intervals,"[""Ziyi Huang"", ""Henry Lam"", ""Haofeng Zhang""]",[],,,,,
GBszJ1XlKDj,2022,Reject,False,Quasi-Newton policy gradient algorithms,"['Haoya Li', 'Samarth Gupta', 'Hsiang-Fu Yu', 'Lexing Ying', 'Inderjit S Dhillon']",[],We proposed a quasi-Newton policy gradient algorithm for reinforcement learning problems with general entropic regularization and proved its quadratic convergence. ,,,,
GCXq4UHH7h4,2021,Reject,False,Selective Sensing: A Data-driven Nonuniform Subsampling Approach for Computation-free On-Sensor Data Dimensionality Reduction,"[""Zhikang Zhang"", ""Kai Xu"", ""Fengbo Ren""]","[""Compressive sensing"", ""nonuniform subsampling"", ""machine learning""]",We propose a selective sensing framework that adopts the novel concept of data-driven nonuniform subsampling for on-sensor data dimensionality reduction.,,,,
GDUfz1phf06,2022,Reject,False,AutoNF: Automated Architecture Optimization of Normalizing Flows Using a Mixture Distribution Formulation,"['Yu Wang', 'Jan Drgona', 'Jiaxin Zhang', 'Karthik Somayaji NS', 'Frank Y Liu', 'Malachi Schram', 'Peng Li']","[""normalizing flow"", ""architecture optimization""]",A novel automated optimization framework for normalizing flow.,,,,
GEpTemgn7cq,2021,Reject,False,Dependency Structure Discovery from Interventions,"[""Nan Rosemary Ke"", ""Olexa Bilaniuk"", ""Anirudh Goyal"", ""Stefan Bauer"", ""Bernhard Sch\u00f6lkopf"", ""Michael Curtis Mozer"", ""Hugo Larochelle"", ""Christopher Pal"", ""Yoshua Bengio""]","[""structure learning"", ""deep learning"", ""continuous"", ""optimization""]",A continuous optimization method to learn Bayesian networks' structure.,,,,
GFsU8a0sGB,2021,Accept (Poster),True,Federated Learning via Posterior Averaging: A New Perspective and Practical Algorithms,"[""Maruan Al-Shedivat"", ""Jennifer Gillenwater"", ""Eric Xing"", ""Afshin Rostamizadeh""]","[""federated learning"", ""posterior inference"", ""MCMC""]","A new approach to federated learning that generalizes federated optimization, combines local MCMC-based sampling with global optimization-based posterior inference, and achieves competitive results on challenging benchmarks.",2010.05273,cs.LG,2020-10-11 15:55:45+00:00,2021-01-30 01:50:00+00:00
GH7QRzUDdXG,2021,Accept (Poster),False,A Geometric Analysis of Deep Generative Image Models and Its Applications,"[""Binxu Wang"", ""Carlos R Ponce""]","[""Deep generative model"", ""Interpretability"", ""GAN"", ""Differential Geometry"", ""Optimization"", ""Model Inversion"", ""Feature Visualization""]","We developed tools to compute the metric tensor of image manifold learnt by GANs, empirically analyzed their geometry, and found this knowledge useful to GAN inversion and finding interpretable axes.",,,,
GHCu1utcBvX,2021,Reject,False,Transferability of Compositionality,"[""Yuanpeng Li"", ""Liang Zhao"", ""Joel Hestness"", ""Ka Yee Lun"", ""Kenneth Church"", ""Mohamed Elhoseiny""]","[""Compositionality""]",,,,,
GIBm-_kax6,2022,Reject,False,Expected Improvement-based Contextual Bandits,"['Hung Tran-The', 'Sunil Gupta', 'Santu Rana', 'Long Tran-Thanh', 'Svetha Venkatesh']","[""Linear Bandits"", ""Contextual Bandits"", ""Expected Improvement"", ""Neural Tangent Kernel""]",,,,,
GIEPR9OomyX,2022,Reject,False,Langevin Autoencoders for Learning Deep Latent Variable Models,"['Shohei Taniguchi', 'Yusuke Iwasawa', 'Wataru Kumagai', 'Yutaka Matsuo']","[""Langevin dynamics"", ""amortized inference"", ""latent variable model"", ""deep generative model""]",We introduce amortization method of Langevin dynamics for learning deep latent variable models.,,,,
GIeGTl8EYx,2021,Reject,False,Deep Graph Neural Networks with Shallow Subgraph Samplers,"[""Hanqing Zeng"", ""Muhan Zhang"", ""Yinglong Xia"", ""Ajitesh Srivastava"", ""Rajgopal Kannan"", ""Viktor Prasanna"", ""Long Jin"", ""Andrey Malevich"", ""Ren Chen""]","[""Graph Neural Networks"", ""Graph Sampling"", ""Network Embedding""]",We train deep GNNs on shallow and localized subgraphs to enhance the accuracy and efficiency of node embedding. ,,,,
GJkTaYTmzVS,2021,Reject,False,Play to Grade: Grading Interactive Coding Games as Classifying Markov Decision Process,"[""Allen Nie"", ""Emma Brunskill"", ""Chris Piech""]","[""Deep Reinforcement Learning"", ""Education"", ""Automated Grading"", ""Program Testing""]",We apply deep reinforcement learning to learn an agent that can interact with online coding games and develop classifier to grade them with high accuracy.,2110.14615,cs.AI,2021-10-27 17:37:33+00:00,2021-10-27 17:37:33+00:00
GJnpCsLQThe,2021,Reject,True,Gradient Descent Ascent for Min-Max Problems on Riemannian Manifolds,"[""Feihu Huang"", ""Shangqian Gao"", ""Heng Huang""]","[""Min-Max Optimization"", ""Riemannian Manifold"", ""Robust Training""]",,2010.06097,cs.LG,2020-10-13 00:54:00+00:00,2021-03-17 15:09:46+00:00
GJwMHetHc73,2021,Accept (Spotlight),False,Unsupervised Object Keypoint Learning using Local Spatial Predictability,"[""Anand Gopalakrishnan"", ""Sjoerd van Steenkiste"", ""J\u00fcrgen Schmidhuber""]","[""unsupervised representation learning"", ""object-keypoint representations"", ""visual saliency""]","We propose PermaKey, a novel method for learning object keypoint representations that leverages local predictability as a measure of objectness.",2011.12930,cs.CV,2020-11-25 18:27:05+00:00,2021-03-08 15:10:29+00:00
GKLLd9FOe5l,2021,Reject,False,Online Testing of Subgroup Treatment Effects Based on Value Difference,"[""Miao Yu"", ""Wenbin Lu"", ""Rui Song""]","[""online A/B testing"", ""subgroup treatment effects testing"", ""continuous monitoring"", ""supervised representation learning"", ""classification""]","We propose a subgroup treatment effect test to detect the existence of a subgroup with enhanced treatment effects, which allows continuous monitoring.",2109.00712,stat.ME,2021-09-02 05:05:04+00:00,2021-09-02 05:05:04+00:00
GMYWzWztDx5,2022,Reject,False,NormFormer: Improved Transformer Pretraining with Extra Normalization,"['Sam Shleifer', 'Myle Ott']","[""Language Modeling"", ""NLP"", ""Transformer"", ""Zero Shot Learning""]",The gradients for transformer language models are too big (small) at early (late) layers and fixing the bug improves substantially over GPT3 and roberta-base.,,,,
GMgHyUPrXa,2021,Accept (Poster),False,A Design Space Study for LISTA and Beyond,"[""Tianjian Meng"", ""Xiaohan Chen"", ""Yifan Jiang"", ""Zhangyang Wang""]",[],,2104.04110,cs.LG,2021-04-08 23:01:52+00:00,2021-04-08 23:01:52+00:00
GNv-TyWu3PY,2021,Reject,False,Robust Learning for Congestion-Aware Routing,"[""Sreenivas Gollapudi"", ""Kostas Kollias"", ""Benjamin Plaut"", ""Ameya Velingker""]","[""routing algorithms"", ""adversarial learning"", ""congestion functions""]","We present an algorithm which learns an optimal routing policy on any graph for any Lipschitz-continuous congestion functions, even in the presence of noisy observations and adversarial routing requests.",,,,
GOr80bgf52v,2022,Reject,False,Factored World Models for Zero-Shot Generalization in Robotic Manipulation,"['Ondrej Biza', 'Thomas Kipf', 'David Klee', 'Robert Platt', 'Jan-Willem van de Meent', 'Lawson L.S. Wong']","[""reinforcement learning"", ""world models"", ""robotic manipulation"", ""zero-shot transfer""]",Learned factored world models can perform zero-shot generalization to unseen tasks in robotic manipulation.,,,,
GPuvhWrEdUn,2021,Reject,True,MixCon: Adjusting the Separability of Data Representations for Harder Data Recovery,"[""Xiaoxiao Li"", ""YANGSIBO HUANG"", ""Binghui Peng"", ""Zhao Song"", ""Kai Li""]","[""Data Recovery"", ""Data Separability"", ""Distributed Deep Learning""]",We investigate the trade-off between data utility and risk of data recovery from the angle of adjusting data separability.,2010.11463,cs.LG,2020-10-22 06:02:44+00:00,2020-10-22 06:02:44+00:00
GQd7mXSPua,2022,Accept (Poster),True,Meta Learning Low Rank Covariance Factors for Energy Based Deterministic Uncertainty,"['Jeffrey Ryan Willette', 'Hae Beom Lee', 'Juho Lee', 'Sung Ju Hwang']","[""calibration"", ""meta-learning""]","We propose a novel meta learning algorithm which learns low rank covariance factors, and utilizes an energy-based inference to achieve a calibrated prediction. ",2110.06381,stat.ML,2021-10-12 22:04:19+00:00,2021-10-15 00:55:41+00:00
GQjaI9mLet,2022,Accept (Spotlight),False,Independent SE(3)-Equivariant Models for End-to-End Rigid Protein Docking,"['Octavian-Eugen Ganea', 'Xinyuan Huang', 'Charlotte Bunne', 'Yatao Bian', 'Regina Barzilay', 'Tommi S. Jaakkola', 'Andreas Krause']","[""protein complexes"", ""protein structure"", ""rigid body docking"", ""SE(3) equivariance"", ""graph neural networks""]",We perform rigid protein docking using a novel independent SE(3)-equivariant message passing mechanism that guarantees the same resulting protein complex independent of the initial placement of the two 3D structures.,,,,
GSTrduvZSjT,2021,Reject,False,Adaptive Gradient Methods Converge Faster with Over-Parameterization (and you can do a line-search),"[""Sharan Vaswani"", ""Issam H. Laradji"", ""Frederik Kunstner"", ""Si Yi Meng"", ""Mark Schmidt"", ""Simon Lacoste-Julien""]","[""Adaptive gradient methods"", ""Over-parameterization"", ""Stochastic line-search"", ""Momentum""]",Adaptive gradient methods can converge faster for over-parameterized models and their performance can be further improved by incorporating classical line-search techniques.,,,,
GTGb3M_KcUl,2021,Accept (Poster),False,DynaTune: Dynamic Tensor Program Optimization in Deep Neural Network Compilation,"[""Minjia Zhang"", ""Menghao Li"", ""Chi Wang"", ""Mingqin Li""]","[""Efficient Deep Learning Inference"", ""Scalability"", ""Code Compilation"", ""Bayesian Inference""]",We accelerate tensor program optimization by considering it as a multi-armed bandits problem and using Bayesian inference to achieve fast convergence.,,,,
GU11Lbci5J,2022,Reject,False,Understanding AdamW through Proximal Methods and Scale-Freeness,"['Zhenxun Zhuang', 'Mingrui Liu', 'Ashok Cutkosky', 'Francesco Orabona']","[""Optimization of Deep Neural Networks"", ""Scale-free"", ""AdamW""]",This paper shows that AdamW can be seen as an approximation of the proximal updates and enjoys the scale-freeness property which correlates closely with the large advantage AdamW enjoys over Adam-$\ell_2$ on training DNNs without batch normalization.,2202.00089,cs.LG,2022-01-31 21:00:55+00:00,2022-01-31 21:00:55+00:00
GUrhfTuf_3,2022,Accept (Poster),True,SimVLM: Simple Visual Language Model Pretraining with Weak Supervision,"['Zirui Wang', 'Jiahui Yu', 'Adams Wei Yu', 'Zihang Dai', 'Yulia Tsvetkov', 'Yuan Cao']","[""Vision-Language Pretraining"", ""Multimodal Language Model"", ""Weak Supervision""]",,2108.10904,cs.CV,2021-08-24 18:14:00+00:00,2021-08-24 18:14:00+00:00
GVDwiINkMR,2022,Reject,False,Picking Daisies in Private: Federated Learning from Small Datasets,"['Michael Kamp', 'Jonas Fischer', 'Jilles Vreeken']","[""federated learning"", ""distributed"", ""sparse data"", ""daisy chain"", ""small datasets""]","We propose Federated Daisy-Chaining to train a model collaboratively from extremely small, distributed datasets by intertwining model aggregations with permutations of local models.",,,,
GVNGAaY2Dr1,2021,Reject,True,Multi-Agent Collaboration via Reward Attribution Decomposition,"[""Tianjun Zhang"", ""Huazhe Xu"", ""Xiaolong Wang"", ""Yi Wu"", ""Kurt Keutzer"", ""Joseph E. Gonzalez"", ""Yuandong Tian""]","[""multi-agent reinforcement leanring"", ""ad hoc team play""]",,2010.08531,cs.LG,2020-10-16 17:42:11+00:00,2020-10-16 17:42:11+00:00
GWQWAeE9EpB,2022,Accept (Poster),False,DictFormer: Tiny Transformer with Shared Dictionary,"['Qian Lou', 'Ting Hua', 'Yen-Chang Hsu', 'Yilin Shen', 'Hongxia Jin']","[""Transformer"", ""Parameters Sharing"", ""Tiny"", ""On-device Transformer"", ""Machine Translation"", ""Attention"", ""Dictionary Sharing""]","We propose DictFormer with efficient shared dictionary to provide a compact, fast, and accurate transformer model.",,,,
GXJPLbB5P-y,2021,Reject,False,Simplifying Models with Unlabeled Output Data,"[""Sang Michael Xie"", ""Tengyu Ma"", ""Percy Liang""]","[""semi-supervised learning"", ""structured prediction""]","Composing a model with a denoiser learned on unlabeled output examples can offload the complexity of learning complex output structure and invariances onto the denoiser, improving generalization in structured prediction problems.",,,,
GY6-6sTvGaf,2021,Accept (Spotlight),False,Image Augmentation Is All You Need: Regularizing Deep Reinforcement Learning from Pixels,"[""Denis Yarats"", ""Ilya Kostrikov"", ""Rob Fergus""]",[],The first successful demonstration that image augmentation can be applied to image-based Deep RL to achieve SOTA performance.,,,,
GafvgJTFkgb,2021,Reject,False,A Technical and Normative Investigation of Social Bias Amplification,"[""Angelina Wang"", ""Olga Russakovsky""]","[""bias amplification"", ""fairness"", ""societal considerations""]","We examine bias amplification from both normative and technical perspectives, including introducing a new metric for measuring bias amplification that mitigates the shortcomings of prior work.",,,,
GbCkSfstOIA,2021,Reject,False,Semi-Supervised Learning via Clustering Representation Space,"[""Yen-Chieh Huang"", ""Yuh-Jye Lee"", ""Chih-Chi Wu"", ""Yi-Wei Chiu"", ""Yong-Xiang Lin"", ""\bCHENG-YING LI"", ""Po-Hung Ko""]","[""semi-supervised learning"", ""deep learning"", ""clustering"", ""embedding latent space""]",We proposed a novel loss function that combines supervised learning with clustering in deep neural networks.,,,,
Gc4MQq-JIgj,2021,Reject,False,Reconnaissance for reinforcement learning with safety constraints,"[""Shin-ichi Maeda"", ""Hayato Watahiki"", ""Yi Ouyang"", ""Shintarou Okada"", ""Masanori Koyama""]","[""Reinforcement Learning"", ""Safety constraints"", ""Constrained Markov Decision Process""]",We propose a safe RL algorithm that conducts safety-assessment  and reward optimization in two separate phases by using a  simulator to efficiently train a danger analogue of Q-function,,,,
GdPZJxjk46V,2022,Reject,False,Dataset transformations trade-offs to adapt machine learning methods across domains,"['Napoleon Costilla-Enriquez', 'Yang Weng']","[""Datasets"", ""multiple domains"", ""cyber-attacks"", ""optimal transport""]",,,,,
GesLOTU_r23,2022,Reject,False,Gradient Explosion and Representation Shrinkage in Infinite Networks,['Adam Klukowski'],"[""deep learning theory"", ""mean-field approximation""]",Non-perturbative analysis of signal propagation reveals new problems with deep networks.,,,,
GgOEm9twFO_,2022,Reject,False,PhaseFool: Phase-oriented Audio Adversarial Examples via Energy Dissipation,"['Ziyue Jiang', 'Yi Ren', 'Zhou Zhao']","[""Audio adversarial examples"", ""audio adversarial attacks"", ""automatic speech recognition""]",We propose a phase-oriented algorithm named PhaseFool that adversarially dissipate the energy that is crucial for ASR systems and efficiently generate imperceptible audio adversarial examples.,,,,
Ggx8fbKZ1-D,2021,Reject,True,Adaptive Hierarchical Hyper-gradient Descent,"[""RENLONG JIE"", ""Junbin Gao"", ""Andrey Vasnev"", ""Minh-Ngoc Tran""]","[""learning rate adaptation"", ""hyper-gradient descent"", ""meta learning"", ""optimisation"", ""hierarchical system""]",We introduce hierarchical learning rate adaptation with hyper-gradient descent for deep neural networks.,2008.07277,cs.LG,2020-08-17 13:01:36+00:00,2021-05-11 06:48:55+00:00
GhVS8_yPeEa,2022,Accept (Poster),False,Effect of scale on catastrophic forgetting in neural networks,"['Vinay Venkatesh Ramasesh', 'Aitor Lewkowycz', 'Ethan Dyer']","[""Catastrophic forgetting"", ""continual learning"", ""scaling"", ""language modeling"", ""image classification""]","We find that large, pre-trained models are robust to catastrophic forgetting.  ",,,,
GiddFXGDmqp,2022,Reject,False,Spatially Invariant Unsupervised 3D Object-Centric Learning and Scene Decomposition,"['Tianyu Wang', 'miaomiao Liu', 'Kee Siong Ng']","[""generatvie model"", ""variational autoencoder"", ""mixture model"", ""unsupervised object centric learning""]",,,,,
Gj9aQfQEHRS,2021,Reject,False,Transformers satisfy,"[""Feng Shi"", ""CHEN LI"", ""Shijie Bian"", ""Yiqiao Jin"", ""Ziheng Xu"", ""Tian Han"", ""Song-Chun Zhu""]","[""constraint satisfaction problem"", ""graph attention"", ""transformers""]",we propose a Graph Transformer architecture for solving constraint satisfaction problems.,,,,
GjqcL-v0J2A,2021,Reject,False,Mixture Representation Learning with Coupled Autoencoding Agents,"[""Yeganeh Marghi"", ""Rohan Gala"", ""Uygar S\u00fcmb\u00fcl""]","[""Multi-agent network"", ""representation learning"", ""collective decision making"", ""type-preserving data augmentation""]",We propose a multi-agent variational framework to jointly infer discrete and continuous factors through collective decision making.,,,,
GlN8MUkciwi,2022,Reject,False,Learning Context-Adapted Video-Text Retrieval by Attending to User Comments,"['Laura Hanu', 'Yuki M Asano', 'James Thewlis', 'Christian Rupprecht']","[""Multimodal Representation Learning"", ""Video"", ""Text"", ""Retrieval"", ""User Comments""]",User comments are an overlooked modality that can be leveraged to improve video retrieval,,,,
Gpp1dfvZYYH,2022,Reject,False,"ProgFed: Effective, Communication, and Computation Efficient Federated Learning by Progressive Training","['Hui-Po Wang', 'Sebastian U Stich', 'Yang He', 'Mario Fritz']","[""federated learning"", ""progressive learning""]","We propose ProgFed, a progressive learning framework for communication and computation cost reduction in federated learning.",,,,
GrFix2vWsh4,2022,Reject,True,The hidden label-marginal biases of segmentation losses,"['Bingyuan Liu', 'Jose Dolz', 'Adrian Galdran', 'Riadh Kobbi', 'Ismail Ben Ayed']",[],,2104.08717,cs.CV,2021-04-18 04:59:39+00:00,2021-10-06 00:02:13+00:00
GrvigKxc13E,2022,Reject,False,"Gradient play in stochastic games: stationary points, convergence, and sample complexity","['Runyu Zhang', 'Zhaolin Ren', 'Na Li']","[""multiagent reinforcement learning"", ""stochastic game"", ""policy gradient"", ""Nash equilibrium"", ""sample complexity""]",,,,,
GsH-K1VIyy,2022,Accept (Poster),True,Data-Driven Offline Optimization for Architecting Hardware Accelerators,"['Aviral Kumar', 'Amir Yazdanbakhsh', 'Milad Hashemi', 'Kevin Swersky', 'Sergey Levine']","[""computer architecture and systems"", ""machine learning"", ""data-driven optimization""]",,2110.11346,cs.AR,2021-10-20 17:06:09+00:00,2022-02-03 23:50:50+00:00
GtCq61UFDId,2021,Reject,True,SoCal: Selective Oracle Questioning for Consistency-based Active Learning of Cardiac Signals,"[""Dani Kiyasseh"", ""Tingting Zhu"", ""David A. Clifton""]","[""Active learning"", ""consistency-training"", ""cardiac signals"", ""healthcare""]",,2004.09557,cs.LG,2020-04-20 18:20:03+00:00,2020-11-28 18:49:00+00:00
GthNKCqdDg,2022,Reject,False,Selective Token Generation for Few-shot Language Modeling,"['Daejin Jo', 'Taehwan Kwon', 'Sungwoong Kim', 'Eun-Sol Kim']","[""Natural Language Generation"", ""Reinforcement Learning"", ""Few-shot Learning"", ""Deep Learning""]",,,,,
GtiDFD1pxpz,2021,Reject,False,Intelligent Matrix Exponentiation,"[""Thomas Fischbacher"", ""Iulia Maria Comsa"", ""Krzysztof Potempa"", ""Moritz Firsching"", ""Luca Versari"", ""Jyrki Alakuijala""]","[""matrix exponential"", ""tensor methods"", ""supervised learning"", ""domain extrapolation"", ""certified robustness""]","The matrix exponential as a high-dimensional nonlinearity in machine learning of geometric, periodic and general structures.",,,,
Gu5WqN9J3Fn,2021,Accept (Poster),True,Learning Manifold Patch-Based Representations of Man-Made Shapes,"[""Dmitriy Smirnov"", ""Mikhail Bessmeltsev"", ""Justin Solomon""]","[""3D shape representations"", ""CAD modeling"", ""sketch-based modeling"", ""computer graphics"", ""computer vision"", ""deep learning""]",We propose a parametrically defined patch-based 3D shape representation that is compatible both with traditional CAD modeling tools and modern deep learning pipelines.,1906.12337,cs.GR,2019-06-28 17:36:48+00:00,2021-02-09 23:31:07+00:00
GugZ5DzzAu,2022,Accept (Poster),False,Permutation Compressors for Provably Faster Distributed Nonconvex Optimization,"['RafaÅ Szlendak', 'Alexander Tyurin', 'Peter RichtÃ¡rik']","[""MARINA"", ""distributed training"", ""permutation compressor"", ""correlated compressor"", ""Hessian variance"", ""communication complexity"", ""nonconvex optimization""]","In this paper, we present the novel compression scheme for distributed non-convex optimization.",,,,
GvqjmSwUxkY,2021,Reject,True,Rethinking the Truly Unsupervised Image-to-Image Translation,"[""Kyungjune Baek"", ""Yunjey Choi"", ""Youngjung Uh"", ""Jaejun Yoo"", ""Hyunjung Shim""]","[""unsupervised approach"", ""image-to-image translation"", ""representation learning""]",We propose a truly unsupervised image-to-image translation model even without set-level supervisions.,2006.06500,cs.CV,2020-06-11 15:15:12+00:00,2021-08-20 03:36:26+00:00
GwjkaD3g-V1,2021,Reject,False,Semi-Supervised Learning of Multi-Object 3D Scene Representations,"[""Cathrin Elich"", ""Martin R. Oswald"", ""Marc Pollefeys"", ""Joerg Stueckler""]","[""scene understanding"", ""representation learning"", ""multi-object scene decomposition"", ""pose estimation"", ""shape and appearance estimation""]","We propose a model to learn representations of scenes composed of multiple objects which explicitly describes the underlying 3D geometry by encoding the individual object poses, 3D shapes and texture.",,,,
Gx6Tvlm-hWW,2022,Reject,False,Trading Coverage for Precision: Conformal Prediction with Limited False Discoveries,"['Adam Fisch', 'Tal Schuster', 'Tommi S. Jaakkola', 'Regina Barzilay']","[""conformal prediction"", ""confidence"", ""uncertainty estimation"", ""false discovery"", ""natural language processing"", ""computer vision"", ""chemistry""]",,,,,
GzHjhdpk-YH,2021,Reject,False,The Unbalanced Gromov Wasserstein Distance: Conic Formulation and Relaxation,"[""Thibault Sejourne"", ""Fran\u00e7ois-Xavier Vialard"", ""Gabriel Peyr\u00e9""]","[""Gromov-Wasserstein"", ""Non-convex optimization"", ""Optimal Transport"", ""Partial matching""]","It is the generalization of the Gromov-Wasserstein distance inspired from unbalanced optimal transport, which is proved to define a distance and to be computable via GPU routines.",,,,
GzMUD_GGvJN,2021,Reject,False,On the Importance of Distraction-Robust Representations for Robot Learning,"[""Andy Wang"", ""Antoine Cully""]","[""Unsupervised Representation Learning"", ""Robot Control"", ""Quality-Diversity""]",This paper introduces the concept of Distraction-Robust Representation Learning and proposes a simple and effective architecture that can be applied to robot learning algorithms.,,,,
H-AAaJ9v_lE,2021,Reject,False,Legendre Deep Neural Network (LDNN) and its application for approximation of nonlinear VolterraâFredholmâHammerstein integral equations,"[""Kourosh Parand"", ""Zeinab Hajimohammadi"", ""Ali Ghodsi""]","[""Deep neural network"", ""Volterra\u2013Fredholm\u2013Hammerstein integral equations"", ""Legendre orthogonal polynomials"", ""Gaussian quadrature method"", ""Collocation method""]",we propose the Legendre Deep Neural Network (LDNN) for solving nonlinear VolterraâFredholmâHammerstein integral equations (V-F-H-IEs),,,,
H-BVtEaipej,2021,Reject,True,Global Attention Improves Graph Networks Generalization,"[""Omri Puny"", ""Heli Ben-Hamu"", ""Yaron Lipman""]","[""Graph Neural Network"", ""Self-Attention"", ""Generalization of GNNs"", ""Weisfeiler-Lehman""]",Low rank global self-attention for improving generalization of graph neural networks,2006.07846,cs.LG,2020-06-14 09:01:57+00:00,2020-11-12 10:30:15+00:00
H-SPvQtMwm,2021,Reject,False,Synthesizer: Rethinking Self-Attention for Transformer Models,"[""Yi Tay"", ""Dara Bahri"", ""Donald Metzler"", ""Da-Cheng Juan"", ""Zhe Zhao"", ""Che Zheng""]","[""Transformers"", ""Deep Learning"", ""Attention""]","We propose synthesizing the attention matrix and achieve simple, efficient and competitive performance.",,,,
H-iABMvzIc,2022,Accept (Poster),False,Switch to Generalize: Domain-Switch Learning for Cross-Domain Few-Shot Classification,"['Zhengdong Hu', 'Yifan Sun', 'Yi Yang']",[],,,,,
H-sddFpZAp4,2022,Reject,True,ModeRNN: Harnessing Spatiotemporal Mode Collapse in Unsupervised Predictive Learning,"['Zhiyu Yao', 'Yunbo Wang', 'Haixu Wu', 'Jianmin Wang', 'Mingsheng Long']","[""Predictive Learning"", ""Video Prediction""]","This paper studies a new problem as spatiotemporal mode collapse. ModeRNN is designed to reduce complex modes to several spatiotemporal slots. With this design, ModeRNN can break the limitation of mode collapse and benefit from mixed visual dynamics.",2110.03882,cs.LG,2021-10-08 03:47:54+00:00,2021-10-13 11:17:58+00:00
H0oaWl6THa,2022,Accept (Spotlight),False,Hybrid Local SGD for Federated Learning with Heterogeneous Communications,"['Yuanxiong Guo', 'Ying Sun', 'Rui Hu', 'Yanmin Gong']","[""Federated Learning"", ""Communication Efficiency"", ""Heterogeneity"", ""Local SGD""]",,,,,
H0syOoy3Ash,2021,Accept (Poster),True,Average-case Acceleration for Bilinear Games and Normal Matrices,"[""Carles Domingo-Enrich"", ""Fabian Pedregosa"", ""Damien Scieur""]","[""Smooth games"", ""First-order Methods"", ""Acceleration"", ""Bilinear games"", ""Average-case Analysis"", ""Orthogonal Polynomials""]","We extend the framework of average-case optimal first-order methods to problems with non-symmetric matrices, which naturally arise in equilibrium finding for games.",2010.02076,math.OC,2020-10-05 15:13:37+00:00,2020-10-05 15:13:37+00:00
H1-nGgWC-,2018,Accept (Poster),False,Gaussian Process Behaviour in Wide Deep Neural Networks,"[""Alexander G. de G. Matthews"", ""Jiri Hron"", ""Mark Rowland"", ""Richard E. Turner"", ""Zoubin Ghahramani""]","[""Gaussian Processes"", ""Bayesian Deep Learning"", ""Theory of Deep Neural Networks""]",,,,,
H1-oTz-Cb,2018,Reject,False,Parametrizing filters of a CNN with a GAN,"[""Yannic Kilcher"", ""Gary Becigneul"", ""Thomas Hofmann""]","[""invariance"", ""cnn"", ""gan"", ""infogan"", ""transformation""]",,,,,
H113pWZRb,2018,Reject,False,Topology Adaptive Graph Convolutional  Networks,"[""Jian Du"", ""Shanghang Zhang"", ""Guanhang Wu"", ""Jos\u00e9 M. F. Moura"", ""Soummya Kar""]","[""graph convolutional neural networks"", ""graph-structured data"", ""semi-classification""]",Low computational complexity graph CNN (without approximation) with better classification accuracy,,,,
H11lAfbCW,2018,Reject,False,On Characterizing the Capacity of Neural Networks Using Algebraic Topology,"[""William H. Guss"", ""Ruslan Salakhutdinov""]","[""deep learning theory"", ""architecture selection"", ""algebraic topology""]",We show that the learnability of different neural architectures can be characterized directly by computable measures of data complexity.,,,,
H12GRgcxg,2017,Accept (Poster),False,Training deep neural-networks using a noise adaptation layer,"[""Jacob Goldberger"", ""Ehud Ben-Reuven""]","[""Deep learning"", ""Optimization""]",Training neural network with noisy labels,,,,
H135uzZ0-,2018,Accept (Poster),False,Mixed Precision Training of Convolutional Neural Networks using Integer Operations,"[""Dipankar Das"", ""Naveen Mellempudi"", ""Dheevatsa Mudigere"", ""Dhiraj Kalamkar"", ""Sasikanth Avancha"", ""Kunal Banerjee"", ""Srinivas Sridharan"", ""Karthik Vaidyanathan"", ""Bharat Kaul"", ""Evangelos Georganas"", ""Alexander Heinecke"", ""Pradeep Dubey"", ""Jesus Corbal"", ""Nikita Shustrov"", ""Roma Dubtsov"", ""Evarist Fomenko"", ""Vadim Pirogov""]","[""deep learning training"", ""reduced precision"", ""imagenet"", ""dynamic fixed point""]",Mixed precision training pipeline using 16-bit integers on general purpose HW;  SOTA accuracy for ImageNet-class CNNs; Best reported accuracy for ImageNet-1K classification task with any reduced precision training;,,,,
H139Q_gAW,2018,Reject,False,Learning Graph Convolution Filters from Data Manifold,"[""Guokun Lai"", ""Hanxiao Liu"", ""Yiming Yang""]","[""Label Propagation"", ""Depthwise separable convolution"", ""Graph and geometric convolution""]","We devise a novel Depthwise Separable Graph Convolution (DSGC) for the generic spatial domain data, which is highly compatible with depthwise separable convolution.",,,,
H13F3Pqll,2017,Reject,False,Inverse Problems in Computer Vision using  Adversarial  Imagination Priors,"[""Hsiao-Yu Fish Tung"", ""Katerina Fragkiadaki""]","[""Unsupervised Learning"", ""Deep learning""]","We present a model that given a visual image learns to generate imaginations of  complete scenes, albedo, shading etc, by using adversarial data driven priors on the imaginations spaces.",,,,
H13WofbAb,2018,Reject,False,Faster Distributed Synchronous SGD with Weak Synchronization,"[""Cong Xie"", ""Oluwasanmi O. Koyejo"", ""Indranil Gupta""]","[""distributed"", ""deep learning"", ""straggler""]",,,,,
H15RufWAW,2018,Reject,False,GraphGAN: Generating Graphs via Random Walks,"[""Aleksandar Bojchevski"", ""Oleksandr Shchur"", ""Daniel Z\u00fcgner"", ""Stephan G\u00fcnnemann""]","[""GAN"", ""graphs"", ""random walks"", ""implicit generative models""]",Using GANs to generate graphs via random walks.,,,,
H15odZ-C-,2018,Accept (Poster),False,Semantic Interpolation in Implicit Models,"[""Yannic Kilcher"", ""Aurelien Lucchi"", ""Thomas Hofmann""]","[""Deep Generative Models"", ""GANs""]",,,,,
H178hw9ex,2017,Reject,False,Dynamic Steerable Frame Networks,"[""J\u00f6rn-Henrik Jacobsen"", ""Bert De Brabandere"", ""Arnold W.M. Smeulders""]","[""Computer vision"", ""Deep learning""]","Introducing non-orthogonal and overcomplete bases for ConvNets and derive Dynamic Steerable Frame Networks, a hybrid of Dynamic Filter Networks and Spatial Transformers.",,,,
H18WqugAb,2018,Invite to Workshop Track,False,Still not systematic after all these years: On the compositional skills of sequence-to-sequence recurrent networks,"[""Brenden Lake"", ""Marco Baroni""]","[""sequence-to-sequence recurrent networks"", ""compositionality"", ""systematicity"", ""generalization"", ""language-driven navigation""]","Using a simple language-driven navigation task, we study the compositional capabilities of modern seq2seq recurrent networks.",,,,
H18uzzWAZ,2018,Reject,False,Correcting Nuisance Variation using Wasserstein Distance,"[""Gil Tabak"", ""Minjie Fan"", ""Samuel J. Yang"", ""Stephan Hoyer"", ""Geoff Davis""]","[""Nuisance variation"", ""transform learning"", ""image embeddings""]","We correct nuisance variation for image embeddings across different domains, preserving only relevant information.",,,,
H196sainb,2018,Accept (Poster),False,Word translation without parallel data,"[""Guillaume Lample"", ""Alexis Conneau"", ""Marc'Aurelio Ranzato"", ""Ludovic Denoyer"", ""Herv\u00e9 J\u00e9gou""]","[""unsupervised learning"", ""machine translation"", ""multilingual embeddings"", ""parallel dictionary induction"", ""adversarial training""]","Aligning languages without the Rosetta Stone: with no parallel data, we construct bilingual dictionaries using adversarial training, cross-domain local scaling, and an accurate proxy criterion for cross-validation.",,,,
H1A5ztj3b,2018,Reject,False,Super-Convergence: Very Fast Training of Residual Networks Using Large Learning Rates,"[""Leslie N. Smith"", ""Nicholay Topin""]","[""Deep Learning"", ""machine learning""]",Empirical proof of a new phenomenon requires new theoretical insights and is relevent to the active discussions in the literature on SGD and understanding generalization.,,,,
H1BHbmWCZ,2018,Reject,False,TOWARDS ROBOT VISION MODULE DEVELOPMENT WITH EXPERIENTIAL ROBOT LEARNING,"[""Ahmed A Aly"", ""Joanne Bechta Dugan""]","[""Deep Learning"", ""Robotics"", ""Artificial Intelligence"", ""Computer Vision""]",3 thrusts serving as stepping stones for robot experiential learning of vision module,,,,
H1BLjgZCb,2018,Accept (Poster),False,Generating Natural Adversarial Examples,"[""Zhengli Zhao"", ""Dheeru Dua"", ""Sameer Singh""]","[""adversarial examples"", ""generative adversarial networks"", ""interpretability"", ""image classification"", ""textual entailment"", ""machine translation""]","We propose a framework to generate ânaturalâ adversaries against black-box classifiers for both visual and textual domains, by doing the search for adversaries in the latent semantic space.",,,,
H1BO9M-0Z,2018,Reject,False,Lifelong Word Embedding via Meta-Learning,"[""Hu Xu"", ""Bing Liu"", ""Lei Shu"", ""Philip S. Yu""]","[""Lifelong learning"", ""meta learning"", ""word embedding""]",learning better domain embeddings via lifelong learning and meta-learning,,,,
H1DGha1CZ,2018,Reject,False,Enhancing Batch Normalized Convolutional Networks using Displaced Rectifier Linear Units: A Systematic Comparative Study,"[""David Mac\u00eado"", ""Cleber Zanchettin"", ""Adriano L. I. Oliveira"", ""Teresa Ludermir""]","[""Batch Normalized"", ""Convolutional Neural Networks"", ""Displaced Rectifier Linear Unit"", ""Comparative Study""]",A new activation function called Displaced Rectifier Linear Unit is proposed. It is showed to enhance the training and inference performance of batch normalized convolutional neural networks.,,,,
H1DJFybC-,2018,Reject,False,Learning to Infer Graphics Programs from Hand-Drawn Images,"[""Kevin Ellis"", ""Daniel Ritchie"", ""Armando Solar-Lezama"", ""Joshua B. Tenenbaum""]","[""program induction"", ""HCI"", ""deep learning""]",Learn to convert a hand drawn sketch into a high-level program,,,,
H1DkN7ZCZ,2018,Invite to Workshop Track,False,Deep learning mutation prediction enables early stage lung cancer detection in liquid biopsy,"[""Steven T. Kothen-Hill"", ""Asaf Zviran"", ""Rafael C. Schulman"", ""Sunil Deochand"", ""Federico Gaiti"", ""Dillon Maloney"", ""Kevin Y. Huang"", ""Will Liao"", ""Nicolas Robine"", ""Nathaniel D. Omans"", ""Dan A. Landau""]","[""somatic mutation"", ""variant calling"", ""cancer"", ""liquid biopsy"", ""early detection"", ""convolution"", ""deep learning"", ""machine learning"", ""lung cancer"", ""error suppression"", ""mutect""]"," Current somatic mutation methods do not work with liquid biopsies (ie low coverage sequencing), we apply a CNN architecture to a unique representation of a read and its ailgnment, we show significant improvement over previous methods in the low frequency setting.",,,,
H1Dy---0Z,2018,Accept (Poster),False,Distributed Prioritized Experience Replay,"[""Dan Horgan"", ""John Quan"", ""David Budden"", ""Gabriel Barth-Maron"", ""Matteo Hessel"", ""Hado van Hasselt"", ""David Silver""]","[""deep learning"", ""reinforcement learning"", ""distributed systems""]","A distributed architecture for deep reinforcement learning at scale, using parallel data-generation to improve the state of the art on the Arcade Learning Environment benchmark in a fraction of the wall-clock training time of previous approaches.",,,,
H1ERcs09KQ,2019,Reject,False,Hierarchically Clustered Representation Learning,"[""Su-Jin Shin"", ""Kyungwoo Song"", ""Il-Chul Moon""]","[""Representation learning"", ""Hierarchical clustering"", ""Nonparametric Bayesian modeling""]","We introduce hierarchically clustered representation learning (HCRL), which simultaneously optimizes representation learning and hierarchical clustering in the embedding space.",,,,
H1Fk2Iqex,2017,Invite to Workshop Track,False,Fast Chirplet Transform to Enhance CNN Machine Listening - Validation on Animal calls and Speech,"[""Herve Glotin"", ""Julien Ricard"", ""Randall Balestriero""]","[""Applications"", ""Supervised Learning"", ""Deep learning"", ""Speech""]",Proposing a chirplet transform in order to regulate the input of deep-CNN and possible extension to chirplet learning for deep learning bioacoustics,,,,
H1GEvHcee,2017,Reject,False,Annealing Gaussian into ReLU: a New Sampling Strategy for Leaky-ReLU RBM,"[""Chun-Liang Li"", ""Siamak Ravanbakhsh"", ""Barnabas Poczos""]","[""Deep learning"", ""Unsupervised Learning""]",We study fundamental property of leaky RBM. We link the leaky RBM and truncated Gaussian distribution and propose a novel sampling algorithm without additional computation cost.,,,,
H1GLm2R9Km,2019,Reject,False,Learning Backpropagation-Free Deep Architectures with Kernels,"[""Shiyu Duan"", ""Shujian Yu"", ""Yunmei Chen"", ""Jose Principe""]","[""supervised learning"", ""backpropagation-free deep architecture"", ""kernel method""]",We combine kernel method with connectionist models and show that the resulting deep architectures can be trained layer-wise and have more transparent learning dynamics. ,,,,
H1GaLiAcY7,2019,Reject,False,Learning to Separate Domains in Generalized Zero-Shot and Open Set Learning: a probabilistic perspective,"[""Hanze Dong"", ""Yanwei Fu"", ""Leonid Sigal"", ""SungJu Hwang"", ""Yu-Gang Jiang"", ""Xiangyang Xue""]","[""Generalized zero-shot learning"", ""domain division"", ""bootstrapping"", ""Kolmogorov-Smirnov""]", This paper studies the problem of domain division by segmenting instances drawn from different probabilistic distributions.  ,,,,
H1Gfx3Rqtm,2019,Reject,False,End-to-End Hierarchical Text Classification with Label Assignment Policy,"[""Yuning Mao"", ""Jingjing Tian"", ""Jiawei Han"", ""Xiang Ren""]","[""Hierarchical Classification"", ""Text Classification""]",,,,,
H1Go7Koex,2017,Reject,False,Character-aware Attention Residual Network for Sentence Representation,"[""Xin Zheng"", ""Zhenzhou Wu""]","[""Deep learning""]",We propose a character-aware attention residual network for short text representation.,,,,
H1Gq5Q9el,2017,Reject,False,Unsupervised Pretraining for Sequence to Sequence Learning,"[""Prajit Ramachandran"", ""Peter J. Liu"", ""Quoc V. Le""]","[""Natural language processing"", ""Deep learning"", ""Semi-Supervised Learning"", ""Transfer Learning""]",Pretraining seq2seq models gives large gains in both generalization and optimization on a variety of tasks.,,,,
H1Heentlx,2017,Reject,False,Deep Variational Canonical Correlation Analysis,"[""Weiran Wang"", ""Xinchen Yan"", ""Honglak Lee"", ""Karen Livescu""]",[],A deep generative model for multi-view representation learning,,,,
H1I3M7Z0b,2018,Invite to Workshop Track,False,WSNet: Learning Compact and Efficient Networks with Weight Sampling,"[""Xiaojie Jin"", ""Yingzhen Yang"", ""Ning Xu"", ""Jianchao Yang"", ""Jiashi Feng"", ""Shuicheng Yan""]","[""Deep learning"", ""model compression""]",We present a novel network architecture for learning compact and efficient deep neural networks,,,,
H1K6Tb-AZ,2018,Reject,False,TESLA: Task-wise Early Stopping and Loss Aggregation for Dynamic Neural Network Inference,"[""Chun-Min Chang"", ""Chia-Ching Lin"", ""Hung-Yi Ou Yang"", ""Chin-Laung Lei"", ""Kuan-Ta Chen""]",[],,,,,
H1LAqMbRW,2018,Reject,False,Latent forward model for Real-time Strategy game planning with incomplete information,"[""Yuandong Tian"", ""Qucheng Gong""]","[""Real time strategy"", ""latent space"", ""forward model"", ""monte carlo tree search"", ""reinforcement learning"", ""planning""]","The paper analyzes the latent space learned by model-free approaches in a miniature incomplete information game, trains a forward model in the latent space and apply it to Monte-Carlo Tree Search, yielding positive performance.",,,,
H1M7soActX,2019,Reject,False,The Anisotropic Noise in Stochastic Gradient Descent: Its Behavior of Escaping from Minima and Regularization Effects,"[""Zhanxing Zhu"", ""Jingfeng Wu"", ""Bing Yu"", ""Lei Wu"", ""Jinwen Ma""]","[""Stochastic gradient descent"", ""anisotropic noise"", ""regularization""]",We provide theoretical and empirical analysis on the role of anisotropic noise introduced by stochastic gradient on escaping from minima.,,,,
H1MBuiAqtX,2019,Reject,False,"Unicorn: Continual learning with a universal, off-policy agent","[""Daniel J. Mankowitz"", ""Augustin \u017d\u00eddek"", ""Andr\u00e9 Barreto"", ""Dan Horgan"", ""Matteo Hessel"", ""John Quan"", ""Junhyuk Oh"", ""Hado van Hasselt"", ""David Silver"", ""Tom Schaul""]","[""reinforcement learning"", ""continual learning"", ""universal value functions"", ""off-policy learning"", ""multi-task""]",Agents learning jointly and off-policy about many tasks make progress on challenging continual learning domains.,,,,
H1MOqeHYvB,2020,Reject,False,At Your Fingertips: Automatic Piano Fingering Detection,"[""Amit Moryossef"", ""Yanai Elazar"", ""Yoav Goldberg""]","[""piano"", ""fingering"", ""dataset""]","We automatically extract fingering information from videos of piano performances, to be used in automatic fingering prediction models.",,,,
H1MW72AcK7,2019,Accept (Poster),False,Optimal Control Via Neural Networks: A Convex Approach,"[""Yize Chen"", ""Yuanyuan Shi"", ""Baosen Zhang""]","[""optimal control"", ""input convex neural network"", ""convex optimization""]",,,,,
H1MczcgR-,2018,Accept (Poster),False,Understanding Short-Horizon Bias in Stochastic Meta-Optimization,"[""Yuhuai Wu"", ""Mengye Ren"", ""Renjie Liao"", ""Roger Grosse.""]","[""meta-learning; optimization; short-horizon bias.""]",We investigate the bias in the short-horizon meta-optimization objective.,,,,
H1MgjoR9tQ,2019,Accept (Poster),False,CBOW Is Not All You Need: Combining CBOW with the Compositional Matrix Space Model,"[""Florian Mai"", ""Lukas Galke"", ""Ansgar Scherp""]","[""Text representation learning"", ""Sentence embedding"", ""Efficient training scheme"", ""word2vec""]",We present a novel training scheme for efficiently obtaining order-aware sentence representations.,,,,
H1MjAnqxg,2017,Reject,False,Intelligible Language Modeling with Input Switched Affine Networks,"[""Jakob Foerster"", ""Justin Gilmer"", ""Jan Chorowski"", ""Jascha Sohl-dickstein"", ""David Sussillo""]","[""Natural language processing"", ""Deep learning"", ""Supervised Learning""]",Input Switched Affine Networks combine intelligibility with performance for character level language modeling. ,,,,
H1MzKs05F7,2019,Reject,False,Adversarial Vulnerability of Neural Networks Increases with Input Dimension,"[""Carl-Johann Simon-Gabriel"", ""Yann Ollivier"", ""L\u00e9on Bottou"", ""Bernhard Sch\u00f6lkopf"", ""David Lopez-Paz""]","[""adversarial vulnerability"", ""neural networks"", ""gradients"", ""FGSM"", ""adversarial data-augmentation"", ""gradient regularization"", ""robust optimization""]",Neural nets have large gradients by design; that makes them adversarially vulnerable.,,,,
H1Nyf7W0Z,2018,Reject,False,Alpha-divergence bridges maximum likelihood and reinforcement learning in neural sequence generation,"[""Sotetsu Koyamada"", ""Yuta Kikuchi"", ""Atsunori Kanemura"", ""Shin-ichi Maeda"", ""Shin Ishii""]","[""neural network"", ""reinforcement learning"", ""natural language processing"", ""machine translation"", ""alpha-divergence""]",Propose new objective function for neural sequence generation which integrates ML-based and RL-based objective functions.,,,,
H1O0KGC6b,2018,Reject,False,Post-training for Deep Learning,"[""Thomas Moreau"", ""Julien Audiffren""]",[],"We propose an additional training step, called post-training, which computes optimal weights for the last layer of the network.",,,,
H1OQukZ0-,2018,Reject,False,Online Hyper-Parameter Optimization,"[""Damien Vincent"", ""Sylvain Gelly"", ""Nicolas Le Roux"", ""Olivier Bousquet""]","[""hyper-parameters"", ""optimization""]",An algorithm for optimizing regularization hyper-parameters during training,,,,
H1T2hmZAb,2018,Accept (Poster),False,Deep Complex Networks,"[""Chiheb Trabelsi"", ""Olexa Bilaniuk"", ""Ying Zhang"", ""Dmitriy Serdyuk"", ""Sandeep Subramanian"", ""Joao Felipe Santos"", ""Soroush Mehri"", ""Negar Rostamzadeh"", ""Yoshua Bengio"", ""Christopher J Pal""]","[""deep learning"", ""complex-valued neural networks""]",,,,,
H1UOm4gA-,2018,Accept (Poster),False,Interactive Grounded Language Acquisition and Generalization in a 2D World,"[""Haonan Yu"", ""Haichao Zhang"", ""Wei Xu""]","[""grounded language learning and generalization"", ""zero-shot language learning""]",Training an agent in a 2D virtual world for grounded language acquisition and generalization.,,,,
H1U_af-0-,2018,Reject,False,Quadrature-based features for kernel approximation,"[""Marina Munkhoeva"", ""Yermek Kapushev"", ""Evgeny Burnaev"", ""Ivan Oseledets""]","[""kernel methods"", ""low-rank approximation"", ""quadrature rules"", ""random features""]",Quadrature rules for kernel approximation.,,,,
H1V4QhAqYQ,2019,Reject,False,Augment your batch: better training with larger batches,"[""Elad Hoffer"", ""Itay Hubara"", ""Niv Giladi"", ""Daniel Soudry""]","[""Large Batch Training"", ""Augmentation"", ""Deep Learning""]",Improve accuracy by large batches composed of multiple instances of each sample at the same batch,,,,
H1VGkIxRZ,2018,Accept (Poster),False,Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks,"[""Shiyu Liang"", ""Yixuan Li"", ""R. Srikant""]","[""Neural networks"", ""out-of-distribution detection""]",,,,,
H1VjBebR-,2018,Accept (Poster),False,The Role of Minimal Complexity Functions in Unsupervised Learning of Semantic Mappings,"[""Tomer Galanti"", ""Lior Wolf"", ""Sagie Benaim""]","[""Unsupervised learning"", ""cross-domain mapping"", ""Kolmogorov complexity"", ""Occam's razor""]","Our hypothesis is that given two domains, the lowest complexity mapping that has a low discrepancy approximates the target mapping.",,,,
H1VyHY9gg,2017,Accept (Poster),False,Data Noising as Smoothing in Neural Network Language Models,"[""Ziang Xie"", ""Sida I. Wang"", ""Jiwei Li"", ""Daniel L\u00e9vy"", ""Aiming Nie"", ""Dan Jurafsky"", ""Andrew Y. Ng""]","[""Natural language processing"", ""Deep learning""]",Derive data noising schemes for neural network language models corresponding to techniques in n-gram smoothing.,,,,
H1W1UN9gg,2017,Accept (Poster),False,Deep Information Propagation,"[""Samuel S. Schoenholz"", ""Justin Gilmer"", ""Surya Ganguli"", ""Jascha Sohl-Dickstein""]","[""Theory"", ""Deep learning""]",We predict whether randomly initialized neural networks can be trained by studying whether or not information can travel through them.,,,,
H1WgVz-AZ,2018,Accept (Poster),False,Learning Approximate Inference Networks for Structured Prediction,"[""Lifu Tu"", ""Kevin Gimpel""]","[""Approximate Inference Networks"", ""Structured Prediction"", ""Multi-Label Classification"", ""Sequence Labeling""]",,,,,
H1Ww66x0-,2018,Reject,False,Lifelong Learning with Output Kernels,"[""Keerthiram Murugesan"", ""Jaime Carbonell""]","[""multitask learning"", ""lifelong learning"", ""online learning""]",a novel approach for online lifelong learning using output kernels.,,,,
H1Xw62kRZ,2018,Accept (Poster),False,Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis,"[""Rudy Bunel"", ""Matthew Hausknecht"", ""Jacob Devlin"", ""Rishabh Singh"", ""Pushmeet Kohli""]","[""Program Synthesis"", ""Reinforcement Learning"", ""Language Model""]",Using the DSL grammar and reinforcement learning to improve synthesis of programs with complex control flow.,,,,
H1Y8hhg0b,2018,Accept (Poster),False,Learning Sparse Neural Networks through L_0 Regularization,"[""Christos Louizos"", ""Max Welling"", ""Diederik P. Kingma""]","[""Sparsity"", ""compression"", ""hard and soft attention.""]",We show how to optimize the expected L_0 norm of parametric models with gradient descent and introduce a new distribution that facilitates hard gating.,,,,
H1Yp-j1Cb,2018,Accept (Poster),False,An Online Learning Approach to Generative Adversarial Networks,"[""Paulina Grnarova"", ""Kfir Y Levy"", ""Aurelien Lucchi"", ""Thomas Hofmann"", ""Andreas Krause""]","[""Generative Adversarial Networks"", ""GANs"", ""online learning""]",,,,,
H1YynweCb,2018,Invite to Workshop Track,False,Kronecker Recurrent Units,"[""Cijo Jose"", ""Moustapha Cisse"", ""Francois Fleuret""]","[""Recurrent neural network"", ""Vanishing and exploding gradients"", ""Parameter efficiency"", ""Kronecker matrices"", ""Soft unitary constraint""]",Out work presents a Kronecker factorization of recurrent weight matrices for parameter efficient and well conditioned recurrent neural networks.,,,,
H1_EDpogx,2017,Reject,False,Near-Data Processing for Machine Learning,"[""Hyeokjun Choe"", ""Seil Lee"", ""Hyunha Nam"", ""Seongsik Park"", ""Seijoon Kim"", ""Eui-Young Chung"", ""Sungroh Yoon""]",[],,,,,
H1_QSDqxl,2017,Reject,False,Rule Mining in Feature Space,"[""Stefano Teso"", ""Andrea Passerini""]","[""Unsupervised Learning""]",We propose an algorithm to discover logical theories from relational embeddings of knowledge bases.,,,,
H1a37GWCZ,2018,Reject,False,UNSUPERVISED SENTENCE EMBEDDING USING DOCUMENT STRUCTURE-BASED CONTEXT,"[""Taesung Lee"", ""Youngja Park""]","[""distributed representation"", ""sentence embedding"", ""structure"", ""technical documents"", ""sentence embedding"", ""out-of-vocabulary""]","To train a sentence embedding using technical documents, our approach considers document structure to find broader context and handle out-of-vocabulary words.",,,,
H1aIuk-RW,2018,Accept (Poster),False,Active Learning for Convolutional Neural Networks: A Core-Set Approach,"[""Ozan Sener"", ""Silvio Savarese""]","[""Active Learning"", ""Convolutional Neural Networks"", ""Core-Set Selection""]",We approach to the problem of active learning as a core-set selection problem and show that this approach is especially useful in the batch active learning setting which is crucial when training CNNs.,,,,
H1acq85gx,2017,Accept (Poster),False,Maximum Entropy Flow Networks,"[""Gabriel Loaiza-Ganem *"", ""Yuanjun Gao *"", ""John P. Cunningham""]",[],,,,,
H1bM1fZCW,2018,Reject,False,GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks,"[""Zhao Chen"", ""Vijay Badrinarayanan"", ""Chen-Yu Lee"", ""Andrew Rabinovich""]","[""Multitask learning"", ""computer vision"", ""multitask loss function""]",We show how you can boost performance in a multitask network by tuning an adaptive multitask loss function that is learned through directly balancing network gradients.,,,,
H1bhRHeA-,2018,Reject,False,Unbiased scalable softmax optimization,"[""Francois Fagan"", ""Garud Iyengar""]","[""softmax"", ""optimization"", ""implicit sgd""]",Propose first methods for exactly optimizing the softmax distribution using stochastic gradient with runtime independent on the number of classes or datapoints.,,,,
H1cKvl-Rb,2018,Reject,False,UCB EXPLORATION VIA Q-ENSEMBLES,"[""Richard Y. Chen"", ""Szymon Sidor"", ""Pieter Abbeel"", ""John Schulman""]","[""Reinforcement learning"", ""Q-learning"", ""ensemble method"", ""upper confidence bound""]","Adapting UCB exploration to ensemble Q-learning improves over prior methods such as Double DQN, A3C+ on Atari benchmark",,,,
H1cWzoxA-,2018,Accept (Poster),False,Bi-Directional Block Self-Attention for Fast and Memory-Efficient Sequence Modeling,"[""Tao Shen"", ""Tianyi Zhou"", ""Guodong Long"", ""Jing Jiang"", ""Chengqi Zhang""]","[""deep learning"", ""attention mechanism"", ""sequence modeling"", ""natural language processing"", ""sentence embedding""]","A self-attention network for RNN/CNN-free sequence encoding with small memory consumption, highly parallelizable computation and state-of-the-art performance on several NLP tasks",1804.00857,cs.CL,2018-04-03 07:41:10+00:00,2018-04-03 07:41:10+00:00
H1dh6Ax0Z,2018,Accept (Poster),False,TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep Reinforcement Learning,"[""Gregory Farquhar"", ""Tim Rockt\u00e4schel"", ""Maximilian Igl"", ""Shimon Whiteson""]","[""reinforcement learning"", ""deep learning"", ""planning""]","We present TreeQN and ATreeC, new architectures for deep reinforcement learning in discrete-action domains that integrate differentiable on-line tree planning into the action-value function or policy.",,,,
H1e-X64FDB,2020,Reject,False,"Fast Linear Interpolation for Piecewise-Linear Functions, GAMs, and Deep Lattice Networks","[""Nathan Zhang"", ""Kevin Canini"", ""Sean Silva"", ""and Maya R. Gupta""]","[""hardware"", ""compiler"", ""MLIR"", ""runtime"", ""CPU"", ""interpolation""]","Fast implementations of linear interpolation operators are given for both piecewise linear functions and multi-dimensional look-up tables, producing 3-11x faster runtimes for single evaluations.",,,,
H1e0-30qKm,2019,Reject,False,Unlabeled Disentangling of GANs with Guided Siamese Networks,"[""G\u00f6khan Yildirim"", ""Nikolay Jetchev"", ""Urs Bergmann""]","[""GAN"", ""disentange"", ""siamese networks"", ""semantic""]",We use Siamese Networks to guide and disentangle the generation process in GANs without labeled data.,,,,
H1e0Wp4KvH,2020,Accept (Poster),False,Automated curriculum generation through setter-solver interactions,"[""Sebastien Racaniere"", ""Andrew Lampinen"", ""Adam Santoro"", ""David Reichert"", ""Vlad Firoiu"", ""Timothy Lillicrap""]","[""Deep Reinforcement Learning"", ""Automatic Curriculum""]",We investigate automatic curriculum generation and identify a number of losses useful to learn to generate a curriculum of tasks.,,,,
H1e31AEYwB,2020,Reject,False,Stiffness: A New Perspective on Generalization in Neural Networks,"[""Stanislav Fort"", ""Pawe\u0142 Krzysztof Nowak"", ""Stanis\u0142aw Jastrzebski"", ""Srini Narayanan""]","[""stiffness"", ""gradient alignment"", ""critical scale""]","We defined the concept of stiffness, showed its utility in providing a perspective to better understand generalization in neural networks, observed its variation with learning rate, and defined the concept of dynamical critical length using it.",,,,
H1e3HlSFDr,2020,Reject,False,Variational Constrained Reinforcement Learning with Application to Planning at Roundabout,"[""Yuan Tian"", ""Minghao Han"", ""Lixian Zhang"", ""Wulong Liu"", ""Jun Wang"", ""Wei Pan""]","[""Safe reinforcement learning"", ""Autonomous driving"", ""obstacle avoidance""]",,,,,
H1e552VKPr,2020,Reject,False,Subgraph Attention for Node Classification and Hierarchical Graph Pooling,"[""Sambaran Bandyopadhyay"", ""Manasvi Aggarwal"", ""M. N. Murty""]","[""Graph Neural Network"", ""Graph Attention"", ""Graph Pooling"", ""Node Classification"", ""Graph Classification"", ""Network Representation Learning""]",We propose a novel subgraph attention mechanism which can be readily used for node classification and we further propose a hierarchical graph classification technique using it.,,,,
H1e572A5tQ,2019,Reject,False,TarMAC: Targeted Multi-Agent Communication,"[""Abhishek Das"", ""Theophile Gervet"", ""Joshua Romoff"", ""Dhruv Batra"", ""Devi Parikh"", ""Mike Rabbat"", ""Joelle Pineau""]",[],Targeted communication in multi-agent cooperative reinforcement learning,,,,
H1e5GJBtDr,2020,Reject,False,Axial Attention in Multidimensional Transformers,"[""Jonathan Ho"", ""Nal Kalchbrenner"", ""Dirk Weissenborn"", ""Tim Salimans""]","[""self-attention"", ""transformer"", ""images"", ""videos""]",Easy-to-implement and effective multidimensional Transformer with faster sampling,,,,
H1e6ij0cKQ,2019,Reject,False,EFFICIENT SEQUENCE LABELING WITH ACTOR-CRITIC TRAINING,"[""Saeed Najafi"", ""Colin Cherry"", ""Greg Kondrak""]","[""Structured Prediction"", ""Reinforcement Learning"", ""NLP""]",,,,,
H1e8wsCqYX,2019,Reject,False,Laplacian Networks: Bounding Indicator Function Smoothness for Neural Networks Robustness,"[""Carlos Eduardo Rosar Kos Lassance"", ""Vincent Gripon"", ""Antonio Ortega""]","[""GSP"", ""robustness"", ""noise"", ""deep learning"", ""neural networks""]",,,,,
H1eA7AEtvS,2020,Accept (Spotlight),True,ALBERT: A Lite BERT for Self-supervised Learning of Language Representations,"[""Zhenzhong Lan"", ""Mingda Chen"", ""Sebastian Goodman"", ""Kevin Gimpel"", ""Piyush Sharma"", ""Radu Soricut""]","[""Natural Language Processing"", ""BERT"", ""Representation Learning""]","A new pretraining method that establishes new state-of-the-art results on the GLUE, RACE, and SQuAD benchmarks while having fewer parameters compared to BERT-large. ",1909.11942,cs.CL,2019-09-26 07:06:13+00:00,2020-02-09 03:00:18+00:00
H1eArT4tPH,2020,Reject,False,The Effect of Residual Architecture on the Per-Layer Gradient of Deep Networks,"[""Etai Littwin"", ""Lior Wolf""]",[],,,,,
H1eCR34FPB,2020,Reject,False,Sequence-level Intrinsic Exploration Model for Partially Observable Domains,"[""Haiyan Yin"", ""Jianda Chen"", ""Sinno Jialin Pan""]","[""deep learning"", ""reinforcement learning""]",,,,,
H1eCw3EKvH,2020,Accept (Poster),False,On the Weaknesses of Reinforcement Learning for Neural Machine Translation,"[""Leshem Choshen"", ""Lior Fox"", ""Zohar Aizenbud"", ""Omri Abend""]","[""Reinforcement learning"", ""MRT"", ""minimum risk training"", ""reinforce"", ""machine translation"", ""peakkiness"", ""generation""]",Reinforcment practices for machine translation performance gains might not come from better predictions.,,,,
H1eD7REtPr,2020,Reject,False,CAN ALTQ LEARN FASTER: EXPERIMENTS AND THEORY,"[""Bowen Weng"", ""Huaqing Xiong"", ""Yingbin Liang"", ""Wei Zhang""]","[""Reinforcement Learning"", ""Q-Learning"", ""Adam"", ""Restart"", ""Convergence Analysis""]",New Experiments and Theory for Adam Based Q-Learning,,,,
H1eF3kStPS,2020,Reject,False,Redundancy-Free Computation Graphs for Graph Neural Networks,"[""Zhihao Jia"", ""Sina Lin"", ""Rex Ying"", ""Jiaxuan You"", ""Jure Leskovec"", ""Alex Aiken.""]","[""Graph Neural Networks"", ""Runtime Performance""]","We present Hierarchically Aggregated computation Graphs (HAGs), a new GNN graph representation that explicitly avoids redundant computations in GNN training and inference.",,,,
H1eH4n09KX,2019,Reject,False,Adversarial Audio Super-Resolution with Unsupervised Feature Losses,"[""Sung Kim"", ""Visvesh Sathe""]",[],,,,,
H1eH9hNtwr,2020,Reject,False,Stagnant zone segmentation with U-net,"[""Selam Waktola"", ""Laurent Babout"", ""Krzysztof Grudzien""]",[],,,,,
H1eJAANtvr,2020,Reject,False,CGT: Clustered Graph Transformer for Urban Spatio-temporal Prediction,"[""Xu Geng"", ""Lingyu Zhang"", ""Shulin Li"", ""Yuanbo Zhang"", ""Lulu Zhang"", ""Leye Wang"", ""Qiang Yang"", ""Hongtu Zhu"", ""Jieping Ye""]","[""Unsmooth spatiotemporal forecasting"", ""Clustered graph neural network"", ""Graph-Transformer"", ""Urban computing""]","We developed CGT (clustered graph-transformer) for handling the spatial and temporal unsmoothness, which greatly improve the model capability and lift the spatiotemporal prediction performance.",,,,
H1eKT1SFvH,2020,Reject,False,Towards Effective 2-bit Quantization: Pareto-optimal Bit Allocation for Deep CNNs Compression,"[""Zhe Wang"", ""Jie Lin"", ""Mohamed M. Sabry Aly"", ""Sean I Young"", ""Vijay Chandrasekhar"", ""Bernd Girod""]",[],,,,,
H1eLE8qlx,2017,Reject,False,Options Discovery with Budgeted Reinforcement Learning,"[""Aurelia L\u00e9on"", ""Ludovic Denoyer""]","[""Reinforcement Learning""]","The article describes a new learning model called Budgeted Option Neural Network (BONN) able to discover options based on a budgeted learning objective, and a new RL learning framework called Bi-POMDP.",,,,
H1eLVxrKwS,2020,Reject,False,Removing input features via a generative model to explain their attributions to classifier's decisions,"[""Chirag Agarwal"", ""Dan Schonfeld"", ""Anh Nguyen""]","[""attribution maps"", ""generative models"", ""inpainting"", ""counterfactual"", ""explanations"", ""interpretability"", ""explainability""]",,,,,
H1eMBn09Km,2019,Reject,False,Using GANs for Generation of Realistic City-Scale Ride Sharing/Hailing Data Sets,"[""Abhinav Jauhri"", ""Brad Stocks"", ""Jian Hui Li"", ""Koichi Yamada"", ""John Paul Shen""]","[""ride-sharing"", ""generative modeling"", ""parallelization"", ""application""]",This paper focuses on the synthetic generation of human mobility data in urban areas using GANs. ,,,,
H1eNleBYwr,2020,Reject,True,GENN: Predicting Correlated Drug-drug Interactions with Graph Energy Neural Networks,"[""Tengfei Ma"", ""Junyuan Shang"", ""Cao Xiao"", ""Jimeng Sun""]","[""graph neural networks"", ""energy model"", ""structure prediction"", ""drug-drug-interaction""]",,1910.02107,cs.LG,2019-10-04 19:03:12+00:00,2019-10-08 02:50:56+00:00
H1eRBoC9FX,2019,Reject,True,Unsupervised Meta-Learning for Reinforcement Learning,"[""Abhishek Gupta"", ""Benjamin Eysenbach"", ""Chelsea Finn"", ""Sergey Levine""]","[""Meta-Learning"", ""Reinforcement Learning"", ""Exploration"", ""Unsupervised""]",Remove the burden of task distribution specification in meta-reinforcement learning by using unsupervised exploration,1806.04640,cs.LG,2018-06-12 16:48:52+00:00,2020-04-30 16:55:56+00:00
H1eRI04KPB,2020,Reject,True,Likelihood Contribution based Multi-scale Architecture for Generative Flows,"[""Hari Prasanna Das"", ""Pieter Abbeel"", ""Costas J. Spanos""]","[""Generative Flow"", ""Normalizing Flow"", ""Multi-scale Architecture"", ""RealNVP"", ""Dimension Factorization""]",Data-dependent factorization of dimensions in a multi-scale architecture based on contribution to the total log-likelihood,1908.01686,cs.LG,2019-08-05 15:14:18+00:00,2019-09-25 06:18:38+00:00
H1eRYxHYPB,2020,Reject,False,Optimal Unsupervised Domain Translation,"[""Emmanuel de B\u00e9zenac"", ""Ibrahim Ayed"", ""Patrick Gallinari""]","[""Unsupervised Domain Translation"", ""CycleGAN"", ""Optimal Transport""]","We propose a novel, more rigorous framework for Unsupervised Domain Translation based on Optimal Transport.",,,,
H1eSS3CcKX,2019,Accept (Poster),False,Stochastic Optimization of Sorting Networks via Continuous Relaxations,"[""Aditya Grover"", ""Eric Wang"", ""Aaron Zweig"", ""Stefano Ermon""]","[""continuous relaxations"", ""sorting"", ""permutation"", ""stochastic computation graphs"", ""Plackett-Luce""]","We provide a continuous relaxation to the sorting operator, enabling end-to-end, gradient-based stochastic optimization.",,,,
H1eUz1rKPr,2020,Reject,False,Representation Learning with Multisets,"[""Vasco Portilheiro""]","[""multisets"", ""fuzzy sets"", ""permutation invariant"", ""representation learning"", ""containment"", ""partial order"", ""clustering""]","Based on fuzzy set theory, we propose a model that given only the sizes of symmetric differences between pairs of multisets, learns representations of such multisets and their elements.",1911.08577,cs.LG,2019-11-19 20:50:20+00:00,2019-11-19 20:50:20+00:00
H1eVlgHKPr,2020,Reject,False,Event Discovery for History Representation in Reinforcement Learning,"[""Aleksandr Ermolov"", ""Enver Sangineto"", ""Nicu Sebe""]","[""reinforcement learning"", ""self-supervision"", ""POMDP""]",event discovery to represent the history for the agent in RL,,,,
H1eWGREFvB,2020,Reject,False,Stein Self-Repulsive Dynamics: Benefits from Past Samples,"[""Mao Ye"", ""Tongzheng Ren"", ""Qiang Liu""]","[""Approximate Inference"", ""Markov Chain Monte Carlo"", ""Stein Variational Gradient Descent""]",We propose a new Stein self-repulsive dynamics for obtaining diversified samples from intractable un-normalized distributions. ,2002.09070,cs.LG,2020-02-21 00:26:38+00:00,2020-12-15 05:36:41+00:00
H1eY00VFDB,2020,Reject,False,Retrospection: Leveraging the Past for Efficient Training of Deep Neural Networks,"[""Ayush Chopra"", ""Surgan Jandial"", ""Mausoom Sarkar"", ""Balaji Krishnamurthy"", ""Vineeth Balasubramanian""]","[""Deep Neural Networks"", ""Supervised Learning"", ""Classification"", ""Training Strategy"", ""Generative Adversarial Networks"", ""Convolutional Neural Networks""]",A retrospection loss that enables networks  to leverage past parameter states as guidance during training to improve performance,,,,
H1e_cC4twS,2020,Accept (Poster),False,Non-Autoregressive Dialog State Tracking,"[""Hung Le"", ""Richard Socher"", ""Steven C.H. Hoi""]","[""task-oriented"", ""dialogues"", ""dialogue state tracking"", ""non-autoregressive""]","We propose the first non-autoregressive neural model for Dialogue State Tracking (DST), achieving the SOTA accuracy (49.04%) on MultiWOZ2.1 benchmark, and reducing inference latency by an order of magnitude.",,,,
H1eadi0cFQ,2019,Reject,False,Escaping Flat Areas via Function-Preserving Structural Network Modifications,"[""Yannic Kilcher"", ""Gary B\u00e9cigneul"", ""Thomas Hofmann""]","[""deep learning"", ""cnn"", ""structural modification"", ""optimization"", ""saddle point""]","If optimization gets stuck in a saddle, we add a filter to a CNN in a specific way in order to escape the saddle.",,,,
H1ebTsActm,2019,Accept (Poster),True,Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality,"[""Taiji Suzuki""]","[""deep learning theory"", ""approximation analysis"", ""generalization error analysis"", ""Besov space"", ""minimax optimality""]",,1810.08033,stat.ML,2018-10-18 13:17:20+00:00,2018-10-18 13:17:20+00:00
H1ebc0VYvH,2020,Reject,True,Unaligned Image-to-Sequence Transformation with Loop Consistency,"[""Siyang Wang"", ""Justin Lazarow"", ""Kwonjoon Lee"", ""Zhuowen Tu""]",[],LoopGAN extends cycle length in CycleGAN to enable unaligned sequential transformation for more than two time steps.,1910.04149,cs.CV,2019-10-09 17:50:45+00:00,2019-10-09 17:50:45+00:00
H1ebhnEYDH,2020,Accept (Spotlight),False,White Noise Analysis of Neural Networks,"[""Ali Borji"", ""Sikun Lin""]","[""Classification images"", ""spike triggered analysis"", ""deep learning"", ""network visualization"", ""adversarial attack"", ""adversarial defense"", ""microstimulation"", ""computational neuroscience""]",,1912.12106,cs.CV,2019-12-23 18:14:34+00:00,2019-12-23 18:14:34+00:00
H1ecDoR5Y7,2019,Reject,False,Local Stability and Performance of Simple Gradient Penalty $\mu$-Wasserstein GAN,"[""Cheolhyeong Kim"", ""Seungtae Park"", ""Hyung Ju Hwang""]","[""WGAN"", ""gradient penalty"", ""stability"", ""measure valued differentiation""]",This paper deals with stability of simple gradient penalty $\mu$-WGAN optimization by introducing a concept of measure valued differentiation.,,,,
H1edEyBKDS,2020,Accept (Poster),False,Plug and Play Language Models: A Simple Approach to Controlled Text Generation,"[""Sumanth Dathathri"", ""Andrea Madotto"", ""Janice Lan"", ""Jane Hung"", ""Eric Frank"", ""Piero Molino"", ""Jason Yosinski"", ""Rosanne Liu""]","[""controlled text generation"", ""generative models"", ""conditional generative models"", ""language modeling"", ""transformer""]",We control the topic and sentiment of text generation (almost) without any training. ,1912.02164,cs.CL,2019-12-04 18:32:15+00:00,2020-03-03 05:33:49+00:00
H1edIiA9KQ,2019,Accept (Poster),False,Generating Multiple Objects at Spatially Distinct Locations,"[""Tobias Hinz"", ""Stefan Heinrich"", ""Stefan Wermter""]","[""controllable image generation"", ""text-to-image synthesis"", ""generative model"", ""generative adversarial network"", ""gan""]",Extend GAN architecture to obtain control over locations and identities of multiple objects within generated images.,,,,
H1efEp4Yvr,2020,Reject,False,Global Concavity and Optimization in a Class of Dynamic Discrete Choice Models,"[""Yiding Feng"", ""Ekaterina Khmelnitskaya"", ""Denis Nekipelov""]","[""Reinforcement learning"", ""Policy Gradient"", ""Global Concavity"", ""Dynamic Discrete Choice Model""]",,,,,
H1eiZnAqKm,2019,Reject,False,The Expressive Power of Gated Recurrent Units as a Continuous Dynamical System,"[""Ian D. Jordan"", ""Piotr Aleksander Sokol"", ""Il Memming Park""]","[""Gated Recurrent Units"", ""Recurrent Neural Network"", ""Time Series Predictions"", ""interpretable"", ""Nonlinear Dynamics"", ""Dynamical Systems""]","We classify the the dynamical features one and two GRU cells can and cannot capture in continuous time, and verify our findings experimentally with k-step time series prediction. ",1906.01005,cs.LG,2019-06-03 18:13:32+00:00,2021-07-29 02:50:50+00:00
H1ekF2EYDH,2020,Reject,False,TechKG: A Large-Scale Chinese Technology-Oriented Knowledge Graph,"[""Feiliang Ren""]","[""Chinese knowledge graph building""]",TechKG,,,,
H1emfT4twB,2020,Accept (Poster),True,Few-shot Text Classification with Distributional Signatures,"[""Yujia Bao"", ""Menghua Wu"", ""Shiyu Chang"", ""Regina Barzilay""]","[""text classification"", ""meta learning"", ""few shot learning""]","Meta-learning methods used for vision, directly applied to NLP, perform worse than nearest neighbors on new classes; we can do better with distributional signatures.",1908.06039,cs.CL,2019-08-16 15:46:14+00:00,2020-02-18 17:47:46+00:00
H1emus0qF7,2019,Accept (Poster),False,Near-Optimal Representation Learning for Hierarchical Reinforcement Learning,"[""Ofir Nachum"", ""Shixiang Gu"", ""Honglak Lee"", ""Sergey Levine""]","[""representation hierarchy reinforcement learning""]",We translate a bound on sub-optimality of representations to a practical training objective in the context of hierarchical reinforcement learning.,,,,
H1enKkrFDB,2020,Accept (Spotlight),False,Stable Rank Normalization for Improved Generalization in Neural Networks and GANs,"[""Amartya Sanyal"", ""Philip H. Torr"", ""Puneet K. Dokania""]","[""Generelization"", ""regularization"", ""empirical lipschitz""]","We propose Stable Rank Normalisation, a new regularisor based on recent generelization bounds and show how to optimize it with extensive experiments.",,,,
H1eo9h4KPH,2020,Reject,False,Certifying Distributional Robustness using Lipschitz Regularisation,"[""Zac Cranko"", ""Zhan Shi"", ""Xinhua Zhang"", ""Simon Kornblith"", ""Richard Nock""]","[""kernel method"", ""adversarial learning"", ""distributionally robust optimization""]",,,,,
H1ep5TNKwr,2020,Reject,True,Hebbian Graph Embeddings,"[""Shalin Shah"", ""Venkataramana Kini""]","[""graph embeddings"", ""hebbian learning"", ""simulated annealing""]","Graph embeddings for link prediction, reconstruction and for a recommender system",1908.08037,cs.LG,2019-08-21 02:45:43+00:00,2020-02-20 21:25:36+00:00
H1epaJSYDS,2020,Reject,False,Anchor & Transform: Learning Sparse Representations of Discrete Objects,"[""Paul Pu Liang"", ""Manzil Zaheer"", ""Yuan Wang"", ""Amr Ahmed""]","[""sparse representation learning"", ""discrete inputs"", ""natural language processing""]","We propose a general method to learn sparse representations of discrete objects that is scalable, flexible, end-to-end trainable, and allows the user to easily incorporate domain knowledge about object relationships.",2003.08197,cs.LG,2020-03-18 13:07:51+00:00,2021-03-11 06:11:05+00:00
H1eqOnNYDH,2020,Reject,False,Data augmentation instead of explicit regularization,"[""Alex Hernandez-Garcia"", ""Peter K\u00f6nig""]","[""data augmentation"", ""implicit regularization"", ""explicit regularization"", ""object recognition"", ""convolutional neural networks""]",Deep neural networks trained with data augmentation do not require any other explicit regularization (such as weight decay and dropout) and exhibit greater adaptaibility to changes in the architecture and the amount of training data.,,,,
H1eqQeHFDS,2020,Accept (Poster),False,AdvectiveNet: An Eulerian-Lagrangian Fluidic Reservoir for Point Cloud Processing     ,"[""Xingzhe He"", ""Helen Lu Cao"", ""Bo Zhu""]","[""Point Cloud Processing"", ""Physical Reservoir Learning"", ""Eulerian-Lagrangian Method"", ""PIC/FLIP""]",We present a new grid-particle learning method to process point clouds motivated by computational fluid dynamics.,2002.00118,cs.CV,2020-02-01 01:21:05+00:00,2020-06-24 19:44:09+00:00
H1eqjiCctX,2019,Accept (Poster),False,Understanding Composition of Word Embeddings via Tensor Decomposition,"[""Abraham Frandsen"", ""Rong Ge""]","[""word embeddings"", ""semantic composition"", ""tensor decomposition""]","We present a generative model for compositional word embeddings that captures syntactic relations, and provide empirical verification and evaluation.",,,,
H1eqviAqYX,2019,Reject,False,Why Do Neural Response Generation Models Prefer Universal Replies?,"[""Bowen Wu"", ""Nan Jiang"", ""Zhifeng Gao"", ""Zongsheng Wang"", ""Suke Li"", ""Wenge Rong"", ""Baoxun Wang""]","[""Neural Response Generation"", ""Universal Replies"", ""Optimization Goal Analysis"", ""Max-Marginal Ranking Regularization""]",Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.,,,,
H1ersoRqtm,2019,Accept (Poster),False,Structured Neural Summarization,"[""Patrick Fernandes"", ""Miltiadis Allamanis"", ""Marc Brockschmidt""]","[""Summarization"", ""Graphs"", ""Source Code""]",One simple trick to improve sequence models: Compose them with a graph model,,,,
H1ervR4FwH,2020,Reject,False,Improved Structural Discovery and Representation Learning of Multi-Agent Data,"[""Jennifer Hobbs"", ""Matthew Holbrook"", ""Nathan Frank"", ""Long Sha"", ""Patrick Lucey""]","[""multi-agent"", ""gaussian mixture"", ""permutation learning"", ""representation learning"", ""group structure""]",We propose an improved approach to discovering the group structure and ordered representation of multi-agent data,1912.13107,cs.LG,2019-12-30 22:49:55+00:00,2019-12-30 22:49:55+00:00
H1ewdiR5tQ,2019,Accept (Poster),False,Graph Wavelet Neural Network,"[""Bingbing Xu"", ""Huawei Shen"", ""Qi Cao"", ""Yunqi Qiu"", ""Xueqi Cheng""]","[""graph convolution"", ""graph wavelet transform"", ""graph Fourier transform"", ""semi-supervised learning""]","We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.",,,,
H1exf64KwH,2020,Accept (Poster),True,Exploring Model-based Planning with Policy Networks,"[""Tingwu Wang"", ""Jimmy Ba""]","[""reinforcement learning"", ""model-based reinforcement learning"", ""planning""]",how to achieve state-of-the-art performance by combining policy network in model-based planning,1906.08649,cs.LG,2019-06-20 14:13:12+00:00,2019-06-20 14:13:12+00:00
H1ezFREtwH,2020,Accept (Poster),True,Composing Task-Agnostic Policies with Deep Reinforcement Learning,"[""Ahmed H. Qureshi"", ""Jacob J. Johnson"", ""Yuzhe Qin"", ""Taylor Henderson"", ""Byron Boots"", ""Michael C. Yip""]","[""composition"", ""transfer learning"", ""deep reinforcement learning""]",We propose a novel reinforcement learning-based skill transfer and composition method that takes the agent's primitive policies to solve unseen tasks.,1905.10681,cs.LG,2019-05-25 21:40:38+00:00,2019-12-30 20:32:24+00:00
H1f7S3C9YQ,2019,Reject,False,SynonymNet: Multi-context Bilateral Matching for Entity Synonyms,"[""Chenwei Zhang"", ""Yaliang Li"", ""Nan Du"", ""Wei Fan"", ""Philip S. Yu""]","[""deep learning"", ""entity synonym""]","We introduce SynonymNet, a deep model for entity synonym discovery by a bilateral matching among multiple pieces of contexts in which an entity is mentioned.",,,,
H1fF0iR9KX,2019,Reject,False,Geometry aware convolutional filters for omnidirectional images representation,"[""Renata Khasanova"", ""Pascal Frossard""]","[""omnidirectional images"", ""classification"", ""deep learning"", ""graph signal processing""]",,,,,
H1fU8iAqKX,2019,Accept (Poster),True,A rotation-equivariant convolutional neural network model of primary visual cortex,"[""Alexander S. Ecker"", ""Fabian H. Sinz"", ""Emmanouil Froudarakis"", ""Paul G. Fahey"", ""Santiago A. Cadena"", ""Edgar Y. Walker"", ""Erick Cobos"", ""Jacob Reimer"", ""Andreas S. Tolias"", ""Matthias Bethge""]","[""rotation equivariance"", ""equivariance"", ""primary visual cortex"", ""V1"", ""neuroscience"", ""system identification""]",A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional groupings of V1 neurons.,1809.10504,q-bio.NC,2018-09-27 13:16:37+00:00,2018-09-27 13:16:37+00:00
H1faSn0qY7,2019,Reject,False,DL2: Training and Querying Neural Networks with Logic,"[""Marc Fischer"", ""Mislav Balunovic"", ""Dana Drachsler-Cohen"", ""Timon Gehr"", ""Ce Zhang"", ""Martin Vechev""]","[""neural networks"", ""training with constraints"", ""querying networks"", ""semantic training""]",A differentiable loss for logic constraints for training and querying neural networks.,,,,
H1fevoAcKX,2019,Reject,False,Globally Soft Filter Pruning For Efficient Convolutional Neural Networks,"[""Ke Xu"", ""Xiaoyun Wang"", ""Qun Jia"", ""Jianjing An"", ""Dong Wang""]","[""Filter Pruning"", ""Model Compression"", ""Efficient Convolutional Neural Networks""]",,,,,
H1fl8S9ee,2017,Accept (Poster),False,Learning and Policy Search in Stochastic Dynamical Systems with Bayesian Neural Networks,"[""Stefan Depeweg"", ""Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"", ""Finale Doshi-Velez"", ""Steffen Udluft""]","[""Deep learning"", ""Reinforcement Learning""]",,,,,
H1fsUiRcKQ,2019,Reject,False,Fast adversarial training for semi-supervised learning,"[""Dongha Kim"", ""Yongchan Choi"", ""Jae-Joon Han"", ""Changkyu Choi"", ""Yongdai Kim""]","[""Deep learning"", ""Semi-supervised learning"", ""Adversarial training""]",We propose a fast and efficient semi-supervised learning method using adversarial training.,,,,
H1g0Z3A9Fm,2019,Accept (Poster),False,Supervised Community Detection with Line Graph Neural Networks,"[""Zhengdao Chen"", ""Lisha Li"", ""Joan Bruna""]","[""community detection"", ""graph neural networks"", ""belief propagation"", ""energy landscape"", ""non-backtracking matrix""]",We propose a novel graph neural network architecture based on the non-backtracking matrix defined over the edge adjacencies and demonstrate its effectiveness in community detection tasks on graphs.,,,,
H1g0piA9tQ,2019,Reject,False,Evaluation Methodology for Attacks Against Confidence Thresholding Models,"[""Ian Goodfellow"", ""Yao Qin"", ""David Berthelot""]","[""adversarial examples""]",We present metrics and an optimal attack for evaluating models that defend against adversarial examples using confidence thresholding,,,,
H1g2NhC5KQ,2019,Accept (Poster),False,Multiple-Attribute Text Rewriting,"[""Guillaume Lample"", ""Sandeep Subramanian"", ""Eric Smith"", ""Ludovic Denoyer"", ""Marc'Aurelio Ranzato"", ""Y-Lan Boureau""]","[""controllable text generation"", ""generative models"", ""conditional generative models"", ""style transfer""]",A system for rewriting text conditioned on multiple controllable attributes,,,,
H1g4M0EtPS,2020,Reject,False,Gaussian MRF Covariance Modeling for Efficient Black-Box Adversarial Attacks,"[""Anit Kumar Sahu"", ""J. Zico Kolter"", ""Satya Narayan Shukla""]","[""Black-Box Adversarial Attacks"", ""Gaussian Markov Random Fields""]",A query efficient one-step black-box adversarial attack,,,,
H1g4k309F7,2019,Accept (Poster),False,Wasserstein Barycenter Model Ensembling,"[""Pierre Dognin*"", ""Igor Melnyk*"", ""Youssef Mroueh*"", ""Jarret Ross*"", ""Cicero Dos Santos*"", ""Tom Sercu*""]","[""Wasserstein barycenter model ensembling""]",we propose to use Wasserstein barycenters for semantic model ensembling,,,,
H1g6kaVKvH,2020,Reject,False,Learning with Long-term Remembering: Following the Lead of Mixed Stochastic Gradient,"[""Yunhui Guo"", ""Mingrui Liu"", ""Tianbao Yang"", ""Tajana Rosing""]","[""lifelong learning"", ""continual learning""]",A novel and effective lifelong learning algorithm which achieves the state-of-the-art results on several benchmarks.,,,,
H1g6osRcFQ,2019,Accept (Poster),False,Policy Transfer with Strategy Optimization,"[""Wenhao Yu"", ""C. Karen Liu"", ""Greg Turk""]","[""transfer learning"", ""reinforcement learning"", ""modeling error"", ""strategy optimization""]","We propose a policy transfer algorithm that can overcome large and challenging discrepancies in the system dynamics such as latency, actuator modeling error, etc.",,,,
H1g6s0NtwS,2020,Reject,False,Learning Neural Surrogate Model for Warm-Starting Bayesian Optimization,"[""Haotian Zhang"", ""Jian Sun"", ""Zongben Xu""]","[""Bayesian optimization"", ""meta learning"", ""neural network"", ""surrogate model"", ""hyper-parameters tuning""]",,,,,
H1g79ySYvB,2020,Reject,False,Revisiting Gradient Episodic Memory for Continual Learning,"[""Zhiyi Chen"", ""Tong Lin*""]",[],,,,,
H1g8p1BYvS,2020,Reject,False,Adversarial Filters of Dataset Biases,"[""Ronan Le Bras"", ""Swabha Swayamdipta"", ""Chandra Bhagavatula"", ""Rowan Zellers"", ""Matthew Peters"", ""Ashish Sabharwal"", ""Yejin Choi""]",[],,,,,
H1gB4RVKvB,2020,Accept (Poster),False,Recurrent neural circuits for contour detection,"[""Drew Linsley*"", ""Junkyung Kim*"", ""Alekh Ashok"", ""Thomas Serre""]","[""Contextual illusions"", ""visual cortex"", ""recurrent feedback"", ""neural circuits""]","Contextual illusions are a feature, not a bug, of neural routines optimized for contour detection.",,,,
H1gBhkBFDH,2020,Accept (Poster),False,B-Spline CNNs on Lie groups,"[""Erik J Bekkers""]","[""equivariance"", ""Lie groups"", ""B-Splines"", ""G-CNNs"", ""deep learning"", ""group convolution"", ""computer vision"", ""medical image analysis""]",The paper describes a flexible framework for building CNNs that are equivariant to a large class of transformations groups.,,,,
H1gBsgBYwH,2020,Accept (Spotlight),False,Generalization of Two-layer Neural Networks: An Asymptotic Viewpoint,"[""Jimmy Ba"", ""Murat Erdogdu"", ""Taiji Suzuki"", ""Denny Wu"", ""Tianzong Zhang""]","[""Neural Networks"", ""Generalization"", ""High-dimensional Statistics""]","Derived population risk of two-layer neural networks in high dimensions and examined presence / absence of  ""double descent"".",,,,
H1gCeyHFDS,2020,Reject,False,Gram-Gauss-Newton Method: Learning Overparameterized Neural Networks for Regression Problems,"[""Tianle Cai*"", ""Ruiqi Gao*"", ""Jikai Hou*"", ""Siyu Chen"", ""Dong Wang"", ""Di He"", ""Zhihua Zhang"", ""Liwei Wang""]","[""Deep learning"", ""Optimization"", ""Second-order method"", ""Neural Tangent Kernel regression""]","A novel Gram-Gauss-Newton method to train neural networks, inspired by neural tangent kernel and Gauss-Newton method, with fast convergence speed both theoretically and experimentally.",,,,
H1gDNyrKDS,2020,Accept (Talk),True,Understanding and Robustifying Differentiable Architecture Search,"[""Arber Zela"", ""Thomas Elsken"", ""Tonmoy Saikia"", ""Yassine Marrakchi"", ""Thomas Brox"", ""Frank Hutter""]","[""Neural Architecture Search"", ""AutoML"", ""AutoDL"", ""Deep Learning"", ""Computer Vision""]",We study the failure modes of DARTS (Differentiable Architecture Search) by looking at the eigenvalues of the Hessian of validation loss w.r.t. the architecture and propose robustifications based on our analysis.,1909.09656,cs.LG,2019-09-20 18:03:06+00:00,2020-01-28 14:14:05+00:00
H1gDaa4YwS,2020,Reject,False,Learning General and Reusable Features via Racecar-Training,"[""You Xie"", ""Nils Thuerey""]","[""transfer learning"", ""neural networks"", ""generalization"", ""reusable features""]",We propose a novel bi-directional training approach for learning of general features.,,,,
H1gDgn0qY7,2019,Reject,False,A Study of Robustness of Neural Nets Using Approximate Feature Collisions,"[""Ke Li*"", ""Tianhao Zhang*"", ""Jitendra Malik""]",[],,,,,
H1gEP6NFwr,2020,Reject,False,On the Tunability of Optimizers in Deep Learning,"[""Prabhu Teja S*"", ""Florian Mai*"", ""Thijs Vogels"", ""Martin Jaggi"", ""Francois Fleuret""]","[""Optimization"", ""Benchmarking"", ""Hyperparameter optimization""]",We provide a method to benchmark optimizers that is cognizant to the hyperparameter tuning process.,,,,
H1gFuiA9KX,2019,Reject,False,Skip-gram word embeddings in hyperbolic space,"[""Matthias Leimeister"", ""Benjamin J. Wilson""]","[""word embeddings"", ""hyperbolic"", ""skip-gram""]",,,,,
H1gHb1rFwr,2020,Reject,False,Extreme Values are Accurate and Robust in Deep Networks,"[""Jianguo Li"", ""Mingjie Sun"", ""Changshui Zhang""]","[""Biological inspired CNN architecture design"", ""Adversarial Robustness Architecture""]",This paper aims to leverage good properties of robust visual features like SIFT to renovate CNN architectures towards better accuracy and robustness.,,,,
H1gKYo09tX,2019,Accept (Poster),False,code2seq: Generating Sequences from Structured Representations of Code,"[""Uri Alon"", ""Shaked Brody"", ""Omer Levy"", ""Eran Yahav""]","[""source code"", ""programs"", ""code2seq""]",We leverage the syntactic structure of source code to generate natural language sequences.,,,,
H1gL-2A9Ym,2019,Accept (Poster),False,Predict then Propagate: Graph Neural Networks meet Personalized PageRank,"[""Johannes Klicpera"", ""Aleksandar Bojchevski"", ""Stephan G\u00fcnnemann""]","[""Graph"", ""GCN"", ""GNN"", ""Neural network"", ""Graph neural network"", ""Message passing neural network"", ""Semi-supervised classification"", ""Semi-supervised learning"", ""PageRank"", ""Personalized PageRank""]",Personalized propagation of neural predictions (PPNP) improves graph neural networks by separating them into prediction and propagation via personalized PageRank.,,,,
H1gL3RVtwr,2020,Reject,False,CURSOR-BASED ADAPTIVE QUANTIZATION FOR DEEP NEURAL NETWORK,"[""Bapu Li(*)"", ""Yanwen Fan(*)"", ""Zhiyu Cheng"", ""Yingze Bao (* means equal contribution)""]",[],,,,,
H1gMCsAqY7,2019,Accept (Poster),False,Slimmable Neural Networks,"[""Jiahui Yu"", ""Linjie Yang"", ""Ning Xu"", ""Jianchao Yang"", ""Thomas Huang""]","[""Slimmable neural networks"", ""mobile deep learning"", ""accuracy-efficiency trade-offs""]","We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.",,,,
H1gN6kSFwS,2020,Reject,False,Learning Neural Causal Models from Unknown Interventions,"[""Nan Rosemary Ke"", ""Olexa Bilaniuk"", ""Anirudh Goyal"", ""Stephan Bauer"", ""Hugol Larochelle"", ""Chris Pal"", ""Yoshua Bengio""]","[""deep learning"", ""graphical models"", ""meta learning""]",Using end-to-end deep learning to discover the structure of a graphical model which is robust to interventions and trained without knowing what the interventions are,,,,
H1gNHs05FX,2019,Reject,False,Clinical Risk: wavelet reconstruction networks for marked point processes,"[""Jeremy C. Weiss""]","[""point processes"", ""wavelets"", ""temporal neural networks"", ""Hawkes processes""]","Wavelet reconstructions on relative time, used in absolute-time point process models, improve risk prediction of complications and adherence in diabetes.",,,,
H1gNOeHKPS,2020,Accept (Spotlight),False,Neural Arithmetic Units,"[""Andreas Madsen"", ""Alexander Rosenberg Johansen""]",[],,2001.05016,cs.NE,2020-01-14 19:35:04+00:00,2020-01-14 19:35:04+00:00
H1gR5iR5FX,2019,Accept (Poster),False,Analysing Mathematical Reasoning Abilities of Neural Models,"[""David Saxton"", ""Edward Grefenstette"", ""Felix Hill"", ""Pushmeet Kohli""]","[""mathematics"", ""dataset"", ""algebraic"", ""reasoning""]","A dataset for testing mathematical reasoning (and algebraic generalization), and results on current sequence-to-sequence models.",,,,
H1gRM2A5YX,2019,Reject,False,Analysis of Memory Organization for Dynamic Neural Networks,"[""Ying Ma"", ""Jose Principe""]","[""memory analysis"", ""recurrent neural network"", ""LSTM"", ""neural Turing machine"", ""neural stack"", ""differentiable neural computers""]",,,,,
H1gS364FwS,2020,Reject,False,Event extraction from unstructured Amharic text,"[""Ephrem Tadesse"", ""Rosa Tsegaye"", ""Kuulaa Qaqqabaa""]","[""Event extraction"", ""machine learning classifiers"", ""Nominal events""]",This paper extract events from Amharic text.,,,,
H1gTEj09FX,2019,Accept (Poster),True,RotDCF: Decomposition of Convolutional Filters for Rotation-Equivariant Deep Networks,"[""Xiuyuan Cheng"", ""Qiang Qiu"", ""Robert Calderbank"", ""Guillermo Sapiro""]",[],,1805.06846,cs.CV,2018-05-17 16:24:51+00:00,2018-05-17 16:24:51+00:00
H1gWyJBFDr,2020,Reject,False,Fully Convolutional Graph Neural Networks using Bipartite Graph Convolutions,"[""Marcel Nassar"", ""Xin Wang"", ""Evren Tumer""]","[""Graph Neural Networks"", ""Graph Convolutional Networks""]",,,,,
H1gX8C4YPr,2020,Accept (Poster),True,DD-PPO: Learning Near-Perfect PointGoal Navigators from 2.5 Billion Frames,"[""Erik Wijmans"", ""Abhishek Kadian"", ""Ari Morcos"", ""Stefan Lee"", ""Irfan Essa"", ""Devi Parikh"", ""Manolis Savva"", ""Dhruv Batra""]","[""autonomous navigation"", ""habitat"", ""embodied AI"", ""pointgoal navigation"", ""reinforcement learning""]",,1911.00357,cs.CV,2019-11-01 13:07:37+00:00,2020-01-20 04:18:58+00:00
H1gXzxHKvH,2020,Reject,False,Deep Nonlinear Stochastic Optimal Control for Systems with Multiplicative Uncertainties,"[""Marcus Pereira"", ""Ziyi Wang"", ""Tianrong Chen"", ""Evangelos Theodorou""]","[""Deep Learning"", ""Stochastic Optimal Control"", ""Robotics"", ""Biomechanics"", ""LSTM""]",,,,,
H1gZV30qKQ,2019,Reject,False,Transfer Value or Policy? A Value-centric Framework Towards Transferrable Continuous Reinforcement Learning,"[""Xingchao Liu"", ""Tongzhou Mu"", ""Hao Su""]","[""Reinforcement Learning"", ""Transfer Learning"", ""Control"", ""Value function""]",,,,,
H1gZsJBYwH,2020,Reject,False,Hybrid Weight Representation: A Quantization Method Represented with Ternary and Sparse-Large Weights,"[""Jinbae Park"", ""Sung-Ho Bae""]","[""quantized neural networks"", ""centralized quantization"", ""hybrid weight representation"", ""weighted ridge"", ""ternary weight""]",A representation of quantized neural networks with both values and indices. Centralizing weights for the efficiency of the representation.,,,,
H1gax6VtDB,2020,Accept (Talk),False,Contrastive Learning of Structured World Models,"[""Thomas Kipf"", ""Elise van der Pol"", ""Max Welling""]","[""state representation learning"", ""graph neural networks"", ""model-based reinforcement learning"", ""relational learning"", ""object discovery""]",Contrastively-trained Structured World Models (C-SWMs) learn object-oriented state representations and a relational model of an environment from raw pixel input.,1911.12247,stat.ML,2019-11-27 16:10:04+00:00,2020-01-05 13:38:44+00:00
H1gcw1HYPr,2020,Reject,False,AlignNet: Self-supervised Alignment Module,"[""Antonia Creswell"", ""Luis Piloto"", ""David Barrett"", ""Kyriacos Nikiforou"", ""David Raposo"", ""Marta Garnelo"", ""Peter Battaglia"", ""Murray Shanahan""]","[""Graph networks"", ""alignment"", ""objects"", ""relation networks""]","A differentiable model for aligning pre-extracted entity representations with a slot based memory, to which new objects can be added.",,,,
H1gdAC4KDB,2020,Reject,False,Adversarially Robust Generalization Just Requires More Unlabeled Data,"[""Runtian Zhai"", ""Tianle Cai"", ""Di He"", ""Chen Dan"", ""Kun He"", ""John E. Hopcroft"", ""Liwei Wang""]","[""Adversarial Robustness"", ""Semi-supervised Learning""]",,,,,
H1gdF34FvS,2020,Reject,True,Advantage Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning,"[""Xue Bin Peng"", ""Aviral Kumar"", ""Grace Zhang"", ""Sergey Levine""]","[""reinforcement learning"", ""policy search"", ""control""]",We represent a simple off-policy reinforcement learning algorithm that uses standard supervised learning methods as subroutines.,1910.00177,cs.LG,2019-10-01 02:23:38+00:00,2019-10-07 20:23:21+00:00
H1gfFaEYDS,2020,Accept (Poster),False,Adversarially Robust Representations with Smooth Encoders,"[""Taylan Cemgil"", ""Sumedh Ghaisas"", ""Krishnamurthy (Dj) Dvijotham"", ""Pushmeet Kohli""]","[""Adversarial Learning"", ""Robust Representations"", ""Variational AutoEncoder"", ""Wasserstein Distance"", ""Variational Inference""]",We propose a method for computing adversarially robust representations in an entirely unsupervised way.,,,,
H1gfOiAqYm,2019,Accept (Poster),False,Execution-Guided Neural Program Synthesis,"[""Xinyun Chen"", ""Chang Liu"", ""Dawn Song""]",[],,,,,
H1ggKyrYwB,2020,Reject,True,On Incorporating Semantic Prior Knowlegde in Deep Learning Through Embedding-Space Constraints,"[""Damien Teney"", ""Ehsan Abbasnejad"", ""Anton van den Hengel""]","[""regularizers"", ""vision"", ""language"", ""vqa"", ""visual question answering""]",Training method to enforce strict constraints on learned embeddings during supervised training. Applied to visual question answering.,1909.13471,cs.CV,2019-09-30 06:26:09+00:00,2019-11-17 04:07:47+00:00
H1gh_sC9tm,2019,Reject,False,Prior Networks for Detection of Adversarial Attacks,"[""Andrey Malinin"", ""Mark Gales""]","[""Uncertainty"", ""Prior Networks"", ""Adversarial Attacks"", ""Detection""]",We show that it is possible to successfully detect a range of adversarial attacks using measures of uncertainty derived from Prior Networks.,,,,
H1glKiCqtm,2019,Reject,False,The Effectiveness of Pre-Trained Code Embeddings,"[""Ben Trevett"", ""Donald Reay"", ""N. K. Taylor""]","[""machine learning"", ""deep learning"", ""summarization"", ""embeddings"", ""word embeddings"", ""source code"", ""programming languages"", ""programming language processing""]","Researchers exploring natural language processing techniques applied to source code are not using any form of pre-trained embeddings, we show that they should be.",,,,
H1gmHaEKwB,2020,Accept (Poster),True,Data-Independent Neural Pruning via Coresets,"[""Ben Mussay"", ""Margarita Osadchy"", ""Vladimir Braverman"", ""Samson Zhou"", ""Dan Feldman""]","[""coresets"", ""neural pruning"", ""network compression""]","We propose an efficient, provable and data independent method for network compression via neural pruning using coresets of neurons -- a novel construction proposed in this paper.",1907.04018,cs.LG,2019-07-09 07:11:39+00:00,2020-01-03 05:42:38+00:00
H1goBoR9F7,2019,Accept (Poster),False,Dynamic Sparse Graph for Efficient Deep Learning,"[""Liu Liu"", ""Lei Deng"", ""Xing Hu"", ""Maohua Zhu"", ""Guoqi Li"", ""Yufei Ding"", ""Yuan Xie""]","[""Sparsity"", ""compression"", ""training"", ""acceleration""]",We construct dynamic sparse graph via dimension-reduction search to reduce compute and memory cost in both DNN training and inference.,,,,
H1gpET4YDB,2020,Reject,False,Blockwise Self-Attention for Long Document Understanding,"[""Jiezhong Qiu"", ""Hao Ma"", ""Omer Levy"", ""Scott Wen-tau Yih"", ""Sinong Wang"", ""Jie Tang""]","[""BERT"", ""Transformer""]","We present BlockBERT, a lightweight and efficient BERT model that is designed to better modeling long-distance dependencies.",1911.02972,cs.CL,2019-11-07 16:35:53+00:00,2020-11-01 12:48:03+00:00
H1gsz30cKX,2019,Accept (Poster),False,Fixup Initialization: Residual Learning Without Normalization,"[""Hongyi Zhang"", ""Yann N. Dauphin"", ""Tengyu Ma""]","[""deep learning"", ""residual networks"", ""initialization"", ""batch normalization"", ""layer normalization""]",All you need to train deep residual networks is a good initialization; normalization layers are not necessary.,,,,
H1guaREYPr,2020,Accept (Poster),False,From Inference to Generation: End-to-end Fully Self-supervised Generation of Human Face from Speech,"[""Hyeong-Seok Choi"", ""Changdae Park"", ""Kyogu Lee""]","[""Multi-modal learning"", ""Self-supervised learning"", ""Voice profiling"", ""Conditional GANs""]",This paper proposes a method of end-to-end multi-modal generation of human face from speech based on a self-supervised learning framework.,2004.05830,eess.AS,2020-04-13 09:01:49+00:00,2020-04-13 09:01:49+00:00
H1gupiC5KQ,2019,Reject,False,The wisdom of the crowd: reliable deep reinforcement learning through ensembles of Q-functions,"[""Daniel Elliott"", ""Charles Anderson""]","[""reinforcement learning"", ""ensembles"", ""deep learning"", ""neural network""]",Examined how a simple ensemble approach can tackle the biggest challenges in Q-learning.,,,,
H1gx1CNKPH,2020,Reject,False,Augmenting Transformers with KNN-Based Composite Memory,"[""Angela Fan"", ""Claire Gardent"", ""Chloe Braud"", ""Antoine Bordes""]","[""knn"", ""memory-augmented networks"", ""language generation"", ""dialogue""]",augment transformers with KNN-based search modules to read from multi-modal external information,,,,
H1gx3kSKPS,2020,Reject,False,Stein Bridging: Enabling Mutual Reinforcement between Explicit and Implicit Generative Models,"[""Qitian Wu"", ""Rui Gao"", ""Hongyuan Zha""]","[""generative models"", ""generative adversarial networks"", ""energy models""]",,,,,
H1gy1erYDH,2020,Reject,False,CaptainGAN: Navigate Through Embedding Space For Better Text Generation,"[""Chun-Hsing Lin"", ""Alvin Chiang"", ""Chi-Liang Liu"", ""Chien-Fu Lin"", ""Po-Hsien Chu"", ""Siang-Ruei Wu"", ""Yi-En Tsai"", ""Chung-Yang (Ric) Huang""]","[""Generative Adversarial Network"", ""Text Generation"", ""Straight-Through Estimator""]",An effective gradient-based method for training a text generating GAN,,,,
H1gyy1BtDS,2020,Reject,False,An Information Theoretic Approach to Distributed Representation Learning,"[""Abdellatif Zaidi"", ""Inaki Estella Aguerri""]","[""Information Bottleneck"", ""Distributed Learning""]",,,,,
H1gzR2VKDH,2020,Accept (Poster),True,Hierarchical Foresight: Self-Supervised Learning of Long-Horizon Tasks via Visual Subgoal Generation,"[""Suraj Nair"", ""Chelsea Finn""]","[""video prediction"", ""reinforcement learning"", ""planning""]","Hierarchical visual foresight learns to generate visual subgoals that break down long-horizon tasks into subtasks, using only self-supervision.",1909.05829,cs.LG,2019-09-12 17:36:45+00:00,2019-09-12 17:36:45+00:00
H1gz_nNYDS,2020,Reject,True,AutoSlim: Towards One-Shot Architecture Search for Channel Numbers,"[""Jiahui Yu"", ""Thomas Huang""]","[""AutoSlim"", ""Neural Architecture Search"", ""Efficient Networks"", ""Network Pruning""]","We present an automated approach to search the number of channels in a neural network to achieve better accuracy under constrained resources (e.g., FLOPs, latency, memory footprint or model size).",1903.11728,cs.CV,2019-03-27 23:17:28+00:00,2019-06-01 03:19:54+00:00
H1gza2NtwH,2020,Reject,False,Towards understanding the true loss surface of deep neural networks using random matrix theory and iterative spectral methods,"[""Diego Granziol"", ""Timur Garipov"", ""Dmitry Vetrov"", ""Stefan Zohren"", ""Stephen Roberts"", ""Andrew Gordon Wilson""]","[""Random Matrix theory"", ""deep learning"", ""deep learning theory"", ""hessian eigenvalues"", ""true risk""]",Understanding the neural network Hessian eigenvalues under the data generating distribution.,,,,
H1hoFU9xe,2017,Reject,False,Generative Adversarial Networks for Image Steganography,"[""Denis Volkhonskiy"", ""Boris Borisenko"", ""Evgeny Burnaev""]","[""Computer vision"", ""Deep learning"", ""Unsupervised Learning"", ""Applications"", ""Supervised Learning""]",We consider a new type of GAN model and apply it to secure image steganography,,,,
H1kG7GZAW,2018,Accept (Poster),False,Variational Inference of Disentangled Latent Concepts from Unlabeled Observations,"[""Abhishek Kumar"", ""Prasanna Sattigeri"", ""Avinash Balakrishnan""]","[""disentangled representations"", ""variational inference""]",We propose a variational inference based approach for encouraging the inference of disentangled latents. We also propose a new metric for quantifying disentanglement. ,,,,
H1kMMmb0-,2018,Reject,False,Sequential Coordination of Deep Models for Learning Visual Arithmetic,"[""Eric Crawford"", ""Guillaume Rabusseau"", ""Joelle Pineau""]","[""reinforcement learning"", ""pretrained"", ""deep learning"", ""perception"", ""algorithmic""]",We use reinforcement learning to train an agent to solve a set of visual arithmetic tasks using provided pre-trained perceptual modules and transformations of internal representations created by those modules.,,,,
H1kjdOYlx,2017,Invite to Workshop Track,False,Modular Multitask Reinforcement Learning with Policy Sketches,"[""Jacob Andreas"", ""Dan Klein"", ""Sergey Levine""]","[""Reinforcement Learning"", ""Transfer Learning""]",Learning multitask deep hierarchical policies with guidance from symbolic policy sketches,,,,
H1l-02VKPB,2020,Reject,False,Topology-Aware Pooling via Graph Attention,"[""Hongyang Gao"", ""Shuiwang Ji""]",[],,,,,
H1l-SjA5t7,2019,Reject,False,Explicit Information Placement on Latent Variables using Auxiliary Generative Modelling Task,"[""Nat Dilokthanakul"", ""Nick Pawlowski"", ""Murray Shanahan""]","[""disentanglement"", ""vae"", ""clustering"", ""prior imposition"", ""deep generative models""]",We propose a method that can explicitly place information into a specific subset of the latent variables in deep generative models.  We demonstrate the use of the method in a task of disentangling global structure from local features in images.  ,,,,
H1l0O6EYDH,2020,Reject,True,A NEW POINTWISE CONVOLUTION IN DEEP NEURAL NETWORKS THROUGH EXTREMELY FAST AND NON PARAMETRIC TRANSFORMS,"[""Joonhyun Jeong"", ""Sung-Ho Bae""]","[""Pointwise Convolution"", ""Discrete Walsh-Hadamard Transform"", ""Discrete Cosine-Transform""]",We introduce new pointwise convolution layers equipped with extremely fast conventional transforms in deep neural network.,1906.12172,cs.CV,2019-06-25 10:47:08+00:00,2019-06-25 10:47:08+00:00
H1l2mxHKvr,2020,Reject,False,Few-Shot Few-Shot Learning and the role of Spatial Attention,"[""Yann Lifchitz"", ""Yannis Avrithis"", ""Sylvaine Picard""]","[""few-shot learning"", ""spatial attention""]",We study a new problem where a pretrained model is adapted for few-shot learning using limited base class data and introduce a spatial attention mechanism for this task.,2002.07522,cs.CV,2020-02-18 12:32:01+00:00,2020-02-18 12:32:01+00:00
H1l3s6NtvH,2020,Reject,False,A Bayes-Optimal View on Adversarial Examples,"[""Eitan Richardson"", ""Yair Weiss""]","[""Adversarial Examples"", ""Generative Models""]","We show analytically and empirically that the Bayes-optimal classifiers are, in some settings, vulnerable to adversarial examples. We then show that even when the optimal classifier is robust, trained CNNs are vulnerable.",,,,
H1l7bnR5Ym,2019,Accept (Poster),False,ProbGAN: Towards Probabilistic GAN with Theoretical Guarantees,"[""Hao He"", ""Hao Wang"", ""Guang-He Lee"", ""Yonglong Tian""]","[""Generative Adversarial Networks"", ""Bayesian Deep Learning"", ""Mode Collapse"", ""Inception Score"", ""Generator"", ""Discriminator"", ""CIFAR-10"", ""STL-10"", ""ImageNet""]",A novel probabilistic treatment for GAN with theoretical guarantee.,,,,
H1l8sz-AW,2018,Reject,False,Improving generalization by regularizing in $L^2$ function space,"[""Ari S Benjamin"", ""Konrad Kording""]","[""natural gradient"", ""generalization"", ""optimization"", ""function space"", ""Hilbert""]","It's important to consider optimization in function space, not just parameter space. We introduce a learning rule that reduces distance traveled in function space, just like SGD limits distance traveled in parameter space.",,,,
H1lADsCcFQ,2019,Reject,False,LEARNING ADVERSARIAL EXAMPLES WITH RIEMANNIAN GEOMETRY,"[""Shufei Zhang"", ""Kaizhu Huang"", ""Rui Zhang"", ""Amir Hussain""]","[""Adversarial training"", ""Adversarial examples"", ""Riemannian Geometry"", ""Machine Learning"", ""Deep Learning""]",,,,,
H1lBYCEFDB,2020,Reject,True,A Coordinate-Free Construction of Scalable Natural Gradient,"[""Kevin Luk"", ""Roger Grosse""]","[""Natural gradient"", ""second-order optimization"", ""K-FAC"", ""parameterization invariance"", ""deep learning""]",We explicitly construct a Riemannian metric under which the natural gradient matches the K-FAC update; exact affine invariances follows immediately.,1808.10340,cs.LG,2018-08-30 15:06:03+00:00,2018-08-30 15:06:03+00:00
H1lBj2VFPS,2020,Accept (Poster),False,Linear Symmetric Quantization of Neural Networks for Low-precision Integer Hardware,"[""Xiandong Zhao"", ""Ying Wang"", ""Xuyi Cai"", ""Cheng Liu"", ""Lei Zhang""]","[""quantization"", ""integer-arithmetic-only DNN accelerator"", ""acceleration""]",We introduce an efficient quantization process that allows for performance acceleration on specialized integer-only neural network accelerator.,,,,
H1lC8o0cKX,2019,Reject,False,Unsupervised Emergence of Spatial Structure from Sensorimotor Prediction,"[""Alban Laflaqui\u00e8re"", ""Michael Garcia Ortiz""]","[""spatial perception"", ""grounding"", ""sensorimotor prediction"", ""unsupervised learning"", ""representation learning""]",A practical evaluation of hypotheses previously laid out about the unsupervised emergence of spatial representations from sensorimotor prediction.,,,,
H1lDSCEYPH,2020,Reject,False,Beyond GANs: Transforming without a Target Distribution,"[""Matthew Amodio"", ""David van Dijk"", ""Ruth Montgomery"", ""Guy Wolf"", ""Smita Krishnaswamy""]","[""GAN"", ""domain transfer"", ""computational biology"", ""latent space manipulations""]",A method for learning a transformation between one pair of source/target datasets and applying it a separate source dataset for which there is no target dataset,,,,
H1lDbaVYvH,2020,Reject,False,SMiRL: Surprise Minimizing RL in Entropic Environments,"[""Glen Berseth"", ""Daniel Geng"", ""Coline Devin"", ""Dinesh Jayaraman"", ""Chelsea Finn"", ""Sergey Levine""]","[""intrinsic motivation"", ""reinforcement learning"", ""unsurpervised RL""]",Learning emergent behavior by minimizing Bayesian surprise with RL in natural environments with entropy.,,,,
H1lFZnR5YX,2019,Reject,False,Neural Regression Tree,"[""Wenbo Zhao"", ""Shahan Ali Memon"", ""Bhiksha Raj"", ""Rita Singh""]","[""regression-via-classification"", ""discretization"", ""regression tree"", ""neural model"", ""optimization""]",A novel neural regression tree for optimal discretization in regression-via-classification problems.,,,,
H1lFsREYPS,2020,Reject,False,ASGen: Answer-containing Sentence Generation to Pre-Train Question Generator for Scale-up Data in Question Answering,"[""Akhil Kedia"", ""Sai Chetan Chinthakindi"", ""Seohyun Back"", ""Haejun Lee"", ""Jaegul Choo""]","[""Question Answering"", ""Machine Reading Comprehension"", ""Data Augmentation"", ""Question Generation"", ""Answer Generation""]","We propose Answer-containing Sentence Generation (ASGen), a novel pre-training method for generating synthetic data for machine reading comprehension.",,,,
H1lGHsA9KX,2019,Reject,False,A Resizable Mini-batch Gradient Descent based on a Multi-Armed Bandit,"[""Seong Jin Cho"", ""Sunghun Kang"", ""Chang D. Yoo""]","[""Batch size"", ""Optimization"", ""Mini-batch gradient descent"", ""Multi-armed bandit""]",An optimization algorithm that explores various batch sizes based on probability and automatically exploits successful batch size which minimizes validation loss.,,,,
H1lIzhC9FX,2019,Reject,False,Learning to remember: Dynamic Generative Memory for Continual Learning,"[""Oleksiy Ostapenko"", ""Mihai Puscas"", ""Tassilo Klein"", ""Moin Nabi""]","[""Continual Learning"", ""Catastrophic Forgetting"", ""Dynamic Network Expansion""]",,,,,
H1lJJnR5Ym,2019,Accept (Poster),False,Exploration by random network distillation,"[""Yuri Burda"", ""Harrison Edwards"", ""Amos Storkey"", ""Oleg Klimov""]","[""reinforcement learning"", ""exploration"", ""curiosity""]",A simple exploration bonus is introduced and achieves state of the art performance in 3 hard exploration Atari games.,,,,
H1lJws05K7,2019,Reject,False,On the Selection of Initialization and Activation Function for Deep Neural Networks,"[""Soufiane Hayou"", ""Arnaud Doucet"", ""Judith Rousseau""]","[""Deep Neural Networks"", ""Initialization"", ""Gaussian Processes""]",How to effectively choose Initialization and Activation function for deep neural networks,,,,
H1lK5kBKvr,2020,Reject,False,Semi-supervised 3D Face Reconstruction with Nonlinear Disentangled Representations,"[""Zhongpai Gao"", ""Juyong Zhang"", ""Yudong Guo"", ""Chao Ma"", ""Guangtao Zhai"", ""Xiaokang Yang""]","[""3D face reconstruction"", ""semi-supervised learning"", ""disentangled representation"", ""inverse rendering"", ""graph convolutional networks""]",We train our face reconstruction model with adversarial loss in semi-supervised manner on hybrid batches of unlabeled and labeled face images to exploit the value of large amounts of unlabeled face images from unconstrained photo collections.,,,,
H1lKNp4Fvr,2020,Reject,False,A shallow feature extraction network with a large receptive field for stereo matching tasks,"[""Jianguo Liu"", ""Yunjian Feng"", ""Guo Ji"", ""Fuwu Yan""]","[""stereo matching"", ""feature extraction network"", ""convolution neural network"", ""receptive field""]","We introduced a shallow featrue extraction network with a large receptive field for stereo matching tasks, which uses a simple structure to get better performance.",,,,
H1lK_lBtvS,2020,Accept (Poster),False,Classification-Based Anomaly Detection for General Data,"[""Liron Bergman"", ""Yedid Hoshen""]","[""anomaly detection""]","Anomaly detection method that uses: openset techniques for better generalization, random-transformation classification for non-image data.",2005.02359,cs.LG,2020-05-05 17:44:40+00:00,2020-05-05 17:44:40+00:00
H1lKd6NYPS,2020,Reject,False,Online Meta-Critic Learning for Off-Policy Actor-Critic Methods,"[""Wei Zhou"", ""Yiying Li"", ""Yongxin Yang"", ""Huaimin Wang"", ""Timothy M. Hospedales""]","[""off-policy actor-critic"", ""reinforcement learning"", ""meta-learning""]","We present Meta-Critic, an auxiliary critic module for off-policy actor-critic methods that can be meta-learned online during single task learning.",2003.05334,cs.LG,2020-03-11 14:39:49+00:00,2020-11-02 04:53:38+00:00
H1lMogrKDH,2020,Reject,False,LEARNING DIFFICULT PERCEPTUAL TASKS WITH HODGKIN-HUXLEY NETWORKS,"[""Alan Lockett"", ""Ankit Patel"", ""Paul Pfaffinger""]","[""conductance-weighted averaging"", ""neural modeling"", ""normalization methods""]",A network of static time Hodgkin-Huxley neurons can perform well on computer vision datasets.,,,,
H1lNPxHKDH,2020,Accept (Poster),True,A Function Space View of Bounded Norm Infinite Width ReLU Nets: The Multivariate Case,"[""Greg Ongie"", ""Rebecca Willett"", ""Daniel Soudry"", ""Nathan Srebro""]","[""inductive bias"", ""regularization"", ""infinite-width networks"", ""ReLU networks""]","We characterize the space of functions realizable as a ReLU network with an unbounded number of units (infinite width), but where the Euclidean norm of the weights is bounded.",1910.01635,cs.LG,2019-10-03 17:56:10+00:00,2019-10-03 17:56:10+00:00
H1lNb0NtPH,2020,Reject,False,DIME: AN INFORMATION-THEORETIC DIFFICULTY MEASURE FOR AI DATASETS,"[""Peiliang Zhang"", ""Huan Wang"", ""Nikhil Naik"", ""Caiming Xiong"", ""Richard Socher""]","[""Information Theory"", ""Fano\u2019s Inequality"", ""Difficulty Measure"", ""Donsker-Varadhan Representation"", ""Theory""]","We extend Fanoâs inequality to the common case of continuous-feature-discrete-label random variables, and design a neural-network based difficulty measure for AI datasets.",,,,
H1lOUeSFvB,2020,Reject,False,Improving Gradient Estimation in Evolutionary Strategies With Past Descent Directions,"[""Florian Meier"", ""Asier Mujika"", ""Marcelo Gauy"", ""Angelika Steger""]","[""Evolutionary Strategies"", ""Surrogate Gradients""]",,,,,
H1lPUiRcYQ,2019,Reject,False,Computing committor functions for the study of rare events using deep learning with importance sampling,"[""Qianxiao Li"", ""Bo Lin"", ""Weiqing Ren""]","[""committor function"", ""rare event"", ""deep learning"", ""importance sampling""]",Computing committor functions for rare events,,,,
H1lQIgrFDS,2020,Reject,False,$\ell_1$ Adversarial Robustness Certificates: a Randomized Smoothing Approach,"[""Jiaye Teng"", ""Guang-He Lee"", ""Yang Yuan""]",[],We derive the first tight $\ell_1$ robustness certificate under isotropic Laplace distributions. ,,,,
H1lQJ1HYwS,2020,Reject,True,Deep amortized clustering,"[""Juho Lee"", ""Yoonho Lee"", ""Yee Whye Teh""]","[""clustering"", ""amortized inference"", ""meta learning"", ""deep learning""]",,1909.13433,cs.LG,2019-09-30 02:35:49+00:00,2019-09-30 02:35:49+00:00
H1lS8oA5YQ,2019,Reject,False,Feature Attribution As Feature Selection,"[""Satoshi Hara"", ""Koichi Ikeno"", ""Tasuku Soma"", ""Takanori Maehara""]","[""feature attribution"", ""feature selection""]",,,,,
H1lTQ1rFvS,2020,Reject,False,R2D2: Reuse & Reduce via Dynamic Weight Diffusion for Training Efficient NLP Models,"[""Yi Tay"", ""Aston Zhang"", ""Shuai Zhang"", ""Alvin Chan"", ""Luu Anh Tuan"", ""Siu Cheung Hui""]","[""Deep Learning"", ""Natural Language Processing""]",Efficient transform layers inspired by Hamilton Products save parameters,,,,
H1lTRJBtwB,2020,Reject,True,Compositional Transfer in Hierarchical Reinforcement Learning,"[""Markus Wulfmeier"", ""Abbas Abdolmaleki"", ""Roland Hafner"", ""Jost Tobias Springenberg"", ""Michael Neunert"", ""Tim Hertweck"", ""Thomas Lampe"", ""Noah Siegel"", ""Nicolas Heess"", ""Martin Riedmiller""]","[""Multitask"", ""Transfer Learning"", ""Reinforcement Learning"", ""Hierarchical Reinforcement Learning"", ""Compositional"", ""Off-Policy""]","We develop a hierarchical, actor-critic algorithm for compositional transfer by sharing policy components and demonstrate component specialization and related direct benefits in multitask domains as well as its adaptation for single tasks.",1906.11228,cs.LG,2019-06-26 17:42:07+00:00,2020-05-19 17:29:06+00:00
H1lTUCVYvH,2020,Reject,False,Rethinking Curriculum Learning With Incremental Labels And Adaptive Compensation,"[""Madan Ravi Ganesh"", ""Jason J. Corso""]","[""Curriculum Learning"", ""Incremental Label Learning"", ""Label Smoothing"", ""Deep Learning""]",A novel approach to curriculum learning by incrementally learning labels and adaptively smoothing labels for mis-classified samples which boost average performance and decreases standard deviation.,2001.04529,cs.CV,2020-01-13 21:00:46+00:00,2020-08-13 16:00:02+00:00
H1lUOsA9Fm,2019,Reject,False,Synthnet: Learning synthesizers end-to-end,"[""Florin Schimbinschi"", ""Christian Walder"", ""Sarah Erfani"", ""James Bailey""]","[""audio"", ""synthesizers"", ""music"", ""convolutional neural networks"", ""generative models"", ""autoregressive models""]","A convolutional autoregressive generative model that generates high fidelity audio, behchmarked on music",,,,
H1lVvgHKDr,2020,Reject,False,Knowledge Transfer via Student-Teacher Collaboration,"[""Tianxiao Gao"", ""Ruiqin Xiong"", ""Zhenhua Liu"", ""Siwei ma"", ""Feng Wu"", ""Tiejun Huang"", ""Wen Gao""]","[""Network Compression and Acceleration"", ""Knowledge Transfer"", ""Student-Teacher Collaboration"", ""Deep Learning.""]",We propose a novel knowledge transfer method which employs a student-teacher collaboration network.,,,,
H1lWzpNKvr,2020,Reject,False,Efficient Multivariate Bandit Algorithm with Path Planning,"[""Keyu Nie"", ""Zezhong Zhang"", ""Ted Tao Yuan"", ""Rong Song"", ""Pauline Berry Burke""]","[""Multivariate Multi-armed Bandit"", ""Monte Carlo Tree Search"", ""Thompson Sampling"", ""Path Planning""]",A novel way utilizing tree models to solve multivariate Multi-Armed Bandit problem.,,,,
H1lXCaVKvS,2020,Reject,False,Frustratingly easy quasi-multitask learning,"[""G\u00e1bor Berend"", ""Norbert Kis-Szab\u00f3""]","[""multitask learning"", ""ensembling""]",We propose a computationally efficient alternative for traditional ensemble learning for neural nets.,,,,
H1lXVJStwB,2020,Reject,False,Dynamic Instance Hardness,"[""Tianyi Zhou"", ""Shengjie Wang"", ""Jeff A. Bilmes""]","[""training dynamics"", ""instance hardness"", ""curriculum learning"", ""neural nets memorization""]",New understanding of training dynamics and metrics of memorization hardness lead to efficient and provable curriculum learning.,,,,
H1lZJpVFvr,2020,Accept (Poster),True,Robust Local Features for Improving the Generalization of Adversarial Training,"[""Chuanbiao Song"", ""Kun He"", ""Jiadong Lin"", ""Liwei Wang"", ""John E. Hopcroft""]","[""adversarial robustness"", ""adversarial training"", ""adversarial example"", ""deep learning""]",We propose a new stream of adversarial training approach called Robust Local Features for Adversarial Training (RLFAT) that significantly improves both the adversarially robust generalization and the standard generalization.,1909.10147,cs.CV,2019-09-23 04:19:34+00:00,2020-02-02 13:54:45+00:00
H1l_0JBYwS,2020,Accept (Spotlight),False,Spectral  Embedding of Regularized Block Models,"[""Nathan De Lara"", ""Thomas Bonald""]","[""Spectral embedding"", ""regularization"", ""block models"", ""clustering""]","Graph regularization forces spectral embedding to focus on the largest clusters, making the representation less sensitive to noise. ",1912.10903,cs.LG,2019-12-23 15:06:54+00:00,2019-12-23 15:06:54+00:00
H1l_gA4KvH,2020,Reject,False,Surrogate-Based Constrained Langevin Sampling With Applications to Optimal Material Configuration Design,"[""Thanh V Nguyen"", ""Youssef Mroueh"", ""Samuel C. Hoffman"", ""Payel Das"", ""Pierre Dognin"", ""Giuseppe Romano"", ""Chinmay Hegde""]","[""Black-box Constrained Langevin sampling"", ""surrogate methods"", ""projected and proximal methods"", ""approximation theory of gradients"", ""nano-porous material configuration design""]",We propose surrogate based Constrained Langevin sampling with application in nano-porous material configuration design.,,,,
H1lac2Vtwr,2020,Reject,True,SesameBERT: Attention for Anywhere,"[""Ta-Chun Su"", ""Hsiang-Chih Cheng""]","[""Natural Language Processing"", ""Deep Learning"", ""Self Attention""]","We proposed SesameBERT, a generalized fine-tuning method that enables the extraction of global information among all layers through Squeeze and Excitation and enriches local information by capturing neighboring contexts via Gaussian blurring.",1910.03176,cs.CL,2019-10-08 02:31:35+00:00,2019-10-08 02:31:35+00:00
H1laeJrKDB,2020,Accept (Poster),False,Controlling generative models with continuous factors of variations,"[""Antoine Plumerault"", ""Herv\u00e9 Le Borgne"", ""C\u00e9line Hudelot""]","[""Generative models"", ""factor of variation"", ""GAN"", ""beta-VAE"", ""interpretable representation"", ""interpretability""]",A model to control the generation of images with GAN and beta-VAE with regard to scale and position of the objects,2001.10238,cs.LG,2020-01-28 10:04:04+00:00,2020-01-28 10:04:04+00:00
H1ldNoC9tX,2019,Reject,False,"Classification from Positive, Unlabeled and Biased Negative Data","[""Yu-Guan Hsieh"", ""Gang Niu"", ""Masashi Sugiyama""]","[""positive-unlabeled learning"", ""dataset shift"", ""empirical risk minimization""]","This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.",,,,
H1ldzA4tPr,2020,Accept (Spotlight),True,Learning Compositional Koopman Operators for Model-Based Control,"[""Yunzhu Li"", ""Hao He"", ""Jiajun Wu"", ""Dina Katabi"", ""Antonio Torralba""]","[""Koopman operators"", ""graph neural networks"", ""compositionality""]",Learning compositional Koopman operators for efficient system identification and model-based control.,1910.08264,cs.LG,2019-10-18 05:11:16+00:00,2020-04-27 17:09:47+00:00
H1leCRNYvS,2020,Reject,False,Hierarchical Bayes Autoencoders,"[""Shuangfei Zhai"", ""Carlos Guestrin"", ""Joshua M. Susskind""]",[],,,,,
H1lefTEKDS,2020,Reject,False,Benchmarking Model-Based Reinforcement Learning,"[""Tingwu Wang"", ""Xuchan Bao"", ""Ignasi Clavera"", ""Jerrick Hoang"", ""Yeming Wen"", ""Eric Langlois"", ""Shunshi Zhang"", ""Guodong Zhang"", ""Pieter Abbeel"", ""Jimmy Ba""]","[""Reinforcement learning"", ""model based Reinforcement learning"", ""Benchmarking""]",Benchmarking Model-Based Reinforcement Learning in continuous control tasks,,,,
H1lfwAVFwr,2020,Reject,False,CAPACITY-LIMITED REINFORCEMENT LEARNING: APPLICATIONS IN DEEP ACTOR-CRITIC METHODS FOR CONTINUOUS CONTROL,"[""Tyler James Malloy"", ""Matthew Riemer"", ""Miao Liu"", ""Tim Klinger"", ""Gerald Tesauro"", ""Chris R. Sims""]","[""Reinforcement Learning"", ""Generalization"", ""Information Theory"", ""Rate-Distortion Theory""]",Applying a limit to the amount of information used to represent policies affords some improvements in generalization in Reinforcement Learning,,,,
H1lhqpEYPr,2020,Accept (Poster),True,Actor-Critic Provably Finds Nash Equilibria of Linear-Quadratic Mean-Field Games,"[""Zuyue Fu"", ""Zhuoran Yang"", ""Yongxin Chen"", ""Zhaoran Wang""]",[],Actor-Critic method with function approximation finds the Nash equilibrium pairs in mean-field games with theoretical guarantee. ,1910.07498,math.OC,2019-10-16 17:59:20+00:00,2019-10-16 17:59:20+00:00
H1livgrFvr,2020,Reject,False,Out-of-Distribution Image Detection Using the Normalized Compression Distance,"[""Sehun Yu"", ""Donga Lee"", ""Hwanjo Yu""]","[""Out-of-Distribution Detection"", ""Normalized Compression Distance"", ""Convolutional Neural Networks""]",We propose MALCOM which utilizes both the global average and spatial pattern of the feature maps to accurately identify out-of-distribution samples. ,,,,
H1lj0nNFwB,2020,Accept (Poster),True,The Implicit Bias of Depth: How Incremental Learning Drives Generalization,"[""Daniel Gissin"", ""Shai Shalev-Shwartz"", ""Amit Daniely""]","[""gradient flow"", ""gradient descent"", ""implicit regularization"", ""implicit bias"", ""generalization"", ""optimization"", ""quadratic network"", ""matrix sensing""]","We study the sparsity-inducing bias of deep models, caused by their learning dynamics.",1909.12051,cs.LG,2019-09-26 12:38:41+00:00,2019-12-28 10:44:16+00:00
H1lkYkrKDB,2020,Reject,False,UNIVERSAL MODAL EMBEDDING OF DYNAMICS IN VIDEOS AND ITS APPLICATIONS,"[""Israr Ul Haq"", ""Yoshinobu Kawahara""]","[""Non-linear dynamics"", ""Convolutional Autoencoder"", ""Foreground modeling"", ""Video classification"", ""Dynamic mode decomposition""]",Dynamic information extraction in multivariate time series data,,,,
H1lma24tPB,2020,Accept (Talk),False,Principled Weight Initialization for Hypernetworks,"[""Oscar Chang"", ""Lampros Flokas"", ""Hod Lipson""]","[""hypernetworks"", ""initialization"", ""optimization"", ""meta-learning""]",The first principled weight initialization method for hypernetworks,,,,
H1lmhaVtvr,2020,Accept (Poster),True,Dynamical Distance Learning for Semi-Supervised and Unsupervised Skill Discovery,"[""Kristian Hartikainen"", ""Xinyang Geng"", ""Tuomas Haarnoja"", ""Sergey Levine""]","[""reinforcement learning"", ""semi-supervised learning"", ""unsupervised learning"", ""robotics"", ""deep learning""]",We show how to automatically learn dynamical distances in reinforcement learning setting and use them to provide well-shaped reward functions for reaching new goals.,1907.08225,cs.LG,2019-07-18 18:07:47+00:00,2020-02-14 10:16:54+00:00
H1lmyRNFvr,2020,Accept (Poster),False,Augmenting Genetic Algorithms with Deep Neural Networks for Exploring the Chemical Space,"[""AkshatKumar Nigam"", ""Pascal Friederich"", ""Mario Krenn"", ""Alan Aspuru-Guzik""]","[""Generative model"", ""Chemical Space"", ""Inverse Molecular Design""]",Tackling inverse design via genetic algorithms augmented with deep neural networks. ,,,,
H1lnJ2Rqt7,2019,Reject,False,LARGE BATCH SIZE TRAINING OF NEURAL NETWORKS WITH ADVERSARIAL TRAINING AND SECOND-ORDER INFORMATION,"[""Zhewei Yao"", ""Amir Gholami"", ""Kurt Keutzer"", ""Michael Mahoney""]","[""adversarial training"", ""large batch size"", ""neural network""]",Large batch size training using adversarial training and second order information,,,,
H1lo3sC9KX,2019,Reject,False,Asynchronous SGD without gradient delay for efficient distributed training,"[""Roman Talyansky"", ""Pavel Kisilev"", ""Zach Melamed"", ""Natan Peterfreund"", ""Uri Verner""]","[""SGD"", ""distributed asynchronous training"", ""deep learning"", ""optimisation""]",A method for an efficient asynchronous distributed training of deep learning models along with theoretical regret bounds.,,,,
H1loF2NFwr,2020,Accept (Poster),True,Evaluating The Search Phase of Neural Architecture Search,"[""Kaicheng Yu"", ""Christian Sciuto"", ""Martin Jaggi"", ""Claudiu Musat"", ""Mathieu Salzmann""]","[""Neural architecture search"", ""parameter sharing"", ""random search"", ""evaluation framework""]",We empirically disprove a fundamental hypothesis of the widely-adopted weight sharing strategy in neural architecture search and explain why the state-of-the-arts NAS algorithms performs similarly to random search.,1902.08142,cs.LG,2019-02-21 17:11:56+00:00,2019-11-22 17:07:59+00:00
H1lqZhRcFm,2019,Accept (Poster),False,Unsupervised Learning of the Set of Local Maxima,"[""Lior Wolf"", ""Sagie Benaim"", ""Tomer Galanti""]","[""Unsupervised Learning"", ""One-class Classification"", ""Multi-player Optimization""]",,,,,
H1ls_eSKPH,2020,Reject,False,Overcoming Catastrophic Forgetting via Hessian-free Curvature Estimates,"[""Leonid Butyrev"", ""Georgios Kontes"", ""Christoffer L\u00f6ffler"", ""Christopher Mutschler""]","[""catastrophic forgetting"", ""multi-task learning"", ""continual learning""]",This paper provides an approach to address catastrophic forgetting via Hessian-free curvature estimates,,,,
H1ltQ3R9KQ,2019,Reject,False,Causal Reasoning from Meta-reinforcement learning,"[""Ishita Dasgupta"", ""Jane Wang"", ""Silvia Chiappa"", ""Jovana Mitrovic"", ""Pedro Ortega"", ""David Raposo"", ""Edward Hughes"", ""Peter Battaglia"", ""Matthew Botvinick"", ""Zeb Kurth-Nelson""]","[""meta-learning"", ""causal reasoning"", ""deep reinforcement learning"", ""artificial intelligence""]",meta-learn a learning algorithm capable of causal reasoning,1901.08162,cs.LG,2019-01-23 23:03:59+00:00,2019-01-23 23:03:59+00:00
H1lug3R5FX,2019,Reject,False,On the Geometry of Adversarial Examples,"[""Marc Khoury"", ""Dylan Hadfield-Menell""]","[""adversarial examples"", ""high-dimensional geometry""]",We present a geometric framework for proving robustness guarantees and highlight the importance of codimension in adversarial examples. ,,,,
H1lxVyStPH,2020,Accept (Poster),False,Generalized Convolutional Forest Networks for Domain Generalization and Visual Recognition,"[""Jongbin Ryu"", ""Gitaek Kwon"", ""Ming-Hsuan Yang"", ""Jongwoo Lim""]",[],,,,,
H1lxeRNYvB,2020,Reject,False,Neural Operator Search,"[""Wei Li"", ""Shaogang Gong"", ""Xiatian Zhu""]","[""deep learning"", ""autoML"", ""neural architecture search"", ""image classification"", ""attention learning"", ""dynamic convolution""]","We propose a novel idea of Neural Operator Search (NOS) that incorporates  additional operators into a NAS search space, searching more advanced architectures with self-calibration. ",,,,
H1lyiaVFwB,2020,Reject,False,DUAL ADVERSARIAL MODEL FOR GENERATING 3D POINT CLOUD,"[""Yuhang Zhang"", ""Zhenwei Miao"", ""Tiebin Mi"", ""Robert Caiming Qiu""]","[""point cloud"", ""generative"", ""latent space""]",,,,,
H1mCp-ZRZ,2018,Accept (Poster),False,Action-dependent Control Variates for Policy Optimization via Stein Identity,"[""Hao Liu*"", ""Yihao Feng*"", ""Yi Mao"", ""Dengyong Zhou"", ""Jian Peng"", ""Qiang Liu""]","[""reinforcement learning"", ""control variates"", ""sample efficiency"", ""variance reduction""]",,,,,
H1meywxRW,2018,Accept (Poster),False,DCN+: Mixed Objective And Deep Residual Coattention for Question Answering,"[""Caiming Xiong"", ""Victor Zhong"", ""Richard Socher""]","[""question answering"", ""deep learning"", ""natural language processing"", ""reinforcement learning""]","We introduce the DCN+ with deep residual coattention and mixed-objective RL, which achieves state of the art performance on the Stanford Question Answering Dataset.",,,,
H1oRQDqlg,2017,Invite to Workshop Track,False,Learning to Draw Samples: With Application to Amortized MLE for Generative Adversarial Learning,"[""Dilin Wang"", ""Qiang Liu""]","[""Unsupervised Learning""]",,,,,
H1oyRlYgg,2017,Accept (Oral),False,On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima,"[""Nitish Shirish Keskar"", ""Dheevatsa Mudigere"", ""Jorge Nocedal"", ""Mikhail Smelyanskiy"", ""Ping Tak Peter Tang""]","[""Deep learning"", ""Optimization""]","We present numerical evidence for the argument that if deep networks are trained using large (mini-)batches, they converge to sharp minimizers, and these minimizers have poor generalization properties. ",,,,
H1pri9vTZ,2018,Reject,False,Deep Function Machines: Generalized Neural Networks for Topological Layer Expression,"[""William H. Guss""]","[""deep learning theory"", ""infinite neural networks"", ""topology""]",,,,,
H1q-TM-AW,2018,Accept (Poster),False,A DIRT-T Approach to Unsupervised Domain Adaptation,"[""Rui Shu"", ""Hung Bui"", ""Hirokazu Narui"", ""Stefano Ermon""]","[""domain adaptation"", ""unsupervised learning"", ""semi-supervised learning""]",SOTA on unsupervised domain adaptation by leveraging the cluster assumption.,,,,
H1rRWl-Cb,2018,Reject,False,An information-theoretic analysis of deep latent-variable models,"[""Alex Alemi"", ""Ben Poole"", ""Ian Fischer"", ""Josh Dillon"", ""Rif A. Saurus"", ""Kevin Murphy""]","[""information theory"", ""generative models"", ""latent variable models"", ""variational autoencoders""]",We provide an information theoretic and experimental analysis of state-of-the-art variational autoencoders.,,,,
H1sUHgb0Z,2018,Accept (Poster),False,Learning From Noisy Singly-labeled Data,"[""Ashish Khetan"", ""Zachary C. Lipton"", ""Animashree Anandkumar""]","[""crowdsourcing"", ""noisy annotations"", ""deep leaerning""]",A new approach for learning a model from noisy crowdsourced annotations.,,,,
H1srNebAZ,2018,Reject,False,Discovering the mechanics of hidden neurons,"[""Simon Carbonnelle"", ""Christophe De Vleeschouwer""]","[""deep learning"", ""experimental analysis"", ""hidden neurons""]",We report experiments providing strong evidence that a neuron behaves like a binary classifier during training and testing,,,,
H1tSsb-AW,2018,Accept (Oral),False,Variance Reduction for Policy Gradient with Action-Dependent Factorized Baselines,"[""Cathy Wu"", ""Aravind Rajeswaran"", ""Yan Duan"", ""Vikash Kumar"", ""Alexandre M Bayen"", ""Sham Kakade"", ""Igor Mordatch"", ""Pieter Abbeel""]","[""reinforcement learning"", ""policy gradient"", ""variance reduction"", ""baseline"", ""control variates""]",Action-dependent baselines can be bias-free and yield greater variance reduction than state-only dependent baselines for policy gradient methods.,,,,
H1u8fMW0b,2018,Reject,False,Toward predictive machine learning for active vision,"[""Emmanuel Dauc\u00e9""]","[""active inference"", ""predictive coding"", ""motor control""]",Pros and cons of saccade-based computer vision under a predictive coding perspective,,,,
H1uP7ebAW,2018,Reject,False,Learning to diagnose from scratch by exploiting dependencies among labels,"[""Li Yao"", ""Eric Poblenz"", ""Dmitry Dagunts"", ""Ben Covington"", ""Devon Bernard"", ""Kevin Lyman""]","[""medical diagnosis"", ""medical imaging"", ""multi-label classification""]",we present the state-of-the-art results of using neural networks to diagnose chest x-rays,,,,
H1uR4GZRZ,2018,Accept (Poster),False,Stochastic Activation Pruning for Robust Adversarial Defense,"[""Guneet S. Dhillon"", ""Kamyar Azizzadenesheli"", ""Zachary C. Lipton"", ""Jeremy D. Bernstein"", ""Jean Kossaifi"", ""Aran Khanna"", ""Animashree Anandkumar""]",[],,,,,
H1vCXOe0b,2018,Reject,False,Interpreting Deep Classification Models With Bayesian Inference,"[""Hanshu Yan"", ""Jiashi Feng""]",[],,,,,
H1vEXaxA-,2018,Accept (Poster),True,Emergent Translation in Multi-Agent Communication,"[""Jason Lee"", ""Kyunghyun Cho"", ""Jason Weston"", ""Douwe Kiela""]",[],,1710.06922,cs.CL,2017-10-12 00:37:27+00:00,2018-04-11 03:22:49+00:00
H1wgawqxl,2017,Invite to Workshop Track,False,Nonparametrically Learning Activation Functions in Deep Neural Nets,"[""Carson Eisenach"", ""Zhaoran Wang"", ""Han Liu""]",[],A new class of nonparametric activation functions for deep learning with theoretical guarantees for generalization error.,,,,
H1wt9x-RW,2018,Reject,False,Interpretable and Pedagogical Examples,"[""Smitha Milli"", ""Pieter Abbeel"", ""Igor Mordatch""]","[""machine teaching"", ""interpretability"", ""communication"", ""cognitive science""]","We show that training a student and teacher network iteratively, rather than jointly, can produce emergent, interpretable teaching strategies.",,,,
H1x-3xSKDr,2020,Reject,True,Batch Normalization is a Cause of Adversarial Vulnerability,"[""Angus Galloway"", ""Anna Golubeva"", ""Thomas Tanay"", ""Medhat Moussa"", ""Graham W. Taylor""]","[""batch normalization"", ""adversarial examples"", ""robustness""]",Batch normalization reduces robustness at test-time to common corruptions and adversarial examples.,1905.02161,cs.LG,2019-05-06 17:21:08+00:00,2019-05-29 22:08:08+00:00
H1x-pANtDB,2020,Reject,False,A closer look at network resolution for efficient network design,"[""Taojiannan Yang"", ""Sijie Zhu"", ""Yan Shen"", ""Mi Zhang"", ""Andrew Willis"", ""Chen Chen""]","[""deep learning"", ""computer vision"", ""efficient network design"", ""dynamic neural networks""]",,,,,
H1x-x309tm,2019,Accept (Poster),False,On the Convergence of A Class of Adam-Type Algorithms  for Non-Convex Optimization,"[""Xiangyi Chen"", ""Sijia Liu"", ""Ruoyu Sun"", ""Mingyi Hong""]","[""nonconvex optimization"", ""Adam"", ""convergence analysis""]","We analyze convergence of Adam-type algorithms and provide mild sufficient conditions to guarantee their convergence, we also show  violating the conditions can makes an algorithm diverge.",,,,
H1x1noAqKX,2019,Reject,False,Discriminative out-of-distribution detection for semantic segmentation,"[""Petra Bevandi\u0107"", ""Sini\u0161a \u0160egvi\u0107"", ""Ivan Kre\u0161o"", ""Marin Or\u0161i\u0107""]","[""out-of-distribution detection"", ""semantic segmentation""]",We present a novel approach for detecting out-of-distribution pixels in semantic segmentation.,,,,
H1x3SnAcYQ,2019,Reject,False,A Better Baseline for Second Order Gradient Estimation in Stochastic Computation Graphs,"[""Jingkai Mao"", ""Jakob Foerster"", ""Tim Rockt\u00e4schel"", ""Gregory Farquhar"", ""Maruan Al-Shedivat"", ""Shimon Whiteson""]","[""Reinforcement learning"", ""meta-learning"", ""higher order derivatives"", ""gradient estimation"", ""stochastic computation graphs""]","We extend the DiCE formalism of higher order gradient estimation with a new baseline for variance reduction of second order derivatives, improving sample efficiency by two orders of magnitude. ",,,,
H1x5wRVtvS,2020,Accept (Poster),True,Variational Hetero-Encoder Randomized GANs for Joint Image-Text Modeling,"[""Hao Zhang"", ""Bo Chen"", ""Long Tian"", ""Zhengjue Wang"", ""Mingyuan Zhou""]","[""Deep topic model"", ""image generation"", ""text generation"", ""raster-scan-GAN"", ""zero-shot learning""]","A novel Bayesian deep learning framework that captures and relates hierarchical semantic and visual concepts, performing well on a variety of image and text modeling and generation tasks.",1905.08622,cs.CV,2019-05-18 13:58:12+00:00,2020-01-07 20:51:34+00:00
H1x8b6EtvH,2020,Reject,True,Network Pruning for Low-Rank Binary Index,"[""Dongsoo Lee"", ""Se Jung Kwon"", ""Byeongwook Kim"", ""Parichay Kapoor"", ""Gu-Yeon Wei""]","[""Pruning"", ""Model compression"", ""Index compression"", ""low-rank"", ""binary matrix decomposition""]",We propose a new pruning technique to generate a low-rank binary index matrix.,1905.05686,cs.LG,2019-05-14 16:00:41+00:00,2019-05-14 16:00:41+00:00
H1x9004YPr,2020,Reject,False,Contextual Temperature for Language Modeling,"[""Pei-Hsin Wang"", ""Sheng-Iou Hsieh"", ""Shieh-Chieh Chang"", ""Jia-Yu Pan"", ""Yu-Ting Chen"", ""Wei Wei"", ""Da-Cheng Juan""]","[""natural language processing"", ""language modeling"", ""sequence modeling"", ""temperature scaling""]","We propose contextual temperature, a mechanism that enables temperature scaling for language models based on the context of each word. Contextual temperature co-adapts with model parameters and can be learned during training.",,,,
H1xAH2RqK7,2019,Reject,False,Generative Adversarial Models for Learning Private and Fair Representations,"[""Chong Huang"", ""Xiao Chen"", ""Peter Kairouz"", ""Lalitha Sankar"", ""Ram Rajagopal""]","[""Data Privacy"", ""Fairness"", ""Adversarial Learning"", ""Generative Adversarial Networks"", ""Minimax Games"", ""Information Theory""]","We present Generative Adversarial Privacy and Fairness (GAPF), a data-driven framework for learning private and fair representations with certified privacy/fairness guarantees",,,,
H1xD9sR5Fm,2019,Accept (Poster),False,Minimum Divergence vs. Maximum Margin: an Empirical Comparison on Seq2Seq Models,"[""Huan Zhang"", ""Hai Zhao""]","[""sequence to sequence"", ""training criteria""]",,,,,
H1xEtoRqtQ,2019,Reject,False,Scaling shared model governance via model splitting,"[""Miljan Martic"", ""Jan Leike"", ""Andrew Trask"", ""Matteo Hessel"", ""Shane Legg"", ""Pushmeet Kohli""]","[""deep learning"", ""reinforcement learning"", ""multi-party computation""]",We study empirically how hard it is to recover missing parts of trained models,,,,
H1xEwsR9FX,2019,Reject,False,Convolutional CRFs for Semantic Segmentation,"[""Marvin Teichmann"", ""Roberto Cipolla""]","[""conditional random fields"", ""semantic segmentation"", ""computer vision"", ""structured learning""]","We propose Convolutional CRFs a fast, powerful and trainable alternative to Fully Connected CRFs.",,,,
H1xFWgrFPS,2020,Accept (Spotlight),True,Explanation  by Progressive  Exaggeration,"[""Sumedha Singla"", ""Brian Pollack"", ""Junxiang Chen"", ""Kayhan Batmanghelich""]","[""Explain"", ""deep learning"", ""black box"", ""GAN"", ""counterfactual""]","A method to explain a classifier, by generating visual perturbation of an image by exaggerating  or diminishing the semantic features that the classifier associates with a target label.",1911.00483,cs.LG,2019-11-01 17:48:24+00:00,2020-02-10 20:32:23+00:00
H1xJhJStPS,2020,Reject,False,Equilibrium Propagation with Continual Weight Updates,"[""Maxence Ernoult"", ""Julie Grollier"", ""Damien Querlioz"", ""Yoshua Bengio"", ""Benjamin Scellier""]","[""Biologically Plausible Neural Networks"", ""Equilibrium Propagation""]","We propose a continual version of Equilibrium Propagation, where neuron and synapse dynamics occur simultaneously throughout the second phase, with theoretical guarantees and numerical simulations.",2005.04168,cs.NE,2020-04-29 14:54:30+00:00,2020-04-29 14:54:30+00:00
H1xJjlbAZ,2018,Reject,False,INTERPRETATION OF NEURAL NETWORK IS FRAGILE,"[""Amirata Ghorbani"", ""Abubakar Abid"", ""James Zou""]","[""Adversarial Attack"", ""Interpretability"", ""Saliency Map"", ""Influence Function"", ""Robustness"", ""Machine Learning"", ""Deep Learning"", ""Neural Network""]",Can we trust a neural network's explanation for its prediction? We examine the robustness of several popular notions of interpretability of neural networks including saliency maps and influence functions and design adversarial examples against them.,,,,
H1xKBCEYDr,2020,Reject,True,Black-box Adversarial Attacks with Bayesian Optimization,"[""Satya Narayan Shukla"", ""Anit Kumar Sahu"", ""Devin Willmott"", ""J. Zico Kolter""]","[""black-box adversarial attacks"", ""bayesian optimization""]",We show that a relatively simple black-box adversarial attack scheme using Bayesian optimization and dimension upsampling  is preferable to existing methods when the number of available queries is very low.,1909.13857,cs.LG,2019-09-30 17:35:02+00:00,2019-09-30 17:35:02+00:00
H1xPR3NtPB,2020,Accept (Poster),False,Are Pre-trained Language Models Aware of Phrases? Simple but Strong Baselines for Grammar Induction,"[""Taeuk Kim"", ""Jihun Choi"", ""Daniel Edmiston"", ""Sang-goo Lee""]",[],,2002.00737,cs.CL,2020-01-30 11:06:49+00:00,2020-01-30 11:06:49+00:00
H1xQSjCqFQ,2019,Reject,False,Excitation Dropout: Encouraging Plasticity in Deep Neural Networks,"[""Andrea Zunino"", ""Sarah Adel Bargal"", ""Pietro Morerio"", ""Jianming Zhang"", ""Stan Sclaroff"", ""Vittorio Murino""]","[""Dropout"", ""Saliency"", ""Deep Neural Networks""]",We propose a guided dropout regularizer for deep networks based on the evidence of a network prediction.,,,,
H1xQVn09FX,2019,Accept (Poster),False,GANSynth: Adversarial Neural Audio Synthesis,"[""Jesse Engel"", ""Kumar Krishna Agrawal"", ""Shuo Chen"", ""Ishaan Gulrajani"", ""Chris Donahue"", ""Adam Roberts""]","[""GAN"", ""Audio"", ""WaveNet"", ""NSynth"", ""Music""]",High-quality audio synthesis with GANs,,,,
H1xSNiRcF7,2019,Accept (Oral),False,Smoothing the Geometry of Probabilistic Box Embeddings,"[""Xiang Li"", ""Luke Vilnis"", ""Dongxu Zhang"", ""Michael Boratko"", ""Andrew McCallum""]","[""embeddings"", ""order embeddings"", ""knowledge graph embedding"", ""relational learning""]",Improve hierarchical embedding models using kernel smoothing,,,,
H1xSOTVtvH,2020,Reject,False,Robust Domain Randomization for Reinforcement Learning,"[""Reda Bahi Slaoui"", ""William R. Clements"", ""Jakob N. Foerster"", ""S\u00e9bastien Toth""]","[""reinforcement learning"", ""domain randomization"", ""domain adaptation""]",We produce reinforcement learning agents that generalize well to a wide range of environments using a novel regularization technique.,,,,
H1xTup4KPr,2020,Reject,True,Needles in Haystacks: On Classifying Tiny Objects in Large Images,"[""Nick Pawlowski"", ""Suvrat Bhooshan"", ""Nicolas Ballas"", ""Francesco Ciompi"", ""Ben Glocker"", ""Michal Drozdzal""]","[""computer vision"", ""CNNs"", ""small objects"", ""low signal-to-noise image classification""]","We study low- and very-low-signal-to-noise classification scenarios, where objects that correlate with class label occupy tiny proportion of the entire image (e.g. medical or hyperspectral imaging).",1908.06037,cs.CV,2019-08-16 15:42:55+00:00,2020-01-06 13:13:07+00:00
H1xaJn05FQ,2019,Accept (Poster),False,Sliced Wasserstein Auto-Encoders,"[""Soheil Kolouri"", ""Phillip E. Pope"", ""Charles E. Martin"", ""Gustavo K. Rohde""]","[""optimal transport"", ""Wasserstein distances"", ""auto-encoders"", ""unsupervised learning""]",In this paper we use the sliced-Wasserstein distance to shape the latent distribution of an auto-encoder into any samplable prior distribution. ,,,,
H1xauR4Kvr,2020,Reject,False,The Discriminative Jackknife: Quantifying Uncertainty in Deep Learning via Higher-Order Influence Functions,"[""Ahmed M. Alaa"", ""Mihaela van der Schaar""]",[],,2007.13481,cs.LG,2020-06-29 13:36:52+00:00,2020-06-29 13:36:52+00:00
H1xipsA5K7,2019,Accept (Poster),False,Learning Two-layer Neural Networks with Symmetric Inputs,"[""Rong Ge"", ""Rohith Kuditipudi"", ""Zhize Li"", ""Xiang Wang""]","[""Neural Network"", ""Optimization"", ""Symmetric Inputs"", ""Moment-of-moments""]",We give an algorithm for learning a two-layer neural network with symmetric input distribution. ,,,,
H1xk8jAqKQ,2019,Reject,False,Backplay: 'Man muss immer umkehren',"[""Cinjon Resnick"", ""Roberta Raileanu"", ""Sanyam Kapoor"", ""Alexander Peysakhovich"", ""Kyunghyun Cho"", ""Joan Bruna""]","[""Exploration"", ""Games"", ""Pommerman"", ""Bomberman"", ""AI"", ""Reinforcement Learning"", ""Machine Learning""]","Learn by working backwards from a single demonstration, even an inefficient one, and progressively have the agent do more of the solving itself.",,,,
H1xmqiAqFm,2019,Reject,False,Investigating CNNs' Learning Representation under label noise,"[""Ryuichiro Hataya"", ""Hideki Nakayama""]","[""learning with noisy labels"", ""deep learning"", ""convolutional neural networks""]","Are CNNs robust or fragile to label noise? Practically, robust.",,,,
H1xpe2C5Km,2019,Reject,False,Trace-back along capsules and its application on semantic segmentation  		,"[""Tao Sun"", ""Zhewei Wang"", ""C. D. Smith"", ""Jundong Liu""]","[""capsule"", ""capsule network"", ""semantic segmentation"", ""FCN""]","A capsule-based semantic segmentation, in which the probabilities of the class labels are traced back through capsule pipeline. ",,,,
H1xsSjC9Ym,2019,Accept (Poster),False,Learning to Understand Goal Specifications by Modelling Reward,"[""Dzmitry Bahdanau"", ""Felix Hill"", ""Jan Leike"", ""Edward Hughes"", ""Arian Hosseini"", ""Pushmeet Kohli"", ""Edward Grefenstette""]","[""instruction following"", ""reward modelling"", ""language understanding""]","We propose AGILE, a framework for training agents to perform instructions from examples of respective goal-states.",,,,
H1xscnEKDr,2020,Accept (Spotlight),True,Defending Against Physically Realizable Attacks on Image Classification,"[""Tong Wu"", ""Liang Tong"", ""Yevgeniy Vorobeychik""]","[""defense against physical attacks"", ""adversarial machine learning""]",Defending Against Physically Realizable Attacks on Image Classification,1909.09552,cs.LG,2019-09-20 15:11:09+00:00,2020-02-14 20:07:55+00:00
H1xwNhCcYm,2019,Accept (Poster),False,Do Deep Generative Models Know What They Don't Know? ,"[""Eric Nalisnick"", ""Akihiro Matsukawa"", ""Yee Whye Teh"", ""Dilan Gorur"", ""Balaji Lakshminarayanan""]","[""deep generative models"", ""out-of-distribution inputs"", ""flow-based models"", ""uncertainty"", ""density""]",,,,,
H1xzdlStvB,2020,Reject,False,Multi-Precision Policy Enforced Training (MuPPET) : A precision-switching strategy for quantised fixed-point training of CNNs,"[""Aditya Rajagopal"", ""Diederik A. Vink"", ""Stylianos I. Venieris"", ""Christos-Savvas Bouganis""]",[],,,,,
H1z-PsR5KX,2019,Accept (Poster),False,Identifying and Controlling Important Neurons in Neural Machine Translation,"[""Anthony Bau"", ""Yonatan Belinkov"", ""Hassan Sajjad"", ""Nadir Durrani"", ""Fahim Dalvi"", ""James Glass""]","[""neural machine translation"", ""individual neurons"", ""unsupervised"", ""analysis"", ""correlation"", ""translation control"", ""distributivity"", ""localization""]","Unsupervised methods for finding, analyzing, and controlling important neurons in NMT",,,,
H1zJ-v5xl,2017,Accept (Poster),False,Quasi-Recurrent Neural Networks,"[""James Bradbury"", ""Stephen Merity"", ""Caiming Xiong"", ""Richard Socher""]","[""Natural language processing"", ""Deep learning""]","QRNNs, composed of convolutions and a recurrent pooling function, outperform LSTMs on a variety of sequence tasks and are up to 16 times faster.",,,,
H1z_Z2A5tX,2019,Reject,False,DONâT JUDGE A BOOK BY ITS COVER - ON THE DYNAMICS OF RECURRENT NEURAL NETWORKS,"[""Doron Haviv"", ""Alexander Rivkind"", ""Omri Barak""]",[],,,,,
H1zeHnA9KX,2019,Accept (Poster),False,Representing Formal Languages: A Comparison Between Finite Automata and Recurrent Neural Networks ,"[""Joshua J. Michalenko"", ""Ameesh Shah"", ""Abhinav Verma"", ""Richard G. Baraniuk"", ""Swarat Chaudhuri"", ""Ankit B. Patel""]","[""Language recognition"", ""Recurrent Neural Networks"", ""Representation Learning"", ""deterministic finite automaton"", ""automaton""]",Finite Automata Can be Linearly decoded from Language-Recognizing RNNs using low coarseness abstraction functions and high accuracy decoders. ,,,,
H1ziPjC5Fm,2019,Accept (Poster),False,Visual Explanation by Interpretation: Improving Visual Feedback Capabilities of Deep Neural Networks,"[""Jose Oramas"", ""Kaili Wang"", ""Tinne Tuytelaars""]","[""model explanation"", ""model interpretation"", ""explainable ai"", ""evaluation""]",Interpretation by Identifying model-learned features that serve as indicators for the task of interest. Explain model decisions by highlighting the response of these features in test data. Evaluate explanations objectively with a controlled dataset.,,,,
H1zriGeCZ,2018,Accept (Poster),False,Hyperparameter optimization: a spectral approach,"[""Elad Hazan"", ""Adam Klivans"", ""Yang Yuan""]","[""Hyperparameter Optimization"", ""Fourier Analysis"", ""Decision Tree"", ""Compressed Sensing""]",A hyperparameter tuning algorithm using discrete Fourier analysis and compressed sensing,,,,
H1zxjsCqKQ,2019,Reject,False,Gradient-based learning for F-measure and other performance metrics,"[""Yu Gai"", ""Zheng Zhang"", ""Kyunghyun Cho""]",[],,,,,
H38f_9b90BO,2021,Reject,False,Towards Robust Graph Neural Networks against Label Noise,"[""Jun Xia"", ""Haitao Lin"", ""Yongjie Xu"", ""Lirong Wu"", ""Zhangyang Gao"", ""Siyuan Li"", ""Stan Z. Li""]","[""Graph Neural Networks"", ""Graph Node Classification"", ""Label Noise""]","To the best of our knowledge, we are the first to focus on the label noise existing in utilizing GNNs to classify graph nodes.",,,,
H3zl1mDHDTn,2022,Reject,False,Lagrangian Method for Episodic Learning,['Huang Bojun'],"[""Reinforcement Learning"", ""Imitation Learning"", ""Lagrangian Duality"", ""Machine Translation""]","The paper studies a Lagrangian duality phenomenon in reinfocement learning and imitation learning, with algorithmic applications to machine translation.",,,,
H4EXaI6HR2,2022,Reject,False,Representing value functions in power systems using parametric network series,"['Ruben Chaer', 'Ximena Caporale', 'Vanina Camacho', 'Ignacio RamÃ­rez']","[""approximate dynamic programming"", ""cost function approximation"", ""artificial neural networks"", ""parametric network series""]","We describe a novel architecture, named parametric network series, for modeling cost-to-go functions in highly variable electricity generation systems",,,,
H4J8FGHOhx_,2022,Reject,True,A Principled Permutation Invariant Approach to Mean-Field Multi-Agent Reinforcement Learning,"['Yan Li', 'Lingxiao Wang', 'Jiachen Yang', 'Ethan Wang', 'Zhaoran Wang', 'Tuo Zhao', 'Hongyuan Zha']",[],,2105.08268,cs.LG,2021-05-18 04:35:41+00:00,2021-05-18 04:35:41+00:00
H4PmOqSZDY,2022,Accept (Poster),False,Towards Empirical Sandwich Bounds on the Rate-Distortion Function,"['Yibo Yang', 'Stephan Mandt']","[""information theory"", ""deep generative modeling"", ""lossy data compression""]",We make a first attempt at an algorithm for sandwiching the rate-distortion function of a general data sources requiring only i.i.d. samples.,2111.12166,cs.IT,2021-11-23 21:50:27+00:00,2021-11-23 21:50:27+00:00
H5B3lmpO1g,2021,Reject,False,Goal-Auxiliary Actor-Critic for 6D Robotic Grasping with Point Clouds,"[""Lirui Wang"", ""Yu Xiang"", ""Dieter Fox""]","[""Robotics"", ""Reinforcement Learning"", ""Learning from Demonstration""]","We propose to augment reinforcement learning with demonstrations and goal auxiliary tasks, for learning closed-loop control policies in 6D robotic grasping using point clouds, which achieves over 90% success rates on grasping various unseen objects.",,,,
H6ATjJ0TKdf,2021,Accept (Poster),True,Layer-adaptive Sparsity for the Magnitude-based Pruning,"[""Jaeho Lee"", ""Sejun Park"", ""Sangwoo Mo"", ""Sungsoo Ahn"", ""Jinwoo Shin""]","[""network pruning"", ""layerwise sparsity"", ""magnitude-based pruning""]","We propose LAMP, a general-purpose layerwise sparsity selection scheme for magnitude pruning.",2010.07611,cs.LG,2020-10-15 09:14:02+00:00,2021-05-09 10:19:51+00:00
H6ZWlQrPGS2,2021,Reject,False,Fast Binarized Neural Network Training with Partial Pre-training,"[""Alex Renda"", ""Joshua Wolff Fromm""]","[""binarized neural network"", ""binary"", ""quantized"", ""1-bit"", ""low precision""]","We demonstrate a technique, partial pre-training, that allows for faster from-scratch training of binarized neural networks.",,,,
H6mR1eaBP1l,2022,Reject,False,Training sequence labeling models using prior knowledge,['Dani El-Ayyass'],[],Training sequence labeling models using prior knowledge,,,,
H7Edu1_IZgR,2022,Reject,False,Transformers are Meta-Reinforcement Learners,['Luckeciano Carvalho Melo'],"[""Reinforcement Learning"", ""Meta-Reinforcement Learning"", ""Transformers""]",,,,,
H7HDG--DJF0,2022,Accept (Poster),False,Multi-Agent MDP Homomorphic Networks,"['Elise van der Pol', 'Herke van Hoof', 'Frans A Oliehoek', 'Max Welling']","[""multiagent systems"", ""reinforcement learning"", ""equivariance"", ""symmetry""]",We introduce globally equivariant multi-agent policy networks with distributed execution.,,,,
H8UHdhWG6A3,2021,Accept (Poster),False,Distributed Momentum for Byzantine-resilient Stochastic Gradient Descent,"[""El Mahdi El Mhamdi"", ""Rachid Guerraoui"", ""S\u00e9bastien Rouault""]","[""Byzantine SGD"", ""Distributed ML"", ""Momentum""]","An inexpensive method to substantially improve the effectiveness of existing Byzantine-resilient SGD defenses, assessed against state-of-the-art attacks and supported by theoretical insights.",,,,
H8VDvtm1ij8,2021,Reject,False,Normalizing Flows for Calibration and Recalibration,"[""Achintya Gopal"", ""Aaron Key""]","[""recalibration"", ""normalizing flows"", ""uncertainty""]",This paper introduces using normalizing flows for recalibration and extends recalibration to the multivariate case.,,,,
H8hgu4XsTXi,2021,Reject,False,Estimating Treatment Effects via Orthogonal Regularization,"[""Tobias Hatt"", ""Stefan Feuerriegel""]","[""Treatment Effects"", ""Regularization"", ""Neural Networks""]","In order to estimate average causal effects, we develop a regularization framework in which we formalize unconfoundedness as an orthogonality constraint.",2101.08490,cs.LG,2021-01-21 08:05:35+00:00,2021-10-13 12:29:01+00:00
H92-E4kFwbR,2021,Reject,False,Composite Adversarial Training for Multiple Adversarial Perturbations and Beyond,"[""Xinyang Zhang"", ""Zheng Zhang"", ""Ting Wang""]","[""adversarial examples"", ""deep learning"", ""robustness""]","A new adversarial training framework for multiple adversarial perturbations and a new ""composite"" adversary.",,,,
H94a1_Pyr-6,2022,Accept (Poster),False,Auto-scaling Vision Transformers without Training,"['Wuyang Chen', 'Wei Huang', 'Xianzhi Du', 'Xiaodan Song', 'Zhangyang Wang', 'Denny Zhou']","[""vision transformer"", ""neural architecture search"", ""training-free search"", ""efficient training""]","We automate the design and scaling of vision transformers without any training, achieving state-of-the-art performance on ImageNet classification and COCO object detection.",,,,
HBsJNesj2S,2022,Accept (Poster),False,Neural Relational Inference with Node-Specific Information ,['Ershad Banijamali'],"[""Graph Neural Networks"", ""Variational Inference"", ""Trajectory Prediction""]","We use variational inference to uncover relations among agents in a multi-agent system, given that the agents can have access to some private information",,,,
HC5VgCHtU10,2021,Reject,False,Disentangling style and content for low resource video domain adaptation: a case study on keystroke inference attacks,"[""John Lim"", ""Fabian Monrose"", ""Jan-Michael Frahm""]","[""Applications"", ""side channel attacks"", ""supervised disentangled learning"", ""video domain adaptation""]",,,,,
HCRVf71PMF,2022,Accept (Poster),True,LFPT5: A Unified Framework for Lifelong Few-shot Language Learning Based on Prompt Tuning of T5,"['Chengwei Qin', 'Shafiq Joty']","[""lifelong few-shot language Learning"", ""prompt tuning"", ""pseudo samples"", ""knowledge distillation""]",We define a challenging yet practical problem as Lifelong Few-shot Language Learning and propose a unified framework for it based on prompt tuning of T5.,2110.07298,cs.CL,2021-10-14 12:06:29+00:00,2021-10-14 12:06:29+00:00
HCSgyPUfeDj,2021,Accept (Poster),True,Learning and Evaluating Representations for Deep One-Class Classification,"[""Kihyuk Sohn"", ""Chun-Liang Li"", ""Jinsung Yoon"", ""Minho Jin"", ""Tomas Pfister""]","[""deep one-class classification"", ""self-supervised learning""]","We present a two-stage framework for deep one-class classification, composed of state-of-the-art self-supervised representation learning followed by generative or discriminative one-class classifiers.",2011.02578,cs.CV,2020-11-04 23:33:41+00:00,2021-03-25 23:11:23+00:00
HCa8gC_COVk,2021,Reject,True,Mutual Calibration between Explicit and Implicit Deep Generative Models,"[""Qitian Wu"", ""Rui Gao"", ""Hongyuan Zha""]","[""deep generative models"", ""generative adversarial networks"", ""density estimation""]","We propose a new joint training framework that connects explicit and implicit deep generative models, enabling their mutual regulairzation and compensation",1909.13035,cs.LG,2019-09-28 06:39:33+00:00,2021-10-26 13:05:50+00:00
HCelXXcSEuH,2022,Accept (Poster),False,Doubly Adaptive Scaled Algorithm for Machine Learning Using Second-Order Information,"['Majid Jahani', 'Sergey Rusakov', 'Zheng Shi', 'Peter RichtÃ¡rik', 'Michael W. Mahoney', 'Martin Takac']","[""Convex Optimization"", ""Non-Convex Optimization"", ""Stochastic Optimization"", ""Second-Order Optimization"", ""Deep Learning""]",Second-Order Method for Large Scale Machine Learning Tasks,,,,
HFE5P8nhmmL,2022,Reject,False,SVMnet: Non-parametric image classification based on convolutional SVM ensembles for small training sets,"['Hunter Goddard', 'Lior Shamir']","[""machine learning"", ""support vector machine"", ""convolutional neural network""]",SVMnet is a new machine learning model for image classification inspired by convolutional neural networks and designed for classification tasks where few labeled training samples are available.,,,,
HFPTzdwN39,2022,Accept (Poster),False,Measuring the Interpretability of Unsupervised Representations via Quantized Reversed Probing,"['Iro Laina', 'Yuki M Asano', 'Andrea Vedaldi']","[""Representation learning"", ""Computer vision"", ""Interpretability""]",We propose quantized reverse probing as a information-theoretic measure to assess the degree to which self-supervised visual representations align with human-interpretable concepts. ,,,,
HFmAukZ-k-2,2022,Accept (Spotlight),False,Learning the Dynamics of Physical Systems from Sparse Observations with Finite Element Networks,"['Marten Lienen', 'Stephan GÃ¼nnemann']","[""spatio-temporal"", ""finite"", ""elements"", ""forecasting"", ""continuous"", ""partial"", ""differential"", ""equation"", ""PDE"", ""graph"", ""gnn"", ""time-series""]",A continuous-time graph neural network model for spatio-temporal forecasting that can structurally incorporate prior knowledge,,,,
HG7vlodGGm,2022,Reject,False,TempoRL: Temporal Priors for Exploration in Off-Policy Reinforcement Learning,"['Marco Bagatella', 'Sammy Joe Christen', 'Otmar Hilliges']","[""deep reinforcement learning"", ""exploration"", ""prior""]",We introduce state-independent temporal priors to accelerate RL in unseen tasks.,,,,
HHSEKOnPvaO,2021,Accept (Spotlight),False,Graph-Based Continual Learning,"[""Binh Tang"", ""David S. Matteson""]",[],,,,,
HHUSDJb_4KJ,2022,Reject,False,Unifying Distribution Alignment as a Loss for Imbalanced Semi-supervised Learning,"['Justin Lazarow', 'Kihyuk Sohn', 'Chun-Liang Li', 'Zizhao Zhang', 'Chen-Yu Lee', 'Tomas Pfister']","[""semi-supervised learning"", ""imbalanced learning""]","We simplify imbalanced semi-supervised learning by using the same alignment approach in both supervised and unsupervised branches --- requiring only a few lines of code, reducing training time, and improving classification performance overall",,,,
HHiiQKWsOcV,2021,Accept (Poster),False,Explaining the Efficacy of Counterfactually Augmented Data,"[""Divyansh Kaushik"", ""Amrith Setlur"", ""Eduard H Hovy"", ""Zachary Chase Lipton""]","[""humans in the loop"", ""annotation artifacts"", ""text classification"", ""sentiment analysis"", ""natural language inference""]",We present a framework for thinking about counterfactually augmented data and make strides towards understanding its benefits in out-of-domain generalization.,,,,
HHpWuWayMo,2022,Reject,False,Evaluating Robustness of Cooperative MARL,"['Nhan Pham', 'Lam M. Nguyen', 'Jie Chen', 'Thanh Lam Hoang', 'Subhro Das', 'Tsui-Wei Weng']","[""cooperative multi-agent reinforcement learning"", ""adversarial attack"", ""continuous action""]",,,,,
HI0j7omXTaG,2021,Reject,False,Keep the Gradients Flowing: Using Gradient Flow to study Sparse Network Optimization,"[""Kale-ab Tessera"", ""Sara Hooker"", ""Benjamin Rosman""]","[""neural networks"", ""sparsity"", ""gradient flow"", ""sparse network optimization""]",We use gradient flow to study sparse network optimization.,2102.01670,cs.LG,2021-02-02 18:40:26+00:00,2021-06-16 02:49:34+00:00
HI99z0aLsl,2022,Reject,False,Benign Overfitting in Adversarially Robust Linear Classification,"['Jinghui Chen', 'Yuan Cao', 'Quanquan Gu']","[""Benign Overfitting"", ""Robust Linear Classification""]",,2112.15250,cs.LG,2021-12-31 00:27:31+00:00,2021-12-31 00:27:31+00:00
HIGSa_3kOx3,2021,Accept (Poster),False,Reset-Free Lifelong Learning with Skill-Space Planning,"[""Kevin Lu"", ""Aditya Grover"", ""Pieter Abbeel"", ""Igor Mordatch""]","[""reset-free"", ""lifelong"", ""reinforcement learning""]",,2012.03548,cs.LG,2020-12-07 09:33:02+00:00,2021-06-15 18:39:59+00:00
HJ0NvFzxl,2017,Accept (Oral),False,Learning Graphical State Transitions,"[""Daniel D. Johnson""]","[""Natural language processing"", ""Deep learning"", ""Supervised Learning"", ""Structured prediction""]","I introduce a set of differentiable graph transformations, and use them to build a model with a graphical internal state that can extract structured data from text and use it to answer queries.",,,,
HJ0UKP9ge,2017,Accept (Poster),False,Bidirectional Attention Flow for Machine Comprehension,"[""Minjoon Seo"", ""Aniruddha Kembhavi"", ""Ali Farhadi"", ""Hannaneh Hajishirzi""]","[""Natural language processing"", ""Deep learning""]",,,,,
HJ1HFlZAb,2018,Reject,False,Evaluation of generative networks through their data augmentation capacity,"[""Timoth\u00e9e Lesort"", ""Florian Bordes"", ""Jean-Francois Goudou"", ""David Filliat""]","[""Generative models"", ""Evaluation of generative models"", ""Data Augmentation""]",Evaluating generative networks through their data augmentation capacity on discrimative models.,,,,
HJ1JBJ5gl,2017,Reject,False,Representing inferential uncertainty in deep neural networks through sampling,"[""Patrick McClure"", ""Nikolaus Kriegeskorte""]","[""Deep learning"", ""Theory"", ""Applications""]",Dropout- and dropconnect-based Bayesian deep neural networks with sampling at inference better represent their own inferential uncertainty than traditional deep neural networks.,,,,
HJ1kmv9xx,2017,Accept (Poster),False,LR-GAN: Layered Recursive Generative Adversarial Networks for Image Generation,"[""Jianwei Yang"", ""Anitha Kannan"", ""Dhruv Batra"", ""Devi Parikh""]","[""Computer vision"", ""Deep learning"", ""Unsupervised Learning""]","A layered recursive GAN for image generation, which considers the structure in images and can disentangle the foreground objects from background well in unsupervised manner.",,,,
HJ39YKiTb,2018,Reject,False,Associative Conversation Model: Generating Visual Information from Textual Information,"[""Yoichi Ishibashi"", ""Hisashi Miyamori""]","[""conversation model"", ""multimodal embedding"", ""attention mechanism"", ""natural language processing"", ""encoder-decoder model""]",Proposal of the sentence generation method based on fusion between textual information and visual information associated with the textual information,,,,
HJ3d2Ax0-,2018,Invite to Workshop Track,False,Benefits of Depth for Long-Term Memory of Recurrent Networks,"[""Yoav Levine"", ""Or Sharir"", ""Amnon Shashua""]","[""recurrent neural networks"", ""deep networks"", ""correlations"", ""long term memory"", ""tensor networks"", ""tensor analysis""]",We propose a measure of long-term memory and prove that deep recurrent networks are much better fit to model long-term temporal dependencies than shallow ones.,,,,
HJ4IhxZAb,2018,Reject,False,Meta-Learning Transferable Active Learning Policies by Deep Reinforcement Learning,"[""Kunkun Pang"", ""Mingzhi Dong"", ""Timothy Hospedales""]","[""Active Learning"", ""Deep Reinforcement Learning""]",,,,,
HJ5AUm-CZ,2018,Reject,False,The Variational Homoencoder: Learning to Infer High-Capacity Generative Models from Few Examples,"[""Luke Hewitt"", ""Andrea Gane"", ""Tommi Jaakkola"", ""Joshua B. Tenenbaum""]","[""generative models"", ""one-shot learning"", ""metalearning"", ""pixelcnn"", ""hierarchical bayesian"", ""omniglot""]","Technique for learning deep generative models with shared latent variables, applied to Omniglot with a PixelCNN decoder.",,,,
HJ5PIaseg,2017,Invite to Workshop Track,False,Towards an automatic Turing test: Learning to evaluate dialogue responses,"[""Ryan Lowe"", ""Michael Noseworthy"", ""Iulian V. Serban"", ""Nicolas Angelard-Gontier"", ""Yoshua Bengio"", ""Joelle Pineau""]","[""Natural language processing"", ""Applications""]",We propose a model for evaluating dialogue responses that correlates significantly with human judgement at the utterance-level and system-level.,,,,
HJ6idTdgg,2017,Reject,False,Pedestrian Detection Based On Fast R-CNN and Batch Normalization ,"[""Zhong-Qiu Zhao"", ""Haiman Bian"", ""Donghui Hu"", ""Herve Glotin""]",[],,,,,
HJ7O61Yxe,2017,Reject,False,Modelling Relational Time Series using Gaussian Embeddings,"[""Ludovic Dos Santos"", ""Ali Ziat"", ""Ludovic Denoyer"", ""Benjamin Piwowarski"", ""Patrick Gallinari""]","[""Applications"", ""Deep learning""]",We learn latent gaussian distributions for modelling correlated series.,,,,
HJ8W1Q-0Z,2018,Reject,False,GATED FAST WEIGHTS FOR ASSOCIATIVE RETRIEVAL,"[""Imanol Schlag"", ""J\u00fcrgen Schmidhuber""]","[""fast weights"", ""RNN"", ""associative retrieval"", ""time-varying variables""]",An improved Fast Weight network which shows better results on a general toy task.,,,,
HJ94fqApW,2018,Accept (Poster),False,Rethinking the Smaller-Norm-Less-Informative Assumption in Channel Pruning of Convolution Layers,"[""Jianbo Ye"", ""Xin Lu"", ""Zhe Lin"", ""James Z. Wang""]","[""model pruning"", ""batch normalization"", ""convolutional neural network"", ""ISTA""]",A CNN model pruning method using ISTA and rescaling trick to enforce sparsity of scaling parameters in batch normalization.,,,,
HJ9rLLcxg,2017,Invite to Workshop Track,False,Dataset Augmentation in Feature Space,"[""Terrance DeVries"", ""Graham W. Taylor""]","[""Unsupervised Learning""]",We argue for domain-agnostic data augmentation in feature space by applying simple transformations to seq2seq context vectors.,,,,
HJBhEMbRb,2018,Reject,False,A Spectral Approach to Generalization and Optimization in Neural Networks,"[""Farzan Farnia"", ""Jesse Zhang"", ""David Tse""]","[""Generalization"", ""Neural Networks"", ""Fourier Analysis""]",,,,,
HJC2SzZCW,2018,Accept (Poster),False,Sensitivity and Generalization in Neural Networks: an Empirical Study,"[""Roman Novak"", ""Yasaman Bahri"", ""Daniel A. Abolafia"", ""Jeffrey Pennington"", ""Jascha Sohl-Dickstein""]","[""generalization"", ""complexity"", ""experimental study"", ""linear regions"", ""Jacobian""]","We perform massive experimental studies characterizing the relationships between Jacobian norms, linear regions, and generalization.",,,,
HJCXZQbAZ,2018,Accept (Poster),False,Hierarchical Density Order Embeddings,"[""Ben Athiwaratkun"", ""Andrew Gordon Wilson""]","[""embeddings"", ""word embeddings"", ""probabilistic embeddings"", ""hierarchical representation"", ""probabilistic representation"", ""order embeddings"", ""wordnet"", ""hyperlex""]",,,,,
HJDBUF5le,2017,Accept (Poster),False,Towards a Neural Statistician,"[""Harrison Edwards"", ""Amos Storkey""]",[],Learning representations of datasets with an extension of VAEs.,,,,
HJDUjKeA-,2018,Reject,False,Learning objects from pixels,"[""David Saxton""]","[""objects"", ""unsupervised"", ""reinforcement learning"", ""atari""]","We show how discrete objects can be learnt in an unsupervised fashion from pixels, and how to perform reinforcement learning using this object representation.",,,,
HJDV5YxCW,2018,Reject,False,Heterogeneous Bitwidth Binarization in Convolutional Neural Networks,"[""Josh Fromm"", ""Matthai Philipose"", ""Shwetak Patel""]","[""Deep Learning"", ""Computer Vision"", ""Approximation""]",We introduce fractional bitwidth approximation and show it has significant advantages.,,,,
HJDdiT9gl,2017,Reject,False,Generating Long and Diverse Responses with Neural Conversation Models,"[""Louis Shao"", ""Stephan Gouws"", ""Denny Britz"", ""Anna Goldie"", ""Brian Strope"", ""Ray Kurzweil""]","[""Natural language processing"", ""Deep learning""]",We generate high quality and informative open-domain conversation responses using seq2seq model with target-side attention and stochastic beam search with segment-by-segment reranking. ,,,,
HJE6X305Fm,2019,Accept (Poster),False,Don't let your Discriminator  be fooled,"[""Brady Zhou"", ""Philipp Kr\u00e4henb\u00fchl""]","[""GAN"", ""generative models"", ""computer vision""]",A discriminator that is not easily fooled by adversarial example makes GAN training more robust and leads to a smoother objective.,,,,
HJF3iD9xe,2017,Invite to Workshop Track,False,Deep Learning with Sets and Point Clouds,"[""Siamak Ravanbakhsh"", ""Jeff Schneider"", ""Barnabas Poczos""]","[""Deep learning"", ""Structured prediction"", ""Computer vision"", ""Supervised Learning"", ""Semi-Supervised Learning""]",Parameter-sharing for permutation-equivariance and invariance with applications to point-cloud classification.,,,,
HJG0ojCcFm,2019,Reject,False,Negotiating Team Formation Using Deep Reinforcement Learning,"[""Yoram Bachrach"", ""Richard Everett"", ""Edward Hughes"", ""Angeliki Lazaridou"", ""Joel Leibo"", ""Marc Lanctot"", ""Mike Johanson"", ""Wojtek Czarnecki"", ""Thore Graepel""]","[""Reinforcement Learning"", ""Negotiation"", ""Team Formation"", ""Cooperative Game Theory"", ""Shapley Value""]",Reinforcement learning can be used to train agents to negotiate team formation across many negotiation protocols,,,,
HJG1Uo09Fm,2019,Reject,False,Learning to Reinforcement Learn by Imitation,"[""Rosen Kralev"", ""Russell Mendonca"", ""Alvin Zhang"", ""Tianhe Yu"", ""Abhishek Gupta"", ""Pieter Abbeel"", ""Sergey Levine"", ""Chelsea Finn""]","[""meta-learning"", ""reinforcement learning"", ""imitation learning""]",,,,,
HJG7m2AcF7,2019,Reject,False,Context Mover's Distance & Barycenters: Optimal transport of contexts for building representations,"[""Sidak Pal Singh"", ""Andreas Hug"", ""Aymeric Dieuleveut"", ""Martin Jaggi""]","[""representation learning"", ""wasserstein distance"", ""wasserstein barycenter"", ""entailment""]",,,,,
HJGODLqgx,2017,Accept (Poster),False,Recurrent Hidden Semi-Markov Model,"[""Hanjun Dai"", ""Bo Dai"", ""Yan-Ming Zhang"", ""Shuang Li"", ""Le Song""]","[""Deep learning"", ""Unsupervised Learning"", ""Structured prediction""]",We propose to incorporate the RNN to model the generative process in Hidden Semi-Markov Model for unsupervised segmentation and labeling.,,,,
HJGXzmspb,2018,Accept (Oral),False,Training and Inference with Integers in Deep Neural Networks,"[""Shuang Wu"", ""Guoqi Li"", ""Feng Chen"", ""Luping Shi""]","[""quantization"", ""training"", ""bitwidth"", ""ternary weights""]",We apply training and inference with only low-bitwidth integers in DNNs,,,,
HJGciiR5Y7,2019,Accept (Poster),True,Latent Convolutional Models,"[""ShahRukh Athar"", ""Evgeny Burnaev"", ""Victor Lempitsky""]","[""latent models"", ""convolutional networks"", ""unsupervised learning"", ""deep learning"", ""modeling natural images"", ""image restoration""]",We present a new deep latent model of natural images that can be trained from unlabeled datasets and can be utilized to solve various image restoration tasks.,1806.06284,cs.CV,2018-06-16 19:31:32+00:00,2018-11-02 04:35:49+00:00
HJGkisCcKm,2019,Accept (Poster),False,A Universal Music Translation Network,"[""Noam Mor"", ""Lior Wolf"", ""Adam Polyak"", ""Yaniv Taigman""]",[],An automatic method for converting music between instruments and styles,,,,
HJGtFoC5Fm,2019,Reject,False,On the Margin Theory of Feedforward Neural Networks,"[""Colin Wei"", ""Jason Lee"", ""Qiang Liu"", ""Tengyu Ma""]","[""generalization theory"", ""implicit regularization"", ""generalization"", ""over-parametrization"", ""theory"", ""deep learning theory"", ""margin""]",We show that training feedforward relu networks with a weak regularizer results in a maximum margin and analyze the implications of this result.,,,,
HJGv1Z-AW,2018,Accept (Oral),False,Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input,"[""Angeliki Lazaridou"", ""Karl Moritz Hermann"", ""Karl Tuyls"", ""Stephen Clark""]","[""disentanglement"", ""communication"", ""emergent language"", ""compositionality"", ""multi-agent""]",A controlled study of the role of environments with respect to properties in emergent communication protocols.,1804.03984,cs.AI,2018-04-11 13:51:19+00:00,2018-04-11 13:51:19+00:00
HJGven05Y7,2019,Accept (Poster),True,How to train your MAML,"[""Antreas Antoniou"", ""Harrison Edwards"", ""Amos Storkey""]","[""meta-learning"", ""deep-learning"", ""few-shot learning"", ""supervised learning"", ""neural-networks"", ""stochastic optimization""]","MAML is great, but it has many problems, we solve many of those problems and as a result we learn most hyper parameters end to end, speed-up training and inference and set a new SOTA in few-shot learning",1810.09502,cs.LG,2018-10-22 18:48:16+00:00,2019-03-05 23:11:02+00:00
HJGwcKclx,2017,Accept (Poster),False,Soft Weight-Sharing for Neural Network Compression,"[""Karen Ullrich"", ""Edward Meeds"", ""Max Welling""]","[""Deep learning"", ""Optimization""]",We use soft weight-sharing to compress neural network weights.,,,,
HJIY0E9ge,2017,Reject,False,A Simple yet Effective Method to Prune Dense Layers of Neural Networks,"[""Mohammad Babaeizadeh"", ""Paris Smaragdis"", ""Roy H. Campbell""]","[""Deep learning""]",Pruning neural networks by adding output neurons with fully random targets and removing strongly correlated neurons.,,,,
HJIhGXWCZ,2018,Reject,False,Prediction Under Uncertainty with Error Encoding Networks,"[""Mikael Henaff"", ""Junbo Zhao"", ""Yann Lecun""]",[],A simple and easy to train method for multimodal prediction in time series. ,,,,
HJIoJWZCZ,2018,Accept (Poster),False,Adversarial Dropout Regularization,"[""Kuniaki Saito"", ""Yoshitaka Ushiku"", ""Tatsuya Harada"", ""Kate Saenko""]","[""domain adaptation"", ""computer vision"", ""generative models""]",We present a new adversarial method for adapting neural representations based on a critic that detects non-discriminative features.,,,,
HJJ0w--0W,2018,Reject,False,Long-term Forecasting using Tensor-Train RNNs,"[""Rose Yu"", ""Stephan Zheng"", ""Anima Anandkumar"", ""Yisong Yue""]","[""RNNs"", ""time series forecasting"", ""nonlinear dynamics"", ""tensor-train""]",Accurate forecasting over very long time horizons using tensor-train RNNs,,,,
HJJ23bW0b,2018,Accept (Poster),False,Initialization matters: Orthogonal Predictive State Recurrent Neural Networks,"[""Krzysztof Choromanski"", ""Carlton Downey"", ""Byron Boots""]","[""recurrent neural networks"", ""orthogonal random features"", ""predictive state representations""]",Improving Predictive State Recurrent Neural Networks via Orthogonal Random Features,,,,
HJKkY35le,2017,Accept (Poster),False,Mode Regularized Generative Adversarial Networks,"[""Tong Che"", ""Yanran Li"", ""Athul Jacob"", ""Yoshua Bengio"", ""Wenjie Li""]","[""Deep learning"", ""Unsupervised Learning""]",,,,,
HJM4rsRqFX,2019,Reject,False,Neural Variational Inference For Embedding Knowledge Graphs,"[""Alexander I. Cowen-Rivers"", ""Pasquale Minervini""]","[""Statistical Relational Learning"", ""Knowledge Graphs"", ""Knowledge Extraction"", ""Latent Feature Models"", ""Variational Inference.""]",Working toward generative knowledge graph models to better estimate predictive uncertainty in knowledge inference. ,,,,
HJMC_iA5tm,2019,Accept (Poster),False,Learning a SAT Solver from Single-Bit Supervision,"[""Daniel Selsam"", ""Matthew Lamm"", ""Benedikt B\\\""{u}nz"", ""Percy Liang"", ""Leonardo de Moura"", ""David L. Dill""]","[""sat"", ""search"", ""graph neural network"", ""theorem proving"", ""proof""]","We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.",,,,
HJMCcjAcYX,2019,Accept (Poster),False,Learning Representations of Sets through Optimized Permutations,"[""Yan Zhang"", ""Jonathon Hare"", ""Adam Pr\u00fcgel-Bennett""]","[""sets"", ""representation learning"", ""permutation invariance""]","Learn how to permute a set, then encode permuted set with RNN to obtain a set representation.",,,,
HJMCdsC5tX,2019,Reject,False,A fully automated periodicity detection in time series,"[""Tom Puech"", ""Matthieu Boussard""]","[""Time series"", ""feature engineering"", ""period detection"", ""machine learning""]","This paper presents a method to autonomously find multiple periodicities in a signal, using FFT and ACF and add three news steps (clustering/filtering/detrending)",,,,
HJMHpjC9Ym,2019,Accept (Poster),False,Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition,"[""Chun-Fu (Richard) Chen"", ""Quanfu Fan"", ""Neil Mallinar"", ""Tom Sercu"", ""Rogerio Feris""]","[""CNN"", ""multi-scale"", ""efficiency"", ""object recognition"", ""speech recognition""]",,,,,
HJMN-xWC-,2018,Reject,False,Learning Parsimonious Deep Feed-forward Networks,"[""Zhourong Chen"", ""Xiaopeng Li"", ""Nevin L. Zhang""]","[""Parsimonious Deep Feed-forward Networks"", ""structure learning"", ""classification"", ""overfitting"", ""fewer parameters"", ""high interpretability""]",An unsupervised structure learning method for Parsimonious Deep Feed-forward Networks.,,,,
HJMRvsAcK7,2019,Reject,False,Dynamic Pricing on E-commerce Platform with Deep Reinforcement Learning,"[""Jiaxi Liu"", ""Yidong Zhang"", ""Xiaoqing Wang"", ""Yuming Deng"", ""Xingyu Wu"", ""Miaolan Xie""]","[""reinforcement learning"", ""dynamic pricing"", ""e-commerce"", ""revenue management"", ""field experiment""]","This paper describes a methodology for pre-training, evaluating and online dynamic pricing on E-commerce platform using deep reinforcement learning.",,,,
HJMXTsCqYQ,2019,Reject,False,Constrained Bayesian Optimization for Automatic Chemical Design,"[""Ryan-Rhys Griffiths"", ""Jos\u00e9 Miguel Hern\u00e1ndez-Lobato""]","[""Bayesian Optimization"", ""Generative Models""]",,,,,
HJMXus0ct7,2019,Reject,False,iRDA Method for Sparse Convolutional Neural Networks,"[""Xiaodong Jia"", ""Liang Zhao"", ""Lian Zhang"", ""Juncai He"", ""Jinchao Xu""]","[""sparse convolutional neural networks"", ""regularized dual averaging""]",A sparse optimization algorithm for deep CNN models.,,,,
HJMghjA9YX,2019,Reject,False,Model Comparison for Semantic Grouping,"[""Francisco Vargas"", ""Kamen Brestnichki"", ""Nils Hammerla""]","[""model comparison"", ""semantic similarity"", ""STS"", ""von Mises-Fisher"", ""Information Theoretic Criteria""]",Competitive alternative to sentence embeddings in the task of semantic similarity using model comparison,,,,
HJMjW3RqtX,2019,Reject,False,One-Shot High-Fidelity Imitation: Training Large-Scale Deep Nets with RL,"[""Tom Le Paine"", ""Sergio Gomez"", ""Ziyu Wang"", ""Scott Reed"", ""Yusuf Aytar"", ""Tobias Pfaff"", ""Matt Hoffman"", ""Gabriel Barth-Maron"", ""Serkan Cabi"", ""David Budden"", ""Nando de Freitas""]","[""Imitation Learning"", ""Deep Learning""]","We present MetaMimic, an algorithm that takes as input a demonstration dataset and outputs (i) a one-shot high-fidelity imitation policy (ii) an unconditional task policy.",,,,
HJMsiiRctX,2019,Reject,False,Probabilistic Program Induction for Intuitive Physics Game Play,"[""Fahad Alhasoun""]","[""intuitive physics"", ""probabilistic programming"", ""computational cognitive science"", ""probabilistic models""]",The paper describes a method imitating human cognition about the physical world to play games in environments of physical interactions.,,,,
HJNGGmZ0Z,2018,Reject,False,What is image captioning made of?,"[""Pranava Madhyastha"", ""Josiah Wang"", ""Lucia Specia""]","[""image captioning"", ""representation learning"", ""interpretability"", ""rnn"", ""multimodal"", ""vision to language""]",This paper presents an empirical analysis on the role of different types of image representations and probes the properties of these representations for the task of image captioning.,,,,
HJNJws0cF7,2019,Reject,False,Convolutional Neural Networks combined with Runge-Kutta Methods,"[""Mai Zhu"", ""Bo Chang"", ""Chong Fu""]",[],,,,,
HJNMYceCW,2018,Accept (Poster),False,Residual Loss Prediction: Reinforcement Learning With No Incremental Feedback,"[""Hal Daum\u00e9 III"", ""John Langford"", ""Amr Sharaf""]","[""Reinforcement Learning"", ""Structured Prediction"", ""Contextual Bandits"", ""Learning Reduction""]",We present a novel algorithm for solving reinforcement learning and bandit structured prediction problems with very sparse loss feedback.,,,,
HJOQ7MgAW,2018,Reject,False,Long Short-Term Memory as a Dynamically Computed Element-wise Weighted Sum,"[""Omer Levy"", ""Kenton Lee"", ""Nicholas FitzGerald"", ""Luke Zettlemoyer""]",[],"Gates do all the heavy lifting in LSTMs by computing element-wise weighted sums, and removing the internal simple RNN does not degrade model performance.",,,,
HJOZBvcel,2017,Invite to Workshop Track,False,Learning to Discover Sparse Graphical Models,"[""Eugene Belilovsky"", ""Kyle Kastner"", ""Gael Varoquaux"", ""Matthew B. Blaschko""]",[],Sparse graphical model structure estimators make restrictive assumptions.  We show that empirical risk minimization can yield SOTA estimators for edge prediction across a wide range of graph structure distributions.  ,,,,
HJPSN3gRW,2018,Reject,False,Learning to navigate by distilling visual information and natural language instructions,"[""Abhishek Sinha"", ""Akilesh B"", ""Mausoom Sarkar"", ""Balaji Krishnamurthy""]","[""Deep reinforcement learning"", ""Computer Vision"", ""Multi-modal fusion"", ""Language Grounding""]",Attention based architecture for language grounding via reinforcement learning in a new customizable 2D grid environment  ,,,,
HJPmdP9le,2017,Reject,False,Efficient Summarization with Read-Again and Copy Mechanism,"[""Wenyuan Zeng"", ""Wenjie Luo"", ""Sanja Fidler"", ""Raquel Urtasun""]",[],,,,,
HJRV1ZZAW,2018,Reject,False,FAST READING COMPREHENSION WITH CONVNETS,"[""Felix Wu"", ""Ni Lao"", ""John Blitzer"", ""Guandao Yang"", ""Kilian Weinberger""]","[""reading comprehension"", ""question answering"", ""CNN"", ""ConvNet"", ""Inference""]",,,,,
HJSA_e1AW,2018,Reject,False,Normalized Direction-preserving Adam,"[""Zijun Zhang"", ""Lin Ma"", ""Zongpeng Li"", ""Chuan Wu""]","[""optimization"", ""generalization"", ""Adam"", ""SGD""]","A tailored version of Adam for training DNNs, which bridges the generalization gap between Adam and SGD.",,,,
HJSCGD9ex,2017,Reject,False,Beyond Bilingual: Multi-sense Word Embeddings using Multilingual Context,"[""Shyam Upadhyay"", ""Kai-Wei Chang"", ""James Zou"", ""Matt Taddy"", ""Adam Kalai""]","[""Natural language processing""]",Using multilingual context for learning multi-sense embeddings helps.,,,,
HJStZKqel,2017,Invite to Workshop Track,False,Lifelong Perceptual Programming By Example,"[""Alexander L. Gaunt"", ""Marc Brockschmidt"", ""Nate Kushman"", ""Daniel Tarlow""]","[""Deep learning"", ""Supervised Learning""]",Combination of differentiable interpreters and neural networks for lifelong learning of a model composed of neural and source code functions,,,,
HJTXaw9gx,2017,Invite to Workshop Track,False,Recursive Regression with Neural Networks: Approximating the HJI PDE Solution,"[""Vicen\u00e7 Rubies Royo"", ""Claire Tomlin""]","[""Supervised Learning"", ""Games"", ""Theory""]",A neural network that learns an approximation to a function by generating its own regression points,,,,
HJTzHtqee,2017,Accept (Poster),False,A Compare-Aggregate Model for Matching Text Sequences,"[""Shuohang Wang"", ""Jing Jiang""]","[""Natural language processing"", ""Deep learning""]","A general ""compare-aggregate"" framework that performs word-level matching followed by aggregation using Convolutional Neural Networks",,,,
HJUOHGWRb,2018,Reject,False,Contextual Explanation Networks,"[""Maruan Al-Shedivat"", ""Avinava Dubey"", ""Eric P. Xing""]","[""interpretability"", ""regularization"", ""deep learning"", ""graphical models"", ""model diagnostics"", ""survival analysis""]",A class of networks that generate simple models on the fly (called explanations) that act as a regularizer and enable consistent model diagnostics and interpretability.,,,,
HJV1zP5xg,2017,Reject,False,Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models,"[""Ashwin K Vijayakumar"", ""Michael Cogswell"", ""Ramprasaath R. Selvaraju"", ""Qing Sun"", ""Stefan Lee"", ""David Crandall"", ""Dhruv Batra""]","[""Deep learning"", ""Computer vision"", ""Natural language processing""]","We introduce a novel, diversity promoting beam search algorithm that results in significantly improved diversity between decoded sequences as evaluated on multiple sequence generation tasks.",,,,
HJWGdbbCW,2018,Reject,False,Reinforcement and Imitation Learning for Diverse Visuomotor Skills,"[""Yuke Zhu"", ""Ziyu Wang"", ""Josh Merel"", ""Andrei Rusu"", ""Tom Erez"", ""Serkan Cabi"", ""Saran Tunyasuvunakool"", ""J\u00e1nos Kram\u00e1r"", ""Raia Hadsell"", ""Nando de Freitas"", ""Nicolas Heess""]","[""reinforcement learning"", ""imitation learning"", ""robotics"", ""visuomotor skills""]",combine reinforcement learning and imitation learning to solve complex robot manipulation tasks from pixels,,,,
HJWHIKqgl,2017,Accept (Poster),False,Generative Models and Model Criticism via Optimized Maximum Mean Discrepancy,"[""Danica J. Sutherland"", ""Hsiao-Yu Tung"", ""Heiko Strathmann"", ""Soumyajit De"", ""Aaditya Ramdas"", ""Alex Smola"", ""Arthur Gretton""]","[""Unsupervised Learning""]","A way to optimize the power of an MMD test, to use it for evaluating generative models and training GANs",,,,
HJWLfGWRb,2018,Accept (Poster),False,Matrix capsules with EM routing,"[""Geoffrey E Hinton"", ""Sara Sabour"", ""Nicholas Frosst""]","[""Computer Vision"", ""Deep Learning"", ""Dynamic routing""]","Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ",,,,
HJWzXsKxx,2017,Reject,False,Training Long Short-Term Memory With Sparsified Stochastic Gradient Descent,"[""Maohua Zhu"", ""Minsoo Rhu"", ""Jason Clemons"", ""Stephen W. Keckler"", ""Yuan Xie""]","[""Optimization"", ""Deep learning""]",A simple yet effective technique to induce considerable amount of sparsity in LSTM training,,,,
HJXOfZ-AZ,2018,Reject,False,When and where do feed-forward neural networks learn localist representations?,"[""Ella M. Gale"", ""Nicolas Martin"", ""Jeffrey Bowers""]","[""localist"", ""pdp"", ""neural network"", ""representation"", ""psychology"", ""cognition""]",Local codes have been found in feed-forward neural networks,,,,
HJXyS7bRb,2018,Reject,False,A Goal-oriented Neural Conversation Model by Self-Play,"[""Wei Wei"", ""Quoc V. Le"", ""Andrew M. Dai"", ""Li-Jia Li""]","[""conversation model"", ""seq2seq"", ""self-play"", ""reinforcement learning""]",A Goal-oriented Neural Conversation Model by Self-Play,,,,
HJYQLb-RW,2018,Invite to Workshop Track,False,On the limitations of first order approximation in GAN dynamics,"[""Jerry Li"", ""Aleksander Madry"", ""John Peebles"", ""Ludwig Schmidt""]","[""GANs"", ""first order dynamics"", ""convergence"", ""mode collapse""]","To understand GAN training, we define simple GAN dynamics, and show quantitative differences between optimal and first order updates in this model.",,,,
HJYoqzbC-,2018,Reject,False,A comparison of second-order methods for deep convolutional neural networks,"[""Patrick H. Chen"", ""Cho-jui Hsieh""]",[],,,,,
HJZiRkZC-,2018,Reject,False,Byte-Level Recursive Convolutional Auto-Encoder for Text,"[""Xiang Zhang"", ""Yann LeCun""]",[],,,,,
HJ_X8GupW,2018,Reject,False,Multi-label Learning for Large Text Corpora using Latent Variable Model with Provable Gurantees,"[""Sayantan Dasgupta""]","[""Spectral Method"", ""Multi-label Learning"", ""Tensor Factorisation""]",,,,,
HJ_aoCyRZ,2018,Accept (Poster),False,SpectralNet: Spectral Clustering using Deep Neural Networks,"[""Uri Shaham"", ""Kelly Stanton"", ""Henry Li"", ""Ronen Basri"", ""Boaz Nadler"", ""Yuval Kluger""]","[""unsupervised learning"", ""spectral clustering"", ""siamese networks""]",Unsupervised spectral clustering using deep neural networks,,,,
HJaDJZ-0W,2018,Reject,False,Block-Sparse Recurrent Neural Networks,"[""Sharan Narang"", ""Eric Undersander"", ""Gregory Diamos""]","[""Pruning"", ""block sparsity"", ""structured sparsity"", ""Recurrent Neural Networks"", ""Speech Recognition""]",We show the RNNs can be pruned to induce block sparsity which improves speedup for sparse operations on existing hardware,,,,
HJcLcw9xg,2017,Reject,False,The Preimage of Rectifier Network Activities,"[""Stefan Carlsson"", ""Hossein Azizpour"", ""Ali Razavian""]",[],,,,,
HJcSzz-CZ,2018,Accept (Poster),False,Meta-Learning for Semi-Supervised Few-Shot Classification,"[""Mengye Ren"", ""Eleni Triantafillou"", ""Sachin Ravi"", ""Jake Snell"", ""Kevin Swersky"", ""Joshua B. Tenenbaum"", ""Hugo Larochelle"", ""Richard S. Zemel""]","[""Few-shot learning"", ""semi-supervised learning"", ""meta-learning""]",We propose novel extensions of Prototypical Networks that are augmented with the ability to use unlabeled examples when producing prototypes.,,,,
HJcjQTJ0W,2018,Reject,False,PrivyNet: A Flexible Framework for Privacy-Preserving Deep Neural Network Training,"[""Meng Li"", ""Liangzhen Lai"", ""Naveen Suda"", ""Vikas Chandra"", ""David Z. Pan""]","[""Privacy-preserving deep learning"", ""Neural network training""]","To enable cloud-based DNN training while protecting the data privacy simultaneously, we propose to leverage the intermediate data representations, which is achieved by splitting the DNNs and deploying them separately onto local platforms and the cloud.",,,,
HJdXGy1RW,2018,Reject,False,CrescendoNet: A Simple Deep Convolutional Neural Network with Ensemble Behavior,"[""Xiang Zhang"", ""Nishant Vishwamitra"", ""Hongxin Hu"", ""Feng Luo""]","[""CNN"", ""ensemble"", ""image recognition""]","We introduce CrescendoNet, a deep CNN architecture by stacking simple building blocks without residual connections.",,,,
HJe-blSYvH,2020,Reject,False,Unsupervised Learning of Efficient and Robust Speech Representations,"[""Kazuya Kawakami"", ""Luyu Wang"", ""Chris Dyer"", ""Phil Blunsom"", ""Aaron van den Oord""]",[],,2001.11128,cs.CL,2020-01-29 23:24:56+00:00,2020-01-29 23:24:56+00:00
HJe-oRVtPB,2020,Reject,False,STABILITY AND CONVERGENCE THEORY FOR LEARNING RESNET: A FULL CHARACTERIZATION,"[""Huishuai Zhang"", ""Da Yu"", ""Mingyang Yi"", ""Wei Chen"", ""Tie-yan Liu""]","[""ResNet"", ""stability"", ""convergence theory"", ""over-parameterization""]","We characterize the stability and convergence of gradient descent learning ResNet, unveiling the theorectical and practical importance of tau =1/sqrt(L) in the residual block.",,,,
HJe3TsR5K7,2019,Reject,False,Learning Joint Wasserstein Auto-Encoders for Joint Distribution Matching,"[""Jiezhang Cao"", ""Yong Guo"", ""Langyuan Mo"", ""Peilin Zhao"", ""Junzhou Huang"", ""Mingkui Tan""]","[""joint distribution matching"", ""image-to-image translation"", ""video-to-video synthesis"", ""Wasserstein distance""]","We propose a novel Joint Wasserstein Auto-Encoders (JWAE) for Joint Distribution Matching problem, and apply it to image-to-image translation and video-to-video synthesis tasks.",,,,
HJe4Cp4KwH,2020,Reject,True,GNN-FiLM: Graph Neural Networks with Feature-wise Linear Modulation,"[""Marc Brockschmidt""]","[""Graph Neural Networks""]",new GNN formalism + extensive experiments; showing differences between GGNN/GCN/GAT are smaller than thought,1906.12192,cs.LG,2019-06-28 13:07:22+00:00,2020-06-26 16:45:48+00:00
HJe5_6VKwS,2020,Reject,False,Model-based Saliency for the Detection of Adversarial Examples,"[""Lisa Schut"", ""Yarin Gal""]","[""Adversarial Examples"", ""Defense"", ""Model-based Saliency""]",We show that gradients are unable to capture shifts in saliency due to adversarial perturbations and present an alternative adversarial defense using learnt saliency models that is effective against both black-box and white-box attacks.,,,,
HJe62s09tX,2019,Accept (Poster),False,Unsupervised Hyper-alignment for Multilingual Word Embeddings,"[""Jean Alaux"", ""Edouard Grave"", ""Marco Cuturi"", ""Armand Joulin""]",[],,,,,
HJe6uANtwH,2020,Accept (Poster),False,Capsules with Inverted Dot-Product Attention Routing,"[""Yao-Hung Hubert Tsai"", ""Nitish Srivastava"", ""Hanlin Goh"", ""Ruslan Salakhutdinov""]","[""capsule networks"", ""routing"", ""attention""]","We present a new routing method for Capsule networks, and it performs at-par with ResNet-18 on CIFAR-10/ CIFAR-100.",2002.04764,cs.LG,2020-02-12 02:09:33+00:00,2020-02-26 17:48:16+00:00
HJe7bxBYvr,2020,Reject,False,Avoiding Negative Side-Effects and Promoting Safe Exploration with Imaginative Planning,"[""Dhruv Ramani"", ""Benjamin Eysenbach""]","[""Reinforcement Learning"", ""AI-Safety"", ""Model-Based Reinforcement Learning"", ""Safe-Exploration""]",,,,,
HJe7unNFDH,2020,Reject,False,Scaling Up Neural Architecture Search with Big Single-Stage Models,"[""Jiahui Yu"", ""Pengchong Jin"", ""Hanxiao Liu"", ""Gabriel Bender"", ""Pieter-Jan Kindermans"", ""Mingxing Tan"", ""Thomas Huang"", ""Xiaodan Song"", ""Quoc Le""]","[""Single-Stage Neural Architecture Search""]","We scale up neural architecture search with big single-stage models, surpassing all state-of-the-art models from 200 to 1000 MFLOPs including EfficientNets.",,,,
HJe88xBKPr,2020,Reject,True,Mixed Precision Training With 8-bit Floating Point,"[""Naveen Mellempudi"", ""Sudarshan Srinivasan"", ""Dipankar Das"", ""Bharat Kaul""]","[""8-bit training"", ""8-bit floating point"", ""low precision training"", ""deep learning""]","We demonstrated state-of-the-art training results using 8-bit floating point representation, across Resnet, GNMT, Transformer.",1905.12334,cs.LG,2019-05-29 11:25:09+00:00,2019-05-29 11:25:09+00:00
HJe9cR4KvB,2020,Reject,False,Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling,"[""Ouyu Lan*"", ""Xiao Huang*"", ""Bill Yuchen Lin"", ""He Jiang"", ""Xiang Ren""]","[""crowdsourcing"", ""domain adaptation"", ""sequence labeling"", ""named entity recognition"", ""weak supervision""]",A model to contextually aggregate multi-source supervision for sequence learning.,,,,
HJeABnCqKQ,2019,Reject,False,Generative Adversarial Self-Imitation Learning,"[""Junhyuk Oh"", ""Yijie Guo"", ""Satinder Singh"", ""Honglak Lee""]",[],,,,,
HJeANgBYwr,2020,Reject,False,Towards Scalable Imitation Learning for Multi-Agent Systems with Graph Neural Networks,"[""Siyu Zhou"", ""Chaitanya Rajasekhar"", ""Mariano J. Phielipp"", ""Heni Ben Amor""]","[""Graph Neural Networks"", ""Scalability"", ""Swarms"", ""Imitation""]",Improve the scalability of graph neural networks on imitation learning and prediction of swarm motion,,,,
HJeB0sC9Fm,2019,Reject,False,Detecting Memorization in ReLU Networks,"[""Edo Collins"", ""Siavash Arjomand Bigdeli"", ""Sabine S\u00fcsstrunk""]","[""Memorization"", ""Generalization"", ""ReLU"", ""Non-negative matrix factorization""]",We use the non-negative rank of ReLU activation matrices as a complexity measure and show it (negatively) correlates with good generalization.,,,,
HJeEP04KDH,2020,Reject,False,Quantized Reinforcement Learning (QuaRL),"[""Srivatsan Krishnan"", ""Sharad Chitlangia"", ""Maximilian Lam"", ""Zishen Wan"", ""Aleksandra Faust"", ""Vijay Janapa Reddi""]","[""Deep Reinforcement Learning"", ""Quantization""]",We conduct 350+ experiments to show that RL models can be quantized to 6-8 bits without harming quality; show narrower weight distribution facilitates quantization; show quantization speeds training by 50% and inference by 18x.,,,,
HJeFmkBtvB,2020,Reject,True,Annealed Denoising score matching: learning Energy based model in high-dimensional spaces,"[""Zengyi Li"", ""Yubei Chen"", ""Friedrich T. Sommer""]","[""Energy based models"", ""score matching"", ""annealing"", ""likelihood"", ""generative model"", ""unsupervised learning""]",Learned energy based model with score matching,1910.07762,stat.ML,2019-10-17 08:21:17+00:00,2019-12-20 04:58:04+00:00
HJeIU0VYwB,2020,Reject,False,ADA+: A GENERIC FRAMEWORK WITH MORE ADAPTIVE EXPLICIT ADJUSTMENT FOR LEARNING RATE,"[""Yue Zhao"", ""Xiangsheng Huang"", ""Ludan Kou""]","[""Optimization"", ""Adaptive Methods"", ""Convergence"", ""Convolutional Neural Network""]","This work proposes a novel generic framework, in which we explicitly analyze different behaviors brought by various types of Î¦(Â·),  and based on the framework we propose a more adaptive optimization algorithm.",,,,
HJeIX6EKvr,2020,Reject,False,Leveraging inductive bias of neural networks for learning without explicit human annotations,"[""Fatih Furkan Yilmaz"", ""Reinhard Heckel""]","[""dataset construction"", ""deep learning"", ""candidate examples""]",,,,,
HJeKCi0qYX,2019,Reject,True,MILE: A Multi-Level Framework for Scalable Graph Embedding,"[""Jiongqian Liang"", ""Saket Gurukar"", ""Srinivasan Parthasarathy""]","[""Network Embedding"", ""Graph Convolutional Networks"", ""Deep Learning""]",A generic framework to scale existing graph embedding techniques to large graphs.,1802.09612,cs.AI,2018-02-26 21:18:43+00:00,2020-08-13 21:56:38+00:00
HJeLBpEFPB,2020,Reject,False,Unsupervised Universal Self-Attention Network for Graph Classification,"[""Dai Quoc Nguyen"", ""Tu Dinh Nguyen"", ""Dinh Phung""]","[""Graph embedding"", ""graph classification"", ""universal self-attention network"", ""graph neural network""]",,,,,
HJeNIjA5Y7,2019,Reject,False,Image Score: how to select useful samples,"[""Simiao Zuo"", ""Jialin Wu""]",[],,,,,
HJeO7RNKPr,2020,Accept (Poster),True,DeepV2D: Video to Depth with Differentiable Structure from Motion,"[""Zachary Teed"", ""Jia Deng""]","[""Structure-from-Motion"", ""Video to Depth"", ""Dense Depth Estimation""]",DeepV2D predicts depth from a video clip by composing elements of classical SfM into a fully differentiable network.,1812.04605,cs.CV,2018-12-11 18:47:12+00:00,2020-04-27 19:17:43+00:00
HJeOMhA5K7,2019,Reject,False,Human-Guided Column Networks: Augmenting Deep Learning with Advice,"[""Mayukh Das"", ""Yang Yu"", ""Devendra Singh Dhami"", ""Gautam Kunapuli"", ""Sriraam Natarajan""]","[""Knowledge-guided learning"", ""Human advice"", ""Column Networks"", ""Knowledge-based relational deep model"", ""Collective classification""]",Guiding relation-aware deep models towards better learning with human knowledge.,,,,
HJeOekHKwr,2020,Accept (Poster),False,Smoothness and Stability in GANs,"[""Casey Chu"", ""Kentaro Minami"", ""Kenji Fukumizu""]","[""generative adversarial networks"", ""stability"", ""smoothness"", ""convex conjugate""]",We develop a principled theoretical framework for understanding and enforcing the stability of various types of GANs,2002.04185,cs.LG,2020-02-11 03:08:28+00:00,2020-02-11 03:08:28+00:00
HJePRoAct7,2019,Reject,False,Graph U-Net,"[""Hongyang Gao"", ""Shuiwang Ji""]","[""graph"", ""pooling"", ""unpooling"", ""U-Net""]",We propose the graph U-Net based on our novel graph pooling and unpooling layer for network embedding.,,,,
HJePXkHtvS,2020,Reject,False,Deep Generative Classifier for Out-of-distribution Sample Detection,"[""Dongha Lee"", ""Sehun Yu"", ""Hwanjo Yu""]","[""Out-of-distribution Detection"", ""Generative Classifier"", ""Deep Neural Networks"", ""Multi-class Classification"", ""Gaussian Discriminant Analysis""]","This paper proposes a deep generative classifier which is effective to detect out-of-distribution samples as well as classify in-distribution samples, by integrating the concept of Gaussian discriminant analysis into deep neural networks.",,,,
HJePno0cYm,2019,Reject,False,Transformer-XL: Language Modeling with Longer-Term Dependency,"[""Zihang Dai*"", ""Zhilin Yang*"", ""Yiming Yang"", ""William W. Cohen"", ""Jaime Carbonell"", ""Quoc V. Le"", ""Ruslan Salakhutdinov""]","[""Language Modeling"", ""Self-Attention""]",,,,,
HJePy3RcF7,2019,Reject,False,Rethinking learning rate schedules for stochastic optimization,"[""Rong Ge"", ""Sham M. Kakade"", ""Rahul Kidambi"", ""Praneeth Netrapalli""]","[""SGD"", ""learning rate"", ""step size schedules"", ""stochastic approximation"", ""stochastic optimization"", ""deep learning"", ""non-convex optimization"", ""stochastic gradient descent""]",This paper presents a rigorous study of why practically used learning rate schedules (for a given computational budget) offer significant advantages even though these schemes are not advocated by the classical theory of Stochastic Approximation.,,,,
HJeQToAqKQ,2019,Reject,False,TherML: The Thermodynamics of Machine Learning,"[""Alexander A. Alemi"", ""Ian Fischer""]","[""representation learning"", ""information theory"", ""information bottleneck"", ""thermodynamics"", ""predictive information""]",We offer a framework for representation learning that connects with a wide class of existing objectives and is analogous to thermodynamics.,,,,
HJeQbnA5tm,2019,Reject,False,Noisy Information Bottlenecks for Generalization,"[""Julius Kunze"", ""Louis Kirsch"", ""Hippolyt Ritter"", ""David Barber""]","[""information theory"", ""deep learning"", ""generalization"", ""information bottleneck"", ""variational inference"", ""approximate inference""]",We limit mutual information between parameters and data using noise to improve generalization in deep models.,,,,
HJeRkh05Km,2019,Accept (Poster),False,Visual Semantic Navigation using Scene Priors,"[""Wei Yang"", ""Xiaolong Wang"", ""Ali Farhadi"", ""Abhinav Gupta"", ""Roozbeh Mottaghi""]","[""Visual Navigation"", ""Scene Prior"", ""Knowledge Graph"", ""Graph Convolution Networks"", ""Deep Reinforcement Learning""]",,,,,
HJeRm3Aqt7,2019,Reject,False,GenEval: A Benchmark Suite for Evaluating Generative Models,"[""Anton Bakhtin"", ""Arthur Szlam"", ""Marc'Aurelio Ranzato""]","[""generative models"", ""GAN"", ""VAE"", ""Real NVP""]",We introduce battery of synthetic distributions and metrics for measuring the success of generative models  ,,,,
HJeRveHKDH,2020,Reject,False,ADAPTIVE GENERATION OF PROGRAMMING PUZZLES,"[""Ashwin Kalyan"", ""Oleksandr Polozov"", ""Adam Tauman Kalai""]","[""program synthesis"", ""reasoning"", ""math problems""]","We introduce Programming Puzzles, an expressive set of reasoning problems that require minimal understanding of other domains like language. We then introduce TroubleMakers, an algorithm to generate hard programming puzzles. ",,,,
HJeT3yrtDr,2020,Accept (Poster),False,Cross-Lingual Ability of Multilingual BERT: An Empirical Study,"[""Karthikeyan K"", ""Zihan Wang"", ""Stephen Mayhew"", ""Dan Roth""]","[""Cross-Lingual Learning"", ""Multilingual BERT""]","Comprehensive analysis on Linguistic Properties, Model Architecture, and Input and Learning Objective of cross-lingual ability of Multilingual BERT",1912.07840,cs.CL,2019-12-17 06:53:05+00:00,2020-02-15 18:48:42+00:00
HJeTo2VFwH,2020,Accept (Spotlight),True,A Signal Propagation Perspective for Pruning Neural Networks at Initialization,"[""Namhoon Lee"", ""Thalaiyasingam Ajanthan"", ""Stephen Gould"", ""Philip H. S. Torr""]","[""neural network pruning"", ""signal propagation perspective"", ""sparse neural networks""]",We formally characterize the initialization conditions for effective pruning at initialization and analyze the signal propagation properties of the resulting pruned networks which leads to a method to enhance their trainability and pruning results.,1906.06307,cs.LG,2019-06-14 17:26:29+00:00,2020-02-16 18:23:41+00:00
HJeVnCEKwH,2020,Accept (Poster),True,A Closer Look at the Optimization Landscapes of Generative Adversarial Networks,"[""Hugo Berard"", ""Gauthier Gidel"", ""Amjad Almahairi"", ""Pascal Vincent"", ""Simon Lacoste-Julien""]","[""Deep Learning"", ""Generative models"", ""GANs"", ""Optimization"", ""Visualization""]","By proposing new visualization techniques we give better insights on GANs optimization in practical settings, we show that GANs on challenging datasets exhibit rotational behavior and do not converge to Nash-Equilibria",1906.04848,cs.LG,2019-06-11 22:34:19+00:00,2020-04-27 16:38:04+00:00
HJeYSxHFDS,2020,Reject,False,Gauge Equivariant Spherical CNNs,"[""Berkay Kicanaoglu"", ""Pim de Haan"", ""Taco Cohen""]","[""deep learning"", ""convolutional networks"", ""equivariance"", ""gauge equivariance"", ""symmetry"", ""geometric deep learning"", ""manifold convolution""]",This paper proposes a scalable equivariant spherical convolution.,,,,
HJeYalBKvr,2020,Reject,False,Attention over Phrases,"[""Wanyun Cui""]","[""representation learning"", ""natural language processing"", ""attention""]",We study the problem of representing phrases as atoms in attention.,,,,
HJe_Z04Yvr,2020,Accept (Poster),True,Adjustable Real-time Style Transfer,"[""Mohammad Babaeizadeh"", ""Golnaz Ghiasi""]","[""Image Style Transfer"", ""Deep Learning""]",Stochastic style transfer with adjustable features. ,1811.08560,cs.CV,2018-11-21 02:20:05+00:00,2018-11-21 02:20:05+00:00
HJe_yR4Fwr,2020,Accept (Poster),True,Improved Sample Complexities for Deep Neural Networks and Robust Classification via an All-Layer Margin,"[""Colin Wei"", ""Tengyu Ma""]","[""deep learning theory"", ""generalization bounds"", ""adversarially robust generalization"", ""data-dependent generalization bounds""]","We propose a new notion of margin that has a direct relationship with neural net generalization, and obtain improved generalization bounds for neural nets and robust classification by analyzing this margin.",1910.04284,cs.LG,2019-10-09 22:45:45+00:00,2021-06-16 05:12:53+00:00
HJedXaEtvS,2020,Accept (Poster),False,Editable Neural Networks,"[""Anton Sinitsin"", ""Vsevolod Plokhotnyuk"", ""Dmitry Pyrkin"", ""Sergei Popov"", ""Artem Babenko""]","[""editing"", ""editable"", ""meta-learning"", ""maml""]",Training neural networks so you can efficiently patch them later.,,,,
HJedho0qFX,2019,Reject,False,Using Word Embeddings to Explore the Learned Representations of Convolutional Neural Networks,"[""Dhanush Dharmaretnam"", ""Chris Foster"", ""Alona Fyshe""]","[""Distributional Semantics"", ""word embeddings"", ""cnns"", ""interpretability""]","A simple technique using word embeddings provides multiple insights into the function and performance of CNNs, both during and after training, and for misclassified and adversarial examples.",,,,
HJeg46EKPr,2020,Reject,False,Integrative Tensor-based Anomaly Detection System For Satellites,"[""Youjin Shin"", ""Sangyup Lee"", ""Shahroz Tariq"", ""Myeong Shin Lee"", ""OkchulJung"", ""Daewon Chung"", ""Simon Woo""]","[""Tensor decomposition"", ""Anomaly detection""]",Integrative Tensor-based Anomaly Detection(ITAD) framework for a satellite system.,,,,
HJehSnCcFX,2019,Reject,False,Inference of unobserved event streams with neural Hawkes particle smoothing,"[""Hongyuan Mei"", ""Guanghui Qin"", ""Jason Eisner""]",[],,,,,
HJei-2RcK7,2019,Reject,False,Graph Transformer ,"[""Yuan Li"", ""Xiaodan Liang"", ""Zhiting Hu"", ""Yinbo Chen"", ""Eric P. Xing""]","[""Graph neural networks"", ""transformer"", ""attention""]",,,,,
HJeiDpVFPr,2020,Accept (Poster),False,An Inductive Bias for Distances: Neural Nets that Respect the Triangle Inequality,"[""Silviu Pitis"", ""Harris Chan"", ""Kiarash Jamali"", ""Jimmy Ba""]","[""metric learning"", ""deep metric learning"", ""neural network architectures"", ""triangle inequality"", ""graph distances""]","We propose novel neural network architectures, guaranteed to satisfy the triangle inequality, for purposes of (asymmetric) metric learning and modeling graph distances. ",2002.05825,cs.LG,2020-02-14 00:47:31+00:00,2020-07-06 20:06:56+00:00
HJej3s09Km,2019,Reject,False,On the effect of the activation function on the distribution of hidden nodes in a deep network,"[""Philip M. Long and Hanie Sedghi""]","[""theory"", ""length map"", ""initialization""]","We prove that, for activation functions satisfying some conditions, as a deep network gets wide, the lengths of the vectors of hidden variables converge to a length map.",,,,
HJej6jR5Fm,2019,Reject,False,Meta-Learning to Guide Segmentation,"[""Kate Rakelly*"", ""Evan Shelhamer*"", ""Trevor Darrell"", ""Alexei A. Efros"", ""Sergey Levine""]","[""meta-learning"", ""few-shot learning"", ""visual segmentation""]",We propose a meta-learning approach for guiding visual segmentation tasks from varying amounts of supervision.,,,,
HJekvT4twr,2020,Reject,False,RGTI:Response generation via templates integration for End to End dialog,"[""Yuxin Zhang"", ""Songyan Liu""]","[""End-to-end dialogue systems"", ""transformer"", ""pointer-generate network""]",A new simple but efficient model for end-to-end dialogue ,,,,
HJel76NYPS,2020,Reject,False,Collaborative Generated Hashing for Market Analysis and Fast Cold-start Recommendation,"[""Yan Zhang"", ""Ivor W. Tsang"", ""Lixin Duan"", ""Guowu Yang""]","[""Recommender system"", ""generated model"", ""market analysis"", ""hash"", ""cold start""]",It can generate effective hash codes for efficient cold-start recommendation and meanwhile provide a feasible marketing strategy.,,,,
HJem3yHKwH,2020,Accept (Poster),False,EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks,"[""Sanchari Sen"", ""Balaraman Ravindran"", ""Anand Raghunathan""]","[""ensembles"", ""mixed precision"", ""robustness"", ""adversarial attacks""]",We propose ensembles of mixed-precision DNNs as a new form of defense against adversarial attacks,2004.10162,cs.LG,2020-04-21 17:17:09+00:00,2020-04-21 17:17:09+00:00
HJemQJBKDr,2020,Reject,False,Continual Density Ratio Estimation (CDRE): A new method for evaluating generative models in continual learning,"[""Yu Chen"", ""Song Liu"", ""Tom Diethe"", ""Peter Flach""]","[""density ratio estimation"", ""continual learning"", ""evaluation"", ""generative model"", ""f divergence""]",We propose a new method (Continual Density Ratio Estimation) for evaluating generative models in continual learning using f-divegences.,,,,
HJenn6VFvB,2020,Accept (Spotlight),False,Hamiltonian Generative Networks,"[""Peter Toth"", ""Danilo J. Rezende"", ""Andrew Jaegle"", ""S\u00e9bastien Racani\u00e8re"", ""Aleksandar Botev"", ""Irina Higgins""]","[""Hamiltonian dynamics"", ""normalising flows"", ""generative model"", ""physics""]",We introduce a class of generative models that reliably learn Hamiltonian dynamics from high-dimensional observations. The learnt Hamiltonian can be applied to sequence modeling or as a normalising flow.,,,,
HJepJh0qKX,2019,Reject,False,Empirical Study of Easy and Hard Examples in CNN Training,"[""Ikki Kishida"", ""Hideki Nakayama""]","[""easy examples"", ""hard example"", ""CNN""]","Unknown properties of easy and hard examples are shown, and they come from biases in a dataset and SGD.",,,,
HJepXaVYDr,2020,Accept (Poster),True,Stochastic AUC Maximization with Deep Neural Networks,"[""Mingrui Liu"", ""Zhuoning Yuan"", ""Yiming Ying"", ""Tianbao Yang""]","[""Stochastic AUC Maximization"", ""Deep Neural Networks""]","The paper designs two algorithms for the stochastic AUC maximization problem with state-of-the-art complexities when using deep neural network as predictive model, which are also verified by empirical studies.",1908.10831,cs.LG,2019-08-28 17:02:49+00:00,2020-06-30 03:25:14+00:00
HJeqWztlg,2017,Reject,False,Hierarchical compositional feature learning,"[""Miguel Lazaro-Gredilla"", ""Yi Liu"", ""D. Scott Phoenix"", ""Dileep George""]","[""Unsupervised Learning""]","We show that max-product message passing with an appropriate schedule can be used to perform inference and learning in a directed multilayer generative model, thus recovering interpretable features from binary images.",,,,
HJeqhA4YDS,2020,Accept (Poster),False,Denoising and Regularization via Exploiting the Structural Bias of Convolutional Generators,"[""Reinhard Heckel and Mahdi Soltanolkotabi""]","[""theory for deep learning"", ""convolutional network"", ""deep image prior"", ""deep decoder"", ""dynamics of gradient descent"", ""overparameterization""]",,,,,
HJerDj05tQ,2019,Reject,False,Optimization on Multiple Manifolds,"[""Mingyang Yi"", ""Huishuai Zhang"", ""Wei Chen"", ""Zhi-ming Ma"", ""Tie-yan Liu""]","[""Optimization"", ""Multiple constraints"", ""Manifold""]",This paper introduces an algorithm to handle optimization problem with multiple constraints under vision of manifold.,,,,
HJeu43ActQ,2019,Accept (Poster),False,NOODL: Provable Online Dictionary Learning and Sparse Coding,"[""Sirisha Rambhatla"", ""Xingguo Li"", ""Jarvis Haupt""]","[""dictionary learning"", ""provable dictionary learning"", ""online dictionary learning"", ""sparse coding"", ""support recovery"", ""iterative hard thresholding"", ""matrix factorization"", ""neural architectures"", ""neural networks"", ""noodl""]",We present a provable algorithm for exactly recovering both factors of the dictionary learning model. ,,,,
HJeuOiRqKQ,2019,Reject,False,Pooling Is Neither Necessary nor Sufficient for Appropriate Deformation Stability in CNNs,"[""Avraham Ruderman"", ""Neil C. Rabinowitz"", ""Ari S. Morcos"", ""Daniel Zoran""]","[""Convolutional Neural Networks"", ""Deformation Stability"", ""Pooling"", ""Transformation Invariance""]",We find that pooling alone does not determine deformation stability in CNNs and that filter smoothness plays an important role in determining stability. ,,,,
HJew70NYvH,2020,Reject,False,TPO: TREE SEARCH POLICY OPTIMIZATION FOR CONTINUOUS ACTION SPACES,"[""Amir Yazdanbakhsh"", ""Ebrahim Songhori"", ""Robert Ormandi"", ""Anna Goldie"", ""Azalia Mirhoseini""]","[""monte-carlo tree search"", ""reinforcement learning"", ""tree search"", ""policy optimization""]",We use MCTS to further optimize a bootstrapped policy for continuous action spaces under a policy iteration setting.,,,,
HJewiCVFPB,2020,Reject,False,Gradient Surgery for Multi-Task Learning,"[""Tianhe Yu"", ""Saurabh Kumar"", ""Abhishek Gupta"", ""Karol Hausman"", ""Sergey Levine"", ""Chelsea Finn""]","[""multi-task learning"", ""deep learning""]","We develop a simple and general approach for avoiding interference between gradients from different tasks, which improves the performance of multi-task learning in both the supervised and reinforcement learning domains.",,,,
HJewuJWCZ,2018,Accept (Poster),False,Learning to Teach,"[""Yang Fan"", ""Fei Tian"", ""Tao Qin"", ""Xiang-Yang Li"", ""Tie-Yan Liu""]",[],"We propose and verify the effectiveness of learning to teach, a new framework to automatically guide machine learning process.",,,,
HJewxlHFwH,2020,Reject,False,Skew-Explore: Learn faster in continuous spaces with sparse rewards,"[""Xi Chen"", ""Yuan Gao"", ""Ali Ghadirzadeh"", ""Marten Bjorkman"", ""Ginevra Castellano"", ""Patric Jensfelt""]","[""reinforcement learning"", ""exploration"", ""sparse reward""]",,,,,
HJex0o05F7,2019,Reject,False,UaiNets: From Unsupervised to Active Deep Anomaly Detection,"[""Tiago Pimentel"", ""Marianne Monteiro"", ""Juliano Viana"", ""Adriano Veloso"", ""Nivio Ziviani""]","[""Anomaly Detection"", ""Active  Learning"", ""Unsupervised Learning""]",A method for active anomaly detection. We present a new layer that can be attached to any deep learning model designed for unsupervised anomaly detection to transform it into an active method.,,,,
HJezF3VYPB,2020,Accept (Poster),False,Federated Adversarial Domain Adaptation,"[""Xingchao Peng"", ""Zijun Huang"", ""Yizhe Zhu"", ""Kate Saenko""]","[""Federated Learning"", ""Domain Adaptation"", ""Transfer Learning"", ""Feature Disentanglement""]","we present a principled approach to the problem of federated domain adaptation, which aims to align the representations learned among the different nodes with the data distribution of the target node.",1911.02054,cs.CV,2019-11-05 19:45:49+00:00,2019-12-21 22:03:36+00:00
HJf7ts0cFm,2019,Reject,False,State-Regularized Recurrent Networks,"[""Cheng Wang"", ""Mathias Niepert""]","[""recurrent network"", ""finite state machines"", ""state-regularized"", ""interpretability and explainability""]","We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (DFA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.",,,,
HJf9ZhC9FX,2019,Accept (Poster),False,Stochastic Gradient/Mirror Descent: Minimax Optimality and Implicit Regularization,"[""Navid Azizan"", ""Babak Hassibi""]","[""optimization"", ""stochastic gradient descent"", ""mirror descent"", ""implicit regularization"", ""deep learning theory""]",,,,,
HJfQrs0qt7,2019,Reject,False,Convergence Properties of Deep Neural Networks on Separable Data,"[""Remi Tachet des Combes"", ""Mohammad Pezeshki"", ""Samira Shabanian"", ""Aaron Courville"", ""Yoshua Bengio""]","[""learning dynamics"", ""gradient descent"", ""classification"", ""optimization"", ""cross-entropy"", ""hinge loss"", ""implicit regularization"", ""gradient starvation""]",This paper analyzes the learning dynamics of neural networks on classification tasks solved by gradient descent using the cross-entropy and hinge losses.,,,,
HJfSEnRqKQ,2019,Accept (Poster),False,Active Learning with Partial Feedback,"[""Peiyun Hu"", ""Zachary C. Lipton"", ""Anima Anandkumar"", ""Deva Ramanan""]","[""Active Learning"", ""Learning from Partial Feedback""]","We provide a new perspective on training a machine learning model from scratch in hierarchical label setting, i.e. thinking of it as two-way communication between human and algorithms, and study how we can both measure and improve the efficiency. ",,,,
HJflg30qKX,2019,Accept (Poster),False,Gradient descent aligns the layers of deep linear networks,"[""Ziwei Ji"", ""Matus Telgarsky""]","[""implicit regularization"", ""alignment of layers"", ""deep linear networks"", ""gradient descent"", ""separable data""]",,,,,
HJfwJ2A5KX,2019,Accept (Poster),False,Data-Dependent Coresets for Compressing Neural Networks with Applications to Generalization Bounds,"[""Cenk Baykal"", ""Lucas Liebenwein"", ""Igor Gilitschenski"", ""Dan Feldman"", ""Daniela Rus""]","[""coresets"", ""neural network compression"", ""generalization bounds"", ""matrix sparsification""]",,,,,
HJfxbhR9KQ,2019,Reject,False,Mimicking actions is a good strategy for beginners: Fast Reinforcement Learning with Expert Action Sequences,"[""Tharun Medini"", ""Anshumali Shrivastava""]","[""Reinforcement Learning"", ""Imitation Learning"", ""Atari"", ""A3C"", ""GA3C""]",Appending most frequent action pairs from an expert player to a novice RL agent's action space improves the scores by huge margin.,,,,
HJg1NTGZRZ,2018,Reject,False,Bit-Regularized Optimization of Neural Nets,"[""Mohamed Amer"", ""Aswin Raghavan"", ""Graham W. Taylor"", ""Sek Chai""]",[],,,,,
HJg2b0VYDr,2020,Accept (Poster),True,Selection via Proxy: Efficient Data Selection for Deep Learning,"[""Cody Coleman"", ""Christopher Yeh"", ""Stephen Mussmann"", ""Baharan Mirzasoleiman"", ""Peter Bailis"", ""Percy Liang"", ""Jure Leskovec"", ""Matei Zaharia""]","[""data selection"", ""active-learning"", ""core-set selection"", ""deep learning"", ""uncertainty sampling""]",we can significantly improve the computational efficiency of data selection in deep learning by using a much smaller proxy model to perform data selection.,1906.11829,cs.LG,2019-06-26 23:01:47+00:00,2020-10-27 00:52:20+00:00
HJg3HyStwB,2020,Reject,True,Perturbations are not Enough: Generating Adversarial Examples with Spatial Distortions,"[""He Zhao"", ""Trung Le"", ""Paul Montague"", ""Olivier De Vel"", ""Tamas Abraham"", ""Dinh Phung""]",[],A new adversarial attack for images with both perturbations and spatial distortions,1910.01329,cs.LG,2019-10-03 07:15:40+00:00,2019-10-03 07:15:40+00:00
HJg3Rp4FwH,2020,Reject,False,Policy Optimization In the Face of Uncertainty,"[""Tung-Long Vuong"", ""Han Nguyen"", ""Hai Pham"", ""Kenneth Tran""]","[""Reinforcement Learning"", ""Model-based Reinforcement Learning""]",,,,,
HJg3rjA5tQ,2019,Reject,False,Spread Divergences,"[""David Barber"", ""Mingtian Zhang"", ""Raza Habib"", ""Thomas Bird""]","[""Generative Adversarial Network"", ""Divergence""]",Using noise to define the divergence between distributions with different support.,,,,
HJg4qxSKPB,2020,Reject,True,Implicit Rugosity Regularization via Data Augmentation,"[""Daniel LeJeune"", ""Randall Balestriero"", ""Hamid Javadi"", ""Richard G. Baraniuk""]","[""deep networks"", ""implicit regularization"", ""Hessian"", ""rugosity"", ""curviness"", ""complexity""]","Data augmentation provides an implicit regularization of the rugosity or ""roughness"" of the learned function of a deep network.",1905.11639,cs.LG,2019-05-28 06:53:04+00:00,2019-10-10 20:31:18+00:00
HJg6VREFDH,2020,Reject,False,iWGAN: an Autoencoder WGAN for Inference,"[""Yao Chen"", ""Qingyi Gao"", ""Xiao Wang""]","[""Generative model"", ""Autoencoder"", ""Inference""]",,2109.05652,stat.ML,2021-09-13 00:43:21+00:00,2021-09-13 00:43:21+00:00
HJg6e2CcK7,2019,Reject,False,Clean-Label Backdoor Attacks,"[""Alexander Turner"", ""Dimitris Tsipras"", ""Aleksander Madry""]","[""data poisoning"", ""backdoor attacks"", ""clean labels"", ""adversarial examples"", ""generative adversarial networks""]",We show how to successfully perform backdoor attacks without changing training labels.,,,,
HJgBA2VYwH,2020,Accept (Poster),True,FSPool: Learning Set Representations with Featurewise Sort Pooling,"[""Yan Zhang"", ""Jonathon Hare"", ""Adam Pr\u00fcgel-Bennett""]","[""set auto-encoder"", ""set encoder"", ""pooling""]",Sort in encoder and undo sorting in decoder to avoid responsibility problem in set auto-encoders,1906.02795,cs.LG,2019-06-06 20:16:40+00:00,2020-05-01 09:40:45+00:00
HJgC60EtwB,2020,Accept (Poster),False,Robust Reinforcement Learning for Continuous Control with Model Misspecification,"[""Daniel J. Mankowitz"", ""Nir Levine"", ""Rae Jeong"", ""Abbas Abdolmaleki"", ""Jost Tobias Springenberg"", ""Yuanyuan Shi"", ""Jackie Kay"", ""Todd Hester"", ""Timothy Mann"", ""Martin Riedmiller""]","[""reinforcement learning"", ""robustness""]",A framework for incorporating robustness to model misspecification into continuous control Reinforcement Learning algorithms.,,,,
HJgCF0VFwr,2020,Accept (Poster),False,Probabilistic Connection Importance Inference and Lossless Compression of Deep Neural Networks,"[""Xin Xing"", ""Long Sha"", ""Pengyu Hong"", ""Zuofeng Shang"", ""Jun S. Liu""]",[],,,,,
HJgCcCNtwH,2020,Reject,False,NeuroFabric: Identifying Ideal Topologies for Training A Priori Sparse Networks,"[""Mihailo Isakov"", ""Michel A. Kinsy""]","[""Sparsity"", ""model compression"", ""training"", ""topology""]",We investigate pruning DNNs before training and provide an answer to which topology should be used for training a priori sparse networks.,2002.08339,cs.LG,2020-02-19 18:29:18+00:00,2020-02-19 18:29:18+00:00
HJgEMpVFwB,2020,Accept (Poster),False,Adversarial Policies: Attacking Deep Reinforcement Learning,"[""Adam Gleave"", ""Michael Dennis"", ""Cody Wild"", ""Neel Kant"", ""Sergey Levine"", ""Stuart Russell""]","[""deep RL"", ""adversarial examples"", ""security"", ""multi-agent""]",Deep RL policies can be attacked by other agents taking actions so as to create natural observations that are adversarial.,,,,
HJgEe1SKPr,2020,Reject,False,GAN-based Gaussian Mixture Model Responsibility Learning,"[""Wanming Huang"", ""Shuai Jiang"", ""Xuan Liang"", ""Ian Oppermann"", ""Richard Yi Da Xu""]","[""Generative Adversarial Networks""]",,,,,
HJgExaVtwr,2020,Accept (Poster),False,DivideMix: Learning with Noisy Labels as Semi-supervised Learning,"[""Junnan Li"", ""Richard Socher"", ""Steven C.H. Hoi""]","[""label noise"", ""semi-supervised learning""]",We propose a novel semi-supervised learning approach with SOTA performance on combating learning with noisy labels.,,,,
HJgFW6EKvH,2020,Reject,False,Generating Robust Audio Adversarial Examples using Iterative Proportional Clipping,"[""Hongting Zhang"", ""Qiben Yan"", ""Pan Zhou""]","[""audio adversarial examples"", ""attack"", ""machine learning""]",,,,,
HJgJS30qtm,2019,Reject,False,REVISTING NEGATIVE TRANSFER USING ADVERSARIAL LEARNING,"[""Saneem Ahmed Chemmengath"", ""Samarth Bharadwaj"", ""Suranjana Samanta"", ""Karthik Sankaranarayanan""]","[""Negative Transfer"", ""Adversarial Learning""]",We look at negative transfer from a domain adaptation point of view to derive an adversarial learning algorithm.,,,,
HJgJtT4tvB,2020,Accept (Poster),False,ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning,"[""Weihao Yu"", ""Zihang Jiang"", ""Yanfei Dong"", ""Jiashi Feng""]","[""reading comprehension"", ""logical reasoning"", ""natural language processing""]","We introduce ReClor, a reading comprehension dataset requiring logical reasoning, and find that current state-of-the-art models struggle with real logical reasoning with poor performance near that of random guess.",2002.04326,cs.CL,2020-02-11 11:54:29+00:00,2020-08-22 07:14:30+00:00
HJgK0h4Ywr,2020,Accept (Poster),True,Theory and Evaluation Metrics for Learning Disentangled Representations,"[""Kien Do"", ""Truyen Tran""]","[""disentanglement"", ""metrics""]",,1908.09961,cs.LG,2019-08-26 23:55:11+00:00,2021-03-18 22:59:04+00:00
HJgKYlSKvr,2020,Reject,False,Unsupervised Generative 3D Shape Learning from Natural Images,"[""Attila Szabo"", ""Givi Meishvili"", ""Paolo Favaro""]","[""unsupervised"", ""3D"", ""differentiable"", ""rendering"", ""disentangling"", ""interpretable""]",We train a generative 3D model of shapes from natural images in an fully unsupervised way.,,,,
HJgLLyrYwB,2020,Accept (Poster),False,State-only Imitation with Transition Dynamics Mismatch,"[""Tanmay Gangwani"", ""Jian Peng""]","[""Imitation learning"", ""Reinforcement Learning"", ""Inverse Reinforcement Learning""]",Algorithm for imitation with state-only expert demonstrations; builds on adversarial-IRL; experiments with transition dynamics mismatch b/w expert and imitator,2002.11879,stat.ML,2020-02-27 02:27:46+00:00,2020-02-27 02:27:46+00:00
HJgLZR4KvH,2020,Accept (Talk),True,Dynamics-Aware Unsupervised Discovery of Skills,"[""Archit Sharma"", ""Shixiang Gu"", ""Sergey Levine"", ""Vikash Kumar"", ""Karol Hausman""]","[""reinforcement learning"", ""unsupervised learning"", ""model-based learning"", ""deep learning"", ""hierarchical reinforcement learning""]",We propose an unsupervised skill discovery which enables model-based planning for hierarchical reinforcement learning.,1907.01657,cs.LG,2019-07-02 21:32:19+00:00,2020-02-14 23:20:43+00:00
HJgODj05KX,2019,Reject,False,A preconditioned accelerated stochastic gradient descent algorithm,"[""Alexandru Onose"", ""Seyed Iman Mossavat"", ""Henk-Jan H. Smilde""]","[""stochastic optimization"", ""neural network"", ""preconditioned accelerated stochastic gradient descent""]","We propose a preconditioned accelerated gradient method that combines Nesterovâs accelerated gradient descent with a class of diagonal preconditioners, in a stochastic setting.",,,,
HJgOl3AqY7,2019,Reject,True,Modulated Variational Auto-Encoders for Many-to-Many Musical Timbre Transfer,"[""Adrien Bitton"", ""Philippe Esling"", ""Axel Chemla-Romeu-Santos""]","[""Musical Timbre"", ""Instrument Translation"", ""Domain Translation"", ""Style Transfer"", ""Sound Synthesis"", ""Musical Information"", ""Deep Learning"", ""Variational Auto-Encoder"", ""Generative Models"", ""Network Conditioning""]","The paper uses Variational Auto-Encoding and network conditioning for Musical Timbre Transfer, we develop and generalize our architecture for many-to-many instrument transfers together with visualizations and evaluations.",1810.00222,cs.SD,2018-09-29 15:31:23+00:00,2018-09-29 15:31:23+00:00
HJgRCyHFDr,2020,Reject,False,On Weight-Sharing and Bilevel Optimization in Architecture Search,"[""Mikhail Khodak"", ""Liam Li"", ""Maria-Florina Balcan"", ""Ameet Talwalkar""]","[""neural architecture search"", ""weight-sharing"", ""bilevel optimization"", ""non-convex optimization"", ""hyperparameter optimization"", ""model selection""]",An analysis of the learning and optimization structures of architecture search in neural networks and beyond.,,,,
HJgS7p4FPH,2020,Reject,False,Accelerating Reinforcement Learning Through GPU Atari Emulation,"[""Steven Dalton"", ""Michael Garland"", ""Iuri Frosio""]","[""GPU"", ""reinforcement learning""]","This paper introduces a new library to emulate Atari games on a GPU and shows its benefits in terms of acceleration and scaling to multiple GPU system, while also providing an analysis of the advantages and disadvantages of GPU emulation for RL.",,,,
HJgSwyBKvr,2020,Accept (Poster),True,Weakly Supervised Disentanglement with Guarantees,"[""Rui Shu"", ""Yining Chen"", ""Abhishek Kumar"", ""Stefano Ermon"", ""Ben Poole""]","[""disentanglement"", ""theory of disentanglement"", ""representation learning"", ""generative models""]",We construct a theoretical framework for weakly supervised disentanglement and conducted lots of experiments to back up the theory.,1910.09772,cs.LG,2019-10-22 05:21:51+00:00,2020-04-10 21:39:33+00:00
HJgTHnActQ,2019,Reject,False,Local Image-to-Image Translation via Pixel-wise Highway Adaptive Instance Normalization,"[""Wonwoong Cho"", ""Seunghwan Choi"", ""Junwoo Park"", ""David Keetae Park"", ""Tao Qin"", ""Jaegul Choo""]","[""image to image translation"", ""image translation"", ""exemplar"", ""mutlimodal""]",,,,,
HJgVisRqtX,2019,Reject,False,SEGEN: SAMPLE-ENSEMBLE GENETIC EVOLUTIONARY NETWORK MODEL,"[""Jiawei Zhang"", ""Limeng Cui"", ""Fisher B. Gouza""]","[""Genetic Evolutionary Network"", ""Deep Learning"", ""Genetic Algorithm"", ""Ensemble Learning"", ""Representation Learning""]","We introduce a new representation learning model, namely âSample-Ensemble Genetic Evolutionary Networkâ (SEGEN), which can serve as an alternative approach to deep learning models.",,,,
HJgXCV9xx,2017,Accept (Poster),False,Dialogue Learning With Human-in-the-Loop,"[""Jiwei Li"", ""Alexander H. Miller"", ""Sumit Chopra"", ""Marc'Aurelio Ranzato"", ""Jason Weston""]","[""Natural language processing""]",we explore a reinforcement learning setting for dialogue where the bot improves its abilities using reward-based or textual feedback,,,,
HJgXsjA5tQ,2019,Accept (Poster),True,On the loss landscape of a class of deep neural networks with no bad local valleys,"[""Quynh Nguyen"", ""Mahesh Chandra Mukkamala"", ""Matthias Hein""]","[""loss landscape"", ""local minima"", ""deep neural networks""]",,1809.10749,cs.LG,2018-09-27 20:09:59+00:00,2018-12-24 00:58:29+00:00
HJgZrsC5t7,2019,Reject,False,Improving On-policy Learning with Statistical Reward Accumulation,"[""Yubin Deng"", ""Ke Yu"", ""Dahua Lin"", ""Xiaoou Tang"", ""Chen Change Loy""]",[],Improving On-policy Learning with Statistical Reward Accumulation,,,,
HJg_ECEKDr,2020,Reject,False,Generative Teaching Networks: Accelerating Neural Architecture Search by Learning  to Generate Synthetic Training Data,"[""Felipe Petroski Such"", ""Aditya Rawal"", ""Joel Lehman"", ""Kenneth Stanley"", ""Jeff Clune""]","[""Generative models"", ""generating synthetic data"", ""neural architecture search"", ""learning to teach"", ""meta-learning""]","We meta-learn a DNN to generate synthetic training data that rapidly teaches a learning DNN a target task, speeding up neural architecture search nine-fold. ",,,,
HJg_tkBtwS,2020,Reject,False,Model-Agnostic Feature Selection with Additional Mutual Information,"[""Mukund Sudarshan"", ""Aahlad Manas Puli"", ""Lakshmi Subramanian"", ""Sriram Sankararaman"", ""Rajesh Ranganath""]","[""feature selection"", ""interpretability"", ""randomization"", ""fdr control"", ""p-values""]","We develop a simple regression-based model-agnostic feature selection method to interpret data generating processes with FDR control, and outperform several popular baselines on several simulated, medical, and image datasets.",,,,
HJgb7lSFwS,2020,Reject,False,Distance-based Composable Representations with Neural Networks,"[""Graham Spinks"", ""Marie-Francine Moens""]","[""Representation learning"", ""Wasserstein distance"", ""Composability"", ""Templates""]",,,,,
HJgcvJBFvB,2020,Accept (Poster),True,Network Randomization: A Simple Technique for Generalization in Deep Reinforcement Learning,"[""Kimin Lee"", ""Kibok Lee"", ""Jinwoo Shin"", ""Honglak Lee""]","[""Deep reinforcement learning"", ""Generalization in visual domains""]",We propose a simple randomization technique for improving generalization in deep reinforcement learning across tasks with various unseen visual patterns.,1910.05396,cs.LG,2019-10-11 20:12:52+00:00,2020-02-15 08:29:25+00:00
HJgcw0Etwr,2020,Reject,False,Toward Understanding Generalization of Over-parameterized Deep ReLU network trained with SGD in Student-teacher Setting,"[""Yuandong Tian""]","[""deep ReLU network"", ""theoretical analysis"", ""generalization"", ""training dynamics"", ""student teacher setting"", ""interpolation region"", ""over-parameterization""]",This paper analyzes training dynamics and critical points of training deep ReLU network via SGD in the teacher-student setting. ,,,,
HJgd1nAqFX,2019,Accept (Poster),False,DOM-Q-NET:  Grounded RL on Structured Language,"[""Sheng Jia"", ""Jamie Ryan Kiros"", ""Jimmy Ba""]","[""Reinforcement Learning"", ""Web Navigation"", ""Graph Neural Networks""]",Graph-based Deep Q Network for Web Navigation ,,,,
HJgdo6VFPH,2020,Reject,True,OmniNet: A unified architecture for multi-modal multi-task learning,"[""Subhojeet Pramanik"", ""Priyanka Agrawal"", ""Aman Hussain""]","[""multimodal"", ""multi-task"", ""transformer"", ""spatio-temporal"", ""attention-networks"", ""neural-network""]",OmniNet is a unified and extended version of the Transformer architecture for multi-modal multi-task learning. ,1907.07804,cs.LG,2019-07-17 22:59:56+00:00,2020-07-03 09:59:06+00:00
HJgeEh09KQ,2019,Accept (Poster),False,Boosting Robustness Certification of Neural Networks,"[""Gagandeep Singh"", ""Timon Gehr"", ""Markus P\u00fcschel"", ""Martin Vechev""]","[""Robustness certification"", ""Adversarial Attacks"", ""Abstract Interpretation"", ""MILP Solvers"", ""Verification of Neural Networks""]",We refine the over-approximation results from incomplete verifiers using MILP solvers to prove more robustness properties than state-of-the-art. ,,,,
HJgepaNtDS,2020,Reject,False,Learnable Group Transform For Time-Series,"[""Romain Cosentino"", ""Behnaam Aazhang""]","[""Group Transform"", ""Time-Frequency Representation"", ""Wavelet Transform"", ""Group Theory"", ""Representation Theory"", ""Time-Series""]",,,,,
HJgfDREKDB,2020,Accept (Poster),True,Higher-Order Function Networks for Learning Composable 3D Object Representations,"[""Eric Mitchell"", ""Selim Engin"", ""Volkan Isler"", ""Daniel D Lee""]","[""computer vision"", ""3d reconstruction"", ""deep learning"", ""representation learning""]",Neural nets can encode complex 3D objects into the parameters of other (surprisingly small) neural nets,1907.10388,cs.LG,2019-07-24 12:31:16+00:00,2020-04-06 05:18:09+00:00
HJggj3VKPH,2020,Reject,False,On the Dynamics and Convergence of Weight Normalization for Training Neural Networks,"[""Yonatan Dukler"", ""Quanquan Gu"", ""Guido Montufar""]","[""Normalization methods"", ""Weight Normalization"", ""Convergence Theory""]",We prove ReLU networks trained with weight normalization converge and analyze distinct behavior of different convergence regimes.,,,,
HJghoa4YDB,2020,Reject,True,Temporal-difference learning for nonlinear value function approximation in the lazy training regime,"[""Andrea Agazzi"", ""Jianfeng Lu""]","[""deep reinforcement learning"", ""function approximation"", ""temporal-difference"", ""lazy training""]","Proof of convergence for TD learning with nonlinear value function approximation when parameters undergo little displacement during training. This regime (lazy training), occurs naturally in neural networks.",1905.10917,cs.LG,2019-05-27 01:11:41+00:00,2021-08-11 20:03:39+00:00
HJgkj0NFwr,2020,Reject,True,Differentiable Architecture Compression,"[""Shashank Singh"", ""Ashish Khetan"", ""Zohar Karnin""]",[],,1905.08170,cs.LG,2019-05-20 15:30:06+00:00,2019-05-20 15:30:06+00:00
HJgkx2Aqt7,2019,Accept (Poster),False,Learning To Simulate,"[""Nataniel Ruiz"", ""Samuel Schulter"", ""Manmohan Chandraker""]","[""Simulation in machine learning"", ""reinforcement learning"", ""policy gradients"", ""image rendering""]",We propose an algorithm that automatically adjusts parameters of a simulation engine to generate training data for a neural network such that validation accuracy is maximized.,,,,
HJglg2A9FX,2019,Reject,False,Iteratively Learning from the Best,"[""Yanyao Shen"", ""Sujay Sanghavi""]","[""noisy samples"", ""deep learning"", ""generative adversarial network""]",We propose a simple framework that addresses the problem of spurious data in both supervised and unsupervised settings.,,,,
HJgpugrKPS,2020,Accept (Poster),True,Scale-Equivariant Steerable Networks,"[""Ivan Sosnovik"", ""Micha\u0142 Szmaja"", ""Arnold Smeulders""]","[""Scale Equivariance"", ""Steerable Filters""]",,1910.11093,cs.CV,2019-10-14 16:46:34+00:00,2020-02-06 14:09:17+00:00
HJguLo0cKQ,2019,Reject,False,Strength in Numbers: Trading-off Robustness and Computation via Adversarially-Trained Ensembles,"[""Edward Grefenstette"", ""Robert Stanforth"", ""Brendan O'Donoghue"", ""Jonathan Uesato"", ""Grzegorz Swirszcz"", ""Pushmeet Kohli""]","[""adversarial examples"", ""adversarial robustness"", ""visualisation"", ""ensembles""]",Adversarial training of ensembles provides robustness to adversarial examples beyond that observed in adversarially trained models and independently-trained ensembles thereof.,,,,
HJgyAoRqFQ,2019,Reject,False,State-Denoised Recurrent Neural Networks,"[""Michael C. Mozer"", ""Denis Kazakov"", ""Robert V. Lindsey""]","[""recurrent nets"", ""attractor nets"", ""denoising"", ""sequence processing""]",We propose a mechanism for denoising the internal state of an RNN to improve generalization performance.,,,,
HJgySxSKvB,2020,Reject,False,Deep Relational Factorization Machines,"[""Hongchang Gao"", ""Gang Wu"", ""Ryan Rossi"", ""Viswanathan Swaminathan"", ""Heng Huang""]",[],,,,,
HJgzpgrYDr,2020,Reject,False,Learning to Reason: Distilling Hierarchy via Self-Supervision and Reinforcement Learning,"[""Jung-Su Ha"", ""Young-Jin Park"", ""Hyeok-Joo Chae"", ""Soon-Seo Park"", ""Han-Lim Choi""]","[""Reinforcement learning"", ""Self-supervised learning"", ""unsupervised learning"", ""representation learning""]",This work attempts to construct a hierarchical structure that combines learning and reasoning for multi-task RL.,,,,
HJgzt2VKPB,2020,Accept (Talk),True,CATER: A diagnostic dataset for Compositional Actions & TEmporal Reasoning,"[""Rohit Girdhar"", ""Deva Ramanan""]","[""Video Understanding"", ""Temporal Reasoning""]","We propose a new video understanding benchmark, with tasks that by-design require temporal reasoning to be solved, unlike most existing video datasets.",1910.04744,cs.CV,2019-10-10 17:52:19+00:00,2020-04-05 03:39:21+00:00
HJhIM0xAW,2018,Accept (Poster),False,Learning a neural response metric for retinal prosthesis,"[""Nishal P Shah"", ""Sasidhar Madugula"", ""EJ Chichilnisky"", ""Yoram Singer"", ""Jonathon Shlens""]","[""Metric learning"", ""Computational Neuroscience"", ""Retina"", ""Neural Prosthesis""]",Using triplets to learn a metric for comparing neural responses and improve the performance of a prosthesis.,,,,
HJhcg6Fxg,2017,Reject,False,Binary Paragraph Vectors,"[""Karol Grzegorczyk"", ""Marcin Kurdziel""]","[""Natural language processing"", ""Transfer Learning""]",Learning short codes for text documents with Binary Paragraph Vectors.,,,,
HJjePwx0-,2018,Reject,False,Better Generalization by Efficient Trust Region Method,"[""Xuanqing Liu"", ""Jason D. Lee"", ""Cho-Jui Hsieh""]",[],,,,,
HJjiFK5gx,2017,Accept (Poster),False,Neural Program Lattices,"[""Chengtao Li"", ""Daniel Tarlow"", ""Alexander L. Gaunt"", ""Marc Brockschmidt"", ""Nate Kushman""]","[""Deep learning"", ""Semi-Supervised Learning""]",,,,,
HJjvxl-Cb,2018,Invite to Workshop Track,False,Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor,"[""Tuomas Haarnoja"", ""Aurick Zhou"", ""Pieter Abbeel"", ""Sergey Levine""]","[""deep reinforcement learning"", ""maximum entropy learning"", ""stochastic actor-critic""]","We propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework.",,,,
HJl0jiRqtX,2019,Reject,False,EDDI: Efficient Dynamic Discovery of High-Value Information with Partial VAE,"[""Chao Ma"", ""Sebastian Tschiatschek"", ""Konstantina Palla"", ""Jose Miguel Hernandez Lobato"", ""Sebastian Nowozin"", ""Cheng Zhang""]","[""active variable selection"", ""missing data"", ""amortized inference""]",,,,,
HJl1ujCct7,2019,Reject,False,A Multi-modal one-class generative adversarial network for anomaly detection in manufacturing,"[""Shuhui Qu"", ""Janghwan Lee"", ""Wei Xiong"", ""Wonhyouk Jang"", ""Jie Wang""]","[""Anomaly detection"", ""one-class model"", ""GAN""]",,,,,
HJl2Ns0qKX,2019,Reject,False,Generative adversarial interpolative autoencoding: adversarial training on latent space interpolations encourages convex latent distributions,"[""Tim Sainburg"", ""Marvin Thielk"", ""Brad Thielman"", ""Benjamin Migliori"", ""Timothy Gentner""]","[""convex"", ""GAN"", ""autoencoder"", ""interpolation"", ""stimuli generation"", ""adversarial"", ""latent distribution""]",We designed an autoencoder which is trained to learn a convex latent distribution by using an adversarial loss function to discriminate latent space interpolations from real data. ,,,,
HJl8AaVFwB,2020,Reject,False,Deep Multiple Instance Learning for Taxonomic Classification of Metagenomic read sets,"[""Andreas Georgiou"", ""Vincent Fortuin"", ""Harun Mustafa"", ""Gunnar R\u00e4tsch""]",[],,,,,
HJl8SgHtwr,2020,Reject,False,VIMPNN: A physics informed neural network for estimating potential energies of out-of-equilibrium systems,"[""Jay Morgan"", ""Adeline Paiement"", ""Christian Klinke""]","[""neural network"", ""chemical energy estimation"", ""density functional theory""]",Using physics informed properties to estimate ground-state energies of molecular and crystal systems with a Neural Network,,,,
HJl8SkBYPr,2020,Reject,False,Consistency-Based Semi-Supervised Active Learning: Towards Minimizing Labeling Budget,"[""Mingfei Gao"", ""Zizhao Zhang"", ""Guo Yu"", ""Sercan O. Arik"", ""Larry S. Davis"", ""Tomas Pfister""]","[""Active learning"", ""semi-supervised learning""]",,,,,
HJl8_eHYvS,2020,Accept (Poster),False,Discriminative Particle Filter Reinforcement Learning for Complex Partial observations,"[""Xiao Ma"", ""Peter Karkus"", ""David Hsu"", ""Wee Sun Lee"", ""Nan Ye""]","[""Reinforcement Learning"", ""Partial Observability"", ""Differentiable Particle Filtering""]","We introduce DPFRL, a framework for reinforcement learning under partial and complex observations with an importance-weighted particle filter",2002.09884,cs.LG,2020-02-23 11:22:43+00:00,2020-02-23 11:22:43+00:00
HJlA0C4tPS,2020,Accept (Spotlight),False,A Probabilistic Formulation of Unsupervised Text Style Transfer,"[""Junxian He"", ""Xinyi Wang"", ""Graham Neubig"", ""Taylor Berg-Kirkpatrick""]","[""unsupervised text style transfer"", ""deep latent sequence model""]","We formulate a probabilistic latent sequence model to tackle unsupervised text style transfer, and show its effectiveness across a suite of unsupervised text style transfer tasks. ",2002.03912,cs.CL,2020-02-10 16:20:49+00:00,2020-04-29 23:26:16+00:00
HJlAUaVYvH,2020,Reject,False,Optimising Neural Network Architectures for Provable Adversarial Robustness,"[""Henry Gouk"", ""Timothy M. Hospedales""]","[""Provable adversarial robustness"", ""Lipschitz neural networks"", ""network architectures""]",,,,,
HJlEUoR9Km,2019,Reject,False,Improved resistance of neural networks to adversarial images through generative pre-training,"[""Joachim Wabnig""]","[""adversarial images"", ""Boltzmann machine"", ""mean field approximation""]",Generative pre-training with mean field Boltzmann machines increases robustness against adversarial images in neural networks.,,,,
HJlF3h4FvB,2020,Reject,True,Distillation $\approx$ Early Stopping? Harvesting Dark Knowledge Utilizing Anisotropic Information Retrieval For Overparameterized NN,"[""Bin Dong"", ""Jikai Hou"", ""Yiping Lu"", ""Zhihua Zhang""]","[""Distillation"", ""Learning Thoery"", ""Corrupted Label""]","theoretically understand the regularization effect of distillation. We show that early stopping is essential in this process. From this perspective, we developed a distillation method for learning with corrupted Label with theoretical guarantees.",1910.01255,stat.ML,2019-10-02 23:53:39+00:00,2019-10-02 23:53:39+00:00
HJlHzJBFwB,2020,Reject,False,Accelerating Monte Carlo Bayesian Inference via Approximating Predictive Uncertainty over the Simplex,"[""Yufei Cui"", ""Wuguannan Yao"", ""Qiao Li"", ""Antoni Chan"", ""Chun Jason Xue""]",[],,,,,
HJlISCEKvB,2020,Reject,False,Improving Multi-Manifold GANs with a Learned Noise Prior,"[""Matthew Amodio"", ""Smita Krishnaswamy""]","[""GAN"", ""generative adversarial network"", ""ensemble""]",A multi-generator GAN framework with an additional network to learn a prior over the input noise.,,,,
HJlLKjR9FQ,2019,Accept (Poster),True,Towards Understanding Regularization in Batch Normalization,"[""Ping Luo"", ""Xinjiang Wang"", ""Wenqi Shao"", ""Zhanglin Peng""]","[""batch normalization"", ""regularization"", ""deep learning""]",,1809.00846,cs.LG,2018-09-04 09:01:10+00:00,2019-04-24 05:23:45+00:00
HJlMkTNYvH,2020,Reject,False,MODiR: Multi-Objective Dimensionality Reduction for Joint Data Visualisation,"[""Tim Repke"", ""Ralf Krestel""]","[""dimensionality reduction"", ""visualisation"", ""text visualisation"", ""network drawing""]","Dimensionality reduction algorithm to visualise text with network information, for example an email corpus or co-authorships.",,,,
HJlNpoA5YQ,2019,Accept (Poster),False,The Laplacian in RL: Learning Representations with Efficient Approximations,"[""Yifan Wu"", ""George Tucker"", ""Ofir Nachum""]","[""Laplacian"", ""reinforcement learning"", ""representation""]",We propose a scalable method to approximate the eigenvectors of the Laplacian in the reinforcement learning context and we show that the learned representations can improve the performance of an RL agent.,,,,
HJlPC6NKDH,2020,Reject,False,Training Deep Neural Networks by optimizing over nonlocal paths in hyperparameter space,"[""Vlad Pushkarov"", ""Yonathan Efroni"", ""Mykola Maksymenko"", ""Maciej Koch-Janusz""]","[""deep learning"", ""Hyperparameter optimization"", ""dropout""]",Physics-inspired method for deep neural networks training in joint weights-hyperparameters space by optimizing over the non local path in that space. ,,,,
HJlP_pEFPH,2020,Reject,False,SRDGAN: learning the noise prior for Super Resolution with Dual Generative Adversarial Networks,"[""Jingwei GUAN"", ""Cheng PAN"", ""Songnan LI and Dahai YU""]","[""Super Resolution GAN Denoise""]",,,,,
HJlQ96EtPr,2020,Reject,False,FleXOR: Trainable Fractional Quantization,"[""Dongsoo Lee"", ""Se Jung Kwon"", ""Byeongwook Kim"", ""Yongkweon Jeon"", ""Baeseong Park"", ""Jeongin Yun"", ""Gu-Yeon Wei""]","[""Quantization"", ""Model Compression"", ""Trainable Compression"", ""XOR"", ""Encryption""]",We propose an encryption algorithm/architecture to compress quantized weights in order to achieve fractional numbers of bits per weight,,,,
HJlQfnCqKX,2019,Accept (Poster),False,Predicting the Generalization Gap in Deep Networks with Margin Distributions,"[""Yiding Jiang"", ""Dilip Krishnan"", ""Hossein Mobahi"", ""Samy Bengio""]","[""Deep learning"", ""large margin"", ""generalization bounds"", ""generalization gap.""]",We develop a new scheme to predict the generalization gap in deep networks with high accuracy.,,,,
HJlRFlHFPS,2020,Reject,False,Unsupervised Distillation of Syntactic Information from Contextualized Word Representations,"[""Shauli Ravfogel"", ""Yanai Elazar"", ""Jacob Goldberger"", ""Yoav Goldberg""]","[""dismantlement"", ""contextualized word representations"", ""language models"", ""representation learning""]",We distill language models representations for syntax by unsupervised metric learning,2010.05265,cs.CL,2020-10-11 15:13:18+00:00,2021-03-11 20:41:09+00:00
HJlSmC4FPS,2020,Accept (Poster),True,Robust And Interpretable Blind Image Denoising Via Bias-Free Convolutional Neural Networks,"[""Sreyas Mohan"", ""Zahra Kadkhodaie"", ""Eero P. Simoncelli"", ""Carlos Fernandez-Granda""]","[""denoising"", ""overfitting"", ""generalization"", ""robustness"", ""interpretability"", ""analysis of neural networks""]","We show that removing constant terms from CNN architectures ensures strong generalization across noise levels, and also provides interpretability of the denoising method via linear-algebra techniques.",1906.05478,eess.IV,2019-06-13 04:48:21+00:00,2020-02-08 05:55:05+00:00
HJlTpCEKvS,2020,Reject,True,Which Tasks Should Be Learned Together in Multi-task Learning?,"[""Trevor Standley"", ""Amir R. Zamir"", ""Dawn Chen"", ""Leonidas Guibas"", ""Jitendra Malik"", ""Silvio Savarese""]","[""multi-task learning"", ""Computer Vision""]","We analyze what tasks are best learned together in one network, and which are best to learn separately. ",1905.07553,cs.CV,2019-05-18 08:20:14+00:00,2020-09-03 00:03:26+00:00
HJlU-AVtvS,2020,Reject,True,A Fine-Grained Spectral Perspective on Neural Networks,"[""Greg Yang"", ""Hadi Salman""]","[""Neural Tangent Kernel"", ""Neural Network Gaussian Process"", ""Spectral theory"", ""Eigenvalues"", ""Harmonic analysis""]","Eigenvalues of Conjugate (aka NNGP) and Neural Tangent Kernel can be computed in closed form over the Boolean cube and reveal the effects of hyperparameters on neural network inductive bias, training, and generalization.",1907.10599,cs.LG,2019-07-24 17:58:45+00:00,2020-04-09 15:12:11+00:00
HJlWIANtPH,2020,Reject,False,Neural Embeddings for Nearest Neighbor Search Under Edit Distance,"[""Xiyuan Zhang"", ""Yang Yuan"", ""Piotr Indyk""]","[""Embedding"", ""Edit Distance"", ""Nearest Neighbor Search"", ""Learning-Augmented Algorithm""]","We propose a learning-based edit distance embedding method, which improves over prior data-independent approaches.",,,,
HJlWWJSFDH,2020,Accept (Spotlight),False,Strategies for Pre-training Graph Neural Networks,"[""Weihua Hu*"", ""Bowen Liu*"", ""Joseph Gomes"", ""Marinka Zitnik"", ""Percy Liang"", ""Vijay Pande"", ""Jure Leskovec""]","[""Pre-training"", ""Transfer learning"", ""Graph Neural Networks""]","We develop a strategy for pre-training Graph Neural Networks (GNNs) and systematically study its effectiveness on multiple datasets, GNN architectures, and diverse downstream tasks.",,,,
HJlWXhC5Km,2019,Reject,False,Learning to Control Visual Abstractions for Structured Exploration in Deep Reinforcement Learning,"[""catalin ionescu"", ""tejas kulkarni"", ""aaron van de oord"", ""andriy mnih"", ""vlad mnih""]","[""exploration"", ""deep reinforcement learning"", ""intrinsic motivation"", ""unsupervised learning""]",structured exploration in deep reinforcement learning via unsupervised visual abstraction discovery and control,,,,
HJlXC3EtwB,2020,Reject,False,Learning to Anneal and Prune Proximity Graphs for Similarity Search,"[""Minjia Zhang"", ""Wenhan Wang"", ""Yuxiong He""]","[""Similarity search"", ""Proximity graph"", ""Learning to prune"", ""Edge heterogeneity"", ""Annealing"", ""Efficiency""]",Annealable proximity graphs facilitates similarity search by learning to prune inferior edges without drastically changing graph properties.,,,,
HJlY0jA5F7,2019,Reject,False,Improving Sample-based Evaluation for Generative Adversarial Networks,"[""Shaohui Liu*"", ""Yi Wei*"", ""Jiwen Lu"", ""Jie Zhou""]",[],This paper improves existing sample-based evaluation for GANs and contains some insightful experiments.,,,,
HJlY_6VKDr,2020,Reject,False,BUZz: BUffer Zones for defending  adversarial examples in image classification,"[""Phuong Ha Nguyen*"", ""Kaleel Mahmood*"", ""Lam M. Nguyen"", ""Thanh Nguyen"", ""Marten van Dijk""]","[""adversarial machine learning"", ""machine learning security""]",Achieving strong adversarial defense (coined as BUZz) comparable to existing ones based on new security concept -- buffer zones,,,,
HJlYzhR9tm,2019,Reject,False,Language Modeling with Graph Temporal Convolutional Networks,"[""Hongyin Luo"", ""Yichen Li"", ""Jie Fu"", ""James Glass""]","[""Graph Neural Network"", ""Language Modeling"", ""Convolution""]",,,,,
HJldzhA5tQ,2019,Reject,False,Learning powerful policies and better dynamics models by encouraging consistency,"[""Shagun Sodhani"", ""Anirudh Goyal"", ""Tristan Deleu"", ""Yoshua Bengio"", ""Jian Tang""]","[""model-based reinforcement learning"", ""deep learning"", ""generative agents"", ""policy gradient"", ""imitation learning""]","In this paper, we formulate a way to ensure consistency between the predictions of dynamics model and the real observations from the environment. Thus allowing the agent to learn powerful policies, as well as better dynamics models.",,,,
HJlfAo09KX,2019,Reject,True,Guaranteed Recovery of One-Hidden-Layer Neural Networks via Cross Entropy,"[""Haoyu Fu"", ""Yuejie Chi"", ""Yingbin Liang""]","[""cross entropy"", ""neural networks"", ""parameter recovery""]",We provide the first theoretical analysis of guaranteed recovery of one-hidden-layer neural networks under cross entropy loss for classification problems.,1802.06463,stat.ML,2018-02-18 22:49:56+00:00,2020-05-06 04:09:34+00:00
HJlfuTEtvB,2020,Accept (Poster),True,CLN2INV: Learning Loop Invariants with Continuous Logic Networks,"[""Gabriel Ryan"", ""Justin Wong"", ""Jianan Yao"", ""Ronghui Gu"", ""Suman Jana""]","[""loop invariants"", ""deep learning"", ""logic learning""]","We introduce the Continuous Logic Network (CLN), a novel neural architecture for automatically learning loop invariants and general SMT formulas.",1909.11542,cs.LG,2019-09-25 15:05:02+00:00,2019-10-17 16:07:49+00:00
HJlgm-B9lx,2017,Reject,False,Learning to Understand: Incorporating Local Contexts with Global Attention for Sentiment Classification,"[""Zhigang Yuan"", ""Yuting Hu"", ""Yongfeng Huang""]","[""Natural language processing"", ""Deep learning"", ""Applications""]",a global-local mutually representation-learning attention model for sentiment analysis,,,,
HJli2hNKDH,2020,Accept (Poster),False,Observational Overfitting in Reinforcement Learning,"[""Xingyou Song"", ""Yiding Jiang"", ""Stephen Tu"", ""Yilun Du"", ""Behnam Neyshabur""]","[""observational"", ""overfitting"", ""reinforcement"", ""learning"", ""generalization"", ""implicit"", ""regularization"", ""overparametrization""]",We isolate one factor of RL generalization by analyzing the case when the agent only overfits to the observations. We show that architectural implicit regularizations occur in this regime.,1912.02975,cs.LG,2019-12-06 04:52:16+00:00,2019-12-28 04:04:43+00:00
HJlk-eHFwH,2020,Reject,False,AdaGAN: Adaptive GAN for Many-to-Many Non-Parallel Voice Conversion,"[""Maitreya Patel"", ""Mirali Purohit"", ""Mihir Parmar"", ""Nirmesh J. Shah"", ""Hemant A. Patil""]","[""Voice Conversion"", ""Deep Learning"", ""Non parallel"", ""GAN"", ""AdaGAN"", ""AdaIN""]",Novel adaptive instance normalization based GAN framework for non parallel many-to-many and zero-shot VC. ,,,,
HJlmHoR5tQ,2019,Accept (Poster),True,Adversarial Imitation via Variational Inverse Reinforcement Learning,"[""Ahmed H. Qureshi"", ""Byron Boots"", ""Michael C. Yip""]","[""Inverse Reinforcement Learning"", ""Imitation learning"", ""Variational lnference"", ""Learning from demonstrations""]",Our method introduces the empowerment-regularized maximum-entropy inverse reinforcement learning to learn near-optimal rewards and policies from expert demonstrations.,1809.06404,cs.LG,2018-09-17 18:47:47+00:00,2019-02-22 23:32:23+00:00
HJlmhs05tm,2019,Reject,False,EnGAN: Latent Space MCMC and Maximum Entropy Generators for Energy-based Models,"[""Rithesh Kumar"", ""Anirudh Goyal"", ""Aaron Courville"", ""Yoshua Bengio""]","[""Energy based model"", ""Generative models"", ""MCMC"", ""GANs""]","We introduced entropy maximization to GANs, leading to a reinterpretation of the critic as an energy function.",,,,
HJlnC1rKPB,2020,Accept (Poster),False,On the Relationship between Self-Attention and Convolutional Layers,"[""Jean-Baptiste Cordonnier"", ""Andreas Loukas"", ""Martin Jaggi""]","[""self-attention"", ""attention"", ""transformers"", ""convolution"", ""CNN"", ""image"", ""expressivity"", ""capacity""]",A self-attention layer can perform convolution and often learns to do so in practice.,1911.03584,cs.LG,2019-11-08 23:48:38+00:00,2020-01-10 09:06:09+00:00
HJloElBYvB,2020,Accept (Poster),False,Phase Transitions for the Information Bottleneck in Representation Learning,"[""Tailin Wu"", ""Ian Fischer""]","[""Information Theory"", ""Representation Learning"", ""Phase Transition""]",We give a theoretical analysis of the Information Bottleneck objective to understand and predict observed phase transitions in the prediction vs. compression tradeoff.,2001.01878,cs.LG,2020-01-07 03:55:32+00:00,2020-01-07 03:55:32+00:00
HJlrS1rYwH,2020,Reject,False,Policy Tree Network,"[""Zac Wellmer"", ""Sepanta Zeighami"", ""James Kwok""]","[""Reinforcement Learning""]",,,,,
HJlt7209Km,2019,Reject,False,Theoretical and Empirical Study of Adversarial Examples,"[""Fuchen Liu"", ""Hongwei Shang"", ""Hong Zhang""]","[""Adversarial examples"", ""Feature smoothing"", ""Data augmentation"", ""Decision boundary""]",,,,,
HJluEeHKwH,2020,Reject,False,The Differentiable Cross-Entropy Method,"[""Brandon Amos"", ""Denis Yarats""]","[""machine learning"", ""differentiable optimization"", ""control"", ""reinforcement learning""]",DCEM learns latent domains for optimization problems and helps bridge the gap between model-based and model-free RL --- we create a differentiable controller and fine-tune parts of it with PPO,,,,
HJlvCR4KDS,2020,Reject,False,Why Does the VQA Model Answer No?: Improving Reasoning through Visual and Linguistic Inference,"[""Seungjun Jung"", ""Junyoung Byun"", ""Kyujin Shim"", ""Changick Kim""]","[""Image Captioning"", ""Visual Question Answering"", ""Explainable A.I"", ""Beam Search"", ""Constrained Beam Search""]",,,,,
HJlxIJBFDr,2020,Accept (Poster),True,Sample Efficient Policy Gradient Methods with Recursive Variance Reduction,"[""Pan Xu"", ""Felicia Gao"", ""Quanquan Gu""]","[""Policy Gradient"", ""Reinforcement Learning"", ""Sample Efficiency""]",,1909.08610,cs.LG,2019-09-18 17:58:48+00:00,2021-08-01 22:04:34+00:00
HJlyLgrFvB,2020,Reject,False,All Simulations Are Not Equal: Simulation Reweighing for Imperfect Information Games,"[""Qucheng Gong"", ""Yuandong Tian""]","[""Contract Bridge"", ""Simulation"", ""Imperfect Information Games"", ""Reweigh"", ""Belief Modeling""]",Reweighing simulations through action history backwards verification can improve performances in imperfect information games.,,,,
HJlzxgBtwH,2020,Reject,True,Minimally distorted Adversarial Examples with a Fast Adaptive Boundary Attack,"[""Francesco Croce"", ""Matthias Hein""]","[""adversarial attacks"", ""adversarial robustness""]","We introduce a white-box adversarial attack wrt the $l_1$-, $l_2$- and $l_\infty$-norm achieving  state-of-the-art performances, minimizing the norm of the perturbations and being computationally cheap.",1907.02044,cs.LG,2019-07-03 17:22:05+00:00,2020-07-20 15:18:47+00:00
HJnQJXbC-,2018,Reject,False,AMPNet: Asynchronous Model-Parallel Training for Dynamic Neural Networks,"[""Alexander L. Gaunt"", ""Matthew A. Johnson"", ""Alan Lawrence"", ""Maik Riechert"", ""Daniel Tarlow"", ""Ryota Tomioka"", ""Dimitrios Vytiniotis"", ""Sam Webster""]","[""asynchronous"", ""neural network"", ""deep learning"", ""graph"", ""tree"", ""rnn""]",Using asynchronous gradient updates to accelerate dynamic neural network training,,,,
HJpfMIFll,2017,Accept (Poster),False,Geometry of Polysemy,"[""Jiaqi Mu"", ""Suma Bhat"", ""Pramod Viswanath""]","[""Natural language processing""]",,,,,
HJqUtdOaZ,2018,Reject,False,ENRICHMENT OF FEATURES FOR CLASSIFICATION USING AN OPTIMIZED LINEAR/NON-LINEAR COMBINATION OF INPUT FEATURES,"[""Mehran Taghipour-Gorjikolaie"", ""Seyyed Mohammad Razavi"", ""Javad Sadri""]","[""Classification"", ""Feature Combination"", ""Feature Mapping"", ""Feed-Forward Neural Network"", ""Genetic Algorithm"", ""Linear Transfer Function"", ""Non-Linear Transfer Function""]",A method for enriching and combining features to improve classification accuracy,,,,
HJr4QJ26W,2018,Reject,False,Improving image generative models with human interactions,"[""Andrew Kyle Lampinen"", ""David So"", ""Douglas Eck"", ""Fred Bertsch""]","[""human in the loop"", ""GANs"", ""generative adversarial networks"", ""image generative models"", ""computer vision""]","We describe how to improve an image generative model according to a slow- or difficult-to-evaluate objective, such as human feedback, which could have many applications, like making more aesthetic images.",,,,
HJrDIpiee,2017,Reject,False,Investigating Recurrence and Eligibility Traces in Deep Q-Networks,"[""Jean Harb"", ""Doina Precup""]","[""Reinforcement Learning"", ""Deep learning""]",Analyze the effects of using eligibility traces different optimizations in Deep Recurrent Q-Networks,,,,
HJrJpzZRZ,2018,Reject,False,Self-Supervised Learning of Object Motion Through Adversarial Video Prediction,"[""Alex X. Lee"", ""Frederik Ebert"", ""Richard Zhang"", ""Chelsea Finn"", ""Pieter Abbeel"", ""Sergey Levine""]","[""adversarial"", ""video prediction"", ""flow""]",,,,,
HJsjkMb0Z,2018,Accept (Poster),False,i-RevNet: Deep Invertible Networks,"[""J\u00f6rn-Henrik Jacobsen"", ""Arnold W.M. Smeulders"", ""Edouard Oyallon""]",[],,,,,
HJsk5-Z0W,2018,Reject,False,Structured Deep Factorization Machine: Towards General-Purpose Architectures,"[""Jos\u00e9 P. Gonz\u00e1lez-Brenes"", ""Ralph Edezhath""]","[""factorization"", ""general-purpose methods""]",Scalable general-purpose factorization algorithm-- also helps to circumvent cold start problem.,,,,
HJtEm4p6Z,2018,Accept (Poster),False,Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning,"[""Wei Ping"", ""Kainan Peng"", ""Andrew Gibiansky"", ""Sercan O. Arik"", ""Ajay Kannan"", ""Sharan Narang"", ""Jonathan Raiman"", ""John Miller""]","[""2000-Speaker Neural TTS"", ""Monotonic Attention"", ""Speech Synthesis""]",,,,,
HJtN5K9gx,2017,Reject,False,Learning Disentangled Representations in Deep Generative Models,"[""N. Siddharth"", ""Brooks Paige"", ""Alban Desmaison"", ""Jan-Willem van de Meent"", ""Frank Wood"", ""Noah D. Goodman"", ""Pushmeet Kohli"", ""Philip H.S. Torr""]","[""Semi-Supervised Learning"", ""Deep learning"", ""Computer vision""]",,,,,
HJvvRoe0W,2018,Accept (Poster),False,An image representation based convolutional network for DNA classification,"[""Bojian Yin"", ""Marleen Balvert"", ""Davide Zambrano"", ""Alexander Schoenhuth"", ""Sander Bohte""]","[""DNA sequences"", ""Hilbert curves"", ""Convolutional neural networks"", ""chromatin structure""]",A method to transform DNA sequences into 2D images using space-filling Hilbert Curves to enhance the strengths of CNNs,,,,
HJw8fAgA-,2018,Reject,False,Learning Dynamic State Abstractions for Model-Based Reinforcement Learning,"[""Lars Buesing"", ""Theophane Weber"", ""Sebastien Racaniere"", ""S. M. Ali Eslami"", ""Danilo Rezende"", ""David Reichert"", ""Fabio Viola"", ""Frederic Besse"", ""Karol Gregor"", ""Demis Hassabis"", ""Daan Wierstra""]","[""generative models"", ""probabilistic modelling"", ""reinforcement learning"", ""state-space models"", ""planning""]",,,,,
HJx-3grYDB,2020,Accept (Poster),False,Learning Nearly Decomposable Value Functions Via Communication Minimization,"[""Tonghan Wang*"", ""Jianhao Wang*"", ""Chongyi Zheng"", ""Chongjie Zhang""]","[""Multi-agent reinforcement learning"", ""Nearly decomposable value function"", ""Minimized communication"", ""Multi-agent systems""]",,,,,
HJx-akSKPS,2020,Reject,False,Neural Subgraph Isomorphism Counting,"[""Xin Liu"", ""Haojie Pan"", ""Mutian He"", ""Yangqiu Song"", ""Xin Jiang""]","[""subgraph isomorphism"", ""graph neural networks""]","In this paper, we study a new graph learning problem: learning to count subgraph isomorphisms.",,,,
HJx0U64FwS,2020,Reject,False,A Mechanism of Implicit Regularization in Deep Learning,"[""Masayoshi Kubo"", ""Genki Sugiura"", ""Kenta Shinzato"", ""Momose Oyama""]","[""Implicit Regularization"", ""Generalization"", ""Deep Neural Network"", ""Low Complexity""]",,,,,
HJx38iC5KX,2019,Reject,False,Domain Generalization via Invariant Representation under Domain-Class Dependency,"[""Kei Akuzawa"", ""Yusuke Iwasawa"", ""Yutaka Matsuo""]","[""domain generalization"", ""adversarial learning"", ""invariant feature learning""]",Address the trade-off caused by the dependency of classes on domains in domain generalization,,,,
HJx4KjRqYQ,2019,Reject,False,Ergodic Measure Preserving Flows,"[""Yichuan Zhang"", ""Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"", ""Zoubin Ghahramani""]","[""Markov chain Monte Carlo"", ""variational inference"", ""deep generative models""]",A novel computational scalable inference framework for training deep generative models and general statistical inference.,,,,
HJx4PAEYDH,2020,Reject,False,R-TRANSFORMER: RECURRENT NEURAL NETWORK ENHANCED TRANSFORMER,"[""Zhiwei Wang"", ""Yao Ma"", ""Zitao Liu"", ""Jiliang Tang""]","[""Sequence Modeling"", ""Multi-head Attention"", ""RNNs""]",This paper proposes an effective generic sequence model which leverages the strengths of both RNNs and Multi-head attention.,,,,
HJx54i05tX,2019,Accept (Oral),False,"On Random Deep Weight-Tied Autoencoders: Exact Asymptotic Analysis, Phase Transitions, and Implications to Training","[""Ping Li"", ""Phan-Minh Nguyen""]","[""Random Deep Autoencoders"", ""Exact Asymptotic Analysis"", ""Phase Transitions""]","We study the behavior of weight-tied multilayer vanilla autoencoders under the assumption of random weights. Via an exact characterization in the limit of large dimensions, our analysis reveals interesting phase transition phenomena.",,,,
HJx7l309Fm,2019,Reject,False,Actor-Attention-Critic for Multi-Agent Reinforcement Learning,"[""Shariq Iqbal"", ""Fei Sha""]","[""multi-agent"", ""reinforcement learning"", ""attention"", ""actor-critic""]",We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.,,,,
HJx7uJStPH,2020,Reject,False,Music Source Separation in the Waveform Domain,"[""Alexandre Defossez"", ""Nicolas Usunier"", ""Leon Bottou"", ""Francis Bach""]","[""source separation"", ""audio synthesis"", ""deep learning""]",We match the performance of spectrogram based model with a model trained end-to-end in the waveform domain,,,,
HJx81ySKwr,2020,Accept (Poster),False,Iterative energy-based projection on a normal data manifold for anomaly localization,"[""David Dehaene"", ""Oriel Frigo"", ""S\u00e9bastien Combrexelle"", ""Pierre Eline""]","[""deep learning"", ""visual inspection"", ""unsupervised anomaly detection"", ""anomaly localization"", ""autoencoder"", ""variational autoencoder"", ""gradient descent"", ""inpainting""]",We use gradient descent on a regularized autoencoder loss to correct anomalous images.,2002.03734,cs.CV,2020-02-10 13:35:41+00:00,2020-02-10 13:35:41+00:00
HJx8HANFDH,2020,Accept (Poster),True,Four Things Everyone Should Know to Improve Batch Normalization,"[""Cecilia Summers"", ""Michael J. Dinneen""]","[""batch normalization""]",Four things that improve batch normalization across all batch sizes,1906.03548,cs.LG,2019-06-09 01:14:48+00:00,2020-02-14 05:20:53+00:00
HJx9EhC9tQ,2019,Accept (Poster),False, Reasoning About Physical Interactions with Object-Oriented Prediction and Planning,"[""Michael Janner"", ""Sergey Levine"", ""William T. Freeman"", ""Joshua B. Tenenbaum"", ""Chelsea Finn"", ""Jiajun Wu""]","[""structured scene representation"", ""predictive models"", ""intuitive physics"", ""self-supervised learning""]",We present a framework for learning object-centric representations suitable for planning in tasks that require an understanding of physics.,,,,
HJxB5sRcFQ,2019,Accept (Poster),False,LayoutGAN: Generating Graphic Layouts with Wireframe Discriminators,"[""Jianan Li"", ""Jimei Yang"", ""Aaron Hertzmann"", ""Jianming Zhang"", ""Tingfa Xu""]",[],,,,,
HJxDugSFDB,2020,Reject,True,Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a Latent Variable Model,"[""Alex X. Lee"", ""Anusha Nagabandi"", ""Pieter Abbeel"", ""Sergey Levine""]",[],,1907.00953,cs.LG,2019-07-01 17:45:09+00:00,2020-10-26 12:21:51+00:00
HJxEhREKDH,2020,Accept (Poster),False,On the Global Convergence  of Training Deep Linear ResNets,"[""Difan Zou"", ""Philip M. Long"", ""Quanquan Gu""]",[],"Under certain condition on the input and output linear transformations, both GD and SGD can achieve global convergence for training deep linear ResNets.",2003.01094,cs.LG,2020-03-02 18:34:49+00:00,2020-03-02 18:34:49+00:00
HJxFrs09YQ,2019,Reject,False,GENERALIZED ADAPTIVE MOMENT ESTIMATION,"[""Guoqiang Zhang"", ""Kenta Niwa"", ""W. Bastiaan Kleijn""]","[""adaptive moment estimation"", ""SGD"", ""AMSGrad""]",A new adaptive gradient method is proposed for effectively training deep neural networks,,,,
HJxJ2h4tPr,2020,Reject,False,HighRes-net: Multi-Frame Super-Resolution by Recursive Fusion,"[""Michel Deudon"", ""Alfredo Kalaitzis"", ""Md Rifat Arefin"", ""Israel Goytom"", ""Zhichao Lin"", ""Kris Sankaran"", ""Vincent Michalski"", ""Samira E Kahou"", ""Julien Cornebise"", ""Yoshua Bengio""]","[""multi-frame super-resolution"", ""super-resolution"", ""remote sensing"", ""fusion"", ""de-aliasing"", ""deep learning"", ""registration""]","The first deep learning approach to MFSR to solve registration, fusion, up-sampling in an end-to-end manner.",,,,
HJxJdp4YvS,2020,Reject,False,Variational pSOM: Deep Probabilistic Clustering with Self-Organizing Maps,"[""Laura Manduchi"", ""Matthias H\u00fcser"", ""Gunnar R\u00e4tsch"", ""Vincent Fortuin""]","[""Self-organizing maps"", ""Generative models"", ""Unsupervised representation learning""]","We present a new deep architecture, VarPSOM, and its extension to time series data, VarTPSOM,  which achieve superior clustering performance compared to current deep clustering methods on static and temporal data.",,,,
HJxK5pEYvr,2020,Accept (Poster),False,Tree-Structured Attention with Hierarchical Accumulation,"[""Xuan-Phi Nguyen"", ""Shafiq Joty"", ""Steven Hoi"", ""Richard Socher""]","[""Tree"", ""Constituency Tree"", ""Hierarchical Accumulation"", ""Machine Translation"", ""NMT"", ""WMT"", ""IWSLT"", ""Text Classification"", ""Sentiment Analysis""]",,,,,
HJxKhyStPH,2020,Reject,True,Toward Understanding The Effect of Loss Function on The Performance of Knowledge Graph Embedding,"[""Mojtaba Nayyeri"", ""Chengjin Xu"", ""Yadollah Yaghoobzadeh"", ""Hamed Shariat Yazdi"", ""Jens Lehmann""]","[""Knowledge graph embedding"", ""Translation based embedding"", ""loss function"", ""relation pattern""]",,1909.00519,cs.AI,2019-09-02 03:10:14+00:00,2019-10-10 08:58:05+00:00
HJxMYANtPH,2020,Accept (Poster),False,The Local Elasticity of Neural Networks,"[""Hangfeng He"", ""Weijie Su""]",[],,,,,
HJxN0CNFPB,2020,Reject,False,Ladder Polynomial Neural Networks,"[""Li-Ping Liu"", ""Ruiyuan Gu"", ""Xiaozhe Hu""]","[""polynomial neural networks""]","This paper proposes LPNN, which is a new type of polynomial neural networks that can have arbitrary polynomial order.  ",2106.13834,cs.LG,2021-06-25 18:16:48+00:00,2021-06-29 04:57:17+00:00
HJxNAnVtDS,2020,Accept (Talk),False,On the Convergence of FedAvg on Non-IID Data,"[""Xiang Li"", ""Kaixuan Huang"", ""Wenhao Yang"", ""Shusen Wang"", ""Zhihua Zhang""]","[""Federated Learning"", ""stochastic optimization"", ""Federated Averaging""]",,,,,
HJxR7R4FvS,2020,Accept (Poster),False,RaCT: Toward Amortized Ranking-Critical Training For Collaborative Filtering ,"[""Sam Lobel*"", ""Chunyuan Li*"", ""Jianfeng Gao"", ""Lawrence Carin""]","[""Collaborative Filtering"", ""Recommender Systems"", ""Actor-Critic"", ""Learned Metrics""]","We apply the actor-critic methodology from reinforcement learning to collaborative filtering, resulting in improved performance across a variety of latent-variable models",,,,
HJxRMlrtPH,2020,Reject,False,Verification of Generative-Model-Based Visual Transformations,"[""Matthew Mirman"", ""Timon Gehr"", ""Martin Vechev""]","[""robustness certification"", ""formal verification"", ""robustness analysis"", ""latent space interpolations""]",We verify deterministic and probabilistic properties of neural networks using non-convex relaxations over visible transformations specified by generative models,,,,
HJxTgeBtDr,2020,Reject,False,Towards Interpretable Evaluations: A Case Study of Named Entity Recognition,"[""Jinlan Fu"", ""Pengfei Liu"", ""Xuanjing Huang""]","[""interpretable evaluation"", ""dataset biases"", ""model biases"", ""NER""]","We propose a generalized evaluation methodology to interpret model biases, dataset biases, and their correlation.",,,,
HJxV-ANKDH,2020,Accept (Poster),False,Efficient Riemannian Optimization on the Stiefel Manifold via the Cayley Transform,"[""Jun Li"", ""Fuxin Li"", ""Sinisa Todorovic""]","[""Orthonormality"", ""Efficient Riemannian Optimization"", ""the Stiefel manifold.""]",This paper is about efficient Riemannian optimization on the Stiefel manifold that enforces the parameter matrices orthonormal.,,,,
HJxV5yHYwB,2020,Reject,False,Solving single-objective tasks by preference multi-objective reinforcement learning,"[""Jinsheng Ren"", ""Shangqi Guo"", ""Feng Chen""]","[""reinforcement learning"", ""single-objective tasks"", ""multi-objectivization""]",Solving complex single-objective tasks by preference multi-objective reinforcement learning.,,,,
HJxVC1SYwr,2020,Reject,False,Crafting Data-free Universal Adversaries with Dilate Loss,"[""Deepak Babu Sam"", ""ABINAYA K"", ""Sudharsan K A"", ""Venkatesh Babu RADHAKRISHNAN""]",[],,,,,
HJxWl0NKPB,2020,Reject,False,Combining MixMatch and Active Learning for Better Accuracy with Fewer Labels,"[""Shuang Song"", ""David Berthelot"", ""Afshin Rostamizadeh""]","[""active learning"", ""semi-supervised learning""]",We combine MixMatch and active learning to obtain better accuracy with fewer labels and we follow this by a cost analysis comparing labeling data vs adding unlabeled data.. ,,,,
HJxXynC9t7,2019,Reject,False,Expressiveness in Deep Reinforcement Learning,"[""Xufang Luo"", ""Qi Meng"", ""Di He"", ""Wei Chen"", ""Yunhong Wang"", ""Tie-Yan Liu""]",[],,,,,
HJxYwiC5tm,2019,Reject,False,Why do deep convolutional networks generalize so poorly to small image transformations?,"[""Aharon Azulay"", ""Yair Weiss""]","[""Convolutional neural networks"", ""The sampling theorem"", ""Sensitivity to small image transformations"", ""Dataset bias"", ""Shiftability""]","Modern deep CNNs are not invariant to translations, scalings and other realistic image transformations, and this lack of invariance is related to the subsampling operation and the biases contained in image datasets.",,,,
HJx_d34YDB,2020,Reject,False,VIDEO AFFECTIVE IMPACT PREDICTION WITH MULTIMODAL FUSION AND LONG-SHORT TEMPORAL CONTEXT,"[""Yin Zhao"", ""Longjun Cai"", ""Chaoping Tu"", ""Jie Zhang"", ""Wu Wei""]","[""multi-modal fusion"", ""affective computing"", ""temporal context"", ""residual-based training strategy""]",,,,,
HJxcP2EFDS,2020,Reject,False,Amharic Negation Handling,"[""Girma Neshir""]","[""Negation Handling Algorithm"", ""Amharic Sentiment Analysis"", ""Amharic Sentiment lexicon"", ""char level"", ""word level ngram"", ""machine learning"", ""hybrid""]",This work presents Amharic Negation Handling for efficient Sentiment Classification.,,,,
HJxdAoCcYX,2019,Reject,False,Characterizing Malicious Edges targeting on Graph Neural Networks,"[""Xiaojun Xu"", ""Yue Yu"", ""Bo Li"", ""Le Song"", ""Chengfeng Liu"", ""Carl Gunter""]",[],,,,,
HJxdTxHYvB,2020,Accept (Poster),False,BREAKING  CERTIFIED  DEFENSES:  SEMANTIC  ADVERSARIAL  EXAMPLES  WITH  SPOOFED  ROBUSTNESS  CERTIFICATES,"[""Amin Ghiasi"", ""Ali Shafahi"", ""Tom Goldstein""]",[],,,,,
HJxeWnCcF7,2019,Accept (Poster),False,Learning Mixed-Curvature Representations in Product Spaces,"[""Albert Gu"", ""Frederic Sala"", ""Beliz Gunel"", ""Christopher R\u00e9""]","[""embeddings"", ""non-Euclidean geometry"", ""manifolds"", ""geometry of data""]",Product manifold embedding spaces with heterogenous curvature yield improved representations compared to traditional embedding spaces for a variety of structures.,,,,
HJxf53EtDr,2020,Reject,False,Unifying Graph Convolutional Networks as Matrix Factorization,"[""Zhaocheng Liu"", ""Qiang Liu"", ""Haoli Zhang"", ""Jun Zhu""]","[""graph convolutional networks"", ""matrix factorization"", ""unification""]",We unify graph convolutional networks as co-training and unitized matrix factorization.,,,,
HJxfm2CqKm,2019,Reject,False,Discovering General-Purpose Active Learning Strategies,"[""Ksenia Konyushkova"", ""Raphael Sznitman"", ""Pascal Fua""]","[""active learning"", ""meta learning"", ""reinforcement learning""]",,,,,
HJxhUpVKDr,2020,Reject,True,Branched Multi-Task Networks: Deciding What Layers To Share,"[""Simon Vandenhende"", ""Stamatios Georgoulis"", ""Bert De Brabandere"", ""Luc Van Gool""]","[""Multi-Task Learning"", ""Neural Network Architectures"", ""Deep learning"", ""Efficient Architectures""]",A method for the automated construction of branched multi-task networks with strong experimental evaluation on diverse multi-tasking datasets.,1904.02920,cs.CV,2019-04-05 08:00:32+00:00,2020-08-13 06:44:45+00:00
HJxhWa4KDr,2020,Reject,False,MMD GAN with Random-Forest Kernels,"[""Tao Huang"", ""Zhen Han"", ""Xu Jia"", ""Hanyuan Hang""]","[""GANs"", ""MMD"", ""kernel"", ""random forest"", ""unbiased gradients""]",Equip MMD GANs with a new random-forest kernel.,,,,
HJxiMAVtPH,2020,Reject,True,Multi-scale Attributed Node Embedding,"[""Benedek Rozemberczki"", ""Carl Allen"", ""Rik Sarkar""]","[""network embedding"", ""graph embedding"", ""node embedding"", ""network science"", ""graph representation learning""]",We develop efficient multi-scale approximate attributed network embedding procedures with provable properties.,1909.13021,cs.LG,2019-09-28 04:13:33+00:00,2021-03-21 22:05:08+00:00
HJxkvlBtwH,2020,Reject,False,Certifying Neural Network Audio Classifiers,"[""Wonryong Ryou"", ""Mislav Balunovic"", ""Gagandeep Singh"", ""Martin Vechev""]","[""Adversarial Examples"", ""Audio Classifier"", ""Speech Recognition"", ""Certified Robustness"", ""Deep Learning""]",We present the first approach to certify robustness of neural networks against noise-based perturbations in the audio domain.,,,,
HJxnM1rFvr,2020,Reject,True,HUBERT Untangles BERT to Improve Transfer across NLP Tasks,"[""Mehrad Moradshahi"", ""Hamid Palangi"", ""Monica S. Lam"", ""Paul Smolensky"", ""Jianfeng Gao""]","[""Tensor Product Representation"", ""BERT"", ""Transfer Learning"", ""Neuro-Symbolic Learning""]",We introduce HUBERT which combines the power of Tensor-Product Representations and BERT language model.,1910.12647,cs.CL,2019-10-25 06:25:25+00:00,2021-04-25 23:42:01+00:00
HJxp9kBFDS,2020,Reject,False,Invariance vs Robustness of Neural Networks,"[""Sandesh Kamath"", ""Amit Deshpande"", ""K V Subrahmanyam""]","[""Invariance"", ""Adversarial"", ""Robustness""]",,,,,
HJxpDiC5tX,2019,Reject,False, Large-Scale Visual Speech Recognition,"[""Brendan Shillingford"", ""Yannis Assael"", ""Matthew W. Hoffman"", ""Thomas Paine"", ""C\u00edan Hughes"", ""Utsav Prabhu"", ""Hank Liao"", ""Hasim Sak"", ""Kanishka Rao"", ""Lorrayne Bennett"", ""Marie Mulville"", ""Ben Coppin"", ""Ben Laurie"", ""Andrew Senior"", ""Nando de Freitas""]","[""visual speech recognition"", ""speech recognition"", ""lipreading""]",This work presents a scalable solution to continuous visual speech recognition.,,,,
HJxqMhC5YQ,2019,Reject,False,End-to-End Multi-Lingual Multi-Speaker Speech Recognition,"[""Hiroshi Seki"", ""Takaaki Hori"", ""Shinji Watanabe"", ""Jonathan Le Roux"", ""John R. Hershey""]","[""end-to-end ASR"", ""multi-lingual ASR"", ""multi-speaker ASR"", ""code-switching"", ""encoder-decoder"", ""connectionist temporal classification""]",,,,,
HJxrVA4FDS,2020,Accept (Spotlight),False,Disentangling neural mechanisms for perceptual grouping,"[""Junkyung Kim*"", ""Drew Linsley*"", ""Kalpit Thakkar"", ""Thomas Serre""]","[""Perceptual grouping"", ""visual cortex"", ""recurrent feedback"", ""horizontal connections"", ""top-down connections""]",Horizontal and top-down feedback connections are responsible for complementary perceptual grouping strategies in biological and recurrent vision systems.,,,,
HJxwAo09KQ,2019,Reject,False,Learned optimizers that outperform on wall-clock and validation loss,"[""Luke Metz"", ""Niru Maheswaranathan"", ""Jeremy Nixon"", ""Daniel Freeman"", ""Jascha Sohl-dickstein""]","[""Learned Optimizers"", ""Meta-Learning""]","We analyze problems when training learned optimizers, address those problems via variational optimization using two complementary gradient estimators, and train optimizers that are 5x faster in wall-clock time than baseline optimizers (e.g. Adam).",,,,
HJxwDiActX,2019,Accept (Poster),False,StrokeNet: A Neural Painting Environment,"[""Ningyuan Zheng"", ""Yifan Jiang"", ""Dingjiang Huang""]","[""image generation"", ""differentiable model"", ""reinforcement learning"", ""deep learning"", ""model based""]","StrokeNet is a novel architecture where the agent is trained to draw by strokes on a differentiable simulation of the environment, which could effectively exploit the power of back-propagation.",,,,
HJxwvCEFvH,2020,Reject,False,SPECTRA: Sparse Entity-centric Transitions,"[""Rim Assouel"", ""Yoshua Bengio""]","[""representation learning"", ""slot-structured representations"", ""sparse slot-structured transitions"", ""entity-centric representation"", ""unsupervised learning"", ""object-centric""]",Sparse slot-structured transition model. Training is done such that such that latent slots correspond to relevant entities of the visual scene.,,,,
HJxyAjRcFX,2019,Accept (Poster),False,Harmonizing Maximum Likelihood with GANs for Multimodal Conditional Generation,"[""Soochan Lee"", ""Junsoo Ha"", ""Gunhee Kim""]","[""conditional GANs"", ""conditional image generation"", ""multimodal generation"", ""reconstruction loss"", ""maximum likelihood estimation"", ""moment matching""]",We prove that the mode collapse in conditional GANs is largely attributed to a mismatch between reconstruction loss and GAN loss and introduce a set of novel loss functions as alternatives for reconstruction loss.,,,,
HJxyZkBKDr,2020,Accept (Spotlight),False,NAS-Bench-201: Extending the Scope of Reproducible Neural Architecture Search,"[""Xuanyi Dong"", ""Yi Yang""]","[""Neural Architecture Search"", ""AutoML"", ""Benchmark""]",A NAS benchmark applicable to almost any NAS algorithms.,2001.00326,cs.CV,2020-01-02 05:28:26+00:00,2020-01-15 12:38:55+00:00
HJy_5Mcll,2017,Reject,False,ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation,"[""Adam Paszke"", ""Abhishek Chaurasia"", ""Sangpil Kim"", ""Eugenio Culurciello""]","[""Deep learning""]",,,,,
HJz05o0qK7,2019,Accept (Poster),False,Measuring Compositionality in Representation Learning,"[""Jacob Andreas""]","[""compositionality"", ""representation learning"", ""evaluation""]","This paper proposes a simple procedure for evaluating compositional structure in learned representations, and uses the procedure to explore the role of compositionality in four learning problems.",,,,
HJz6tiCqYm,2019,Accept (Poster),False,Benchmarking Neural Network Robustness to Common Corruptions and Perturbations,"[""Dan Hendrycks"", ""Thomas Dietterich""]","[""robustness"", ""benchmark"", ""convnets"", ""perturbations""]",We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness,,,,
HJzLdjR9FX,2019,Reject,False,DeepTwist: Learning Model Compression via Occasional Weight Distortion,"[""Dongsoo Lee"", ""Parichay Kapoor"", ""Byeongwook Kim""]","[""deep learning"", ""model compression"", ""pruning"", ""quantization"", ""SVD"", ""regularization"", ""framework""]",We propose a unified model compression framework for performing a variety of model compression techniques.,,,,
HJzgZ3JCW,2018,Accept (Poster),False,Efficient Sparse-Winograd Convolutional Neural Networks,"[""Xingyu Liu"", ""Jeff Pool"", ""Song Han"", ""William J. Dally""]","[""deep learning"", ""convolutional neural network"", ""pruning""]",Prune and ReLU in Winograd domain for efficient convolutional neural network,1802.06367,cs.CV,2018-02-18 12:29:05+00:00,2018-02-18 12:29:05+00:00
HK_B2K0026,2021,Reject,False,Attention Based Joint Learning for Supervised Electrocardiogram Arrhythmia Differentiation with Unsupervised Abnormal Beat Segmentation,"[""Xinrong Hu"", ""long wen"", ""shushui wang"", ""Dongpo Liang"", ""Jian Zhuang"", ""Yiyu Shi""]","[""interpretability"", ""multitask learning"", ""attention mechanism"", ""electrocardiography""]","This paper presents a joint learning framework for supervised arrhythmia differentiation with unsupervised abnormal heart beat seg mentation on ECG, where the two tasks can benefit from each other.  ",,,,
HL_qE4fz-JZ,2022,Reject,True,Input Dependent Sparse Gaussian Processes ,"['Bahram Jafrasteh', 'Carlos Villacampa-Calvo', 'Daniel HernÃ¡ndez-Lobato']","[""gaussian processes"", ""variational inference"", ""neural networks"", ""sparse approximations""]",A new method for Sparse variational GPs that amortizes the computation of the location of the inducing points and the approximate posterior distribution using a NN.,2107.07281,cs.LG,2021-07-15 12:19:10+00:00,2021-07-15 12:19:10+00:00
HMEiDPTOTmY,2021,Reject,False,Later Span Adaptation for Language Understanding,"[""Rongzhou Bao"", ""Zhuosheng Zhang"", ""hai zhao""]",[],,,,,
HMJdXzbWKH,2022,Accept (Poster),False,Online Target Q-learning with Reverse Experience Replay: Efficiently finding the Optimal Policy for Linear MDPs,"['Naman Agarwal', 'Syomantak Chaudhuri', 'Prateek Jain', 'Dheeraj Mysore Nagaraj', 'Praneeth Netrapalli']","[""Q Learning"", ""RL with Function Approximation"", ""Experience Replay"", ""Online Target Learning""]",,,,,
HMR-7-4-Zr,2022,Reject,False,Contractive error feedback for gradient compression,"['Bingcong Li', 'Shuai Zheng', 'Parameswaran Raman', 'Anshumali Shrivastava', 'Georgios B. Giannakis']",[],This work reduces the memory overhead in communication efficient methods for distributed training.,,,,
HMqNjkBEqP4,2021,Reject,False,Bayesian Meta-Learning for Few-Shot 3D Shape Completion ,"[""Masanori Koyama"", ""Toshiki Nakanishi"", ""Shin-ichi Maeda"", ""Vitor Campagnolo Guizilini"", ""Adrien Gaidon""]","[""shape completion"", ""Meta-learning"", ""Few-shot"", ""3D reconstruction""]",We propose a novel shape completion algorithm that uses Bayesian meta-learning to improve generalization and performance on sparse datasets.,,,,
HNA0kUAFdbv,2021,Reject,False,CANVASEMB: Learning Layout Representation with Large-scale Pre-training for Graphic Design,"[""Yuxi Xie"", ""Danqing Huang"", ""Jinpeng Wang"", ""Chin-Yew Lin""]","[""Layout Representation"", ""Pre-training""]","we propose CanvasEmb for layout representation learning, which pre-trains deep representation from large-scale unlabeled graphic designs and facilitates downstream tasks for design intelligence.",,,,
HNytlGv1VjG,2021,Reject,False,What are effective labels for augmented data? Improving robustness with AutoLabel,"[""Yao Qin"", ""Xuezhi Wang"", ""Balaji Lakshminarayanan"", ""Ed Chi"", ""Alex Beutel""]","[""data augmentation"", ""image classification"", ""calibration"", ""distributional shifts"", ""adversarial robustness""]",,,,,
HO80-Z4l0M,2021,Reject,False,Alpha Net: Adaptation with Composition in Classifier Space,"[""Nadine Chang"", ""Jayanth Koushik"", ""Michael Tarr"", ""Martial Hebert"", ""Yu-Xiong Wang""]","[""long-tail recognition"", ""classifier composition""]","In this work, we demonstrate that transferring knowledge within classifier space can greatly improve the recognition performance on rare categories in the long-tail.",,,,
HOFxeCutxZR,2021,Accept (Poster),False,Enjoy Your Editing: Controllable GANs for Image Editing via Latent Space Navigation,"[""Peiye Zhuang"", ""Oluwasanmi O Koyejo"", ""Alex Schwing""]","[""Image manipulation"", ""GANs"", ""latent space of GANs""]",We propose a state-of-the-art approach to semantically edit images by transferring latent vectors towards meaningful latent space directions. ,,,,
HO_LL-oqBzW,2022,Reject,False,FCause: Flow-based Causal Discovery,"['Tomas Geffner', 'Emre Kiciman', 'Angus Lamb', 'Martin Kukla', 'Miltiadis Allamanis', 'Cheng Zhang']",[],,,,,
HObMhrCeAAF,2022,Accept (Poster),True,GradSign: Model Performance Inference with Theoretical Insights,"['Zhihao Zhang', 'Zhihao Jia']","[""Model Performance Inference"", ""Optimization Landscape"", ""NAS""]",Model performance inference inspired by sample-wise optimization landscape analysis,2110.08616,cs.LG,2021-10-16 17:03:10+00:00,2021-10-16 17:03:10+00:00
HOjLHrlZhmx,2022,Accept (Poster),True,CROP: Certifying Robust Policies for Reinforcement Learning through Functional Smoothing,"['Fan Wu', 'Linyi Li', 'Zijian Huang', 'Yevgeniy Vorobeychik', 'Ding Zhao', 'Bo Li']",[],,2106.09292,cs.LG,2021-06-17 07:58:32+00:00,2021-06-17 07:58:32+00:00
HP-tcf48fT,2021,Reject,False,Learning to Search for Fast Maximum Common Subgraph Detection,"[""Yunsheng Bai"", ""Derek Qiang Xu"", ""Yizhou Sun"", ""Wei Wang""]","[""graph matching"", ""maximum common subgraph"", ""graph neural network"", ""reinforcement learning"", ""search""]",We design a fast RL based approach to maximum common subgraph detection.,,,,
HPGtPvFNROh,2021,Reject,False,DROPS: Deep Retrieval of Physiological Signals via Attribute-specific Clinical Prototypes,"[""Dani Kiyasseh"", ""Tingting Zhu"", ""David A. Clifton""]","[""Contrastive learning"", ""information retrieval"", ""clustering"", ""physiological signals"", ""healthcare""]",,,,,
HQoCa9WODc0,2021,Reject,False,Suppressing Outlier Reconstruction in Autoencoders for Out-of-Distribution Detection,"[""Sangwoong Yoon"", ""Yung-Kyun Noh"", ""Frank C. Park""]","[""autoencoder"", ""outlier detection"", ""novelty detection"", ""energy-based model""]","We investigate the phenomenon of an autoencoder reconstructing outliers and propose Energy-Based Autoencoder, where the reconstruction of outliers are explicitly suppressed through an energy-based formulation.",,,,
HRF6T1SsyDn,2022,Reject,False,On the Expressiveness and Learning of Relational Neural Networks on Hypergraphs,"['Zhezheng Luo', 'Jiayuan Mao', 'Joshua B. Tenenbaum', 'Leslie Pack Kaelbling']","[""graph neural networks"", ""deep learning theory""]",We present a framework for analyzing the expressiveness and learning of relational models applied to hypergraph reasoning tasks. ,,,,
HRL6el2SBQ,2022,Reject,False,Intra-class Mixup for Out-of-Distribution Detection,"['Deepak Ravikumar', 'Sangamesh Kodge', 'Isha Garg', 'Kaushik Roy']",[],,,,,
HTVch9AMPa,2022,Accept (Poster),False,Delaunay Component Analysis for Evaluation of Data Representations,"['Petra Poklukar', 'Vladislav Polianskii', 'Anastasiia Varava', 'Florian T. Pokorny', 'Danica Kragic Jensfelt']","[""Interpretation and Evaluation of Learned Representations"", ""Generative Models"", ""Contrastive Learning""]",We present Delaunay Component Analysis (DCA) framework for evaluation of learned data representations which anayzes geometric and topological properties of representation spaces using Delaunay graphs.,,,,
HTfUrAxjPkR,2022,Reject,True,Translatotron 2: Robust direct speech-to-speech translation,"['Ye Jia', 'Michelle Tadmor Ramanovich', 'Tal Remez', 'Roi Pomerantz']","[""Speech-to-speech translation"", ""voice transferring"", ""end-to-end""]",A direct speech-to-speech translation model with performance very close to conventional cascade systems; also supports voice retention on input with speaker turns.,2107.08661,cs.CL,2021-07-19 07:43:49+00:00,2021-12-03 18:40:32+00:00
HTp-6yLGGX,2022,Accept (Poster),False,Hot-Refresh Model Upgrades with Regression-Free Compatible Training in Image Retrieval,"['Binjie Zhang', 'Yixiao Ge', 'Yantao Shen', 'Yu Li', 'Chun Yuan', 'XUYUAN XU', 'Yexin Wang', 'Ying Shan']","[""Compatible Representation Learning"", ""Image Retrieval"", ""Model Regression""]",We for the first time study the model regression problem in hot-refresh model upgrades of image retrieval systems with compatible representation learning.,2201.09724,cs.CV,2022-01-24 14:59:12+00:00,2022-01-24 14:59:12+00:00
HTx7vrlLBEj,2022,Accept (Spotlight),False,Half-Inverse Gradients for Physical Deep Learning,"['Patrick Schnell', 'Philipp Holl', 'Nils Thuerey']","[""physical simulation"", ""partial differential equations"", ""physical loss functions"", ""optimization""]","By proposing a novel Jacobian-based optimizer, we question the current practice of using the state-of-the-art gradient-based methods for the optimization of neural networks with physics objectives.",,,,
HUeyM2qVey2,2022,Reject,False,Universal Joint Approximation of Manifolds and Densities by Simple Injective Flows,"['Michael Anthony Puthawala', 'Matti Lassas', 'Ivan DokmaniÄ', 'Maarten V. de Hoop']","[""Universality"", ""Flow Networks"", ""Manifold Learning"", ""Density Estimation""]",We analyze neural networks composed of bijective flows and injective expansive elements and find that such networks universally approximate a large class of manifolds and densities there on.,,,,
HW4aTJHx0X,2021,Reject,False,What's new? Summarizing Contributions in Scientific Literature,"[""Hiroaki Hayashi"", ""Wojciech Maciej Kryscinski"", ""Bryan McCann"", ""Nazneen Rajani"", ""Caiming Xiong""]","[""abstractive summarization"", ""scientific papers""]","We propose a new task of disentangled paper summarization which aims to summarize contributions and contexts of scientific papers, we show the importance and usefulness of the task through experiments.",,,,
HWX5j6Bv_ih,2021,Reject,False,Cross-Node Federated Graph Neural Network for Spatio-Temporal Data Modeling,"[""Chuizheng Meng"", ""Sirisha Rambhatla"", ""Yan Liu""]","[""Federated Learning"", ""Graph Neural Network"", ""Spatio-Temporal Data Modeling""]",We propose a federated spatio-temporal model which explicitly encodes the underlying graph structure using graph neural network (GNN)-based architecture while ensuring that the data generated locally remains decentralized.,2106.05223,cs.LG,2021-06-09 17:12:43+00:00,2021-06-09 17:12:43+00:00
HWqv5Pm3E3,2021,Reject,False,Source-free Domain Adaptation via Distributional Alignment by Matching Batch Normalization Statistics,"[""Masato Ishii"", ""Masashi Sugiyama""]","[""domain adaptation"", ""transfer learning""]",,2101.10842,cs.CV,2021-01-19 14:22:33+00:00,2021-01-19 14:22:33+00:00
HY6i9FYBeFG,2022,Reject,False,S3: Supervised Self-supervised Learning under Label Noise,"['Chen Feng', 'Georgios Tzimiropoulos', 'Ioannis Patras']","[""Learning under label noise"", ""Supervised learning"", ""Self-supervised learning""]",An effective and robust method SOTA performance for learning with complex noisy dataset,2111.11288,cs.CV,2021-11-22 15:49:20+00:00,2021-11-22 15:49:20+00:00
HZcDljfUljt,2021,Reject,False,Filter pre-pruning for improved fine-tuning of quantized deep neural networks,"[""Jun Nishikawa"", ""Ryoji Ikegaya""]","[""Deep Neural Networks"", ""Quantization"", ""Quantize"", ""Pruning"", ""MobileNet"", ""compression""]",We propose a new pruning method for quantization and a new quantization workflow for high performance with low-bits.,2011.06751,cs.CV,2020-11-13 04:12:54+00:00,2020-11-25 05:22:16+00:00
H_qwVb8DQb-,2022,Reject,True,Balancing Average and Worst-case Accuracy in Multitask Learning,"['Paul Michel', 'Sebastian Ruder', 'Dani Yogatama']","[""multitask learning"", ""distributionally robust optimization""]","We propose a dynamic task weighting algorithm for minimizing worst-case performance in multitask learning by ""looking ahead"" and anticipating task interactions",2110.05838,cs.LG,2021-10-12 09:00:46+00:00,2021-10-12 09:00:46+00:00
HajQFbx_yB,2021,Accept (Oral),True,Scalable Learning and MAP Inference for Nonsymmetric Determinantal Point Processes,"[""Mike Gartrell"", ""Insu Han"", ""Elvis Dohmatob"", ""Jennifer Gillenwater"", ""Victor-Emmanuel Brunel""]","[""determinantal point processes"", ""unsupervised learning"", ""representation learning"", ""submodular optimization""]",We propose scalable learning and maximum a posteriori (MAP) inference algorithms for nonsymmetric determinantal point processes (DPPs).,2006.09862,cs.LG,2020-06-17 13:42:09+00:00,2021-04-13 15:16:06+00:00
Harn4_EZBw,2022,Accept (Poster),False,Generative Pseudo-Inverse Memory,"['Kha Pham', 'Hung Le', 'Man Ngo', 'Truyen Tran', 'Bao Ho', 'Svetha Venkatesh']",[],,,,,
HbZTcIuiMAG,2021,Reject,False,Fusion 360 Gallery: A Dataset and Environment for Programmatic CAD Reconstruction,"[""Karl Willis"", ""Yewen Pu"", ""Jieliang Luo"", ""Hang Chu"", ""Tao Du"", ""Joseph Lambourne"", ""Armando Solar-Lezama"", ""Wojciech Matusik""]","[""CAD"", ""dataset"", ""3D"", ""reconstruction"", ""environment"", ""design"", ""sequence""]",The Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction.,,,,
HbtFCX2PLq0,2022,Accept (Spotlight),False,Churn Reduction via Distillation,"['Heinrich Jiang', 'Harikrishna Narasimhan', 'Dara Bahri', 'Andrew Cotter', 'Afshin Rostamizadeh']","[""distillation"", ""churn"", ""constraints""]",We show distillation is a principled and practical solution to churn reduction.,,,,
HdX654Yn81,2021,Reject,False,Improving the Unsupervised Disentangled Representation Learning with VAE Ensemble,"[""Nanxiang Li"", ""Shabnam Ghaffarzadegan"", ""Liu Ren""]","[""Unsupervised disentangled representation learning"", ""network ensemble"", ""variational auto encoder""]",We show both theoretically and experimentally that an ensemble of VAEs with linear transformations connecting their latent representations can improve the unsupervised disentangled representation learning. ,,,,
HdnUQk9jbUO,2022,Reject,False,Linear Convergence of SGD on Overparametrized Shallow Neural Networks,"['Paul Rolland', 'Ali Ramezani-Kebrya', 'ChaeHwan Song', 'Fabian Latorre', 'Volkan Cevher']",[],,,,,
HeEzgm-f4g1,2021,Reject,False,On Batch-size Selection for Stochastic Training for Graph Neural Networks,"[""Yaochen Hu"", ""Amit Levi"", ""Ishaan Kumar"", ""Yingxue Zhang"", ""Mark Coates""]",[],,,,,
Hf3qXoiNkR,2021,Accept (Poster),False,Learning from others' mistakes: Avoiding dataset biases without modeling them,"[""Victor Sanh"", ""Thomas Wolf"", ""Yonatan Belinkov"", ""Alexander M Rush""]","[""dataset bias"", ""product of experts"", ""natural language processing""]",Reducing a model's reliance on dataset biases by encouraging a robust model to learn from a weak learner's mistakes.,,,,
HfUyCRBeQc,2022,Accept (Poster),False,Selective Ensembles for Consistent Predictions,"['Emily Black', 'Klas Leino', 'Matt Fredrikson']","[""consistency"", ""prediction consistency"", ""model duplicity"", ""inconsistent predictions"", ""deep models"", ""deep networks"", ""explanations"", ""saliency maps"", ""gradient-based explanations"", ""fairness"", ""interpretability""]","Deep models give inconsistent predictions and explanations over small changes (e.g. random initialization). We can mitigate this by using selective ensemble models, which abstain from prediction if their constituent models do not agree sufficiently.",2111.08230,cs.LG,2021-11-16 05:03:56+00:00,2021-11-16 05:03:56+00:00
HfnQjEN_ZC,2021,Reject,True,Ballroom Dance Movement Recognition Using a Smart Watch and Representation Learning,"[""Varun Badrinath Krishna""]","[""ballroom"", ""sequence"", ""deep"", ""learning"", ""machine"", ""markov"", ""prior""]",Deep learning combined with Markov priors are used ,2008.10122,cs.LG,2020-08-23 22:36:28+00:00,2020-09-04 05:25:56+00:00
Hg7xLoENqHW,2022,Reject,False,Robust Imitation via Mirror Descent Inverse Reinforcement Learning,"['Dong-Sig Han', 'Hyunseo Kim', 'Hyundo Lee', 'JeHwan Ryu', 'Byoung-Tak Zhang']","[""inverse reinforcement learning"", ""reward learning"", ""regularized markov decision processes"", ""imitation learning""]",we present a new online IRL algorithm that provides iterative proximal optimization targets.,,,,
HgLO8yalfwc,2021,Accept (Spotlight),True,Regularized Inverse Reinforcement Learning,"[""Wonseok Jeon"", ""Chen-Yang Su"", ""Paul Barde"", ""Thang Doan"", ""Derek Nowrouzezahrai"", ""Joelle Pineau""]","[""inverse reinforcement learning"", ""reward learning"", ""regularized markov decision processes"", ""reinforcement learning""]",We propose tractable solutions of regularized IRL and algorithms to acquire those solutions.,2010.03691,cs.LG,2020-10-07 23:38:47+00:00,2020-12-03 01:34:00+00:00
HiHWMiLP035,2022,Reject,True,E$^2$CM: Early Exit via Class Means for Efficient Supervised and Unsupervised Learning,"['Alperen Gormez', 'Erdem Koyuncu']","[""class means"", ""early exit"", ""efficient neural networks""]","We propose a better early exit technique for deep neural networks, which achieves the same performance with less computation.",2103.01148,cs.LG,2021-03-01 17:31:55+00:00,2021-10-20 15:54:27+00:00
HjD70ArLTQt,2021,Reject,False,Generating unseen complex scenes: are we there yet?,"[""Arantxa Casanova"", ""Michal Drozdzal"", ""Adriana Romero""]","[""generative adversarial networks"", ""conditional scene generation"", ""zero-shot generalization"", ""out of distribution""]",We study current state-of-the-art approaches for complex scene conditional image generation and measure their ability to generalize to unseen scene layouts and unseen object combinations.,,,,
Hk-FlMbAZ,2018,Reject,False,The Manifold Assumption and Defenses Against Adversarial Perturbations,"[""Xi Wu"", ""Uyeong Jang"", ""Lingjiao Chen"", ""Somesh Jha""]","[""the manifold assumption"", ""adversarial perturbation"", ""neural networks""]",Defending against adversarial perturbations of neural networks from manifold assumption ,,,,
Hk-mgcsgx,2017,Reject,False,An Information Retrieval Approach for Finding Dependent Subspaces of Multiple Views,"[""Ziyuan Lin"", ""Jaakko Peltonen""]","[""Unsupervised Learning""]","A novel method for seeking dependent subspaces across multiple views, preserving neighborhood relationships of data",,,,
Hk0wHx-RW,2018,Accept (Poster),False,Learning Sparse Latent Representations with the Deep Copula Information Bottleneck,"[""Aleksander Wieczorek*"", ""Mario Wieser*"", ""Damian Murezzan"", ""Volker Roth""]","[""Information Bottleneck"", ""Deep Information Bottleneck"", ""Deep Variational Information Bottleneck"", ""Variational Autoencoder"", ""Sparsity"", ""Disentanglement"", ""Interpretability"", ""Copula"", ""Mutual Information""]",We apply the copula transformation to the Deep Information Bottleneck which leads to restored invariance properties and a disentangled latent space with superior predictive capabilities.,,,,
Hk1iOLcle,2017,Reject,False,MS MARCO: A Human-Generated MAchine Reading COmprehension Dataset,"[""Tri Nguyen"", ""Mir Rosenberg"", ""Xia Song"", ""Jianfeng Gao"", ""Saurabh Tiwary"", ""Rangan Majumder"", ""Li Deng""]",[],A large scale human annotated data set for web-based reading comprehension along with baselines.,,,,
Hk1l9Xqxe,2017,Reject,False,BIOACOUSTIC SEGMENTATION BY HIERARCHICAL DIRICHLET PROCESS HIDDEN MARKOV MODEL,"[""Vincent Roger"", ""Marius Bartcus"", ""Faicel Chamroukhi"", ""Herv\u00e9 Glotin""]",[],,,,,
Hk2MHt-3-,2018,Reject,False,Coupled Ensembles of Neural Networks,"[""Anuvabh Dutt"", ""Denis Pellerin"", ""Georges Qu\u00e9not""]","[""Ensemble learning"", ""neural networks""]",We show that splitting a neural network into parallel branches improves performance and that proper coupling of the branches improves performance even further.,,,,
Hk2aImxAb,2018,Accept (Oral),False,Multi-Scale Dense Networks for Resource Efficient Image Classification,"[""Gao Huang"", ""Danlu Chen"", ""Tianhong Li"", ""Felix Wu"", ""Laurens van der Maaten"", ""Kilian Weinberger""]","[""efficient learning"", ""budgeted learning"", ""deep learning"", ""image classification"", ""convolutional networks""]",,,,,
Hk3ddfWRW,2018,Accept (Poster),False,Imitation Learning from Visual Data with Multiple Intentions,"[""Aviv Tamar"", ""Khashayar Rohanimanesh"", ""Yinlam Chow"", ""Chris Vigorito"", ""Ben Goodrich"", ""Michael Kahane"", ""Derik Pridmore""]","[""multi-modal imitation learning"", ""deep learning"", ""generative models"", ""stochastic neural networks""]",multi-modal imitation learning from unstructured demonstrations using stochastic neural network modeling intention. ,,,,
Hk3mPK5gg,2017,Accept (Poster),False,Training Agent for First-Person Shooter Game with Actor-Critic Curriculum Learning,"[""Yuxin Wu"", ""Yuandong Tian""]","[""Reinforcement Learning"", ""Applications"", ""Games""]","We propose a novel framework for training vision-based agent for First-Person Shooter (FPS) Game, Doom, using actor-critic model and curriculum training. ",,,,
Hk41X2AqtQ,2019,Reject,False,Hierarchically-Structured Variational Autoencoders for Long Text Generation,"[""Dinghan Shen"", ""Asli Celikyilmaz"", ""Yizhe Zhang"", ""Liqun Chen"", ""Xin Wang"", ""Lawrence Carin""]","[""Natural Language Processing"", ""Text Generation"", ""Variational Autoencoders""]",Propose a hierarchically-structured variational autoencoder for generating long and coherent units of text,,,,
Hk4_qw5xe,2017,Accept (Oral),False,Towards Principled Methods for Training Generative Adversarial Networks,"[""Martin Arjovsky"", ""Leon Bottou""]",[],We introduce a theory about generative adversarial networks and their issues.,,,,
Hk4dFjR5K7,2019,Accept (Poster),False,ADef: an Iterative Algorithm to Construct Adversarial Deformations,"[""Rima Alaifari"", ""Giovanni S. Alberti"", ""Tandri Gauksson""]","[""Adversarial examples"", ""deformations"", ""deep neural networks"", ""computer vision""]","We propose a new, efficient algorithm to construct adversarial examples by means of deformations, rather than additive perturbations.",,,,
Hk4fpoA5Km,2019,Accept (Poster),False,Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning,"[""Ilya Kostrikov"", ""Kumar Krishna Agrawal"", ""Debidatta Dwibedi"", ""Sergey Levine"", ""Jonathan Tompson""]","[""deep learning"", ""reinforcement learning"", ""imitation learning"", ""adversarial learning""]",We address sample inefficiency and reward bias in adversarial imitation learning algorithms such as GAIL and AIRL.,,,,
Hk4kQHceg,2017,Invite to Workshop Track,False,Multiplicative LSTM for sequence modelling,"[""Ben Krause"", ""Iain Murray"", ""Steve Renals"", ""Liang Lu""]","[""Deep learning"", ""Natural language processing"", ""Unsupervised Learning""]",Combines LSTM and multiplicative RNN architectures; achieves 1.19 bits/character on Hutter prize dataset with dynamic evaluation.,,,,
Hk5elxbRW,2018,Accept (Poster),False,Smooth Loss Functions for Deep Top-k Classification,"[""Leonard Berrada"", ""Andrew Zisserman"", ""M. Pawan Kumar""]",[],Smooth Loss Function for Top-k Error Minimization,,,,
Hk6WhagRW,2018,Accept (Poster),False,Emergent Communication through Negotiation,"[""Kris Cao"", ""Angeliki Lazaridou"", ""Marc Lanctot"", ""Joel Z Leibo"", ""Karl Tuyls"", ""Stephen Clark""]","[""multi-agent learning"", ""reinforcement learning"", ""game theory"", ""emergent communication""]","We teach agents to negotiate using only reinforcement learning; selfish agents can do so, but only using a trustworthy communication channel, and prosocial agents can negotiate using cheap talk.",,,,
Hk6a8N5xe,2017,Reject,False,Classify or Select: Neural Architectures for Extractive Document Summarization,"[""Ramesh Nallapati"", ""Bowen Zhou and Mingbo Ma""]","[""Natural language processing"", ""Supervised Learning"", ""Applications"", ""Deep learning""]","This paper presents two different neural architectures for extractive document summarization whose predictions are very interpretable, and show that they reach or outperform state-of-the-art supervised models.",,,,
Hk6kPgZA-,2018,Accept (Oral),False,Certifying Some Distributional Robustness with Principled Adversarial Training,"[""Aman Sinha"", ""Hongseok Namkoong"", ""John Duchi""]","[""adversarial training"", ""distributionally robust optimization"", ""deep learning"", ""optimization"", ""learning theory""]","We provide a fast, principled adversarial training procedure with computational and statistical performance guarantees.",,,,
Hk85q85ee,2017,Invite to Workshop Track,False,Symmetry-Breaking Convergence Analysis of Certain Two-layered Neural Networks with ReLU nonlinearity,"[""Yuandong Tian""]","[""Theory"", ""Deep learning"", ""Optimization""]","In this paper, we use dynamical system to analyze the nonlinear weight dynamics of two-layered bias-free ReLU networks.",,,,
Hk8N3Sclg,2017,Accept (Oral),False,Multi-Agent Cooperation and the Emergence of (Natural) Language,"[""Angeliki Lazaridou"", ""Alexander Peysakhovich"", ""Marco Baroni""]","[""Natural language processing"", ""Reinforcement Learning"", ""Games""]",,,,,
Hk8TGSKlg,2017,Accept (Poster),False,Reasoning with Memory Augmented Neural Networks for Language Comprehension,"[""Tsendsuren Munkhdalai"", ""Hong Yu""]","[""Natural language processing"", ""Deep learning""]",,,,,
Hk8XMWgRb,2018,Accept (Poster),False,Not-So-Random Features,"[""Brian Bullins"", ""Cyril Zhang"", ""Yi Zhang""]","[""kernel learning"", ""random features"", ""online learning""]","A simple and practical algorithm for learning a margin-maximizing translation-invariant or spherically symmetric kernel from training data, using tools from Fourier analysis and regret minimization.",,,,
Hk8rlUqge,2017,Reject,False,Joint Multimodal Learning with Deep Generative Models,"[""Masahiro Suzuki"", ""Kotaro Nakayama"", ""Yutaka Matsuo""]",[],,,,,
Hk91SGWR-,2018,Invite to Workshop Track,False,Investigating Human Priors for Playing Video Games,"[""Rachit Dubey"", ""Pulkit Agrawal"", ""Deepak Pathak"", ""Thomas L. Griffiths"", ""Alexei A. Efros""]","[""Prior knowledge"", ""Reinforcement learning"", ""Cognitive Science""]",We investigate the various kinds of prior knowledge that help human learning and find that general priors about objects play the most critical role in guiding human gameplay.,,,,
Hk95PK9le,2017,Accept (Poster),False,Deep Biaffine Attention for Neural Dependency Parsing,"[""Timothy Dozat"", ""Christopher D. Manning""]","[""Natural language processing"", ""Deep learning""]",,,,,
Hk99zCeAb,2018,Accept (Oral),False,"Progressive Growing of GANs for Improved Quality, Stability, and Variation","[""Tero Karras"", ""Timo Aila"", ""Samuli Laine"", ""Jaakko Lehtinen""]","[""generative adversarial networks"", ""unsupervised learning"", ""hierarchical methods""]","We train generative adversarial networks in a progressive fashion, enabling us to generate high-resolution images with high quality.",,,,
Hk9Xc_lR-,2018,Accept (Poster),False,On the Discrimination-Generalization Tradeoff in GANs,"[""Pengchuan Zhang"", ""Qiang Liu"", ""Dengyong Zhou"", ""Tao Xu"", ""Xiaodong He""]","[""generative adversarial network"", ""discrimination"", ""generalization""]",This paper studies the discrimination and generalization properties of GANs when the discriminator set is a restricted function class like neural networks.,,,,
HkAClQgA-,2018,Accept (Poster),False,A Deep Reinforced Model for Abstractive Summarization,"[""Romain Paulus"", ""Caiming Xiong"", ""Richard Socher""]","[""deep learning"", ""natural language processing"", ""reinforcement learning"", ""text summarization"", ""sequence generation""]",A summarization model combining a new intra-attention and reinforcement learning method to increase summary ROUGE scores and quality for long sequences.,,,,
HkCjNI5ex,2017,Reject,False,Regularizing Neural Networks by Penalizing Confident Output Distributions,"[""Gabriel Pereyra"", ""George Tucker"", ""Jan Chorowski"", ""Lukasz Kaiser"", ""Geoffrey Hinton""]","[""Deep learning"", ""Supervised Learning"", ""Speech"", ""Structured prediction""]","We show that penalizing low entropy output distributions, which has been shown to improve exploration in reinforcement learning, acts as a strong regularizer in supervised learning.",,,,
HkCnm-bAb,2018,Invite to Workshop Track,False,Can Deep Reinforcement Learning solve Erdos-Selfridge-Spencer Games?,"[""Maithra Raghu"", ""Alex Irpan"", ""Jacob Andreas"", ""Robert Kleinberg"", ""Quoc Le"", ""Jon Kleinberg""]","[""deep learning"", ""deep reinforcement learning"", ""combinatorial games"", ""optimality""]","We adapt a family of combinatorial games with tunable difficulty and an optimal policy expressible as linear network, developing it as a rich environment for reinforcement learning, showing contrasts in performance with supervised learning, and analyzing multiagent learning and generalization. ",,,,
HkCsm6lRb,2018,Accept (Poster),False,Generative Models of Visually Grounded Imagination,"[""Ramakrishna Vedantam"", ""Ian Fischer"", ""Jonathan Huang"", ""Kevin Murphy""]","[""variational autoencoders"", ""generative models"", ""language"", ""vision"", ""abstraction"", ""compositionality"", ""hierarchy""]","A VAE-variant which can create diverse images corresponding to novel concrete or abstract ""concepts"" described using attribute vectors.",,,,
HkCvZXbC-,2018,Reject,False,3C-GAN: AN CONDITION-CONTEXT-COMPOSITE GENERATIVE ADVERSARIAL NETWORKS FOR GENERATING IMAGES SEPARATELY,"[""Yeu-Chern Harn"", ""Vladimir Jojic""]",[],,,,,
HkE0Nvqlg,2017,Accept (Poster),False,Structured Attention Networks,"[""Yoon Kim"", ""Carl Denton"", ""Luong Hoang"", ""Alexander M. Rush""]",[],Use a graphical model as a hidden layer to perform attention over latent structures,,,,
HkEI22jeg,2017,Accept (Poster),False,Multilayer Recurrent Network Models of Primate Retinal Ganglion Cell Responses,"[""Eleanor Batty"", ""Josh Merel"", ""Nora Brackbill"", ""Alexander Heitman"", ""Alexander Sher"", ""Alan Litke"", ""E.J. Chichilnisky"", ""Liam Paninski""]","[""Deep learning"", ""Applications""]",,,,,
HkElFj0qYQ,2019,Reject,False,PPD: Permutation Phase Defense Against Adversarial Examples in Deep Learning,"[""Mehdi Jafarnia-Jahromi"", ""Tasmin Chowdhury"", ""Hsin-Tai Wu"", ""Sayandev Mukherjee""]","[""permutation phase defense"", ""adversarial attacks"", ""deep learning""]",Permutation phase defense is proposed as a novel method to guard against adversarial attacks in deep learning.,,,,
HkG3e205K7,2019,Accept (Poster),False,Doubly Reparameterized Gradient Estimators for Monte Carlo Objectives,"[""George Tucker"", ""Dieterich Lawson"", ""Shixiang Gu"", ""Chris J. Maddison""]","[""variational autoencoder"", ""reparameterization trick"", ""IWAE"", ""VAE"", ""RWS"", ""JVI""]",Doubly reparameterized gradient estimators provide unbiased variance reduction which leads to improved performance.,,,,
HkGGfhC5Y7,2019,Reject,False,Towards a better understanding of Vector Quantized Autoencoders,"[""Aurko Roy"", ""Ashish Vaswani"", ""Niki Parmar"", ""Arvind Neelakantan""]","[""machine translation"", ""vector quantized autoencoders"", ""non-autoregressive"", ""NMT""]",Understand the VQ-VAE discrete autoencoder systematically using EM and use it to design non-autogressive translation model matching a strong autoregressive baseline.,,,,
HkGJUXb0-,2018,Invite to Workshop Track,False,Learning Efficient Tensor Representations with Ring Structure Networks,"[""Qibin Zhao"", ""Masashi Sugiyama"", ""Longhao Yuan"", ""Andrzej Cichocki""]","[""Tensor Decomposition"", ""Tensor Networks"", ""Stochastic Gradient Descent""]",,,,,
HkGSniC9FQ,2019,Reject,False,An Analysis of Composite Neural Network Performance from Function Composition Perspective,"[""Ming-Chuan Yang"", ""Meng Chang Chen""]",[],,,,,
HkGTwjCctm,2019,Reject,False,Pyramid Recurrent Neural Networks for Multi-Scale Change-Point Detection,"[""Zahra Ebrahimzadeh"", ""Min Zheng"", ""Selcuk Karakas"", ""Samantha Kleinberg""]","[""changepoint detection"", ""multivariate time series data"", ""multiscale RNN""]",We introduce a scale-invariant neural network architecture for changepoint detection in multivariate time series.,,,,
HkGcX--0-,2018,Reject,False,Auxiliary Guided Autoregressive Variational Autoencoders,"[""Thomas Lucas"", ""Jakob Verbeek""]",[],,,,,
HkGmDsR9YQ,2019,Reject,True,Generalization and Regularization in DQN,"[""Jesse Farebrother"", ""Marlos C. Machado"", ""Michael Bowling""]","[""generalization"", ""reinforcement learning"", ""dqn"", ""regularization"", ""transfer learning"", ""multitask""]","We study the generalization capabilities of DQN using the new modes and difficulties of Atari games. We show how regularization can improve DQN's ability to generalize across tasks, something it often fails to do.",1810.00123,cs.LG,2018-09-29 00:52:34+00:00,2020-01-17 23:25:22+00:00
HkGsHj05tQ,2019,Reject,False,Effective and Efficient Batch Normalization Using Few Uncorrelated Data for Statistics' Estimation,"[""Zhaodong Chen"", ""Lei Deng"", ""Guoqi Li"", ""Jiawei Sun"", ""Xing Hu"", ""Ling Liang"", ""YufeiDing"", ""Yuan Xie""]","[""batch normalization"", ""acceleration"", ""correlation"", ""sampling""]","We propose accelerating Batch Normalization (BN) through sampling less correlated data for reduction operations  with regular execution pattern, which achieves up to 2x and 20% speedup for BN itself and the overall training, respectively.",,,,
HkGzUjR5tQ,2019,Reject,False,DATNet: Dual Adversarial Transfer for Low-resource Named Entity Recognition,"[""Joey Tianyi Zhou"", ""Hao Zhang"", ""Di Jin"", ""Hongyuan Zhu"", ""Rick Siow Mong Goh"", ""Kenneth Kwok""]","[""Low-resource"", ""Named Entity Recognition""]",We propose a new  architecture termed Dual Adversarial Transfer Network (DATNet) for addressing low-resource Named Entity Recognition (NER) and achieve new state-of-the-art performances on CoNLL and Twitter NER.,,,,
HkIQH7qel,2017,Reject,False,Learning Recurrent Span Representations for Extractive Question Answering,"[""Kenton Lee"", ""Tom Kwiatkowksi"", ""Ankur Parikh"", ""Dipanjan Das""]","[""Natural language processing""]",We present a globally normalized architecture for extractive question answering that contains explicit representations of all possible answer spans.,,,,
HkJ1rgbCb,2018,Reject,False,Using Deep Reinforcement Learning to Generate Rationales for Molecules,"[""Benson Chen"", ""Connor Coley"", ""Regina Barzilay"", ""Tommi Jaakkola""]","[""Reinforcement Learning"", ""Chemistry"", ""Interpretable Models""]",We use a reinforcement learning over molecular graphs to generate rationales for interpretable molecular property prediction.,,,,
HkJq1Ocxl,2017,Invite to Workshop Track,False,Programming With a Differentiable Forth Interpreter,"[""Matko Bo\u0161njak"", ""Tim Rockt\u00e4schel"", ""Jason Naradowsky"", ""Sebastian Riedel""]",[],"This paper presents the first neural implementation of an abstract machine for an actual language, allowing programmers to inject prior procedural knowledge into neural architectures in a straightforward manner.",,,,
HkL7n1-0b,2018,Accept (Oral),True,Wasserstein Auto-Encoders,"[""Ilya Tolstikhin"", ""Olivier Bousquet"", ""Sylvain Gelly"", ""Bernhard Schoelkopf""]","[""auto-encoder"", ""generative models"", ""GAN"", ""VAE"", ""unsupervised learning""]","We propose a new auto-encoder based on the Wasserstein distance, which improves on the sampling properties of VAE.",1711.01558,stat.ML,2017-11-05 10:18:27+00:00,2019-12-05 10:27:44+00:00
HkLXCE9lx,2017,Reject,False,RL^2: Fast Reinforcement Learning via Slow Reinforcement Learning,"[""Yan Duan"", ""John Schulman"", ""Xi Chen"", ""Peter L. Bartlett"", ""Ilya Sutskever"", ""Pieter Abbeel""]","[""Reinforcement Learning"", ""Deep learning""]","We propose to learn a âfastâ reinforcement learning algorithm using standard, off-the-shelf (âslowâ) reinforcement learning algorithms, where the âfastâ version is represented as an RNN, and fast RL happens inside its activations.",,,,
HkM3vjCcF7,2019,Reject,False,Multi-Scale Stacked Hourglass Network for Human Pose Estimation,"[""Chunsheng Guo"", ""Wenlong Du"", ""Na Ying""]","[""Human pose estimation"", ""Hourglass network"", ""Multi-scale analysis""]","Differentiated inputs cause functional differentiation of the network, and the interaction of loss functions between networks can affect the optimization process.",,,,
HkMCybx0-,2018,Reject,False,Improving Deep Learning by Inverse Square Root Linear Units (ISRLUs),"[""Brad Carlile"", ""Guy Delamarter"", ""Paul Kinney"", ""Akiko Marti"", ""Brian Whitney""]","[""Deep learning"", ""Theory""]",We introduce the ISRLU activation function which is continuously differentiable and faster than ELU. The related ISRU replaces tanh & sigmoid.,,,,
HkMhoDITb,2018,Reject,False,Reinforcement Learning via Replica Stacking of Quantum Measurements for the Training of Quantum Boltzmann Machines,"[""Anna Levit"", ""\u0006 Daniel Crawford"", ""Navid Ghadermarzy"", ""Jaspreet S. Oberoi"", ""Ehsan Zahedinejad"", ""Pooya Ronagh""]","[""Quantum Annealing"", ""Reinforcement Learning"", ""Boltzmann Machines"", ""Markov Chain Monte Carlo""]",We train Quantum Boltzmann Machines using a replica stacking method and a quantum annealer to perform a reinforcement learning task.,,,,
HkMlGnC9KQ,2019,Reject,False,On Regularization and Robustness of Deep Neural Networks,"[""Alberto Bietti*"", ""Gr\u00e9goire Mialon*"", ""Julien Mairal""]","[""regularization"", ""robustness"", ""deep learning"", ""convolutional networks"", ""kernel methods""]",,,,,
HkMvEOlAb,2018,Accept (Poster),False,Learning Latent Representations in Neural Networks for Clustering through Pseudo Supervision and Graph-based Activity Regularization,"[""Ozsel Kilinc"", ""Ismail Uysal""]","[""representation learning"", ""unsupervised clustering"", ""pseudo supervision"", ""graph-based activity regularization"", ""auto-clustering output layer""]",,,,,
HkMwHsCctm,2019,Reject,False,Principled Deep Neural Network Training through Linear Programming,"[""Daniel Bienstock"", ""Gonzalo Mu\u00f1oz"", ""Sebastian Pokutta""]","[""deep learning theory"", ""neural network training"", ""empirical risk minimization"", ""non-convex optimization"", ""treewidth""]",Using linear programming we show that the computational complexity of approximate Deep Neural Network training depends polynomially on the data size for several architectures,,,,
HkNDsiC9KQ,2019,Accept (Oral),False,Meta-Learning Update Rules for Unsupervised Representation Learning,"[""Luke Metz"", ""Niru Maheswaranathan"", ""Brian Cheung"", ""Jascha Sohl-Dickstein""]","[""Meta-learning"", ""unsupervised learning"", ""representation learning""]","We learn an unsupervised learning algorithm that produces useful representations from a set of supervised tasks. At test-time, we apply this algorithm to new tasks without any supervision and show performance comparable to a VAE.",,,,
HkNEuToge,2017,Reject,False,Energy-Based Spherical Sparse Coding,"[""Bailey Kong"", ""Charless C. Fowlkes""]",[],,,,,
HkNGYjR9FX,2019,Accept (Poster),False,Learning Recurrent Binary/Ternary Weights,"[""Arash Ardakani"", ""Zhengyun Ji"", ""Sean C. Smithson"", ""Brett H. Meyer"", ""Warren J. Gross""]","[""Quantized Recurrent Neural Network"", ""Hardware Implementation"", ""Deep Learning""]","We propose high-performance LSTMs with binary/ternary weights, that can greatly reduce implementation complexity",,,,
HkNGsseC-,2018,Accept (Poster),False,On the Expressive Power of Overlapping Architectures of Deep Learning,"[""Or Sharir"", ""Amnon Shashua""]","[""Deep Learning"", ""Expressive Efficiency"", ""Overlapping"", ""Receptive Fields""]",We analyze how the degree of overlaps between the receptive fields of a convolutional network affects its expressive power.,,,,
HkNKFiGex,2017,Accept (Poster),False,Neural Photo Editing with Introspective Adversarial Networks,"[""Andrew Brock"", ""Theodore Lim"", ""J.M. Ritchie"", ""Nick Weston""]","[""Computer vision"", ""Unsupervised Learning"", ""Applications""]",An interface for editing photos using generative image models.,,,,
HkNRsU5ge,2017,Accept (Poster),False,Sigma Delta Quantized Networks,"[""Peter O'Connor"", ""Max Welling""]","[""Computer vision"", ""Deep learning"", ""Applications""]",A deep neural network that saves computation on temporal data by using neurons that only communicate their changes in activation,,,,
HkOhuyA6-,2018,Reject,False,Graph Classification with 2D Convolutional Neural Networks,"[""Antoine J.-P. Tixier"", ""Giannis Nikolentzos"", ""Polykarpos Meladianos"", ""Michalis Vazirgiannis""]","[""graph classification"", ""convolutional neural networks"", ""2D CNN"", ""representation""]",We introduce a novel way to represent graphs as multi-channel image-like structures that allows them to be handled by vanilla 2D CNNs.,,,,
HkPCrEZ0Z,2018,Reject,False,Combining Model-based and Model-free RL via Multi-step Control Variates,"[""Tong Che"", ""Yuchen Lu"", ""George Tucker"", ""Surya Bhupatiraju"", ""Shane Gu"", ""Sergey Levine"", ""Yoshua Bengio""]",[],,,,,
HkSOlP9lg,2017,Reject,False,Recurrent Inference Machines for Solving Inverse Problems,"[""Patrick Putzky"", ""Max Welling""]","[""Optimization"", ""Deep learning"", ""Computer vision""]",,,,,
HkTEFfZRb,2018,Accept (Poster),False,Attacking Binarized Neural Networks,"[""Angus Galloway"", ""Graham W. Taylor"", ""Medhat Moussa""]","[""adversarial examples"", ""adversarial attacks"", ""binary"", ""binarized neural networks""]","We conduct adversarial attacks against binarized neural networks and show that we reduce the impact of the strongest attacks, while maintaining comparable accuracy in a black-box setting",,,,
HkUR_y-RZ,2018,Accept (Poster),False,SEARNN: Training RNNs with global-local losses,"[""R\u00e9mi Leblond"", ""Jean-Baptiste Alayrac"", ""Anton Osokin"", ""Simon Lacoste-Julien""]","[""Structured prediction"", ""RNNs""]","We introduce SeaRNN, a novel algorithm for RNN training, inspired by the learning to search approach to structured prediction, in order to avoid the limitations of MLE training.",,,,
HkUfnZFt1Rw,2021,Reject,False,Dissecting graph measures performance for node clustering in LFR parameter space,"[""Vladimir Ivashkin"", ""Pavel Chebotarev""]","[""graph theory"", ""graph measures"", ""kernel k-means"", ""clustering""]",We investigated graph features space and found zones of leadership for several graph node measures in node clustering task.,,,,
HkXWCMbRW,2018,Accept (Poster),False,Towards Image Understanding from Deep Compression Without Decoding,"[""Robert Torfason"", ""Fabian Mentzer"", ""Eirikur Agustsson"", ""Michael Tschannen"", ""Radu Timofte"", ""Luc Van Gool""]",[],,1803.06131,cs.CV,2018-03-16 09:51:09+00:00,2018-03-16 09:51:09+00:00
HkYhZDqxg,2017,Accept (Poster),False,Tree-structured decoding with doubly-recurrent neural networks,"[""David Alvarez-Melis"", ""Tommi S. Jaakkola""]","[""Natural language processing"", ""Supervised Learning"", ""Structured prediction""]","A new architecture for generating tree-structured objects from encoded representations, which models separately the width and depth recurrences across the tree and predicts both content and topology.",,,,
HkZy-bW0-,2018,Accept (Poster),False,Temporally Efficient Deep Learning with Spikes,"[""Peter O'Connor"", ""Efstratios Gavves"", ""Matthias Reisser"", ""Max Welling""]","[""online learning"", ""spiking networks"", ""deep learning"", ""temporal""]",An algorithm for training neural networks efficiently on temporally redundant data.,,,,
HkanP0lRW,2018,Reject,False,Data-driven Feature Sampling for Deep Hyperspectral Classification and Segmentation,"[""William M. Severa"", ""Jerilyn A. Timlin"", ""Suraj Kholwadwala"", ""Conrad D. James"", ""James B. Aimone""]","[""Applied deep learning"", ""Image segmentation"", ""Hyperspectral Imaging"", ""Feature sampling""]",We applied deep learning techniques to hyperspectral image segmentation and iterative feature sampling.,,,,
HkbJTYyAb,2018,Reject,False,Convolutional Normalizing Flows,"[""Guoqing Zheng"", ""Yiming Yang"", ""Jaime Carbonell""]",[],,,,,
Hkbd5xZRb,2018,Accept (Oral),False,Spherical CNNs,"[""Taco S. Cohen"", ""Mario Geiger"", ""Jonas K\u00f6hler"", ""Max Welling""]","[""deep learning"", ""equivariance"", ""convolution"", ""group convolution"", ""3D"", ""vision"", ""omnidirectional"", ""shape recognition"", ""molecular energy regression""]","We introduce Spherical CNNs, a convolutional network for spherical signals, and apply it to 3D model recognition and molecular energy regression.",,,,
HkbmWqxCZ,2018,Reject,False,The Mutual Autoencoder: Controlling Information in Latent Code Representations,"[""Mary Phuong"", ""Max Welling"", ""Nate Kushman"", ""Ryota Tomioka"", ""Sebastian Nowozin""]",[],,,,,
Hkc-TeZ0W,2018,Accept (Poster),False,A Hierarchical Model for Device Placement,"[""Azalia Mirhoseini"", ""Anna Goldie"", ""Hieu Pham"", ""Benoit Steiner"", ""Quoc V. Le"", ""Jeff Dean""]","[""deep learning"", ""device placement"", ""policy gradient optimization""]","We introduce a hierarchical model for efficient, end-to-end placement of computational graphs onto hardware devices.",,,,
HkcTe-bR-,2018,Invite to Workshop Track,False,Exploring Deep Recurrent Models with Reinforcement Learning for Molecule Design,"[""Daniel Neil"", ""Marwin Segler"", ""Laura Guasch"", ""Mohamed Ahmed"", ""Dean Plumbley"", ""Matthew Sellwood"", ""Nathan Brown""]","[""reinforcement learning"", ""molecule design"", ""de novo design"", ""ppo"", ""sample-efficient reinforcement learning""]","We investigate a variety of RL algorithms for molecular generation and define new benchmarks (to be released as an OpenAI Gym), finding PPO and a hill-climbing MLE algorithm work best.",,,,
HkcdHtqlx,2017,Reject,False,Gated-Attention Readers for Text Comprehension,"[""Bhuwan Dhingra"", ""Hanxiao Liu"", ""Zhilin Yang"", ""William W. Cohen"", ""Ruslan Salakhutdinov""]","[""Natural language processing"", ""Deep learning"", ""Supervised Learning""]",,,,,
Hke-JhA9Y7,2019,Accept (Poster),False,Learning concise representations for regression by evolving networks of trees,"[""William La Cava"", ""Tilak Raj Singh"", ""James Taggart"", ""Srinivas Suri"", ""Jason H. Moore""]","[""regression"", ""stochastic optimization"", ""evolutionary compution"", ""feature engineering""]",Representing the network architecture as a set of syntax trees and optimizing their structure leads to accurate and concise regression models. ,,,,
Hke-WTVtwr,2020,Accept (Spotlight),False,Encoding word order in complex embeddings,"[""Benyou Wang"", ""Donghao Zhao"", ""Christina Lioma"", ""Qiuchi Li"", ""Peng Zhang"", ""Jakob Grue Simonsen""]","[""word embedding"", ""complex-valued neural network"", ""position embedding""]",,1912.12333,cs.CL,2019-12-27 20:59:38+00:00,2020-06-28 04:37:07+00:00
Hke0K1HKwr,2020,Accept (Spotlight),False,Sequential Latent Knowledge Selection for Knowledge-Grounded Dialogue,"[""Byeongchang Kim"", ""Jaewoo Ahn"", ""Gunhee Kim""]","[""dialogue"", ""knowledge"", ""language"", ""conversation""]",Our approach is the first attempt to leverage a sequential latent variable model for knowledge selection in the multi-turn knowledge-grounded dialogue. It achieves the new state-of-the-art performance on Wizard of Wikipedia benchmark.,2002.07510,cs.CL,2020-02-18 11:59:59+00:00,2020-06-16 02:04:57+00:00
Hke0V1rKPS,2020,Accept (Poster),False,Jacobian Adversarially Regularized Networks for Robustness,"[""Alvin Chan"", ""Yi Tay"", ""Yew Soon Ong"", ""Jie Fu""]","[""adversarial examples"", ""robust machine learning"", ""deep learning""]",We show that training classifiers to produce salient input Jacobian matrices with a GAN-like regularization can boost adversarial robustness.,1912.10185,cs.CV,2019-12-21 02:46:50+00:00,2020-01-29 08:06:12+00:00
Hke0lRNYwS,2020,Reject,False,Convolutional Bipartite Attractor Networks,"[""Michael L. Iuzzolino"", ""Yoram Singer"", ""Michael C. Mozer""]","[""attractor network"", ""recurrent network"", ""energy function"", ""convolutional network"", ""image completion"", ""super-resolution""]","We revisit attractor nets in light of modern deep learning methods and propose a convolutional bipartite architecture with a novel training loss, activation function, and connectivity constraints.",,,,
Hke0oa4KwS,2020,Reject,False,Empirical confidence estimates for classification by deep neural networks,"[""Chris Finlay"", ""Adam M. Oberman""]","[""confidence"", ""classification"", ""uncertainty"", ""anomaly"", ""robustness""]",Provably accurate results for top 1 and top k confidence using a simple binning method,,,,
Hke12T4KPS,2020,Reject,False,Using Hindsight to Anchor Past Knowledge in Continual Learning,"[""Arslan Chaudhry"", ""Albert Gordo"", ""David Lopez-Paz"", ""Puneet K. Dokania"", ""Philip Torr""]","[""Continual Learning"", ""Lifelong Learning"", ""Catastrophic Forgetting""]",A continual learning method that uses replay buffer to construct anchors by maximizing the forgetting of a task and later keep the predictions on these anchors invariant by a meta-learning objective.,,,,
Hke1gySFvB,2020,Reject,False,Enhancing Language Emergence through Empathy,"[""Marie Ossenkopf""]","[""multi-agent deep reinforcement learning"", ""emergent communication"", ""auxiliary tasks""]",An auxiliary prediction task can speed up learning in language emergence setups.,,,,
Hke20iA9Y7,2019,Accept (Poster),False,Efficient Training on Very Large Corpora via Gramian Estimation,"[""Walid Krichene"", ""Nicolas Mayoraz"", ""Steffen Rendle"", ""Li Zhang"", ""Xinyang Yi"", ""Lichan Hong"", ""Ed Chi"", ""John Anderson""]","[""similarity learning"", ""pairwise learning"", ""matrix factorization"", ""Gramian estimation"", ""variance reduction"", ""neural embedding models"", ""recommender systems""]","We develop efficient methods to train neural embedding models with a dot-product structure, by reformulating the objective function in terms of generalized Gram matrices, and maintaining estimates of those matrices.",,,,
Hke3gyHYwH,2020,Accept (Poster),True,Simple and Effective Regularization Methods for Training on Noisily Labeled Data with Generalization Guarantee,"[""Wei Hu"", ""Zhiyuan Li"", ""Dingli Yu""]","[""deep learning theory"", ""regularization"", ""noisy labels""]",,1905.11368,cs.LG,2019-05-27 17:52:28+00:00,2020-10-02 20:43:58+00:00
Hke4_JrYDr,2020,Reject,False,Global-Local Network for Learning Depth with Very Sparse Supervision,"[""Antonio Loquercio"", ""Alexey Dosovitskiy"", ""Davide Scaramuzza""]","[""Depth Perception"", ""Learning from Sparse Supervision"", ""Learning from Interaction.""]",An approach to learning depth from very sparse supervision.,2003.00752,cs.CV,2020-03-02 10:44:13+00:00,2020-07-16 10:01:55+00:00
Hke4l2AcKQ,2019,Accept (Poster),False,MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders,"[""Xuezhe Ma"", ""Chunting Zhou"", ""Eduard Hovy""]","[""VAE"", ""regularization"", ""auto-regressive""]",,,,,
Hke8Do0cF7,2019,Reject,False,Deep processing of structured data,"[""\u0141ukasz Maziarka"", ""Marek \u015amieja"", ""Aleksandra Nowak"", ""Jacek Tabor"", ""\u0141ukasz Struski"", ""Przemys\u0142aw Spurek""]","[""structured data"", ""representation learning"", ""deep neural networks""]",General framework of learning representation of structured inputs.,,,,
HkeAepVKDH,2020,Reject,False,QGAN: Quantize Generative Adversarial Networks to Extreme low-bits,"[""Peiqi Wang"", ""Yu Ji"", ""Xinfeng Xie"", ""Yongqiang Lyu"", ""Dongsheng Wang"", ""Yuan Xie""]","[""generative adversarial networks"", ""quantization"", ""extreme low bits""]",,,,,
HkeGhoA5FX,2019,Accept (Poster),False,Residual Non-local Attention Networks for Image Restoration,"[""Yulun Zhang"", ""Kunpeng Li"", ""Kai Li"", ""Bineng Zhong"", ""Yun Fu""]","[""Non-local network"", ""attention network"", ""image restoration"", ""residual learning""]",New state-of-the-art framework for image restoration,,,,
HkeILsRqFQ,2019,Reject,False,An experimental study of layer-level training speed and its impact on generalization,"[""Simon Carbonnelle"", ""Christophe De Vleeschouwer""]","[""generalization"", ""optimization"", ""vanishing gradients"", ""experimental"", ""fundamental research""]",This paper provides empirical evidence that 1) the speed at which each layer trains influences generalization and 2) this phenomenon is at the root of weight decay's and adaptive gradient methods' impact on generalization.,,,,
HkeJVllRW,2018,Reject,False,Sparse-Complementary Convolution for Efficient Model Utilization on CNNs,"[""Chun-Fu (Richard) Chen"", ""Jinwook Oh"", ""Quanfu Fan"", ""Marco Pistoia"", ""Gwo Giun (Chris) Lee""]","[""CNN"", ""sparse convolution"", ""sparse kernel"", ""sparsity"", ""model utilization"", ""image classification""]",TL;DR,,,,
HkeJzANFwS,2020,Reject,False,Contextual Text Style Transfer,"[""Yu Cheng"", ""Zhe Gan"", ""Yizhe Zhang"", ""Oussama Elachqar"", ""Dianqi Li"", ""Jingjing Liu""]",[],,2005.00136,cs.CL,2020-04-30 23:01:12+00:00,2020-04-30 23:01:12+00:00
HkeKVh05Fm,2019,Reject,False,Multi-Grained Entity Proposal Network for Named Entity Recognition,"[""Congying Xia"", ""Chenwei Zhang"", ""Tao Yang"", ""Yaliang Li"", ""Nan Du"", ""Xian Wu"", ""Wei Fan"", ""Fenglong Ma"", ""Philip S. Yu""]",[],,,,,
HkeMYJHYvS,2020,Reject,False,High-Frequency guided Curriculum Learning for Class-specific Object Boundary Detection,"[""VSR Veeravasarapu"", ""Deepak Mittal"", ""Abhishek Goel"", ""Maneesh Singh""]","[""Computer Vision"", ""Object Contour Detection"", ""Curriculum Learning"", ""Wavelets"", ""Aerial Imagery""]",This work proposes a novel ConvNet architecture and a two-stage training scheme for class-specific object boundary estimation with improved performance levels.,,,,
HkeO104tPB,2020,Reject,True,Reinforcement Learning without Ground-Truth State,"[""Xingyu Lin"", ""Harjatin Singh Baweja"", ""David Held""]","[""Self-supervised"", ""goal-conditioned reinforcement learning""]","This paper proposes to use an indicator function for specifying reward in goal-conditioned reinforcement learning, eliminating the need for reward engineering.",1905.07866,cs.RO,2019-05-20 04:17:03+00:00,2019-07-15 06:44:33+00:00
HkePNpVKPB,2020,Accept (Poster),False,Compositional languages emerge in a neural iterated learning model,"[""Yi Ren"", ""Shangmin Guo"", ""Matthieu Labeau"", ""Shay B. Cohen"", ""Simon Kirby""]","[""Compositionality"", ""Multi-agent"", ""Emergent language"", ""Iterated learning""]",Use iterated learning framework to facilitate the dominance of high compositional language in multi-agent games.,2002.01365,cs.CL,2020-02-04 15:19:09+00:00,2020-02-17 11:22:04+00:00
HkePOCNtPH,2020,Reject,False,Non-Sequential Melody Generation,"[""Mitchell Billard"", ""Robert Bishop"", ""Moustafa Elsisy"", ""Laura Graves"", ""Antonina Kolokolova"", ""Vineel Nagisetty"", ""Zachary Northcott"", ""Heather Patey""]","[""melody generation"", ""DCGAN"", ""dilated convolutions""]",Representing melodies as images with semantic units aligned we can generate them using a DCGAN without any recurrent components.,,,,
HkeQ6ANYDB,2020,Reject,False,Blending Diverse Physical Priors with Neural Networks,"[""Yunhao Ba"", ""Guangyuan Zhao"", ""Achuta Kadambi""]","[""Physics-based learning"", ""Physics-aware learning""]",A new method for physics-based learning is proposed that can handle a more diverse range of quality in the physical prior and dataset.,,,,
HkeSdCEtDS,2020,Reject,True,Alternating Recurrent Dialog Model with Large-Scale Pre-Trained Language Models,"[""Qingyang Wu"", ""Yichi Zhang"", ""Yu Li"", ""Zhou Yu""]","[""NLP"", ""Pre-training"", ""GPT-2"", ""Text Generation"", ""Dialog Generation""]","We propose a simple, general, and effective framework with the large pre-trained language model GPT-2.",1910.03756,cs.CL,2019-10-09 02:31:37+00:00,2021-04-26 19:48:38+00:00
HkeUDCNFPS,2020,Reject,False,Learning Temporal Abstraction with Information-theoretic Constraints for Hierarchical Reinforcement Learning,"[""Wenshan Wang"", ""Yaoyu Hu"", ""Sebastian Scherer""]","[""hierarchical reinforcement learning"", ""temporal abstraction""]","We propose a novel HRL framework, in which we formulate the temporal abstraction problem as learning a latent representation  of  action  sequence.",,,,
HkeWSnR5Y7,2019,Reject,False,Provable Defenses against Spatially Transformed Adversarial Inputs: Impossibility and Possibility Results,"[""Xinyang Zhang"", ""Yifan Huang"", ""Chanh Nguyen"", ""Shouling Ji"", ""Ting Wang""]",[],,,,,
HkeZQJBKDB,2020,Reject,False,Universal approximations of permutation invariant/equivariant functions by deep neural networks,"[""Akiyoshi Sannai"", ""Yuuki Takai"", ""Matthieu Cordonnier""]","[""finite group"", ""invariant"", ""equivariant"", ""neural networks""]","For a given $G$-invariant/equivariant function, we construct its universal approximator by deep neural network whose layers equip $G$-actions and each affine transformations are $G$-equivariant/invariant. ",,,,
Hke_f0EYPH,2020,Reject,False,Efficient Training of Robust and Verifiable Neural Networks,"[""Akhilan Boopathy"", ""Lily Weng"", ""Sijia Liu"", ""Pin-Yu Chen"", ""Luca Daniel""]",[],,,,,
HkedQp4tPr,2020,Reject,True,Parallel Scheduled Sampling,"[""Daniel Duckworth"", ""Arvind Neelakantan"", ""Ben Goodrich"", ""Lukasz Kaiser"", ""Samy Bengio""]","[""deep learning"", ""generative models"", ""teacher forcing"", ""scheduled sampling""]",We describe a simple technique to parallelize Scheduled Sampling across time  which gives better sample quality and train almost as fast as teacher-forcing.,1906.04331,cs.CL,2019-06-11 00:43:38+00:00,2019-10-21 18:41:37+00:00
Hkee1JBKwB,2020,Reject,False,Convolutional Tensor-Train LSTM for Long-Term Video Prediction,"[""Jiahao Su"", ""Wonmin Byeon"", ""Furong Huang"", ""Jan Kautz"", ""Animashree Anandkumar""]","[""Tensor decomposition"", ""Video prediction""]","we propose convolutional tensor-train LSTM,  which learns higher-order Convolutional LSTM efficiently using convolutional tensor-train decomposition. ",,,,
HkeeITEYDr,2020,Reject,False,Robust Reinforcement Learning with Wasserstein Constraint,"[""Linfang Hou"", ""Liang Pang"", ""Xin Hong"", ""Yanyan Lan"", ""Zhiming Ma"", ""Dawei Yin""]",[],,2006.00945,cs.LG,2020-06-01 13:48:59+00:00,2020-06-01 13:48:59+00:00
Hkeh21BKPH,2020,Reject,False,Towards Finding Longer Proofs,"[""Zsolt Zombori"", ""Adri\u00e1n Csisz\u00e1rik"", ""Henryk Michalewski"", ""Cezary Kaliszyk"", ""Josef Urban""]","[""automated theorem proving"", ""reinforcement learning"", ""curriculum learning"", ""internal guidance""]","We present FLoP, a reinforcement learning based guidance system for automated theorem proving geared towards Finding Longer Proofs.",,,,
HkehD3VtvS,2020,Reject,True,"Deep Reasoning Networks:  Thinking Fast and Slow, for Pattern De-mixing","[""Di Chen"", ""Yiwei Bai"", ""Wenting Zhao"", ""Sebastian Ament"", ""John M. Gregoire"", ""Carla P. Gomes""]","[""Deep Reasoning Network"", ""Pattern De-mixing""]","We introduce Deep Reasoning Networks (DRNets), an end-to-end framework that combines deep learning with reasoning for solving pattern de-mixing tasks, typically in an unsupervised or weakly-supervised setting. ",1906.00855,cs.LG,2019-06-03 15:09:57+00:00,2019-06-04 15:41:03+00:00
HkejNgBtPB,2020,Accept (Poster),False,Variational Template Machine for Data-to-Text Generation,"[""Rong Ye"", ""Wenxian Shi"", ""Hao Zhou"", ""Zhongyu Wei"", ""Lei Li""]",[],,2002.01127,cs.CL,2020-02-04 04:53:45+00:00,2020-02-13 09:50:56+00:00
HkekMnR5Ym,2019,Reject,False,Meta-Learning Neural Bloom Filters,"[""Jack W Rae"", ""Sergey Bartunov"", ""Timothy P Lillicrap""]","[""meta-learning"", ""memory"", ""one-shot learning"", ""bloom filter"", ""set membership"", ""familiarity"", ""compression""]",We investigate the space efficiency of memory-augmented neural nets when learning set membership.,,,,
Hkekl0NFPr,2020,Accept (Spotlight),False,Conditional Learning of Fair Representations,"[""Han Zhao"", ""Amanda Coston"", ""Tameem Adel"", ""Geoffrey J. Gordon""]","[""algorithmic fairness"", ""representation learning""]",We propose a novel algorithm for learning fair representations that can simultaneously mitigate two notions of disparity among different demographic subgroups.,,,,
Hkem-lrtvH,2020,Accept (Poster),False,BayesOpt Adversarial Attack,"[""Binxin Ru"", ""Adam Cobb"", ""Arno Blaas"", ""Yarin Gal""]","[""Black-box Adversarial Attack"", ""Bayesian Optimisation"", ""Gaussian Process""]",We propose a query-efficient black-box attack which uses Bayesian optimisation in combination with Bayesian model selection to optimise over the adversarial perturbation and the optimal degree of search space dimension reduction. ,,,,
Hkemdj09YQ,2019,Reject,False,Rectified Gradient: Layer-wise Thresholding for Sharp and Coherent Attribution Maps,"[""Beomsu Kim"", ""Junghoon Seo"", ""Jeongyeol Choe"", ""Jamyoung Koo"", ""Seunghyeon Jeon"", ""Taegyun Jeon""]","[""Interpretability"", ""Attribution Method"", ""Attribution Map""]",We propose a new attribution method that removes noise from saliency maps through layer-wise thresholding during backpropagation.,,,,
HkenPn4KPH,2020,Reject,True,When Does Self-supervision Improve Few-shot Learning?,"[""Jong-Chyi Su"", ""Subhransu Maji"", ""Bharath Hariharan""]","[""Few-shot learning"", ""Self-supervised learning"", ""Meta-learning"", ""Multi-task learning""]",Self-supervision improves few-shot recognition on small and challenging datasets without relying on extra data; Extra data helps only when it is from the same or similar domain.,1910.03560,cs.CV,2019-10-08 17:47:14+00:00,2020-07-30 06:08:35+00:00
HkeoOo09YX,2019,Accept (Poster),False,Meta-Learning For Stochastic Gradient MCMC,"[""Wenbo Gong"", ""Yingzhen Li"", ""Jos\u00e9 Miguel Hern\u00e1ndez-Lobato""]","[""Meta Learning"", ""MCMC""]",This paper proposes a method to automate the design of stochastic gradient MCMC proposal using meta learning approach. ,,,,
HkepKG-Rb,2018,Reject,False,A Semantic Loss Function for Deep Learning with Symbolic Knowledge,"[""Jingyi Xu"", ""Zilu Zhang"", ""Tal Friedman"", ""Yitao Liang"", ""Guy Van den Broeck""]","[""deep learning"", ""symbolic knowledge"", ""semi-supervised learning"", ""constraints""]",,,,,
HkeryxBtPB,2020,Accept (Poster),True,MMA Training: Direct Input Space Margin Maximization through Adversarial Training,"[""Gavin Weiguang Ding"", ""Yash Sharma"", ""Kry Yik Chau Lui"", ""Ruitong Huang""]","[""adversarial robustness"", ""perturbation"", ""margin maximization"", ""deep learning""]",We propose MMA training to directly maximize input space margin in order to improve adversarial robustness primarily by removing the requirement of specifying a fixed distortion bound.,1812.02637,cs.LG,2018-12-06 16:15:52+00:00,2020-03-04 19:58:33+00:00
Hkes0iR9KX,2019,Reject,False,DEEP GEOMETRICAL GRAPH CLASSIFICATION,"[""Mostafa Rahmani"", ""Ping Li""]","[""Graph classification"", ""Deep Learning"", ""Graph pooling"", ""Embedding""]",The graph analysis problem is transformed into a point cloud analysis problem. ,,,,
Hkesr205t7,2019,Reject,False,Learning shared manifold representation of images and attributes for generalized zero-shot learning,"[""Masahiro Suzuki"", ""Yusuke Iwasawa"", ""Yutaka Matsuo""]","[""zero-shot learning"", ""variational autoencoders""]",,,,,
HketHo0qFm,2019,Reject,False,Hybrid Policies Using Inverse Rewards for Reinforcement Learning,"[""Yao Shi"", ""Tian Xia"", ""Guanjun Zhao"", ""Xin Gao""]","[""Reinforcement Learning"", ""Rewards""]","A broad-spectrum improvement for reinforcement learning algorithms, which combines the policies using original rewards and inverse (negative) rewards",,,,
HketzTNYwS,2020,Reject,True,"Unifying Question Answering, Text Classification, and Regression via Span Extraction","[""Nitish Shirish Keskar"", ""Bryan McCann"", ""Caiming Xiong"", ""Richard Socher""]","[""NLP"", ""span-extraction"", ""BERT""]","Question answering, regression and classification can be unified as span extraction with improved generality and performance. ",1904.09286,cs.CL,2019-04-19 17:58:29+00:00,2019-09-20 18:01:55+00:00
HkeuD34KPH,2020,Reject,True,SSE-PT: Sequential Recommendation Via Personalized Transformer,"[""Liwei Wu"", ""Shuqing Li"", ""Cho-Jui Hsieh"", ""James Sharpnack""]","[""sequential recommendation"", ""personalized transformer"", ""stochastic shared embeddings""]",,1908.05435,cs.LG,2019-08-15 06:35:04+00:00,2019-08-15 06:35:04+00:00
HkewNJStDr,2020,Reject,False,Efficient High-Dimensional Data Representation Learning via Semi-Stochastic Block Coordinate Descent Methods,"[""Bingkun Wei"", ""Yangyang Li"", ""Fanhua Shang"", ""Yuanyuan Liu"", ""Hongying Liu"", ""Shengmei Shen""]","[""Sparse learning"", ""Hard thresholding"", ""High-dimensional regression""]",,,,,
Hkex2a4FPr,2020,Reject,False,On Variational Learning of Controllable Representations for Text without Supervision,"[""Peng Xu"", ""Yanshuai Cao"", ""Jackie Chi Kit Cheung""]","[""sequence variational autoencoders"", ""unsupervised learning"", ""controllable text generation"", ""text style transfer""]","why previous VAEs on text cannot learn controllable latent representation as on images, as well as a fix to enable the first success towards controlled text generation without supervision",,,,
Hkexw1BtDr,2020,Reject,False,Deep Auto-Deferring Policy for Combinatorial Optimization,"[""Sungsoo Ahn"", ""Younggyo Seo"", ""Jinwoo Shin""]","[""deep reinforcement learning"", ""combinatorial optimization""]",We propose a new scalable framework based on deep reinforcement learning for solving combinatorial optimization on large graphs.,2006.09607,cs.LG,2020-06-17 02:19:31+00:00,2020-06-29 06:17:07+00:00
HkeyZhC9F7,2019,Reject,True,Learning Heuristics for Automated Reasoning through Reinforcement Learning,"[""Gil Lederman"", ""Markus N. Rabe"", ""Edward A. Lee"", ""Sanjit A. Seshia""]","[""reinforcement learning"", ""deep learning"", ""logics"", ""formal methods"", ""automated reasoning"", ""backtracking search"", ""satisfiability"", ""quantified Boolean formulas""]",RL finds better heuristics for automated reasoning algorithms.,1807.08058,cs.LO,2018-07-20 23:59:36+00:00,2019-10-30 19:38:45+00:00
HkezXnA9YX,2019,Accept (Poster),False,Systematic Generalization: What Is Required and Can It Be Learned?,"[""Dzmitry Bahdanau*"", ""Shikhar Murty*"", ""Michael Noukhovitch"", ""Thien Huu Nguyen"", ""Harm de Vries"", ""Aaron Courville""]","[""systematic generalization"", ""language understanding"", ""visual questions answering"", ""neural module networks""]",We show that modular structured models are the best in terms of systematic generalization and that their end-to-end versions don't generalize as well.,,,,
HkezfhA5Y7,2019,Reject,False,A Rate-Distortion Theory of Adversarial Examples,"[""Angus Galloway"", ""Anna Golubeva"", ""Graham W. Taylor""]","[""adversarial examples"", ""information bottleneck"", ""robustness""]",We argue that excess capacity is a significant cause of susceptibility to adversarial examples.,,,,
Hkf2_sC5FX,2019,Accept (Poster),False,Efficient Lifelong Learning with A-GEM,"[""Arslan Chaudhry"", ""Marc\u2019Aurelio Ranzato"", ""Marcus Rohrbach"", ""Mohamed Elhoseiny""]","[""Lifelong Learning"", ""Continual Learning"", ""Catastrophic Forgetting"", ""Few-shot Transfer""]",An efficient lifelong learning algorithm that provides a better trade-off between accuracy and time/ memory complexity compared to other algorithms. ,,,,
HkfPSh05K7,2019,Accept (Poster),False,Multi-step Retriever-Reader Interaction for Scalable Open-domain Question Answering,"[""Rajarshi Das"", ""Shehzaad Dhuliawala"", ""Manzil Zaheer"", ""Andrew McCallum""]","[""Open domain Question Answering"", ""Reinforcement Learning"", ""Query reformulation""]",Paragraph retriever and machine reader interacts with each other via reinforcement learning to yield large improvements on open domain datasets,,,,
HkfXMz-Ab,2018,Accept (Oral),False,Neural Sketch Learning for Conditional Program Generation,"[""Vijayaraghavan Murali"", ""Letao Qi"", ""Swarat Chaudhuri"", ""Chris Jermaine""]","[""Program generation"", ""Source code"", ""Program synthesis"", ""Deep generative models""]","We give a method for generating type-safe programs in a Java-like language, given a small amount of syntactic information about the desired code.",,,,
HkfYOoCcYX,2019,Accept (Poster),False,Double Viterbi: Weight Encoding for High Compression Ratio and Fast On-Chip Reconstruction for Deep Neural Network,"[""Daehyun Ahn"", ""Dongsoo Lee"", ""Taesu Kim"", ""Jae-Joon Kim""]","[""quantization"", ""pruning"", ""memory footprint"", ""model compression"", ""sparse matrix""]",We present a new weight encoding scheme which enables high compression ratio and fast sparse-to-dense matrix conversion.,,,,
Hkfmn5n6W,2018,Invite to Workshop Track,False,Exponentially vanishing sub-optimal local minima in multilayer neural networks,"[""Daniel Soudry"", ""Elad Hoffer""]","[""neural networks"", ""theory"", ""optimization"", ""local minima"", ""loss landscape""]","""Bad"" local minima are vanishing in a multilayer neural net: a proof with more reasonable assumptions than before",,,,
HkfwpiA9KX,2019,Reject,False,Automata Guided Skill Composition,"[""Xiao Li"", ""Yao Ma"", ""Calin Belta""]","[""Skill composition"", ""temporal logic"", ""finite state automata""]",A formal method's approach to skill composition in reinforcement learning tasks,,,,
Hkg-xgrYvH,2020,Accept (Poster),False,Empirical Bayes Transductive Meta-Learning with Synthetic Gradients,"[""Shell Xu Hu"", ""Pablo Garcia Moreno"", ""Yang Xiao"", ""Xi Shen"", ""Guillaume Obozinski"", ""Neil Lawrence"", ""Andreas Damianou""]","[""Meta-learning"", ""Empirical Bayes"", ""Synthetic Gradient"", ""Information Bottleneck""]","We propose a transductive meta-learning algorithm using synthetic gradients, analyze its generalization via information bottleneck, show SOTA results on few-shot learning.",,,,
Hkg0olStDr,2020,Reject,False,Multi-Step Decentralized Domain Adaptation,"[""Akhil Mathur"", ""Shaoduo Gan"", ""Anton Isopoussu"", ""Fahim Kawsar"", ""Nadia Berthouze"", ""Nicholas D. Lane""]","[""domain adaptation"", ""decentralization""]","A novel method for decentralized and distributed domain adaptation, as a way to make these methods more practical in real ML systems.",,,,
Hkg1YiAcK7,2019,Reject,False,Learning Implicit Generative Models by Teaching Explicit Ones,"[""Chao Du"", ""Kun Xu"", ""Chongxuan Li"", ""Jun Zhu"", ""Bo Zhang""]",[],,,,,
Hkg1csA5Y7,2019,Reject,False,A fast quasi-Newton-type method for large-scale stochastic optimisation,"[""Adrian Wills"", ""Thomas B. Sch\u00f6n"", ""Carl Jidling""]","[""optimisation"", ""large-scale"", ""stochastic""]",,,,,
Hkg313AcFX,2019,Reject,False,Metropolis-Hastings view on variational inference and adversarial training,"[""Kirill Neklyudov"", ""Dmitry Vetrov""]","[""MCMC"", ""GANs"", ""Variational Inference""]",Learning to sample via lower bounding the acceptance rate of the Metropolis-Hastings algorithm,,,,
Hkg4TI9xl,2017,Accept (Poster),False,A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks,"[""Dan Hendrycks"", ""Kevin Gimpel""]","[""Computer vision""]",Methods to Detect When a Network Is Wrong,,,,
Hkg4W2AcFm,2019,Accept (Poster),False,Overcoming the Disentanglement vs Reconstruction Trade-off via Jacobian Supervision,"[""Jos\u00e9 Lezama""]","[""disentangling"", ""autoencoders"", ""jacobian"", ""face manipulation""]",A method for learning image representations that are good for both disentangling factors of variation and obtaining faithful reconstructions.,,,,
Hkg5lAEtvS,2020,Reject,False,Towards Physics-informed Deep Learning for Turbulent Flow Prediction,"[""Rui Wang"", ""Karthik Kashinath"", ""Mustafa Mustafa"", ""Adrian Albert"", ""Rose Yu""]",[],,1911.08655,physics.comp-ph,2019-11-20 01:16:57+00:00,2020-06-13 22:11:29+00:00
Hkg8bDqee,2017,Accept (Poster),False,Introspection:Accelerating Neural Network Training By Learning Weight Evolution,"[""Abhishek Sinha"", ""Aahitagni Mukherjee"", ""Mausoom Sarkar"", ""Balaji Krishnamurthy""]","[""Computer vision"", ""Deep learning"", ""Optimization""]","Acceleration of training by performing weight updates, using knowledge obtained from training other neural networks.",,,,
Hkg9HgBYwH,2020,Reject,False,Encoding Musical Style with Transformer Autoencoders,"[""Kristy Choi"", ""Curtis Hawthorne"", ""Ian Simon"", ""Monica Dinculescu"", ""Jesse Engel""]","[""music generation"", ""sequence-to-sequence model"", ""controllable generation""]",,1912.05537,cs.SD,2019-12-10 19:51:44+00:00,2020-06-30 05:00:40+00:00
HkgAJxrYwr,2020,Reject,False,Attack-Resistant Federated Learning with Residual-based Reweighting,"[""Shuhao Fu"", ""Chulin Xie"", ""Bo Li"", ""Qifeng Chen""]","[""robust federated learning"", ""backdoor attacks""]",We present a novel aggregation algorithm with residual-based reweighting for attack-resistant federated learning.,,,,
HkgB2TNYPS,2020,Accept (Poster),False,A Theoretical Analysis of the Number of Shots in Few-Shot Learning,"[""Tianshi Cao"", ""Marc T Law"", ""Sanja Fidler""]","[""Few shot learning"", ""Meta Learning"", ""Performance Bounds""]",The paper analyzes the effect of shot number on prototypical networks and proposes a robust method when the shot number differs from meta-training to meta-testing time.,,,,
HkgBsaVtDB,2020,Reject,True,Unified recurrent network for many feature types,"[""Alexander Stec"", ""Diego Klabjan"", ""Jean Utke""]","[""sparse"", ""recurrent"", ""asynchronous"", ""time"", ""series""]","We introduce a unified RNN that handles five different feature types, each in a different manner.",1809.08717,stat.ML,2018-09-24 01:37:26+00:00,2018-09-24 01:37:26+00:00
HkgDTiCctQ,2019,Reject,False,Knowledge Distillation from Few Samples,"[""Tianhong Li"", ""Jianguo Li"", ""Zhuang Liu"", ""Changshui Zhang""]","[""knowledge distillation"", ""few-sample learning"", ""network compression""]",This paper proposes a novel and simple method for knowledge distillation from few samples.,,,,
HkgEQnRqYQ,2019,Accept (Poster),False,RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space,"[""Zhiqing Sun"", ""Zhi-Hong Deng"", ""Jian-Yun Nie"", ""Jian Tang""]","[""knowledge graph embedding"", ""knowledge graph completion"", ""adversarial sampling""]",A new state-of-the-art approach for knowledge graph embedding.,,,,
HkgFDgSYPH,2020,Reject,False,Adaptive Online Planning for Continual Lifelong Learning,"[""Kevin Lu"", ""Igor Mordatch"", ""Pieter Abbeel""]","[""reinforcement learning"", ""model predictive control"", ""planning"", ""model based"", ""model free"", ""uncertainty"", ""computation""]",We propose a method for reducing planning in MPC by measuring the uncertainty of model-free value and policy networks.,,,,
HkgH0TEYwH,2020,Accept (Poster),True,Deep Semi-Supervised Anomaly Detection,"[""Lukas Ruff"", ""Robert A. Vandermeulen"", ""Nico G\u00f6rnitz"", ""Alexander Binder"", ""Emmanuel M\u00fcller"", ""Klaus-Robert M\u00fcller"", ""Marius Kloft""]","[""anomaly detection"", ""deep learning"", ""semi-supervised learning"", ""unsupervised learning"", ""outlier detection"", ""one-class classification"", ""deep anomaly detection"", ""deep one-class classification""]","We introduce Deep SAD, a deep method for general semi-supervised anomaly detection that especially takes advantage of labeled anomalies.",1906.02694,cs.LG,2019-06-06 16:46:56+00:00,2020-02-14 10:10:15+00:00
HkgHk3RctX,2019,Reject,False,Seq2Slate: Re-ranking and Slate Optimization with RNNs,"[""Irwan Bello"", ""Sayali Kulkarni"", ""Sagar Jain"", ""Craig Boutilier"", ""Ed Chi"", ""Elad Eban"", ""Xiyang Luo"", ""Alan Mackey"", ""Ofer Meshi""]","[""Recurrent neural networks"", ""learning to rank"", ""pointer networks""]","A pointer network architecture for re-ranking items, learned from click-through logs.",,,,
HkgMxkHtPH,2020,Reject,False,UWGAN: UNDERWATER GAN FOR REAL-WORLD UNDERWATER COLOR RESTORATION AND DEHAZING,"[""Nan Wang"", ""Yabin Zhou"", ""Fenglei Han"", ""Lichao Wan"", ""Haitao Zhu"", ""Yaojing Zheng""]","[""underwater image"", ""image restoration"", ""image enhancement"", ""GAN"", ""CNNs""]",A new apporach to enhance underwater images based on GAN and CNNs,,,,
HkgNdt26Z,2018,Accept (Poster),False,Distributed Fine-tuning of Language Models on Private Data,"[""Vadim Popov"", ""Mikhail Kudinov"", ""Irina Piontkovskaya"", ""Petr Vytovtov"", ""Alex Nevidomsky""]","[""distributed training"", ""federated learning"", ""language modeling"", ""differential privacy""]",We propose a method of distributed fine-tuning of language models on user devices without collection of private data,,,,
HkgR8erKwB,2020,Reject,False,PAC-Bayesian Neural Network Bounds,"[""Yossi Adi"", ""Alex Schwing"", ""Tamir Hazan""]","[""PAC-Bayesian bounds"", ""PAC-Bayes"", ""Generalization bounds"", ""Bayesian inference""]",We derive a new PAC-Bayesian Bound for unbounded loss functions (e.g. Negative Log-Likelihood). ,,,,
HkgSEnA5KQ,2019,Accept (Poster),False,Guiding Policies with Language via Meta-Learning,"[""John D. Co-Reyes"", ""Abhishek Gupta"", ""Suvansh Sanjeev"", ""Nick Altieri"", ""Jacob Andreas"", ""John DeNero"", ""Pieter Abbeel"", ""Sergey Levine""]","[""meta-learning"", ""language grounding"", ""interactive""]",We propose a meta-learning method for interactively correcting policies with natural language.,,,,
HkgSk2A9Y7,2019,Reject,False,Stochastic Gradient Push for Distributed Deep Learning,"[""Mahmoud Assran"", ""Nicolas Loizou"", ""Nicolas Ballas"", ""Mike Rabbat""]","[""optimization"", ""distributed"", ""large scale"", ""deep learning""]","For distributed training over high-latency networks, use gossip-based approximate distributed averaging instead of exact distribute averaging like AllReduce.",,,,
HkgTTh4FDH,2020,Accept (Poster),False,Implicit Bias of Gradient Descent based Adversarial Training on Separable Data,"[""Yan Li"", ""Ethan X.Fang"", ""Huan Xu"", ""Tuo Zhao""]","[""implicit bias"", ""adversarial training"", ""robustness"", ""gradient descent""]","The solution of gradient descent based adversarial training converges in direction to a robust max margin solution that is adapted to adversary geometry, using L2 perturbation also shows significant speed-up in convergence compared to clean training.",,,,
HkgTkhRcKQ,2019,Accept (Poster),False,AdaShift: Decorrelation and Convergence of Adaptive Learning Rate Methods,"[""Zhiming Zhou*"", ""Qingru Zhang*"", ""Guansong Lu"", ""Hongwei Wang"", ""Weinan Zhang"", ""Yong Yu""]","[""optimizer"", ""Adam"", ""convergence"", ""decorrelation""]",We analysis and solve the non-convergence issue of Adam.,,,,
HkgU3xBtDS,2020,Reject,False,REFINING MONTE CARLO TREE SEARCH AGENTS BY MONTE CARLO TREE SEARCH,"[""Katsuki Ohto""]","[""Reinforcement Learning"", ""Monte Carlo Tree Search"", ""Alpha Zero""]",Apply Monte Carlo Tree Search to episode generation in Alpha Zero,,,,
HkgXteBYPB,2020,Reject,False,Stochastic Neural Physics Predictor,"[""Piotr Tatarczyk"", ""Damian Mrowca"", ""Li Fei-Fei"", ""Daniel L. K. Yamins"", ""Nils Thuerey""]","[""physics prediction"", ""forward dynamics"", ""stochastic environments"", ""dropout""]",We propose a stochastic differentiable forward dynamics predictor that is able to sample multiple physically plausible trajectories under the same initial input state and show that it can be used to train model-free policies more efficiently.,,,,
HkgYEyrFDr,2020,Reject,False,Learning Good Policies By Learning Good Perceptual Models,"[""Yilun Du"", ""Phillip Isola""]","[""visual representation learning"", ""reinforcement learning"", ""curiosity""]",We present a formulation of curiosity as a visual representation learning problem and show that it allows good visual representations in agents.,,,,
HkgYmhR9KX,2019,Accept (Poster),False,AD-VAT: An Asymmetric Dueling mechanism for learning Visual Active Tracking,"[""Fangwei Zhong"", ""Peng Sun"", ""Wenhan Luo"", ""Tingyun Yan"", ""Yizhou Wang""]","[""Active tracking"", ""reinforcement learning"", ""adversarial learning"", ""multi agent""]","We propose AD-VAT, where the tracker and the target object, viewed as two learnable agents, are opponents and can mutually enhance during training.",,,,
HkgaETNtDB,2020,Accept (Poster),True,Mixout: Effective Regularization to Finetune Large-scale Pretrained Language Models,"[""Cheolhyoung Lee"", ""Kyunghyun Cho"", ""Wanmo Kang""]","[""regularization"", ""finetuning"", ""dropout"", ""dropconnect"", ""adaptive L2-penalty"", ""BERT"", ""pretrained language model""]",,1909.11299,cs.LG,2019-09-25 06:04:37+00:00,2020-01-23 02:18:43+00:00
HkgbKaEtvB,2020,Reject,False,End-To-End Input Selection for Deep Neural Networks,"[""Stefan Oehmcke"", ""Fabian Gieseke""]","[""Deep Learning"", ""Input Selection"", ""Gumbel Softmax Trick"", ""Remote Sensing"", ""Feature Selection""]",We propose a framework that automatically learns to select the relevant parts of the input data for a given neural network and its task.,,,,
HkgeGeBYDB,2020,Accept (Poster),False,RaPP: Novelty Detection with Reconstruction along Projection Pathway,"[""Ki Hyun Kim"", ""Sangwoo Shim"", ""Yongsub Lim"", ""Jongseob Jeon"", ""Jeongwoo Choi"", ""Byungchan Kim"", ""Andre S. Yoon""]","[""Novelty Detection"", ""Anomaly Detection"", ""Outlier Detection"", ""Semi-supervised Learning""]",A new methodology for novelty detection by utilizing hidden space activation values obtained from a deep autoencoder.,,,,
HkghV209tm,2019,Reject,False,Optimistic Acceleration for Optimization,"[""Jun-Kun Wang"", ""Xiaoyun Li"", ""Ping Li""]","[""optimization"", ""Adam"", ""AMSGrad""]",We consider new variants of optimization algorithms for training deep nets.,,,,
HkghoaNYPB,2020,Reject,False,AlgoNet: $C^\infty$ Smooth Algorithmic Neural Networks,"[""Felix Petersen"", ""Christian Borgelt"", ""Oliver Deussen""]","[""Algorithms"", ""Smoothness"", ""Differentiable"", ""Inverse Problems"", ""Adversarial Training"", ""Neural Networks"", ""Deep Learning"", ""Differentiable Renderer"", ""3D Mesh"", ""Turing-completeness"", ""Library""]",Integrating classical algorithms into neural networks.,,,,
HkgmzhC5F7,2019,Reject,False,A Modern Take on the Bias-Variance Tradeoff in Neural Networks,"[""Brady Neal"", ""Sarthak Mittal"", ""Aristide Baratin"", ""Vinayak Tantia"", ""Matthew Scicluna"", ""Simon Lacoste-Julien"", ""Ioannis Mitliagkas""]","[""bias-variance tradeoff"", ""deep learning theory"", ""generalization"", ""concentration""]",We revisit empirically and theoretically the bias-variance tradeoff for neural networks to shed more light on their generalization properties.,,,,
Hkgnii09Ym,2019,Reject,False,Set Transformer,"[""Juho Lee"", ""Yoonho Lee"", ""Jungtaek Kim"", ""Adam R. Kosiorek"", ""Seungjin Choi"", ""Yee Whye Teh""]","[""attention"", ""meta-learning"", ""set-input neural networks"", ""permutation invariant modeling""]",Attention-based neural network to process set-structured data,,,,
HkgnpiR9Y7,2019,Reject,False,Recycling the discriminator for improving the inference mapping of GAN,"[""Duhyeon Bang"", ""Hyunjung Shim""]",[],,,,,
Hkgpnn4YvH,2020,Reject,False,Graph Neural Networks For Multi-Image Matching,"[""Stephen Phillips"", ""Kostas Daniilidis""]","[""Graph Neural Networks"", ""Multi-image Matching""]",We use Graph Neural Networks to learning multi-image feature matching with Geometric side losses.,,,,
HkgqFiAcFm,2019,Accept (Poster),False,Marginal Policy Gradients: A Unified Family of Estimators for Bounded Action Spaces with Applications,"[""Carson Eisenach"", ""Haichuan Yang"", ""Ji Liu"", ""Han Liu""]","[""reinforcement learning"", ""policy gradient"", ""MOBA games""]",,,,,
HkgqmyrYDH,2020,Reject,False,WORD SEQUENCE PREDICTION FOR AMHARIC LANGUAGE,"[""Nuniyat Kifle"", ""Ermias Abebe""]","[""Word prediction"", ""POS"", ""Statistical approach""]","Amharic word sequence prediction model is developed with statistical methods using Hidden Markov Model by incorporating detailed parts of speech tag , user profiling or adaptation. ",,,,
HkgrZ0EYwB,2020,Accept (Poster),True,Unpaired Point Cloud Completion on Real Scans using Adversarial Training,"[""Xuelin Chen"", ""Baoquan Chen"", ""Niloy J. Mitra""]","[""point cloud completion"", ""generative adversarial network"", ""real scans""]",,1904.00069,cs.CV,2019-03-29 19:45:21+00:00,2020-02-23 11:38:31+00:00
Hkgs3aNYDS,2020,Reject,False,Quantum Expectation-Maximization for Gaussian Mixture Models,"[""Iordanis Kerenidis"", ""Anupam Prakash"", ""Alessandro Luongo""]","[""Quantum"", ""ExpectationMaximization"", ""Unsupervised"", ""QRAM""]",It's the quantum algorithm for Expectation Maximization. It's fast: the runtime depends only polylogarithmically on the number of elements in the dataset. ,,,,
HkgsPhNYPS,2020,Accept (Poster),True,SELF: Learning to Filter Noisy Labels with Self-Ensembling,"[""Duc Tam Nguyen"", ""Chaithanya Kumar Mummadi"", ""Thi Phuong Nhung Ngo"", ""Thi Hoai Phuong Nguyen"", ""Laura Beggel"", ""Thomas Brox""]","[""Ensemble Learning"", ""Robust Learning"", ""Noisy Labels"", ""Labels Filtering""]",We propose a self-ensemble framework to train more robust deep learning models under noisy labeled datasets.,1910.01842,cs.CV,2019-10-04 08:59:54+00:00,2019-10-04 08:59:54+00:00
HkgsUJrtDB,2020,Accept (Poster),False,RÃ©nyi Fair Inference,"[""Sina Baharlouei"", ""Maher Nouiehed"", ""Ahmad Beirami"", ""Meisam Razaviyayn""]",[],,,,,
HkgsWxrtPB,2020,Accept (Poster),False,Meta Reinforcement Learning with Autonomous Inference of Subtask Dependencies,"[""Sungryull Sohn"", ""Hyunjae Woo"", ""Jongwook Choi"", ""Honglak Lee""]","[""Meta reinforcement learning"", ""subtask graph""]",A novel meta-RL method that infers latent subtask structure,2001.00248,cs.LG,2020-01-01 17:34:00+00:00,2020-04-14 01:44:03+00:00
HkgtJRVFPS,2020,Reject,False,Topological Autoencoders,"[""Michael Moor"", ""Max Horn"", ""Bastian Rieck"", ""Karsten Borgwardt""]","[""Topology"", ""Deep Learning"", ""Autoencoders"", ""Persistent Homology"", ""Representation Learning"", ""Dimensionality Reduction"", ""Topological Machine Learning"", ""Topological Data Analysis""]",,,,,
HkgxW0EYDS,2020,Accept (Poster),True,Scalable Model Compression by Entropy Penalized Reparameterization,"[""Deniz Oktay"", ""Johannes Ball\u00e9"", ""Saurabh Singh"", ""Abhinav Shrivastava""]","[""deep learning"", ""model compression"", ""computer vision"", ""information theory""]",An end-to-end trainable model compression method optimizing accuracy jointly with the expected model size.,1906.06624,cs.LG,2019-06-15 22:46:33+00:00,2020-02-16 17:51:13+00:00
HkgxasA5Ym,2019,Reject,False,Reliable Uncertainty Estimates in Deep Neural Networks using Noise Contrastive Priors,"[""Danijar Hafner"", ""Dustin Tran"", ""Timothy Lillicrap"", ""Alex Irpan"", ""James Davidson""]","[""uncertainty estimates"", ""out of distribution"", ""bayesian neural network"", ""neural network priors"", ""regression"", ""active learning""]",We train neural networks to be uncertain on noisy inputs to avoid overconfident predictions outside of the training distribution.,,,,
HkgxheBFDS,2020,Reject,False,Undersensitivity in Neural Reading Comprehension,"[""Johannes Welbl"", ""Pasquale Minervini"", ""Max Bartolo"", ""Pontus Stenetorp"", ""Sebastian Riedel""]","[""reading comprehension"", ""undersensitivity"", ""adversarial questions"", ""adversarial training"", ""robustness"", ""biased data setting""]","We demonstrate vulnerability to undersensitivity attacks in SQuAD2.0 and NewsQA neural reading comprehension models, where the model predicts the same answer with increased confidence to adversarially chosen questions, and compare defence strategies.",2003.04808,cs.CL,2020-02-15 19:03:36+00:00,2020-02-15 19:03:36+00:00
Hki-ZlbA-,2018,Reject,False,Ground-Truth Adversarial Examples,"[""Nicholas Carlini"", ""Guy Katz"", ""Clark Barrett"", ""David L. Dill""]","[""adversarial examples"", ""neural networks"", ""formal verification"", ""ground truths""]",We use formal verification to assess the effectiveness of techniques for finding adversarial examples or for defending against adversarial examples.,,,,
HkinqfbAb,2018,Reject,False,Automatic Parameter Tying in Neural Networks,"[""Yibo Yang"", ""Nicholas Ruozzi"", ""Vibhav Gogate""]","[""neural network"", ""quantization"", ""compression""]",A k-means prior combined with L1 regularization yields state-of-the-art compression results.,,,,
HkjL6MiTb,2018,Reject,False,Siamese Survival Analysis with Competing Risks,"[""Anton Nemchenko"", ""Kartik Ahuja"", ""Mihaela Van Der Schaar""]","[""survival analysis"", ""competing risks"", ""siamese neural networks""]",In this work we introduce a novel Siamese Deep Neural Network architecture that is able to effectively learn from data in the presence of multiple adverse events.,,,,
Hkl-di09FQ,2019,Reject,False,Decoupling feature extraction from policy learning: assessing benefits of state representation learning in goal based robotics,"[""Antonin Raffin"", ""Ashley Hill"", ""Ren\u00e9 Traor\u00e9"", ""Timoth\u00e9e Lesort"", ""Natalia D\u00edaz-Rodr\u00edguez"", ""David Filliat""]","[""reinforcement learning"", ""state representation learning"", ""feature extraction"", ""robotics"", ""deep learning""]",We evaluate the benefits of decoupling feature extraction from policy learning in robotics and propose a new way of combining state representation learning methods.,,,,
Hkl1iRNFwS,2020,Accept (Poster),False,The Early Phase of Neural Network Training,"[""Jonathan Frankle"", ""David J. Schwab"", ""Ari S. Morcos""]","[""empirical"", ""learning dynamics"", ""lottery tickets"", ""critical periods"", ""early""]","We thoroughly investigate neural network learning dynamics over the early phase of training, finding that these changes are crucial and difficult to approximate, though extended pretraining can recover them.",2002.10365,cs.LG,2020-02-24 16:51:01+00:00,2020-02-24 16:51:01+00:00
Hkl4EANFDH,2020,Reject,False,Regularizing Trajectories to Mitigate Catastrophic Forgetting,"[""Paul Michel"", ""Elisabeth Salesky"", ""Graham Neubig""]","[""Continual Learning"", ""Regularization"", ""Adaptation"", ""Natural Gradient""]",Regularizing the optimization trajectory with the Fisher information of old tasks reduces catastrophic forgetting greatly,,,,
Hkl5aoR5tm,2019,Accept (Poster),False,On Self Modulation for Generative Adversarial Networks,"[""Ting Chen"", ""Mario Lucic"", ""Neil Houlsby"", ""Sylvain Gelly""]","[""unsupervised learning"", ""generative adversarial networks"", ""deep generative modelling""]","A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. ",,,,
Hkl6i0EFPH,2020,Reject,False,Scalable Differentially Private Data Generation via Private  Aggregation  of  Teacher Ensembles,"[""Yunhui Long"", ""Suxin Lin"", ""Zhuolin Yang"", ""Carl A. Gunter"", ""Han Liu"", ""Bo Li""]",[],,,,,
Hkl84iCcFm,2019,Reject,False,RESIDUAL NETWORKS CLASSIFY INPUTS BASED ON THEIR NEURAL TRANSIENT DYNAMICS,"[""Fereshteh Lagzi""]","[""Residual Networks"", ""Dynamical Systems"", ""Classification""]",,,,,
Hkl9JlBYvr,2020,Accept (Poster),True,VariBAD: A Very Good Method for Bayes-Adaptive Deep RL via Meta-Learning,"[""Luisa Zintgraf"", ""Kyriacos Shiarlis"", ""Maximilian Igl"", ""Sebastian Schulze"", ""Yarin Gal"", ""Katja Hofmann"", ""Shimon Whiteson""]","[""Meta-Learning"", ""Bayesian Reinforcement Learning"", ""BAMDPs"", ""Deep Reinforcement Learning""]","VariBAD opens a path to tractable approximate Bayes-optimal exploration for deep RL using ideas from meta-learning, Bayesian RL, and approximate variational inference.",1910.08348,cs.LG,2019-10-18 11:44:59+00:00,2020-02-27 19:40:21+00:00
HklAhi09Y7,2019,Reject,False,Question Generation using a Scratchpad Encoder,"[""Ryan Y Benmalek"", ""Madian Khabsa"", ""Suma Desu"", ""Claire Cardie"", ""Michele Banko""]","[""Question Generation"", ""Natural Language Generation"", ""Scratchpad Encoder"", ""Sequence to Sequence""]","In this paper we introduce the Scratchpad Encoder, a novel addition to the sequence to sequence (seq2seq) framework and explore its effectiveness in generating natural language questions from a given logical form.",,,,
HklBjCEKvH,2020,Accept (Poster),True,Generalization through Memorization: Nearest Neighbor Language Models,"[""Urvashi Khandelwal"", ""Omer Levy"", ""Dan Jurafsky"", ""Luke Zettlemoyer"", ""Mike Lewis""]","[""language models"", ""k-nearest neighbors""]","We extend a pre-trained neural language model by linearly interpolating it with a k-nearest neighbors model, achieving new state-of-the-art results on Wikitext-103 with no additional training.",1911.00172,cs.CL,2019-11-01 01:09:53+00:00,2020-02-15 01:04:52+00:00
HklCk1BtwS,2020,Reject,False,Word embedding re-examined: is the symmetrical factorization optimal?,"[""Zhichao Han"", ""Jia Li"", ""Xu Li"", ""Hong Cheng""]","[""word embedding"", ""matrix factorization"", ""linear transformation"", ""neighborhood structure""]",,,,,
HklCmaVtPS,2020,Reject,False,UW-NET: AN INCEPTION-ATTENTION NETWORK FOR UNDERWATER IMAGE CLASSIFICATION,"[""Miao Yang and Ke Hu"", ""Chongyi Li"", ""Zhiqiang Wei""]","[""Underwater image"", ""Convolutional neural network"", ""Image classification"", ""Inception module"", ""Attention module""]",A visual understanding mechanism for special environment,,,,
HklE01BYDB,2020,Reject,True,Improving Sample Efficiency in Model-Free Reinforcement Learning from Images,"[""Denis Yarats"", ""Amy Zhang"", ""Ilya Kostrikov"", ""Brandon Amos"", ""Joelle Pineau"", ""Rob Fergus""]","[""reinforcement learning"", ""model-free"", ""off-policy"", ""image-based reinforcement learning"", ""continuous control""]",We design a simple and efficient model-free off-policy method for image-based reinforcement learning that matches the state-of-the-art model-based methods in sample efficiency,1910.01741,cs.LG,2019-10-02 15:50:03+00:00,2020-07-09 15:42:09+00:00
HklFUlBKPB,2020,Reject,False,Identifying Weights and Architectures of Unknown ReLU Networks,"[""David Rolnick"", ""Konrad P. Kording""]","[""deep neural network"", ""ReLU"", ""piecewise linear function"", ""linear region"", ""activation region"", ""weights"", ""parameters"", ""architecture""]","We show that in many cases it is possible to reconstruct the architecture, weights, and biases of a deep ReLU network given the network's output for specified inputs.",,,,
HklJV3A9Ym,2019,Reject,False,Approximation capability of neural networks on sets of probability measures and tree-structured data,"[""Tom\u00e1\u0161 Pevn\u00fd"", ""Vojt\u011bch Kova\u0159\u00edk""]","[""multi-instance learning"", ""hierarchical models"", ""universal approximation theorem""]",This paper extends the proof of density of neural networks in the space of continuous (or even measurable) functions on Euclidean spaces to functions on compact sets of probability measures. ,,,,
HklJdaNYPH,2020,Reject,True,Augmenting Self-attention with Persistent Memory,"[""Sainbayar Sukhbaatar"", ""Edouard Grave"", ""Guillaume Lample"", ""Herve Jegou"", ""Armand Joulin""]","[""transformer"", ""language modeling"", ""self-attention""]",A novel attention layer that combines self-attention and feed-forward sublayers of Transformer networks.,1907.01470,cs.LG,2019-07-02 15:56:20+00:00,2019-07-02 15:56:20+00:00
HklKWhC5F7,2019,Reject,False,How Training Data Affect the Accuracy and Robustness of Neural Networks for Image Classification,"[""Suhua Lei"", ""Huan Zhang"", ""Ke Wang"", ""Zhendong Su""]","[""Adversarial attacks"", ""Robustness"", ""CW"", ""I-FGSM""]",,,,,
HklKui0ct7,2019,Accept (Poster),False,Off-Policy Evaluation and Learning from Logged Bandit Feedback: Error Reduction via Surrogate Policy,"[""Yuan Xie"", ""Boyi Liu"", ""Qiang Liu"", ""Zhaoran Wang"", ""Yuan Zhou"", ""Jian Peng""]","[""Causal inference"", ""Policy Optimization"", ""Non-asymptotic analysis""]",,,,,
HklOo0VFDH,2020,Accept (Poster),False,Decoding As Dynamic Programming For Recurrent Autoregressive Models,"[""Najam Zaidi"", ""Trevor Cohn"", ""Gholamreza Haffari""]","[""Decoding""]",Approximate inference using dynamic programming for Autoregressive models.,,,,
HklPzxHFwB,2020,Reject,False,Zero-Shot Policy Transfer with Disentangled Attention,"[""Josh Roy"", ""George Konidaris""]","[""Transfer Learning"", ""Reinforcement Learning"", ""Attention"", ""Domain Adaptation"", ""Representation Learning"", ""Feature Extraction""]",We present an agent that uses a beta-vae to extract visual features and an attention mechanism to ignore irrelevant features from visual observations to enable robust transfer between visual domains.,,,,
HklQYxBKwS,2020,Accept (Poster),True,"Neural tangent kernels, transportation mappings, and universal approximation","[""Ziwei Ji"", ""Matus Telgarsky"", ""Ruicheng Xian""]","[""Neural Tangent Kernel"", ""universal approximation"", ""Barron"", ""transport mapping""]","The NTK linearization is a universal approximator, even when looking arbitrarily close to initialization",1910.06956,cs.LG,2019-10-15 17:52:49+00:00,2020-02-15 00:45:24+00:00
HklQxnC5tX,2019,Reject,False,Overlapping Community Detection with Graph Neural Networks,"[""Oleksandr Shchur"", ""Stephan G\u00fcnnemann""]","[""community detection"", ""deep learning for graphs""]",Detecting overlapping communities in graphs using graph neural networks,,,,
HklRKpEKDr,2020,Reject,False,Deep Coordination Graphs,"[""Wendelin Boehmer"", ""Vitaly Kurin"", ""Shimon Whiteson""]","[""multi-agent reinforcement learning"", ""coordination graph"", ""deep Q-learning"", ""value factorization"", ""relative overgeneralization""]",We introduce an efficient value factorization architecture for MARL that is defined by a coordination graph.,,,,
HklRwaEKwB,2020,Accept (Spotlight),True,"Ridge Regression: Structure, Cross-Validation, and Sketching","[""Sifan Liu"", ""Edgar Dobriban""]","[""ridge regression"", ""sketching"", ""random matrix theory"", ""cross-validation"", ""high-dimensional asymptotics""]","We study the structure of ridge regression in a high-dimensional asymptotic framework, and get insights about cross-validation and sketching.",1910.02373,math.ST,2019-10-06 05:00:40+00:00,2020-03-29 04:14:36+00:00
HklSeREtPB,2020,Accept (Spotlight),False,Emergence of functional and structural properties of the head direction system by optimization of recurrent neural networks,"[""Christopher J. Cueva"", ""Peter Y. Wang"", ""Matthew Chin"", ""Xue-Xin Wei""]","[""recurrent network"", ""head direction system"", ""neural circuits"", ""neural coding""]",Artificial neural networks trained with gradient descent are capable of recapitulating both realistic neural activity and the anatomical organization of a biological circuit.,1912.10189,q-bio.NC,2019-12-21 03:51:58+00:00,2020-05-17 09:06:33+00:00
HklSf3CqKm,2019,Accept (Poster),True,Subgradient Descent Learns Orthogonal Dictionaries,"[""Yu Bai"", ""Qijia Jiang"", ""Ju Sun""]","[""Dictionary learning"", ""Sparse coding"", ""Non-convex optimization"", ""Theory""]",Efficient dictionary learning by L1 minimization via a novel analysis of the non-convex non-smooth geometry.,1810.10702,cs.LG,2018-10-25 03:07:58+00:00,2019-07-01 05:26:18+00:00
HklUCCVKDB,2020,Accept (Poster),True,Uncertainty-guided Continual Learning with Bayesian Neural Networks,"[""Sayna Ebrahimi"", ""Mohamed Elhoseiny"", ""Trevor Darrell"", ""Marcus Rohrbach""]","[""continual learning"", ""catastrophic forgetting""]",A regularization-based approach for continual learning using Bayesian neural networks to predict parameters' importance,1906.02425,cs.LG,2019-06-06 05:40:25+00:00,2020-02-20 01:08:22+00:00
HklVMnR5tQ,2019,Reject,False,Exploring the interpretability of LSTM neural networks over multi-variable data,"[""Tian Guo"", ""Tao Lin""]","[""Interpretability"", ""recurrent neural network"", ""attention""]",,,,,
HklVTi09tm,2019,Reject,False,Detecting Topological Defects in 2D Active Nematics Using Convolutional Neural Networks,"[""Ruoshi Liu"", ""Michael M. Norton"", ""Seth Fraden"", ""Pengyu Hong""]",[],An interesting application of CNN in soft condensed matter physics experiments.,,,,
HklWsREKwr,2020,Reject,True,Training Deep Neural Networks with Partially Adaptive Momentum,"[""Jinghui Chen"", ""Dongruo Zhou"", ""Yiqi Tang"", ""Ziyan Yang"", ""Yuan Cao"", ""Quanquan Gu""]",[],,1806.06763,cs.LG,2018-06-18 15:17:01+00:00,2020-06-23 06:47:00+00:00
HklXn1BKDH,2020,Accept (Poster),False,Learning To Explore Using Active Neural SLAM,"[""Devendra Singh Chaplot"", ""Dhiraj Gandhi"", ""Saurabh Gupta"", ""Abhinav Gupta"", ""Ruslan Salakhutdinov""]","[""Navigation"", ""Exploration""]",A modular and hierarchical approach to learn policies for exploring 3D environments.,2004.05155,cs.CV,2020-04-10 17:57:29+00:00,2020-04-10 17:57:29+00:00
HklY120cYm,2019,Accept (Poster),False,ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech,"[""Wei Ping"", ""Kainan Peng"", ""Jitong Chen""]","[""text-to-speech"", ""deep generative models"", ""end-to-end training"", ""text to waveform""]",,,,,
HklZOfW0W,2018,Reject,False,UPS: optimizing Undirected Positive Sparse graph for neural graph filtering,"[""Mikhail Yurochkin"", ""Dung Thai"", ""Hung Hai Bui"", ""XuanLong Nguyen""]",[],Graph Optimization with signal filtering in the vertex domain.,,,,
HklZUpEtvr,2020,Reject,False,"OPTIMAL TRANSPORT, CYCLEGAN, AND PENALIZED LS FOR UNSUPERVISED LEARNING IN INVERSE PROBLEMS","[""Byeongsu Sim"", ""Gyutaek Oh"", ""Sungjun Lim"", ""and Jong Chul Ye""]","[""Optimal transport"", ""CycleGAN"", ""penalized LS"", ""unsupervised learning"", ""and inverse problems""]",,,,,
Hkl_bCVKDr,2020,Reject,True,Scaleable input gradient regularization for adversarial robustness,"[""Chris Finlay"", ""Adam M Oberman""]","[""adversarial robustness"", ""gradient regularization"", ""robust certification"", ""robustness bounds""]",New robust certification bounds motivate gradient regularization for adversarial robustness ,1905.11468,stat.ML,2019-05-27 19:40:52+00:00,2019-10-04 14:12:34+00:00
Hkl_sAVtwr,2020,Reject,True,Compressed Sensing with Deep Image Prior and Learned Regularization,"[""Dave Van Veen"", ""Ajil Jalal"", ""Mahdi Soltanolkotabi"", ""Eric Price"", ""Sriram Vishwanath"", ""Alexandros G. Dimakis""]","[""compressed sensing"", ""sparsity"", ""inverse problems""]",Compressed sensing methods with untrained networks and theoretical guarantees,1806.06438,stat.ML,2018-06-17 20:11:03+00:00,2020-10-29 19:55:19+00:00
Hkla1eHFvS,2020,Reject,False,Efficient Exploration via State Marginal Matching,"[""Lisa Lee"", ""Benjain Eysenbach"", ""Emilio Parisotto"", ""Erix Xing"", ""Sergey Levine"", ""Ruslan Salakhutdinov""]","[""reinforcement learning"", ""exploration"", ""distribution matching"", ""robotics""]",We view exploration in RL as a problem of matching a marginal distribution over states.,,,,
HklbTjRcKX,2019,Reject,False,What Information Does a ResNet Compress?,"[""Luke Nicholas Darlow"", ""Amos Storkey""]","[""Deep Learning"", ""Information Bottleneck"", ""Residual Neural Networks"", ""Information Theory""]","The Information Bottleneck Principle applied to ResNets, using PixelCNN++ models to decode mutual information and conditionally generate images for information illustration",2003.06254,cs.LG,2020-03-13 13:02:11+00:00,2020-03-13 13:02:11+00:00
Hklc6oAcFX,2019,Reject,False,Co-manifold learning with missing data,"[""Gal Mishne"", ""Eric C. Chi"", ""Ronald R. Coifman""]","[""nonlinear dimensionality reduction"", ""missing data"", ""manifold learning"", ""co-clustering"", ""optimization""]",Nonlinear representations of observations and features of a data matrix with missing entries and coupled geometries,,,,
Hklcm0VYDS,2020,Reject,False,How noise affects the Hessian spectrum in overparameterized neural networks,"[""Mingwei Wei"", ""David Schwab""]","[""noise"", ""optimization"", ""loss landscape"", ""Hessian""]","This paper shows that for overparameterized networks with a degenerate valley in their loss landscape, SGD on average decreases the trace of the Hessian of the loss and generalizes this result to other noise structures.",,,,
HkldyTNYwH,2020,Accept (Poster),False,AE-OT: A NEW GENERATIVE MODEL BASED ON EXTENDED SEMI-DISCRETE OPTIMAL TRANSPORT,"[""Dongsheng An"", ""Yang Guo"", ""Na Lei"", ""Zhongxuan Luo"", ""Shing-Tung Yau"", ""Xianfeng Gu""]","[""Generative model"", ""auto-encoder"", ""optimal transport"", ""mode collapse"", ""regularity""]",,,,,
Hklgis0cF7,2019,Reject,False,Radial Basis Feature Transformation to Arm CNNs Against Adversarial Attacks,"[""Saeid Asgari Taghanaki"", ""Shekoofeh Azizi"", ""Ghassan Hamarneh""]","[""Radial basis feature transformation"", ""convolutional neural networks"", ""adversarial defense""]",A new nonlinear defense against adversarial attacks.,,,,
HkliveStvH,2020,Reject,False,Connectivity-constrained interactive annotations for panoptic segmentation,"[""Ruobing Shen"", ""Bo Tang"", ""Ismail Ben Ayed"", ""Andrea Lodi"", ""Thomas Guthier""]","[""Panoptic Segmentation"", ""Semantic Segmentation"", ""Interactive Segmentation"", ""Integer Programming""]",,,,,
HkljfjFee,2017,Accept (Poster),False,Support Regularized Sparse Coding and Its Fast Encoder,"[""Yingzhen Yang"", ""Jiahui Yu"", ""Pushmeet Kohli"", ""Jianchao Yang"", ""Thomas S. Huang""]",[],"We present Support Regularized Sparse Coding (SRSC) to improve the regular sparse coding, and propose a feed-forward neural network termed Deep Support Regularized Sparse Coding (Deep-SRSC) as its fast encoder.",,,,
HkljioCcFQ,2019,Accept (Poster),False,MARGINALIZED AVERAGE ATTENTIONAL NETWORK FOR WEAKLY-SUPERVISED LEARNING,"[""Yuan Yuan"", ""Yueming Lyu"", ""Xi Shen"", ""Ivor W. Tsang"", ""Dit-Yan Yeung""]","[""feature aggregation"", ""weakly supervised learning"", ""temporal action localization""]",A novel marginalized average attentional network for weakly-supervised temporal action localization ,,,,
HklkeR4KPB,2020,Accept (Poster),False,ReMixMatch: Semi-Supervised Learning with Distribution Matching and Augmentation Anchoring,"[""David Berthelot"", ""Nicholas Carlini"", ""Ekin D. Cubuk"", ""Alex Kurakin"", ""Kihyuk Sohn"", ""Han Zhang"", ""Colin Raffel""]","[""semi-supervised learning""]","We introduce Distribution Matching and Augmentation Anchoring, two improvements to MixMatch which produce state-of-the-art results and enable surprisingly strong performance with only 40 labels on CIFAR-10 and SVHN.",1911.09785,cs.LG,2019-11-21 23:44:25+00:00,2020-02-13 23:14:46+00:00
HklliySFDS,2020,Reject,False,Continual Learning with Gated Incremental Memories for Sequential Data Processing,"[""Andrea Cossu"", ""Antonio Carta"", ""Davide Bacciu""]","[""continual learning"", ""recurrent neural networks"", ""progressive networks"", ""gating autoencoders"", ""sequential data processing""]","We tackled the problem of CL in sequential data processing scenarios, providing a set of domain-agnostic benchmarks against which we compared performances of a novel RNN for CL and other standard RNNs.",2004.04077,cs.LG,2020-04-08 16:00:20+00:00,2020-04-08 16:00:20+00:00
HklmoRVYvr,2020,Reject,False,Long History Short-Term Memory for Long-Term Video Prediction,"[""Wonmin Byeon"", ""Jan Kautz""]","[""LSTM"", ""video"", ""long-term prediction""]","We propose a new recurrent unit, Long History Short-Term Memory (LH-STM) which incorporates long history states into a recurrent unit to learn longer range dependencies.",,,,
HklnzhR9YQ,2019,Reject,False,Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks,"[""Kenta Oono"", ""Taiji Suzuki""]","[""CNN"", ""ResNet"", ""learning theory"", ""approximation theory"", ""non-parametric estimation"", ""block-sparse""]",It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \textit{block-sparse} structure even if the size of each layer in the CNN is fixed.,,,,
Hklo5RNtwS,2020,Reject,False,Behavior-Guided Reinforcement Learning,"[""Aldo Pacchiano"", ""Jack Parker-Holder"", ""Yunhao Tang"", ""Anna Choromanska"", ""Krzysztof Choromanski"", ""Michael I. Jordan""]","[""Reinforcement Learning"", ""Optimal Transport"", ""Evolution Strategies""]","We seek to find the right measure of similarity between two policies, acting on the same underlying MDP, and devise algorithms to leverage this information for reinforcement learning.",,,,
HklpCzC6-,2018,Reject,False,Image Segmentation by Iterative Inference from Conditional Score Estimation,"[""Adriana Romero"", ""Michal Drozdzal"", ""Akram Erraqabi"", ""Simon J\u00e9gou"", ""Yoshua Bengio""]","[""semantic segmentation"", ""conditional denoising autoencoders"", ""iterative inference""]",Refining segmentation proposals by performing iterative inference with conditional denoising autoencoders.,,,,
Hklr204Fvr,2020,Accept (Poster),False,Towards a Deep Network Architecture for Structured Smoothness,"[""Haroun Habeeb"", ""Oluwasanmi Koyejo""]",[],A feedforward layer to incorporate structured smoothness into a deep learning model,,,,
HklsHyBKDr,2020,Reject,False,On Predictive Information Sub-optimality of RNNs,"[""Zhe Dong"", ""Deniz Oktay"", ""Ben Poole"", ""Alexander A. Alemi""]",[],,,,,
Hkls_yBKDB,2020,Reject,True,Neural Program Synthesis By Self-Learning,"[""Yifan Xu"", ""Lu Dai"", ""Udaikaran Singh"", ""Kening Zhang"", ""Zhuowen Tu""]","[""Neural Program Synthesis"", ""Reinforcement Learning"", ""Deep learning"", ""Self-Learning""]","We develop a neural program synthesis algorithm,AutoAssemblet, to explore the large-scale  code  space  efficiently  via  self-learning  under  the  reinforcement  learning  (RL)  framework.",1910.05865,cs.LG,2019-10-13 23:44:37+00:00,2019-10-13 23:44:37+00:00
Hklso24Kwr,2020,Accept (Poster),False,Continual Learning with Adaptive Weights (CLAW),"[""Tameem Adel"", ""Han Zhao"", ""Richard E. Turner""]","[""Continual learning""]",A continual learning framework which learns to automatically adapt its architecture based on a proposed variational inference algorithm. ,1911.09514,stat.ML,2019-11-21 14:59:58+00:00,2020-06-16 01:00:11+00:00
HklsthVYDH,2020,Reject,False,Learning to Defense by Learning to Attack,"[""Zhehui Chen"", ""Haoming Jiang"", ""Yuyang Shi"", ""Bo Dai"", ""Tuo Zhao""]",[],,,,,
HklvMJSYPB,2020,Reject,False,Adaptive Adversarial Imitation Learning,"[""Yiren Lu"", ""Jonathan Tompson"", ""Sergey Levine""]","[""Imitation Learning"", ""Reinforcement Learning""]",,,,,
HklvmlrKPB,2020,Reject,False,Improving Sequential Latent Variable Models with Autoregressive Flows,"[""Joseph Marino"", ""Lei Chen"", ""Jiawei He"", ""Stephan Mandt""]","[""Autoregressive Flows"", ""Sequence Modeling"", ""Latent Variable Models"", ""Video Modeling"", ""Variational Inference""]",We show how autoregressive flows can be used to improve sequential latent variable models.,2010.03172,cs.LG,2020-10-07 05:14:37+00:00,2020-10-07 05:14:37+00:00
HklxbgBKvr,2020,Accept (Poster),False,Model-based reinforcement learning for biological sequence design,"[""Christof Angermueller"", ""David Dohan"", ""David Belanger"", ""Ramya Deshpande"", ""Kevin Murphy"", ""Lucy Colwell""]","[""reinforcement learning"", ""blackbox optimization"", ""molecule design""]","We augment model-free policy learning with a sequence-level surrogate reward functions and count-based visitation bonus and demonstrate effectiveness in the large batch, low-round regime seen in designing DNA and protein sequences.",,,,
HklyMhCqYQ,2019,Reject,False,Super-Resolution via Conditional Implicit Maximum Likelihood Estimation,"[""Ke Li*"", ""Shichong Peng*"", ""Jitendra Malik""]","[""super-resolution""]",We propose a new method for image super-resolution based on IMLE. ,,,,
Hklz71rYvS,2020,Accept (Spotlight),False,Kernelized Wasserstein Natural Gradient,"[""M Arbel"", ""A Gretton"", ""W Li"", ""G Montufar""]","[""kernel methods"", ""natural gradient"", ""information geometry"", ""Wasserstein metric""]",Estimator for the Wasserstein natural gradient,,,,
HkmaTz-0W,2018,Invite to Workshop Track,False,Visualizing the Loss Landscape of Neural Nets,"[""Hao Li"", ""Zheng Xu"", ""Gavin Taylor"", ""Tom Goldstein""]","[""visualization"", ""loss surface"", ""flatness"", ""sharpness""]","We explore the structure of neural loss functions, and the effect of loss landscapes on generalization, using a range of visualization methods.",,,,
Hkn7CBaTW,2018,Accept (Poster),False,Learning how to explain neural networks: PatternNet and PatternAttribution,"[""Pieter-Jan Kindermans"", ""Kristof T. Sch\u00fctt"", ""Maximilian Alber"", ""Klaus-Robert M\u00fcller"", ""Dumitru Erhan"", ""Been Kim"", ""Sven D\u00e4hne""]","[""machine learning"", ""interpretability"", ""deep learning""]","Without learning, it is impossible to explain a machine learning model's decisions.",,,,
HknbyQbC-,2018,Reject,False,Generating Adversarial Examples with Adversarial Networks,"[""Chaowei Xiao"", ""Bo Li"", ""Jun-Yan Zhu"", ""Warren He"", ""Mingyan Liu"", ""Dawn Song""]","[""adversarial examples"", ""generative adversarial network"", ""black-box attack""]",We propose to generate adversarial example based on generative adversarial networks in a semi-whitebox and black-box settings.,,,,
Hko85plCW,2018,Accept (Poster),False,Monotonic Chunkwise Attention,"[""Chung-Cheng Chiu*"", ""Colin Raffel*""]","[""attention"", ""sequence-to-sequence"", ""speech recognition"", ""document summarization""]",An online and linear-time attention mechanism that performs soft attention over adaptively-located chunks of the input sequence.,,,,
Hkp3uhxCW,2018,Reject,False,Revisiting Bayes by Backprop,"[""Meire Fortunato"", ""Charles Blundell"", ""Oriol Vinyals""]","[""Bayesian"", ""Deep Learning"", ""Recurrent Neural Networks"", ""LSTM""]", Variational Bayes scheme for Recurrent Neural Networks,,,,
HkpLeH9el,2017,Invite to Workshop Track,False,Neural Functional Programming,"[""John K. Feser"", ""Marc Brockschmidt"", ""Alexander L. Gaunt"", ""Daniel Tarlow""]","[""Supervised Learning""]",A differentiable functional programming language for learning programs from input-output examples.,,,,
HkpRBFxRb,2018,Reject,False,Learning to Mix n-Step Returns: Generalizing Lambda-Returns for Deep Reinforcement Learning,"[""Sahil Sharma"", ""Girish Raguvir J *"", ""Srivatsan Ramesh *"", ""Balaraman Ravindran""]","[""Reinforcement Learning"", ""Lambda-Returns""]",A novel way to generalize lambda-returns by allowing the RL agent to decide how much it wants to weigh each of the n-step returns.,,,,
HkpYwMZRb,2018,Invite to Workshop Track,False,Gradients explode - Deep Networks are shallow - ResNet explained,"[""George Philipp"", ""Dawn Song"", ""Jaime G. Carbonell""]","[""deep learning"", ""MLP"", ""ResNet"", ""residual network"", ""exploding gradient problem"", ""vanishing gradient problem"", ""effective depth"", ""batch normalization"", ""covariate shift""]","We show that in contras to popular wisdom, the exploding gradient problem has not been solved and that it limits the depth to which MLPs can be effectively trained. We show why gradients explode and how ResNet handles them.",,,,
HkpbnH9lx,2017,Accept (Poster),False,Density estimation using Real NVP,"[""Laurent Dinh"", ""Jascha Sohl-Dickstein"", ""Samy Bengio""]","[""Deep learning"", ""Unsupervised Learning""]",Efficient invertible neural networks for density estimation and generation,,,,
HksioDcxl,2017,Reject,False,Joint Training of Ratings and Reviews with Recurrent Recommender Networks,"[""Chao-Yuan Wu"", ""Amr Ahmed"", ""Alex Beutel"", ""Alexander J. Smola""]",[],,,,,
Hksj2WWAW,2018,Accept (Poster),False,Combining Symbolic Expressions and Black-box Function Evaluations in Neural Programs,"[""Forough Arabshahi"", ""Sameer Singh"", ""Animashree Anandkumar""]","[""symbolic reasoning"", ""mathematical equations"", ""recursive neural networks"", ""neural programing""]",,,,,
HktJec1RZ,2018,Accept (Poster),False,Towards Neural Phrase-based Machine Translation,"[""Po-Sen Huang"", ""Chong Wang"", ""Sitao Huang"", ""Dengyong Zhou"", ""Li Deng""]","[""Neural Machine Translation"", ""Sequence to Sequence"", ""Sequence Modeling""]",Neural phrase-based machine translation with linear decoding time,,,,
HktK4BeCZ,2018,Accept (Oral),False,Learning Deep Mean Field Games for Modeling Large Population Behavior,"[""Jiachen Yang"", ""Xiaojing Ye"", ""Rakshit Trivedi"", ""Huan Xu"", ""Hongyuan Zha""]","[""mean field games"", ""reinforcement learning"", ""Markov decision processes"", ""inverse reinforcement learning"", ""deep learning"", ""inverse optimal control"", ""computational social science"", ""population modeling""]",Inference of a mean field game (MFG) model of large population behavior via a synthesis of MFG and Markov decision processes.,,,,
HktRlUlAZ,2018,Accept (Poster),False,Polar Transformer Networks,"[""Carlos Esteves"", ""Christine Allen-Blanchette"", ""Xiaowei Zhou"", ""Kostas Daniilidis""]","[""equivariance"", ""invariance"", ""canonical coordinates""]","We learn feature maps invariant to translation, and equivariant to rotation and scale.",,,,
HktXuGb0-,2018,Reject,False,Reward Estimation via State Prediction,"[""Daiki Kimura"", ""Subhajit Chaudhury"", ""Ryuki Tachibana"", ""Sakyasingha Dasgupta""]","[""reinforcement learning"", ""inverse reinforcement learning"", ""imitation learning""]",Reward Estimation from Game Videos,,,,
Hku9NK5lx,2017,Accept (Poster),False,Training Compressed Fully-Connected Networks with a Density-Diversity Penalty,"[""Shengjie Wang"", ""Haoran Cai"", ""Jeff Bilmes"", ""William Noble""]","[""Deep learning""]","We propose a new ''density-diversity penalty'' to fully-connected layers to get significantly high sparsity and low diversity trained matrices, while keeping the performance the same.",,,,
HkuGJ3kCb,2018,Accept (Poster),False,All-but-the-Top: Simple and Effective Postprocessing for Word Representations,"[""Jiaqi Mu"", ""Pramod Viswanath""]",[],,,,,
HkuVu3ige,2017,Reject,False,On orthogonality and learning recurrent networks with long term dependencies,"[""Eugene Vorontsov"", ""Chiheb Trabelsi"", ""Samuel Kadoury"", ""Chris Pal""]","[""Deep learning""]","While orthogonal matrices improve neural network stability during training, deviating from orthogonality may improve model convergence speed and performance.",,,,
HkvS3Mqxe,2017,Reject,False,Coarse Pruning of Convolutional Neural Networks with Random Masks,"[""Sajid Anwar"", ""Wonyong Sung""]",[],"This work has proposed a new pruning strategy for CNN. Further, feature map and kernel pruning granularities are proposed for good pruning ratios and simple sparse representation.",,,,
HkwBEMWCZ,2018,Accept (Poster),False,Skip Connections Eliminate Singularities,"[""Emin Orhan"", ""Xaq Pitkow""]","[""deep learning"", ""optimization"", ""skip connections""]",Degenerate manifolds arising from the non-identifiability of the model slow down learning in deep networks; skip connections help by breaking degeneracies.,,,,
HkwVAXyCW,2018,Accept (Poster),False,Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks,"[""V\u00edctor Campos"", ""Brendan Jou"", ""Xavier Gir\u00f3-i-Nieto"", ""Jordi Torres"", ""Shih-Fu Chang""]","[""recurrent neural networks"", ""dynamic learning"", ""conditional computation""]",A modification for existing RNN architectures which allows them to skip state updates while preserving the performance of the original architectures.,,,,
HkwZSG-CZ,2018,Accept (Oral),False,Breaking the Softmax Bottleneck: A High-Rank RNN Language Model,"[""Zhilin Yang"", ""Zihang Dai"", ""Ruslan Salakhutdinov"", ""William W. Cohen""]",[],,,,,
HkwoSDPgg,2017,Accept (Oral),False,Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data,"[""Nicolas Papernot"", ""Mart\u00edn Abadi"", ""\u00dalfar Erlingsson"", ""Ian Goodfellow"", ""Kunal Talwar""]",[],Semi-supervised learning of a privacy-preserving student model with GANs by knowledge transfer from an ensemble of teachers trained on partitions of private data.,,,,
HkwrqtlR-,2018,Reject,False,WHAT ARE GANS USEFUL FOR?,"[""Pablo M. Olmos"", ""Briland Hitaj"", ""Paolo Gasti"", ""Giuseppe Ateniese"", ""Fernando Perez-Cruz""]","[""Generative Modeling"", ""Generative Adversarial Networks"", ""Density Estimation""]",,,,,
Hkx-ii05FQ,2019,Reject,False,The Cakewalk Method,"[""Uri Patish"", ""Shimon Ullman""]","[""policy gradient"", ""combinatorial optimization"", ""blackbox optimization"", ""stochastic optimization"", ""reinforcement learning""]","A new policy gradient algorithm designed to approach black-box combinatorial optimization problems. The algorithm relies only on function evaluations, and returns locally optimal solutions with high probability.",,,,
Hkx1qkrKPr,2020,Accept (Poster),True,DropEdge: Towards Deep Graph Convolutional Networks on Node Classification,"[""Yu Rong"", ""Wenbing Huang"", ""Tingyang Xu"", ""Junzhou Huang""]","[""graph neural network"", ""over-smoothing"", ""over-fitting"", ""dropedge"", ""graph convolutional networks""]","This paper proposes DropEdge, a novel and flexible technique to alleviate over-smoothing and overfitting issue in deep Graph Convolutional Networks.",1907.10903,cs.LG,2019-07-25 08:57:45+00:00,2020-03-12 08:04:36+00:00
Hkx3ElHYwS,2020,Reject,False,GQ-Net: Training Quantization-Friendly Deep Networks,"[""Rundong Li"", ""Rui Fan""]","[""Network quantization"", ""Efficient deep learning""]",We train accurate fully quantized networks using a loss function maximizing full precision model accuracy and minimizing the difference between the full precision and quantized networks.,,,,
Hkx6hANtwH,2020,Accept (Poster),False,LambdaNet: Probabilistic Type Inference using Graph Neural Networks,"[""Jiayi Wei"", ""Maruth Goyal"", ""Greg Durrett"", ""Isil Dillig""]","[""Type inference"", ""Graph neural network"", ""Programming languages"", ""Pointer network""]","We have presented LambdaNet, a neural architecture for type inference that combines the strength of explicit program analysis with graph neural networks.",2005.02161,cs.PL,2020-04-29 17:48:40+00:00,2020-04-29 17:48:40+00:00
Hkx6p6EFDr,2020,Reject,False,Equivariant Entity-Relationship Networks,"[""Devon Graham"", ""Siamak Ravanbakhsh""]","[""deep learning"", ""relational model"", ""knowledge graph"", ""exchangeability"", ""equivariance""]",We propose a feed-forward layer that is informed by the ER model of relational data and show that it is the most expressive linear layer possible under given the equivariance constraints. ,,,,
Hkx7_1rKwS,2020,Accept (Poster),False,On Solving Minimax Optimization Locally: A Follow-the-Ridge Approach,"[""Yuanhao Wang*"", ""Guodong Zhang*"", ""Jimmy Ba""]","[""minimax optimization"", ""smooth differentiable games"", ""local convergence"", ""generative adversarial networks"", ""optimization""]",,,,,
Hkx7xRVYDr,2020,Accept (Spotlight),True,Duration-of-Stay Storage Assignment under Uncertainty,"[""Michael Lingzhi Li"", ""Elliott Wolf"", ""Daniel Wintz""]","[""Storage Assignment"", ""Deep Learning"", ""Duration-of-Stay"", ""Application"", ""Natural Language Processing"", ""Parallel Network""]",We develop a new storage assignment framework with a novel neural network that enables large efficiency gains in the warehouse.,1903.05063,cs.LG,2019-03-12 17:12:07+00:00,2020-02-01 01:38:44+00:00
HkxAAvcxx,2017,Reject,False,Transformation-based Models of Video Sequences,"[""Joost van Amersfoort"", ""Anitha Kannan"", ""Marc'Aurelio Ranzato"", ""Arthur Szlam"", ""Du Tran"", ""Soumith Chintala""]","[""Computer vision"", ""Unsupervised Learning""]",Predict next frames of a video sequence by modelling transformations,,,,
HkxARkrFwB,2020,Accept (Spotlight),False,word2ket: Space-efficient Word Embeddings inspired by Quantum Entanglement,"[""Aliakbar Panahi"", ""Seyran Saeedi"", ""Tom Arodz""]","[""word embeddings"", ""natural language processing"", ""model reduction""]",We use ideas from quantum computing to propose word embeddings that utilize much fewer trainable parameters.,1911.04975,cs.LG,2019-11-12 16:06:50+00:00,2020-03-03 14:08:07+00:00
HkxAS6VFDB,2020,Reject,False,Prune or quantize? Strategy for Pareto-optimally low-cost and accurate CNN,"[""Kengo Nakata"", ""Daisuke Miyashita"", ""Asuka Maki"", ""Fumihiko Tachibana"", ""Shinichi Sasaki"", ""Jun Deguchi""]","[""CNN"", ""Quantization"", ""Pruning"", ""Accelerator"", ""Computational cost""]","This paper reveals that ""prune-then-quantize method"" is the best strategy to achieve Pareto-optimal performance by using a proposed hardware-agnostic metric to measure computational cost.",,,,
HkxAisC9FQ,2019,Reject,False,Improved robustness to adversarial examples using Lipschitz regularization of the loss,"[""Chris Finlay"", ""Adam M. Oberman"", ""Bilal Abbasi""]","[""Adversarial training"", ""adversarial examples"", ""deep neural networks"", ""regularization"", ""Lipschitz constant""]","Improvements to adversarial robustness, as well as provable robustness guarantees, are obtained by augmenting adversarial training with a tractable Lipschitz regularization",,,,
HkxBJT4YvB,2020,Accept (Poster),False,Learning Disentangled Representations for CounterFactual Regression,"[""Negar Hassanpour"", ""Russell Greiner""]","[""Counterfactual Regression"", ""Causal Effect Estimation"", ""Selection Bias"", ""Off-policy Learning""]",,,,,
HkxCEhAqtQ,2019,Reject,False,Accelerated Gradient Flow for Probability Distributions,"[""Amirhossein Taghvaei"", ""Prashant G. Mehta""]","[""Optimal transportation"", ""Mean-field optimal control"", ""Wasserstein gradient flow"", ""Markov-chain Monte-Carlo""]",Methodology and numerical algorithms for constructing accelerated gradient flows on the space of probability distributions.,,,,
HkxCcJHtPr,2020,Reject,True,CAT: Compression-Aware Training for bandwidth reduction,"[""Chaim Baskin"", ""Brian Chmiel"", ""Evgenii Zheltonozhskii"", ""Ron Banner"", ""Alex M. Bronstein"", ""Avi Mendelson""]","[""compression"", ""quantization"", ""efficient inference"", ""memory bandwidth"", ""entropy"", ""compression-aware training"", ""Huffman"", ""variable length coding""]",Adding an entropy-reducing regularization to the loss to improve activation compression in inference time reducing memory bandwidth.,1909.11481,cs.CV,2019-09-25 13:29:58+00:00,2019-09-25 13:29:58+00:00
HkxCenR5F7,2019,Reject,False,Variational recurrent models for representation learning,"[""Qingming Tang"", ""Mingda Chen"", ""Weiran Wang"", ""Karen Livescu""]","[""Representation learning"", ""variational model""]",,,,,
HkxCzeHFDB,2020,Accept (Poster),True,Functional Regularisation for  Continual Learning with Gaussian Processes,"[""Michalis K. Titsias"", ""Jonathan Schwarz"", ""Alexander G. de G. Matthews"", ""Razvan Pascanu"", ""Yee Whye Teh""]","[""Continual Learning"", ""Gaussian Processes"", ""Lifelong learning"", ""Incremental Learning""]",Using inducing point sparse Gaussian process methods to overcome catastrophic forgetting in neural networks.,1901.11356,stat.ML,2019-01-31 13:51:27+00:00,2020-02-11 16:05:28+00:00
HkxDheHFDr,2020,Reject,False,LAVAE: Disentangling Location and Appearance,"[""Andrea Dittadi"", ""Ole Winther""]","[""structured scene representations"", ""compositional representations"", ""generative models"", ""unsupervised learning""]","Generative model that learns structured, interpretable, object-based representations of visual scenes, disentangling object location and appearance.",,,,
HkxF5RgC-,2018,Accept (Poster),False,Sparse Persistent RNNs: Squeezing Large Recurrent Networks On-Chip,"[""Feiwen Zhu"", ""Jeff Pool"", ""Michael Andersch"", ""Jeremy Appleyard"", ""Fung Xie""]","[""Sparsity"", ""Pruning"", ""Compression"", ""RNN"", ""LSTM"", ""Persistent"", ""RF-Resident"", ""GPU""]","Combining network pruning and persistent kernels into a practical, fast, and accurate network implementation.",,,,
HkxIIaVKPB,2020,Reject,False,Unsupervised-Learning of time-varying features,"[""Henrik H\u00f8eg"", ""Matthias Brix"", ""Oswin Krause""]","[""Representation Learning"", ""Variational Autoencoder"", ""Unsupervised Learning"", ""Deep-Learning"", ""Registration""]","We introduce a model-architecture based on conditional VAEs that can learn time-varying features, as for example image-transformations, efficiently.",,,,
HkxJHlrFvr,2020,Reject,False,Angular Visual Hardness,"[""Beidi Chen"", ""Weiyang Liu"", ""Animesh Garg"", ""Zhiding Yu"", ""Anshumali Shrivastava"", ""Jan Kautz"", ""Anima Anandkumar""]","[""angular similarity"", ""self-training"", ""hard samples mining""]",A novel measure in CNN based on angular similarity that is shown to correlate strongly with human visual hardness with gains in applications such as self-training.,,,,
HkxJpnVtPr,2020,Reject,False,A Stochastic Trust Region Method for Non-convex Minimization,"[""Zebang Shen"", ""Pan Zhou"", ""Cong Fang"", ""Jiahao Xie"", ""Alejandro Ribeiro""]",[],,,,,
HkxKH2AcFm,2019,Accept (Poster),False,Towards GAN Benchmarks Which Require Generalization,"[""Ishaan Gulrajani"", ""Colin Raffel"", ""Luke Metz""]","[""evaluation"", ""generative adversarial networks"", ""adversarial divergences""]",We argue that GAN benchmarks must require a large sample from the model to penalize memorization and investigate whether neural network divergences have this property.,,,,
HkxLXnAcFQ,2019,Accept (Poster),False,A Closer Look at Few-shot Classification,"[""Wei-Yu Chen"", ""Yen-Cheng Liu"", ""Zsolt Kira"", ""Yu-Chiang Frank Wang"", ""Jia-Bin Huang""]","[""few shot classification"", ""meta-learning""]", A detailed empirical study in few-shot classification that revealing challenges in standard evaluation setting and showing a new direction.,,,,
HkxMG209K7,2019,Reject,False,An Alarm System for Segmentation Algorithm Based on Shape Model,"[""Fengze Liu"", ""Yingda Xia"", ""Dong Yang"", ""Alan Yuille"", ""Daguang Xu""]","[""segmentation evaluation"", ""shape feature"", ""variational auto-encoder""]",We use VAE to capture the shape feature for automatic segmentation evaluation,,,,
HkxOoiAcYX,2019,Reject,False,Estimating Information Flow in DNNs,"[""Ziv Goldfeld"", ""Ewout van den Berg"", ""Kristjan Greenewald"", ""Brian Kingsbury"", ""Igor Melnyk"", ""Nam Nguyen"", ""Yury Polyanskiy""]","[""information theory"", ""representation learning"", ""deep learning"", ""differential entropy estimation""]","Deterministic deep neural networks do not discard information, but they do cluster their inputs.",,,,
HkxQRTNYPH,2020,Accept (Talk),False,Mirror-Generative Neural Machine Translation,"[""Zaixiang Zheng"", ""Hao Zhou"", ""Shujian Huang"", ""Lei Li"", ""Xin-Yu Dai"", ""Jiajun Chen""]","[""neural machine translation"", ""generative model"", ""mirror""]",,,,,
HkxQzlHFPr,2020,Reject,False,Robust Natural Language Representation Learning for Natural Language Inference by Projecting Superficial Words out,"[""Wanyun Cui"", ""Guangyu Zheng"", ""Wei Wang""]","[""natural language inference"", ""first order logic""]",We use neural networks to project superficial information out for natural language inference by defining and identifying the superficial information from the perspective of first-order logic.,,,,
HkxSOAEFDB,2020,Reject,False,Octave Graph Convolutional Network,"[""Heng Chang"", ""Yu Rong"", ""Somayeh Sojoudi"", ""Junzhou Huang"", ""Wenwu Zhu""]","[""Graph Convolutional Networks"", ""Octave Convolution"", ""Graph Mining""]",Octave convolutional learning for graphs in spectral domain within the framework of Graph Convolutional Networks,,,,
HkxStoC5F7,2019,Accept (Poster),False,Meta-Learning Probabilistic Inference for Prediction,"[""Jonathan Gordon"", ""John Bronskill"", ""Matthias Bauer"", ""Sebastian Nowozin"", ""Richard Turner""]","[""probabilistic models"", ""approximate inference"", ""few-shot learning"", ""meta-learning""]",Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   ,,,,
HkxTwkrKDB,2020,Accept (Poster),True,On Universal Equivariant Set Networks,"[""Nimrod Segol"", ""Yaron Lipman""]","[""deep learning"", ""universality"", ""set functions"", ""equivariance""]",Settling permutation equivariance universality for popular deep models. ,1910.02421,cs.LG,2019-10-06 11:37:56+00:00,2020-01-23 20:15:00+00:00
HkxU2pNYPH,2020,Reject,False,Sticking to the Facts: Confident Decoding for Faithful Data-to-Text Generation,"[""Ran Tian"", ""Shashi Narayan"", ""Thibault Sellam"", ""Ankur P. Parikh""]","[""Natural Language Processing"", ""Text Generation"", ""Data-to-Text Generation"", ""Hallucination"", ""Calibration"", ""Variational Bayes""]",We propose a confidence-oriented decoder to reduce hallucination in neural structured-data-to-text generation.,,,,
HkxWXkStDB,2020,Reject,True,Improving Robustness Without Sacrificing Accuracy with Patch Gaussian Augmentation,"[""Raphael Gontijo Lopes"", ""Dong Yin"", ""Ben Poole"", ""Justin Gilmer"", ""Ekin D. Cubuk""]","[""Data Augmentation"", ""Out-of-distribution"", ""Robustness"", ""Generalization"", ""Computer Vision"", ""Corruption""]",Simple augmentation method overcomes robustness/accuracy trade-off observed in literature and opens questions about the effect of training distribution on out-of-distribution generalization.,1906.02611,cs.LG,2019-06-06 17:54:24+00:00,2019-06-06 17:54:24+00:00
HkxWrsC5FQ,2019,Reject,False,Provable Guarantees on Learning Hierarchical Generative Models with Deep CNNs,"[""Eran Malach"", ""Shai Shalev-Shwartz""]","[""deep learning"", ""theory""]",A generative model for deep CNNs with provable theoretical guarantees that actually works,,,,
HkxYzANYDB,2020,Accept (Spotlight),False,CLEVRER: Collision Events for Video Representation and Reasoning,"[""Kexin Yi*"", ""Chuang Gan*"", ""Yunzhu Li"", ""Pushmeet Kohli"", ""Jiajun Wu"", ""Antonio Torralba"", ""Joshua B. Tenenbaum""]","[""Neuro-symbolic"", ""Reasoning""]",We present a diagnostic dataset for systematic study of temporal and casual reasoning in videos. ,,,,
HkxZVlHYvH,2020,Reject,True,Ergodic Inference: Accelerate Convergence by Optimisation,"[""Yichuan Zhang"", ""Jos\u00e9 Miguel Hern\u00e1ndez-Lobato""]","[""MCMC"", ""variational inference"", ""statistical inference""]","In this work, we aim to improve upon MCMC and VI by a novel hybrid method based on the idea of reducing simulation bias of finite-length MCMC chains using gradient-based optimisation.",1805.10377,cs.LG,2018-05-25 21:55:12+00:00,2019-10-16 09:26:51+00:00
HkxZigSYwS,2020,Reject,False,Universal Safeguarded Learned Convex Optimization with Guaranteed Convergence,"[""Howard Heaton"", ""Xiaohan Chen"", ""Zhangyang Wang"", ""Wotao Yin""]","[""L2O"", ""learn to optimize"", ""fixed point"", ""machine learning"", ""neural network"", ""ADMM"", ""LADMM"", ""ALISTA"", ""D-LADMM""]","We provide the first general framework, with convergence guarantees, for applying learning to optimize schemes to any convex optimization problem.",,,,
HkxaFoC9KQ,2019,Accept (Poster),False,Deep reinforcement learning with relational inductive biases,"[""Vinicius Zambaldi"", ""David Raposo"", ""Adam Santoro"", ""Victor Bapst"", ""Yujia Li"", ""Igor Babuschkin"", ""Karl Tuyls"", ""David Reichert"", ""Timothy Lillicrap"", ""Edward Lockhart"", ""Murray Shanahan"", ""Victoria Langston"", ""Razvan Pascanu"", ""Matthew Botvinick"", ""Oriol Vinyals"", ""Peter Battaglia""]","[""relational reasoning"", ""reinforcement learning"", ""graph neural networks"", ""starcraft"", ""generalization"", ""inductive bias""]",Relational inductive biases improve out-of-distribution generalization capacities in model-free reinforcement learning agents,,,,
Hkxarj09Y7,2019,Reject,True,Unified recurrent network for many feature types,"[""Alexander Stec"", ""Diego Klabjan"", ""Jean Utke""]","[""sparse"", ""recurrent"", ""asynchronous"", ""time"", ""series""]","We introduce a unified RNN that handles five different feature types, each in a different manner.",1809.08717,stat.ML,2018-09-24 01:37:26+00:00,2018-09-24 01:37:26+00:00
Hkxbz1HKvr,2020,Reject,False,Learning Key Steps to Attack Deep Reinforcement Learning Agents,"[""Chien-Min Yu"", ""Hsuan-Tien Lin""]","[""deep reinforcement learning"", ""adversarial attacks""]",We propose a novel reinforcement learning framework where an attacker can learn more effective key steps to attack the reinforcement learning agent.,,,,
HkxcUxrFPS,2020,Reject,True,Improving Visual Relation Detection using Depth Maps,"[""Sahand Sharifzadeh"", ""Sina Moayed Baharlou"", ""Max Berrendorf"", ""Rajat Koner"", ""Volker Tresp""]","[""Visual Relation Detection"", ""Scene Graph Generation""]",Synthetically generated depth maps can improved visual relation detection.,1905.00966,cs.CV,2019-05-02 21:14:35+00:00,2020-10-17 13:58:38+00:00
HkxdQkSYDB,2020,Accept (Poster),True,Graph Convolutional Reinforcement Learning,"[""Jiechuan Jiang"", ""Chen Dun"", ""Tiejun Huang"", ""Zongqing Lu""]",[],,1810.09202,cs.LG,2018-10-22 12:17:40+00:00,2020-02-11 13:46:23+00:00
HkxeThNFPH,2020,Reject,True,Safe Policy Learning for Continuous Control,"[""Yinlam Chow"", ""Ofir Nachum"", ""Aleksandra Faust"", ""Edgar Duenez-Guzman"", ""Mohammad Ghavamzadeh""]","[""reinforcement learning"", ""policy gradient"", ""safety""]",A general framework for incorporating long-term safety constraints in policy-based reinforcement learning,1901.10031,cs.LG,2019-01-28 23:14:58+00:00,2019-02-11 20:52:42+00:00
HkxedlrFwB,2020,Reject,False,Accelerating First-Order Optimization Algorithms,"[""Ange Tato"", ""Roger Nkambou""]","[""Neural Networks"", ""Gradient Descent"", ""First order optimization""]",Accelerating First-Order Optimization Algorithms,,,,
Hkxi2gHYvH,2020,Reject,False,Predictive Coding for Boosting Deep Reinforcement Learning with Sparse Rewards,"[""Xingyu Lu"", ""Pieter Abbeel"", ""Stas Tiomkin""]","[""reinforcement learning"", ""representation learning"", ""reward shaping"", ""predictive coding""]",We apply predictive coding to provide reward signals in sparse reward problems.,,,,
HkxjYoCqKX,2019,Accept (Poster),False,Relaxed Quantization for Discretized Neural Networks,"[""Christos Louizos"", ""Matthias Reisser"", ""Tijmen Blankevoort"", ""Efstratios Gavves"", ""Max Welling""]","[""Quantization"", ""Compression"", ""Neural Networks"", ""Efficiency""]",We introduce a technique that allows for gradient based training of quantized neural networks.,,,,
HkxjqxBYDB,2020,Accept (Poster),False,Episodic Reinforcement Learning with Associative Memory,"[""Guangxiang Zhu*"", ""Zichuan Lin*"", ""Guangwen Yang"", ""Chongjie Zhang""]","[""Deep Reinforcement Learning"", ""Episodic Control"", ""Episodic Memory"", ""Associative Memory"", ""Non-Parametric Method"", ""Sample Efficiency""]",,,,,
HkxlcnVFwB,2020,Accept (Talk),False,GenDICE: Generalized Offline Estimation of Stationary Values,"[""Ruiyi Zhang*"", ""Bo Dai*"", ""Lihong Li"", ""Dale Schuurmans""]","[""Off-policy Policy Evaluation"", ""Reinforcement Learning"", ""Stationary Distribution Correction Estimation"", ""Fenchel Dual""]","In this paper, we proposed a novel algorithm, GenDICE, for general stationary distribution correction estimation, which can handle both discounted and average off-policy evaluation on multiple behavior-agnostic samples.",,,,
HkxnclHKDr,2020,Reject,False,Provable Representation Learning for Imitation Learning via Bi-level Optimization,"[""Sanjeev Arora"", ""Simon S. Du"", ""Sham Kakade"", ""Yuping Luo"", ""Nikunj Saunshi""]","[""imitation learning"", ""representation learning"", ""multitask learning"", ""theory"", ""behavioral cloning"", ""imitation from observations alone"", ""reinforcement learning""]","Using a bi-level optimization framework, we learn representations by leveraging multiple imitation learning tasks to provably reduce the sample complexity of learning a policy for a new task",2002.10544,cs.LG,2020-02-24 21:03:52+00:00,2020-02-24 21:03:52+00:00
Hkxp3JHtPr,2020,Reject,False,Deep Variational Semi-Supervised Novelty Detection,"[""Tal Daniel"", ""Thanard Kurutach"", ""Aviv Tamar""]","[""anomaly detection"", ""semi-supervised anomaly detection"", ""variational autoencoder""]","We proposed two VAE modifications that account for negative data examples, and used them for semi-supervised anomaly detection.",1911.04971,cs.LG,2019-11-12 16:03:50+00:00,2021-11-04 08:18:47+00:00
Hkxr1nCcFm,2019,Reject,False,An investigation of model-free planning,"[""Arthur Guez"", ""Mehdi Mirza"", ""Karol Gregor"", ""Rishabh Kabra"", ""S\u00e9bastien Racani\u00e8re"", ""Th\u00e9ophane Weber"", ""David Raposo"", ""Adam Santoro"", ""Laurent Orseau"", ""Tom Eccles"", ""Greg Wayne"", ""David Silver"", ""Timothy Lillicrap""]",[],,,,,
Hkxvl0EtDH,2020,Reject,False,A Causal View on Robustness  of Neural Networks,"[""Cheng Zhang"", ""Yingzhen Li""]","[""Neural Network Robustness"", ""Variational autoencoder (VAE)"", ""Causality"", ""Deep generative model""]",,,,,
HkxwmRVtwH,2020,Reject,False,Gaussian Process Meta-Representations Of Neural Networks,"[""Theofanis Karaletsos"", ""Thang Bui""]","[""Bayesian Neural Networks"", ""Representation Learning"", ""Gaussian Processes"", ""Variational Inference""]",We derive a Gaussian Process prior for Bayesian Neural Networks based on representations of units and use compositional kernels to model inductive biases for deep learning.,,,,
Hkxx3o0qFX,2019,Reject,True,High Resolution and Fast Face Completion via Progressively Attentive GANs,"[""Zeyuan Chen"", ""Shaoliang Nie"", ""Tianfu Wu"", ""Christopher G. Healey""]","[""Face Completion"", ""progressive GANs"", ""Attribute Control"", ""Frequency-oriented Attention""]",,1801.07632,cs.CV,2018-01-23 16:12:26+00:00,2018-01-23 16:12:26+00:00
HkxzNpNtDS,2020,Reject,False,Generalized Natural Language Grounded Navigation via Environment-agnostic Multitask Learning,"[""Xin Wang"", ""Vihan Jain"", ""Eugene Ie"", ""William Wang"", ""Zornitsa Kozareva"", ""Sujith Ravi""]","[""Natural Language Grounded Navigation"", ""Multitask Learning"", ""Agnostic Learning""]",We propose to learn a more generalized policy for natural language grounded navigation tasks via environment-agnostic multitask learning.,,,,
Hkxzx0NtDB,2020,Accept (Talk),False,Your classifier is secretly an energy based model and you should treat it like one,"[""Will Grathwohl"", ""Kuan-Chieh Wang"", ""Joern-Henrik Jacobsen"", ""David Duvenaud"", ""Mohammad Norouzi"", ""Kevin Swersky""]","[""energy based models"", ""adversarial robustness"", ""generative models"", ""out of distribution detection"", ""outlier detection"", ""hybrid models"", ""robustness"", ""calibration""]",We show that there is a hidden generative model inside of every classifier. We demonstrate how to train this model and show the many benefits of doing so.  ,,,,
HkyYqU9lx,2017,Reject,False,Sequence to Sequence Transduction with Hard Monotonic Attention,"[""Roee Aharoni"", ""Yoav Goldberg""]","[""Natural language processing"", ""Applications""]",Sequence to sequence learning with a hard attention mechanism that works better than soft attention models on monotonically aligned sequences,,,,
Hkz6aNqle,2017,Reject,False,Deep Error-Correcting Output Codes,"[""Guoqiang Zhong"", ""Yuchen Zheng"", ""Peng Zhang"", ""Mengqi Li"", ""Junyu Dong""]",[],,,,,
HkzNXhC9KQ,2019,Reject,False,Adaptive Sample-space & Adaptive Probability coding: a neural-network based approach for compression,"[""Ken Nakanishi"", ""Shin-ichi Maeda"", ""Takeru Miyato"", ""Masanori Koyama""]","[""Data compression"", ""Image compression"", ""Deep Learning"", ""Convolutional neural networks""]",,,,,
HkzOWnActX,2019,Reject,False,Model-Agnostic Meta-Learning for Multimodal Task Distributions,"[""Risto Vuorio"", ""Shao-Hua Sun"", ""Hexiang Hu"", ""Joseph J. Lim""]","[""Meta-learning"", ""gradient-based meta-learning"", ""model-based meta-learning""]","We proposed a meta-learner that generalizes across a multimodal task distribution by identifying the modes of a task distribution and modulating its meta-learned prior parameters accordingly, allowing faster adaptation through gradient updates.",,,,
HkzRQhR9YX,2019,Accept (Poster),False,Tree-Structured Recurrent Switching Linear Dynamical Systems for Multi-Scale Modeling,"[""Josue Nassar"", ""Scott Linderman"", ""Monica Bugallo"", ""Il Memming Park""]","[""machine learning"", ""bayesian statistics"", ""dynamical systems""]",,,,,
HkzSQhCcK7,2019,Accept (Poster),False,STCN: Stochastic Temporal Convolutional Networks,"[""Emre Aksan"", ""Otmar Hilliges""]","[""latent variables"", ""variational inference"", ""temporal convolutional networks"", ""sequence modeling"", ""auto-regressive modeling""]",We combine the computational advantages of temporal convolutional architectures with the expressiveness of stochastic latent variables.,,,,
HkzZBi0cFQ,2019,Reject,False,Quantization for Rapid Deployment of Deep Neural Networks,"[""Jun Haeng Lee"", ""Sangwon Ha"", ""Saerom Choi"", ""Won-Jo Lee"", ""Seungwon Lee""]",[],,,,,
HkzuKpLgg,2017,Reject,False,Efficient Communications in Training Large Scale Neural Networks,"[""Linnan Wang"", ""Wei Wu"", ""George Bosilca"", ""Richard Vuduc"", ""Zenglin Xu""]","[""Applications"", ""Deep learning""]",Tackle the communications in the parallel training of neural networks,,,,
HkzyX3CcFQ,2019,Reject,False,Contextual Recurrent Convolutional Model for Robust Visual Learning,"[""Siming Yan*"", ""Bowen Xiao*"", ""Yimeng Zhang"", ""Tai Sing Lee""]","[""contextual modulation"", ""recurrent convolutional network"", ""robust visual learning""]",we proposed a novel contextual recurrent convolutional network with robust property of visual learning ,,,,
HmAhqnu3qu,2021,Reject,False,Graph Representation Learning for Multi-Task Settings: a Meta-Learning Approach,"[""Davide Buffelli"", ""Fabio Vandin""]","[""Graph Representation Learning"", ""Multi-Task Learning"", ""Meta-Learning"", ""Graph Neural Networks""]","A novel representation learning strategy, based on meta-learning, for multi-task graph representation learning.",,,,
HmFBdvBkUUY,2022,Reject,False,SpecTRA: Spectral Transformer for Graph Representation Learning,"['Anson Bastos', 'Abhishek Nadgeri', 'Kuldeep Singh', 'Hiroki Kanezashi', 'Toyotaro Suzumura', ""Isaiah Onando Mulang'""]","[""Graph Representation Learning"", ""Transformer"", ""GNNs""]",This work aims to empower transformers to learn the essential components of the graph spectrum while filtering out the noise by effectively integrating the attention of the transformer with the spectrum of the graph. ,,,,
HndgQudNb91,2022,Accept (Poster),True,Learning to Downsample for Segmentation of Ultra-High Resolution Images,"['Chen Jin', 'Ryutaro Tanno', 'Thomy Mertzanidou', 'Eleftheria Panagiotaki', 'Daniel C. Alexander']","[""ultra-high resolution image segmentation"", ""non-uniform dowmsampling"", ""efficient segmentation"", ""large volume image segmentation"", ""medical image segmentation""]",We propose a method for learning to downsample ultra high-resolution images that reflects the importance of each location.,2109.11071,cs.CV,2021-09-22 23:04:59+00:00,2021-09-22 23:04:59+00:00
HowQIZwD_42,2021,Reject,False,Measuring and Harnessing Transference in Multi-Task Learning,"[""Chris Fifty"", ""Ehsan Amid"", ""Zhe Zhao"", ""Tianhe Yu"", ""Rohan Anil"", ""Chelsea Finn""]","[""multitask learning""]",Quantifying information transfer in multi-task learning and leveraging this measure to determine task groupings and improve learning efficiency.,,,,
Hr-cI3LMKb8,2021,Reject,False,Leveraging affinity cycle consistency to isolate factors of variation in learned representations,"[""Kieran A Murphy"", ""Varun Jampani"", ""Srikumar Ramalingam"", ""Ameesh Makadia""]",[],,,,,
Hrtbm8u0RXu,2021,Reject,True,Provable Memorization via Deep Neural Networks using Sub-linear Parameters,"[""Sejun Park"", ""Jaeho Lee"", ""Chulhee Yun"", ""Jinwoo Shin""]","[""memorization""]",Neural networks with o(N) parameters can memorize arbitrary N samples under some mild condition.,2010.13363,cs.LG,2020-10-26 06:19:38+00:00,2021-11-02 15:33:07+00:00
Ht85_jyihxp,2022,Accept (Poster),False,Efficient and Differentiable Conformal Prediction with General Function Classes,"['Yu Bai', 'Song Mei', 'Huan Wang', 'Yingbo Zhou', 'Caiming Xiong']","[""uncertainty quantification"", ""conformal prediction"", ""prediction sets""]","We generalize conformal prediction to learning multiple parameters within a general function class, to obtain an improved efficiency subject to valid coverage.",,,,
HuaYQfggn5u,2022,Accept (Poster),True,FedBABU: Toward Enhanced Representation for Federated Image Classification,"['Jaehoon Oh', 'SangMook Kim', 'Se-Young Yun']","[""Federated Learning"", ""Representation Learning""]","We propose a novel algorithm, FedBABU, which updates and aggregates only the body during federated training for enhanced representation.",2106.06042,cs.LG,2021-06-04 04:34:26+00:00,2022-02-09 02:26:20+00:00
Hw2Za4N5hy0,2021,Reject,False,Federated Learning with Decoupled Probabilistic-Weighted Gradient Aggregation,"[""Jian-hui Duan"", ""Wenzhong Li"", ""Sanglu Lu""]","[""Federated Learning"", ""Gradient Aggregation"", ""Variational Inference""]",,,,,
HxzSxSxLOJZ,2021,Accept (Poster),False,ResNet After All: Neural ODEs and Their Numerical Solution,"[""Katharina Ott"", ""Prateek Katiyar"", ""Philipp Hennig"", ""Michael Tiemann""]",[],We explain why some Neural ODE models do not permit a continuous-depth interpretation after training and how to fix it.,,,,
Hy-2G6ile,2017,Invite to Workshop Track,False,Gated Multimodal Units for Information Fusion,"[""John Arevalo"", ""Thamar Solorio"", ""Manuel Montes-y-G\u00f3mez"", ""Fabio A. Gonz\u00e1lez""]","[""Multi-modal learning"", ""Applications"", ""Supervised Learning""]",Gated Multimodal Units: a novel unit that learns to combine multiple modalities using multiplicative gates,,,,
Hy-lMNqex,2017,Reject,False,Tartan: Accelerating Fully-Connected and Convolutional Layers in Deep Learning Networks by Exploiting Numerical Precision Variability,"[""Alberto Delm\u00e1s Lascorz"", ""Sayeh Sharify"", ""Patrick Judd"", ""Andreas Moshovos""]","[""Deep learning"", ""Applications""]",A hardware accelerator whose execution time for Fully-Connected and Convolutional Layers  in CNNs vary inversely proportional with the number of bits used to represent the input activations and/or weights.,,,,
Hy0L4t5el,2017,Reject,False,Tree-Structured Variational Autoencoder,"[""Richard Shin"", ""Alexander A. Alemi"", ""Geoffrey Irving"", ""Oriol Vinyals""]",[],,,,,
Hy1d-ebAb,2018,Invite to Workshop Track,False,Learning Deep Generative Models of Graphs,"[""Yujia Li"", ""Oriol Vinyals"", ""Chris Dyer"", ""Razvan Pascanu"", ""Peter Battaglia""]","[""Generative Model of Graphs""]",We study the graph generation problem and propose a powerful deep generative model capable of generating arbitrary graphs.,,,,
Hy3MvSlRW,2018,Reject,False,Adversarial reading networks for machine comprehension,"[""Quentin Grail"", ""Julien Perez""]","[""machine reading"", ""adversarial training""]",,,,,
Hy3_KuYxg,2017,Reject,False,Divide and Conquer with Neural Networks,"[""Alex Nowak"", ""Joan Bruna""]","[""Deep learning""]",learn dynamic programming with neural networks,,,,
Hy4R2oRqKQ,2019,Reject,False,Canonical Correlation Analysis with Implicit Distributions,"[""Yaxin Shi"", ""Donna Xu"", ""Yuangang Pan"", ""Ivor Tsang""]","[""Canonical Correlation Analysis"", ""implicit probabilistic model"", ""cross-view structure output prediction""]",This paper presents a theoretical study for CCA based on implicit distributions and proposes a generative nonlinear CCA variant which achieves consistent encoding for the multi-view input.,,,,
Hy6GHpkCW,2018,Accept (Poster),False,A Neural Representation of Sketch Drawings,"[""David Ha"", ""Douglas Eck""]","[""applications"", ""image modelling"", ""computer-assisted"", ""drawing"", ""art"", ""creativity"", ""dataset""]","We investigate alternative to traditional pixel image modelling approaches, and propose a generative model for vector images.",,,,
Hy6b4Pqee,2017,Accept (Poster),False,Deep Probabilistic Programming,"[""Dustin Tran"", ""Matthew D. Hoffman"", ""Rif A. Saurous"", ""Eugene Brevdo"", ""Kevin Murphy"", ""David M. Blei""]",[],,,,,
Hy7EPh10W,2018,Reject,False,Novelty Detection with GAN,"[""Mark Kliger"", ""Shachar Fleishman""]","[""novelty detection"", ""GAN"", ""feature matching"", ""semi-supervised""]",We propose to solve a problem of simultaneous classification and novelty detection within the GAN framework.,,,,
Hy7fDog0b,2018,Accept (Oral),False,AmbientGAN: Generative models from lossy measurements,"[""Ashish Bora"", ""Eric Price"", ""Alexandros G. Dimakis""]","[""Generative models"", ""Adversarial networks"", ""Lossy measurements""]","How to learn GANs from noisy, distorted, partial observations",,,,
Hy8X3aKee,2017,Reject,False,Deep Symbolic Representation Learning for Heterogeneous Time-series Classification,"[""Shengdong Zhang"", ""Soheil Bahrampour"", ""Naveen Ramakrishnan"", ""Mohak Shah""]",[],,,,,
Hy8hkYeRb,2018,Reject,False,A Deep Predictive Coding Network for Learning Latent Representations,"[""Shirin Dora"", ""Cyriel Pennartz"", ""Sander Bohte""]","[""Predictive coding"", ""deep neural network"", ""generative model"", ""unsupervised learning"", ""learning latent representations""]",A predictive coding based learning algorithm for building deep neural network models of the brain,,,,
HyAbMKwxe,2017,Accept (Poster),False,Tighter bounds lead to improved classifiers,"[""Nicolas Le Roux""]",[],,,,,
HyAddcLge,2017,Reject,False,Revisiting Distributed Synchronous SGD,"[""Jianmin Chen*"", ""Xinghao Pan*"", ""Rajat Monga"", ""Samy Bengio"", ""Rafal Jozefowicz""]","[""Optimization"", ""Deep learning"", ""Applications""]","We proposed distributed synchronous stochastic optimization with backup workers, and show that it converge faster and to better test accuracies.",,,,
HyBbjW-RW,2018,Reject,False,Open Loop Hyperparameter Optimization and Determinantal Point Processes,"[""Jesse Dodge"", ""Kevin Jamieson"", ""Noah A. Smith""]","[""hyperparameter optimization"", ""random search"", ""determinantal point processes"", ""low discrepancy sequences""]","Driven by the need for parallelizable, open-loop hyperparameter optimization methods, we propose the use of $k$-determinantal point processes in  hyperparameter optimization via random search.",,,,
HyCRyS9gx,2017,Reject,False,Fast Adaptation in Generative Models with Generative Matching Networks,"[""Sergey Bartunov"", ""Dmitry P. Vetrov""]","[""Deep learning"", ""Unsupervised Learning""]",A nonparametric conditional generative model with fast small-shot adaptation,,,,
HyDAQl-AW,2018,Reject,False,Time Limits in Reinforcement Learning,"[""Fabio Pardo"", ""Arash Tavakoli"", ""Vitaly Levdik"", ""Petar Kormushev""]","[""reinforcement learning"", ""Markov decision processes"", ""deep learning""]",We consider the problem of learning optimal policies in time-limited and time-unlimited domains using time-limited interactions.,,,,
HyDMX0l0Z,2018,Invite to Workshop Track,False,Towards Effective GANs for Data Distributions with Diverse Modes,"[""Sanchit Agrawal"", ""Gurneet Singh"", ""Mitesh Khapra""]","[""generative adversarial networks"", ""GANs"", ""deep learning"", ""unsupervised learning"", ""generative models"", ""adversarial learning""]",We introduce theory to explain the failure of GANs on complex datasets and propose a solution to fix it.,,,,
HyET6tYex,2017,Reject,False,Universality in halting time,"[""Levent Sagun"", ""Thomas Trogdon"", ""Yann LeCun""]","[""Optimization""]",Normalized halting time distributions are independent of the input data distribution.,,,,
HyEeMu_xx,2017,Reject,False,Progressive Attention Networks for Visual Attribute Prediction,"[""Paul Hongsuck Seo"", ""Zhe Lin"", ""Scott Cohen"", ""Xiaohui Shen"", ""Bohyung Han""]","[""Deep learning"", ""Computer vision"", ""Multi-modal learning""]",Progressive attention model that accurately attends to the target objects of various scales and shapes through multiple CNN layers.,,,,
HyEi7bWR-,2018,Reject,False,Orthogonal Recurrent Neural Networks with Scaled Cayley Transform,"[""Kyle Helfrich"", ""Devin Willmott"", ""Qiang Ye""]","[""recurrent neural networks"", ""vanishing gradients"", ""exploding gradients"", ""orthogonal"", ""unitary"", ""long term dependencies"", ""uRNN""]",A novel approach to maintain orthogonal recurrent weight matrices in a RNN.,,,,
HyEl3o05Fm,2019,Reject,False,Stochastic Adversarial Video Prediction,"[""Alex X. Lee"", ""Richard Zhang"", ""Frederik Ebert"", ""Pieter Abbeel"", ""Chelsea Finn"", ""Sergey Levine""]","[""video prediction"", ""GANs"", ""variational autoencoder""]",,,,,
HyEtjoCqFX,2019,Accept (Poster),False,Soft Q-Learning with Mutual-Information Regularization,"[""Jordi Grau-Moya"", ""Felix Leibfried"", ""Peter Vrancx""]","[""reinforcement learning"", ""regularization"", ""entropy"", ""mutual information""]",,,,,
HyFaiGbCW,2018,Reject,False,Generalization of Learning using Reservoir Computing,"[""Sanjukta Krishnagopal"", ""Yiannis Aloimonos"", ""Michelle Girvan""]","[""Generalization"", ""Reservoir Computing"", ""dynamical system"", ""Siamese Neural Network"", ""image classification"", ""similarity"", ""dimensionality reduction""]","Generalization of the relationships learnt between pairs of images using a small training data to previously unseen types of images using an explainable dynamical systems model, Reservoir Computing, and a biologically plausible learning technique based on analogies.",,,,
HyFkG45gl,2017,Reject,False,Machine Solver for Physics Word Problems,"[""Megan Leszczynski"", ""Jose Moreira""]",[],"We build an automated solver for a class of physics word problems, using a combination of neural networks and a numerical integrator.",,,,
HyG1_j0cYQ,2019,Reject,False,Pumpout: A Meta Approach for Robustly Training Deep Neural Networks with Noisy Labels,"[""Bo Han"", ""Gang Niu"", ""Jiangchao Yao"", ""Xingrui Yu"", ""Miao Xu"", ""Ivor Tsang"", ""Masashi Sugiyama""]","[""Noisy Labels"", ""Deep Learning"", ""Meta Approach""]","Starting from tomorrow, never worry about your DNNs memorizing noisy labels---forget bad labels by Pumpout in an active manner!",,,,
HyGBdo0qFm,2019,Accept (Poster),False,On the Turing Completeness of Modern Neural Network Architectures,"[""Jorge P\u00e9rez"", ""Javier Marinkovi\u0107"", ""Pablo Barcel\u00f3""]","[""Transformer"", ""NeuralGPU"", ""Turing completeness""]",We show that the Transformer architecture and the Neural GPU are Turing complete.,,,,
HyGDdsCcFQ,2019,Reject,False,Better Generalization with On-the-fly Dataset Denoising,"[""Jiaming Song"", ""Tengyu Ma"", ""Michael Auli"", ""Yann Dauphin""]","[""dataset denoising"", ""supervised learning"", ""implicit regularization""]",We introduce a fast and easy-to-implement algorithm that is robust to dataset noise.,,,,
HyGEM3C9KQ,2019,Accept (Poster),False,"Improving Differentiable Neural Computers Through Memory Masking, De-allocation, and Link Distribution Sharpness Control","[""Robert Csordas"", ""Juergen Schmidhuber""]","[""rnn"", ""dnc"", ""memory augmented neural networks"", ""mann""]",,,,,
HyGIdiRqtm,2019,Accept (Poster),False,Evaluating Robustness of Neural Networks with Mixed Integer Programming,"[""Vincent Tjeng"", ""Kai Y. Xiao"", ""Russ Tedrake""]","[""verification"", ""adversarial robustness"", ""adversarial examples"", ""deep learning""]","We efficiently verify the robustness of deep neural models with over 100,000 ReLUs, certifying more samples than the state-of-the-art and finding more adversarial examples than a strong first-order attack.",,,,
HyGLy2RqtQ,2019,Reject,False,Over-parameterization Improves Generalization in the XOR Detection Problem,"[""Alon Brutzkus"", ""Amir Globerson""]","[""deep learning"", ""theory"", ""non convex optimization"", ""over-parameterization""]",We show in a simplified learning task that over-parameterization improves generalization of a convnet that is trained with gradient descent.,,,,
HyGTuv9eg,2017,Accept (Poster),False,Incorporating long-range consistency in CNN-based texture generation,"[""Guillaume Berger"", ""Roland Memisevic""]","[""Computer vision"", ""Deep learning""]",We propose a simple extension to the Gatys et al. algorithm which makes it possible to incorporate long-range structure into texture generation.,,,,
HyGcghRct7,2019,Accept (Poster),False,Random mesh projectors for inverse problems,"[""Konik Kothari*"", ""Sidharth Gupta*"", ""Maarten v. de Hoop"", ""Ivan Dokmanic""]","[""imaging"", ""inverse problems"", ""subspace projections"", ""random Delaunay triangulations"", ""CNN"", ""geophysics"", ""regularization""]",We solve ill-posed inverse problems with scarce ground truth examples by estimating an ensemble of random projections of the model instead of the model itself.,,,,
HyGh4sR9YQ,2019,Reject,False,Deep Neuroevolution: Genetic Algorithms are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning,"[""Felipe Petroski Such"", ""Vashisht Madhavan"", ""Edoardo Conti"", ""Joel Lehman"", ""Kenneth O. Stanley"", ""Jeff Clune""]","[""Neuroevolution"", ""Reinforcement Learning""]",,,,,
HyGhN2A5tm,2019,Accept (Poster),False,Multi-Agent Dual Learning,"[""Yiren Wang"", ""Yingce Xia"", ""Tianyu He"", ""Fei Tian"", ""Tao Qin"", ""ChengXiang Zhai"", ""Tie-Yan Liu""]","[""Dual Learning"", ""Machine Learning"", ""Neural Machine Translation""]",,,,,
HyGySsAct7,2019,Reject,False,Targeted Adversarial Examples for Black Box Audio Systems,"[""Rohan Taori"", ""Amog Kamsetty"", ""Brenton Chu"", ""Nikita Vemuri""]","[""adversarial attack"", ""adversarial examples"", ""audio processing"", ""speech to text"", ""deep learning"", ""adversarial audio"", ""black box"", ""machine learning""]",We present a novel black-box targeted attack on speech to text systems that supports arbitrarily long adversarial transcriptions and achieves state of the art performance.,,,,
HyH9lbZAW,2018,Accept (Poster),False,Variational Message Passing with Structured Inference Networks,"[""Wu Lin"", ""Nicolas Hubacher"", ""Mohammad Emtiyaz Khan""]","[""Variational Inference"", ""Variational Message Passing"", ""Variational Auto-Encoder"", ""Graphical Models"", ""Structured Models"", ""Natural Gradients""]",We propose a variational message-passing algorithm for models that contain both the deep model and probabilistic graphical model.,,,,
HyHmGyZCZ,2018,Reject,False,Comparison of Paragram and GloVe Results for Similarity Benchmarks,"[""Jakub Dutkiewicz"", ""Czes\u0142aw J\u0119drzejek""]","[""language models"", ""vector spaces"", ""word embedding"", ""similarity""]",Paper provides a description of a procedure to enhance word vector space model with an evaluation of Paragram and GloVe models for Similarity Benchmarks.,,,,
HyI5ro0pW,2018,Reject,False,Neural Networks with Block Diagonal Inner Product Layers,"[""Amy Nesky"", ""Quentin Stout""]","[""Deep Learning"", ""Neural Networks""]",We look at neural networks with block diagonal inner product layers for efficiency.,,,,
HyI6s40a-,2018,Reject,False,Towards Safe Deep Learning: Unsupervised Defense Against Generic Adversarial Attacks,"[""Bita Darvish Rouhani"", ""Mohammad Samragh"", ""Tara Javidi"", ""Farinaz Koushanfar""]","[""Adversarial Attacks"", ""Unsupervised Defense"", ""Deep Learning""]",Devising unsupervised defense mechanisms against adversarial attacks is crucial to ensure the generalizability of the defense. ,,,,
HyIFzx-0b,2018,Reject,False,BinaryFlex: On-the-Fly Kernel Generation in Binary Convolutional Networks,"[""Vincent W.-S. Tseng"", ""Sourav Bhattachary"", ""Javier Fern\u00e1ndez Marqu\u00e9s"", ""Milad Alizadeh"", ""Catherine Tong"", ""Nicholas Donald Lane""]",[],,,,,
HyKZyYlRZ,2018,Reject,False,Large Scale Multi-Domain Multi-Task Learning with MultiModel,"[""Lukasz Kaiser"", ""Aidan N. Gomez"", ""Noam Shazeer"", ""Ashish Vaswani"", ""Niki Parmar"", ""Llion Jones"", ""Jakob Uszkoreit""]","[""multi-task learning"", ""transfer learning""]",Large scale multi-task architecture solves ImageNet and translation together and shows transfer learning.,,,,
HyM25Mqel,2017,Accept (Poster),False,Sample Efficient Actor-Critic with  Experience Replay,"[""Ziyu Wang"", ""Victor Bapst"", ""Nicolas Heess"", ""Volodymyr Mnih"", ""Remi Munos"", ""Koray Kavukcuoglu"", ""Nando de Freitas""]","[""Deep learning"", ""Reinforcement Learning""]",Prepared for ICLR 2017.,,,,
HyM7AiA5YX,2019,Accept (Poster),False,Complement Objective Training,"[""Hao-Yun Chen"", ""Pei-Hsin Wang"", ""Chun-Hao Liu"", ""Shih-Chieh Chang"", ""Jia-Yu Pan"", ""Yu-Ting Chen"", ""Wei Wei"", ""Da-Cheng Juan""]","[""optimization"", ""entropy"", ""image recognition"", ""natural language understanding"", ""adversarial attacks"", ""deep learning""]","We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.",,,,
HyM8V2A9Km,2019,Reject,False,ACTRCE: Augmenting Experience via Teacherâs Advice,"[""Yuhuai Wu"", ""Harris Chan"", ""Jamie Kiros"", ""Sanja Fidler"", ""Jimmy Ba""]","[""language goals"", ""task generalization"", ""hindsight experience replays"", ""language grounding""]",Combine language goal representation with hindsight experience replays.,,,,
HyMRUiC9YX,2019,Reject,False,Exploring and Enhancing the Transferability of Adversarial Examples,"[""Lei Wu"", ""Zhanxing Zhu"", ""Cheng Tai""]","[""Deep learning"", ""Adversarial example"", ""Transferability"", ""Smoothed gradient""]",,,,,
HyMRaoAqKX,2019,Reject,True,Implicit Autoencoders,"[""Alireza Makhzani""]","[""Unsupervised Learning"", ""Generative Models"", ""Variational Inference"", ""Generative Adversarial Networks.""]","We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.",1805.09804,cs.LG,2018-05-24 17:46:43+00:00,2019-02-07 03:40:18+00:00
HyMS8iRcK7,2019,Reject,False,SEQUENCE MODELLING WITH AUTO-ADDRESSING AND RECURRENT MEMORY INTEGRATING NETWORKS,"[""Zhangheng Li"", ""Jia-Xing Zhong"", ""Jingjia Huang"", ""Tao Zhang"", ""Thomas Li"", ""Ge Li""]","[""Memory Network"", ""RNN"", ""Sequence Modelling""]",We propose a light-weight Memory-Augmented RNN (MARNN) for sequence modelling.,,,,
HyMTkQZAb,2018,Accept (Poster),False,Kronecker-factored Curvature Approximations for Recurrent Neural Networks,"[""James Martens"", ""Jimmy Ba"", ""Matt Johnson""]","[""optimization"", ""K-FAC"", ""natural gradient"", ""recurrent neural networks""]",We extend the K-FAC method to RNNs by developing a new family of Fisher approximations.,,,,
HyMnYiR9Y7,2019,Reject,False,DOMAIN ADAPTATION VIA DISTRIBUTION AND REPRESENTATION MATCHING: A CASE STUDY ON TRAINING DATA SELECTION VIA REINFORCEMENT LEARNING,"[""Miaofeng Liu"", ""Yan Song"", ""Hongbin Zou"", ""Tong Zhang""]","[""domain adaptation"", ""training data selection"", ""reinforcement learning"", ""natural language processing""]",Training data selection via reinforcement learning,,,,
HyMuaiAqY7,2019,Reject,False,Deli-Fisher GAN: Stable and Efficient Image Generation With Structured Latent Generative Space,"[""Boli Fang"", ""Chuck Jia"", ""Miao Jiang"", ""Dhawal Chaturvedi""]","[""Generative Adversarial Networks"", ""Structured Latent Space"", ""Stable Training""]","This paper proposes a new Generative Adversarial Network that is more stable, more efficient, and produces better images than those of status-quo ",,,,
HyMxAi05Km,2019,Reject,False,Dual Learning: Theoretical Study and Algorithmic Extensions,"[""Zhibing Zhao"", ""Yingce Xia"", ""Tao Qin"", ""Tie-Yan Liu""]","[""machine translation"", ""dual learning""]",,,,,
HyN-M2Rctm,2019,Accept (Poster),False,Mode Normalization,"[""Lucas Deecke"", ""Iain Murray"", ""Hakan Bilen""]","[""Deep Learning"", ""Expert Models"", ""Normalization"", ""Computer Vision""]",We present a novel normalization method for deep neural networks that is robust to multi-modalities in intermediate feature distributions.,,,,
HyNA5iRcFQ,2019,Accept (Poster),False,Detecting Egregious Responses in Neural Sequence-to-sequence Models,"[""Tianxing He"", ""James Glass""]","[""Deep Learning"", ""Natural Language Processing"", ""Adversarial Attacks"", ""Dialogue Response Generation""]",This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.,,,,
HyNbtiR9YX,2019,Reject,False,Unsupervised Document Representation using Partition Word-Vectors Averaging,"[""Vivek Gupta"", ""Ankit Kumar Saw"", ""Partha Pratim Talukdar"", ""Praneeth Netrapalli""]","[""Unsupervised Learning"", ""Natural Language Processing"", ""Representation Learning"", ""Document Embedding""]",A simple unsupervised method for multi-sentence-document embedding using partition based word vectors averaging that achieve results comparable to sophisticated models.,,,,
HyNmRiCqtm,2019,Reject,False,CDeepEx: Contrastive Deep Explanations,"[""Amir Feghahati"", ""Christian R. Shelton"", ""Michael J. Pazzani"", ""Kevin Tang""]","[""Deep learning"", ""Explanation"", ""Network interpretation"", ""Contrastive explanation""]","A method to answer ""why not class B?"" for explaining deep networks",,,,
HyNxRZ9xg,2017,Reject,False,Cat2Vec: Learning Distributed Representation of Multi-field Categorical Data,"[""Ying Wen"", ""Jun Wang"", ""Tianyao Chen"", ""Weinan Zhang""]","[""Unsupervised Learning"", ""Deep learning"", ""Applications""]",an unsupervised pairwise interaction model to learning the distributed representation of multi-field categorical data,,,,
HyPpD0g0Z,2018,Reject,False,Grouping-By-ID: Guarding Against Adversarial Domain Shifts,"[""Christina Heinze-Deml"", ""Nicolai Meinshausen""]","[""supervised representation learning"", ""causality"", ""interpretability"", ""transfer learning""]","We propose counterfactual regularization to guard against adversarial domain shifts arising through shifts in the distribution of latent ""style features"" of images.",,,,
HyQJ-mclg,2017,Accept (Poster),False,Incremental Network Quantization: Towards Lossless CNNs with Low-precision Weights,"[""Aojun Zhou"", ""Anbang Yao"", ""Yiwen Guo"", ""Lin Xu"", ""Yurong Chen""]","[""Deep learning"", ""Optimization""]","This paper presents INQ, targeting to efficiently transform any pre-trained full-precision convolutional neural network (CNN) model into a low-precision version whose connection weights are constrained to be either powers of two or zero.",,,,
HyQWFOVge,2017,Reject,False,Significance of Softmax-Based Features over Metric Learning-Based Features,"[""Shota Horiguchi"", ""Daiki Ikami"", ""Kiyoharu Aizawa""]","[""Computer vision"", ""Deep learning""]",We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.,,,,
HyRVBzap-,2018,Accept (Poster),False,Cascade Adversarial Machine Learning Regularized with a Unified Embedding,"[""Taesik Na"", ""Jong Hwan Ko"", ""Saibal Mukhopadhyay""]","[""adversarial machine learning"", ""embedding"", ""regularization"", ""adversarial attack""]",Cascade adversarial training + low level similarity learning improve robustness against both white box and black box attacks.,,,,
HyRnez-RW,2018,Accept (Poster),False,Multi-Mention Learning for Reading Comprehension with Neural Cascades,"[""Swabha Swayamdipta"", ""Ankur P. Parikh"", ""Tom Kwiatkowski""]","[""reading comprehension"", ""multi-loss"", ""question answering"", ""scalable"", ""TriviaQA"", ""feed-forward"", ""latent variable"", ""attention""]","We propose neural cascades, a simple and trivially parallelizable approach to reading comprehension, consisting only of feed-forward nets and attention that achieves state-of-the-art performance on the TriviaQA dataset.",,,,
HyTqHL5xg,2017,Accept (Poster),False,Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data,"[""Maximilian Karl"", ""Maximilian Soelch"", ""Justin Bayer"", ""Patrick van der Smagt""]","[""Deep learning"", ""Unsupervised Learning""]",,,,,
HyTrSegCb,2018,Reject,False,Achieving morphological agreement with Concorde,"[""Daniil Polykovskiy"", ""Dmitry Soloviev""]","[""NLP"", ""morphology"", ""seq2seq""]",Proposed architecture to solve morphological agreement task,,,,
HyUNwulC-,2018,Accept (Poster),False,Parallelizing Linear Recurrent Neural Nets Over Sequence Length,"[""Eric Martin"", ""Chris Cundy""]","[""rnn"", ""sequence"", ""parallel"", ""qrnn"", ""sru"", ""gilr"", ""gilr-lstm""]",use parallel scan to parallelize linear recurrent neural nets. train model on length 1 million dependency,,,,
HyVbhi0cYX,2019,Reject,False,Complexity of Training ReLU Neural Networks,"[""Digvijay Boob"", ""Santanu S. Dey"", ""Guanghui Lan""]","[""NP-hardness"", ""ReLU activation"", ""Two hidden layer networks""]",,,,,
HyVxPsC9tm,2019,Reject,False,DynCNN: An Effective Dynamic Architecture on Convolutional Neural Network for Surveillance Videos,"[""De-Qin Gao"", ""Ping-Chen Tsai"", ""Shanq-Jang Ruan""]","[""CNN optimization"", ""Reduction on convolution calculation"", ""dynamic convolution"", ""surveillance video""]",An optimizing architecture on CNN for surveillance videos with 75.7% reduction on FLOPs and 2.2 times improvement on FPS,,,,
HyWDCXjgx,2017,Reject,False,Multi-label learning with the RNNs for Fashion Search,"[""Taewan Kim""]","[""Computer vision"", ""Deep learning"", ""Supervised Learning"", ""Applications""]",Works for applying LSTM into the multi-label learning in an application to computer vision,,,,
HyWG0H5ge,2017,Invite to Workshop Track,False,Neural Taylor Approximations: Convergence and Exploration in Rectifier Networks,"[""David Balduzzi"", ""Brian McWilliams"", ""Tony Butler-Yeoman""]","[""Deep learning"", ""Optimization"", ""Theory"", ""Supervised Learning""]",We provide the first convergence result for rectifier neural networks and investigate implications for exploration in shattered landscapes.,,,,
HyWWpw5ex,2017,Reject,False,Recurrent Coevolutionary Feature Embedding Processes for Recommendation,"[""Hanjun Dai*"", ""Yichen Wang*"", ""Rakshit Trivedi"", ""Le Song""]","[""Deep learning"", ""Applications""]","Our work combines recurrent neural network with point process models for recommendation, which captures the co-evolution nature of users' and items' latent features.",,,,
HyWrIgW0W,2018,Accept (Poster),True,"Stochastic gradient descent performs variational inference, converges to limit cycles for deep networks","[""Pratik Chaudhari"", ""Stefano Soatto""]","[""sgd"", ""variational inference"", ""gradient noise"", ""out-of-equilibrium""]","SGD implicitly performs variational inference; gradient noise is highly non-isotropic, so SGD does not even converge to critical points of the original loss",1710.11029,cs.LG,2017-10-30 15:58:18+00:00,2018-01-16 08:04:21+00:00
HyXBcYg0b,2018,Reject,False,Residual Gated Graph ConvNets,"[""Xavier Bresson"", ""Thomas Laurent""]","[""graph neural networks"", ""ConvNets"", ""RNNs"", ""pattern matching"", ""semi-supervised clustering""]","We compare graph RNNs and graph ConvNets, and we consider the most generic class of graph ConvNets with residuality.",,,,
HyXNCZbCZ,2018,Reject,False,Hierarchical Adversarially Learned Inference,"[""Mohamed Ishmael Belghazi"", ""Sai Rajeswar"", ""Olivier Mastropietro"", ""Negar Rostamzadeh"", ""Jovana Mitrovic"", ""Aaron Courville""]","[""generative"", ""hierarchical"", ""unsupervised"", ""semisupervised"", ""latent"", ""ALI"", ""GAN""]",Adversarially trained hierarchical generative model with robust and semantically learned latent representation.,,,,
HyY0Ff-AZ,2018,Reject,False,Representing Entropy : A short proof of the equivalence between soft Q-learning and policy gradients,"[""Pierre H. Richemond"", ""Brendan Maginnis""]","[""soft Q-learning"", ""policy gradients"", ""entropy"", ""Legendre transformation"", ""duality"", ""convex analysis"", ""Donsker-Varadhan""]",A short proof of the equivalence of soft Q-learning and policy gradients.,,,,
HyY4Owjll,2017,Reject,False,Boosted Generative Models,"[""Aditya Grover"", ""Stefano Ermon""]","[""Theory"", ""Deep learning"", ""Unsupervised Learning""]",,,,,
HyZoi-WRb,2018,Accept (Poster),False,Debiasing Evidence Approximations: On Importance-weighted Autoencoders and Jackknife Variational Inference,"[""Sebastian Nowozin""]","[""variational inference"", ""approximate inference"", ""generative models""]","Variational inference is biased, let's debias it.",,,,
Hy_o3x-0b,2018,Reject,False,Feature Map Variational Auto-Encoders,"[""Lars Maal\u00f8e"", ""Ole Winther""]","[""deep learning"", ""representation learning"", ""variational auto-encoders"", ""variational inference"", ""generative models""]",We present a generative model that proves state-of-the-art results on gray-scale and natural images.,,,,
Hyanrrqlg,2017,Reject,False,HFH: Homologically Functional Hashing for Compressing Deep Neural Networks,"[""Lei Shi"", ""Shikun Feng"", ""Zhifan Zhu""]",[],,,,,
HycUbvcge,2017,Reject,False,Deep Generalized Canonical Correlation Analysis,"[""Adrian Benton"", ""Huda Khayrallah"", ""Biman Gujral"", ""Drew Reisinger"", ""Sheng Zhang"", ""Raman Arora""]","[""Unsupervised Learning"", ""Deep learning"", ""Multi-modal learning""]",A multiview representation learning technique that can learn nonlinear mappings from arbitrarily many views to a shared semantic space -- Deep Generalized Canonical Correlation Analysis.,,,,
HydnA1WCb,2018,Reject,False,Gaussian Prototypical Networks for Few-Shot Learning on Omniglot,"[""Stanislav Fort""]","[""one-shot learning"", ""few-shot learning"", ""Omniglot""]",A novel architecture for few-shot classification capable of dealing with uncertainty.,,,,
Hye-LiR5Y7,2019,Reject,False,SOSELETO: A Unified Approach to Transfer Learning and Training with Noisy Labels,"[""Or Litany"", ""Daniel Freedman""]","[""transfer learning""]","Learning with limited training data by exploiting ""helpful"" instances from a rich data source.  ",,,,
Hye-p0VFPB,2020,Reject,False,Efficient Systolic Array Based on Decomposable MAC for Quantized Deep Neural Networks,"[""Ning-Chi Huang"", ""Huan-Jan Chou"", ""Kai-Chiang Wu""]",[],,,,,
Hye00pVtPS,2020,Reject,False,CONFEDERATED MACHINE LEARNING ON HORIZONTALLY AND VERTICALLY SEPARATED MEDICAL DATA FOR LARGE-SCALE HEALTH SYSTEM INTELLIGENCE,"[""Dianbo Liu"", ""Tim Miller"", ""Kenneth Mandl""]","[""Confederated learning"", ""siloed medical data"", ""representation joining""]",a confederated learning method that train model from horizontally and vertically separated medical data ,,,,
Hye190VKvH,2020,Reject,False,Longitudinal Enrichment of Imaging Biomarker Representations for Improved Alzheimer's Disease Diagnosis,"[""Saad Elbeleidy"", ""Lyujian Lu"", ""L. Zoe Baker"", ""Hua Wang"", ""Feiping Nie""]",[],,,,,
Hye1RJHKwB,2020,Accept (Poster),True,Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators,"[""Daniel Stoller"", ""Sebastian Ewert"", ""Simon Dixon""]","[""Adversarial Learning"", ""Semi-supervised Learning"", ""Image generation"", ""Image segmentation"", ""Missing Data""]","We decompose the discriminator in a GAN in a principled way so that each component can be independently trained on different parts of the input. The resulting ""FactorGAN"" can be used for semi-supervised learning and in missing data scenarios.",1905.12660,cs.LG,2019-05-29 18:10:08+00:00,2020-01-30 15:35:37+00:00
Hye1kTVFDS,2020,Accept (Poster),False,The Variational Bandwidth Bottleneck: Stochastic Evaluation on an Information Budget,"[""Anirudh Goyal"", ""Yoshua Bengio"", ""Matthew Botvinick"", ""Sergey Levine""]","[""Variational Information Bottleneck"", ""Reinforcement learning""]",Training agents with adaptive computation based on information bottleneck can promote generalization. ,2004.11935,stat.ML,2020-04-24 18:29:31+00:00,2020-04-24 18:29:31+00:00
Hye4KeSYDr,2020,Reject,False,Evaluations and Methods for Explanation through Robustness Analysis,"[""Cheng-Yu Hsieh"", ""Chih-Kuan Yeh"", ""Xuanqing Liu"", ""Pradeep Ravikumar"", ""Seungyeon Kim"", ""Sanjiv Kumar"", ""Cho-Jui Hsieh""]","[""Interpretability"", ""Explanations"", ""Adversarial Robustness""]",We propose new objective measurement for evaluating explanations based on the notion of adversarial robustness. The evaluation criteria further allows us to derive new explanations which capture pertinent features qualitatively and quantitatively.,2006.00442,cs.LG,2020-05-31 05:52:05+00:00,2021-04-08 21:18:01+00:00
Hye4WaVYwr,2020,Reject,True,Bootstrapping the Expressivity with Model-based Planning,"[""Kefan Dong"", ""Yuping Luo"", ""Tengyu Ma""]","[""reinforcement learning theory"", ""model-based reinforcement learning"", ""planning"", ""expressivity"", ""approximation theory"", ""deep reinforcement learning theory""]","We compare deep model-based and model-free RL algorithms by studying the approximability of $Q$-functions, policies, and dynamics by neural networks. ",1910.05927,cs.LG,2019-10-14 06:17:49+00:00,2020-09-06 12:15:54+00:00
Hye5TaVtDH,2020,Reject,False,Matrix Multilayer Perceptron,"[""Jalil Taghia"", ""Maria B\u00e5nkestad"", ""Fredrik Lindsten"", ""Thomas Sch\u00f6n""]","[""Multilayer Perceptron"", ""symmetric positive definite"", ""heteroscedastic regression"", ""covariance estimation""]",,,,,
Hye64hA9tm,2019,Reject,False,Measuring Density and Similarity of Task Relevant Information in Neural Representations,"[""Danish Pruthi"", ""Mansi Gupta"", ""Nitish Kumar Kulkarni"", ""Graham Neubig"", ""Eduard Hovy""]","[""Neural Networks"", ""Representation"", ""Information density"", ""Transfer Learning""]",Measuring information density and cross-task similarity in neural models and its application in transfer learning.,,,,
Hye6uoC9tm,2019,Reject,False,Incremental Hierarchical Reinforcement Learning with Multitask LMDPs,"[""Adam C Earle"", ""Andrew M Saxe"", ""Benjamin Rosman""]","[""Reinforcement learning"", ""hierarchy"", ""linear markov decision process"", ""lmdl"", ""subtask discovery"", ""incremental""]","We develop an agent capable of incrementally growing a hierarchical representation, and using its experience to date to improve exploration.",,,,
Hye87grYDH,2020,Reject,False,Sparse Transformer: Concentrated Attention Through Explicit Selection,"[""Guangxiang Zhao"", ""Junyang Lin"", ""Zhiyuan Zhang"", ""Xuancheng Ren"", ""Xu Sun""]","[""Attention"", ""Transformer"", ""Machine Translation"", ""Natural Language Processing"", ""Sparse"", ""Sequence to sequence learning""]",This work propose Sparse Transformer to improve the concentration of attention on the global context through an explicit selection of the most relevant segments for sequence to sequence learning. ,,,,
Hye9lnCct7,2019,Accept (Poster),False,Learning Actionable Representations with Goal Conditioned Policies,"[""Dibya Ghosh"", ""Abhishek Gupta"", ""Sergey Levine""]","[""Representation Learning"", ""Reinforcement Learning""]",Learning state representations which capture factors necessary for control,1811.07819,cs.LG,2018-11-19 17:30:36+00:00,2019-01-29 06:44:13+00:00
HyeAPeBFwS,2020,Reject,False,Quantifying uncertainty with GAN-based priors,"[""Dhruv V. Patel"", ""Assad A. Oberai""]","[""Bayesian inference"", ""Uncertainty quantification"", ""Generative adversarial networks""]",Quantifying uncertainty in inference via GAN priors,,,,
HyeCnkHtwH,2020,Reject,False,Efficient generation of structured objects with Constrained Adversarial Networks,"[""Jacopo Gobbi"", ""Luca Di Liello"", ""Pierfrancesco Ardino"", ""Paolo Morettin"", ""Stefano Teso"", ""Andrea Passerini""]","[""deep generative models"", ""generative adversarial networks"", ""constraints""]",We extend GANs towards the generation of structured objects like molecules and video game levels,,,,
HyeEIyBtvr,2020,Reject,False,BETANAS: Balanced Training and selective drop for Neural Architecture Search,"[""Muyuan Fang"", ""Qiang Wang"", ""Jian Zhang"", ""Zhao Zhong""]","[""neural architecture search"", ""weight sharing"", ""auto machine learning"", ""deep learning"", ""CNN""]",A novel method to search for neural architectures via weight sharing.,,,,
HyeFAsRctQ,2019,Accept (Poster),False,Verification of Non-Linear Specifications for Neural Networks,"[""Chongli Qin"", ""Krishnamurthy (Dj) Dvijotham"", ""Brendan O'Donoghue"", ""Rudy Bunel"", ""Robert Stanforth"", ""Sven Gowal"", ""Jonathan Uesato"", ""Grzegorz Swirszcz"", ""Pushmeet Kohli""]","[""Verification"", ""Convex Optimization"", ""Adversarial Robustness""]",,,,,
HyeG9lHYwH,2020,Reject,False,Compression without Quantization,"[""Gergely Flamich"", ""Marton Havasi"", ""Jos\u00e9 Miguel Hern\u00e1ndez-Lobato""]","[""Image Compression"", ""Bits-back efficient"", ""Quantization""]","We introduce a principled, end-to-end differentiable, bits-back efficient transform coding framework and apply it to image compression.",,,,
HyeG9yHKPr,2020,Reject,False,Causally Correct Partial Models for Reinforcement Learning,"[""Danilo J. Rezende"", ""Ivo Danihelka"", ""George Papamakarios"", ""Nan Rosemary Ke"", ""Ray Jiang"", ""Theophane Weber"", ""Karol Gregor"", ""Hamza Merzic"", ""Fabio Viola"", ""Jane Wang"", ""Jovana Mitrovic"", ""Frederic Besse"", ""Ioannis Antonoglou"", ""Lars Buesing"", ""Julian Schrittwieser"", ""Thomas Hubert"", ""David Silver""]","[""causality"", ""model-based reinforcement learning""]",Causally correct partial models do not have to generate the whole observation to remain causally correct in stochastic environments.,,,,
HyeGBj09Fm,2019,Accept (Poster),False,Generating Liquid Simulations with Deformation-aware Neural Networks,"[""Lukas Prantl"", ""Boris Bonev"", ""Nils Thuerey""]","[""deformation learning"", ""spatial transformer networks"", ""fluid simulation""]",Learning weighting and deformations of space-time data sets for highly efficient approximations of liquid behavior.,,,,
HyeJf1HKvS,2020,Accept (Poster),False,Deep Graph Matching Consensus,"[""Matthias Fey"", ""Jan E. Lenssen"", ""Christopher Morris"", ""Jonathan Masci"", ""Nils M. Kriege""]","[""graph matching"", ""graph neural networks"", ""neighborhood consensus"", ""deep learning""]",We develop a deep graph matching architecture which refines initial correspondences in order to reach neighborhood consensus.,2001.09621,cs.LG,2020-01-27 08:05:57+00:00,2020-01-27 08:05:57+00:00
HyeJmlrFvH,2020,Reject,True,Provably Communication-efficient Data-parallel SGD via Nonuniform Quantization,"[""Ali Ramezani-Kebrya"", ""Fartash Faghri"", ""Ilya Markov"", ""Vitalii Aksenov"", ""Dan Alistarh"", ""Daniel M. Roy""]",[],NUQSGD closes the gap between the theoretical guarantees of QSGD and the empirical performance of QSGDinf.,1908.06077,cs.LG,2019-08-16 17:59:01+00:00,2021-05-03 21:39:42+00:00
HyeKcgHFvS,2020,Reject,False,Gradient-based training of Gaussian Mixture Models in High-Dimensional Spaces,"[""Alexander Gepperth"", ""Benedikt Pf\u00fclb""]","[""GMM"", ""SGD""]","We present a stochastic gradient descent algorithm for training GMMs in high-dimensional spaces, which performs similarly to the traditional EM procedure but which is much more memory-efficient.",,,,
HyePberFvH,2020,Reject,False,Monte Carlo Deep Neural Network Arithmetic,"[""Julian Faraone"", ""Philip Leong""]","[""deep learning"", ""quantization"", ""floating point"", ""monte carlo methods""]",Determining the sensitivity of Deep Neural Networks to floating point rounding error using Monte Carlo Methods,,,,
HyePrhR5KX,2019,Accept (Poster),False,DyRep: Learning Representations over Dynamic Graphs,"[""Rakshit Trivedi"", ""Mehrdad Farajtabar"", ""Prasenjeet Biswal"", ""Hongyuan Zha""]","[""Dynamic Graphs"", ""Representation Learning"", ""Dynamic Processes"", ""Temporal Point Process"", ""Attention"", ""Latent Representation""]",Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.,,,,
HyeS73ActX,2019,Reject,False,Multi-Objective Value Iteration with Parameterized Threshold-Based Safety Constraints,"[""Hussein Sibai"", ""Sayan Mitra""]","[""reinforcement learning"", ""Markov decision processes"", ""safety constraints"", ""multi-objective optimization"", ""geometric analysis""]",,,,,
HyeSin4FPB,2020,Accept (Spotlight),False,Learning to Control PDEs with Differentiable Physics,"[""Philipp Holl"", ""Nils Thuerey"", ""Vladlen Koltun""]","[""Differentiable physics"", ""Optimal control"", ""Deep learning""]",We train a combination of neural networks to predict optimal trajectories for complex physical systems.,,,,
HyeU1hRcFX,2019,Reject,False,Unsupervised Conditional Generation using noise engineered mode matching GAN,"[""Deepak Mishra"", ""Prathosh AP"", ""Aravind J"", ""Prashant Pandey"", ""Santanu Chaudhury""]","[""Noise engineered GAN"", ""Latent space engineering"", ""Mode matching"", ""Unsupervised learning""]",A GAN model where an inversion mapping from the generated data space to an engineered latent space is learned such that properties of the data generating distribution are matched to those of the latent distribution.,,,,
HyeVtoRqtQ,2019,Accept (Poster),False,Trellis Networks for Sequence Modeling,"[""Shaojie Bai"", ""J. Zico Kolter"", ""Vladlen Koltun""]","[""sequence modeling"", ""language modeling"", ""recurrent networks"", ""convolutional networks"", ""trellis networks""]",Trellis networks are a new sequence modeling architecture that bridges recurrent and convolutional models and sets a new state of the art on word- and character-level language modeling.,,,,
HyeX7aVKvr,2020,Reject,False,Zero-shot task adaptation by homoiconic meta-mapping,"[""Andrew K. Lampinen"", ""James L. McClelland""]","[""Meta-mapping"", ""zero-shot"", ""task adaptation"", ""task representation"", ""meta-learning""]",We propose an approach to performing novel tasks zero-shot based on adapting task representations,,,,
HyeYJ1SKDH,2020,Reject,True,FLUID FLOW MASS TRANSPORT FOR GENERATIVE NETWORKS,"[""Jingrong Lin"", ""Keegan Lensink"", ""Eldad Haber""]","[""generative network"", ""optimal mass transport"", ""gaussian mixture"", ""model matching""]",,1910.01694,cs.LG,2019-10-03 19:14:52+00:00,2019-10-07 20:04:45+00:00
HyeYTgrFPB,2020,Accept (Poster),False,Massively Multilingual Sparse Word Representations,"[""G\u00e1bor Berend""]","[""sparse word representations"", ""multilinguality"", ""sparse coding""]",We propose an efficient algorithm for determining multilingually comparable sparse word representations that we release for 27 typologically diverse languages.,,,,
Hye_V0NKwr,2020,Accept (Poster),False,Locality and Compositionality in Zero-Shot Learning,"[""Tristan Sylvain"", ""Linda Petrini"", ""Devon Hjelm""]","[""Zero-shot learning"", ""Compositionality"", ""Locality"", ""Deep Learning""]",An analysis of the effects of compositionality and locality on representation learning for zero-shot learning.,1912.12179,cs.CV,2019-12-20 15:50:57+00:00,2019-12-20 15:50:57+00:00
HyeaSkrYPH,2020,Accept (Poster),False,Certified Defenses for Adversarial Patches,"[""Ping-yeh Chiang*"", ""Renkun Ni*"", ""Ahmed Abdelkader"", ""Chen Zhu"", ""Christoph Studor"", ""Tom Goldstein""]","[""certified defenses"", ""patch attack"", ""adversarial robustness"", ""sparse defense""]",,,,,
HyebplHYwB,2020,Accept (Poster),False,The Shape of Data: Intrinsic Distance for Data Distributions,"[""Anton Tsitsulin"", ""Marina Munkhoeva"", ""Davide Mottin"", ""Panagiotis Karras"", ""Alex Bronstein"", ""Ivan Oseledets"", ""Emmanuel Mueller""]","[""Deep Learning"", ""Generative Models"", ""Nonlinear Dimensionality Reduction"", ""Manifold Learning"", ""Similarity and Distance Learning"", ""Spectral Methods""]",We propose a metric for comparing data distributions based on their geometry while not relying on any positional information.,,,,
HyecJGP5ge,2017,Reject,False,NEUROGENESIS-INSPIRED DICTIONARY LEARNING: ONLINE MODEL ADAPTION IN A CHANGING WORLD,"[""Sahil Garg"", ""Irina Rish"", ""Guillermo Cecchi"", ""Aurelie Lozano""]","[""Unsupervised Learning"", ""Computer vision"", ""Transfer Learning"", ""Optimization"", ""Applications""]","An online dictionary learning incorporates dynamic model adaptation, adding/deleting its elements in response to nonstationary data.",,,,
Hyed4i05KX,2019,Reject,True,Interpreting Layered Neural Networks via Hierarchical Modular Representation,"[""Chihiro Watanabe""]","[""interpretabile machine learning"", ""neural network"", ""hierarchical clustering""]",A method for obtaining a hierarchical cluster structure of a trained layered neural network,1810.01588,stat.ML,2018-10-03 05:38:26+00:00,2018-10-03 05:38:26+00:00
HyefgnCqFm,2019,Reject,False,Learning Partially Observed PDE Dynamics with Neural Networks,"[""Ibrahim Ayed"", ""Emmanuel De B\u00e9zenac"", ""Arthur Pajot"", ""Patrick Gallinari""]","[""deep learning"", ""spatio-temporal dynamics"", ""physical processes"", ""differential equations"", ""dynamical systems""]",,,,,
HyenUkrtDB,2020,Reject,False,Detecting Noisy Training Data with Loss Curves,"[""Geoff Pleiss"", ""Tianyi Zhang"", ""Ethan R. Elenberg"", ""Kilian Q. Weinberger""]","[""Deep learning"", ""noisy data"", ""robust training""]",We introduce a new metric - Area Under the Loss Curve (AUL) - which uses the training dynamics to identify noisy training samples.,,,,
HyenWc5gx,2017,Reject,False,Representation Stability as a Regularizer for Improved Text Analytics Transfer Learning,"[""Matthew Riemer"", ""Elham Khabiri"", ""Richard Goodwin""]","[""Deep learning"", ""Transfer Learning"", ""Natural language processing""]",We propose a novel general purpose regularizer to address catastrophic forgetting in neural network sequential transfer learning.,,,,
Hyepjh4FwB,2020,Reject,True,ProtoAttend: Attention-Based Prototypical Learning,"[""Sercan O. Arik"", ""Tomas Pfister""]","[""Interpretability"", ""sample-based explanations"", ""prototypes"", ""confidence estimation""]",We propose a new learning framework that bases decision-making on few relevant examples that we call prototypes.,1902.06292,cs.LG,2019-02-17 17:12:07+00:00,2019-09-26 01:39:46+00:00
HyeqPJHYvH,2020,Reject,False,Stochastic Latent Residual Video Prediction,"[""Jean-Yves Franceschi"", ""Edouard Delasalles"", ""Mickael Chen"", ""Sylvain Lamprier"", ""Patrick Gallinari""]","[""stochastic video prediction"", ""variational autoencoder"", ""residual dynamics""]",,,,,
HyerxgHYvH,2020,Reject,False,Neural Arithmetic Unit by reusing many small pre-trained networks,"[""Ammar Ahmad"", ""Oneeb Babar"", ""Murtaza Taj""]","[""NALU"", ""feed forward NN""]","We train many small networks each for a specific operation, these are then combined to perform complex operations",,,,
Hyes70EYDB,2020,Reject,False,Visual Interpretability Alone Helps Adversarial Robustness,"[""Akhilan Boopathy"", ""Sijia Liu"", ""Gaoyuan Zhang"", ""Pin-Yu Chen"", ""Shiyu Chang"", ""Luca Daniel""]","[""adversarial robustness"", ""visual explanation"", ""CNN"", ""image classification""]",Exploring the connection between robustness in interpretability and robustness in classification,,,,
HyesW2C9YQ,2019,Reject,False,I Know the Feeling: Learning to Converse with Empathy,"[""Hannah Rashkin"", ""Eric Michael Smith"", ""Margaret Li"", ""Y-Lan Boureau""]","[""dialogue generation"", ""nlp applications"", ""grounded text  generation"", ""contextual representation learning""]","We improve existing dialogue systems for responding to people sharing personal stories, incorporating emotion prediction representations and also release a new benchmark and dataset of empathetic dialogues.",,,,
HyetFnEFDS,2020,Reject,False,Diving into Optimization of Topology in Neural Networks,"[""Kun Yuan"", ""Quanquan Li"", ""Yucong Zhou"", ""Jing Shao"", ""Junjie Yan""]",[],,,,,
HyeuP2EtDB,2020,Reject,False,Scoring-Aggregating-Planning: Learning task-agnostic priors from interactions and sparse rewards for zero-shot generalization,"[""Huazhe Xu"", ""Boyuan Chen"", ""Yang Gao"", ""Trevor Darrell""]","[""learning priors from exploration data"", ""policy zero-shot generalization"", ""reward shaping"", ""model-based""]",We learn dense scores and dynamics model as priors from exploration data and use them to induce a good policy in new tasks in zero-shot condition.,,,,
HyevIJStwH,2020,Accept (Spotlight),False,Understanding Why Neural Networks Generalize Well Through GSNR of Parameters,"[""Jinlong Liu"", ""Yunzhi Bai"", ""Guoqing Jiang"", ""Ting Chen"", ""Huayan Wang""]","[""DNN"", ""generalization"", ""GSNR"", ""gradient descent""]",,,,,
HyevnsCqtQ,2019,Reject,False,Integral Pruning on Activations and Weights for Efficient Neural Networks,"[""Qing Yang"", ""Wei Wen"", ""Zuoguan Wang"", ""Yiran Chen"", ""Hai Li""]","[""activation pruning"", ""weight pruning"", ""computation cost reduction"", ""efficient DNNs""]",This work advances DNN compression beyond the weights to the activations by integrating the activation pruning with the weight pruning. ,,,,
HyewT1BKvr,2020,Reject,False,SpectroBank: A filter-bank convolutional layer for CNN-based audio applications,"[""Helena Peic Tukuljac"", ""Benjamin Ricaud"", ""Nicolas Aspert"", ""Pierre Vandergheynst""]","[""audio"", ""classification"", ""convolutional neural network"", ""deep learning"", ""filter"", ""filter-bank"", ""raw waveform""]",A new convolution layer where the kernels are based on audio signal processing filters with few learnable parameters.,,,,
Hyewf3AqYX,2019,Reject,False,A Frank-Wolfe Framework for Efficient and Effective Adversarial Attacks,"[""Jinghui Chen"", ""Jinfeng Yi"", ""Quanquan Gu""]",[],,,,,
HyexAiA5Fm,2019,Accept (Poster),False,Scalable Unbalanced Optimal Transport using Generative Adversarial Networks,"[""Karren D. Yang"", ""Caroline Uhler""]","[""unbalanced optimal transport"", ""generative adversarial networks"", ""population modeling""]",We propose new methodology for unbalanced optimal transport using generative adversarial networks.,,,,
Hyez1CVYvr,2020,Reject,False,Simultaneous Classification and Out-of-Distribution Detection Using Deep Neural Networks,"[""Aristotelis-Angelos Papadopoulos"", ""Nazim Shaikh"", ""Jiamian Wang"", ""Mohammad Reza Rajati""]","[""Out-of-Distribution Detection"", ""OOD detection"", ""Outlier Exposure"", ""Classification"", ""Open-World Classification"", ""Anomaly Detection"", ""Novelty Detection"", ""Calibration"", ""Neural Networks""]",We propose a novel loss function that achieves state-of-the-art results in out-of-distribution detection with Outlier Exposure both on image and text classiï¬cation tasks.,,,,
HyezBa4tPB,2020,Reject,False,Dirichlet Wrapper to Quantify Classification Uncertainty in Black-Box Systems,"[""Jos\u00e9 Mena Rold\u00e1n"", ""Oriol Pujol Vila"", ""Jordi Vitri\u00e0 Marca""]","[""uncertainty"", ""black-box classifiers"", ""rejection"", ""deep learning"", ""NLP"", ""CV""]",A Dirichlet Deep Learning wrapper to quantify uncertainty in black-box systems applied to a rejection system to improve the quality of predictions,,,,
HyezmlBKwr,2020,Reject,False,Test-Time Training for Out-of-Distribution Generalization,"[""Yu Sun"", ""Xiaolong Wang"", ""Zhuang Liu"", ""John Miller"", ""Alexei A. Efros"", ""Moritz Hardt""]","[""out-of-distribution"", ""distribution shifts""]",Training on a single test input with self-supervision makes the prediction better on this input when it is out-of-distribution.,,,,
HyfHgI6aW,2018,Accept (Poster),False,Memory Augmented Control Networks,"[""Arbaaz Khan"", ""Clark Zhang"", ""Nikolay Atanasov"", ""Konstantinos Karydis"", ""Vijay Kumar"", ""Daniel D. Lee""]","[""planning"", ""memory networks"", ""deep learning"", ""robotics""]",Memory Augmented Network to plan in partially observable environments. ,,,,
Hyffti0ctQ,2019,Reject,False,PRUNING WITH HINTS: AN EFFICIENT FRAMEWORK FOR MODEL ACCELERATION,"[""Wei Gao"", ""Yi Wei"", ""Quanquan Li"", ""Hongwei Qin"", ""Wanli Ouyang"", ""Junjie Yan""]","[""model acceleration"", ""mimic"", ""knowledge distillation"", ""channel pruning""]",This is a work aiming for boosting all the existing pruning and mimic method.,,,,
Hyfg5o0qtm,2019,Reject,False,Temporal Gaussian Mixture Layer for Videos,"[""AJ Piergiovanni"", ""Michael S. Ryoo""]",[],,,,,
Hyfn2jCcKm,2019,Accept (Poster),False,Solving the Rubik's Cube with Approximate Policy Iteration,"[""Stephen McAleer"", ""Forest Agostinelli"", ""Alexander Shmakov"", ""Pierre Baldi""]","[""reinforcement learning"", ""Rubik's Cube"", ""approximate policy iteration"", ""deep learning"", ""deep reinforcement learning""]",We solve the Rubik's Cube with pure reinforcement learning,,,,
HyfyN30qt7,2019,Reject,False,NICE: noise injection and clamping estimation for neural network quantization,"[""Chaim Baskin"", ""Natan Liss"", ""Yoav Chai"", ""Evgenii Zheltonozhskii"", ""Eli Schwartz"", ""Raja Girayes"", ""Avi Mendelson"", ""Alexander M.Bronstein""]","[""Efficient inference"", ""Hardware-efficient model architectures"", ""Quantization""]","Combine noise injection, gradual quantization and activation clamping learning to achieve state-of-the-art 3,4 and 5 bit quantization",,,,
Hyg-JC4FDr,2020,Accept (Poster),False,Imitation Learning via Off-Policy Distribution Matching,"[""Ilya Kostrikov"", ""Ofir Nachum"", ""Jonathan Tompson""]","[""reinforcement learning"", ""deep learning"", ""imitation learning"", ""adversarial learning""]",,1912.05032,cs.LG,2019-12-10 22:31:09+00:00,2019-12-10 22:31:09+00:00
Hyg0vbWC-,2018,Accept (Poster),False,Generating Wikipedia by Summarizing Long Sequences,"[""Peter J. Liu*"", ""Mohammad Saleh*"", ""Etienne Pot"", ""Ben Goodrich"", ""Ryan Sepassi"", ""Lukasz Kaiser"", ""Noam Shazeer""]","[""abstractive summarization"", ""Transformer"", ""long sequences"", ""natural language processing"", ""sequence transduction"", ""Wikipedia"", ""extractive summarization""]",We generate Wikipedia articles abstractively conditioned on source document text.,,,,
Hyg1G2AqtQ,2019,Accept (Poster),False,Variance Reduction for Reinforcement Learning in Input-Driven Environments,"[""Hongzi Mao"", ""Shaileshh Bojja Venkatakrishnan"", ""Malte Schwarzkopf"", ""Mohammad Alizadeh""]","[""reinforcement learning"", ""policy gradient"", ""input-driven environments"", ""variance reduction"", ""baseline""]","For environments dictated partially by external input processes, we derive an input-dependent baseline that provably reduces the variance for policy gradient methods and improves the policy performance in a wide range of RL tasks.",,,,
Hyg1Ls0cKQ,2019,Reject,False,Learning Latent Semantic Representation from Pre-defined Generative Model,"[""Jin-Young Kim"", ""Sung-Bae Cho""]","[""Latent space"", ""Generative adversarial network"", ""variational autoencoder"", ""conditioned generation""]",We propose a generative model that not only produces data with desired features from the pre-defined latent space but also fully understands the features of the data to create characteristics that are not in the dataset.,,,,
Hyg4kkHKwH,2020,Reject,False,V1Net: A computational model of cortical horizontal connections,"[""Vijay Veerabadran"", ""Virginia R. de Sa""]","[""Biologically plausible deep learning"", ""Recurrent Neural Networks"", ""Perceptual grouping"", ""horizontal connections"", ""visual neuroscience"", ""perceptual robustness"", ""Gestalt psychology""]","In this work, we present V1Net -- a novel recurrent neural network modeling cortical horizontal connections that give rise to robust visual representations through perceptual grouping.",,,,
Hyg53gSYPB,2020,Reject,False,Defense against Adversarial Examples by Encoder-Assisted Search in the Latent Coding Space,"[""Wenjing Huang"", ""Shikui Tu"", ""Lei Xu""]","[""Adversarial Defense"", ""Auto-encoder"", ""Adversarial Attack"", ""GAN""]",,,,,
Hyg5TRNtDH,2020,Reject,False,Unsupervised Temperature Scaling: Robust Post-processing Calibration for Domain Shift,"[""Azadeh Sadat Mozafari"", ""Hugo Siqueira Gomes"", ""Christian Gagne""]","[""calibration"", ""domain shift"", ""uncertainty prediction"", ""deep neural networks"", ""temperature scaling""]",A robust post-processing calibration method for domain shift.,1911.11195,cs.LG,2019-11-25 19:59:40+00:00,2019-11-25 19:59:40+00:00
Hyg74h05tX,2019,Reject,False,Flow++: Improving Flow-Based Generative Models  with  Variational Dequantization and Architecture Design  ,"[""Jonathan Ho"", ""Xi Chen"", ""Aravind Srinivas"", ""Yan Duan"", ""Pieter Abbeel""]","[""Deep Generative Models"", ""Normalizing Flows"", ""RealNVP"", ""Density Estimation""]",Improved training of current flow-based generative models (Glow and RealNVP) on density estimation benchmarks,,,,
Hyg96gBKPS,2020,Accept (Poster),False,Monotonic Multihead Attention,"[""Xutai Ma"", ""Juan Miguel Pino"", ""James Cross"", ""Liezl Puzon"", ""Jiatao Gu""]","[""Simultaneous Translation"", ""Transformer"", ""Monotonic Attention""]",Make the transformer streamable with monotonic attention.,,,,
Hyg9anEFPS,2020,Accept (Poster),True,Image-guided Neural Object Rendering,"[""Justus Thies"", ""Michael Zollh\u00f6fer"", ""Christian Theobalt"", ""Marc Stamminger"", ""Matthias Nie\u00dfner""]","[""Neural Rendering"", ""Neural Image Synthesis""]",We propose a learned image-guided rendering technique that combines the benefits of image-based rendering and GAN-based image synthesis while considering view-dependent effects.,1811.10720,cs.CV,2018-11-26 22:24:25+00:00,2020-01-15 15:30:46+00:00
HygBZnRctX,2019,Accept (Oral),False,Transferring Knowledge across Learning Processes,"[""Sebastian Flennerhag"", ""Pablo G. Moreno"", ""Neil D. Lawrence"", ""Andreas Damianou""]","[""meta-learning"", ""transfer learning""]","We propose Leap, a framework that transfers knowledge across learning processes by  minimizing the expected distance the training process travels on a task's loss surface.",,,,
HygDF1rYDB,2020,Reject,False,Explaining Time Series by Counterfactuals,"[""Sana Tonekaboni"", ""Shalmali Joshi"", ""David Duvenaud"", ""Anna Goldenberg""]","[""explainability"", ""counterfactual modeling"", ""time series""]",Explaining Multivariate Time Series Models by finding important observations in time using Counterfactuals,,,,
HygDF6NFPB,2020,Accept (Poster),False,A Fair Comparison of Graph Neural Networks for Graph Classification,"[""Federico Errica"", ""Marco Podda"", ""Davide Bacciu"", ""Alessio Micheli""]","[""graph neural networks"", ""graph classification"", ""reproducibility"", ""graph representation learning""]",We provide a rigorous comparison of different Graph Neural Networks for graph classification.,1912.09893,cs.LG,2019-12-20 15:40:50+00:00,2020-01-07 13:49:46+00:00
HygFxxrFvB,2020,Reject,False,Differentially Private Mixed-Type Data Generation For Unsupervised Learning,"[""Uthaipon Tantipongpipat"", ""Chris Waites"", ""Digvijay Boob"", ""Amaresh Siva"", ""Rachel Cummings""]","[""Differential privacy"", ""synthetic data"", ""private data generation"", ""mixed-type"", ""unsupervised learning"", ""autoencoder"", ""GAN"", ""private deep learning""]","We propose private synthetic data generation algorithm that first combines autoencoder and GAN, and develop new evaluation metrics for synthetic data generation task.",,,,
HygHbTVYPB,2020,Reject,False,LDMGAN: Reducing Mode Collapse in GANs with Latent Distribution Matching,"[""Zhiwen Zuo"", ""Lei Zhao"", ""Huiming Zhang"", ""Qihang Mo"", ""Haibo Chen"", ""Zhizhong Wang"", ""AiLin Li"", ""Lihong Qiu"", ""Wei Xing"", ""Dongming Lu""]","[""Deep Learning"", ""Unsupervised Learning"", ""Generative Adversarial Networks"", ""Mode Collapse"", ""AutoEncoder""]",We propose an AE-based GAN that alleviates mode collapse in GANs.,,,,
HygHtpVtPH,2020,Reject,False,Laplacian Denoising Autoencoder,"[""Jianbo Jiao"", ""Linchao Bao"", ""Yunchao Wei"", ""Shengfeng He"", ""Honghui Shi"", ""Rynson Lau"", ""Thomas Huang""]","[""unsupervised"", ""representation learning"", ""Laplacian""]","We propose a new denoising autoencoder with Laplacian pyramid editing, results in improved representation learning capability.",,,,
HygN634KvH,2020,Reject,False,Temporal Probabilistic Asymmetric Multi-task Learning,"[""Nguyen Anh Tuan"", ""Hyewon Jeong"", ""Eunho Yang"", ""Sungju Hwang""]","[""Multi-task learning"", ""Time-series analysis"", ""Variational Inference""]","We proposed a novel probabilistic asymmetric multi-task learning framework that allows asymmetric knowledge transfer between tasks and across time-steps, based on the uncertainty",,,,
HygOjhEYDH,2020,Accept (Spotlight),True,Intensity-Free Learning of Temporal Point Processes,"[""Oleksandr Shchur"", ""Marin Bilo\u0161"", ""Stephan G\u00fcnnemann""]","[""Temporal point process"", ""neural density estimation""]","Learn in temporal point processes by modeling the conditional density, not the conditional intensity.",1909.12127,cs.LG,2019-09-26 14:11:55+00:00,2020-01-23 10:06:02+00:00
HygPjlrYvB,2020,Reject,False,Learning from Positive and Unlabeled Data  with Adversarial Training,"[""Wenpeng Hu"", ""Ran Le"", ""Bing Liu"", ""Feng Ji"", ""Haiqing Chen"", ""Dongyan Zhao"", ""Jinwen Ma"", ""Rui Yan""]","[""Positive and Unlabeled learning""]",,,,,
HygQ7TNtPr,2020,Reject,False,Rethinking Neural Network Quantization,"[""Qing Jin"", ""Linjie Yang"", ""Zhenyu Liao""]","[""Deep Learning"", ""Convolutional Network"", ""Network Quantization"", ""Efficient Learning""]",,,,,
HygQBn0cYm,2019,Accept (Poster),False,Model-Predictive Policy Learning with Uncertainty Regularization for Driving in Dense Traffic,"[""Mikael Henaff"", ""Alfredo Canziani"", ""Yann LeCun""]","[""model-based reinforcement learning"", ""stochastic video prediction"", ""autonomous driving""]",A model-based RL approach which uses a differentiable uncertainty penalty to learn driving policies from purely observational data.,,,,
HygQro05KX,2019,Reject,False,$A^*$ sampling with probability matching,"[""Yichi Zhou"", ""Jun Zhu""]",[],,,,,
HygS7n0cFQ,2019,Reject,False,Fast Exploration with Simplified Models and Approximately Optimistic Planning in Model Based Reinforcement Learning,"[""Ramtin Keramati"", ""Jay Whang"", ""Patrick Cho"", ""Emma Brunskill""]","[""Reinforcement Learning"", ""Strategic Exploration"", ""Model Based Reinforcement Learning""]",We studied exploration with imperfect planning and used object representation to learn simple models and introduced a new sample efficient RL algorithm that achieves state of the art results on Pitfall!,,,,
HygS91rYvH,2020,Reject,False,Universal Adversarial Attack Using Very Few Test Examples,"[""Amit Deshpande"", ""Sandesh Kamath"", ""K V Subrahmanyam""]","[""universal"", ""adversarial"", ""SVD""]",,,,,
HygSq3VFvH,2020,Reject,False,Self-Supervised State-Control through Intrinsic Mutual Information Rewards,"[""Rui Zhao"", ""Volker Tresp"", ""Wei Xu""]","[""Intrinsic Reward"", ""Deep Reinforcement Learning"", ""Skill Discovery"", ""Mutual Information"", ""Self-Supervised Learning"", ""Unsupervised Learning""]","This paper introduces Mutual Information-based State-Control, a self-supervised reinforcement learning framework for discovering robotic manipulation skills.",,,,
HygT9oRqFX,2019,Reject,False,MixFeat: Mix Feature in Latent Space Learns Discriminative Space,"[""Yoichi Yaguchi"", ""Fumiyuki Shiratani"", ""Hidekazu Iwaki""]","[""regularization"", ""generalization"", ""image classification"", ""latent space"", ""feature learning""]","We provide a novel method named MixFeat, which directly makes the latent space discriminative.",,,,
HygTE309t7,2019,Reject,False,Outlier Detection from Image Data,"[""Lei Cao"", ""Yizhou Yan"", ""Samuel Madden"", ""Elke Rundensteiner""]","[""Image outlier"", ""CNN"", ""Deep Neural Forest""]","A novel approach that detects outliers from image data,  while preserving the classification accuracy of image classification",,,,
HygTUxHKwH,2020,Reject,False,Qgraph-bounded Q-learning: Stabilizing Model-Free Off-Policy Deep Reinforcement Learning,"[""Sabrina Hoppe"", ""Marc Toussaint""]","[""deep learning"", ""reinforcement learning"", ""model-free reinforcement learning"", ""Q-learning"", ""DDPG""]",We link the graph-structure of the replay memory to soft divergence and propose Qgraphs to stabilize model-free off-policy deep RL.,2007.07582,cs.LG,2020-07-15 10:01:32+00:00,2020-07-15 10:01:32+00:00
HygUOoC5KX,2019,Reject,False,Are Generative Classifiers More Robust to Adversarial Attacks?,"[""Yingzhen Li"", ""John Bradshaw"", ""Yash Sharma""]","[""generative models"", ""adversarial attack"", ""defence"", ""detection"", ""Bayes' rule""]","We proposed a generative classifier based on deep generative models, and show improved robustness and detection results against adversarial attacks. ",,,,
HygW26VYwS,2020,Reject,False,Attention Privileged Reinforcement Learning for Domain Transfer,"[""Sasha Salter"", ""Dushyant Rao"", ""Markus Wulfmeier"", ""Raia Hadsell"", ""Ingmar Posner""]","[""sim-to-real"", ""domain randomisation"", ""attention"", ""transfer learning"", ""reinforcement learning""]",,,,,
HygXkJHtvB,2020,Reject,False,Using Objective Bayesian Methods to Determine the Optimal Degree of Curvature within the Loss Landscape,"[""Devon Jarvis"", ""Richard Klein"", ""Benjamin Rosman""]","[""Objective Bayes"", ""Information Geometry"", ""Artificial Neural Networks""]","We reflect that the widest point in the parameter landscape corresponds to a model which has overfit the training data, we propose a new determinant of the optimal width within the parameter landscape.",,,,
HygYmJBKwH,2020,Reject,False,YaoGAN: Learning Worst-case Competitive Algorithms from Self-generated Inputs,"[""Goran Zuzic"", ""Di Wang"", ""Aranyak Mehta"", ""D. Sivakumar""]",[],,,,,
HygYqs0qKX,2019,Reject,False,Conscious Inference for Object Detection,"[""Jiahuan Zhou"", ""Nikolaos Karianakis"", ""Ying Wu"", ""Gang Hua""]","[""consciousness"", ""conscious inference"", ""object detection"", ""object pose estimation""]",,,,,
Hyg_X2C5FX,2019,Accept (Poster),False,GAN Dissection: Visualizing and Understanding Generative Adversarial Networks,"[""David Bau"", ""Jun-Yan Zhu"", ""Hendrik Strobelt"", ""Bolei Zhou"", ""Joshua B. Tenenbaum"", ""William T. Freeman"", ""Antonio Torralba""]","[""GANs"", ""representation"", ""interpretability"", ""causality""]","GAN representations are examined in detail, and sets of representation units are found that control the generation of semantic concepts in the output.",,,,
Hygab1rKDS,2020,Accept (Poster),False,Quantum Algorithms for Deep Convolutional Neural Networks,"[""Iordanis Kerenidis"", ""Jonas Landman"", ""Anupam Prakash""]","[""quantum computing"", ""quantum machine learning"", ""convolutional neural network"", ""theory"", ""algorithm""]",We provide the first algorithm for quantum computers implementing universal convolutional neural network with a speedup,1911.01117,quant-ph,2019-11-04 10:34:46+00:00,2019-11-04 10:34:46+00:00
HygaikBKvS,2020,Reject,True,Off-Policy Actor-Critic with Shared Experience Replay,"[""Simon Schmitt"", ""Matteo Hessel"", ""Karen Simonyan""]","[""Reinforcement Learning"", ""Off-Policy Learning"", ""Experience Replay""]",We investigate and propose solutions for two challenges in reinforcement learning: (a) efficient actor-critic learning with experience replay (b) stability of very off-policy learning.,1909.11583,cs.LG,2019-09-25 16:20:46+00:00,2019-11-18 12:51:59+00:00
HygbQaNYwr,2020,Reject,True,Adversarial Training: embedding adversarial perturbations into the parameter space of a neural network to build a robust system,"[""Shixian Wen"", ""Laurent Itti""]","[""Adversarial Training"", ""Adversarial Examples""]",Perturbation bias inside of the neural network helps us to achieve adversarial training with negligible cost; alleviate accuracy trade-off between clean and adversarial examples; and diversify adversarial perturbations.,1910.04279,cs.LG,2019-10-09 22:16:09+00:00,2019-10-09 22:16:09+00:00
HygcdeBFvr,2020,Reject,False,Score and Lyrics-Free Singing Voice Generation,"[""Jen-Yu Liu"", ""Yu-Hua Chen"", ""Yin-Cheng Yeh"", ""Yi-Hsuan Yang""]","[""singing voice generation"", ""GAN"", ""generative adversarial network""]",Our models generate singing voices without lyrics and scores. They take accompaniment as input and output singing voices.,1912.11747,cs.SD,2019-12-26 01:45:03+00:00,2020-07-21 06:48:42+00:00
HygcvsAcFX,2019,Reject,False,Optimal margin Distribution Network,"[""Shen-Huan Lv"", ""Lu Wang"", ""Zhi-Hua Zhou""]","[""Optimal margin distribution"", ""Deep neural network"", ""Generalization bound""]","This paper presents a deep neural network embedding a loss function in regard to the optimal margin distribution, which alleviates the overfitting problem theoretically and empirically.",,,,
HygegyrYwH,2020,Accept (Poster),True,Polylogarithmic width suffices for gradient descent to achieve arbitrarily small test error with shallow ReLU networks,"[""Ziwei Ji"", ""Matus Telgarsky""]","[""neural tangent kernel"", ""polylogarithmic width"", ""test error"", ""gradient descent"", ""classification""]",,1909.12292,cs.LG,2019-09-26 17:56:28+00:00,2020-02-15 03:53:09+00:00
Hyghb2Rct7,2019,Reject,False,SIMILE: Introducing Sequential Information towards More Effective Imitation Learning,"[""Yutong Bai"", ""Lingxi Xie""]","[""Reinforcement Learning"", ""Imitation Learning"", ""Sequential Information""]",This paper introduces sequential information to improve inverse reinforcement learning algorithms,,,,
Hygi7xStvS,2020,Reject,False,Lossless Data Compression with Transformer,"[""Gautier Izacard"", ""Armand Joulin"", ""Edouard Grave""]","[""data compression"", ""transformer""]",Application of transformer networks to lossless data compression,,,,
HygiDTVKPr,2020,Reject,False,A Mention-Pair Model of Annotation with Nonparametric User Communities,"[""Silviu Paun"", ""Juntao Yu"", ""Jon Chamberlain"", ""Udo Kruschwitz"", ""Massimo Poesio""]","[""model of annotation"", ""coreference resolution"", ""anaphoric annotation"", ""mention pair model"", ""bayesian nonparametrics""]",,,,,
HygjqjR9Km,2019,Accept (Poster),False,Improving MMD-GAN Training with Repulsive Loss Function,"[""Wei Wang"", ""Yuan Sun"", ""Saman Halgamuge""]","[""generative adversarial nets"", ""loss function"", ""maximum mean discrepancy"", ""image generation"", ""unsupervised learning""]",Rearranging the terms in maximum mean discrepancy yields a much better loss function for the discriminator of generative adversarial nets,1812.09916,cs.LG,2018-12-24 13:23:18+00:00,2019-02-08 06:28:35+00:00
HygkpxStvr,2020,Reject,False,Weakly-Supervised Trajectory Segmentation for Learning Reusable Skills,"[""Parsa Mahmoudieh"", ""Trevor Darrell"", ""Deepak Pathak""]","[""skills"", ""demonstration"", ""agent"", ""sub-task"", ""primitives"", ""robot learning"", ""manipulation""]",Weakly supervised segmentation of human demonstrations into skill primitives by only using trajectory-level labels at training with neither time-step segmentation labels nor ordering information.,,,,
Hygm8jC9FQ,2019,Reject,False,FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE,"[""Masanori Yamada"", ""Kim Heecheol"", ""Kosuke Miyoshi"", ""Hiroshi Yamakawa""]","[""disentangled representation learning""]",We propose new model that can disentangle multiple dynamic factors in sequential data,,,,
Hygn2o0qKX,2019,Accept (Poster),False,Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience,"[""Vaishnavh Nagarajan"", ""Zico Kolter""]","[""generalization"", ""PAC-Bayes"", ""SGD"", ""learning theory"", ""implicit regularization""]","We provide a PAC-Bayes based generalization guarantee for uncompressed, deterministic deep networks by generalizing noise-resilience of the network on the training data to the test data.",,,,
HygnDhEtvr,2020,Accept (Poster),True,Reinforcement Learning Based Graph-to-Sequence Model for Natural Question Generation,"[""Yu Chen"", ""Lingfei Wu"", ""Mohammed J. Zaki""]","[""deep learning"", ""reinforcement learning"", ""graph neural networks"", ""natural language processing"", ""question generation""]",,1908.04942,cs.CL,2019-08-14 03:40:04+00:00,2020-08-27 15:49:08+00:00
Hygp1nR9FQ,2019,Reject,False,Unifying Bilateral Filtering and Adversarial Training for Robust Neural Networks,"[""Neale Ratzlaff"", ""Li Fuxin""]","[""Adversarial examples"", ""Image denoising""]",We adapt bilateral filtering as a layer in a neural network which improves robustness to adversarial examples using nonlocal filtering.,,,,
HygpthEtvr,2020,Accept (Poster),False,ProxSGD: Training Structured Neural Networks under Regularization and Constraints,"[""Yang Yang"", ""Yaxiong Yuan"", ""Avraam Chatzimichailidis"", ""Ruud JG van Sloun"", ""Lei Lei"", ""Symeon Chatzinotas""]","[""stochastic gradient descent"", ""regularization"", ""constrained optimization"", ""nonsmooth optimization""]",We propose a convergent proximal-type stochastic gradient descent algorithm for constrained nonsmooth nonconvex optimization problems,,,,
Hygq3JrtwS,2020,Reject,False,On the Reflection of Sensitivity in the Generalization Error,"[""Mahsa Forouzesh"", ""Farnood Salehi"", ""Patrick Thiran""]","[""Generalization Error"", ""Sensitivity Analysis"", ""Deep Neural Networks"", ""Bias-variance Decomposition""]",We study the relation between the generalization error and the sensitivity of the output to random input perturbations in deep neural networks.,,,,
HygqFlBtPS,2020,Reject,False,Improved Training of Certifiably Robust Models,"[""Chen Zhu"", ""Renkun Ni"", ""Ping-yeh Chiang"", ""Hengduo Li"", ""Furong Huang"", ""Tom Goldstein""]","[""Convex Relaxation"", ""Certified Robustness"", ""Regularization""]",,,,,
HygqJnCqtm,2019,Reject,False,Rating Continuous Actions in Spatial Multi-Agent Problems,"[""Uwe Dick"", ""Maryam Tavakol"", ""Ulf Brefeld""]",[],,,,,
HygrAR4tPS,2020,Reject,True,On Empirical Comparisons of Optimizers for Deep Learning,"[""Dami Choi"", ""Christopher J. Shallue"", ""Zachary Nado"", ""Jaehoon Lee"", ""Chris J. Maddison"", ""George E. Dahl""]","[""Deep learning"", ""optimization"", ""adaptive gradient methods"", ""Adam"", ""hyperparameter tuning""]",Optimizer comparisons depend more than you would think on metaparameter tuning details and our prior should be that more general update rules (e.g. adaptive gradient methods) are better.,1910.05446,cs.LG,2019-10-11 23:51:09+00:00,2020-06-16 00:58:12+00:00
HygrdpVKvr,2020,Accept (Poster),False,NAS evaluation is frustratingly hard,"[""Antoine Yang"", ""Pedro M. Esperan\u00e7a"", ""Fabio M. Carlucci""]","[""neural architecture search"", ""nas"", ""benchmark"", ""reproducibility"", ""harking""]","A study of how different components in the NAS pipeline contribute to the final accuracy. Also, a benchmark of 8 methods on 5 datasets.",1912.12522,cs.LG,2019-12-28 21:24:12+00:00,2020-02-13 22:10:12+00:00
HygsfnR9Ym,2019,Accept (Poster),False,Recall Traces: Backtracking Models for Efficient Reinforcement Learning,"[""Anirudh Goyal"", ""Philemon Brakel"", ""William Fedus"", ""Soumye Singhal"", ""Timothy Lillicrap"", ""Sergey Levine"", ""Hugo Larochelle"", ""Yoshua Bengio""]","[""Model free RL"", ""Variational Inference""]","A backward model of previous (state, action) given the next state, i.e. P(s_t, a_t | s_{t+1}), can be used to simulate additional trajectories terminating at states of interest! Improves RL learning efficiency.",,,,
HygsuaNFwr,2020,Accept (Poster),False,Order Learning and Its Application to Age Estimation,"[""Kyungsun Lim"", ""Nyeong-Ho Shin"", ""Young-Yoon Lee"", ""Chang-Su Kim""]","[""Order learning"", ""age estimation"", ""aesthetic assessment""]",The notion of order learning is proposed and it is applied to regression problems in computer vision,,,,
HygtHnR5tQ,2019,Reject,False,Generative Adversarial Networks for Extreme Learned Image Compression,"[""Eirikur Agustsson"", ""Michael Tschannen"", ""Fabian Mentzer"", ""Radu Timofte"", ""Luc van Gool""]","[""Learned compression"", ""generative adversarial networks"", ""extreme compression""]",GAN-based extreme image compression method using less than half the bits of the SOTA engineered codec while preserving visual quality,,,,
HygtiTEYvS,2020,Reject,False,Self-Supervised Policy Adaptation,"[""Christopher Mutschler"", ""Sebastian Pokutta""]","[""reinforcement learning"", ""environment representation"", ""representation learning"", ""model mismatch""]",Greedy State Representation Learning (GSRL) translates a given policy when the environment representation changes ,,,,
Hygv0sC5F7,2019,Reject,False,When Will Gradient Methods Converge to Max-margin Classifier under ReLU Models?,"[""Tengyu Xu"", ""Yi Zhou"", ""Kaiyi Ji"", ""Yingbin Liang""]","[""gradient method"", ""max-margin"", ""ReLU model""]",We study the implicit bias of gradient methods in solving a binary classification problem with nonlinear ReLU models.,,,,
Hygv3xrtDr,2020,Reject,False,Sparse Skill Coding: Learning Behavioral Hierarchies with Sparse Codes,"[""Sophia Sanborn"", ""Michael Chang"", ""Sergey Levine"", ""Thomas Griffiths""]","[""hierarchical reinforcement learning"", ""unsupervised learning"", ""compression""]",,,,,
Hygvln09K7,2019,Reject,False,Meta Learning with Fast/Slow Learners,"[""zhuoyuan@fb.com""]","[""computer vision"", ""meta learning""]",We applied multiple meta-strategy to improve meta-learning performance on base CNNs. ,,,,
HygwvC4tPH,2020,Reject,False,Learning Cross-Context Entity Representations from Text,"[""Jeffrey Ling"", ""Nicholas FitzGerald"", ""Zifei Shan"", ""Livio Baldini Soares"", ""Thibault F\u00e9vry"", ""David Weiss"", ""Tom Kwiatkowski""]","[""entities"", ""entity representations"", ""knowledge representation"", ""entity linking"", ""entity typing""]",We investigate the use of a fill-in-the-blank task to learn context independent representations of entities from the text contexts in which those entities were mentioned,,,,
Hygxb2CqKm,2019,Accept (Poster),False,Stable Recurrent Models,"[""John Miller"", ""Moritz Hardt""]","[""stability"", ""gradient descent"", ""non-convex optimization"", ""recurrent neural networks""]",Stable recurrent models can be approximated by feed-forward networks and empirically perform as well as unstable models on benchmark tasks.,,,,
Hygy01StvH,2020,Reject,False,Impact of the latent space on the ability of GANs to fit the distribution,"[""Thomas Pinetz"", ""Daniel Soukup"", ""Thomas Pock""]","[""Deep Learning"", ""Generative Adversarial Networks"", ""Compression"", ""Perceptual Quality""]",We analyze the impact of the latent space of fully trained generators by pseudo inverting them.,,,,
HyiAuyb0b,2018,Accept (Poster),False,TD or not TD: Analyzing the Role of Temporal Differencing in Deep Reinforcement Learning,"[""Artemij Amiranashvili"", ""Alexey Dosovitskiy"", ""Vladlen Koltun"", ""Thomas Brox""]","[""deep learning"", ""reinforcement learning"", ""temporal difference""]",,1806.01175,cs.LG,2018-06-04 16:16:51+00:00,2018-06-04 16:16:51+00:00
HyiRazbRb,2018,Reject,False,Demystifying overcomplete nonlinear auto-encoders: fast SGD convergence towards sparse representation from random initialization,"[""Cheng Tang"", ""Claire Monteleoni""]","[""stochastic gradient descent"", ""autoencoders"", ""nonconvex optimization"", ""representation learning"", ""theory""]",theoretical analysis of nonlinear wide autoencoder,,,,
Hyig0zb0Z,2018,Reject,False,Gated ConvNets for Letter-Based ASR,"[""Vitaliy Liptchinsky"", ""Gabriel Synnaeve"", ""Ronan Collobert""]","[""automatic speech recognition"", ""letter-based acoustic model"", ""gated convnets""]",A letter-based ConvNet acoustic model leads to a simple and competitive speech recognition pipeline.,,,,
HyjC5yWCW,2018,Accept (Poster),False,Meta-Learning and Universality: Deep Representations and Gradient Descent can Approximate any Learning Algorithm,"[""Chelsea Finn"", ""Sergey Levine""]","[""meta-learning"", ""learning to learn"", ""universal function approximation""]",Deep representations combined with gradient descent can approximate any learning algorithm.,,,,
Hyl7ygStwB,2020,Accept (Poster),False,Incorporating BERT into Neural Machine Translation,"[""Jinhua Zhu"", ""Yingce Xia"", ""Lijun Wu"", ""Di He"", ""Tao Qin"", ""Wengang Zhou"", ""Houqiang Li"", ""Tieyan Liu""]","[""BERT"", ""Neural Machine Translation""]",,,,,
Hyl8yANFDB,2020,Reject,False,Assessing Generalization in TD methods for Deep Reinforcement Learning,"[""Emmanuel Bengio"", ""Doina Precup"", ""Joelle Pineau""]","[""reinforcement learning"", ""deep learning"", ""generalization""]","Empirical investigation showing TD, in particular TD(0), may be preventing generalization in DeepRL",,,,
Hyl9ahVFwH,2020,Reject,False,Learning Similarity Metrics for Numerical Simulations,"[""Georg Kohl"", ""Kiwon Um"", ""Nils Thuerey""]","[""metric learning"", ""CNNs"", ""PDEs"", ""numerical simulation"", ""perceptual evaluation"", ""physics simulation""]",We propose a novel CNN-based metric to robustly compare field data from PDE-based numerical simulations.,2002.07863,cs.LG,2020-02-18 20:11:15+00:00,2020-06-23 18:14:55+00:00
Hyl9xxHYPr,2020,Accept (Poster),True,Demystifying Inter-Class Disentanglement,"[""Aviv Gabbay"", ""Yedid Hoshen""]","[""disentanglement"", ""latent optimization"", ""domain translation""]",Latent Optimization for Representation Disentanglement,1906.11796,cs.LG,2019-06-27 16:58:26+00:00,2020-02-18 18:56:58+00:00
HylA41Btwr,2020,Reject,False,CP-GAN: Towards a Better Global Landscape of GANs,"[""Ruoyu Sun"", ""Tiantian Fang"", ""Alex Schwing""]","[""GAN"", ""global landscape"", ""non-convex optimization"", ""min-max optimization"", ""dynamics""]",,,,,
HylAoJSKvH,2020,Accept (Poster),False,A Stochastic Derivative Free Optimization Method with Momentum,"[""Eduard Gorbunov"", ""Adel Bibi"", ""Ozan Sener"", ""El Houcine Bergou"", ""Peter Richtarik""]","[""derivative-free optimization"", ""stochastic optimization"", ""heavy ball momentum"", ""importance sampling""]",We develop and analyze a new derivative free optimization algorithm with momentum and importance sampling with applications to continuous control.,,,,
HylDpoActX,2019,Reject,False,N-Ary Quantization for CNN Model Compression and Inference Acceleration,"[""G\u00fcnther Schindler"", ""Wolfgang Roth"", ""Franz Pernkopf"", ""Holger Fr\u00f6ning""]","[""low-resource deep neural networks"", ""quantized weights"", ""weight-clustering"", ""resource efficient neural networks""]",We propose a quantization scheme for weights and activations of deep neural networks. This reduces the memory footprint substantially and accelerates inference.,,,,
HylJtiRqYQ,2019,Reject,False,VECTORIZATION METHODS IN RECOMMENDER SYSTEM,"[""Qiang Sun"", ""Bin Wang"", ""Zizhou Gu"", ""Yanwei Fu""]",[],,,,,
HylKJhCcKm,2019,Reject,False,Generalized Capsule Networks with Trainable Routing Procedure,"[""Zhenhua Chen"", ""Chuhua Wang"", ""Tiancong Zhao"", ""David Crandall""]","[""Capsule networks"", ""generalization"", ""scalability"", ""adversarial robustness""]",A scalable capsule network,,,,
HylKvyHYwS,2020,Reject,False,Learning with Protection: Rejection of Suspicious Samples under Adversarial Environment,"[""Masahiro Kato"", ""Yoshihiro Fukuhara"", ""Hirokatsu Kataoka"", ""Shigeo Morishima""]","[""Learning with Rejection"", ""Adversarial Examples""]",,,,,
HylLq2EKwS,2020,Reject,False,Collaborative Filtering With A Synthetic Feedback Loop,"[""Wenlin Wang"", ""Hongteng Xu"", ""Ruiyi Zhang"", ""Wenqi Wang"", ""Lawrence Carin""]",[],,,,,
HylNWkHtvB,2020,Reject,False,Domain-Independent Dominance of Adaptive Methods,"[""Pedro Savarese"", ""David McAllester"", ""Sudarshan Babu"", ""Michael Maire""]",[],,1912.01823,cs.LG,2019-12-04 06:58:53+00:00,2020-03-17 01:25:23+00:00
HylRk2A5FQ,2019,Reject,False,Graph Learning Network: A Structure Learning Algorithm,"[""Darwin Danilo Saire Pilco"", ""Ad\u00edn Ram\u00edrez Rivera""]","[""graph prediction"", ""graph structure learning"", ""graph neural network""]","Methods for simultaneous prediction of nodes' feature embeddings and adjacency matrix, and how to learn this process.",,,,
HylSk205YQ,2019,Reject,False,Multi-agent Deep Reinforcement Learning with Extremely Noisy Observations,"[""Ozsel Kilinc"", ""Giovanni Montana""]","[""Reinforcement learning"", ""multi-agent"", ""hierarchical"", ""noisy observation"", ""partial observability"", ""deep learning""]",,1812.00922,cs.LG,2018-12-03 17:27:41+00:00,2018-12-03 17:27:41+00:00
HylTBhA5tQ,2019,Accept (Poster),False,The Limitations of Adversarial Training and the Blind-Spot Attack,"[""Huan Zhang*"", ""Hongge Chen*"", ""Zhao Song"", ""Duane Boning"", ""Inderjit S. Dhillon"", ""Cho-Jui Hsieh""]","[""Adversarial Examples"", ""Adversarial Training"", ""Blind-Spot Attack""]",We show that even the strongest adversarial training methods cannot defend against adversarial examples crafted on slightly scaled and shifted test images.,,,,
HylTXn0qYX,2019,Accept (Poster),True,Efficiently testing local optimality and escaping saddles for ReLU networks,"[""Chulhee Yun"", ""Suvrit Sra"", ""Ali Jadbabaie""]","[""local optimality"", ""second-order stationary point"", ""escaping saddle points"", ""nondifferentiability"", ""ReLU"", ""empirical risk""]",A theoretical algorithm for testing local optimality and extracting descent directions at nondifferentiable points of empirical risks of one-hidden-layer ReLU networks.,1809.10858,math.OC,2018-09-28 04:53:03+00:00,2019-05-29 00:22:12+00:00
HylVB3AqYm,2019,Accept (Poster),False,ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware,"[""Han Cai"", ""Ligeng Zhu"", ""Song Han""]","[""Neural Architecture Search"", ""Efficient Neural Networks""]",Proxy-less neural architecture search for directly learning architectures on large-scale target task (ImageNet) while reducing the cost to the same level of normal training.,,,,
HylWahVtwB,2020,Reject,True,Neural Architecture Search in Embedding Space,"[""chun-ting liu""]","[""neural architecture search"", ""nas"", ""automl""]","This paper proposed a novel neural architecture search framework, which enables reinforcement learning to search in an embedding space by using architecture encoders and decoders.",1909.03615,cs.LG,2019-09-09 03:28:55+00:00,2020-03-26 08:06:33+00:00
HylZIT4Yvr,2020,Reject,True,Structural Language Models for Any-Code Generation,"[""Uri Alon"", ""Roy Sadaka"", ""Omer Levy"", ""Eran Yahav""]","[""Program Generation"", ""Structural Language Model"", ""SLM"", ""Generative Model"", ""Code Generation""]",We generate source code using a Structural Language Model over the program's Abstract Syntax Tree,1910.00577,cs.LG,2019-09-30 18:54:07+00:00,2020-07-29 12:15:33+00:00
Hyl_vjC5KQ,2019,Accept (Poster),False,Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization,"[""Takayuki Osa"", ""Voot Tangkaratt"", ""Masashi Sugiyama""]","[""Hierarchical reinforcement learning"", ""Representation learning"", ""Continuous control""]",This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. ,,,,
HylcapVtvB,2020,Reject,False,Improving Differentially Private Models with Active Learning,"[""Zhengli Zhao"", ""Nicolas Papernot"", ""Sameer Singh"", ""Neoklis Polyzotis"", ""Augustus Odena""]","[""Differential Privacy"", ""Active Learning""]",We introduce privacy-aware active learning techniques to improve differentially private classifiers and achieve state-of-the-art results.,,,,
HyleYiC9FX,2019,Reject,False,Text Embeddings for Retrieval from a Large Knowledge Base,"[""Tolgahan Cakaloglu"", ""Christian Szegedy"", ""Xiaowei Xu""]","[""Text Embeddings"", ""Document Ranking"", ""Improving Retrieval"", ""Question-Answering"", ""Learning to Rank""]",The new attempt for creating semantically meaningful text embeddings via improved language modeling and utilizing an extra knowledge base,,,,
HyleclHKvS,2020,Reject,False,A Non-asymptotic comparison of SVRG and SGD: tradeoffs between compute and speed,"[""Qingru Zhang"", ""Yuhuai Wu"", ""Fartash Faghri"", ""Tianzong Zhang"", ""Jimmy Ba""]","[""variance reduction"", ""non-asymptotic analysis"", ""trade-off"", ""computational cost"", ""convergence speed""]","Non-asymptotic analysis of SGD and SVRG, showing the strength of each algorithm in convergence speed and computational cost, in both under-parametrized and over-parametrized settings.",,,,
HylfPgHYvr,2020,Reject,False,Occlusion  resistant  learning  of  intuitive physics from videos,"[""Ronan Riochet"", ""Josef Sivic"", ""Ivan Laptev"", ""Emmanuel Dupoux""]",[],,2005.00069,cs.CV,2020-04-30 19:35:54+00:00,2020-04-30 19:35:54+00:00
HylgYB3pZ,2018,Reject,False,Linearly Constrained Weights: Resolving the Vanishing Gradient Problem by Reducing Angle Bias,"[""Takuro Kutsuna""]","[""vanishing gradient problem"", ""multilayer perceptron"", ""angle bias""]",We identify angle bias that causes the vanishing gradient problem in deep nets and propose an efficient method to reduce the bias.,,,,
HylhuTEtwr,2020,Reject,False,The advantage of using Student's t-priors in variational autoencoders,"[""Najmeh Abiri"", ""Mattias Ohlsson""]","[""Variational Autoencoders"", ""DLVMs"", ""Posterior Collapse""]",,,,,
HyljY04YDB,2020,Reject,False,Towards Interpretable Molecular Graph Representation Learning,"[""Emmanuel Noutahi"", ""Dominique Beani"", ""Julien Horwood"", ""Prudencio Tossou""]","[""molecular graphs"", ""graph pooling"", ""hierarchical"", ""GNN"", ""Laplacian"", ""drug discovery""]",We propose a new Laplacian-based hierarchical graph pooling layers that not only outperforms existing GNNs on several graph benchmarks but is also more interpretable.,,,,
HyljzgHtwS,2020,Reject,False,Regularly varying representation for sentence embedding,"[""Hamid Jalalzai"", ""Pierre Colombo"", ""Chlo\u00e9 Clavel"", ""Eric Gaussier"", ""Giovanna Varni"", ""Emmanuel Vignon"", ""Anne Sabourin""]","[""extreme value theory"", ""classification"", ""supvervised learning"", ""data augmentation"", ""representation learning""]",,,,,
HyllasActm,2019,Reject,False,End-to-End Learning of Video Compression Using Spatio-Temporal Autoencoders,"[""Jorge Pessoa"", ""Helena Aidos"", ""Pedro Tom\u00e1s"", ""M\u00e1rio A. T. Figueiredo""]",[],,,,,
HylloR4YDr,2020,Reject,False,Learning Latent Representations for Inverse Dynamics using Generalized Experiences,"[""Aditi Mavalankar"", ""Sicun Gao""]","[""deep reinforcement learning"", ""continuous control"", ""inverse dynamics model""]","We show that the key to achieving good performance with IDMs lies in learning latent representations to encode the information shared between equivalent experiences, so that they can be generalized to unseen scenarios.",,,,
Hylnis0qKX,2019,Reject,False,Task-GAN for Improved GAN based Image Restoration,"[""Jiahong Ouyang"", ""Guanhua Wang"", ""Enhao Gong"", ""Kevin Chen"", ""John Pauly and Greg Zaharchuk""]","[""Task-GAN: Improving Generative Adversarial Network for Image Restoration""]",Couple the GAN based image restoration framework with another task-specific network to generate realistic image while preserving task-specific features.,,,,
HyloPnEKPr,2020,Reject,False,Context-aware Attention Model for Coreference Resolution,"[""Yufei Li"", ""Xiangyu Zhou"", ""Jie Ma"", ""Yu Long"", ""Xuan Wang"", ""Chen Li""]","[""Coreference resolution"", ""Feature Attention""]",We demonstrate an attention model reweighing features around different contexts to reduce the wrongful predictions between similar or identical texts units,,,,
HylpqA4FwS,2020,Accept (Poster),True,RNNs Incrementally Evolving on an Equilibrium Manifold: A Panacea for Vanishing and Exploding Gradients?,"[""Anil Kag"", ""Ziming Zhang"", ""Venkatesh Saligrama""]","[""novel recurrent neural architectures"", ""learning representations of outputs or states""]",Incremental-RNNs resolves exploding/vanishing gradient problem by updating state vectors based on difference between previous state and that predicted by an ODE.,1908.08574,cs.LG,2019-08-22 19:35:13+00:00,2019-08-26 21:20:39+00:00
HylrB04YwH,2020,Reject,False,Overparameterized Neural Networks Can Implement Associative Memory,"[""Adityanarayanan Radhakrishnan"", ""Mikhail Belkin"", ""Caroline Uhler""]","[""Associative Memory"", ""Memorization and Recall"", ""Attractors"", ""Deep Autoencoders""]",We demonstrate that overparameterized neural networks trained using standard optimizers can memorize and recall individual data instances or sequences.  ,,,,
Hyls7h05FQ,2019,Reject,False,A Differentiable Self-disambiguated Sense Embedding Model via Scaled Gumbel Softmax,"[""Fenfei Guo"", ""Mohit Iyyer"", ""Leah Findlater"", ""Jordan Boyd-Graber""]","[""unsupervised representation learning"", ""sense embedding"", ""word sense disambiguation"", ""human evaluation""]",Disambiguate and embed word senses with a differentiable hard-attention model using Scaled Gumbel Softmax,,,,
HylsTT4FvB,2020,Accept (Poster),False,"On the ""steerability"" of generative adversarial networks","[""Ali Jahanian*"", ""Lucy Chai*"", ""Phillip Isola""]","[""generative adversarial network"", ""latent space interpolation"", ""dataset bias"", ""model generalization""]",Interpolations in the latent space demonstrate generalization capacity of GANs and the effect of dataset biases.,,,,
HylsgnCcFQ,2019,Reject,False,Dynamic Graph Representation Learning via Self-Attention Networks,"[""Aravind Sankar"", ""Yanhong Wu"", ""Liang Gou"", ""Wei Zhang"", ""Hao Yang""]","[""Graph Representation Learning"", ""Dynamic Graphs"", ""Attention"", ""Self-Attention"", ""Deep Learning""]","A novel neural architecture named DySAT to learn node representations on dynamic graphs by employing self-attention along two dimensions: structural neighborhood and temporal dynamics, achieves state-of-the-art results in dynamic link prediction.",1812.09430,cs.LG,2018-12-22 01:43:07+00:00,2019-06-15 20:22:42+00:00
HylthC4twr,2020,Reject,False,Frequency Analysis for Graph Convolution Network,"[""Hoang NT"", ""Takanori Maehara""]","[""graph signal processing"", ""frequency analysis"", ""graph convolution neural network"", ""simplified convolution network"", ""semi-supervised vertex classification""]","We study the filtering effect of GCN and SGC on benchmark datasets, find that all datasets are low-frequency and state-of-the-art models do not work in high-frequency settings.",,,,
HylvleBtPB,2020,Reject,False,Language-independent Cross-lingual Contextual Representations,"[""Xiao Zhang"", ""Song Wang"", ""Dejing Dou"", ""Xien Liu"", ""Thien Huu Nguyen"", ""Ji Wu""]","[""contextual representation"", ""cross-lingual"", ""transfer learning""]",A language-independent contextual text representation for zero-shot cross-lingual transfer learning.,,,,
HylwpREtDr,2020,Reject,False,Active Learning Graph Neural Networks via Node Feature Propagation,"[""Yuexin Wu"", ""Yichong Xu"", ""Aarti Singh"", ""Artur Dubrawski"", ""Yiming Yang""]","[""Graph Learning"", ""Active Learning""]",This paper introduces a clustering-based active learning algorithm on graphs.,,,,
HylxE1HKwS,2020,Accept (Poster),True,Once-for-All: Train One Network and Specialize it for Efficient Deployment,"[""Han Cai"", ""Chuang Gan"", ""Tianzhe Wang"", ""Zhekai Zhang"", ""Song Han""]","[""Efficient Deep Learning"", ""Specialized Neural Network Architecture"", ""AutoML""]",We introduce techniques to train a single once-for-all network that fits many hardware platforms.,1908.09791,cs.LG,2019-08-26 16:46:23+00:00,2020-04-29 20:49:05+00:00
Hylyui09tm,2019,Reject,False,EMI: Exploration with Mutual Information Maximizing State and Action Embeddings,"[""Hyoungseok Kim"", ""Jaekyeom Kim"", ""Yeonwoo Jeong"", ""Sergey Levine"", ""Hyun Oh Song""]","[""reinforcement learning"", ""exploration"", ""representation learning""]",,,,,
HylzTiC5Km,2019,Accept (Oral),False,GENERATING HIGH FIDELITY IMAGES WITH SUBSCALE PIXEL NETWORKS AND MULTIDIMENSIONAL UPSCALING,"[""Jacob Menick"", ""Nal Kalchbrenner""]",[],We show that autoregressive models can generate high fidelity images. ,,,,
HylznxrYDr,2020,Reject,False,FINBERT:  FINANCIAL SENTIMENT ANALYSIS   WITH PRE-TRAINED LANGUAGE MODELS,"[""Dogu Araci"", ""Zulkuf Genc""]","[""Financial sentiment analysis"", ""financial text classification"", ""transfer learning"", ""pre-trained language models"", ""BERT"", ""NLP""]","We introduce FinBERT, a language model based on BERT for financial text classification, where we improved state-of-the-art performance by 14 percentage points.",,,,
HymYLebCb,2018,Reject,False,Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification,"[""Kshiteesh Hegde"", ""Malik Magdon-Ismail"", ""Ram Ramanathan"", ""Bishal Thapa""]","[""deep learning"", ""transfer learning"", ""adjacency matrices"", ""image feature representation"", ""Caffe"", ""graph classification""]",We convert subgraphs into structured images and classify them using 1. deep learning and 2. transfer learning (Caffe) and achieve stunning results.,,,,
HymuJz-A-,2018,Invite to Workshop Track,False,Not-So-CLEVR: Visual Relations Strain Feedforward Neural Networks,"[""Junkyung Kim"", ""Matthew Ricci"", ""Thomas Serre""]","[""Visual Relations"", ""Visual Reasoning"", ""SVRT"", ""Attention"", ""Working Memory"", ""Convolutional Neural Network"", ""Deep Learning"", ""Relational Network""]","Using a novel, controlled, visual-relation challenge, we show that same-different tasks critically strain the capacity of CNNs; we argue that visual relations can be better solved using attention-mnemonic strategies.",,,,
HyoST_9xl,2017,Accept (Poster),False,DSD: Dense-Sparse-Dense Training for Deep Neural Networks,"[""Song Han"", ""Jeff Pool"", ""Sharan Narang"", ""Huizi Mao"", ""Enhao Gong"", ""Shijian Tang"", ""Erich Elsen"", ""Peter Vajda"", ""Manohar Paluri"", ""John Tran"", ""Bryan Catanzaro"", ""William J. Dally""]","[""Deep learning""]",DSD effectively achieves superior optimization performance on a wide range of deep neural networks.,,,,
Hyp-JJJRW,2018,Reject,False,Style Memory: Making a Classifier Network Generative,"[""Rey Wiyatno"", ""Jeff Orchard""]","[""neural networks"", ""autoencoder"", ""generative"", ""feed-back""]",Augmenting the top layer of a classifier network with a style memory enables it to be generative.,,,,
Hyp3i2xRb,2018,Reject,False,Overcoming the vanishing gradient problem in plain recurrent networks,"[""Yuhuang Hu"", ""Adrian Huber"", ""Shih-Chii Liu""]","[""vanishing gradient descent"", ""recurrent neural networks"", ""identity mapping""]",We propose a novel network called the Recurrent Identity Network (RIN) which allows a plain recurrent network to overcome the vanishing gradient problem while training very deep models without the use of gates.,,,,
HypkN9yRW,2018,Reject,False,DDRprog: A CLEVR Differentiable Dynamic Reasoning Programmer,"[""Joseph Suarez"", ""Justin Johnson"", ""L. Fei-Fei""]","[""CLEVR"", ""VQA"", ""Visual Question Answering"", ""Neural Programmer""]",A generic dynamic architecture that employs a problem specific differentiable forking mechanism to encode hard data structure assumptions. Applied to CLEVR VQA and expression evaluation.,,,,
Hyq4yhile,2017,Accept (Poster),False,Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning,"[""Abhishek Gupta"", ""Coline Devin"", ""YuXuan Liu"", ""Pieter Abbeel"", ""Sergey Levine""]","[""Deep learning"", ""Reinforcement Learning"", ""Transfer Learning""]",Learning a common feature space between robots with different morphology or actuation to transfer skills.,,,,
HyrCWeWCb,2018,Accept (Poster),False,Trust-PCL: An Off-Policy Trust Region Method for Continuous Control,"[""Ofir Nachum"", ""Mohammad Norouzi"", ""Kelvin Xu"", ""Dale Schuurmans""]","[""Reinforcement learning""]",We extend recent insights related to softmax consistency to achieve state-of-the-art results in continuous control.,,,,
HysBZSqlx,2017,Reject,False,Playing SNES in the Retro Learning Environment,"[""Nadav Bhonker"", ""Shai Rozenberg"", ""Itay Hubara""]","[""Reinforcement Learning"", ""Deep learning"", ""Games""]",Investigating Deep Reinforcement Learning algorithms in a new framework based on the SNES gaming console,,,,
HytSvlWRZ,2018,Reject,False,Subspace Network: Deep Multi-Task Censored Regression for Modeling Neurodegenerative Diseases,"[""Mengying Sun"", ""Inci M. Baytas"", ""Zhangyang Wang"", ""Jiayu Zhou""]","[""subspace"", ""censor"", ""multi-task"", ""deep network""]",,,,,
HyunpgbR-,2018,Reject,False,Structured Exploration via Hierarchical Variational Policy Networks,"[""Stephan Zheng"", ""Yisong Yue""]","[""Deep Reinforcement Learning"", ""Structured Variational Inference"", ""Multi-agent Coordination"", ""Multi-agent Learning""]",Make deep reinforcement learning in large state-action spaces more efficient using structured exploration with deep hierarchical policies.,,,,
Hyvw0L9el,2017,Invite to Workshop Track,False,Generating Interpretable Images with Controllable Structure,"[""Scott Reed"", ""A\u00e4ron van den Oord"", ""Nal Kalchbrenner"", ""Victor Bapst"", ""Matt Botvinick"", ""Nando de Freitas""]","[""Deep learning"", ""Computer vision"", ""Multi-modal learning"", ""Natural language processing""]",Autoregressive text-to-image synthesis with controllable spatial structure.,,,,
Hyx-jyBFPr,2020,Accept (Spotlight),False,Self-labelling via simultaneous clustering and representation learning,"[""Asano YM."", ""Rupprecht C."", ""Vedaldi A.""]","[""self-supervision"", ""feature representation learning"", ""clustering""]","We propose a self-supervised learning formulation that simultaneously learns feature representations and useful dataset labels by optimizing the common cross-entropy loss for features _and_ labels, while maximizing information.",,,,
Hyx0slrFvH,2020,Accept (Poster),True,Mixed Precision DNNs: All you need is a good parametrization,"[""Stefan Uhlich"", ""Lukas Mauch"", ""Fabien Cardinaux"", ""Kazuki Yoshiyama"", ""Javier Alonso Garcia"", ""Stephen Tiedemann"", ""Thomas Kemp"", ""Akira Nakamura""]","[""Deep Neural Network Compression"", ""Quantization"", ""Straight through gradients""]",,1905.11452,cs.LG,2019-05-27 19:03:40+00:00,2020-05-22 17:02:41+00:00
Hyx4knR9Ym,2019,Accept (Poster),False,Generalizable Adversarial Training via Spectral Normalization,"[""Farzan Farnia"", ""Jesse Zhang"", ""David Tse""]","[""Adversarial attacks"", ""adversarial training"", ""spectral normalization"", ""generalization guarantee""]",,,,,
Hyx5qhEYvH,2020,Reject,False,A SPIKING SEQUENTIAL MODEL: RECURRENT LEAKY INTEGRATE-AND-FIRE,"[""Daiheng Gao"", ""Hongwei Wang"", ""Hehui Zhang"", ""Meng Wang"", ""Zhenzhi Wu""]","[""spiking neural network"", ""RNN"", ""spiking mode"", ""brain-inspired"", ""text summarization"", ""DVS""]",,,,,
Hyx6Bi0qYm,2019,Accept (Poster),False,Adversarial Domain Adaptation for Stable Brain-Machine Interfaces,"[""Ali Farshchian"", ""Juan A. Gallego"", ""Joseph P. Cohen"", ""Yoshua Bengio"", ""Lee E. Miller"", ""Sara A. Solla""]","[""Brain-Machine Interfaces"", ""Domain Adaptation"", ""Adversarial Networks""]",We implement an adversarial domain adaptation network to stabilize a fixed Brain-Machine Interface against gradual changes in the recorded neural signals.,,,,
HyxAfnA5tm,2019,Accept (Poster),False,Deep Online Learning Via Meta-Learning: Continual Adaptation for Model-Based RL,"[""Anusha Nagabandi"", ""Chelsea Finn"", ""Sergey Levine""]","[""meta-learning"", ""model-based"", ""reinforcement learning"", ""online learning"", ""adaptation""]",,,,,
HyxBpoR5tm,2019,Reject,False,Adversarially Robust Training through Structured Gradient Regularization,"[""Kevin Roth"", ""Aurelien Lucchi"", ""Sebastian Nowozin"", ""Thomas Hofmann""]","[""Adversarial Training"", ""Gradient Regularization"", ""Deep Learning""]",We propose a novel data-dependent structured gradient regularizer to increase the robustness of neural networks against adversarial perturbations.,,,,
HyxCRCEKwB,2020,Reject,False,ROBUST GENERATIVE ADVERSARIAL NETWORK,"[""Shufei Zhang"", ""Zhuang Qian"", ""Kaizhu Huang"", ""Rui Zhang"", ""Jimin Xiao""]","[""Generative Adversarial Network"", ""Robustness"", ""Deep Learning""]",,,,,
HyxCxhRcY7,2019,Accept (Poster),False,Deep Anomaly Detection with Outlier Exposure,"[""Dan Hendrycks"", ""Mantas Mazeika"", ""Thomas Dietterich""]","[""confidence"", ""uncertainty"", ""anomaly"", ""robustness""]","OE teaches anomaly detectors to learn heuristics for detecting unseen anomalies; experiments are in classification, density estimation, and calibration in NLP and vision settings; we do not tune on test distribution samples, unlike previous work",,,,
HyxFF34FPr,2020,Reject,True,FoveaBox: Beyound Anchor-based Object Detection,"[""Tao Kong"", ""Fuchun Sun"", ""Huaping Liu"", ""Yuning Jiang"", ""Lei Li"", ""Jianbo Shi""]",[],,1904.03797,cs.CV,2019-04-08 01:43:48+00:00,2020-07-16 15:38:26+00:00
HyxG3p4twS,2020,Accept (Poster),False,Quantifying the Cost of Reliable Photo Authentication via High-Performance Learned Lossy Representations,"[""Pawel Korus"", ""Nasir Memon""]","[""image forensics"", ""photo manipulation detection"", ""learned compression"", ""lossy compression"", ""image compression"", ""entropy estimation""]",We learn an efficient lossy image codec that can be optimized to facilitate reliable photo manipulation detection at fractional cost in payload/quality and even at low bitrates.,,,,
HyxGB2AcY7,2019,Accept (Poster),False,Contingency-Aware Exploration in Reinforcement Learning,"[""Jongwook Choi"", ""Yijie Guo"", ""Marcin Moczulski"", ""Junhyuk Oh"", ""Neal Wu"", ""Mohammad Norouzi"", ""Honglak Lee""]","[""Reinforcement Learning"", ""Exploration"", ""Contingency-Awareness""]",We investigate contingency-awareness and controllable aspects in exploration and achieve state-of-the-art performance on Montezuma's Revenge without expert demonstrations.,,,,
HyxJ1xBYDH,2020,Accept (Poster),False,Learning-Augmented Data Stream Algorithms,"[""Tanqiu Jiang"", ""Yi Li"", ""Honghao Lin"", ""Yisong Ruan"", ""David P. Woodruff""]","[""streaming algorithms"", ""heavy hitters"", ""F_p moment"", ""distinct elements"", ""cascaded norms""]",,,,,
HyxJhCEFDS,2020,Accept (Poster),True,Intriguing Properties of Adversarial Training at Scale,"[""Cihang Xie"", ""Alan Yuille""]","[""adversarial defense"", ""adversarial machine learning""]",The first rigor diagnose of large-scale adversarial training on ImageNet,1906.03787,cs.CV,2019-06-10 03:41:52+00:00,2019-12-21 20:48:24+00:00
HyxKIiAqYQ,2019,Accept (Poster),False,Context-adaptive Entropy Model for End-to-end Optimized Image Compression,"[""Jooyoung Lee"", ""Seunghyun Cho"", ""Seung-Kwon Beack""]","[""image compression"", ""deep learning"", ""entropy model""]","Context-adaptive entropy model for use in end-to-end optimized image compression, which significantly improves compression performance",,,,
HyxLRTVKPH,2020,Accept (Poster),True,Budgeted Training: Rethinking Deep Neural Network Training Under Resource Constraints,"[""Mengtian Li"", ""Ersin Yumer"", ""Deva Ramanan""]","[""budgeted training"", ""learning rate schedule"", ""linear schedule"", ""annealing"", ""learning rate decay""]",Introduce a formal setting for budgeted training and propose a budget-aware linear learning rate schedule,1905.04753,cs.CV,2019-05-12 17:49:49+00:00,2020-06-30 00:45:59+00:00
HyxOIoRqFQ,2019,Reject,False,Discrete flow posteriors for variational inference in discrete dynamical systems,"[""Laurence Aitchison"", ""Vincent Adam"", ""Srinivas C. Turaga""]","[""normalising flow"", ""variational inference"", ""discrete latent variable""]",We give a fast normalising-flow like sampling procedure for discrete latent variable models.,,,,
HyxPIyrFvH,2020,Reject,False,When Robustness Doesnât Promote Robustness: Synthetic vs. Natural Distribution Shifts on ImageNet,"[""Rohan Taori"", ""Achal Dave"", ""Vaishaal Shankar"", ""Nicholas Carlini"", ""Benjamin Recht"", ""Ludwig Schmidt""]","[""robustness"", ""distribution shift"", ""image corruptions"", ""adversarial robustness"", ""reliable machine learning""]",We compare current robustness interventions and find that none promote robustness on natural distribution shifts.,2007.00644,cs.LG,2020-07-01 17:53:26+00:00,2020-09-14 09:55:13+00:00
HyxPx3R9tm,2019,Accept (Poster),False,"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow","[""Xue Bin Peng"", ""Angjoo Kanazawa"", ""Sam Toyer"", ""Pieter Abbeel"", ""Sergey Levine""]","[""reinforcement learning"", ""generative adversarial networks"", ""imitation learning"", ""inverse reinforcement learning"", ""information bottleneck""]","Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.",,,,
HyxQ3gSKvr,2020,Reject,True,Variational Information Bottleneck for Unsupervised Clustering: Deep Gaussian Mixture Embedding,"[""Yigit Ugur"", ""George Arvanitakis"", ""Abdellatif Zaidi""]","[""clustering"", ""Variational Information Bottleneck"", ""Gaussian Mixture Model""]",,1905.11741,cs.LG,2019-05-28 11:15:59+00:00,2020-02-27 05:49:25+00:00
HyxQbaEYPr,2020,Reject,True,Leveraging Simple Model Predictions for Enhancing its Performance,"[""Amit Dhurandhar"", ""Karthikeyan Shanmugam"", ""Ronny Luss""]","[""simple models"", ""interpretability"", ""resource constraints""]",Method to improve simple models performance given a (accurate) complex model.,1905.13565,cs.LG,2019-05-30 03:16:36+00:00,2020-06-19 21:17:10+00:00
HyxQzBceg,2017,Accept (Poster),False,Deep Variational Information Bottleneck,"[""Alexander A. Alemi"", ""Ian Fischer"", ""Joshua V. Dillon"", ""Kevin Murphy""]","[""Theory"", ""Computer vision"", ""Deep learning"", ""Supervised Learning""]",Applying the information bottleneck to deep networks using the variational lower bound and reparameterization trick.,,,,
HyxSBh09t7,2019,Reject,False,Graph Generation via Scattering,"[""Dongmian Zou"", ""Gilad Lerman""]","[""graph generative neural network"", ""link prediction"", ""graph and signal generation"", ""scattering network""]",This work proposes a graph generation system based on scattering and demonstrates competitive performance as well as indicates better promise of the generative scattering framework to datasets with a graph structure.,,,,
HyxTJxrtvr,2020,Reject,False,Learning a Spatio-Temporal Embedding for Video Instance Segmentation,"[""Anthony Hu"", ""Alex Kendall"", ""Roberto Cipolla""]","[""computer"", ""vision"", ""video"", ""instance"", ""segmentation"", ""metric"", ""learning""]","We introduce a new spatio-temporal embedding loss on videos that generates temporally consistent video instance segmentation, even with occlusions and missed detections, using appearance, geometry, and temporal context.",1912.08969,cs.CV,2019-12-19 00:59:50+00:00,2019-12-19 00:59:50+00:00
HyxUIj09KX,2019,Reject,False,"S-System, Geometry, Learning, and Optimization: A Theory of Neural Networks","[""Shuai Li"", ""Kui Jia""]","[""neural network theory"", ""probability measure theory"", ""probability coupling theory"", ""S-System"", ""optimization"", ""random matrix"", ""renormalization group"", ""information geometry"", ""coarse graining"", ""hierarchy"", ""activation function"", ""symmetry""]","We present a formal measure-theoretical theory of neural networks (NN) that quantitatively shows NNs renormalize on semantic difference, and under practical conditions large size deep nonlinear NNs can optimize objective functions to zero losses.",,,,
HyxWteSFwS,2020,Reject,False,Deep Interaction Processes for Time-Evolving Graphs,"[""xiaofu chang"", ""jianfeng wen"", ""xuqin liu"", ""yanming fang"", ""le song"", ""yuan qi""]","[""deep temporal point process"", ""multiple time resolutions"", ""dynamic continuous time-evolving graph"", ""anti-fraud detection""]",We present a principled deep neural approach that models continuous time-evolving graphs at multiple time resolutions based on a temporal point processframework.,,,,
HyxY6JHKwr,2020,Accept (Poster),False,You Only Train Once: Loss-Conditional Training of Deep Networks,"[""Alexey Dosovitskiy"", ""Josip Djolonga""]","[""deep learning"", ""image generation""]",A method to train a single model simultaneously minimizing a family of loss functions instead of training a set of per-loss models.,,,,
Hyx_h64Yvr,2020,Reject,False,Kronecker Attention Networks,"[""Hongyang Gao"", ""Zhengyang Wang"", ""Shuiwang Ji""]",[],,2007.08442,cs.CV,2020-07-16 16:26:02+00:00,2020-07-16 16:26:02+00:00
HyxehhNtvS,2020,Reject,False,Why Learning of Large-Scale Neural Networks Behaves Like Convex Optimization,"[""Hui Jiang""]","[""function space"", ""canonical space"", ""neural networks"", ""stochastic gradient descent"", ""disparity matrix""]",Some theoretical work on why learning of large neural networks converges to a global minimum in probability one,,,,
Hyxfs1SYwH,2020,Reject,False,Alleviating Privacy Attacks via Causal Learning,"[""Shruti Tople"", ""Amit Sharma"", ""Aditya Nori""]","[""Causal learning"", ""Membership Inference Attacks"", ""Differential Privacy""]",,,,,
HyxgBerKwB,2020,Reject,False,GraphQA: Protein Model Quality Assessment using Graph Convolutional Network,"[""Federico Baldassarre"", ""David Men\u00e9ndez Hurtado"", ""Arne Elofsson"", ""Hossein Azizpour""]","[""Protein Quality Assessment"", ""Graph Networks"", ""Representation Learning""]",GraphQA is a graph-based method for protein Quality Assessment that improves the state-of-the-art for both hand-engineered and representation-learning approaches,,,,
HyxgoyHtDB,2020,Reject,False,Policy Optimization by Local Improvement through Search,"[""Jialin Song"", ""Joe Wenjie Jiang"", ""Amir Yazdanbakhsh"", ""Ebrahim Songhori"", ""Anna Goldie"", ""Navdeep Jaitly"", ""Azalia Mirhoseini""]","[""policy learning"", ""imitation learning""]",Monte Carlo tree search can generate short time horizon demonstrations for effective imitation learning.,,,,
HyxhqhVKPB,2020,Reject,False,Moniqua: Modulo Quantized Communication in Decentralized SGD,"[""Yucheng Lu"", ""Christopher De Sa""]","[""decentralized training"", ""quantization"", ""communicaiton"", ""stochastic gradient descent""]",We propose a general method that allows decentralized SGD to use quantized communication.,,,,
HyxhusA9Fm,2019,Reject,False,Talk The Walk: Navigating Grids in New York City through Grounded Dialogue,"[""Harm de Vries"", ""Kurt Shuster"", ""Dhruv Batra"", ""Devi Parikh"", ""Jason Weston"", ""Douwe Kiela""]","[""Dialogue"", ""Navigation"", ""Grounded Language Learning""]",First large-scale dialogue dataset grounded in action and perception,,,,
HyxjNyrtPr,2020,Accept (Poster),True,RGBD-GAN: Unsupervised 3D Representation Learning From Natural Image Datasets via RGBD Image Synthesis,"[""Atsuhiro Noguchi"", ""Tatsuya Harada""]","[""image generation"", ""3D vision"", ""unsupervised representation learning""]",RGBD image generation for unsupervised camera parameter conditioning,1909.12573,cs.CV,2019-09-27 09:10:12+00:00,2020-05-25 00:18:28+00:00
HyxjOyrKvr,2020,Accept (Poster),False,Neural Epitome Search for Architecture-Agnostic Network Compression,"[""Daquan Zhou"", ""Xiaojie Jin"", ""Qibin Hou"", ""Kaixin Wang"", ""Jianchao Yang"", ""Jiashi Feng""]","[""Network Compression"", ""Classification"", ""Deep Learning"", ""Weights Sharing""]",We present a novel neural network compression method which can reuse the parameters efficiently to reduce the model size.,,,,
HyxjwgbRZ,2018,Reject,False,Convergence rate of sign stochastic gradient descent for non-convex functions,"[""Jeremy Bernstein"", ""Kamyar Azizzadenesheli"", ""Yu-Xiang Wang"", ""Anima Anandkumar""]","[""sign"", ""stochastic"", ""gradient"", ""non-convex"", ""optimization"", ""gradient"", ""quantization"", ""convergence"", ""rate""]","We prove a non-convex convergence rate for the sign stochastic gradient method. The algorithm has links to algorithms like Adam and Rprop, as well as gradient quantisation schemes used in distributed machine learning.",,,,
HyxlHsActm,2019,Reject,False,Efficient Dictionary Learning with Gradient Descent,"[""Dar Gilboa"", ""Sam Buchanan"", ""John Wright""]","[""dictionary learning"", ""nonconvex optimization""]",We provide an efficient convergence rate for gradient descent on the complete orthogonal dictionary learning objective based on a geometric analysis.,,,,
HyxnH64KwS,2020,Reject,False,The problem with DDPG: understanding failures in deterministic environments with sparse rewards,"[""Guillaume Matheron"", ""Olivier Sigaud"", ""Nicolas Perrin""]","[""ddpg"", ""reinforcement learning"", ""deep learning"", ""policy gradient""]",,,,,
HyxnMyBKwB,2020,Accept (Poster),False,The Gambler's Problem and Beyond,"[""Baoxiang Wang"", ""Shuai Li"", ""Jiajin Li"", ""Siu On Chan""]","[""the gambler's problem"", ""reinforcement learning"", ""fractal"", ""self-similarity"", ""Bellman equation""]",This simple problem's optimal value function is fractal and is like a Cantor function.,2001.00102,stat.ML,2019-12-31 22:48:15+00:00,2020-07-12 12:43:52+00:00
HyxnZh0ct7,2019,Accept (Poster),False,Meta-learning with differentiable closed-form solvers,"[""Luca Bertinetto"", ""Joao F. Henriques"", ""Philip Torr"", ""Andrea Vedaldi""]","[""few-shot learning"", ""one-shot learning"", ""meta-learning"", ""deep learning"", ""ridge regression"", ""classification""]","We propose a meta-learning approach for few-shot classification that achieves strong performance at high-speed by back-propagating through the solution of fast solvers, such as ridge regression or logistic regression.",,,,
HyxnnnVtwB,2020,Reject,True,High performance RNNs with spiking neurons,"[""Manu V Nair"", ""Giacomo Indiveri""]","[""RNNs"", ""Spiking neurons"", ""Neuromorphics""]",A technique to train spiking RNNs to achieve high accuracy without simulating spikes.  ,1905.10692,cs.NE,2019-05-25 23:15:33+00:00,2019-12-20 02:26:53+00:00
HyxoX6EKvB,2020,Reject,False,Reflection-based Word Attribute Transfer,"[""Yoichi Ishibashi"", ""Katsuhito Sudoh"", ""Koichiro Yoshino"", ""Satoshi Nakamura""]","[""embedding"", ""representation learning"", ""analogy"", ""geometry""]",We propose a novel representation learning framework that obtains a vector with an inverted attribute in embedding space without explicit attribute knowledge of the given word. ,2007.02598,cs.CL,2020-07-06 09:17:14+00:00,2020-07-07 04:28:48+00:00
HyxpNnRcFX,2019,Reject,False,Modulating transfer between tasks in gradient-based meta-learning,"[""Erin Grant"", ""Ghassen Jerfel"", ""Katherine Heller"", ""Thomas L. Griffiths""]","[""meta-learning"", ""clustering"", ""learning-to-learn"", ""mixture"", ""hierarchical Bayes"", ""hierarchical model"", ""gradient-based meta-learning""]",We use the connection between gradient-based meta-learning and hierarchical Bayes to learn a mixture of meta-learners that is appropriate for a heterogeneous and evolving task distribution.,,,,
Hyxsl2AqKm,2019,Reject,False,ON THE EFFECTIVENESS OF TASK GRANULARITY FOR TRANSFER LEARNING,"[""Farzaneh Mahdisoltani"", ""Guillaume Berger"", ""Waseem Gharbieh"", ""David Fleet"", ""Roland Memisevic""]","[""Transfer Learning"", ""Video Understanding"", ""Fine-grained Video Classification"", ""Video Captioning"", ""Common Sense"", ""Something-Something Dataset.""]","If the model architecture is fixed, how would the complexity and granularity of task, effect the quality of learned features for transferring to a new task.",,,,
Hyxtso0qtX,2019,Reject,False,Adversarial Exploration Strategy for Self-Supervised Imitation Learning,"[""Zhang-Wei Hong"", ""Tsu-Jui Fu"", ""Tzu-Yun Shann"", ""Yi-Hsiang Chang"", ""Chun-Yi Lee""]","[""adversarial exploration"", ""self-supervised"", ""imitation learning""]",A simple yet effective imitation learning scheme that incentivizes exploration of an environment without any extrinsic reward or human demonstration.,,,,
Hyxu6oAqYX,2019,Reject,False,An Energy-Based Framework for Arbitrary Label Noise Correction,"[""Jaspreet Sahota"", ""Divya Shanmugam"", ""Janahan Ramanan"", ""Sepehr Eghbali"", ""Marcus Brubaker""]","[""label noise"", ""feature dependent noise"", ""label correction"", ""unsupervised machine learning"", ""semi-supervised machine learning""]",We show how to learn a discriminative representation using an energy based semi-supervised model and we show how to use it to correct input dependent label noise of various types on several datasets.,,,,
HyxwZRNtDr,2020,Reject,False,Wasserstein Robust Reinforcement Learning,"[""Mohammed Amin Abdullah"", ""Hang Ren"", ""Haitham Bou-Ammar"", ""Vladimir Milenkovic"", ""Rui Luo"", ""Mingtian Zhang"", ""Jun Wang""]","[""Reinforcement Learning"", ""Robustness"", ""Wasserstein distance""]",An RL algorithm that learns to be robust to changes in dynamics,,,,
HyxyIgHFvr,2020,Accept (Spotlight),True,Truth or backpropaganda? An empirical investigation of deep learning theory,"[""Micah Goldblum"", ""Jonas Geiping"", ""Avi Schwarzschild"", ""Michael Moeller"", ""Tom Goldstein""]","[""Deep learning"", ""generalization"", ""loss landscape"", ""robustness""]","We call into question commonly held beliefs regarding the loss landscape, optimization, network width, and rank.",1910.00359,cs.LG,2019-10-01 13:09:46+00:00,2020-04-28 16:29:45+00:00
HyxzRsR9Y7,2019,Accept (Poster),True,Learning Self-Imitating Diverse Policies,"[""Tanmay Gangwani"", ""Qiang Liu"", ""Jian Peng""]","[""Reinforcement-learning"", ""Imitation-learning"", ""Ensemble-training""]",Policy optimization by using past good rollouts from the agent; learning shaped rewards via divergence minimization; SVPG with JS-kernel for population-based exploration.,1805.10309,stat.ML,2018-05-25 18:17:55+00:00,2019-02-23 00:27:50+00:00
HyyP33gAZ,2018,Accept (Poster),False,Activation Maximization Generative Adversarial Nets,"[""Zhiming Zhou"", ""Han Cai"", ""Shu Rong"", ""Yuxuan Song"", ""Kan Ren"", ""Weinan Zhang"", ""Jun Wang"", ""Yong Yu""]","[""Generative Adversarial Nets"", ""GANs"", ""Evaluation Metrics"", ""Generative Model"", ""Deep Learning"", ""Adversarial Learning"", ""Inception Score"", ""AM Score""]",Understand how class labels help GAN training. Propose a new evaluation metric for generative models. ,,,,
HyydRMZC-,2018,Accept (Poster),False,Spatially Transformed Adversarial Examples,"[""Chaowei Xiao"", ""Jun-Yan Zhu"", ""Bo Li"", ""Warren He"", ""Mingyan Liu"", ""Dawn Song""]","[""adversarial examples"", ""spatial transformation""]","We propose a new approach for generating adversarial examples based on spatial transformation, which produces perceptually realistic examples compared to existing attacks. ",,,,
HyzMyhCcK7,2019,Accept (Poster),True,ProxQuant: Quantized Neural Networks via Proximal Operators,"[""Yu Bai"", ""Yu-Xiang Wang"", ""Edo Liberty""]","[""Model quantization"", ""Optimization"", ""Regularization""]","A principled framework for model quantization using the proximal gradient method, with empirical evaluation and theoretical convergence analyses.",1810.00861,cs.LG,2018-10-01 17:57:02+00:00,2019-03-05 00:28:48+00:00
HyzbhfWRW,2018,Accept (Poster),False,Learn to Pay Attention,"[""Saumya Jetley"", ""Nicholas A. Lord"", ""Namhoon Lee"", ""Philip H. S. Torr""]","[""deep learning"", ""attention-aware representations"", ""image classification"", ""weakly supervised segmentation"", ""domain shift"", ""classifier generalisation"", ""robustness to adversarial attack""]",The paper proposes a method for forcing CNNs to leverage spatial attention in learning more object-centric representations that perform better in various respects.,,,,
HyzdRiR9Y7,2019,Accept (Poster),False,Universal Transformers,"[""Mostafa Dehghani"", ""Stephan Gouws"", ""Oriol Vinyals"", ""Jakob Uszkoreit"", ""Lukasz Kaiser""]","[""sequence-to-sequence"", ""rnn"", ""transformer"", ""machine translation"", ""language understanding"", ""learning to execute""]","We introduce the Universal Transformer, a self-attentive parallel-in-time recurrent sequence model that outperforms Transformers and LSTMs on a wide range of sequence-to-sequence tasks, including machine translation.",,,,
HyztsoC5Y7,2019,Accept (Poster),False,"Learning to Adapt in Dynamic, Real-World Environments through Meta-Reinforcement Learning","[""Anusha Nagabandi"", ""Ignasi Clavera"", ""Simin Liu"", ""Ronald S. Fearing"", ""Pieter Abbeel"", ""Sergey Levine"", ""Chelsea Finn""]","[""meta-learning"", ""reinforcement learning"", ""meta reinforcement learning"", ""online adaptation""]",A model-based meta-RL algorithm that enables a real robot to adapt online in dynamic environments,,,,
I-VfjSBzi36,2021,Reject,False,EarlyBERT: Efficient BERT Training via Early-bird Lottery Tickets,"[""Xiaohan Chen"", ""Yu Cheng"", ""Shuohang Wang"", ""Zhe Gan"", ""Zhangyang Wang"", ""Jingjing Liu""]","[""Natural Language Processing"", ""Lottery Tickets Hypothesis"", ""Efficient Training""]",,2101.00063,cs.CL,2020-12-31 20:38:20+00:00,2021-06-07 18:26:28+00:00
I-nQMZfQz7F,2022,Reject,False,Learning Neural Implicit Functions as Object Representations for Robotic Manipulation,"['Jung-Su Ha', 'Danny Driess', 'Marc Toussaint']","[""Representation Learning"", ""nerual implicit representation"", ""robotic manipulation"", ""task and motion planning""]",This work transfers the idea of neural implicit representations to robotic manipulation applications.,2112.04812,cs.RO,2021-12-09 10:14:13+00:00,2022-01-30 23:57:14+00:00
I1dg7let3Q,2022,Reject,False,Semi-supervised learning objectives as log-likelihoods in a generative model of data curation,"['Stoil Krasimirov Ganev', 'Laurence Aitchison']","[""Bayesian neural network"", ""semi-supervised learning"", ""Bayesian inference""]",We provide an account of SSL objectives as a lower-bound on a principled log-likelihood in a generative model of data curation.,,,,
I1hQbx10Kxn,2022,Accept (Spotlight),True,On Bridging Generic and Personalized Federated Learning for Image Classification,"['Hong-You Chen', 'Wei-Lun Chao']","[""federated learning"", ""personalization"", ""image classification""]",,2107.00778,cs.LG,2021-07-02 00:25:48+00:00,2021-07-02 00:25:48+00:00
I2Hw58KHp8O,2022,Accept (Poster),False,Improving Non-Autoregressive Translation Models Without Distillation,"['Xiao Shi Huang', 'Felipe Perez', 'Maksims Volkovs']","[""Natural Language Processing"", ""Deep Learning"", ""Non-autoregressive Machine Translation"", ""Transformer"", ""Distillation""]",Improving the CMLM non-autoregressive machine translation model so it trains without knowledge distillation and achieves SOTA BLEU score on both raw and distilled dataset,,,,
I3zV6igAT9,2021,Reject,True,Quantile Regularization : Towards Implicit Calibration of Regression Models,"[""Saiteja Utpala"", ""Piyush Rai""]","[""Calibration"", ""Reliable Uncertainty Quantification"", ""Probabilistic Deep Learning""]",an implicit calibration approach for regression models,2002.12860,cs.LG,2020-02-28 16:53:41+00:00,2020-02-28 16:53:41+00:00
I4c4K9vBNny,2021,Accept (Poster),False,Spatial Dependency Networks: Neural Layers for Improved Generative Image Modeling,"[""\u0110or\u0111e Miladinovi\u0107"", ""Aleksandar Stani\u0107"", ""Stefan Bauer"", ""J\u00fcrgen Schmidhuber"", ""Joachim M. Buhmann""]","[""Neural networks"", ""Deep generative models"", ""Image Modeling"", ""Variational Autoencoders""]","A novel neural network layer for improved generative modeling of images, applied to variational autoencoders.",2103.08877,cs.CV,2021-03-16 07:01:08+00:00,2021-03-16 07:01:08+00:00
I4pQCAhSu62,2021,Reject,False,Balancing Robustness and Sensitivity using Feature Contrastive Learning,"[""Seungyeon Kim"", ""Daniel Glasner"", ""Srikumar Ramalingam"", ""Cho-Jui Hsieh"", ""Kishore Papineni"", ""Sanjiv Kumar""]","[""deep learning"", ""non-adversarial robustness"", ""sensitivity"", ""input perturbation"", ""contextual feature utility"", ""contextual feature sensitivity.""]","Taken to the extreme, robustness can hurt sensitivity, we propose a balance by contrasting feature perturbations with high and low contextual utility.",,,,
I6-3mg29P6y,2021,Reject,True,Flatness is a False Friend,"[""Diego Granziol""]",[],"This paper shows that as the weights grow in size and overfit, Hessian based sharpness metrics, such as the trace and spectral norm, tend to zero.",2006.09091,stat.ML,2020-06-16 11:55:24+00:00,2020-06-16 11:55:24+00:00
I6NRcao1w-X,2021,Reject,False,Robust Reinforcement Learning using Adversarial Populations,"[""Eugene Vinitsky"", ""Yuqing du"", ""Kanaad V Parvate"", ""Kathy Jang"", ""Pieter Abbeel"", ""Alexandre Bayen""]","[""Robust Control"", ""Reinforcement Learning"", ""Multiagent Systems""]",We demonstrate that the standard robust RL formulation does not consistently yield robustness but that this can be alleviated using a population of adversaries.,,,,
I6QHpMdZD5k,2021,Reject,False,Learning to Solve Nonlinear Partial Differential Equation Systems To Accelerate MOSFET Simulation,"[""Seungcheol Han"", ""Jonghyun Choi"", ""Sung-Min Hong""]","[""Partial differential equation"", ""nonlinear equation"", ""Newton-Raphson method"", ""convolutional neural network""]",Learning a convolutional neural network to approximately solve nonlinear PDE systems to accelerate MOSFET simulation by more than 12x times.,,,,
IDFQI9OY6K,2021,Accept (Poster),False,Interactive Weak Supervision: Learning Useful Heuristics for Data Labeling,"[""Benedikt Boecking"", ""Willie Neiswanger"", ""Eric Xing"", ""Artur Dubrawski""]","[""weak supervision"", ""data programming"", ""data labeling"", ""active learning""]",We introduce a framework and method for training classifiers on datasets without ground truth annotation by interacting  with domain experts to discover good weak supervision sources. ,2012.06046,cs.LG,2020-12-11 00:10:38+00:00,2021-01-25 20:03:15+00:00
IDwN6xjHnK8,2022,Accept (Poster),False,Transformer-based Transform Coding,"['Yinhao Zhu', 'Yang Yang', 'Taco Cohen']","[""transformer"", ""transform coding"", ""image compression"", ""video compression""]",,,,,
IEKL-OihqX0,2022,Reject,False,Gradient-Guided Importance Sampling for Learning Discrete Energy-Based Models,"['Meng Liu', 'Haoran Liu', 'Shuiwang Ji']","[""Discrete energy-based models"", ""ratio matching"", ""importance sampling"", ""gradient""]",,,,,
IEsx-jwFk3g,2022,Reject,False,Deep Representations for Time-varying Brain Datasets,"['Sikun Lin', 'Shuyun Tang', 'Ambuj Singh']","[""fMRI"", ""graph neural networks"", ""feature attribution""]",We build an efficient graph neural network model that incorporates both structural connectivities and dynamic functional brain signals to learn deep representations of brain activities with insightful interpretations.,,,,
IFqrg1p5Bc,2021,Accept (Poster),False,Distance-Based Regularisation of Deep Networks for Fine-Tuning,"[""Henry Gouk"", ""Timothy Hospedales"", ""massimiliano pontil""]","[""Deep Learning"", ""Transfer Learning"", ""Statistical Learning Theory""]","We derive generalisation bounds applicable to fine-tuning, then demonstrate an algorithm that regularises these bounds improves fine-tuning performance.",,,,
IG3jEGLN0jd,2021,Reject,True,Contrastive estimation reveals topic posterior information to linear models,"[""Christopher Tosh"", ""Akshay Krishnamurthy"", ""Daniel Hsu""]","[""contrastive learning"", ""self-supervised learning"", ""representation learning"", ""theory""]",This paper demonstrates that contrastive learning on text data produces representations that are linearly related to underlying topic structure.,2003.02234,cs.LG,2020-03-04 18:20:55+00:00,2020-03-04 18:20:55+00:00
IJ-88dRfkdz,2022,Reject,True,SoftHebb: Bayesian inference in unsupervised Hebbian soft winner-take-all networks,"['Timoleon Moraitis', 'Dmitry Toichkin', 'Yansong Chua', 'Qinghai Guo']",[],"Rigorous theoretical insights for optimal unsupervised learning in soft winner-take-all networks, and surprising experimental advantages",2107.05747,cs.LG,2021-07-12 21:34:45+00:00,2021-10-06 15:17:11+00:00
IJxaSrLIbkx,2021,Reject,False,"On Relating ""Why?"" and ""Why Not?"" Explanations","[""Alexey Ignatiev"", ""Nina Narodytska"", ""Nicholas Asher"", ""Joao Marques-Silva""]","[""Explanability"", ""contrastive explanations"", ""duality""]",,2012.11067,cs.LG,2020-12-21 01:07:13+00:00,2020-12-21 01:07:13+00:00
IK9ap6nxXr2,2022,Accept (Poster),False,Interacting Contour Stochastic Gradient Langevin Dynamics,"['Wei Deng', 'Siqi Liang', 'Botao Hao', 'Guang Lin', 'Faming Liang']","[""stochastic gradient Langevin dynamics"", ""MCMC"", ""importance sampling"", ""Wang-Landau algorithm"", ""Parallel MCMC Methods"", ""stochastic approximation""]",We propose an interacting contour stochastic gradient Langevin dynamics sampler and prove it can be theoretically more efficient than a single-chain process with an equivalent computational budget.,,,,
IMPA6MndSXU,2021,Accept (Poster),False,Integrating Categorical Semantics into Unsupervised Domain Translation,"[""Samuel Lavoie-Marchildon"", ""Faruk Ahmed"", ""Aaron Courville""]","[""Unsupervised Domain Translation"", ""Unsupervised Learning"", ""Image-to-Image Translation"", ""Deep Learning"", ""Representation Learning""]",We present a method for learning domain invariant categorial semantics which enable UDT on two setups.,,,,
IMPnRXEWpvr,2021,Accept (Poster),False,Towards Impartial Multi-task Learning,"[""Liyang Liu"", ""Yi Li"", ""Zhanghui Kuang"", ""Jing-Hao Xue"", ""Yimin Chen"", ""Wenming Yang"", ""Qingmin Liao"", ""Wayne Zhang""]","[""Multi-task Learning"", ""Impartial Learning"", ""Scene Understanding""]",We propose an impartial multi-task learning method that treats all tasks equally without bias towards any task.,,,,
INO8hGXD2M,2022,Reject,False,Adversarial Distributions Against Out-of-Distribution Detectors,"['Sangwoong Yoon', 'Jinwon Choi', 'Yonghyeon LEE', 'Yung-Kyun Noh', 'Frank C. Park']","[""out-of-distribution detection"", ""outlier detection"", ""adversarial attack"", ""model evaluation"", ""markov chain monte carlo""]",We propose a novel evaluation method for out-of-distribution detectors.,,,,
INXUNEmgbnx,2021,Reject,True,Neural Bayes: A Generic Parameterization Method for Unsupervised Learning,"[""Devansh Arpit"", ""Huan Wang"", ""Caiming Xiong"", ""richard socher"", ""Yoshua Bengio""]","[""unsupervised learning"", ""clustering"", ""manifold separation"", ""representation learning"", ""Bayes rule""]","We propose a simple neural network parameterization based on the Bayes rule to model conditional distributions, and then use it to formulate two objectives: 1. manifold separation; mutual information maximization.",2002.09046,stat.ML,2020-02-20 22:28:53+00:00,2020-02-20 22:28:53+00:00
INhwJdJtxn6,2021,Reject,False,Coverage as a Principle for Discovering Transferable Behavior in Reinforcement Learning,"[""V\u00edctor Campos"", ""Pablo Sprechmann"", ""Steven Stenberg Hansen"", ""Andre Barreto"", ""Charles Blundell"", ""Alex Vitvitskyi"", ""Steven Kapturowski"", ""Adria Puigdomenech Badia""]","[""deep reinforcement learning"", ""transfer learning"", ""unsupervised learning"", ""exploration""]","We pre-train agents to maximize coverage in the absence of reward, and show that the discovered behaviors can be used for transfer to downstream tasks via exploration and exploitation mechanisms.",,,,
IOA9fJUUa0,2022,Reject,False,"How does BERT address polysemy of Korean adverbial postpositions -ey, -eyse, and -(u)lo?","['Seongmin Mun', 'Guillaume Desagulier', 'Gyu-Ho Shin']","[""polysemy"", ""natural language processing"", ""classification"", ""language model"", ""BERT"", ""data visualization"", ""Korean""]",This study reports computational accounts of resolving word-level polysemy of Korean adverbial postpositions by employing BERT and visualization system.,,,,
IOqr2ZyXHz1,2021,Reject,False,Continual Lifelong Causal Effect Inference with Real World Evidence,"[""Zhixuan Chu"", ""Stephen Rathbun"", ""Sheng Li""]","[""continual learning"", ""incremental learning"", ""causal effect inference"", ""representation learning"", ""treatment effect estimation""]",,,,,
IPGZ6S3LDdw,2021,Reject,False,Fast MNAS: Uncertainty-aware Neural Architecture Search with Lifelong Learning,"[""Jihao Liu"", ""Yangting Sun"", ""Ming Zhang"", ""Boxiao Liu"", ""Yu Liu""]","[""Neural Architecture Search"", ""AutoML"", ""Reinforcement Learning (RL)""]",We proposed FNAS which accelerates standard RL based NAS process by $\sim$10x and guarantees better performance on various vision tasks.,,,,
IPy3URgH47U,2022,Reject,False,ACTIVE REFINEMENT OF WEAKLY SUPERVISED MODELS,"['Mononito Goswami', 'Chufan Gao', 'Benedikt Boecking', 'Saswati Ray', 'Artur Dubrawski']","[""Weak Supervision"", ""Active Learning"", ""Fuzzy logic"", ""AI in Healthcare""]","We present WARM, Active Refinement of Weakly Supervised Models, a principled approach to iterative and interactive improvement of weakly supervised models via active learning.",,,,
IR-V6-aP-mv,2022,Reject,True,Batch size-invariance for policy optimization,"['Jacob Hilton', 'Karl Cobbe', 'John Schulman']","[""reinforcement learning"", ""policy gradient"", ""learning rate""]",We show how to make PPO batch size-invariant (changes to the batch size can largely be compensated for by changing other hyperparameters) by decoupling the proximal policy (used for controlling the size of policy updates) from the behavior policy.,2110.00641,cs.LG,2021-10-01 20:33:08+00:00,2022-02-07 21:00:18+00:00
IU8QxEiG4hR,2021,Reject,False,SBEVNet: End-to-End Deep Stereo Layout Estimation,"[""Divam Gupta"", ""Wei Pu"", ""Trenton Tabor"", ""Jeff Schneider""]","[""Layout Estimation"", ""Deep Stereo"", ""Computer Vision""]",A novel end-to-end method for stereo layout estimation. ,2105.11705,cs.CV,2021-05-25 07:10:30+00:00,2021-10-17 21:12:07+00:00
IUYthV32lbK,2021,Reject,False,On the Certified Robustness for Ensemble Models and Beyond,"[""Zhuolin Yang"", ""Linyi Li"", ""Xiaojun Xu"", ""Bhavya Kailkhura"", ""Bo Li""]","[""Adversarial Machine Learning"", ""Model Ensemble"", ""Certified Robustness""]",We analyze the sufficient and necessary conditions on certified ensemble robustness and propose Diversity-Regularized Training (DRT) to boost the certified robustness of ensemble models.,,,,
IUaOP8jQfHn,2021,Reject,False,Benchmarking Unsupervised Object Representations for Video Sequences,"[""Marissa A. Weis"", ""Kashyap Chitta"", ""Yash Sharma"", ""Wieland Brendel"", ""Matthias Bethge"", ""Andreas Geiger"", ""Alexander S Ecker""]","[""Unsupervised learning"", ""object-centric representations"", ""benchmark"", ""tracking""]",We quantitatively analyze the performance of four object-centric representation learning models for video sequences on challenging tracking scenarios. ,,,,
IVwXaHpiO0,2021,Reject,False,SyncTwin: Transparent Treatment Effect Estimation under Temporal Confounding,"[""Zhaozhi Qian"", ""Yao Zhang"", ""Ioana Bica"", ""Angela Wood"", ""Mihaela van der Schaar""]","[""treatment effect"", ""interpretability"", ""healthcare"", ""causal inference""]","We develop SyncTwin, a transparent treatment effect estimation method that deals with confounders with temporal structures and has a broad range of applications in clinical observational studies and beyond.",,,,
IW-EI6BCxy,2021,Reject,False,Variable-Shot Adaptation for Online Meta-Learning,"[""Tianhe Yu"", ""Xinyang Geng"", ""Chelsea Finn"", ""Sergey Levine""]","[""meta-learning"", ""deep learning""]",We present a meta-learning algorithm that handles the variable-shot settings that naturally arise in sequential learning.,,,,
IX3Nnir2omJ,2021,Accept (Poster),False,Characterizing signal propagation to close the performance gap in unnormalized ResNets,"[""Andrew Brock"", ""Soham De"", ""Samuel L Smith""]","[""normalizers"", ""signal propagation"", ""deep learning"", ""neural networks"", ""ResNets"", ""EfficientNets"", ""ImageNet"", ""CNNs"", ""ConvNets""]","We show how to train ResNets completely without normalization, and attain performance competitive with batch-normalized EfficientNets.",,,,
IY4IsjvUhZ,2022,Reject,False,Characterising the Area Under the Curve Loss Function Landscape,"['Maximilian Paul Niroomand', 'Conor T Cafolla', 'John William Roger Morgan', 'David John Wales']","[""loss function landscape"", ""loss function"", ""AUC"", ""area under the curve"", ""alternative loss functions"", ""loss function visualisation""]",We analyse properties of the loss function landscape for surrogate AUC loss function and compare these with a standard cross entropy loss function. ,,,,
IY6Zt3Qu0cT,2022,Reject,False,Fragment-Based Sequential Translation for Molecular Optimization,"['Benson Chen', 'Xiang Fu', 'Tommi S. Jaakkola', 'Regina Barzilay']","[""molecular optimization"", ""molecular generation"", ""drug discovery"", ""reinforcement learning""]",Molecular optimization through learning a search policy that uses a learned molecular fragment vocabulary and a stored exploration frontier,,,,
IYMuTbGzjFU,2022,Accept (Poster),False,Representing Mixtures of Word Embeddings with Mixtures of Topic Embeddings,"['dongsheng wang', 'Dan dan Guo', 'He Zhao', 'Huangjie Zheng', 'Korawat Tanwisuth', 'Bo Chen', 'Mingyuan Zhou']","[""topic model"", ""text mining"", ""distribution matching""]",A novel method to learn in the word embedding space a set of globally shared topic embedding vectors that are manifested differently in each document,,,,
IZQm8mMRVqW,2021,Reject,True,Quickly Finding a Benign Region via Heavy Ball Momentum in Non-Convex Optimization,"[""Jun-Kun Wang"", ""Jacob Abernethy""]",[],,2010.01449,cs.LG,2020-10-04 00:07:06+00:00,2021-02-14 20:06:44+00:00
I_RLPhVUfw8,2022,Reject,False,Dense Gaussian Processes for Few-Shot Segmentation,"['Joakim Johnander', 'Johan Edstedt', 'Michael Felsberg', 'Fahad Khan', 'Martin Danelljan']","[""few-shot learning"", ""few-shot segmentation"", ""segmentation"", ""gaussian processes""]",This paper proposes to tackle few-shot segmentation using dense Gaussian process regression.,,,,
IbFcpYnwCvd,2021,Reject,False,The Logical Options Framework,"[""Brandon Araki"", ""Xiao Li"", ""Kiran Vodrahalli"", ""Jonathan DeCastro"", ""J Micah Fry"", ""Daniela Rus""]","[""reinforcement learning"", ""hierarchical methods"", ""formal methods"", ""formal logic""]","We introduce a composable hierarchical method for learning tasks specified by formal logic, as well as proofs and conditions for satisfaction and optimality.",,,,
IbyMcLKUCqT,2022,Reject,False,Theoretical Analysis of Consistency Regularization with Limited Augmented Data,"['Shuo Yang', 'Yijun Dong', 'Rachel Ward', 'Inderjit S Dhillon', 'sujay sanghavi', 'Qi Lei']","[""data augmentation"", ""consistency regularization"", ""generalization bound""]",We develop a theoretical framework to understand the statistical efï¬ciency of consistency regularization with limited data augmentations.,,,,
IcUWShptD7d,2022,Accept (Poster),False,Monotonic Differentiable Sorting Networks,"['Felix Petersen', 'Christian Borgelt', 'Hilde Kuehne', 'Oliver Deussen']","[""differentiable sorting"", ""monotonic"", ""sorting"", ""ranking"", ""sorting networks""]",,,,,
IeuEO1TccZn,2021,Reject,False,Sufficient and Disentangled Representation Learning,"[""Jian Huang"", ""Yuling Jiao"", ""Xu Liao"", ""Jin Liu"", ""Zhou Yu""]","[""Conditional independence"", ""f-divergence"", ""rotation invariant"", ""neural network"", ""statistical guarantee""]",This paper proposes a sufficient and disentangled representation learning approach in the context of supervised learning. ,,,,
IfEkus1dpU,2021,Reject,False,Cut-and-Paste Neural Rendering,"[""Anand Bhattad"", ""David Forsyth""]","[""Neural Rendering"", ""Reshading"", ""Relighting"", ""Computational Photography"", ""Image Decomposition""]",Convincing cut-and-paste neural rendering by consistent image decomposition inferences. ,,,,
IfNu7Dr-3fQ,2022,Accept (Poster),False,Generalized Kernel Thinning,"['Raaz Dwivedi', 'Lester Mackey']","[""coresets"", ""maximum mean discrepancy"", ""Markov chain Monte Carlo"", ""reproducing kernel Hilbert space"", ""thinning"", ""compression""]","By generalizing kernel thinning, we develop new tools for compressing distributions more effectively than i.i.d. sampling and establish new dimension-free, $O(\sqrt{\log n/n})$ improvements over the usual $n^{-1/4}$ Monte Carlo integration error.",,,,
Ig-VyQc-MLK,2021,Accept (Poster),False,Pruning Neural Networks at Initialization: Why Are We Missing the Mark?,"[""Jonathan Frankle"", ""Gintare Karolina Dziugaite"", ""Daniel Roy"", ""Michael Carbin""]","[""Pruning"", ""Sparsity"", ""Lottery Ticket"", ""Science""]","Methods for pruning neural nets at initialization perform the same or better when shuffling or reinitializing the weights they prune in each layer, a way in which they differ from SOTA weight-pruning methods after training.",,,,
Ig53hpHxS4,2021,Accept (Poster),False,Flowtron: an Autoregressive Flow-based Generative Network for Text-to-Speech Synthesis,"[""Rafael Valle"", ""Kevin J. Shih"", ""Ryan Prenger"", ""Bryan Catanzaro""]","[""Text to speech synthesis"", ""normalizing flows"", ""deep learning""]",In this paper we propose Flowtron: an autoregressive flow-based generative network for text-to-speech synthesis with style transfer and speech varation.,,,,
IgIk8RRT-Z,2021,Accept (Poster),False,CompOFA â Compound Once-For-All Networks for Faster Multi-Platform Deployment,"[""Manas Sahni"", ""Shreya Varshini"", ""Alind Khare"", ""Alexey Tumanov""]","[""Efficient Deep Learning"", ""Latency-aware Neural Architecture Search"", ""AutoML""]",CNN design-space and system insights for faster latency-guided training and searching of models for diverse deployment targets.,2104.12642,cs.CV,2021-04-26 15:10:48+00:00,2021-04-26 15:10:48+00:00
Ih0iJBSy4eq,2022,Reject,False,Can Reinforcement Learning Efficiently Find Stackelberg-Nash Equilibria in General-Sum Markov Games?,"['Han Zhong', 'Zhuoran Yang', 'Zhaoran Wang', 'Michael Jordan']",[],,,,,
Ih7LAeOYIb0,2022,Reject,False,Iterative Memory Network for Long Sequential User Behavior Modeling in Recommender Systems,"['Qianying Lin', 'Wen-Ji Zhou', 'Yanshi Wang', 'Qing Da', 'Qing-Guo Chen', 'Bing Wang']","[""recommender systems"", ""sequential behavior modeling""]","The Iterative Memory Network architecture is a target item triggered, intra-sequence dependency and target-sequence dependency modeling method for user sequential behavior modeling in recommender systems. ",,,,
IhUeMfEmexK,2021,Reject,True,ProxylessKD: Direct Knowledge Distillation with Inherited Classifier for Face Recognition,"[""Weidong Shi"", ""Guanghui Ren"", ""Yunpeng Chen"", ""Shuicheng Yan""]","[""inherited classifier"", ""embedding space alignment"", ""face recognition"", ""knowledge distillation""]","We proposed an inherited classifier knowledge distillation to enhance the feature space alignment between the student model and teacher model, which aims to improve the performance in some retrieval targets, e.g., face recognition.",2011.00265,cs.CV,2020-10-31 13:14:34+00:00,2020-10-31 13:14:34+00:00
IhkSFe9YqMy,2022,Reject,False,Experience Replay More When It's a Key Transition in Deep Reinforcement Learning,"['Youtian Guo', 'Qi Gao']","[""Experience Replay More"", ""Key Transitions"", ""Sampling"", ""Add Noise to Noise"", ""Deep Reinforcement Learning""]","We propose a experience replay mechanism in Deep Reinforcement Learning based on Add Noise to Noise (AN2N), which requires agent to replay more key transitions, abbreviated as Experience Replay More (ERM).",,,,
Ihxw4h-JnC,2022,Reject,False,Stochastic Induction of Decision Trees with Application to Learning Haar Tree,"['Azar Alizadeh', 'Pooya Tavallali', 'Vahid Behzadan', 'Mukesh Singhal']","[""Decision Tree"", ""Stochastic Optimization"", ""Haar Filters"", ""Haar Cascade""]","We propose a novel fast decision tree induction algorithm, outperforming the state-of-the-art by several orders of magnitude.",,,,
IjIzIOkK2D6,2021,Reject,False,Efficient Graph Neural Architecture Search,"[""Huan Zhao"", ""Lanning Wei"", ""quanming yao"", ""Zhiqiang He""]","[""graph neural network"", ""neural architecture search"", ""automated machine learning""]","We propose an effective and efficient framework for graph neural architecture search, which is very important for graph-based tasks.",,,,
IkYEJ5Cps5H,2021,Reject,False,Succinct Network Channel and Spatial Pruning via Discrete Variable QCQP,"[""Yeonwoo Jeong"", ""Deokjae Lee"", ""Gaon An"", ""Changyong Son"", ""Hyun Oh Song""]","[""Network Pruning"", ""Channel pruning"", ""Spatial pruning"", ""Network Compression"", ""MIQCQP"", ""Specified target resource constraint""]",We propose a discrete QCQP formulation for joint channel and spatial pruning which directly maximizes the true objective under the target resource constraints.,,,,
IlJbTsygaI6,2021,Reject,False,Explainable Reinforcement Learning Through Goal-Based Interpretability,"[""Gregory Bonaert"", ""Youri Coppens"", ""Denis Steckelmacher"", ""Ann Nowe""]","[""explainable reinforcement learning"", ""hierarchical reinforcement learning"", ""goal-based interpretability""]",,,,,
Im43P9kuaeP,2021,Reject,False,Certified Watermarks for Neural Networks,"[""Arpit Amit Bansal"", ""Ping-yeh Chiang"", ""Michael Curry"", ""Hossein Souri"", ""Rama Chellappa"", ""John P Dickerson"", ""Rajiv Jain"", ""Tom Goldstein""]","[""certified defense"", ""watermarking"", ""backdoor attack""]","We propose the first certifiable watermark for neural networks, which is also empirically more robust.",,,,
InGI-IMDL18,2021,Reject,False,Secure Federated Learning of User Verification Models,"[""Hossein Hosseini"", ""Hyunsin Park"", ""Sungrack Yun"", ""Christos Louizos"", ""Joseph Soriaga"", ""Max Welling""]","[""Federated learning"", ""User verification models""]",We propose a private and secure method for training user verification models in federated setup.,2104.08776,cs.LG,2021-04-18 08:51:39+00:00,2021-06-07 17:32:41+00:00
Io8oYQb4LRK,2021,Reject,True,Non-greedy Gradient-based Hyperparameter Optimization Over Long Horizons,"[""Paul Micaelli"", ""Amos Storkey""]","[""Hyperparameter optimization"", ""Meta-learning""]",Learning hyperparameter over long horizons without greediness,2007.07869,cs.LG,2020-07-15 17:44:07+00:00,2021-09-30 15:51:36+00:00
Iog0djAdbHj,2022,Accept (Poster),False,Better Supervisory Signals by Observing Learning Paths,"['Yi Ren', 'Shangmin Guo', 'Danica J. Sutherland']","[""Classification"", ""Supervision"", ""Knowledge Distillation""]",A study of how and why teachers in knowledge distillation end up with better supervisory signals than the original labels.,,,,
IohHac70h3R,2021,Reject,False,On the Marginal Regret Bound Minimization of Adaptive Methods,"[""Wenjie Li"", ""Guang Cheng""]","[""Optimization Algorithm"", ""Adaptive algorithms"", ""Online Learning"", ""Regret Minimization""]",We find a new motivation for designing adaptive algorithms that can be potentially much faster than existing algorithms,,,,
Ip195saXqIX,2021,Reject,False,Knowledge Distillation By Sparse Representation Matching,"[""Dat Thanh Tran"", ""Moncef Gabbouj"", ""Alexandros Iosifidis""]","[""Knowledge Distillation"", ""Sparse Representation"", ""Transfer Learning""]",A knowledge distillation method that utilizes sparse representation to transfer intermediate knowledge in convolutional neural networks,2103.17012,cs.CV,2021-03-31 11:47:47+00:00,2021-03-31 11:47:47+00:00
IpPQmzj4T_,2021,Reject,False,Teleport Graph Convolutional Networks,"[""Hongyang Gao"", ""Shuiwang Ji""]","[""over-smoothing""]",We propose a teleport graph convolution layer to address the over-smoothing limitations in graph neural networks.,,,,
IpctgL7khPp,2022,Accept (Poster),False,Information-theoretic Online Memory Selection for Continual Learning,"['Shengyang Sun', 'Daniele Calandriello', 'Huiyi Hu', 'Ang Li', 'Michalis Titsias']","[""Task-free continual learning"", ""replay memory"", ""information theoretic"", ""reservoir sampling""]",We present information-theoretic algorithms to tackle the online memory selection problem in task-free and data imbalanced continual learning.,,,,
IpsTSvfIB6,2021,Reject,False,Approximate Birkhoff-von-Neumann decomposition: a differentiable approach,"[""Andr\u00e9s Hoyos-Idrobo""]","[""Birkhoff-von-Neumann decomposition"", ""doubly stochastic matrices"", ""Riemannian optimization"", ""Fairness exposure in ranking""]",We propose a differentiable method to approximate the Birkhoff-von-Neumann decomposition of a doubly stochastic matrix.,,,,
IptBMO1AR5g,2022,Reject,False,Regularizing Deep Neural Networks with Stochastic Estimators of Hessian Trace,"['Yucong Liu', 'Tong Lin']","[""Regularization"", ""Hessian Trace"", ""Stochastic Estimator"", ""Nonlinear Dynamical System"", ""Generalization Error""]",,,,,
IqVB8e0DlUd,2021,Reject,False,Fair Differential Privacy Can Mitigate the Disparate Impact on Model Accuracy,"[""Wenyan Liu"", ""Xiangfeng Wang"", ""Xingjian Lu"", ""Junhong Cheng"", ""Bo Jin"", ""Xiaoling Wang"", ""Hongyuan Zha""]",[],,,,,
IqZpoAAt2oQ,2021,Reject,False,Function Contrastive Learning of Transferable Representations,"[""Muhammad Waleed Gondal"", ""Shruti Joshi"", ""Nasim Rahaman"", ""Stefan Bauer"", ""Manuel Wuthrich"", ""Bernhard Sch\u00f6lkopf""]","[""Representations Learning"", ""Few-shot Learning"", ""Contrastive Learning""]","A contrastive algorithm to meta-learn task-agnostic, generic representations of functions.",,,,
IqtonxWI0V3,2021,Accept (Poster),False,TropEx: An Algorithm for Extracting Linear Terms in Deep Neural Networks,"[""Martin Trimmel"", ""Henning Petzka"", ""Cristian Sminchisescu""]","[""linear regions"", ""linear terms"", ""deep learning theory"", ""deep neural networks"", ""rectified linear unit"", ""relu network"", ""piecewise linear function"", ""tropical function""]",We propose an algorithm for extracting linear terms of piecewise linear deep neural network functions and apply it to study differences between convolutional and fully-connected networks.,,,,
IrM64DGB21,2021,Accept (Poster),False,On the role of planning in model-based deep reinforcement learning,"[""Jessica B Hamrick"", ""Abram L. Friesen"", ""Feryal Behbahani"", ""Arthur Guez"", ""Fabio Viola"", ""Sims Witherspoon"", ""Thomas Anthony"", ""Lars Holger Buesing"", ""Petar Veli\u010dkovi\u0107"", ""Theophane Weber""]","[""model-based RL"", ""planning"", ""MuZero""]",An empirical investigation into how planning drives performance in model-based RL algorithms.,,,,
IrofNLZuWF,2021,Reject,False,Stochastic Optimization with Non-stationary Noise: The Power of Moment Estimation,"[""Jingzhao Zhang"", ""Hongzhou Lin"", ""Subhro Das"", ""Suvrit Sra"", ""Ali Jadbabaie""]","[""Stochastic optimization""]",We prove that moment estimation can accelerate SGD under the nonstationary noise setting.,,,,
Is5Hpwg2R-h,2022,Reject,False,Targeted Environment Design from Offline Data,"['Izzeddin Gur', 'Ofir Nachum', 'Aleksandra Faust']","[""targeted environment design"", ""offline reinforcement learning"", ""deep learning"", ""adversarial learning""]",Designing simulated environments to match an offline dataset.,,,,
IsHQmuOqRAG,2022,Reject,False,Learning to perceive objects by prediction,"['Tushar Arora', 'Li Erran Li', 'Ming Bo Cai']","[""predictive learning"", ""object-centric representation"", ""3D perception"", ""sensory grounding""]",The sense of object arise by predicting the future,,,,
ItkxLQU01lD,2022,Accept (Poster),True,Convergent Graph Solvers,"['Junyoung Park', 'Jinhyun Choo', 'Jinkyoo Park']","[""Graph"", ""Graph Neural Network"", ""Fixed point"", ""Implicit model"", ""Implicit function theorem"", ""Convergent""]",,2106.01680,cs.LG,2021-06-03 08:29:17+00:00,2022-02-01 12:40:00+00:00
IvepFxYRDG,2022,Accept (Poster),False,Sample Efficient Stochastic Policy Extragradient Algorithm for Zero-Sum Markov Game,"['Ziyi Chen', 'Shaocong Ma', 'Yi Zhou']","[""Two-player Zero-sum Markov game"", ""Entropy regularization"", ""Policy extragradient"", ""Nash equilibrium"", ""Sample complexity""]","This paper proposes a fully decentralized, model-free, provably convergent, sample efficient stochastic policy extragradient algorithm with symmetric and private policy updates",,,,
Ivku4TZgEly,2022,Reject,False,Exploring unfairness in Integrated Gradients based attribution methods,"['David Drakard', 'Rosanne Liu', 'Jason Yosinski']","[""Integrated Gradients"", ""Expected Gradients"", ""Explainable AI"", ""Integrated Certainty Gradients"", ""Attribution""]",Failure cases of Integrated Gradients based attribution methods are identified and explained and a possible solution explored.,,,,
Iw4ZGwenbXf,2021,Accept (Poster),False,NOVAS: Non-convex Optimization via Adaptive Stochastic Search for End-to-end Learning and Control,"[""Ioannis Exarchos"", ""Marcus Aloysius Pereira"", ""Ziyi Wang"", ""Evangelos Theodorou""]","[""deep neural networks"", ""nested optimization"", ""stochastic control"", ""deep FBSDEs""]",,,,,
IwJPj2MBcIa,2022,Accept (Spotlight),True,Compositional Attention: Disentangling Search and Retrieval,"['Sarthak Mittal', 'Sharath Chandra Raparthy', 'Irina Rish', 'Yoshua Bengio', 'Guillaume Lajoie']","[""compositional attention"", ""flexible search and retrieval"", ""better generalization""]",Recombining search and retrieval mechanisms of multi-head attention in a disentangled and flexible manner for better representational capacity and generalization.,2110.09419,cs.LG,2021-10-18 15:47:38+00:00,2021-10-18 15:47:38+00:00
IxCAF8IMatf,2022,Reject,False,A Unified Knowledge Distillation Framework for Deep Directed Graphical Models,"['Yizhuo Chen', 'Kaizhao Liang', 'Zhe Zeng', 'Yifei Yang', 'Shuochao Yao', 'Huajie Shao']","[""Deep Directed Graphical Models"", ""Knowledge Distillation"", ""Reparameterization trick"", ""Model compression""]",We propose a novel unified knowledge distillation framework for deep directed graphical models on various applications,,,,
Ix_mh42xq5w,2022,Accept (Poster),False,PSA-GAN: Progressive Self Attention GANs for Synthetic Time Series,"['Paul Jeha', 'Michael Bohlke-Schneider', 'Pedro Mercado', 'Shubham Kapoor', 'Rajbir Singh Nirwan', 'Valentin Flunkert', 'Jan Gasthaus', 'Tim Januschowski']","[""Synthetic Time Series"", ""GAN"", ""Generative Modeling"", ""Time Series"", ""Forecasting""]",,,,,
Iz3zU3M316D,2021,Accept (Poster),True,AdamP: Slowing Down the Slowdown for Momentum Optimizers on Scale-invariant Weights,"[""Byeongho Heo"", ""Sanghyuk Chun"", ""Seong Joon Oh"", ""Dongyoon Han"", ""Sangdoo Yun"", ""Gyuwan Kim"", ""Youngjung Uh"", ""Jung-Woo Ha""]","[""momentum optimizer"", ""scale-invariant weights"", ""normalize layer"", ""effective learning rate""]",,2006.08217,cs.LG,2020-06-15 08:35:15+00:00,2021-01-18 14:36:15+00:00
J150Q1eQfJ4,2021,Reject,False,Fully Convolutional Approach for Simulating Wave Dynamics,"[""Mario Lino Valencia"", ""Chris D Cantwell"", ""Eduardo Pignatelli"", ""Stathi Fotiadis"", ""Anil Anthony Bharath""]","[""Convolutional neural network"", ""spatio-temporal forecasting"", ""data-driven physics"", ""wave dynamics""]",CNN-based simulation of 2D waves dynamics,,,,
J1rhANsCY9,2022,Accept (Poster),False,Learning Representation from Neural Fisher Kernel with Low-rank Approximation,"['Ruixiang ZHANG', 'Shuangfei Zhai', 'Etai Littwin', 'Joshua M. Susskind']",[],,,,,
J1uOGgf-bP,2022,Reject,False,Test Time Robustification of Deep Models via Adaptation and Augmentation,"['Marvin Mengxin Zhang', 'Sergey Levine', 'Chelsea Finn']","[""distribution shift"", ""test time adaptation"", ""data augmentation""]",,,,,
J3OUycKwz-,2021,Accept (Poster),False,Mapping the Timescale Organization of Neural Language Models,"[""Hsiang-Yun Sherry Chien"", ""Jinhan Zhang"", ""Christopher Honey""]","[""natural language processing"", ""LSTM"", ""timescale"", ""hierarchy"", ""temporal context""]","We demonstrated a model-free technique for mapping the timescale organization in neural network models, and we applied this method to reveal a hierarchical timescale organization within LSTM language models.",,,,
J40FkbdldTX,2021,Reject,False,Exploring single-path Architecture Search ranking correlations,"[""Kevin Alexander Laube"", ""Andreas Zell""]","[""Neural Architecture Search"", ""AutoML"", ""Neural Networks""]",An empirical study of how several method variations affect the quality of the architecture ranking prediction.,,,,
J4XaMT9OcZ,2021,Reject,False,Mitigating Deep Double Descent by Concatenating Inputs,"[""John Chen"", ""Qihan Wang"", ""Anastasios Kyrillidis""]","[""deep double descent"", ""feedforward neural network"", ""image classificaiton""]",We introduce a construction to artificially increase the size of the dataset which mitigates deep double descent in a variety of settings.,2107.00797,cs.LG,2021-07-02 02:06:44+00:00,2021-07-02 02:06:44+00:00
J4iSIR9fhY0,2022,Accept (Spotlight),False,Representation Learning for Online and Offline RL in Low-rank MDPs,"['Masatoshi Uehara', 'Xuezhou Zhang', 'Wen Sun']","[""Provably sample efficient Reinforcement Learning"", ""PAC bounds"", ""Representation learning"", ""Low-rank MDP""]","We study representation learning in low-rank MDP in both online setting and offline setting, and propose statistically and computationally efficient algorithms.",,,,
J5LS3YJH7Zi,2021,Reject,False,CaLFADS: latent factor analysis of dynamical systems in calcium imaging data,"[""Luke Yuri Prince"", ""Shahab Bakhtiari"", ""Colleen J Gillon"", ""Blake Aaron Richards""]","[""latent variable modelling"", ""lfads"", ""neuroscience"", ""variational autoencoders"", ""dynamical systems"", ""calcium imaging"", ""neural data analysis""]",We develop a hierarchical variational autoencoder that is capable of inferring disentangled and meaningful latent dynamics in calcium imaging data,,,,
J7V_4aauV6B,2022,Reject,True,Understanding and Scheduling Weight Decay,"['Zeke Xie', 'Issei Sato', 'Masashi Sugiyama']","[""Weight Decay"", ""Regularization"", ""Optimization"", ""Deep Learning""]","We proposed the first practical design for weight decay scheduling, called the Stable Weight Decay (SWD) method, which adapts weight decay to the effective learning rate.",2011.11152,cs.LG,2020-11-23 00:39:49+00:00,2021-09-21 06:10:02+00:00
J7b4BCtDm4,2022,Accept (Poster),False,How to deal with missing data in supervised deep learning?,"['Niels Bruun Ipsen', 'Pierre-Alexandre Mattei', 'Jes Frellsen']",[],Marginalize over missing values in supervised learning using deep latent variable models.,,,,
J7bUsLCb0zf,2021,Reject,False,Compute- and Memory-Efficient Reinforcement Learning with Latent Experience Replay,"[""Lili Chen"", ""Kimin Lee"", ""Aravind Srinivas"", ""Pieter Abbeel""]","[""reinforcement learning"", ""deep learning"", ""computational efficiency"", ""memory efficiency""]",We present a compute- and memory-efficient modification of off-policy RL algorithms by freezing lower layers of CNN encoders early in training.,,,,
J8P7g_mDpno,2022,Reject,True,Search Spaces for Neural Model Training,"['Darko Stosic', 'Dusan Stosic']","[""search space"", ""sparsity"", ""neural models"", ""deep learning""]",This paper seeks to understand why using more weights improves neural model training in the context of search spaces and using these insights to improve sparse training.,2105.12920,cs.LG,2021-05-27 02:50:08+00:00,2021-05-27 02:50:08+00:00
J8_GttYLFgr,2021,Accept (Poster),True,Trajectory Prediction using Equivariant Continuous Convolution,"[""Robin Walters"", ""Jinxi Li"", ""Rose Yu""]","[""equivariant"", ""symmetry"", ""trajectory prediction"", ""continuous convolution"", ""argoverse""]","Our model, ECCO, uses rotationally-equivariant continuous convolution to improve generalization in trajectory prediction.",2010.11344,cs.LG,2020-10-21 23:18:42+00:00,2021-03-17 22:07:18+00:00
J9_7t9m8xRj,2022,Reject,False,Diverse and Consistent Multi-view Networks for Semi-supervised Regression,"['Cuong Manh Nguyen', 'Le Zhang', 'Arun Raja', 'Xun Xu', 'Balagopal Unnikrishnan', 'Kangkang Lu', 'Chuan-Sheng Foo']",[],A semi-supervised regression technique that unifies multi-view diversity and consistency. ,,,,
JAlqRs9duhz,2021,Reject,False,Straight to the Gradient: Learning to Use Novel Tokens for Neural Text Generation,"[""Xiang Lin"", ""SIMENG HAN"", ""Shafiq Joty""]","[""text generation"", ""text degeneration"", ""language model"", ""summarization"", ""image captioning""]",We proposed a simple modification to MLE based on gradient analysis and achieved significant improvement on token-level degeneration in different tasks.,2106.07207,cs.CL,2021-06-14 07:46:30+00:00,2021-06-14 07:46:30+00:00
JBAZe2yN6Ub,2022,Accept (Poster),False,A First-Occupancy Representation for Reinforcement Learning,"['Ted Moskovitz', 'Spencer R Wilson', 'Maneesh Sahani']","[""successor representation"", ""successor features"", ""generalized policy improvement"", ""GPI""]","We introduce the first-occupancy representation, a modification of the successor representation which enables agents to perform rapid policy evaluation and planning for a class of ethologically important non-Markovian reward functions.",,,,
JBAa9we1AL,2021,Accept (Spotlight),False,Individually Fair Gradient Boosting,"[""Alexander Vargo"", ""Fan Zhang"", ""Mikhail Yurochkin"", ""Yuekai Sun""]","[""Algorithmic fairness"", ""boosting"", ""non-smooth models""]",We propose an algorithm for training individually fair gradient boosted decision trees classifiers.,2103.16785,cs.LG,2021-03-31 03:06:57+00:00,2021-03-31 03:06:57+00:00
JCRblSgs34Z,2021,Accept (Poster),True,Fantastic Four: Differentiable and Efficient Bounds on Singular Values of Convolution Layers,"[""Sahil Singla"", ""Soheil Feizi""]","[""spectral regularization"", ""spectral normalization""]","We derive four provable upper bounds on the largest singular value of convolution layers that are differentiable, independent of size of input image and can be computed efficiently during training with negligible overhead.",1911.10258,cs.LG,2019-11-22 21:29:32+00:00,2021-06-12 10:04:31+00:00
JCz05AtXO3y,2021,Reject,False,Structural Landmarking and Interaction Modelling: on Resolution Dilemmas in Graph Classification,"[""Kai Zhang"", ""Yaokang Zhu"", ""Jun Wang"", ""Haibin Ling"", ""Jie Zhang"", ""Hongyuan Zha""]","[""Graph Pooling"", ""Graph Classiciation"", ""Interaction Preserving Graph Pooling"", ""Structure Landmarking""]",A new framework for graph pooling that allows explicit modelling of graph substructures and their interacting relations.,,,,
JE7a-YejzfN,2021,Reject,True,Geometry matters: Exploring language examples at the decision boundary,"[""Debajyoti Datta"", ""Shashwat Kumar"", ""Laura Barnes"", ""Tom Fletcher""]","[""Natural Language Processing"", ""Text Classification"", ""Information Geomtery"", ""Sentiment Analysis""]","We propose a novel approach to understand the fragility of NLP examples, highlighting limitations in current evaluation methods of text classifiers.",2010.07212,cs.CL,2020-10-14 16:26:13+00:00,2021-10-28 14:10:42+00:00
JEoDctbwCmP,2022,Reject,False,Enforcing physics-based algebraic constraints for inference of PDE models on unstructured grids,"['Valerii Iakovlev', 'Markus Heinonen', 'Harri LÃ¤hdesmÃ¤ki']",[],,,,,
JFKR3WqwyXR,2021,Accept (Poster),True,Neural Jump Ordinary Differential Equations: Consistent Continuous-Time Prediction and Filtering,"[""Calypso Herrera"", ""Florian Krach"", ""Josef Teichmann""]","[""Neural ODE"", ""conditional expectation"", ""irregular-observed data modelling""]",Online prediction and filtering of irregularly-observed time series data using Neural Jump ODE with theoretical convergence guarantees. ,2006.04727,stat.ML,2020-06-08 16:34:51+00:00,2021-04-16 12:54:38+00:00
JGO8CvG5S9,2022,Accept (Spotlight),False,Universal Approximation Under Constraints is Possible with Transformers,"['Anastasis Kratsios', 'Behnoosh Zamanlooy', 'Tianlin Liu', 'Ivan DokmaniÄ']","[""Constrained Universal Approximation"", ""Probabilistic Attention"", ""Transformer Networks"", ""Geometric Deep Learning"", ""Measurable Maximum Theorem"", ""Non-Affine Random Projections"", ""Optimal Transport.""]","We provide the first universal approximation theorem with exact non-convex constraint satisfaction, and we introduce probabilistic transformer networks to do so.  ",,,,
JHXjK94yH-y,2022,Reject,True,Explore and Control with Adversarial Surprise,"['Arnaud Fickinger', 'Natasha Jaques', 'Samyak Parajuli', 'Michael Chang', 'Nicholas Rhinehart', 'Glen Berseth', 'Stuart Russell', 'Sergey Levine']","[""reinforcement learning"", ""intrinsic motivation"", ""exploration"", ""multi-agent""]","Two policies play a multi-agent adversarial game over the amount of surprise or observation entropy an agent experiences, leading the agent to fully explore the underlying state space and learn meaningful behaviors.",2107.07394,cs.LG,2021-07-12 17:58:40+00:00,2021-12-28 22:17:21+00:00
JHcqXGaqiGn,2021,Accept (Poster),False,Accurate Learning of Graph Representations with Graph Multiset Pooling,"[""Jinheon Baek"", ""Minki Kang"", ""Sung Ju Hwang""]","[""Graph representation learning"", ""Graph pooling""]","A novel graph pooling method for graph representation learning, that considers multiset with attention-based operations.",2102.11533,cs.LG,2021-02-23 07:45:58+00:00,2021-06-28 09:07:36+00:00
JHx9ZDCQEA,2021,Reject,False,PolyRetro: Few-shot Polymer Retrosynthesis via Domain Adaptation,"[""Binghong Chen"", ""Chengtao Li"", ""Hanjun Dai"", ""Rampi Ramprasad"", ""Le Song""]","[""ML for Chemistry"", ""Polymer Retrosynthesis"", ""Few-show Learning"", ""Domain Adaptation""]",We propose a novel learning-based search framework for structural constrained optimization problems with application to polymer retrosynthesis.,,,,
JI2TGOehNT0,2021,Reject,False,Combining Imitation and Reinforcement Learning with Free Energy Principle,"[""Ryoya Ogishima"", ""Izumi Karino"", ""Yasuo Kuniyoshi""]","[""Imitation"", ""Reinforcement Learning"", ""Free Energy Principle""]",Extending Free Energy Principle to achieve imitation reinforcement learning for sparse reward problems with suboptimal experts,2107.11811,cs.LG,2021-07-25 14:19:29+00:00,2021-07-25 14:19:29+00:00
JJCjv4dAbyL,2022,Accept (Poster),False,Learning Discrete Structured Variational Auto-Encoder using Natural Evolution Strategies,"['Alon Berliner', 'Guy Rotman', 'Yossi Adi', 'Roi Reichart', 'Tamir Hazan']","[""structured prediction"", ""derivative-free optimization"", ""variational autoencoder""]",,,,,
JJxiD-kg-oK,2022,Accept (Poster),False,Blaschke Product Neural Networks (BPNN): A Physics-Infused Neural Network for Phase Retrieval of Meromorphic Functions,"['Juncheng Dong', 'Simiao Ren', 'Yang Deng', 'Omar Khatib', 'Jordan Malof', 'Mohammadreza Soltani', 'Willie Padilla', 'Vahid Tarokh']","[""Blaschke Product"", ""Neural Network"", ""Phase Retrieval"", ""Metamaterial"", ""Meromorphic Functions""]",,2111.13311,cs.LG,2021-11-26 04:32:31+00:00,2021-11-26 04:32:31+00:00
JKRVarUs3A1,2022,Reject,False,Distributed Optimal Margin Distribution Machine,"['Yilin Wang', 'nan cao', 'Teng Zhang', 'Hai Jin']","[""Distributed machine learning"", ""margin distribution"", ""classification"", ""kernel learning""]","We propose a specially designed Distributed solver for ODM, a novel margin based model, which maintains great generalization performance and achieves nearly ten times speedup simultaneously",,,,
JLbXkHkLCG6,2022,Reject,False,Imitation Learning from Pixel Observations for Continuous Control,"['Samuel Cohen', 'Brandon Amos', 'Marc Peter Deisenroth', 'Mikael Henaff', 'Eugene Vinitsky', 'Denis Yarats']","[""imitation learning"", ""optimal transport"", ""GAIL"", ""adversarial learning""]",We propose strong recipes for imitation learning from visual observations only based on adversarial learning and optimal transport. ,,,,
JM2kFbJvvI,2022,Accept (Poster),False,Who Is the Strongest Enemy? Towards Optimal and Efficient Evasion Attacks in Deep RL,"['Yanchao Sun', 'Ruijie Zheng', 'Yongyuan Liang', 'Furong Huang']","[""adversarial RL"", ""robustness of RL"", ""evasion attack"", ""optimal attack"", ""observation perturbation""]","We theoretically characterize the essence of evasion attacks in RL, and propose a novel attack algorithm for RL agents, which achieves state-of-the-art performance on both attacking and robustifying RL agents in many Atari and MuJoCo tasks.",,,,
JNP-CqSjkDb,2021,Reject,False,Transforming Recurrent Neural Networks with Attention and Fixed-point Equations,"[""Zhaobin Xu"", ""Baotian Hu"", ""Buzhou Tang""]","[""Fixed-point"", ""Attention"", ""Feed Forward Network"", ""Transformer"", ""Recurrent Neural Network"", ""Deep Learning""]",From Recurrent Neural Networks to self-attention models with an approximation of Banach Fixed-point Theorem.,,,,
JNtw9rUJnV,2021,Reject,False,Real-Time AutoML,"[""Iddo Drori"", ""Brandon Kates"", ""Anant Kharkar"", ""Lu Liu"", ""Qiang Ma"", ""Jonah Deykin"", ""Nihar Sidhu"", ""Madeleine Udell""]","[""Automated machine learning"", ""zero-shot learning"", ""graph neural networks"", ""transformers""]",,,,,
JPkQwEdYn8,2022,Accept (Poster),False,Neural Processes with Stochastic Attention: Paying more attention to the context dataset,"['Mingyu Kim', 'Kyeong Ryeol Go', 'Se-Young Yun']","[""neural processes"", ""stochastic attention"", ""variational inference"", ""information theory""]"," This paper extends the attentive neural process (ANP), replacing the deterministic weights in the cross-attention module of ANP with latent weights.",,,,
JSR-YDImK95,2022,Accept (Spotlight),False,Path Auxiliary Proposal for MCMC in Discrete Space,"['Haoran Sun', 'Hanjun Dai', 'Wei Xia', 'Arun Ramamurthy']",[],,,,,
JSsjw8YuG1P,2022,Reject,False,PERSONALIZED LAB TEST RESPONSE PREDICTION WITH KNOWLEDGE AUGMENTATION,"['Suman Bhoi', 'Mong-Li Lee', 'Wynne Hsu', 'Hao Sen Andrew Fang', 'Ngiap Chuan Tan']","[""Lab test responses"", ""Patient Representation"", ""Electronic Health Records""]",Knowledge augmentation and improved patient representation for lab test prediction.,,,,
JU8ceIgm5xB,2021,Reject,False,Decomposing Mutual Information for Representation Learning,"[""Alessandro Sordoni"", ""Nouha Dziri"", ""Hannes Schulz"", ""Geoff Gordon"", ""Remi Tachet des Combes"", ""Philip Bachman""]","[""Mutual Information"", ""Self-supervised learning""]",We present a bound on conditional MI and use it to maximize the MI decomposition across views for representation learning. ,,,,
JV4tkMi4xg,2022,Reject,False,Constrained Discrete Black-Box Optimization using Mixed-Integer Programming,"['Theodore Papalexopoulos', 'Christian Tjandraatmadja', 'Ross Anderson', 'Juan Pablo Vielma', 'David Benjamin Belanger']","[""discrete blackbox optimization"", ""mixed integer programming""]","We use mixed-integer programming to solve the inner loop acquisition problem in model-based blackbox optimization, which allows us to flexibly address general combinatorial and constrained domains.",,,,
JVWB8QRUOi-,2022,Reject,False,Learning Homophilic Incentives in Sequential Social Dilemmas,"['Heng Dong', 'Tonghan Wang', 'Jiayuan Liu', 'Chi Han', 'Chongjie Zhang']","[""Multi-Agent Reinforcement Learning"", ""Sequential Social Dilemma"", ""Cooperation Emergence""]","We pinpoint the problem of second-order social dilemmas, analyze their dynamics, and propose a novel learning framework to encourage homophilic incentives to solve this problem.",,,,
JVs1OrQgR3A,2021,Reject,False,Time Series Counterfactual Inference with Hidden Confounders,"[""Guangyu Li"", ""Jiahao Chen"", ""Samuel A Assefa"", ""Yan Liu""]","[""Time Series Analysis"", ""Counterfactual Inference"", ""Differential Equations.""]",This paper present a differential equation based model for time series counterfactual inference with hidden confounders.,,,,
JVsvIuMDE0Z,2022,Reject,False,Adaptive Behavior Cloning Regularization for Stable Offline-to-Online Reinforcement Learning,"['Yi Zhao', 'Rinu Boney', 'Alexander Ilin', 'Juho Kannala', 'Joni Pajarinen']",[],,,,,
JWOiYxMG92s,2021,Accept (Oral),False,Free Lunch for Few-shot Learning:  Distribution Calibration,"[""Shuo Yang"", ""Lu Liu"", ""Min Xu""]","[""few-shot learning"", ""image classification"", ""distribution estimation""]",The code is available at: https://github.com/ShuoYang-1998/Few_Shot_Distribution_Calibration,,,,
JXSZuWSPH85,2022,Reject,False,Deep Inverse Reinforcement Learning via Adversarial One-Class Classification,"['Daiko Kishikawa', 'Sachiyo Arai']","[""inverse reinforcement learning"", ""one-class classification""]",A novel deep inverse reinforcement learning method was proposed that requires only expert trajectories via adversarial one-class classification.,,,,
JXhROKNZzOc,2022,Accept (Poster),False,SQuant: On-the-Fly Data-Free Quantization via Diagonal Hessian Approximation,"['Cong Guo', 'Yuxian Qiu', 'Jingwen Leng', 'Xiaotian Gao', 'Chen Zhang', 'Yunxin Liu', 'Fan Yang', 'Yuhao Zhu', 'Minyi Guo']","[""Data-Free Quantization"", ""Hessian Matrix"", ""Approximation""]",A fast and accurate data-free quantization framework named SQuant.,,,,
JYQYysrNT3M,2022,Reject,False,Reinforcement Learning with Ex-Post Max-Min Fairness,"['Wang Chi Cheung', 'Zi Yi Ewe']","[""Reinforcement learning"", ""fairness"", ""regret minimization"", ""multi-objective optimization"", ""constrained Markov decision processes""]","We develop near optimal algorithm for reinforcement learning with vectorial rewards, where we are maximizing the expected minimum reward over $K>1$ reward types.",,,,
JYVODnDjU20,2021,Reject,False,UNSUPERVISED ANOMALY DETECTION FROM SEMANTIC SIMILARITY SCORES,"[""Nima Rafiee"", ""Rahil Gholamipoor"", ""Markus Kollmann""]","[""Anomaly Detection"", ""Out-of-Distribution Detection"", ""Novelty Detection""]",Combining Contrastive Learning and Discriminative Learning for unsupervised Anomaly Detection,2012.00461,cs.LG,2020-12-01 13:12:31+00:00,2021-03-26 08:40:34+00:00
JYtwGwIL7ye,2022,Accept (Poster),False,The Effects of Reward Misspecification: Mapping and Mitigating Misaligned Models,"['Alexander Pan', 'Kush Bhatia', 'Jacob Steinhardt']","[""reward misspecification"", ""reinforcement learning"", ""reward hacking"", ""alignment"", ""ml safety""]",We map out trends in reward misspecification and how to mitigate their impact.,2201.03544,cs.LG,2022-01-10 18:58:52+00:00,2022-01-10 18:58:52+00:00
JZrETJlgyq,2022,Reject,False,Exploring Non-Contrastive Representation Learning for Deep Clustering,"['Zhizhong Huang', 'Jie Chen', 'Junping Zhang', 'Hongming Shan']","[""Image Clustering"", ""Representation Learning"", ""Self-supervised Learning""]",We propose a novel non-contrastive clustering method that is based on BYOL without negative samples.,2111.11821,cs.CV,2021-11-23 12:21:53+00:00,2021-11-23 12:21:53+00:00
J_2xNmVcY4,2022,Accept (Poster),False,Optimizing Neural Networks with Gradient Lexicase Selection,"['Li Ding', 'Lee Spector']","[""deep learning"", ""lexicase selection"", ""optimization"", ""evolutionary algorithms""]","We propose Gradient Lexicase Selection, an evolutionary optimization method that improves the generalization of deep neural networks.",,,,
J_F_qqCE3Z5,2022,Accept (Poster),False,DKM: Differentiable k-Means Clustering Layer for Neural Network Compression,"['Minsik Cho', 'Keivan Alizadeh-Vahid', 'Saurabh Adya', 'Mohammad Rastegari']","[""Deep learning"", ""neural network"", ""compression""]","We propose a novel model compression scheme based on differentiable K-means layer, and it delivers the state-of-the-art results.",,,,
J_PHjw4gvXJ,2022,Accept (Poster),False,Improving the Accuracy of Learning Example Weights for Imbalance Classification,"['Yuqi Liu', 'Bin Cao', 'Jing Fan']","[""Imbalance classification"", ""Meta learning"", ""Data weighting.""]",,,,,
J_pvI6ap5Mn,2021,Reject,False,Transfer Learning of Graph Neural Networks with Ego-graph Information Maximization,"[""Qi Zhu"", ""Yidan Xu"", ""Haonan Wang"", ""Chao Zhang"", ""Jiawei Han"", ""Carl Yang""]","[""Transfer learning"", ""graph neural networks""]",We establish a theoretically grounded and practically useful framework for the transfer learning of GNNs with experiments for both theoretical and practical scenarios.,,,,
Jacdvfjicf7,2021,Accept (Poster),True,Interpreting and Boosting Dropout from a Game-Theoretic View,"[""Hao Zhang"", ""Sen Li"", ""YinChao Ma"", ""Mingjie Li"", ""Yichen Xie"", ""Quanshi Zhang""]","[""Dropout"", ""Interpretability"", ""Interactions""]",We prove and improve the utility of the dropout operation from a game-theoretic view.,2009.11729,cs.LG,2020-09-24 14:39:42+00:00,2021-03-16 10:42:04+00:00
JbAqsfbYsJy,2021,Reject,False,Action and Perception as Divergence Minimization,"[""Danijar Hafner"", ""Pedro A Ortega"", ""Jimmy Ba"", ""Thomas Parr"", ""Karl Friston"", ""Nicolas Heess""]","[""objective functions"", ""reinforcement learning"", ""information theory"", ""probabilistic modeling"", ""control as inference"", ""exploration"", ""intrinsic motivation"", ""world models""]",,,,,
JbuYF437WB6,2021,Accept (Poster),False,Directed Acyclic Graph Neural Networks,"[""Veronika Thost"", ""Jie Chen""]","[""Graph Neural Networks"", ""Graph Representation Learning"", ""Directed Acyclic Graphs"", ""DAG"", ""Inductive Bias""]","We propose DAGNN, a graph neural network tailored to directed acyclic graphs that outperforms conventional GNNs by leveraging the partial order as strong inductive bias besides other suitable architectural features.",2101.07965,cs.LG,2021-01-20 04:50:16+00:00,2021-02-02 18:45:44+00:00
JdCUjf9xvlc,2021,Reject,False,Fourier Representations for Black-Box Optimization over Categorical Variables,"[""Hamid Dadkhahi"", ""Jesus Rios"", ""Karthikeyan Shanmugam"", ""Payel Das""]",[],We propose novel Fourier representations as surrogate models for black box optimization over categorical variables and show its performance improvement over existing baselines when combined with state of the art acquisition functions.,,,,
JeSIUeUSUuR,2022,Reject,False,Variability of Neural Networks and Han-Layer: A Variability-Inspired Model,"['Yueyao Yu', 'Yin Zhang']",[],"We provide a new angle to study what makes an artificial neural network easier to train and produce desirable solutions, called Variability, and then build a variability inspired model.",,,,
JedTK_aOaRa,2022,Reject,False,Private Multi-Winner Voting For Machine Learning,"['Adam Dziedzic', 'Christopher A. Choquette-Choo', 'Natalie Dullerud', 'Vinith Menon Suriyakumar', 'Ali Shahin Shamsabadi', 'Muhammad Ahmad Kaleem', 'Somesh Jha', 'Nicolas Papernot', 'Xiao Wang']","[""multi-label"", ""privacy"", ""voting"", ""confidentiality"", ""differential privacy"", ""disributed collaboration"", ""collaboration""]",We propose three new privacy-preserving multi-winner voting mechanisms for machine learning and analyze tradeoffs between them theoretically as well as empirically.,,,,
Jep2ykGUdS,2022,Reject,False,DEUP: Direct Epistemic Uncertainty Prediction,"['Moksh Jain', 'Salem Lahlou', 'Hadi Nekoei', 'Victor I Butoi', 'Paul Bertin', 'Jarrid Rector-Brooks', 'Maksym Korablyov', 'Yoshua Bengio']","[""deep learning"", ""uncertainty estimation""]","We propose training a separate predictor to learn the out-of-sample error at a given input, providing a more precise estimate of epistemic uncertainty, robust to the existence of misspecification.",,,,
JeweO9-QqV-,2021,Reject,False,SoGCN: Second-Order Graph Convolutional Networks,"[""Peihao Wang"", ""Yuehao Wang"", ""Hua Lin"", ""Jianbo Shi""]","[""Graph Convolutional Networks"", ""Filter Representation Power"", ""Graph Polynomial Filters""]","We introduce a second-order graph convolution (SoGC), a maximally localized kernel, that can express a polynomial spectral filter of order $K$ with arbitrary coefficients. ",,,,
Jf24xdaAwF9,2021,Reject,False,Self-Activating Neural Ensembles for Continual Reinforcement Learning,"[""Sam Powers"", ""Abhinav Gupta""]","[""continual reinforcement learning"", ""lifelong learning"", ""deep reinforcement learning""]",We present a novel tree-structured neural architecture that enables the learning of tasks sequentially.,,,,
JfaWawZ8BmX,2022,Accept (Poster),False,Anisotropic Random Feature Regression in High Dimensions,"['Gabriel Mel', 'Jeffrey Pennington']","[""random feature models"", ""high dimensional asymptotics"", ""generalization"", ""learning curves"", ""double descent"", ""multiple descent"", ""alignment""]","We derive exact asymptotic formulas for the total error, bias, and variance of random feature regression with anisotropic inputs and target weights, and identify a new type of singularity in sample-wise learning curves. ",,,,
JiNvAGORcMW,2021,Reject,False,Cross-State Self-Constraint for Feature Generalization in Deep Reinforcement Learning,"[""Guan Ting Liu"", ""Pu-Jen Cheng"", ""GuanYu Lin""]","[""reinforcement learning"", ""generalization"", ""regularization""]",A novel constraint that regularizes the representation feature space by comparing similarity of different pairs of representations. ,,,,
JiYq3eqTKY,2021,Accept (Spotlight),False,On Statistical Bias In Active Learning: How and When to Fix It,"[""Sebastian Farquhar"", ""Yarin Gal"", ""Tom Rainforth""]","[""Active Learning"", ""Monte Carlo"", ""Risk Estimation""]","We formalize the bias introduced by active learning and investigate the situations in which it can be harmful and sometimes even helpful, further introducing novel corrective weights to remove it when doing so is beneficial.",2101.11665,stat.ML,2021-01-27 19:52:24+00:00,2021-05-31 11:46:48+00:00
Jjcv9MTqhcq,2022,Accept (Poster),True,Rethinking Supervised Pre-Training for Better Downstream Transferring,"['Yutong Feng', 'Jianwen Jiang', 'Mingqian Tang', 'Rong Jin', 'Yue Gao']","[""Pre-Training"", ""Contrastive Learning"", ""Representation Learning"", ""Downstream Transferring""]","We propose a new supervised pre-training method based on Leave-One-Out K-Nearest-Neighbor, which relieves the problem of overfitting upstream tasks  and preserving part of intra-class difference for better transferring to downstream tasks.",2110.06014,cs.CV,2021-10-12 13:57:38+00:00,2021-10-12 13:57:38+00:00
JkfYjnOEo6M,2021,Accept (Poster),True,Group Equivariant Stand-Alone Self-Attention For Vision,"[""David W. Romero"", ""Jean-Baptiste Cordonnier""]","[""group equivariant transformers"", ""group equivariant self-attention"", ""group equivariance"", ""self-attention"", ""transformers""]",We provide a general self-attention formulation to impose group equivariance to arbitrary symmetry groups.,2010.00977,cs.CV,2020-10-02 13:16:00+00:00,2021-03-18 19:19:38+00:00
JmU7lyDxTpc,2022,Reject,False,Multi-scale Feature Learning Dynamics: Insights for Double Descent,"['Mohammad Pezeshki', 'Amartya Mitra', 'Yoshua Bengio', 'Guillaume Lajoie']","[""generalization"", ""neural networks"", ""dynamics"", ""double descent""]",This work studies the origins of the epoch-wise double descent.,2112.03215,cs.LG,2021-12-06 18:17:08+00:00,2021-12-06 18:17:08+00:00
Jnspzp-oIZE,2021,Accept (Spotlight),True,Gauge Equivariant Mesh CNNs: Anisotropic convolutions on geometric graphs,"[""Pim De Haan"", ""Maurice Weiler"", ""Taco Cohen"", ""Max Welling""]","[""symmetry"", ""equivariance"", ""mesh"", ""geometric"", ""convolution""]",Expressive anisotropic mesh convolution without having to pick arbitrary kernel orientation by using gauge equivariance,2003.05425,cs.LG,2020-03-11 17:21:15+00:00,2021-11-18 00:23:18+00:00
JoCR4h9O3Ew,2021,Accept (Poster),False,ARMOURED: Adversarially Robust MOdels using Unlabeled data by REgularizing Diversity,"[""Kangkang Lu"", ""Cuong Manh Nguyen"", ""Xun Xu"", ""Kiran Chari"", ""Yu Jing Goh"", ""Chuan-Sheng Foo""]","[""Adversarial Robustness"", ""Semi-supervised Learning"", ""Multi-view Learning"", ""Diversity Regularization"", ""Entropy Maximization""]",ARMOURED is a novel technique for adversarially robust learning that elegantly unifies semi-supervised learning and diversity regularization through a multi-view learning framework. ,,,,
JpNH4CW_zl,2022,Reject,False,Multivariate Time Series Forecasting with Latent Graph Inference,"['Victor Garcia Satorras', 'Syama Sundar Rangapuram', 'Tim Januschowski']","[""Time Series Forecasting"", ""Graph Neural Networks"", ""Graph Inference"", ""Multivariate Time Series""]",,,,,
JprM0p-q0Co,2022,Accept (Spotlight),False,Tackling the Generative Learning Trilemma with Denoising Diffusion GANs,"['Zhisheng Xiao', 'Karsten Kreis', 'Arash Vahdat']",[],"To reduce the number of sampling steps in diffusion models, we propose to model the denoising distribution with conditional GANs. We show our model tackles the generative learning trilemma & achieves high sample quality, diversity & fast sampling.",,,,
Jq8JGA89sDa,2021,Reject,False,Detecting Hallucinated Content in Conditional Neural Sequence Generation,"[""Chunting Zhou"", ""Jiatao Gu"", ""Mona T. Diab"", ""Paco Guzm\u00e1n"", ""Luke Zettlemoyer"", ""Marjan Ghazvininejad""]","[""conditional text generation"", ""hallucination detection"", ""sequence generation evaluation"", ""neural machine translation"", ""abstractive text summarization""]",We propose a new task to predict hallucinated words in the machine output conditioned on the source input and a novel general-purpose method to learn this task.,,,,
Jr8XGtK04Pw,2021,Reject,False,Hippocampal representations emerge when training recurrent neural networks on a memory dependent maze navigation task,"[""Justin Jude"", ""Matthias Hennig""]","[""recurrent neural network"", ""place cell"", ""hippocampus"", ""neural dynamics""]",Recurrent neural networks trained on a combined predictive and maze navigation task produce goal directed behaviour and neural dynamics reported experimentally in the hippocampus.,,,,
JsfFpJhI4BV,2022,Reject,False,Learning Identity-Preserving Transformations on Data Manifolds,"['Marissa Catherine Connor', 'Kion Fallah', 'Christopher John Rozell']","[""manifold learning"", ""unsupervised learning"", ""generative models"", ""lie groups"", ""transport operators"", ""transformation learning""]",We propose new techniques to learn Lie group operators in an autoencoder latent space which represent transformations that preserve the identity of input data without transformation labels.,,,,
Jt8FYFnyTLR,2022,Reject,False,On the Safety of Interpretable Machine Learning: A Maximum Deviation Approach,"['Dennis Wei', 'Rahul Nair', 'Amit Dhurandhar', 'Kush R. Varshney', 'Elizabeth M. Daly', 'Moninder Singh']","[""safety"", ""interpretability"", ""explainability""]","We show the benefit of interpretability from a model safety standpoint, where assessment of safety is formalized through maximum deviation from a reference model.",,,,
JtBRnrlOEFN,2022,Accept (Poster),True,Charformer: Fast Character Transformers via Gradient-based Subword Tokenization,"['Yi Tay', 'Vinh Q. Tran', 'Sebastian Ruder', 'Jai Gupta', 'Hyung Won Chung', 'Dara Bahri', 'Zhen Qin', 'Simon Baumgartner', 'Cong Yu', 'Donald Metzler']","[""transformers"", ""NLP"", ""language""]",Fast Token-Free Models,2106.12672,cs.CL,2021-06-23 22:24:14+00:00,2021-07-02 16:30:28+00:00
JvPopr9skL0,2022,Reject,False,Efficient Out-of-Distribution Detection via CVAE data Generation,"['Mengyu Wang', 'Yijia Shao', 'Haowei Lin', 'Wenpeng Hu', 'Bing Liu']","[""Out-of-distribution Detection""]","We propose a novel pseudo data generation based out-of-distribution detection framework, which is not only efficient but also produces state-of-the-art results.",,,,
JvPsKam58LX,2021,Reject,False,Robust Multi-Agent Reinforcement Learning Driven by Correlated Equilibrium,"[""Yizheng Hu"", ""Kun Shao"", ""Dong Li"", ""Jianye HAO"", ""Wulong Liu"", ""Yaodong Yang"", ""Jun Wang"", ""Zhanxing Zhu""]","[""Robust"", ""Multi-agent"", ""Reinforcement Learning"", ""Correlated Equilibrium""]",,,,,
Jvoe8JCGvy,2022,Reject,False,Online MAP Inference and Learning for Nonsymmetric Determinantal Point Processes,"['Aravind Reddy', 'Ryan Rossi', 'Zhao Song', 'Anup Rao', 'Tung Mai', 'Nedim Lipka', 'Gang Wu', 'Eunyee Koh', 'Nesreen Ahmed']","[""online algorithms"", ""nonsymmetric determinantal point processes""]","We introduce online and streaming MAP inference and learning problems for Non-symmetric Determinantal Point Processes (NDPPs), design algorithms with both theoretical and empirical guarantees, and prove a space lower bound for our inference problem. ",,,,
JxFgJbZ-wft,2022,Accept (Poster),True,Variational Predictive Routing with Nested Subjective Timescales,"['Alexey Zakharov', 'Qinghai Guo', 'Zafeirios Fountas']","[""Hierarchical temporal abstraction"", ""event discovery"", ""hierarchical generative models"", ""variational inference""]",Variational inference hierarchical model that relies on a change detection mechanism to impose a nested temporal hierarchy on its latent structure.,2110.11236,cs.LG,2021-10-21 16:12:59+00:00,2021-10-21 16:12:59+00:00
JyDnXkeJpjU,2021,Reject,True,Task-similarity Aware Meta-learning through Nonparametric Kernel Regression,"[""Arun Venkitaraman"", ""Anders Hansson"", ""Bo Wahlberg""]","[""Task-similarity"", ""Meta-learning"", ""Kernel regression"", ""Nonparametric regression"", ""Task-descriptors""]",This paper investigates the use of nonparametric kernel-regression to obtain a task-similarity aware meta-learning algorithm. ,2006.07212,cs.LG,2020-06-12 14:15:11+00:00,2020-10-12 06:57:56+00:00
JyI9lc8WxW,2022,Reject,False,Planckian jitter: enhancing the color quality of self-supervised visual representations,"['Simone Zini', 'Marco Buzzelli', 'BartÅomiej Twardowski', 'Joost van de weijer']","[""Contrastive Learning"", ""Self-Supervised Learning"", ""Color Features"", ""Illuminant Invariance""]",,,,,
JydXRRDoDTv,2021,Reject,False,Optimistic Policy Optimization with General Function Approximations,"[""Qi Cai"", ""Zhuoran Yang"", ""Csaba Szepesvari"", ""Zhaoran Wang""]",[],,,,,
JywMsiz_NtO,2021,Reject,False,Enforcing Predictive Invariance across Structured Biomedical Domains,"[""Wengong Jin"", ""Regina Barzilay"", ""Tommi S. Jaakkola""]","[""Domain Generalization"", ""Molecular Property Prediction""]",We propose regret minimization for generalization across structured domains such as molecular scaffolds,,,,
JzG0n48hRf,2021,Reject,False,Uncertainty for deep image classifiers on out of distribution data. ,"[""Tiago Salvador"", ""Alexander Iannantuono"", ""Adam M Oberman""]","[""uncertainty"", ""confidence"", ""out of distribution"", ""outlier exposure"", ""classification""]","improving on benchmark estimates of model uncertainty on OOD data, using outlier exposure",,,,
JzNB0eA2-M4,2022,Accept (Poster),False,On the Convergence of the Monte Carlo Exploring Starts Algorithm for Reinforcement Learning,"['Che Wang', 'Shuhan Yuan', 'Kai Shao', 'Keith W. Ross']","[""reinforcement learning"", ""convergence of reinforcement learning algorithm"", ""monte carlo exploring starts""]",We prove that the Monte Carlo Exploring Starts algorithm converges for optimal policy feed-forward MDPs. ,,,,
K-hiHQXEQog,2022,Reject,False,Autoregressive Latent Video Prediction with High-Fidelity Image Generator,"['Younggyo Seo', 'Kimin Lee', 'Fangchen Liu', 'Stephen James', 'Pieter Abbeel']","[""video prediction"", ""autoregressive models""]","We present HARP, an autoregressive latent video prediction model capable of predicting high-resolution future frames.",,,,
K0E_F0gFDgA,2022,Accept (Spotlight),False,The MultiBERTs: BERT Reproductions for Robustness Analysis,"['Thibault Sellam', 'Steve Yadlowsky', 'Ian Tenney', 'Jason Wei', 'Naomi Saphra', ""Alexander D'Amour"", 'Tal Linzen', 'Jasmijn Bastings', 'Iulia Raluca Turc', 'Jacob Eisenstein', 'Dipanjan Das', 'Ellie Pavlick']","[""Pre-trained models"", ""BERT"", ""bootstrapping"", ""hypothesis testing"", ""robustness""]","We introduce MultiBERTs, 25 BERT checkpoints trained with similar hyper-parameters but different random seeds, and the Multi-Bootstrap, a bootstrapping method for experimental settings that involve multiple models and limited test data.",,,,
K1m0oSiGasn,2022,Reject,False,Adaptive Region Pooling for Fine-Grained Representation Learning,"['Tsai-Shien Chen', 'Chih-Ting Liu', 'Shao-Yi Chien']","[""Fine-grained representation learning"", ""Re-identification"", ""Pooling operation""]",This paper introduces a novel pooling operation which would automatically focus on a smaller but more critical region and enrich the granularity of the sub-sampled representations simultaneously.,,,,
K2JfSnLBD9,2022,Accept (Poster),True,C-Planning: An Automatic Curriculum for Learning Goal-Reaching Tasks,"['Tianjun Zhang', 'Benjamin Eysenbach', 'Ruslan Salakhutdinov', 'Sergey Levine', 'Joseph E. Gonzalez']","[""reinforcement learning"", ""planning"", ""variational inference"", ""curriculum learning"", ""waypoints"", ""subgoals""]","An algorithm for goal-conditioned RL that uses an automatic curriculum of waypoints during exploration, derived from variational inference.",2110.12080,cs.LG,2021-10-22 22:05:31+00:00,2021-10-22 22:05:31+00:00
K398CuAKVKB,2021,Reject,False,Removing Dimensional Restrictions on Complex/Hyper-complex Convolutions,"[""Chase John Gaudet"", ""Anthony S. Maida""]","[""CNNs"", ""complex"", ""hypercomplex""]","Novel formulation to capture the important parts of complex/hypercomplex networks, without the dimensionality constraints, namely their ability to treat multi-dimensional data as a single entity (forced local relationship encoding).",,,,
K3bGe_-aMV,2022,Reject,False,Semantically Controllable Generation of Physical Scenes with Explicit Knowledge,"['Wenhao Ding', 'Bo Li', 'Ji Eun Kim', 'Ding Zhao']","[""Deep Generative Models"", ""Knowledge-intergrated Neural Networks"", ""Physical Scene Generation""]",This paper proposes a general framework for semantically contollable scene generation with the guidance of external knowledge.,,,,
K3qa-sMHpQX,2021,Reject,False,ForceNet: A Graph Neural Network for Large-Scale Quantum Chemistry Simulation,"[""Weihua Hu"", ""Muhammed Shuaibi"", ""Abhishek Das"", ""Siddharth Goyal"", ""Anuroop Sriram"", ""Jure Leskovec"", ""Devi Parikh"", ""Larry Zitnick""]","[""Graph Neural Networks"", ""Physical simulation"", ""Quantum chemistry"", ""Catalysis""]",Graph neural network designed to model the complex interactions in large systems of atoms for use in simulating atomic relaxations of catalysts.,,,,
K3uRhaKJuZg,2022,Reject,False,Video Forgery Detection Using Multiple Cues on Fusion of EfficientNet and Swin Transformer,"['Chenyu Liu', 'Jia Li', 'Junxian Duan', 'Huaibo Huang']","[""deepfakes"", ""video forgery detection"", ""high-frequency"", ""texture"", ""optical flow"", ""EfficientNet"", ""Swin Transformer""]",,,,,
K47zHehHcRc,2022,Reject,False,On the interventional consistency of autoencoders,"['Giulia Lanzillotta', 'Felix Leeb', 'Stefan Bauer', 'Bernhard SchÃ¶lkopf']","[""causal representation learning"", ""disentanglement"", ""autoencoders""]",Study of the interventional consistency of autoencoders for causal representation learning.,,,,
K4wkUp5xNK,2021,Reject,False,Invariant Causal Representation Learning,"[""Chaochao Lu"", ""Yuhuai Wu"", ""Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"", ""Bernhard Sch\u00f6lkopf""]",[],"We propose Invariant Causal Representation Learning (ICRL), a novel learning paradigm that enables out-of-distribution generalization in the nonlinear setting.",,,,
K5YasWXZT3O,2021,Accept (Poster),True,Tilted Empirical Risk Minimization,"[""Tian Li"", ""Ahmad Beirami"", ""Maziar Sanjabi"", ""Virginia Smith""]","[""exponential tilting"", ""models of learning and generalization"", ""label noise robustness"", ""fairness""]","We show that tilted empirical risk minimization (TERM) can be used for enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance, all in a unified framework.",2007.01162,cs.LG,2020-07-02 14:49:48+00:00,2021-03-17 16:34:26+00:00
K5a_QFEUzA1,2021,Reject,False,Cross-model Back-translated Distillation for Unsupervised Machine Translation,"[""Phi Xuan Nguyen"", ""Shafiq Joty"", ""Kui Wu"", ""AiTi Aw""]","[""unsupervised machine translation"", ""NMT"", ""machine translation""]",The paper introduces a method to improve unsupervised machine translation using two unsupervised agents to produce diverse data and conduct knowledge distillation. ,,,,
K5j7D81ABvt,2021,Accept (Poster),False,Disambiguating Symbolic Expressions in Informal Documents,"[""Dennis M\u00fcller"", ""Cezary Kaliszyk""]",[],,2101.11716,cs.LG,2021-01-25 10:14:37+00:00,2021-01-25 10:14:37+00:00
K6YbHUIWHOy,2021,Reject,False,Memory Augmented Design of Graph Neural Networks,"[""Tao Xiong"", ""Liang Zhu"", ""Ruofan Wu"", ""Yuan Qi""]",[],,,,,
K9KiBYAthi9,2022,Reject,False,DMSANET: DUAL MULTI SCALE ATTENTION NETWORK,['Abhinav Sagar'],[],,,,,
K9bw7vqp_s,2021,Accept (Poster),False,Learning N:M  Fine-grained Structured Sparse Neural Networks From Scratch,"[""Aojun Zhou"", ""Yukun Ma"", ""Junnan Zhu"", ""Jianbo Liu"", ""Zhijie Zhang"", ""Kun Yuan"", ""Wenxiu Sun"", ""Hongsheng Li""]","[""sparsity"", ""efficient training and inference.""]",a  simple  yet  universal  recipe  to  learn N:M sparse neural networks from scratch,2102.04010,cs.CV,2021-02-08 05:55:47+00:00,2021-04-18 10:18:00+00:00
KB5onONJIAU,2022,Accept (Oral),False,Comparing Distributions by Measuring Differences that Affect Decision Making,"['Shengjia Zhao', 'Abhishek Sinha', 'Yutong He', 'Aidan Perreault', 'Jiaming Song', 'Stefano Ermon']","[""probability divergence"", ""two sample test"", ""generative model""]",,,,,
KBQP4A_J1K,2022,Accept (Poster),True,Adaptive Control Flow in Transformers Improves Systematic Generalization,"['RÃ³bert CsordÃ¡s', 'Kazuki Irie', 'JÃ¼rgen Schmidhuber']","[""transformer"", ""compositionality"", ""systematic generalization"", ""algorithmic reasoning"", ""arithmetic""]",We improve systematic generalization of Transformers on algorithmic tasks by introducing a novel attention mechanism and gating.,2110.07732,cs.LG,2021-10-14 21:24:27+00:00,2021-10-14 21:24:27+00:00
KBWK5Y92BRh,2021,Reject,False,Neighborhood-Aware Neural Architecture Search,"[""Xiaofang Wang"", ""Shengcao Cao"", ""Mengtian Li"", ""Kris M. Kitani""]","[""Neural architecture search"", ""Flat minima""]",We propose a neighborhood-aware formulation for neural architecture search to find flat minima in the search space that can generalize better to new settings.,,,,
KBuOP5HrVQ0,2022,Reject,False,Bayesian Exploration for Lifelong Reinforcement Learning,"['Haotian Fu', 'Shangqun Yu', 'Michael Littman', 'George Konidaris']",[],,,,,
KCzRX9N8BIH,2021,Reject,True,It Is Likely That Your Loss Should be a Likelihood,"[""Mark Hamilton"", ""Evan Shelhamer"", ""William T. Freeman""]","[""Adaptive Losses"", ""Outlier Detection"", ""Adaptive Regularization"", ""Recalibration"", ""Robust Modelling""]","Learning additional likelihood distribution parameters yields new approaches for robust modelling, outlier-detection, calibration, and adaptive regularization.",2007.06059,cs.LG,2020-07-12 18:25:17+00:00,2020-10-02 14:39:37+00:00
KDAEc2nai83,2022,Reject,False,Human-Level Control without Server-Grade Hardware,"['Brett Daley', 'Christopher Amato']","[""Deep Reinforcement Learning""]","A fast DQN implementation optimized for desktop CPU-GPU systems, capable of replicating the original human-level control experiments.",,,,
KEQl-MZ5fg7,2022,Accept (Poster),True,Learning Versatile Neural Architectures by Propagating Network Codes,"['Mingyu Ding', 'Yuqi Huo', 'Haoyu Lu', 'Linjie Yang', 'Zhe Wang', 'Zhiwu Lu', 'Jingdong Wang', 'Ping Luo']","[""Multitask NAS"", ""Task-Transferable Architecture"", ""Neural Predictor"", ""NAS Benchmark""]",An efficient NAS method by inverting neural predictors to directly update architectures and a multitask NAS benchmark for cross-task architecture design and analysis.,2103.13253,cs.CV,2021-03-24 15:20:38+00:00,2021-03-24 15:20:38+00:00
KFUWHgRYEDF,2022,Reject,False,ScaLA: Speeding-Up Fine-tuning of Pre-trained Transformer Networks via Efficient and Scalable Adversarial Perturbation,"['Minjia Zhang', 'Niranjan Uma Naresh', 'Yuxiong He']","[""Efficient Training Methods"", ""Large Batch Optimization"", ""Transformer Networks"", ""BERT""]",ScaLA is a scalable and efficient method for large-batch optimization of pre-trained transformer networks via adversarial perturbation.,,,,
KG4igOosnw8,2021,Reject,True,Discriminative Representation Loss (DRL): A More Efficient Approach than Gradient Re-Projection in Continual Learning,"[""Yu Chen"", ""Tom Diethe"", ""Peter Flach""]","[""continual learning"", ""episodic memory"", ""GEM"", ""experience replay"", ""deep metric learning""]","We reveal the relation between diversity of gradients and discriminativeness of representations and show connections between deep metric learning and continual learning, based on which, we propose a simple yet efficient method for continual learning.",2006.11234,stat.ML,2020-06-19 17:13:42+00:00,2021-03-18 10:25:13+00:00
KIS8jqLp4fQ,2021,Reject,False,On Dynamic Noise Influence in Differential Private Learning,"[""Junyuan Hong"", ""Zhangyang Wang"", ""Jiayu Zhou""]","[""privacy"", ""private learning"", ""dynamic policy""]",Improve utility upper bound for differential private learning by dynamic noise influence,2101.07413,cs.LG,2021-01-19 02:04:00+00:00,2021-01-19 02:04:00+00:00
KJNcAkY8tY4,2021,Accept (Poster),True,Do Wide and Deep Networks Learn the Same Things? Uncovering How Neural Network Representations Vary with Width and Depth,"[""Thao Nguyen"", ""Maithra Raghu"", ""Simon Kornblith""]","[""Representation learning""]","We show that depth/width variations result in distinctive characteristics in the model internal representations, with resulting consequences for representations and output predictions across different model initializations and architectures. ",2010.15327,cs.LG,2020-10-29 02:57:21+00:00,2021-04-10 01:44:17+00:00
KJSC_AsN14,2021,Reject,False,Contrastive Learning with Stronger Augmentations,"[""Xiao Wang"", ""Guo-Jun Qi""]","[""Contrastive learning"", ""Self-supervised learning"", ""Unsupervised learning"", ""Stronger augmentations""]",This paper presents a novel contrastive learning model that enables the use of stronger augmentations via distributional divergence minimization to achieve a new record of accuracy with vanishing performance gap to the fully supervised network.,2104.07713,cs.CV,2021-04-15 18:40:04+00:00,2021-04-15 18:40:04+00:00
KJggliHbs8,2022,Accept (Poster),False,Node Feature Extraction by Self-Supervised Multi-scale Neighborhood Prediction,"['Eli Chien', 'Wei-Cheng Chang', 'Cho-Jui Hsieh', 'Hsiang-Fu Yu', 'Jiong Zhang', 'Olgica Milenkovic', 'Inderjit S Dhillon']","[""Self-supervised learning"", ""Graph Neural Networks"", ""Extreme multi-label classification""]",We design a self-supervised learning method for extracting node representations from raw data.,,,,
KJztlfGPdwW,2022,Accept (Poster),False,Rethinking Goal-Conditioned Supervised Learning and Its Connection to Offline RL,"['Rui Yang', 'Yiming Lu', 'Wenzhe Li', 'Hao Sun', 'Meng Fang', 'Yali Du', 'Xiu Li', 'Lei Han', 'Chongjie Zhang']","[""Goal-conditioned reinforcement learning"", ""offline reinforcement learning"", ""goal-conditioned supervised learning""]",We revisit GCSL's theoretical foundation and present a simple but effective algorithm for offline goal-conditioned RL via weighted supervised learning,2202.04478,cs.LG,2022-02-09 14:17:05+00:00,2022-02-09 14:17:05+00:00
KL5jILuehZ,2022,Reject,False,End-to-End Balancing for Causal Continuous Treatment-Effect Estimation,"['Mohammad Taha Bahadori', 'Eric Tchetgen Tchetgen', 'David Heckerman']","[""End-to-end learning"", ""Entropy Balancing"", ""Continuous Treatments""]",We argue that entropy balancing is suboptimal. We propose the end-to-end balancing framework that directly improves the accuracy of causal inference.,,,,
KLH36ELmwIB,2021,Accept (Poster),True,DARTS-: Robustly Stepping out of Performance Collapse Without Indicators,"[""Xiangxiang Chu"", ""Xiaoxing Wang"", ""Bo Zhang"", ""Shun Lu"", ""Xiaolin Wei"", ""Junchi Yan""]","[""neural architecture search"", ""DARTS stability""]",Indicator-free approach to stabilize DARTS,2009.01027,cs.LG,2020-09-02 12:54:13+00:00,2021-01-15 07:58:11+00:00
KLaDXLAzzFT,2022,Accept (Poster),False,Near-optimal Offline Reinforcement Learning with Linear Representation: Leveraging Variance Information with Pessimism,"['Ming Yin', 'Yaqi Duan', 'Mengdi Wang', 'Yu-Xiang Wang']","[""reinforcement learning theory"", ""markov decision process theory""]",,,,,
KLh86DknDj7,2022,Reject,False,Discovering Classification Rules for Interpretable Learning with Linear Programming,"['Hakan Akyuz', 'Ilker Birbil']","[""Rule generation"", ""linear programming"", ""interpretability""]",,,,,
KNfuensPHDU,2022,Reject,False,Efficient Certification for Probabilistic Robustness,"['Victor Rong', 'Alexandre Megretski', 'Luca Daniel', 'Tsui-Wei Weng']","[""robustness"", ""neural networks"", ""deep learning""]",We make significant improvements to a probabilistic robustness certifier.,,,,
KOtxfjpQsq,2021,Reject,False,Meta-Model-Based Meta-Policy Optimization,"[""Takuya Hiraoka"", ""Takahisa Imagawa"", ""Voot Tangkaratt"", ""Takayuki Osa"", ""Takashi Onishi"", ""Yoshimasa Tsuruoka""]",[],,,,,
KPEFXR1HdIo,2022,Accept (Poster),False,Fine-grained Differentiable Physics: A Yarn-level Model for Fabrics,"['Deshan Gong', 'Zhanxing Zhu', 'Andrew J. Bulpitt', 'He Wang']",[],,,,,
KSSfF5lMIAg,2022,Accept (Poster),False,Model Agnostic Interpretability for Multiple Instance Learning,"['Joseph Early', 'Christine Evers', 'SArvapali Ramchurn']","[""multiple instance learning"", ""interpretability"", ""model-agnostic""]",We propose and compare several methods for model-agnostic interpretability for multiple instance learning.,2201.11701,cs.LG,2022-01-27 17:55:32+00:00,2022-01-28 09:58:57+00:00
KSugKcbNf9,2022,Accept (Poster),False,Transformers Can Do Bayesian Inference,"['Samuel MÃ¼ller', 'Noah Hollmann', 'Sebastian Pineda Arango', 'Josif Grabocka', 'Frank Hutter']",[],,2112.10510,cs.LG,2021-12-20 13:07:39+00:00,2022-02-08 10:26:16+00:00
KTEde38blNB,2021,Reject,True,Intervention Generative Adversarial Nets,"[""Jiadong Liang"", ""Liangyu Zhang"", ""Cheng Zhang"", ""Zhihua Zhang""]",[],,2008.03712,stat.ML,2020-08-09 11:51:54+00:00,2020-08-09 11:51:54+00:00
KTF1h2XWKZA,2022,Reject,False,Multi-batch Reinforcement Learning via Sample Transfer and Imitation Learning,"['Di Wu', 'Tianyu Li', 'David Meger', 'Michael Jenkin', 'Xue Liu', 'Gregory Dudek']","[""Multi-bacth"", ""batch reinfrocement learning"", ""sample transfer""]",We propose to use sample transfer and policy distallation to improve the take-level generation for bacth reinforcement leanring algorithms.,,,,
KTPuIsx4pmo,2022,Accept (Poster),False,Meta-Imitation Learning by Watching Video Demonstrations,"['Jiayi Li', 'Tao Lu', 'Xiaoge Cao', 'Yinghao Cai', 'Shuo Wang']","[""Meta-imitation Learning"", ""One-shot Learning"", ""Learning by Watching"", ""Generative Adversarial Networks""]",We present an approach of meta-imitation learning by watching video demonstrations from humans.,,,,
KTS3QeWxRQq,2021,Reject,False,Quantitative Understanding of VAE as a Non-linearly Scaled Isometric Embedding,"[""Akira Nakagawa"", ""Keizo Kato""]","[""unsupervised representation learning"", ""deep image compression""]",VAE can provide a practical quantitative analysis of input data by mapping to implicit isometric embedding.,,,,
KTlJT1nof6d,2021,Accept (Poster),False,Initialization and Regularization of Factorized Neural Layers,"[""Mikhail Khodak"", ""Neil A. Tenenholtz"", ""Lester Mackey"", ""Nicolo Fusi""]","[""model compression"", ""knowledge distillation"", ""multi-head attention"", ""matrix factorization""]","Principled initialization and regularization of factorized neural layers leads to strong performance in compression, knowledge distillation, and language modeling tasks.",,,,
KUDUoRsEphu,2021,Accept (Spotlight),False,"Learning Incompressible Fluid Dynamics from Scratch - Towards Fast, Differentiable Fluid Models that Generalize","[""Nils Wandel"", ""Michael Weinmann"", ""Reinhard Klein""]","[""Unsupervised Learning"", ""Fluid Dynamics"", ""U-Net""]","We present an unsupervised training framework for incompressible fluid dynamics that allows neural networks to perform fast, accurate, differentiable fluid simulations and generalize to new domain geometries.",2012.11893,physics.flu-dyn,2020-12-22 09:21:40+00:00,2021-03-24 00:04:46+00:00
KUmMSZ_r28W,2022,Reject,False,Particle Based Stochastic Policy Optimization,"['Qiwei Ye', 'Yuxuan Song', 'Chang Liu', 'Fangyun Wei', 'Tao Qin', 'Tie-Yan Liu']","[""reinforcement learning"", ""deep learning""]","We proposed a particle-based discrepancy minimization framework for stochastic policy optimization which enables different discrepancy measure choices, and it works well in both online and offline settings.",,,,
KVTkzgz3g8O,2021,Reject,False,TraDE: A Simple Self-Attention-Based Density Estimator,"[""Rasool Fakoor"", ""Pratik Anil Chaudhari"", ""Jonas Mueller"", ""Alex Smola""]","[""density estimation"", ""self-attention""]",A self-attention-based auto-regressive density estimator which performs significantly better than existing methods.,,,,
KVYq2Ea90PC,2022,Reject,False,A Study of Face Obfuscation in ImageNet,"['Kaiyu Yang', 'Jacqueline Yau', 'Li Fei-Fei', 'Jia Deng', 'Olga Russakovsky']","[""ImageNet"", ""Privacy"", ""Face Obfuscation""]",,,,,
KVhvw16pvi,2022,Reject,False,TAG: Task-based Accumulated Gradients for Lifelong learning,"['Pranshu Malviya', 'Balaraman Ravindran', 'Sarath Chandar']","[""Lifelong Learning"", ""Continual Learning"", ""Catastrophic forgetting""]",Proposed a task-aware optimizer for the lifelong learning setting that utilizes the directions taken by the parameters during the updates by additively accumulating the gradients specific to each task.,,,,
KWToR-Phbrz,2021,Reject,False,Beyond Trivial Counterfactual Generations with Diverse Valuable Explanations,"[""Pau Rodriguez"", ""Massimo Caccia"", ""Alexandre Lacoste"", ""Lee Zamparo"", ""Issam H. Laradji"", ""Laurent Charlin"", ""David Vazquez""]","[""Interpretability"", ""Counterfactual"", ""Explanations"", ""Black-Box""]",DiVE generates counterfactual explanations that are non-trivial or obvious and thus more informative,,,,
KYPz4YsCPj,2021,Accept (Poster),False,Inductive Representation Learning in Temporal Networks via Causal Anonymous Walks,"[""Yanbang Wang"", ""Yen-Yu Chang"", ""Yunyu Liu"", ""Jure Leskovec"", ""Pan Li""]","[""temporal networks"", ""inductive representation learning"", ""anonymous walk"", ""network motif""]","The paper proposes Causal Anonymous Walks (CAW) as an effective way to encode the dynamic laws that govern the evolution of temporal networks, which significantly improves inductive representation learning on those networks.",2101.05974,cs.LG,2021-01-15 05:47:26+00:00,2021-04-26 04:26:19+00:00
K_ETaDx3Iv,2021,Reject,False,FLAGNet : Feature Label based Automatic Generation Network for symbolic music,"[""SeongHyeon Go""]","[""cGAN"", ""RNN"", ""MIDI generation"", ""music""]",Creative and artistic music generator with understanding musical domain knowledge but a bit unstable.,,,,
Kao09W-oe8,2021,Reject,True,Channel-Directed Gradients for Optimization of Convolutional Neural Networks,"[""Dong Lao"", ""Peihao Zhu"", ""Peter Wonka"", ""Ganesh Sundaramoorthi""]","[""stochastic optimization"", ""Riemannian geometry"", ""Riemannian gradient flows"", ""convolutional neural nets""]",,2008.10766,cs.LG,2020-08-25 00:44:09+00:00,2020-08-25 00:44:09+00:00
KcImcc3j-qS,2021,Reject,True,Fast Predictive Uncertainty for Classification with Bayesian Deep Networks,"[""Marius Hobbhahn"", ""Agustinus Kristiadi"", ""Philipp Hennig""]","[""Bayesian Deep Learning"", ""Approximate Inference""]",We re-use an old method (the Laplace Bridge) in the context of Bayesian Deep Learning to improve computation time of the posterior predictive significantly for all Networks that have a Gaussian over the logits.,2003.01227,cs.LG,2020-03-02 22:29:03+00:00,2021-02-09 09:19:59+00:00
KcLlh3Qe7KU,2021,Reject,False,Ensembles of Generative Adversarial Networks for Disconnected Data,"[""Lorenzo Luzi"", ""Randall Balestriero"", ""Richard Baraniuk""]","[""GANs"", ""ensembles"", ""disconnected data""]",We show how ensembles of GANs are better suited than single GANs for learning distributions that generate disconnected data.,,,,
KcTBbZ1kM6K,2021,Reject,False,Out-of-Distribution Generalization Analysis via Influence Function,"[""Haotian Ye"", ""Chuanlong Xie"", ""Yue Liu"", ""Zhenguo Li""]",[],,2101.08521,cs.LG,2021-01-21 09:59:55+00:00,2021-01-21 09:59:55+00:00
KeBPcg5E3X,2022,Reject,False,Representation Disentanglement in Generative Models with Contrastive Learning,"['Shentong Mo', 'Zhun Sun', 'Shumin Han']",[],,,,,
KeI9E-gsoB,2022,Accept (Poster),False,Learning Curves for Gaussian Process Regression with Power-Law Priors and Targets,"['Hui Jin', 'Pradeep Kr. Banerjee', 'Guido Montufar']","[""Gaussian process regression"", ""kernel ridge regression"", ""generalization error"", ""power law"", ""neural tangent kernel""]",We derive the power-law decay rate of the generalization error in Gaussian process regression depending on the eigenspectrum of the prior and the target.,,,,
Kef8cKdHWpP,2022,Accept (Poster),False,DiffSkill: Skill Abstraction from Differentiable Physics for Deformable Object Manipulations with Tools,"['Xingyu Lin', 'Zhiao Huang', 'Yunzhu Li', 'Joshua B. Tenenbaum', 'David Held', 'Chuang Gan']","[""Deformable Object Manipulation"", ""Differentiable Physics""]","We propose DiffSkill, a novel framework for learning skill abstraction from differentiable physics and compose them to solve long-horizontal deformable object manipulations tasks from sensory observation.",,,,
KhLK0sHMgXK,2022,Accept (Spotlight),False,NASPY: Automated Extraction of Automated Machine Learning Models,"['Xiaoxuan Lou', 'Shangwei Guo', 'Jiwei Li', 'Yaoxin Wu', 'Tianwei Zhang']",[],"We present NASPY, an end-to-end adversarial framework to extract the networkarchitecture of deep learning models from Neural Architecture Search (NAS).",,,,
Ki5Mv0iY8C,2021,Reject,False,"On Flat Minima, Large Margins and Generalizability","[""Daniel Lengyel"", ""Nicholas Jennings"", ""Panos Parpas"", ""Nicholas Kantas""]",[],Demonstrating a strong correlation between flatness and large classification margins and discussing its consequences. ,,,,
KiFeuZu24k,2021,Reject,False,Global Self-Attention Networks for Image Recognition,"[""Zhuoran Shen"", ""Irwan Bello"", ""Raviteja Vemulapalli"", ""Xuhui Jia"", ""Ching-Hui Chen""]","[""self-attention"", ""neural network architecture"", ""image classification"", ""semantic segmentation""]",A fully-attentional backbone architecture for vision tasks.,,,,
KjR-3lBYB3y,2022,Reject,False,Learning an Object-Based Memory System,"['Yilun Du', 'Joshua B. Tenenbaum', 'TomÃ¡s Lozano-PÃ©rez', 'Leslie Pack Kaelbling']","[""Long Term Memory"", ""State Estimation"", ""Robot Learning"", ""Object-Centric Learning""]",,,,,
KjeUNkU2d26,2021,Reject,False,Rethinking Content and Style: Exploring Bias for Unsupervised Disentanglement,"[""Xuanchi Ren"", ""Tao Yang"", ""Wenjun Zeng"", ""Yuwang Wang""]","[""Unsupervised Disentanglement"", ""Content and Style Disentanglement"", ""Inductive Bias"", ""Representation Learning""]","Aiming  for unsupervised disentanglement, we introduce an inductive bias by assigning different  and  independent  roles  to  content  and  style  when  approximating  the  real data  distributions. ",,,,
KkIE-qePhW,2022,Reject,False,LSP : Acceleration and Regularization of Graph Neural Networks via Locality Sensitive Pruning of Graphs,"['Eitan Kosman', 'Dotan Di Castro', 'Joel Oren']","[""Graph Sparsification"", ""Graph Neural Networks"", ""Pruning Neural Networks""]","A graph edges pruning methodology for acceleration of graph neural networks, which aims to preserve similarities and dissimilarities of different environments of the graph.",,,,
Kkw3shxszSd,2021,Reject,False,Improving Generalizability of Protein Sequence Models via Data Augmentations,"[""Hongyu Shen"", ""Layne C. Price"", ""Mohammad Taha Bahadori"", ""Franziska Seeger""]",[],,,,,
KmNHWX9H7Kf,2022,Reject,False,Uniform Generalization Bounds for Overparameterized Neural Networks,"['Sattar Vakili', 'Michael Bromberg', 'Jezabel R Garcia', 'Da-shan Shiu', 'Alberto Bernacchia']","[""Information Gain"", ""Effective Dimension"", ""Overparameterized Neural Networks"", ""Neural Tangent Kernel"", ""Random Feature Kernel"", ""RKHS"", ""Mat\u00e9rn"", ""Uniform Error Bounds""]","We characterize eigendecay, information gain and uniform bounds on rate of error decay for overparameterized neural networks in kernel regimes. ",,,,
Kmsf3z-vGu,2022,Reject,False,Gradient-based Meta-solving and Its Applications to Iterative Methods for Solving Differential Equations,"['Sohei Arisaka', 'Qianxiao Li']","[""meta-learning"", ""differential equation"", ""iterative method""]",We developed a unified framework to apply meta-learning approach to a broader range of numerical problems and showed its advantage.,,,,
KmtVD97J43e,2022,Accept (Poster),False,Synchromesh: Reliable Code Generation from Pre-trained Language Models,"['Gabriel Poesia', 'Alex Polozov', 'Vu Le', 'Ashish Tiwari', 'Gustavo Soares', 'Christopher Meek', 'Sumit Gulwani']","[""program synthesis"", ""language models"", ""code generation""]","A framework to generate programs from large pre-trained language models (e.g. GPT-3, Codex) while satisfying syntactic and semantic constraints.",,,,
KmykpuSrjcq,2021,Accept (Poster),False,Prototypical Contrastive Learning of Unsupervised Representations,"[""Junnan Li"", ""Pan Zhou"", ""Caiming Xiong"", ""Steven Hoi""]","[""self-supervised learning"", ""unsupervised learning"", ""representation learning"", ""contrastive learning""]",We propose an unsupervised representation learning method that bridges contrastive learning with clustering in an EM framework.,,,,
KntaNRo6R48,2022,Accept (Poster),False,L0-Sparse Canonical Correlation Analysis,"['Ofir Lindenbaum', 'Moshe Salhov', 'Amir Averbuch', 'Yuval Kluger']",[],We propose a new $\ell_0$-CCA method for learning correlated representations based on sparse subsets of variables from two observed modalities.,,,,
KoCzLK1Hugc,2022,Reject,True,Adversarial robustness against multiple $l_p$-threat models at the price of one and how to quickly fine-tune robust models to another threat model,"['Francesco Croce', 'Matthias Hein']","[""adversarial robustness"", ""multiple norms"", ""adversarial training"", ""fine-tuning""]","We propose a version of adversarial training for fast multiple norms robustness, and transfer robustness among threat models via fine-tuning.",2105.12508,cs.LG,2021-05-26 12:20:47+00:00,2021-05-26 12:20:47+00:00
KpfasTaLUpq,2021,Accept (Poster),False,"Deep Encoder, Shallow Decoder: Reevaluating Non-autoregressive Machine Translation","[""Jungo Kasai"", ""Nikolaos Pappas"", ""Hao Peng"", ""James Cross"", ""Noah Smith""]","[""Machine Translation"", ""Sequence Modeling"", ""Natural Language Processing""]","We show that the speed disadvantage for autoregressive baselines to evaluate non-autoregressive machine translation is overestimated in three aspects: suboptimal layer allocation, insufficient speed measurement, and lack of knowledge distillation.",,,,
Kr7CrZPPPo,2021,Reject,False,Learning a Non-Redundant Collection of Classifiers,"[""Daniel Pace"", ""Alessandra Russo"", ""Murray Shanahan""]",[],Learning to isolate distinct predictive signals using an information-theoretic minimal redundancy criterion.,,,,
KsN9p5qJN3,2021,Reject,False,Energy-based Out-of-distribution Detection for Multi-label Classification,"[""Haoran Wang"", ""Weitang Liu"", ""Alex Bocchieri"", ""Yixuan Li""]",[],"We investigate OOD detection for multi-label classification networks, and propose an energy-based method which is both theoretically meaningful and empirically effective, establishing state-of-the-art performance on common benchmarks. ",,,,
KtH8W3S_RE,2021,Accept (Poster),False,Multi-resolution modeling of a discrete stochastic process identifies causes of cancer,"[""Adam Uri Yaari"", ""Maxwell Sherman"", ""Oliver Clarke Priebe"", ""Po-Ru Loh"", ""Boris Katz"", ""Andrei Barbu"", ""Bonnie Berger""]","[""Computational Biology"", ""non-stationary stochastic processes"", ""cancer research"", ""deep learning"", ""probabelistic models"", ""graphical models""]","We integrate a deep learning framework with a probabilistic model to learn a discrete stochastic process at arbitrary length scales, the method accurately and efficiently model mutations load in a tumor and detect cancer driver mutations genome-wide",,,,
KubHAaKdSr7,2021,Reject,False,Modifying Memories in Transformer Models,"[""Chen Zhu"", ""Ankit Singh Rawat"", ""Manzil Zaheer"", ""Srinadh Bhojanapalli"", ""Daliang Li"", ""Felix Yu"", ""Sanjiv Kumar""]","[""Transformers"", ""memorization"", ""question answering""]",We propose a new task of modifying implicit knowledge stored in parameters of Transformer models.,2012.00363,cs.CL,2020-12-01 09:39:13+00:00,2020-12-01 09:39:13+00:00
Kvbr8NicKq,2022,Reject,False,Fast and Reliable Evaluation of Adversarial Robustness with Minimum-Margin Attack,"['Ruize Gao', 'Jiongxiao Wang', 'Kaiwen Zhou', 'Feng Liu', 'Binghui Xie', 'Gang Niu', 'Bo Han', 'James Cheng']","[""adversarial machine learning"", ""evaluation of adversarial robustness""]",We propose a fast and reliable method to evaluate the adversarial robustness.,,,,
KvyxFqZS_D,2021,Accept (Oral),False,Global Convergence of Three-layer Neural Networks in the Mean Field Regime,"[""Huy Tuan Pham"", ""Phan-Minh Nguyen""]","[""deep learning theory""]",We propose a rigorous framework for three-layer neural networks in the mean field regime and prove a global convergence guarantee.,2105.05228,cs.LG,2021-05-11 17:45:42+00:00,2021-05-11 17:45:42+00:00
KwgQn_Aws3_,2021,Reject,False,Interpretable Sequence Classification Via Prototype Trajectory,"[""Dat Hong"", ""Stephen Baek"", ""Tong Wang""]","[""interpretable"", ""RNN"", ""prototypes""]",The paper proposes an interpretable sequence classification model based on trajectories of prototypes.,,,,
Kwm8I7dU-l5,2022,Accept (Poster),True,Graph-Guided Network for Irregularly Sampled Multivariate Time Series,"['Xiang Zhang', 'Marko Zeman', 'Theodoros Tsiligkaridis', 'Marinka Zitnik']","[""time seres"", ""irregular time series"", ""graph neural networks"", ""attention mechanism"", ""time series classification"", ""multivariate time series"", ""representation learning"", ""embeddings""]",,2110.05357,cs.LG,2021-10-11 15:37:58+00:00,2021-10-11 15:37:58+00:00
KxUlUb26-P3,2021,Reject,True,PABI: A Unified PAC-Bayesian Informativeness Measure for Incidental Supervision Signals,"[""Hangfeng He"", ""Mingyuan Zhang"", ""Qiang Ning"", ""Dan Roth""]","[""informativeness measure"", ""incidental supervision"", ""natural language processing""]",A unified informativeness measure to foreshadow the benefits of incidental supervision signals in natural language processing,2006.05500,cs.LG,2020-06-09 20:59:42+00:00,2021-09-10 16:32:23+00:00
KxbhdyiPHE,2022,Accept (Spotlight),False,Learning Altruistic Behaviours in Reinforcement Learning without External Rewards,"['Tim Franzmeyer', 'Mateusz Malinowski', 'Joao F. Henriques']","[""reinforcement learning"", ""altruistic behavior in AI"", ""multi-agent systems""]",We propose and investigate unsupervised training of agents to behave altruistically towards others by actively maximizing others' choice.,,,,
Kz42iQirPJI,2021,Reject,False,Towards Learning to Remember in Meta Learning of Sequential Domains,"[""Zhenyi Wang"", ""Tiehang Duan"", ""Donglin Zhan"", ""Changyou Chen""]","[""Meta learning"", ""Continual Learning"", ""Sequential Domain Learning""]","First work to investigate learning to remember in meta learning of *sequential domains*, achieving state of the art compared with existing continual learning techniques.",,,,
Kzg0XmE6mxu,2021,Reject,False,Adversarial Deep Metric Learning,"[""Thomas Kobber Panum"", ""Zi Wang"", ""Pengyu Kan"", ""Earlence Fernandes"", ""Somesh Jha""]","[""Deep metric learning"", ""adversarial robustness"", ""adversarial examples"", ""adversarial perturbations"", ""adversarial training""]","We conduct a systematic exploration of the robustness of Deep Metric Learning models, and propose a method to improve their robustness towards adversarial perturbations.",,,,
L-88RyVtXGr,2021,Reject,False,Learning Deeply Shared Filter Bases for Efficient ConvNets,"[""Woochul Kang"", ""Daeyeon Kim""]","[""Deep learning"", ""ConvNets"", ""parameter sharing"", ""model compression"", ""convolutional neural networks"", ""recursive networks""]",We propose an efficient recursive parameter-sharing structure and an effective training mechanism for ConvNets.,,,,
L01Nn_VJ9i,2022,Accept (Poster),False,Back2Future: Leveraging Backfill Dynamics for Improving Real-time Predictions in Future,"['Harshavardhan Kamarthi', 'Alexander RodrÃ­guez', 'B. Aditya Prakash']","[""Epidemic Forecasting"", ""Data revisions"", ""Graph Representation learning"", ""Time Series Forecasting""]",We study the problem of multi-variate backfill for both features and targets and show how to leverage our insights for more general neural framework to improve both model predictions and evaluation,,,,
L1L2G43k14n,2022,Reject,False,WHY FLATNESS DOES AND DOES NOT CORRELATE WITH GENERALIZATION FOR DEEP NEURAL NETWORKS ,"['Shuofeng Zhang', 'Isaac Reid', 'Guillermo Valle-Perez', 'Ard A. Louis']","[""flatness"", ""Bayesian learning"", ""generalization theory""]","The Bayesian prior of a function, instead of local flatness of loss landscape, is the real reason behind first-order generalization of deep neural networks.",,,,
L2LEB4vd9Qw,2021,Reject,False,Multimodal Attention for Layout Synthesis in Diverse Domains,"[""Kamal Gupta"", ""Vijay Mahadevan"", ""Alessandro Achille"", ""Justin Lazarow"", ""Larry S. Davis"", ""Abhinav Shrivastava""]","[""layout generation"", ""layout synthesis"", ""multimodal attention"", ""transformers"", ""document layouts"", ""generative model"", ""3D""]","A simple robust generative model for layouts; results on diverse real world datasets (3D objects, image, document layouts, mobile app wireframes)",,,,
L2V-VQ7Npl0,2022,Reject,False,Reward Learning as Doubly Nonparametric Bandits:  Optimal Design and Scaling Laws,"['Kush Bhatia', 'Wenshuo Guo', 'Jacob Steinhardt']","[""reward learning"", ""Gaussian process bandits"", ""nonparametric learning"", ""reproducing kernel Hilbert spaces""]","We introduce a new framework, doubly nonparametric bandits, to study the reward learning and the associated optimal experiment design problem.",,,,
L2a_bcarHcF,2022,Reject,False,Linear algebra with transformers,['Francois Charton'],"[""Mathematics"", ""Transformers"", ""Computation"", ""Numerical"", ""Linear algebra""]","We train transformers to solve problems of linear algebra (eigenvalues, matrix inversion), with high accuracy",,,,
L2jrxKBloq8,2022,Reject,False,Second-Order Rewards For Successor Features,"['Norman L Tasfi', 'Miriam Capretz']",[],,,,,
L3_SsSNMmy,2022,Accept (Spotlight),False,On the Connection between Local Attention and Dynamic Depth-wise Convolution,"['Qi Han', 'Zejia Fan', 'Qi Dai', 'Lei Sun', 'Ming-Ming Cheng', 'Jiaying Liu', 'Jingdong Wang']","[""local attention"", ""depth-wise convolution"", ""dynamic depth-wise convolution"", ""weight sharing"", ""dynamic weight""]","We study the connection between local attention and dynamic depth-wise convolution in terms of sparse connectivity, weight sharing, and dynamic weight",,,,
L3iGqaCTWS9,2021,Reject,False,Hybrid and Non-Uniform DNN quantization methods using Retro Synthesis data for efficient inference,"[""TEJPRATAP GVSL"", ""Raja Kumar"", ""Pradeep NS""]","[""quantization"", ""dnn inference"", ""data free quantization"", ""synthetic data"", ""model compression""]",,,,,
L4n9FPoQL1,2021,Reject,True,Classify and Generate Reciprocally: Simultaneous Positive-Unlabelled Learning and Conditional Generation with Extra Data,"[""Bing Yu"", ""Ke Sun"", ""He Wang"", ""Zhouchen Lin"", ""Zhanxing Zhu""]",[],,2006.07841,cs.LG,2020-06-14 08:27:40+00:00,2020-06-14 08:27:40+00:00
L4v_5Qtshj7,2021,Reject,False,Goal-Driven Imitation Learning from Observation by Inferring Goal Proximity,"[""Andrew Szot"", ""Youngwoon Lee"", ""Shao-Hua Sun"", ""Joseph J Lim""]","[""Imitation Learning"", ""Learning from Observation""]",,,,,
L5b6jUonKFB,2021,Reject,False,Deep Continuous Networks,"[""Nergis Tomen"", ""Silvia Laura Pintea"", ""Jan van Gemert""]","[""continuous representations"", ""neuroscience"", ""convolutional neural networks"", ""gaussian scale-space"", ""learnable scale"", ""receptive field size"", ""neural ODEs"", ""pattern completion""]",Linking CNNs and biological models via spatio-temporally continuous representations and learnable scale,,,,
L7Irrt5sMQa,2021,Reject,False,The Surprising Power of Graph Neural Networks with Random Node Initialization,"[""Ralph Abboud"", ""Ismail Ilkan Ceylan"", ""Martin Grohe"", ""Thomas Lukasiewicz""]","[""graph representation learning"", ""graph neural networks"", ""expressiveness"", ""universality"", ""random node initialization"", ""Weisfeiler-Lehman heuristic"", ""higher-order graph neural networks""]","We prove that graph neural networks with random node initialization are universal, and verify this theoretical expressivity with a detailed empirical evaluation using carefully constructed datasets.",,,,
L7WD8ZdscQ5,2021,Accept (Poster),False,The Role of Momentum Parameters in the Optimal Convergence of Adaptive Polyak's Heavy-ball Methods,"[""Wei Tao"", ""Sheng Long"", ""Gaowei Wu"", ""Qing Tao""]","[""Deep learning"", ""convex optimization"", ""momentum methods"", ""adaptive heavy-ball methods"", ""optimal convergence""]",A theory-practice gap in convex optimization and deep learning is bridged by giving a novel convergence analysis of the last Iterate of adaptive Heavy-ball methods.,2102.07314,cs.LG,2021-02-15 02:57:14+00:00,2021-02-15 02:57:14+00:00
L7wzpQttNO,2022,Accept (Poster),False,BDDM: Bilateral Denoising Diffusion Models for Fast and High-Quality Speech Synthesis,"['Max W. Y. Lam', 'Jun Wang', 'Dan Su', 'Dong Yu']","[""Speech Synthesis"", ""Vocoder"", ""Generative Model"", ""Diffusion Model""]","In this paper, we propose a novel bilateral denoising diffusion model (BDDM), which takes significantly fewer sampling steps than the SOTA diffusion-based vocoder to generate high-quality audio samples.",,,,
L8BElg6Qldb,2021,Reject,True,Nonvacuous Loss Bounds with Fast Rates for Neural Networks via Conditional Information Measures,"[""Fredrik Hellstr\u00f6m"", ""Giuseppe Durisi""]",[],,2010.11552,cs.LG,2020-10-22 09:23:25+00:00,2021-03-10 10:23:34+00:00
LBv-JtAmm4P,2022,Reject,True,Is Heterophily A Real Nightmare For Graph Neural Networks on Performing Node Classification?,"['Sitao Luan', 'Chenqing Hua', 'Qincheng Lu', 'Jiaqi Zhu', 'Mingde Zhao', 'Shuyuan Zhang', 'Xiao-Wen Chang', 'Doina Precup']","[""Graph Neural Networks"", ""Heterophily"", ""Filterbank"", ""Adaptive Channel Mixing""]",This paper analyzes heterophily problems for graph neural networks and propose adaptive channel mixing framework to boost the performance of GNNs on node classification tasks.,2109.05641,cs.LG,2021-09-12 23:57:05+00:00,2021-09-12 23:57:05+00:00
LBvk4QWIUpm,2022,Accept (Spotlight),False,Tighter Sparse Approximation Bounds for ReLU Neural Networks,"['Carles Domingo-Enrich', 'Youssef Mroueh']","[""neural network"", ""two-layer"", ""infinite-width"", ""approximation"", ""sparse"", ""Radon transform"", ""Fourier transform"", ""ReLU""]","We show conditions under which a function can be represented by an infinite-width neural network on a bounded set, and refine sparse neural network approximation bounds.",,,,
LDAwu17QaJz,2022,Accept (Poster),False,MAML is a Noisy Contrastive Learner,"['Chia Hsiang Kao', 'Wei-Chen Chiu', 'Pin-Yu Chen']","[""Meta learning"", ""contrastive learning"", ""few shot learning""]",The Model-agnostic meta learning (MAML) algorithm is a noisy supervised contrastive learner where the noise comes from random initialization and cross-task interference.,,,,
LDSeViRs4-Q,2021,Reject,True,Increasing-Margin Adversarial (IMA) training to Improve Adversarial Robustness of Neural Networks,"[""Linhai Ma"", ""Liang Liang""]","[""Robustness"", ""CNN"", ""Medical image classification""]",A new adversarial training method with individualized margin estimation to improve robustness against adversarial noises.,2005.09147,cs.CV,2020-05-19 00:26:52+00:00,2021-10-19 21:28:23+00:00
LFjnKhTNNQD,2021,Reject,False,Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization,"[""Manli Shu"", ""Zuxuan Wu"", ""Micah Goldblum"", ""Tom Goldstein""]","[""adversarial training"", ""distributional shifts""]","This work proposes a feature space adversarial training method based on Batchnorm statistics, to attain generalization to distributional shifted data.",,,,
LFs3CnHwfM,2021,Reject,False,A Robust Fuel Optimization Strategy For Hybrid Electric Vehicles: A Deep Reinforcement Learning Based Continuous Time Design Approach,"[""Nilanjan Mukherjee"", ""Sudeshna Sarkar""]","[""Deep Reinforcement Learning"", ""Optimal Control"", ""Fuel Management System"", ""Hybrid Electric vehicles"", ""H\u221e Performance Index""]",A state of the art continuous time robust deep reinforcement learning based fuel optimization strategy using concurrent learning for hybrid electric vehicles.,,,,
LGTmlJ10Kes,2022,Reject,False,Curriculum Discovery through an Encompassing Curriculum Learning Framework,"['Mohamed Elgaar', 'Hadi Amiri']","[""curriculum learning"", ""natural language processing""]","CL framework that works by partitioning training data in three groups based on sample difficulty, developing logistic functions to effectively weight samples, and discovering new curricula that perform best for given models and datasets.",,,,
LGgdb4TS4Z,2021,Accept (Spotlight),False,Topology-Aware Segmentation Using Discrete Morse Theory,"[""Xiaoling Hu"", ""Yusu Wang"", ""Li Fuxin"", ""Dimitris Samaras"", ""Chao Chen""]","[""Topology"", ""Morse theory"", ""Image segmentation""]",This paper proposes a loss based on discrete Morse theory to train deep image segmentation networks for better topological accuracy.,,,,
LI2bhrE_2A,2022,Accept (Spotlight),False,Iterative Refinement Graph Neural Network for Antibody Sequence-Structure Co-design,"['Wengong Jin', 'Jeremy Wohlwend', 'Regina Barzilay', 'Tommi S. Jaakkola']","[""Drug Discovery"", ""Antibody Design"", ""Generative Models"", ""Graph Generation""]",We propose a new graph-based generative model for antibody design,,,,
LIOgGKRCYkG,2021,Reject,True,Target Training: Tricking Adversarial Attacks to Fail,"[""Blerta Lindqvist""]","[""adversarial machine learning""]",Target Training tricks untargeted attacks into becoming attacks targeted at designated target classes.,2006.04504,cs.LG,2020-06-08 12:22:07+00:00,2020-06-08 12:22:07+00:00
LIR3aVGIlln,2021,Reject,False,Equivariant Normalizing Flows for Point Processes and Sets,"[""Marin Bilo\u0161"", ""Stephan G\u00fcnnemann""]","[""point process"", ""set"", ""normalizing flow"", ""equivariance""]",Having permutation equivariant mapping in continuous normalizing flows allows modeling densities over sets.,,,,
LK8bvVSw6rn,2022,Reject,False,How to measure deep uncertainty estimation performance and which models are naturally better at providing it,"['Ido Galil', 'Mohammed Dabbah', 'Ran El-Yaniv']","[""non-Bayesian uncertainty estimation"", ""selective prediction"", ""transformer"", ""vision transformer"", ""vit"", ""risk-coverage curve"", ""selective classification"", ""classification with a reject option""]","Analyzing 484 deep neural models for ImageNet classification, we determine the best architectures and training regimes leading to superior uncertainty estimation",,,,
LLHwQh9zEb,2022,Reject,True,Permutation invariant graph-to-sequence model for template-free retrosynthesis and reaction prediction,"['Zhengkai Tu', 'Connor W. Coley']","[""retrosynthesis"", ""reaction prediction"", ""graph neural network"", ""Transformer"", ""positional embedding""]","A novel Graph2SMILES architecture for computer-aided organic synthesis that yields noticeable improvement over Transformer baselines, while eliminating the need for input SMILES augmentation",2110.09681,cs.LG,2021-10-19 01:23:15+00:00,2021-10-19 01:23:15+00:00
LLoe0U9ShkN,2021,Reject,True,Global inducing point variational posteriors for Bayesian neural networks and deep Gaussian processes,"[""Sebastian W. Ober"", ""Laurence Aitchison""]","[""Bayesian neural networks"", ""deep Gaussian processes"", ""variational inference"", ""inducing points""]",We design an approximate posterior that unifies inference in Bayesian neural networks and deep Gaussian processes by taking the structure of these models into account.,2005.08140,stat.ML,2020-05-17 01:10:37+00:00,2021-06-22 13:39:01+00:00
LM17I_oVVPB,2022,Reject,False,A Simple Reward-free Approach to Constrained Reinforcement Learning,"['Sobhan Miryoosefi', 'Chi Jin']","[""constrained reinforcement learning"", ""reward-free"", ""reinforcement learning theory"", ""approachability"", ""linear function approximation""]","This paper provides a meta algorithm that takes a reward-free RL solver, and convert it to an algorithm for solving constrained RL problems; our framework enables the direct translation of any progress in reward-free RL to constrained RL setting.",,,,
LMslR3CTzE_,2021,Reject,False,Neural Subgraph Matching,"[""Zhitao Ying"", ""Andrew Wang"", ""Jiaxuan You"", ""Chengtao Wen"", ""Arquimedes Canedo"", ""Jure Leskovec""]","[""Graph neural networks"", ""Subgraph matching"", ""Order Embedding""]",Neural approach to learning the problem of subgraph isomorphism,,,,
LNmNWds-q-J,2022,Reject,False,3D Pre-training improves GNNs for Molecular Property Prediction,"['Hannes StÃ¤rk', 'Dominique Beaini', 'Gabriele Corso', 'Prudencio Tossou', 'Christian Dallago', 'Stephan GÃ¼nnemann', 'Pietro Lio']","[""graph neural networks"", ""deep learning"", ""self-supervised learning"", ""molecular representation""]",We pre-train GNNs to understand the geometry of molecules given only their 2D molecular graph.,,,,
LNtTXJ9XXr,2021,Reject,False,Adversarial Masking: Towards Understanding Robustness Trade-off for Generalization,"[""Minhao Cheng"", ""Zhe Gan"", ""Yu Cheng"", ""Shuohang Wang"", ""Cho-Jui Hsieh"", ""Jingjing Liu""]","[""Adversarial Machine Learning"", ""Adversarial Robustness"", ""Adversarial Training"", ""Generalization""]","We introduce a new hypothesis to understand the trade-off between robustness and natural accuracy, and further propose a new method to achieve better generalization using adversarial examples..",,,,
LOz0xDpw4Y,2022,Reject,False,Learning to Efficiently Sample from Diffusion Probabilistic Models,"['Daniel Watson', 'Jonathan Ho', 'Mohammad Norouzi', 'William Chan']",[],We present a simple procedure that discovers log-likelihood-optimal strides for score-based generative models. ,,,,
LQCUmLgFlR,2022,Reject,False,On Optimal Early Stopping: Overparametrization versus Underparametrization,"['Ruoqi Shen', 'Liyao Gao', 'Yian Ma']","[""Early stopping"", ""Overparameterization"", ""Implicit regularization"", ""Generalization"", ""Learning theory""]",,,,,
LQnyIk5dUA,2022,Reject,False,ZeroSARAH: Efficient Nonconvex Finite-Sum Optimization with Zero Full Gradient Computations,"['Zhize Li', 'Slavomir Hanzely', 'Peter RichtÃ¡rik']","[""nonconvex optimization"", ""distributed optimization"", ""finite-sum optimization"", ""zero full gradient computation"", ""variance reduction""]","We propose ZeroSARAH (and distributed D-ZeroSARAH) for solving both standard and distributed nonconvex finite-sum problems without requiring any full gradient computations, not even for the initial point.",,,,
LSFCEb3GYU7,2021,Accept (Spotlight),False,Emergent Symbols through Binding in External Memory,"[""Taylor Whittington Webb"", ""Ishan Sinha"", ""Jonathan Cohen""]","[""abstract rules"", ""out-of-distribution generalization"", ""external memory"", ""indirection"", ""variable binding""]","We introduce a new architecture,  the Emergent Symbol Binding Network, that enables rapid learning of abstract rules and strong generalization of those rules to novel entities.",,,,
LT0KSFnQDWF,2021,Reject,True,Improving Graph Neural Network Expressivity via Subgraph Isomorphism Counting,"[""Giorgos Bouritsas"", ""Fabrizio Frasca"", ""Stefanos Zafeiriou"", ""Michael M. Bronstein""]","[""graph neural networks"", ""graph representation learning"", ""network analysis"", ""network motifs"", ""subgraph isomoprhism""]",We show that enhancing message passing neural networks with subgraph encodings improves their expressive power and allows incorporating domain specific prior knowledge,2006.09252,cs.LG,2020-06-16 15:30:31+00:00,2021-07-05 13:22:05+00:00
LUpE0A3Q-wz,2022,Reject,False,On Convergence of Federated Averaging Langevin Dynamics,"['Wei Deng', 'Yian Ma', 'Zhao Song', 'Qian Zhang', 'Guang Lin']","[""federated learning"", ""Langevin dynamics"", ""federated averaging"", ""posterior inference"", ""MCMC""]",We propose a federated averaging Langevin algorithm (FA-LD) for uncertainty quantification and mean predictions with distributed clients. ,,,,
LVotkZmYyDi,2021,Accept (Poster),False,Proximal Gradient Descent-Ascent: Variable Convergence under KÅ Geometry,"[""Ziyi Chen"", ""Yi Zhou"", ""Tengyu Xu"", ""Yingbin Liang""]","[""Kurdyka-\u0141ojasiewicz geometry"", ""minimax"", ""nonconvex"", ""proximal gradient descent-ascent"", ""variable convergence""]",This is the first work on variable convergence of proximal gradient descent-ascent algorithm for nonconvex minimax optimization under ubiquitous Kurdyka-Åojasiewicz geometry.  ,2102.04653,math.OC,2021-02-09 05:35:53+00:00,2021-02-17 16:51:36+00:00
LXMSvPmsm0g,2021,Accept (Poster),False,Long Live the Lottery: The Existence of Winning Tickets in Lifelong Learning,"[""Tianlong Chen"", ""Zhenyu Zhang"", ""Sijia Liu"", ""Shiyu Chang"", ""Zhangyang Wang""]","[""lottery tickets"", ""winning tickets"", ""lifelong learning""]","Proposed novel bottom-up lifelong pruning effectively identify the winning tickets, which significantly improve the performance of learning over continual tasks",,,,
LYpBYvxIY_R,2022,Reject,False,Cost-Sensitive Hierarchical Classification through Layer-wise Abstentions,"['Alycia Lee', 'Anthony L Pineci', 'Uriah Israel', 'Omer Bar-Tal', 'Leeat Keren', 'David A. Van Valen', 'Anima Anandkumar', 'Yisong Yue', 'Anqi Liu']","[""cost-sensitive learning"", ""hierarchical classification"", ""learning to abstain""]",A cost-sensitive hierarchical classification method by optimizing layer-wise abstaining losses,,,,
LZVXOnSrD0Y,2022,Reject,False,Pareto Frontier Approximation Network (PA-Net) Applied to Multi-objective TSP,"['Ishaan Mehta', 'Sajad Saeedi']","[""Robotics"", ""planning"", ""TSP"", ""RL"", ""Multi Objective Optimization"", ""Pareto Optimality""]",PA-Net: a network that approximates Pareto Frontier for Multi Objective TSP problems.,,,,
L_sHGieq1D,2022,Reject,False,Adversarial Style Augmentation for Domain Generalized Urban-Scene Segmentation,"['Zhun Zhong', 'Yuyang Zhao', 'Gim Hee Lee', 'Nicu Sebe']","[""Domain Generalization"", ""Semantic Segmentation"", ""Adversarial Style Augmentation""]","We propose a novel adversarial style augmentation approach for domain generalization in semantic segmentation, which is easy to implement and can effectively improve the model performance on unseen real domains.",,,,
Lc28QAB4ypz,2021,Accept (Poster),False,Fast And Slow Learning Of Recurrent Independent Mechanisms,"[""Kanika Madan"", ""Nan Rosemary Ke"", ""Anirudh Goyal"", ""Bernhard Sch\u00f6lkopf"", ""Yoshua Bengio""]","[""modular representations"", ""better generalization"", ""learning mechanisms""]",Different time scale learning of independent mechanisms can lead to a better generalization.,2105.08710,cs.LG,2021-05-18 17:50:32+00:00,2021-05-19 03:10:30+00:00
LcF-EEt8cCC,2022,Accept (Poster),False,Denoising Likelihood Score Matching for Conditional Score-based Data Generation,"['Chen-Hao Chao', 'Wei-Fang Sun', 'Bo-Wun Cheng', 'Yi-Chen Lo', 'Chia-Che Chang', 'Yu-Lun Liu', 'Yu-Lin Chang', 'Chia-Ping Chen', 'Chun-Yi Lee']","[""score-based generative model"", ""conditional sampling""]","In this paper, we theoretically formulate a new training objective, called Denoising Likelihood Score Matching (DLSM) loss, for the classifier to match the gradients of the true log likelihood density. ",,,,
LcPefbNSwx_,2021,Reject,False,Factor Normalization for Deep Neural Network Models,"[""Haobo Qi"", ""Jing Zhou"", ""Hansheng Wang""]","[""factor normalization"", ""ultrahigh dimensional features"", ""adaptive learning rate"", ""factor decomposition""]",We develop a new factor normalization method for fast deep neural network training.,,,,
LczpUPwCnR1,2022,Reject,True,ES-Based Jacobian Enables Faster Bilevel Optimization,"['Daouda Sow', 'Kaiyi Ji', 'Yingbin Liang']","[""Evolution Strategies"", ""Computational Complexity"", ""Jacobian Matrix"", ""Stochastic Algorithm"", ""Bilevel Optimization""]","This paper proposes a novel bilevel optimization approach based on ES-based Jacobian estimation, which has provable convergence guarantee and substantially outperforms the existing baselines.",2110.07004,cs.LG,2021-10-13 19:36:50+00:00,2022-02-02 18:26:05+00:00
LdEhiMG9WLO,2022,Accept (Poster),False,Revisit Kernel Pruning with Lottery Regulated Grouped Convolutions,"['Shaochen Zhong', 'Guanqun Zhang', 'Ningjia Huang', 'Shuai Xu']","[""structured pruning"", ""efficient computing"", ""parallel computing"", ""grouped convolution"", ""lottery ticket"", ""weights shifting""]","A simple yet effective structured pruning framework based on kernel pruning, weights shifting, and grouped convolutions.",,,,
Ldau9eHU-qO,2021,Accept (Poster),False,Learning from Demonstration with Weakly Supervised Disentanglement,"[""Yordan Hristov"", ""Subramanian Ramamoorthy""]","[""representation learning for robotics"", ""physical symbol grounding"", ""semi-supervised learning""]","We propose a generative model-based approach to learning interpretable robot trajectory representations from demonstrations (image embeddings and end-effector trajectories) paired with coarse labels, which provide a form of weak supervision.",,,,
LdlwbBP2mlq,2022,Accept (Oral),True,Minibatch vs Local SGD with Shuffling: Tight Convergence Bounds and Beyond,"['Chulhee Yun', 'Shashank Rajput', 'Suvrit Sra']","[""Local SGD"", ""Minibatch SGD"", ""Shuffling"", ""Without-replacement"", ""Convex Optimization"", ""Stochastic Optimization"", ""Federated Learning"", ""Large Scale Learning"", ""Distributed Learning""]","We provide tight upper and lower bounds on convergence rates of shuffling-based minibatch SGD and local SGD, and propose an algorithmic modification that improves convergence rates beyond our lower bounds.",2110.10342,cs.LG,2021-10-20 02:25:25+00:00,2021-10-20 02:25:25+00:00
Le8fg2ppDSv,2022,Reject,False,HydraSum - Disentangling Stylistic Features in Text Summarization using Multi-Decoder Models,"['Tanya Goyal', 'Nazneen Rajani', 'Wenhao Liu', 'Wojciech Maciej Kryscinski']","[""summarization""]",,,,,
LedObtLmCjS,2022,Accept (Poster),False,Bi-linear Value Networks for Multi-goal Reinforcement Learning,"['Ge Yang', 'Zhang-Wei Hong', 'Pulkit Agrawal']","[""Multi-goal reinforcement learning"", ""universal value function approximator""]",We propose a bilinear value function for multi-goal reinforcement learning and show superior sample efficiency and generalizability.,,,,
LgjKqSjDzr,2022,Reject,False,SALT : Sharing Attention between Linear layer and Transformer for tabular dataset,"['Juseong Kim', 'Jinsun Park', 'Giltae Song']","[""Tabular data"", ""Attention matrix"", ""Transformer"", ""Deep learning""]","A novel hybrid deep network architecture for tabular data, dubbed SALT (Sharing Attention between Linear layer and Transformer).",,,,
LhAqAxwH5cn,2021,Reject,False,Robust Loss Functions for Complementary Labels Learning,"[""Defu Liu"", ""Guowu Yang""]","[""Complementary Labels"", ""Robustness"", ""Machine Learning""]",We introduce a novel algorithm of complementary-label learning with the robustness of loss function and the empirical results validate the superiority of our method to current state-of-the-art methods.,,,,
LhObGCkxj4,2022,Reject,False,New Perspective on the Global Convergence of Finite-Sum Optimization,"['Lam M. Nguyen', 'Trang H. Tran', 'Marten van Dijk']","[""non-convex optimization"", ""overparameterized"", ""optimization for deep learning"", ""finite-sum"", ""global minimum""]",We propose a new representation for analyzing the machine learning minimization problem to find an approximate global solution. ,2202.03524,cs.LG,2022-02-07 21:23:16+00:00,2022-02-07 21:23:16+00:00
LhY8QdUGSuw,2021,Accept (Poster),False,Anatomy of Catastrophic Forgetting: Hidden Representations and Task Semantics,"[""Vinay Venkatesh Ramasesh"", ""Ethan Dyer"", ""Maithra Raghu""]","[""Catastrophic forgetting"", ""continual learning"", ""representation analysis"", ""representation learning""]","We study the layerwise change in representations due to catastrophic forgetting, and use our understanding to study how task similarity influences forgetting.",,,,
LiX3ECzDPHZ,2021,Accept (Poster),False,X2T: Training an X-to-Text Typing Interface with Online Learning from User Feedback,"[""Jensen Gao"", ""Siddharth Reddy"", ""Glen Berseth"", ""Nicholas Hardy"", ""Nikhilesh Natraj"", ""Karunesh Ganguly"", ""Anca Dragan"", ""Sergey Levine""]","[""reinforcement learning"", ""human-computer interaction""]",We use online learning from user feedback to train an adaptive interface for typing words using inputs from a brain implant or webcam.,,,,
LjFGgI-_tT0,2021,Reject,False,"BayesAdapter: Being Bayesian, Inexpensively and Robustly, via Bayesian Fine-tuning","[""Zhijie Deng"", ""Xiao Yang"", ""Hao Zhang"", ""Yinpeng Dong"", ""Jun Zhu""]","[""Bayesian neural networks"", ""Bayesian fine-tuning"", ""uncertainty estimation"", ""OOD detection""]",We propose to obtain a reliable BNN by fine-tuning a pre-trained DNN under uncertainty regularization with minimal added overheads.,,,,
LkFG3lB13U5,2021,Accept (Poster),False,Adaptive Federated Optimization,"[""Sashank J. Reddi"", ""Zachary Charles"", ""Manzil Zaheer"", ""Zachary Garrett"", ""Keith Rush"", ""Jakub Kone\u010dn\u00fd"", ""Sanjiv Kumar"", ""Hugh Brendan McMahan""]","[""Federated learning"", ""optimization"", ""adaptive optimization"", ""distributed optimization""]","We propose adaptive federated optimization techniques, and highlight their improved performance over popular methods such as FedAvg.",,,,
Lm8T39vLDTE,2022,Accept (Poster),False,Autoregressive Diffusion Models,"['Emiel Hoogeboom', 'Alexey A. Gritsenko', 'Jasmijn Bastings', 'Ben Poole', 'Rianne van den Berg', 'Tim Salimans']","[""diffusion"", ""autoregressive models"", ""lossless compression""]",A new model class for discrete variables encompassing order agnostic autoregressive models and absorbing discrete diffusion.,,,,
LmUJqB1Cz8,2021,Accept (Spotlight),False,Winning the L2RPN Challenge: Power Grid Management via Semi-Markov Afterstate Actor-Critic,"[""Deunsol Yoon"", ""Sunghoon Hong"", ""Byung-Jun Lee"", ""Kee-Eung Kim""]","[""power grid management"", ""deep reinforcement learning"", ""graph neural network""]","We  present  an  off-policy  actor-critic  approach  that  effectively tackles  the  unique  challenges  in  power  grid  management  by  reinforcement learning,  adopting  the hierarchical policy together with the afterstate representation. ",,,,
LnVNgfvrQjC,2021,Reject,False,CAFENet: Class-Agnostic Few-Shot Edge Detection Network,"[""Younghyun Park"", ""Jun Seo"", ""Jaekyun Moon""]","[""Few-shot edge detection"", ""Few-shot learning"", ""Semantic edge detection""]","We introduce a novel few-shot learning setup, few-shot semantic edge detection, and propose a few-shot edge detector CAFENet . We also construct new datasets for few-shot edge detection and validate CAFENet.",,,,
Lnomatc-1s,2021,Reject,False,Learning-Augmented Sketches for Hessians,"[""Yi Li"", ""Honghao Lin"", ""David Woodruff""]",[],"We show empirically that learned sketches, compared with their ""non-learned"" counterparts, improve the approximation accuracy for typical least square problems (which could be constrained).",,,,
LpSGtq6F5xN,2021,Reject,False,A Mixture of Variational Autoencoders for Deep Clustering,"[""Avi Caciularu"", ""Jacob Goldberger""]","[""deep clustering"", ""variational auto encoder"", ""VAE""]",A VAE based clustering algorithm  based on multiple autoencoders  that obtains  SOTA results  ,,,,
LtI14EpWKH,2022,Reject,False,Tessellated 2D Convolution Networks: A Robust Defence against Adversarial Attacks,"['Swarnava Das', 'Pabitra Mitra', 'Debasis Ganguly']",[],,,,,
LtKcMgGOeLt,2022,Accept (Spotlight),False,When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations,"['Xiangning Chen', 'Cho-Jui Hsieh', 'Boqing Gong']","[""Vision Transformers"", ""Optimization""]",,,,,
LtgEkhLScK3,2021,Reject,False,Probabilistic Mixture-of-Experts for Efficient Deep Reinforcement Learning,"[""Jie Ren"", ""Yewen Li"", ""Zihan Ding"", ""Wei Pan"", ""Hao Dong""]","[""Deep Reinforcement Learning"", ""Sample Efficiency"", ""Gaussian Mixture Models"", ""Mixture-of-Experts""]",An end-to-end differentiable probabilistic mixture-of-experts for improving the exploration and sample efficiency in DRL.,,,,
Ltkwl64I91,2022,Reject,False,Invariance-Guided Feature Evolution  for  Few-Shot Learning,"['Wenming Cao', 'Zhineng Zhao', 'Qifan Liu', 'Zhihai He']","[""Few-shot learning"", ""Invariance loss""]",,,,,
LucJxySuJcE,2021,Accept (Poster),False,Protecting DNNs from Theft using an Ensemble of Diverse Models,"[""Sanjay Kariyappa"", ""Atul Prakash"", ""Moinuddin K Qureshi""]","[""Model stealing"", ""machine learning security""]",Discontinuous predictions produced by an ensemble of diverse models can be used to create an effective defense against model stealing attacks.,,,,
LuyryrCs6Ez,2021,Reject,False,CURI: A Benchmark for Productive Concept Learning Under Uncertainty,"[""Shanmukha Ramakrishna Vedantam"", ""Arthur Szlam"", ""Maximilian Nickel"", ""Ari S. Morcos"", ""Brenden M. Lake""]","[""compositional learning"", ""meta-learning"", ""systematicity"", ""reasoning""]",A novel benchmark that tests compositional reasoning about concepts under uncertainty,,,,
Lv-G9XqLRRy,2022,Reject,False,Restricted Category Removal from Model Representations using Limited Data,"['Pratik Mazumder', 'Pravendra Singh', 'Mohammed Asad Karim']",[],,,,,
LvJ8hLSusrv,2021,Reject,False,Gradient-based tuning of Hamiltonian Monte Carlo hyperparameters,"[""Andrew Campbell"", ""Wenlong Chen"", ""Vincent Stimper"", ""Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"", ""Yichuan Zhang""]","[""Hamiltonian Monte Carlo"", ""HMC"", ""MCMC"", ""Variational Inference""]",A novel gradient based method for automatic tuning of the Hamiltonian Monte Carlo hyperparameters.,,,,
Lvb2BKqL49a,2021,Reject,False,Regularized Mutual Information Neural Estimation,"[""Kwanghee Choi"", ""Siyeong Lee""]","[""Information Theory"", ""Regularization""]",We propose a novel lower bound that effectively regularizes the neural network to alleviate the problems of MINE. ,2011.07932,cs.LG,2020-11-16 13:29:15+00:00,2020-11-16 13:29:15+00:00
LwEQnp6CYev,2021,Accept (Spotlight),False,Quantifying Differences in Reward Functions,"[""Adam Gleave"", ""Michael D Dennis"", ""Shane Legg"", ""Stuart Russell"", ""Jan Leike""]","[""rl"", ""irl"", ""reward learning"", ""distance"", ""benchmarks""]",A theoretically principled distance measure on reward functions that is quick to compute and predicts policy training performance.,,,,
Lwclw6u3Pcw,2022,Reject,False,Characterizing and Measuring the Similarity of Neural Networks with Persistent Homology ,"['David PÃ©rez FernÃ¡ndez', 'Asier GutiÃ©rrez-FandiÃ±o', 'Jordi Armengol-EstapÃ©', 'Marta Villegas']","[""Neural Networks"", ""Topological Data Analysis"", ""similarity"", ""Persistent Homology""]",We provide a method to compare and characterize Neural Networks.,,,,
Lwr8We4MIxn,2022,Accept (Poster),False,A Biologically Interpretable Graph Convolutional Network to Link Genetic Risk Pathways and Imaging Phenotypes of Disease ,"['Sayan Ghosal', 'Qiang Chen', 'Giulio Pergola', 'Aaron L Goldman', 'William Ulrich', 'Daniel R Weinberger', 'Archana Venkataraman']","[""Imaging-genetics"", ""Hierarchical Graph Convolution"", ""Gene Ontology"", ""Bayesian Feature Selection"", ""Schizophrenia""]",Biologically Informed Imaging-Genetics,,,,
LxBFTZT3UOU,2021,Reject,True,A straightforward line search approach on the expected empirical loss for stochastic deep learning problems,"[""Maximus Mutschler"", ""Andreas Zell""]","[""Empirical Optimization"", ""Expected Loss"", ""Line Search""]",A straightforward line search approach on the expected empirical loss for stochastic deep learning problems,2010.00921,cs.LG,2020-10-02 11:04:02+00:00,2020-10-02 11:04:02+00:00
LxhlyKH6VP,2021,Reject,False,ProGAE: A Geometric Autoencoder-based Generative Model for  Disentangling Protein Conformational Space,"[""Norman Joseph Tatro"", ""Payel Das"", ""Pin-Yu Chen"", ""Vijil Chenthamarakshan"", ""Rongjie Lai""]","[""generative models"", ""deep learning"", ""interpretability""]","We introduce ProGAE, a geometric autoencoder for generating the protein conformational space, with separate latent representations of intrinsic and extrinsic geometry.",,,,
LzQQ89U1qm_,2022,Accept (Spotlight),True,Anomaly Transformer: Time Series Anomaly Detection with Association Discrepancy,"['Jiehui Xu', 'Haixu Wu', 'Jianmin Wang', 'Mingsheng Long']","[""Time series anomaly detection"", ""Transformers"", ""Anomaly attention"", ""Association discrepancy""]","This paper detects time series anomalies from a new association-based dimension. We find an inherently normal-abnormal distinguishable evidence as Association Discrepancy. Co-designed with this evidence, our model achieves the SOTA on six benchmarks.",2110.02642,cs.LG,2021-10-06 10:33:55+00:00,2021-10-21 13:20:34+00:00
LzhEvTWpzH,2021,Reject,False,Switching-Aligned-Words Data Augmentation for Neural Machine Translation,"[""Fengshun Xiao"", ""Zuchao Li"", ""hai zhao""]","[""Machine Translation"", ""Data augmentation""]","In this paper, we present a novel data augmentation method for neural machine translation by using only the original training data without extra data. ",,,,
M-9bPO0M2K5,2022,Reject,False,MetaBalance: High-Performance Neural Networks for Class-Imbalanced Data,"['Arpit Bansal', 'Micah Goldblum', 'Valeriia Cherepanova', 'Avi Schwarzschild', 'C. Bayan Bruss', 'Tom Goldstein']",[],,,,,
M2sNIiCC6C,2022,Reject,False,Self-supervised regression learning using domain knowledge: Applications to improving self-supervised image denoising,"['Il Yong Chun', 'Dongwon Park', 'Xuehang Zheng', 'Se Young Chun', 'Yong Long']","[""Self-supervised learning"", ""Regression"", ""Image denoising"", ""Deep learning""]",,,,,
M3NDrHEGyyO,2021,Reject,False,Accelerating Safe Reinforcement Learning with Constraint-mismatched Policies,"[""Tsung-Yen Yang"", ""Justinian Rosca"", ""Karthik R Narasimhan"", ""Peter Ramadge""]","[""Reinforcement learning with constraints"", ""Safe reinforcement learning""]","We propose a new algorithm that learns constraint-satisfying policies with constraint-mismatched baseline policies, and provide theoretical analysis and empirical demonstration in the context of reinforcement learning with constraints.",,,,
M4qXqdw3xC,2021,Reject,False,Boundary Effects in CNNs: Feature or Bug?,"[""Md Amirul Islam"", ""Matthew Kowal"", ""Sen Jia"", ""Konstantinos G. Derpanis"", ""Neil Bruce""]","[""Boundary Effects"", ""Absolute Position Information"", ""Padding"", ""Canvas color"", ""Location Dependent Task""]",Study the relationship between boundary effects and absolute position information.,,,,
M5hiCgL7qt,2022,Reject,False,The NTK Adversary: An Approach to Adversarial Attacks without any Model Access,"['Nikolaos Tsilivis', 'Julia Kempe']","[""Adversarial Attack"", ""Neural Tangent Kernel"", ""Adversarial Examples""]",NTK guided adversarial attacks on NNs without access to any trained model.,,,,
M6M8BEmd6dq,2022,Accept (Poster),True,PEARL: Data Synthesis via Private Embeddings and Adversarial Reconstruction Learning,"['Seng Pei Liew', 'Tsubasa Takahashi', 'Michihiko Ueno']","[""Differential Privacy"", ""Generative Model""]",,2106.04590,cs.LG,2021-06-08 18:00:01+00:00,2021-06-08 18:00:01+00:00
M6jm8fRG5eq,2022,Reject,False,Decentralized Cooperative Multi-Agent Reinforcement Learning with Exploration,"['Weichao Mao', 'Tamer Basar', 'Lin Yang', 'Kaiqing Zhang']","[""decentralized control"", ""decentralized learning"", ""game theory"", ""reinforcement learning"", ""reinforcement learning theory""]",We propose a stage-based Q-learning style algorithm that finds an approximate Nash equilibrium efficiently in decentralized cooperative multi-agent reinforcement learning.,,,,
M71R_ivbTQP,2021,Reject,False,Extract Local Inference Chains of Deep Neural Nets,"[""Haiyan Zhao"", ""Tianyi Zhou"", ""Guodong Long"", ""Jing Jiang"", ""Chengqi Zhang""]","[""Model Interpretability"", ""Model Pruning"", ""Attribution"", ""Model Visualization""]",Our paper propose a method to visualize the reasoning process of DNN on given data from a local region.,,,,
M752z9FKJP,2022,Accept (Spotlight),False,Learning Strides in Convolutional Neural Networks,"['Rachid Riad', 'Olivier Teboul', 'David Grangier', 'Neil Zeghidour']","[""Strides"", ""Convolutional neural networks"", ""Downsampling"", ""Spectral representations"", ""Fourier""]","We introduce DiffStride, the first downsampling layer with learnable strides for convolutional neural networks.",2202.01653,cs.LG,2022-02-03 16:03:36+00:00,2022-02-03 16:03:36+00:00
M88oFvqp_9,2021,Accept (Poster),False,Generating Furry Cars: Disentangling Object Shape and Appearance across Multiple Domains,"[""Utkarsh Ojha"", ""Krishna Kumar Singh"", ""Yong Jae Lee""]","[""multi-domain disentanglement"", ""generative adversarial networks"", ""appearance transfer""]","We present a framework for multi-domain disentanglement, facilitating transfer of appearance from one domain to another.",2104.02052,cs.CV,2021-04-05 17:59:15+00:00,2021-04-05 17:59:15+00:00
M9hdyCNlWaf,2021,Reject,False,Sparse Uncertainty Representation in Deep Learning with Inducing Weights,"[""Hippolyt Ritter"", ""Martin Kukla"", ""Cheng Zhang"", ""Yingzhen Li""]","[""Bayesian neural networks"", ""uncertainty estimation"", ""memory efficiency""]","We introduce a parameter-efficient uncertainty quantification framework for deep neural net, results show competitive performances, but the model size is reduced significantly to < half of a single network.",2105.14594,stat.ML,2021-05-30 18:17:47+00:00,2021-05-30 18:17:47+00:00
MA8eT-vUPvZ,2021,Reject,False,Adaptive Risk Minimization: A Meta-Learning Approach for Tackling Group Shift,"[""Marvin Mengxin Zhang"", ""Henrik Marklund"", ""Nikita Dhawan"", ""Abhishek Gupta"", ""Sergey Levine"", ""Chelsea Finn""]","[""meta-learning"", ""distribution shift"", ""distributional robustness"", ""test time adaptation""]",We meta-learn models that can use unlabeled test data to adapt to group distribution shift.,,,,
MAYipnUpHHD,2022,Reject,False,Reinforcement Learning for Adaptive Mesh Refinement,"['Jiachen Yang', 'Tarik Dzanic', 'Brenden K. Petersen', 'Jun Kudo', 'Ketan Mittal', 'Jean-Sylvain Camier', 'Vladimir Tomov', 'Tuo Zhao', 'Hongyuan Zha', 'Tzanio Kolev', 'Robert Anderson', 'Daniel faissol']","[""reinforcement learning"", ""adaptive mesh refinement"", ""finite element method""]",,,,,
MBOyiNnYthd,2021,Accept (Poster),True,IDF++: Analyzing and Improving Integer Discrete Flows for Lossless Compression,"[""Rianne van den Berg"", ""Alexey A. Gritsenko"", ""Mostafa Dehghani"", ""Casper Kaae S\u00f8nderby"", ""Tim Salimans""]","[""normalizing flows"", ""lossless source compression"", ""generative modeling""]",We analyze and improve integer discrete normalizing flows for lossless source compression.,2006.12459,cs.LG,2020-06-22 17:41:55+00:00,2021-03-23 09:40:50+00:00
MBdafA3G9k,2021,Reject,True,Visual Imitation with Reinforcement Learning using Recurrent Siamese Networks,"[""Glen Berseth"", ""Florian Golemo"", ""Christopher Pal""]","[""Reinforcement Learning"", ""Imitation learning""]",Learning recurrent distance functions between videos to enable imitation learning from a single motion clip.,1901.07186,cs.LG,2019-01-22 06:46:19+00:00,2021-10-21 17:53:35+00:00
MBpHUFrcG2x,2021,Accept (Poster),True,Projected Latent Markov Chain Monte Carlo: Conditional Sampling of Normalizing Flows,"[""Chris Cannella"", ""Mohammadreza Soltani"", ""Vahid Tarokh""]","[""Conditional Sampling"", ""Normalizing Flows"", ""Markov Chain Monte Carlo"", ""Missing Data Inference""]",We introduce and demonstrate a novel MCMC technique for sampling from the exact conditional distributions known by normalizing flows.,2007.06140,cs.LG,2020-07-13 00:47:39+00:00,2021-02-26 16:52:28+00:00
MCe-j2-mVnA,2021,Reject,False,Overcoming barriers to the training of effective learned optimizers,"[""Luke Metz"", ""Niru Maheswaranathan"", ""C. Daniel Freeman"", ""Ben Poole"", ""Jascha Sohl-Dickstein""]","[""learned optimizers"", ""meta-learning""]","We train learned optimizers on large distributions of tasks, with new architectures, and evaluate performance in a number of different ways.",,,,
MD3D5UbTcb1,2021,Reject,True,A Unified View on Graph Neural Networks as Graph Signal Denoising,"[""Yao Ma"", ""Xiaorui Liu"", ""Tong Zhao"", ""Yozen Liu"", ""Jiliang Tang"", ""Neil Shah""]","[""Graph Neural Networks"", ""Graph Signal Denoising"", ""Smoothness""]",,2010.01777,cs.LG,2020-10-05 04:57:18+00:00,2021-10-18 15:29:27+00:00
MDT30TEtaVY,2022,Reject,False,Set Norm and Equivariant Skip Connections: Putting the Deep in Deep Sets,"['Lily H Zhang', 'Veronica Tozzo', 'John M. Higgins', 'Rajesh Ranganath']","[""deep learning"", ""permutation invariance"", ""normalization"", ""residual connections""]","We build deep permutation invariant models Deep Sets++ and Set Transformer++ using normalization layers and residual connections tailored for sets, and we introduce a new single-cell dataset for permutation invariant prediction.",,,,
MDX3F0qAfm3,2021,Reject,False,Can We Use Gradient Norm as a Measure of Generalization Error for Model Selection in Practice?,"[""Haozhe An"", ""Haoyi Xiong"", ""Xuhong Li"", ""Xingjian Li"", ""Dejing Dou"", ""Zhanxing Zhu""]",[],,,,,
MDsQkFP1Aw,2021,Accept (Poster),False,Into the Wild with AudioScope: Unsupervised Audio-Visual Separation of On-Screen Sounds,"[""Efthymios Tzinis"", ""Scott Wisdom"", ""Aren Jansen"", ""Shawn Hershey"", ""Tal Remez"", ""Dan Ellis"", ""John R. Hershey""]","[""Audio-visual sound separation"", ""in-the-wild data"", ""unsupervised learning"", ""self-supervised learning"", ""universal sound separation""]",We propose an open-domain unsupervised audio-visual on-screen separation system trained and tested on in-the-wild videos.,,,,
MEpKGLsY8f,2022,Accept (Spotlight),True,Meta Discovery: Learning to Discover Novel Classes given Very Limited Data,"['Haoang Chi', 'Feng Liu', 'Wenjing Yang', 'Long Lan', 'Tongliang Liu', 'Bo Han', 'Gang Niu', 'Mingyuan Zhou', 'Masashi Sugiyama']",[],,2102.04002,cs.LG,2021-02-08 04:53:14+00:00,2021-06-11 07:46:12+00:00
MG8Zde0ip6u,2021,Reject,False,A Siamese Neural Network for Behavioral Biometrics Authentication,"[""Jes\u00fas Solano"", ""Esteban Rivera"", ""Alejandra Castelblanco"", ""Lizzy Tengana"", ""Christian Lopez"", ""Martin Ochoa""]","[""Deep Learning"", ""Few-shot Learning"", ""Behavioral Biometrics"", ""Biometric Authentication""]",,,,,
MGIg_Q4QtW2,2022,Reject,False,RAR: Region-Aware Point Cloud Registration,"['Yu Hao', 'Yi Fang']",[],,,,,
MIDckA56aD,2021,Accept (Poster),False,Learning perturbation sets for robust machine learning,"[""Eric Wong"", ""J Zico Kolter""]","[""adversarial examples"", ""perturbation sets"", ""robust machine learning"", ""conditional variational autoencoder""]","We learn to characterize real-world changes in well-defined perturbation sets, which allow us train models which are empirically and certifiably robust to real-world adversarial changes. ",,,,
MIX3fJkl_1,2022,Accept (Poster),False,NeuPL: Neural Population Learning,"['Siqi Liu', 'Luke Marris', 'Daniel Hennes', 'Josh Merel', 'Nicolas Heess', 'Thore Graepel']","[""Multi-Agent Learning"", ""Game Theory"", ""Population Learning""]","We propose NeuPL, a general and efficient population learning framework that learns and represents diverse policies in symmetric zero-sum games within a single conditional network via self-play.",,,,
MJAqnaC2vO1,2021,Accept (Poster),True,Auto Seg-Loss: Searching Metric Surrogates for Semantic Segmentation,"[""Hao Li"", ""Chenxin Tao"", ""Xizhou Zhu"", ""Xiaogang Wang"", ""Gao Huang"", ""Jifeng Dai""]","[""Loss Function Search"", ""Metric Surrogate"", ""Semantic Segmentation""]",Auto Seg-Loss is the first general framework for searching surrogate losses for mainstream semantic segmentation metrics. ,2010.07930,cs.CV,2020-10-15 17:59:08+00:00,2020-12-03 05:05:15+00:00
MJIve1zgR_,2021,Accept (Poster),False,Unbiased Teacher for Semi-Supervised Object Detection,"[""Yen-Cheng Liu"", ""Chih-Yao Ma"", ""Zijian He"", ""Chia-Wen Kuo"", ""Kan Chen"", ""Peizhao Zhang"", ""Bichen Wu"", ""Zsolt Kira"", ""Peter Vajda""]","[""Object Detection""]","We propose Unbiased Teacher to jointly address the pseudo-labeling bias issue and the overfitting issue in semi-supervised object detection, and our model performs favorably against existing works on COCO-standard, COCO-additional, and VOC.",2102.09480,cs.CV,2021-02-18 17:02:57+00:00,2021-02-18 17:02:57+00:00
MJmYbFnJAGa,2021,Reject,False,Mime: Mimicking Centralized Stochastic Algorithms in Federated Learning,"[""Sai Praneeth Karimireddy"", ""Martin Jaggi"", ""Satyen Kale"", ""Mehryar Mohri"", ""Sashank J. Reddi"", ""Sebastian U Stich"", ""Ananda Theertha Suresh""]","[""Federated learning"", ""Federated optimization"", ""Adaptive optimization"", ""Adam"", ""Variance Reduction"", ""Distributed optimization"", ""Decentralized optimization""]",Global momentum can be used during local client updates to reduce the effect of non-iid data in cross-device federated learning. ,,,,
MLSvqIHRidA,2021,Accept (Spotlight),False,Contrastive Divergence Learning is a Time Reversal Adversarial Game,"[""Omer Yair"", ""Tomer Michaeli""]","[""Unsupervised learning"", ""energy based model"", ""adversarial learning"", ""contrastive divergence"", ""noise contrastive estimation""]","We present an alternative derivation of the classical Contrastive divergence method, which reveals that it is in fact an adversarial learning procedure.",2012.03295,cs.LG,2020-12-06 15:54:05+00:00,2021-03-15 20:03:43+00:00
MMAeCXIa89,2022,Accept (Poster),False,$\pi$BO: Augmenting Acquisition Functions with User Beliefs for Bayesian Optimization,"['Carl Hvarfner', 'Danny Stoll', 'Artur Souza', 'Luigi Nardi', 'Marius Lindauer', 'Frank Hutter']","[""Bayesian Optimization"", ""Hyperparameter Optimization"", ""Meta-Learning""]","We extend the Bayesian Optimization framework by allowing for arbitrary user priors over promising regions of the search space, to guide the search towards said regions.",,,,
MMXhHXbNsa-,2021,Reject,False,Blind Pareto Fairness and Subgroup Robustness,"[""Natalia Martinez"", ""Martin Bertran"", ""Afroditi Papadaki"", ""Miguel R. D. Rodrigues"", ""Guillermo Sapiro""]","[""fairness"", ""fairness in machine learning"", ""fairness without demographics"", ""robustness"", ""subgroup robustness"", ""blind fairness"", ""pareto fairness""]","We analyze worst-case fairness beyond demographics, and propose Blind Pareto Fairness, a method that reduces worst-case risk of any subgroup of sufï¬cient size, and guarantees that the remaining population receives the best possible level of service.",,,,
MOm8xik_TmO,2022,Reject,False,Isotropic Contextual Representations through Variational Regularization,"['Cornelia Ferner', 'Stefan Wegenkittl']",[],,,,,
MP0LhG4YiiC,2021,Reject,True,Analogical Reasoning for Visually Grounded Compositional Generalization,"[""Bo Wu"", ""Haoyu Qin"", ""Alireza Zareian"", ""Carl Vondrick"", ""Shih-Fu Chang""]",[],,2007.11668,cs.CL,2020-07-22 20:51:58+00:00,2020-07-22 20:51:58+00:00
MP904TiHqJ-,2022,Accept (Poster),False,Provably convergent quasistatic dynamics for mean-field two-player zero-sum games,"['Chao Ma', 'Lexing Ying']","[""quasistatic"", ""minimax optimization"", ""mixed Nash equilibrium"", ""mean-field formulation""]","We propose a quasistatic Wasserstein flow for finding mixed Nash equilibriums, and prove its convergence.",,,,
MPO4oML_JC,2021,Reject,False,Coordinated Multi-Agent Exploration Using Shared Goals,"[""Iou-Jen Liu"", ""Unnat Jain"", ""Alex Schwing""]","[""Multi-agent RL"", ""Deep RL"", ""Exploration""]",The proposed coordinated multi-agent exploration (CMAE) leverages shared goals to coordinate agents' exploration and achieves good performance in various sparse reward environments. ,,,,
MPoQtFC588n,2022,Reject,False,RMNet: Equivalently Removing Residual Connection from Networks,"['Fanxu Meng', 'Hao Cheng', 'Jia-Xin Zhuang', 'Ke Li', 'Xing Sun']","[""Efficient Network"", ""Residual Connection""]",A simple method that can equivalently removing residual connection from networks e.g. ResNet and MobileNetV2,,,,
MQ2sAGunyBP,2022,Accept (Poster),False,R4D: Utilizing Reference Objects for Long-Range Distance Estimation,"['Yingwei Li', 'Tiffany Chen', 'Maya Kabkab', 'Ruichi Yu', 'Longlong Jing', 'Yurong You', 'Hang Zhao']","[""Self-driving"", ""distance estimation"", ""long-range objects""]",,,,,
MQuxKr2F1Xw,2022,Reject,False,Multi-Trigger-Key: Towards Multi-Task Privacy-Preserving In Deep Learning,"['Ren Wang', 'Zhe Xu', 'Alfred Hero']",[],,,,,
MR7XubKUFB,2022,Accept (Poster),True,Adversarial Retriever-Ranker for Dense Text Retrieval,"['Hang Zhang', 'Yeyun Gong', 'Yelong Shen', 'Jiancheng Lv', 'Nan Duan', 'Weizhu Chen']",[],,2110.03611,cs.CL,2021-10-07 16:41:15+00:00,2021-10-29 15:18:40+00:00
MRGFutr0p5e,2022,Reject,False,Graph Barlow Twins: A self-supervised representation learning framework for graphs,"['Piotr Bielak', 'Tomasz Jan Kajdanowicz', 'Nitesh Chawla']","[""graph representation learning"", ""self-supervised learning""]",,,,,
MRQJmsNPp8E,2021,Reject,False,Learning Representations by Contrasting Clusters While Bootstrapping Instances,"[""Junsoo Lee"", ""Hojoon Lee"", ""Inkyu Shin"", ""Jaekyoung Bae"", ""In So Kweon"", ""Jaegul Choo""]","[""unsupervised"", ""self-supervised"", ""image clustering"", ""visual representation learning""]",This work tackles both unsupervised visual representation learning and unsupervised image clustering tasks by contrasting cluster-level features and bootstrapping instance-level representations.,,,,
MSgB8D4Hy51,2022,Accept (Poster),False,Post-Training Detection of Backdoor Attacks for Two-Class and Multi-Attack Scenarios,"['Zhen Xiang', 'David Miller', 'George Kesidis']","[""backdoor"", ""Trojan"", ""adversarial learning"", ""deep neural network""]","We proposed a detection framework against backdoor attacks for two-class and multi-attack scenarios, without access to the classifier's training set or any supervision from clean classifiers trained for the same domain.",,,,
MSwEFaztwkE,2022,Accept (Poster),False,Learning Weakly-supervised Contrastive Representations,"['Yao-Hung Hubert Tsai', 'Tianqin Li', 'Weixin Liu', 'Peiyuan Liao', 'Ruslan Salakhutdinov', 'Louis-Philippe Morency']","[""Self-supervised Learning"", ""Weakly Supervised Learning"", ""Learning with Auxiliary Information"", ""Clustering-based Representation Learning""]",We present a weakly-supervised contrastive learning framework that considers auxiliary information (additional sources of information from data).,,,,
MTex8qKavoS,2022,Accept (Poster),False,MetaShift: A Dataset of Datasets for Evaluating Contextual Distribution Shifts and Training Conflicts,"['Weixin Liang', 'James Zou']","[""benchmark dataset"", ""distribution shift"", ""out-of-domain generalization""]",We leverage annotated subsets within a heterogeneous dataset to evaluate the performance of learning algorithms to distribution shifts and to visualize training dynamics. ,,,,
MTsBazXmX00,2022,Reject,False,Target Propagation via Regularized Inversion,"['Vincent Roulet', 'Zaid Harchaoui']","[""Target propagation"", ""differentiable programming"", ""recurrent neural networks""]",We implement target propagation for RNNs with the actual formulation of the inverse and not with a parameterized inverse; our experiments show the effectiveness of the approach and paves the way for a better understanding of the approach. ,,,,
MUpxS9vDbZr,2022,Reject,False,"Why Should I Trust You, Bellman? Evaluating the Bellman Objective with Off-Policy Data","['Scott Fujimoto', 'David Meger', 'Doina Precup', 'Ofir Nachum', 'Shixiang Shane Gu']","[""reinforcement learning"", ""off-policy reinforcement learning"", ""off-policy evaluation"", ""deep reinforcement learning""]",We show that minimizing the Bellman error does not result in better value prediction accuracy. ,,,,
MWQCPYSJRN,2022,Reject,False,Generative Negative Replay for Continual Learning,"['Gabriele Graffieti', 'Davide Maltoni', 'Lorenzo Pellegrini', 'Vincenzo Lomonaco']","[""Continual Learning"", ""Generative replay"", ""Lifelong learning""]",,,,,
MXEl7i-iru,2022,Accept (Poster),False,GraphENS: Neighbor-Aware Ego Network Synthesis for Class-Imbalanced Node Classification,"['Joonhyung Park', 'Jaeyun Song', 'Eunho Yang']","[""Deep learning"", ""Node classification"", ""Class imbalance"", ""Data Augmentation""]",,,,,
MXdFBmHT4C,2022,Accept (Poster),False,Differentiable Expectation-Maximization for Set Representation Learning,['Minyoung Kim'],"[""Representation learning"", ""Bayesian models"", ""Mixture estimation"", ""Optimal transport"", ""Attention""]","We propose a novel set embedding function, a feed-forward network defined as the (differentiable) maximum-a-posterior estimate of the mixture, approximately attained by a few Expectation-Maximization steps.",,,,
MXrIVw-F_a4,2022,Reject,False,FLOAT:  FAST LEARNABLE ONCE-FOR-ALL ADVERSARIAL TRAINING FOR TUNABLE TRADE-OFF BETWEEN ACCURACY AND ROBUSTNESS,"['Souvik Kundu', 'Peter Anthony Beerel', 'Sairam Sundaresan']","[""Once-for-all adversarial training"", ""in-situ robustness-accuracy trade-off"", ""parameter-efficient in-situ calibration""]","In this paper, we present a fast parameter-efficient once-for-all adversarial training that can calibrate between accuracy and robustness in-situ to yield state-of-the-art classification accuracy. ",,,,
MY3WGKsXct_,2021,Reject,False,Membership Attacks on Conditional Generative Models Using Image Difficulty,"[""Avital Shafran"", ""Shmuel Peleg"", ""Yedid Hoshen""]","[""Membership Inference Attack"", ""Image translation""]",,,,,
MY5iHZ0IZXl,2021,Reject,False,ABSTRACTING INFLUENCE PATHS  FOR EXPLAINING (CONTEXTUALIZATION OF) BERT MODELS,"[""Kaiji Lu"", ""Zifan Wang"", ""Piotr Mardziel"", ""Anupam Datta""]","[""interpretability"", ""natural language processing"", ""transformer"", ""BERT""]",,,,,
M_KwRsbhi5e,2021,Reject,False,Improving Learning to Branch via Reinforcement Learning,"[""Haoran Sun"", ""Wenbo Chen"", ""Hui Li"", ""Le Song""]","[""Mixed Integer Programming"", ""Branching and Bound"", ""Strong Branching"", ""Reinforcement Learning"", ""Evolution Strategy"", ""Novelty Search""]",,,,,
M_eaMB2DOxw,2021,Reject,True,On Representing (Anti)Symmetric Functions,"[""Marcus Hutter""]","[""Neural network"", ""approximation"", ""universality"", ""Slater determinant"", ""Vandermonde matrix"", ""equivariance"", ""symmetry"", ""anti-symmetry"", ""symmetric polynomials"", ""polarized basis"", ""multilayer perceptron"", ""continuity"", ""smoothness""]","We prove universality of the symmetric/equivariant 2-hidden-layer Perceptron and of the FermiNet with a single generalized Slater determinant, both based on polynomials and for particles of arbitrary dimension.",2007.15298,cs.NE,2020-07-30 08:23:33+00:00,2020-07-30 08:23:33+00:00
M_o5E088xO5,2022,Reject,False,PROMISSING: Pruning Missing Values in Neural Networks,"['Seyed Mostafa Kia', 'Nastaran Mohammadian Rad', 'Daniel van Opstal', 'Bart van Schie', 'Wiepke Cahn', 'Andre Marquand', 'Josien P.W. Pluim', 'Hugo G. Schnack']","[""Neural Networks"", ""Missing Values"", ""Data Imputation""]",We present a simple yet effective technique for dealing with missing values in neural networks.,,,,
Ma0S4RcfpR_,2021,Reject,False,A Representational Model of Grid Cells' Path Integration Based on Matrix Lie Algebras,"[""Ruiqi Gao"", ""Jianwen Xie"", ""Xue-Xin Wei"", ""Song-Chun Zhu"", ""Ying Nian Wu""]","[""grid cells"", ""path integration"", ""representational model"", ""Lie algebras"", ""error correction""]",We elucidate a minimally simple recurrent model for grid cells' path integration based on two coupled matrix Lie algebras that underlie two coupled rotation systems that mirror the agent's self-motion.,,,,
MaZFq7bJif7,2021,Accept (Poster),False,Hopper: Multi-hop Transformer for Spatiotemporal Reasoning,"[""Honglu Zhou"", ""Asim Kadav"", ""Farley Lai"", ""Alexandru Niculescu-Mizil"", ""Martin Renqiang Min"", ""Mubbasir Kapadia"", ""Hans Peter Graf""]","[""Multi-hop Reasoning"", ""Object Permanence"", ""Spatiotemporal Understanding"", ""Video Recognition"", ""Transformer""]","We propose Hopper, Multi-Hop Transformer, and CATER-h dataset to approach object-centric spatiotemporal reasoning in videos.",2103.10574,cs.CV,2021-03-19 00:13:04+00:00,2021-03-22 02:00:23+00:00
MbG7JBt0Yvo,2021,Reject,False,Sequence Metric Learning as Synchronization of Recurrent Neural Networks,"[""Paul Compagnon"", ""Gr\u00e9goire Lefebvre"", ""Stefan Duffner"", ""Christophe Garcia""]","[""Metric learning"", ""sequence processing"", ""siamese recurrent neural network"", ""dynamical systems""]",We propose a new neural network architecture for sequence metric learning based on dynamical system synchronization,,,,
MbM_gvIB3Y4,2021,Reject,False,Which Mutual-Information Representation Learning Objectives are Sufficient for Control?,"[""Kate Rakelly"", ""Abhishek Gupta"", ""Carlos Florensa"", ""Sergey Levine""]","[""representation learning"", ""reinforcement learning"", ""information theory""]",We examine whether popular MI-based representation learning objectives for RL yield state representations sufficient for learning and representing optimal control policies,,,,
McYsRk9-rso,2021,Reject,False,Reducing Implicit Bias in Latent Domain Learning,"[""Lucas Deecke"", ""Timothy Hospedales"", ""Hakan Bilen""]","[""Latent Domain Learning"", ""CNN Architectures""]","We demonstrate that standard models suppress underrepresented latent domains, and formulate novel strategies to limit this behavior.",,,,
MeMMmuWRXsy,2022,Reject,False,Robust Robotic Control from Pixels using Contrastive Recurrent State-Space Models,"['Nitish Srivastava', 'Walter Talbott', 'Martin Bertran Lopez', 'Shuangfei Zhai', 'Joshua M. Susskind']","[""contrastive learning"", ""model-based RL"", ""distractions"", ""predictive coding""]",RSSMs with contrastive prediction work surprisingly well for pixel-based RL even in the presence of severe visual distractions.,,,,
MeeQkFYVbzW,2022,Accept (Poster),False,Adversarial Unlearning of Backdoors via Implicit Hypergradient,"['Yi Zeng', 'Si Chen', 'Won Park', 'Zhuoqing Mao', 'Ming Jin', 'Ruoxi Jia']","[""backdoor defense"", ""backdoor removal"", ""backdoor"", ""minimax"", ""implicit hypergradient""]","A minimax formulation of backdoor removal and an implicit gradient-based solver surpasses the state-of-art methods' best results in higher efficacy, efficiency, robustness to variations in triggers, settings, poison ratio, and clean data size.",,,,
Mf4ZSXMZP7,2021,Reject,True,Improving Post Training Neural Quantization: Layer-wise Calibration and Integer Programming,"[""Itay Hubara"", ""Yury Nahshan"", ""Yair Hanani"", ""Ron Banner"", ""Daniel Soudry""]","[""Efficient Deep Learning"", ""Quantization"", ""Compression""]",State-of-the-art results using advanced method for post training per channel quantization - squeezing all the information from the calibration set.,2006.10518,cs.LG,2020-06-14 16:07:55+00:00,2020-12-14 15:55:05+00:00
Mh1Abj33qI,2021,Reject,True,Data-driven Learning of Geometric Scattering Networks,"[""Alexander Tong"", ""Frederik Wenkel"", ""Kincaid Macdonald"", ""Smita Krishnaswamy"", ""Guy Wolf""]","[""Graph Neural Networks"", ""GNNs"", ""Geometric Scattering"", ""Radial Basis Network"", ""Graph Signal Processing"", ""Wavelet""]",We introduce learnable geometric scattering showing theoretical and empirical benefits in graph classification particularly in the biochemical domain.,2010.02415,cs.LG,2020-10-06 01:20:27+00:00,2021-02-22 13:03:54+00:00
Mh40mAxxAUz,2022,Reject,False,Bounding Membership Inference,"['Anvith Thudi', 'I Shumailov', 'Franziska Boenisch', 'Nicolas Papernot']","[""differential privacy"", ""membership inference""]","We bound the accuracy of any membership inference adversary, obtaining a rigorous metric which can be used in conjunction with differential privacy guarantees to understand the privacy of a training algorithm.",,,,
MhTgnultR1K,2021,Reject,False,A Real-time Contribution Measurement Method for Participants in Federated Learning,"[""Bingjie Yan"", ""Yize Zhou"", ""Boyi Liu"", ""Jun Wang"", ""Yuhan Zhang"", ""Li Liu"", ""Xiaolan Nie"", ""Zhiwei Fan"", ""Zhixuan Liang""]","[""Federated Learning"", ""Contribution Evaluation"", ""Multi-party Participation""]",,,,,
MjvduJCsE4,2021,Accept (Poster),True,Exploring the Uncertainty Properties of Neural Networksâ Implicit Priors in the Infinite-Width Limit,"[""Ben Adlam"", ""Jaehoon Lee"", ""Lechao Xiao"", ""Jeffrey Pennington"", ""Jasper Snoek""]","[""Deep Learning"", ""Uncertainty"", ""Infinite-Width Limit"", ""Neural Network Gaussian Process"", ""Bayesian Neural Networks"", ""Gaussian Process""]",We study the uncertainty properties of infinitely-wide neural networks,2010.07355,stat.ML,2020-10-14 18:41:54+00:00,2020-10-14 18:41:54+00:00
Mk6PZtgAgfq,2021,Accept (Oral),False,Rao-Blackwellizing the Straight-Through Gumbel-Softmax Gradient Estimator,"[""Max B Paulus"", ""Chris J. Maddison"", ""Andreas Krause""]","[""gumbel"", ""softmax"", ""gumbel-softmax"", ""straight-through"", ""straightthrough"", ""rao"", ""rao-blackwell""]",We reduce the variance of the straight-through Gumbel-Softmax estimator to improve its performance. ,,,,
MkTPtnjeYTV,2022,Accept (Spotlight),False,On the Optimal Memorization Power of ReLU Neural Networks,"['Gal Vardi', 'Gilad Yehudai', 'Ohad Shamir']","[""Expressivness"", ""Memorization"", ""Theory"", ""VC-dimension"", ""Deep learning theory""]","We show that ReLU neural networks can memorize N samples using \sqrt{N} parameters, and prove that up to logarithmic terms this is the optimal solution.",,,,
MkrAyYVmt7b,2021,Reject,False,Perfect density models cannot guarantee anomaly detection,"[""Charline Le Lan"", ""Laurent Dinh""]","[""anomaly detection"", ""out-of-distribution detection"", ""OOD detection"", ""outlier detection"", ""density estimation""]",Explaining issues of density models for anomaly detection.,2012.03808,cs.LG,2020-12-07 15:50:11+00:00,2021-02-23 18:03:29+00:00
MljXVdp4A3N,2022,Accept (Poster),False,Know Your Action Set: Learning Action Relations for Reinforcement Learning,"['Ayush Jain', 'Norio Kosaka', 'Kyung-Min Kim', 'Joseph J Lim']","[""reinforcement learning"", ""varying action space"", ""relational reasoning""]",Learning action interdependence for reinforcement learning under a varying action space.,,,,
Mlwe37htstv,2022,Reject,False,Efficient Wasserstein and Sinkhorn Policy Optimization,"['Jun Song', 'Chaoyue Zhao', 'Niao He']",[],,,,,
MmCRswl1UYl,2021,Accept (Poster),False,Open Question Answering over Tables and Text,"[""Wenhu Chen"", ""Ming-Wei Chang"", ""Eva Schlinger"", ""William Yang Wang"", ""William W. Cohen""]","[""Question Answering"", ""Tabular Data"", ""Open-domain"", ""Retrieval""]",We propose the new task of answering open-domain questions answering over web tables and text and design new techniques: 1) fused retrieval 2) cross-block reader to resolve the challenges posed in the new task.,,,,
MmcywoW7PbJ,2021,Reject,False,Learn Goal-Conditioned Policy with Intrinsic Motivation for Deep Reinforcement Learning,"[""Jinxin Liu"", ""Donglin Wang"", ""Qiangxing Tian"", ""Zhengyu Chen""]","[""unsupervised reinforcement learning"", ""goal-conditioned policy"", ""intrinsic reward""]",We learn the goal-conditioned policy in an unsupervised manner. ,2104.05043,cs.LG,2021-04-11 16:26:10+00:00,2021-04-11 16:26:10+00:00
MmujBClawFo,2022,Reject,False,Attention: Self-Expression Is All You Need,['Rene Vidal'],"[""Self-attention"", ""sparse representation"", ""subspace clustering""]","This paper shows that attention builds upon a long history of prior work on manifold learning and image processing, including methods such as kernel-based regression, non-local means, locally linear embedding, subspace clustering and sparse coding.",,,,
Mng8CQ9eBW,2022,Accept (Poster),True,BadPre: Task-agnostic Backdoor Attacks to Pre-trained NLP Foundation Models,"['Kangjie Chen', 'Yuxian Meng', 'Xiaofei Sun', 'Shangwei Guo', 'Tianwei Zhang', 'Jiwei Li', 'Chun Fan']",[],,2110.02467,cs.CL,2021-10-06 02:48:58+00:00,2021-10-06 02:48:58+00:00
Mo9R9oqzPo,2022,Reject,False,New Definitions and Evaluations for Saliency Methods: Staying Intrinsic and Sound,"['Arushi Gupta', 'Nikunj Saunshi', 'Dingli Yu', 'Kaifeng Lyu', 'Sanjeev Arora']","[""saliency"", ""masking based methods""]",,,,,
Mos9F9kDwkz,2021,Accept (Oral),True,Complex Query Answering with Neural Link Predictors,"[""Erik Arakelyan"", ""Daniel Daza"", ""Pasquale Minervini"", ""Michael Cochez""]","[""neural link prediction"", ""complex query answering""]","We show how to answer complex queries by answering their sub-queries via neural link predictors, aggregating results via t-norms and t-conorms, and identifying the optimal variable substitutions by solving an optimisation problem.",2011.03459,cs.LG,2020-11-06 16:20:49+00:00,2021-03-18 09:42:49+00:00
MpStQoD73Mj,2021,Reject,True,Differentiable Weighted Finite-State Transducers,"[""Awni Hannun"", ""Vineel Pratap"", ""Jacob Kahn"", ""Wei-Ning Hsu""]","[""weighted automata"", ""automatic differentiation"", ""sequence models""]",A framework for automatic differentiation with weighted finite-state transducers with some example use cases.,2010.01003,cs.LG,2020-10-02 13:52:24+00:00,2020-10-02 13:52:24+00:00
MqEcDNQwOSA,2022,Reject,False,Reconstructing Word Embeddings via Scattered $k$-Sub-Embedding,"['Soonyong Hwang', 'Byung-Ro Moon']","[""word embedding"", ""natural language understanding"", ""weight sharing"", ""contextual embedding""]",We reconstruct the embedding vectors from the shared sub-embedding vectors to lighten the language models.,,,,
Ms9zjhVB5R,2021,Reject,False,SOAR: Second-Order Adversarial Regularization,"[""Avery Ma"", ""Fartash Faghri"", ""Nicolas Papernot"", ""Amir-massoud Farahmand""]","[""Adversarial Robustness""]",We propose second-order adversarial regularizer (SOAR) to improve adversarial robustness of networks against $\ell_\infty$ and $\ell_2$ bounded perturbations.,,,,
MsHnJPaBUZE,2022,Accept (Poster),False,iFlood: A Stable and Effective Regularizer,"['Yuexiang Xie', 'Zhen WANG', 'Yaliang Li', 'Ce Zhang', 'Jingren Zhou', 'Bolin Ding']","[""overfitting"", ""regularizer""]","We propose a novel regularizer named iFlood, which encourages the trained models to better fit the under-fitted instances while suppressing the confidence on over-fitted ones.",,,,
Mspk_WYKoEH,2022,Accept (Poster),True,From Stars to Subgraphs: Uplifting Any GNN with Local Structure Awareness,"['Lingxiao Zhao', 'Wei Jin', 'Leman Akoglu', 'Neil Shah']","[""Graph Neural Networks"", ""Expressiveness"", ""Message Passing Neural Network"", ""Graph Classification""]",,2110.03753,cs.LG,2021-10-07 19:08:08+00:00,2021-12-09 05:32:10+00:00
MtEE0CktZht,2021,Accept (Poster),False,Rank the Episodes: A Simple Approach for Exploration in Procedurally-Generated Environments,"[""Daochen Zha"", ""Wenye Ma"", ""Lei Yuan"", ""Xia Hu"", ""Ji Liu""]","[""Reinforcement Learning"", ""Exploration"", ""Generalization of Reinforcement Learning"", ""Self-Imitation""]",Encouraging exploration via ranking the past episodes and reproducing past good exploration behaviors with imitation learning.,2101.08152,cs.LG,2021-01-20 14:22:01+00:00,2021-02-04 15:48:12+00:00
Mu2ZxFctAI,2021,Accept (Poster),False,Uncertainty-aware Active Learning for Optimal Bayesian Classifier,"[""Guang Zhao"", ""Edward Dougherty"", ""Byung-Jun Yoon"", ""Francis Alexander"", ""Xiaoning Qian""]","[""Active learning"", ""Bayesian classification""]","We focus on pool-based Bayesian active learning, for which we have proposed a new weighted MOCU method and analyzed its theoretical properties to demonstrate the better convergence properties than existing methods in this category.",,,,
MuSYkd1hxRP,2021,Accept (Spotlight),False,Geometry-Aware Gradient Algorithms for Neural Architecture Search,"[""Liam Li"", ""Mikhail Khodak"", ""Nina Balcan"", ""Ameet Talwalkar""]","[""neural architecture search"", ""automated machine learning"", ""weight-sharing"", ""optimization""]",Studying the right single-level optimization geometry yields state-of-the-art methods for NAS.,,,,
Mub9VkGZoZe,2021,Reject,False,Identifying Informative Latent Variables Learned by GIN via Mutual Information,"[""Chen Zhang"", ""Yitong Sun"", ""Mingtian Zhang""]",[],Identifying Informative Latent Variables Learned by GIN via Mutual Information,,,,
Muwg-ncP_ec,2022,Reject,True,Exact Stochastic Newton Method for Deep Learning: the feedforward networks case.,"['Fares B. Mehouachi', 'Chaouki Kasmi']","[""Deep Learning"", ""Second-order Optimization"", ""Newton Method"", ""Sifrian"", ""Hessian"", ""Exact Stochastic Newton"", ""Saddle-Free Newton"", ""Non-Convex Optimization""]",Theory and application of the stochastic second-order Newton method: a closed-form solution to train feedforward neural networks.,2104.03804,cs.LG,2021-04-08 14:29:31+00:00,2021-04-08 14:29:31+00:00
MvO2t0vbs4-,2022,Accept (Poster),False,Wisdom of Committees: An Overlooked Approach To Faster and More Accurate Models,"['Xiaofang Wang', 'Dan Kondratyuk', 'Eric Christiansen', 'Kris M. Kitani', 'Yair Movshovitz-Attias', 'Elad Eban']","[""Ensemble"", ""Cascade"", ""Efficiency""]",A simple ensemble or cascade of off-the-shelf pre-trained models can match or exceed the accuracy of SOTA models while being drastically more efficient.,,,,
MvtLspSX324,2022,Reject,False,Go with the Flow: the distribution of information processing in multi-path networks,"['Mats Leon Richter', 'Krupal Shah', 'Anna Wiedenroth', 'Saketh Bachu', 'Ulf Krumnack']","[""Deep Learning"", ""Multi-path Networks"", ""Similarity of Representations"", ""Regression Probe"", ""Centered Kernel Alignment""]",,,,,
Mwuc0Plt_x2,2021,Reject,True,RG-Flow: A hierarchical and explainable flow model based on renormalization group and sparse prior,"[""Hong-Ye Hu"", ""Dian Wu"", ""Yi-Zhuang You"", ""Bruno Olshausen"", ""Yubei Chen""]","[""Unsupervised learning"", ""representation learning"", ""flow-based generative model"", ""renormalization group"", ""sparse encoding""]","We incorporate the key idea of renormalization group (RG) and sparse prior distribution to design a hierarchical flow-based generative model, which can separate different scale information of images with disentangle representations at each scale.",2010.00029,cs.LG,2020-09-30 18:04:04+00:00,2020-12-18 20:27:11+00:00
MwxaStJXK6v,2021,Reject,False,Double Q-learning: New Analysis and Sharper Finite-time Bound,"[""Lin Zhao"", ""Huaqing Xiong"", ""Yingbin Liang"", ""Wei Zhang""]","[""Double Q-learning"", ""Finite-time analysis"", ""Convergence rate"", ""Stochastic approximation""]",This paper provides an order-level better finite-time convergence rate for double Q-learning by developing a new analysis approach.,,,,
MxaY4FzOTa,2021,Accept (Poster),True,High-Capacity Expert Binary Networks,"[""Adrian Bulat"", ""Brais Martinez"", ""Georgios Tzimiropoulos""]",[],,2010.03558,cs.CV,2020-10-07 17:58:10+00:00,2021-03-30 18:16:16+00:00
MyHwDabUHZm,2021,Accept (Poster),False,Beyond Categorical Label Representations for Image Classification,"[""Boyuan Chen"", ""Yu Li"", ""Sunand Raghupathi"", ""Hod Lipson""]","[""Label Representation"", ""Image Classification"", ""Representation Learning""]",We study the role of label representations for standard image classification task and found high-dimensional hign-entropy labes generally lead to more robust and data-efficient networks.,2104.02226,cs.LG,2021-04-06 01:31:04+00:00,2021-04-06 01:31:04+00:00
N07ebsD-lHp,2021,Reject,False,Defending against black-box adversarial attacks with gradient-free trained sign activation neural networks,"[""Yunzhe Xue"", ""Meiyan Xie"", ""Zhibo Yang"", ""Usman Roshan""]","[""sign activation neural network"", ""gradient-free training"", ""stochastic coordinate descent"", ""black box adversarial attack"", ""hopskipjump"", ""transferability"", ""image distortion""]","We show that an ensemble of our gradient free trained sign activation networks is much more adversarially robust than ensembles of binary, full precision, convolutional neural networks, and than random forest on image, text, and medical ECG data.",,,,
N0M_4BkQ05i,2021,Accept (Poster),True,Selective Classification Can Magnify Disparities Across Groups,"[""Erik Jones"", ""Shiori Sagawa"", ""Pang Wei Koh"", ""Ananya Kumar"", ""Percy Liang""]","[""selective classification"", ""group disparities"", ""log-concavity"", ""robustness""]",,2010.14134,cs.LG,2020-10-27 08:51:30+00:00,2021-04-14 15:56:59+00:00
N0n_QyQ5lBF,2022,Accept (Oral),False,Unsupervised Vision-Language Grammar Induction with Shared Structure Modeling,"['Bo Wan', 'Wenjuan Han', 'Zilong Zheng', 'Tinne Tuytelaars']","[""Grammar Induction"", ""Vision-Language Matching"", ""Unsupervised Learning""]",We introduce a new unsupervised vision-language grammar induction task to explore the multimodal information and induce a shared hierarchical structure for both image and language simultaneously.,,,,
N0uJGWDw21d,2022,Accept (Poster),True,Bag of Instances Aggregation Boosts Self-supervised Distillation,"['Haohang Xu', 'Jiemin Fang', 'XIAOPENG ZHANG', 'Lingxi Xie', 'Xinggang Wang', 'Wenrui Dai', 'Hongkai Xiong', 'Qi Tian']","[""Self-supervised learning"", ""knowledge distillation"", ""instance bagging""]",This paper proposes a new self-supervised distillation method which aggregates related instances bagged by the teacher and shows stronger performance than previous relation-agnostic methods.,2107.01691,cs.CV,2021-07-04 17:33:59+00:00,2021-07-04 17:33:59+00:00
N1WI0vJLER,2022,Accept (Poster),False,Parallel Training of GRU Networks with a Multi-Grid Solver for Long Sequences,"['Euhyun Moon', 'Eric C Cyr']","[""GRU"", ""MGRIT"", ""parallel-in-time"", ""distributed machine learning""]",This paper presents a novel parallel-in-time training scheme for GRU networks based on a MGRIT solver.,,,,
N2nJzgb_ldR,2022,Reject,False,FastRPB: a Scalable Relative Positional Encoding for Long Sequence Tasks,"['Maksim Zubkov', 'Daniil Gavrilov']","[""transformer"", ""linear transformer"", ""long sequences"", ""fast Fourier transform"", ""positional encoding"", ""long range arena""]",Improving efficient transformers with new kernel function and fast relative positional embeddings,,,,
N33d7wjgzde,2021,Accept (Poster),False,Universal Weakly Supervised Segmentation by Pixel-to-Segment Contrastive Learning,"[""Tsung-Wei Ke"", ""Jyh-Jing Hwang"", ""Stella Yu""]","[""weakly supervised representation learning"", ""representation learning for computer vision"", ""metric learning"", ""semantic segmentation""]",We propose a unified pixel-to-segment contrastive learning loss formulation for weakly supervised semantic segmentation with various types of annotations. ,,,,
N3KYKkSvciP,2022,Reject,False,Understanding Square Loss in Training Overparametrized Neural Network Classifiers,"['Tianyang Hu', 'Jun Wang', 'Wenjia Wang', 'Zhenguo Li']","[""classification"", ""square loss"", ""neural tangent kernel"", ""convergence rate""]","Through both theoretical analysis and empirical studies, we identify several ideal properties of using square loss in training neural network classifiers, including provable fast convergence rates, strong robustness, and small calibration error.",,,,
N3zUDGN5lO,2021,Accept (Poster),True,My Body is a Cage: the Role of Morphology in Graph-Based Incompatible Control,"[""Vitaly Kurin"", ""Maximilian Igl"", ""Tim Rockt\u00e4schel"", ""Wendelin Boehmer"", ""Shimon Whiteson""]","[""Deep Reinforcement Learning"", ""Multitask Reinforcement Learning"", ""Graph Neural Networks"", ""Continuous Control"", ""Incompatible Environments""]",Transformer-based approach to multitask incompatible continuous control inspired by a hypothesis that any benefits GNNs extract from the graph structure are outweighed by difficulties they create for message passing.,2010.01856,cs.LG,2020-10-05 08:37:11+00:00,2021-04-14 09:48:02+00:00
N4KRX61-_1d,2022,Reject,False,A Hierarchical Bayesian Approach to Inverse Reinforcement Learning with Symbolic Reward Machines,"['Weichao Zhou', 'Wenchao Li']","[""Reward Machines"", ""Finite State Automata"", ""Finite State Transducers"", ""Inverse Reinforcement Learning"", ""Reinforcement Learning""]",Design Symbolic Reward Machine for RL by Learning from Demonstrations,,,,
N5Zacze7uru,2021,Reject,False,Neural Lyapunov Model Predictive Control,"[""Mayank Mittal"", ""Marco Gallieri"", ""Alessio Quaglino"", ""Seyed Sina Mirrazavi Salehian"", ""Jan Koutnik""]","[""optimal control"", ""mpc"", ""lyapunov neural networks"", ""safe-learning"", ""safety""]",We propose an algorithm to infer the terminal cost and parameters of an MPC controller from transitions generated by an initial unknown demonstrator,,,,
N6JECD-PI5w,2021,Accept (Poster),False,FairFil: Contrastive Neural Debiasing Method for Pretrained Text Encoders,"[""Pengyu Cheng"", ""Weituo Hao"", ""Siyang Yuan"", ""Shijing Si"", ""Lawrence Carin""]","[""Fairness"", ""Contrastive Learning"", ""Mutual Information"", ""Pretrained Text Encoders""]",A debiasing method for large-scale pretrained text encoders via contrastive learning.,2103.06413,cs.CL,2021-03-11 02:01:14+00:00,2021-03-11 02:01:14+00:00
N6SmiyDrkR5,2021,Reject,False,What's in the Box? Exploring the Inner Life of Neural Networks with Robust Rules,"[""Jonas Fischer"", ""Anna Ol\u00e1h"", ""Jilles Vreeken""]","[""Neural Networks"", ""CNN"", ""explaining"", ""interpretable"", ""Rules"", ""black box""]",We propose a rule mining approach that reveals how neural networks perceive the world.,,,,
N8MaByOzUfb,2022,Accept (Poster),False,New Insights on Reducing Abrupt Representation Change in Online Continual Learning,"['Lucas Caccia', 'Rahaf Aljundi', 'Nader Asadi', 'Tinne Tuytelaars', 'Joelle Pineau', 'Eugene Belilovsky']","[""continual learning""]","We study how representations shift at task boundaries in the single-head online continual learning setting, leading to a simple high performance method",,,,
N9W24a4zU,2022,Accept (Poster),True,Steerable Partial Differential Operators for Equivariant Neural Networks,"['Erik Jenner', 'Maurice Weiler']","[""partial differential operators"", ""equivariance"", ""deep learning"", ""steerability""]","We present a framework for equivariant partial differential operators, generalizing existing approaches and narrowing the gap between PDOs and convolutions.",2106.10163,cs.LG,2021-06-18 14:58:19+00:00,2021-10-11 09:20:36+00:00
N9oPAFcuYWX,2021,Reject,False,Understanding and Mitigating Accuracy Disparity in Regression,"[""Jianfeng Chi"", ""Han Zhao"", ""Geoff Gordon"", ""Yuan Tian""]","[""Algorithmic Fairness"", ""Representation Learning""]",,,,,
NB0czpQ3-m,2022,Reject,False,RoMA: a Method for Neural Network Robustness Measurement and Assessment ,"['Natan Levy', 'Guy Katz']","[""Neuran Network"", ""Robustness"", ""Safety Critical Software"", ""Categorial Robustness""]",New method for neural network robustness measurement and assessment ,,,,
NCwIM2Q8ah6,2022,Reject,False,MDFL: A UNIFIED FRAMEWORK WITH META-DROPOUT FOR FEW-SHOT LEARNING,"['Shaobo Lin', 'Xingyu Zeng', 'Rui Zhao']","[""Few-shot learning""]",,,,,
NECTfffOvn1,2021,Accept (Spotlight),False,Fidelity-based Deep Adiabatic Scheduling,"[""Eli Ovits"", ""Lior Wolf""]",[],A new loss for applying supervised deep learning to the problem of scheduling adiabatic quantum computations,,,,
NGBY716p1VR,2021,Reject,True,Towards Understanding Fast Adversarial Training,"[""Bai Li"", ""Shiqi Wang"", ""Suman Jana"", ""Lawrence Carin""]","[""fast adversarial training"", ""adversarial examples""]",We studied and improved fast adversarial training.,2006.03089,cs.LG,2020-06-04 18:19:43+00:00,2020-06-04 18:19:43+00:00
NH29920YEmj,2022,Accept (Poster),False,Who Is Your Right Mixup Partner in Positive and Unlabeled Learning,"['Changchun Li', 'Ximing Li', 'Lei Feng', 'Jihong Ouyang']","[""Positive and Unlabeled Learning"", ""Mixup"", ""Heuristic""]",We propose a novel PU learning method named P3Mix which simultaneously benefits from instance augmentation and supervision correction with a heuristic mixup technique.,,,,
NHHM1jjrH1,2022,Reject,True,An Optimization Perspective on Realizing Backdoor Injection Attacks on Deep Neural Networks in Hardware,"['M. Caner Tol', 'Saad Islam', 'Berk Sunar', 'Ziming Zhang']","[""targeted attack"", ""bit-flip"", ""weight attack"", ""backdoor"", ""trojan""]",We propose a practical targeted attack method against the deployed DNN via flipping a few binary weight bits.,2110.07683,cs.LG,2021-10-14 19:43:53+00:00,2022-02-03 18:00:11+00:00
NK5hHymegzo,2022,Reject,False,On the One-sided Convergence of Adam-type Algorithms in Non-convex Non-concave Min-max Optimization,"['Zehao Dou', 'Yuanzhi Li']","[""Optimization"", ""GAN"", ""Convergence""]",This paper theoretically proves the one-sided convergence of Adam-type algorithms in min-max optimization as well as in GAN's training.,,,,
NLuOUSp9zZd,2021,Reject,False,DO-GAN: A Double Oracle Framework for Generative Adversarial Networks,"[""Aye Phyu Phyu Aung"", ""Xinrun Wang"", ""Runsheng Yu"", ""Bo An"", ""Senthilnath Jayavelu"", ""Xiaoli Li""]","[""GAN"", ""Generative Models"", ""Adversarial Networks"", ""Game Theory""]",We deploy a double-oracle framework to GAN architectures using the generator and discriminator oracles which results in significant improvements over the adapted models.,2102.08577,cs.LG,2021-02-17 05:11:18+00:00,2021-02-17 05:11:18+00:00
NMEceG4v69Y,2022,Accept (Oral),True,CycleMLP: A MLP-like Architecture for Dense Prediction,"['Shoufa Chen', 'Enze Xie', 'Chongjian GE', 'Runjian Chen', 'Ding Liang', 'Ping Luo']","[""MLP"", ""Dense Prediction""]",A versatile MLP-like architecture for both recognition and dense prediction.,2107.10224,cs.CV,2021-07-21 17:23:06+00:00,2021-11-30 14:15:02+00:00
NMgB4CVnMh,2021,Reject,True,Acoustic Neighbor Embeddings,"[""Woojay Jeon""]",[],"This paper proposes a novel acoustic word embedding called ""Acoustic Neighbor Embeddings""",2007.10329,eess.AS,2020-07-20 05:33:07+00:00,2020-11-26 17:53:39+00:00
NNd0J677PN,2021,Reject,False,Voting-based Approaches For Differentially Private Federated Learning,"[""Yuqing Zhu"", ""Xiang Yu"", ""Yi-Hsuan Tsai"", ""Francesco Pittaluga"", ""Masoud Faraki"", ""Manmohan Chandraker"", ""Yu-Xiang Wang""]",[],voting-based differentially private federated learning algorithms for vision applications,,,,
NOApNZTiTNU,2022,Reject,False,Aggressive Q-Learning with Ensembles: Achieving Both High Sample Efficiency and High Asymptotic Performance,"['Yanqiu Wu', 'Xinyue Chen', 'Che Wang', 'Yiming Zhang', 'Zijian Zhou', 'Keith W. Ross']","[""deep reinforcement learning"", ""off-policy"", ""model-free"", ""sample efficiency"", ""ensembles""]",We propose a simple model-free algorithm with ensembles that achieves both high sample efficiency and state-of-the-art asymptotic performance.,,,,
NP9T_pViXU,2022,Reject,True,VIMPAC: Video Pre-Training via Masked Token Prediction and Contrastive Learning,"['Hao Tan', 'Jie Lei', 'Thomas Wolf', 'Mohit Bansal']","[""video"", ""self-supervised learning"", ""representation learning"", ""pre-training"", ""action recognition""]",,2106.11250,cs.CV,2021-06-21 16:48:19+00:00,2021-06-21 16:48:19+00:00
NPJ5zWk_IQj,2022,Reject,False,Translating Robot Skills: Learning Unsupervised Skill Correspondences Across Robots,"['Tanmay Shankar', 'Yixin Lin', 'Aravind Rajeswaran', 'Vikash Kumar', 'Stuart Anderson', 'Jean Oh']","[""Robot Skills"", ""Unsupervised Correspondences"", ""Unsupervised Learning"", ""Alignment"", ""Density Matching"", ""Skill Learning"", ""Robot Learning"", ""Transfer Learning"", ""Skill Transfer""]",We learn unsupervised correspondences between skills across different morphological robots by matching explicit densities of skill sequences. ,,,,
NPab8GcO5Pw,2021,Reject,False,On the Landscape of Sparse Linear Networks,"[""Dachao Lin"", ""Ruoyu Sun"", ""Zhihua Zhang""]","[""theory"", ""sparse network"", ""landscape""]","We discuss sparse linear networks, showing some cases with or without bad-min.",,,,
NQbnPjPYaG6,2021,Accept (Poster),True,On the Impossibility of Global Convergence in Multi-Loss Optimization,"[""Alistair Letcher""]","[""impossibility"", ""global"", ""convergence"", ""optimization"", ""multi-loss"", ""multi-player"", ""multi-agent"", ""gradient"", ""descent""]",We prove that a set of desirable convergence properties cannot simultaneously hold for any multi-loss optimization algorithm.,2005.12649,math.OC,2020-05-26 12:11:18+00:00,2021-01-17 09:14:59+00:00
NQrx8EYMboO,2022,Reject,False,Task-Agnostic Graph Neural Explanations,"['Yaochen Xie', 'Sumeet Katariya', 'Xianfeng Tang', 'Edward W Huang', 'Nikhil Rao', 'Karthik Subbian', 'Shuiwang Ji']","[""Explainability"", ""interpretability"", ""graph neural networks"", ""self-supervised learning""]",,,,,
NRX9QZ6yqt,2022,Accept (Poster),False,Memory Augmented Optimizers for Deep Learning,"['Paul-Aymeric Martin McRae', 'Prasanna Parthasarathi', 'Mido Assran', 'Sarath Chandar']","[""Optimization for Deep learning"", ""Memory augmented Optimizers""]",We propose a framework of memory augmented optimizers and empirically show that the class of optimizers provide accelerated convergence and even better test performance. We show the proposed optimizers converge in smooth strongly convex setting.,,,,
NSBrFgJAHg,2021,Accept (Poster),False,Degree-Quant: Quantization-Aware Training for Graph Neural Networks,"[""Shyam Anil Tailor"", ""Javier Fernandez-Marques"", ""Nicholas Donald Lane""]","[""Graph neural networks"", ""quantization"", ""benchmark""]","We provide a training technique that enables graph neural networks to use low precision integer arithmetic at inference time, yielding up to 4.7x latency improvements on CPU",,,,
NTEz-6wysdb,2021,Accept (Poster),False,Distilling Knowledge from Reader to Retriever for Question Answering,"[""Gautier Izacard"", ""Edouard Grave""]","[""question answering"", ""information retrieval""]",We show that attention scores obtained by training a model to answer questions given a set of support documents can be used to train a model to select relevant passages in a knowledge source.,2012.04584,cs.CL,2020-12-08 17:36:34+00:00,2020-12-08 17:36:34+00:00
NTP9OdaT6nm,2021,Reject,False,Formal Language Constrained Markov Decision Processes,"[""Eleanor Quint"", ""Dong Xu"", ""Samuel W Flint"", ""Stephen D Scott"", ""Matthew Dwyer""]","[""safe reinforcement learning"", ""formal languages"", ""constrained Markov decision process"", ""safety gym"", ""safety""]",Specify safety constraints with formal languages to learn constraint structure representation and densely shape the CMDP cost function,,,,
NUCZeoVlAe,2021,Reject,False,Empirical Studies on the Convergence of Feature Spaces in Deep Learning,"[""Haoran Liu"", ""Haoyi Xiong"", ""Yaqing Wang"", ""Haozhe An"", ""Dongrui Wu"", ""Dejing Dou""]",[],,,,,
NX0nX7TE4lc,2022,Reject,False,DIVERSIFY to Generalize: Learning Generalized Representations for Time Series Classification,"['Wang Lu', 'Jindong Wang', 'Yiqiang Chen', 'Xinwei Sun']","[""Time series classification"", ""domain generalization""]",Learning representations for time series that can generalize well to unseen target distributions,,,,
NX1He-aFO_F,2021,Accept (Poster),True,Learning Value Functions in Deep Policy Gradients using Residual Variance,"[""Yannis Flet-Berliac"", ""reda ouhamma"", ""odalric-ambrym maillard"", ""Philippe Preux""]",[],We introduce a method to improve the learning of the critic in the actor-critic framework.,2010.04440,cs.LG,2020-10-09 08:57:06+00:00,2021-03-15 18:51:46+00:00
NYBmJN4MyZ,2022,Accept (Poster),False,Safe Neurosymbolic Learning with Differentiable Symbolic Execution,"['Chenxi Yang', 'Swarat Chaudhuri']","[""Verified Learning"", ""Neurosymbolic Programs"", ""Safe Learning"", ""Symbolic Execution""]","We present DSE, the first approach to worst-case-safe parameter learning for potentially non-differentiable neurosymbolic programs where we bridge symbolic execution and stochastic gradient estimator to learn the loss of safety properties.",,,,
NZQ8aTScT1-,2022,Reject,False,Eigenspace Restructuring:  a Principle of Space and Frequency in Neural Networks,['Lechao Xiao'],"[""neural network gaussian process"", ""neural tangent kernels"", ""eigenstructure"", ""space and frequency"", ""convolutional networks"", ""spherical harmonics"", ""hierarchical locality"", ""over-parameterized networks""]","The network topology restructures the eigenspaces of the corresponding neural kernels, substantially improving the network's learnability. ",2112.05611,cs.LG,2021-12-10 15:44:14+00:00,2021-12-10 15:44:14+00:00
NZj7TnMr01,2021,Reject,False,Improving Neural Network Accuracy and Calibration Under Distributional Shift with Prior Augmented Data ,"[""Jeffrey Ryan Willette"", ""Juho Lee"", ""Sung Ju Hwang""]","[""Bayesian"", ""Calibration""]",We propose a method of training existing neural network models which results in better calibrated probabilistic outputs.,,,,
Naqw7EHIfrv,2021,Accept (Poster),True,Representation Learning for Sequence Data with Deep Autoencoding Predictive Components,"[""Junwen Bai"", ""Weiran Wang"", ""Yingbo Zhou"", ""Caiming Xiong""]","[""Mutual Information"", ""Unsupervised Learning"", ""Sequence Data"", ""Masked Reconstruction""]",,2010.03135,cs.LG,2020-10-07 03:34:01+00:00,2021-02-28 20:50:46+00:00
NblYkw2U2Yg,2022,Reject,False,A Generalised Inverse Reinforcement Learning Framework,"['Firas Jarboui', 'Vianney Perchet']","[""IRL""]",,,,,
Nc3TJqbcl3,2021,Accept (Poster),False,Extracting Strong Policies for Robotics Tasks from Zero-Order Trajectory Optimizers,"[""Cristina Pinneri"", ""Shambhuraj Sawant"", ""Sebastian Blaes"", ""Georg Martius""]","[""reinforcement learning"", ""zero-order optimization"", ""policy learning"", ""model-based learning"", ""robotics"", ""model predictive control""]",We propose an adaptively guided imitation learning method that is able to extract strong policies for hard robotic tasks from zero-order trajectory optimizers.,,,,
NcFEZOi-rLa,2021,Accept (Poster),False,Shape or Texture: Understanding Discriminative Features in CNNs,"[""Md Amirul Islam"", ""Matthew Kowal"", ""Patrick Esser"", ""Sen Jia"", ""Bj\u00f6rn Ommer"", ""Konstantinos G. Derpanis"", ""Neil Bruce""]","[""Shape"", ""Texture"", ""Shape Bias"", ""Texture Bias"", ""Shape Encoding"", ""Mutual Information""]",Exploring and quantifying shape information encoded in CNNs.,,,,
Nct9j3BVswZ,2022,Reject,False,"Self-Supervise, Refine, Repeat: Improving Unsupervised Anomaly Detection","['Jinsung Yoon', 'Kihyuk Sohn', 'Chun-Liang Li', 'Sercan O Arik', 'Chen-Yu Lee', 'Tomas Pfister']","[""Anomaly detection"", ""Data refinement"", ""Iterative training""]",,,,,
NdOoQnYPj_,2022,Accept (Poster),False,BAM: Bayes Augmented with Memory,"['Josue Nassar', 'Jennifer Rogers Brennan', 'Ben Evans', 'Kendall Lowrey']","[""Bayesian learning"", ""online learning""]",We augment Bayes with memory to generalize many frameworks and overcome limitations of traditional methods in non-stationary settings,,,,
NeRdBeTionN,2021,Accept (Spotlight),False,On Self-Supervised Image Representations for GAN Evaluation,"[""Stanislav Morozov"", ""Andrey Voynov"", ""Artem Babenko""]","[""GAN"", ""evaluation"", ""embedding""]",We show that the state-of-the-art self-supervised representations should be used when comparing GANs on the non-Imagenet datasets,,,,
NeRrtif_hfa,2022,Reject,False,Better state exploration using action sequence equivalence,"['Nathan Grinsztajn', 'Toby Johnstone', 'Johan Ferret', 'Philippe Preux']","[""Reinforcement learning"", ""priors"", ""structure"", ""exploration""]",,,,,
NfZ6g2OmXEk,2021,Reject,False,Prioritized Level Replay,"[""Minqi Jiang"", ""Edward Grefenstette"", ""Tim Rockt\u00e4schel""]","[""Reinforcement Learning"", ""Procedurally Generated Environments"", ""Curriculum Learning"", ""Procgen Benchmark""]","TD error can be exploited to score procedurally generated levels for future learning potential, thereby inducing a curriculum from easier to harder levels and providing significant gains in OpenAI Procgen Benchmark and MiniGrid.",,,,
Nfl-iXa-y7R,2022,Accept (Spotlight),False,Pixelated Butterfly: Simple and Efficient Sparse training for Neural Network Models,"['Beidi Chen', 'Tri Dao', 'Kaizhao Liang', 'Jiaming Yang', 'Zhao Song', 'Atri Rudra', 'Christopher Re']","[""Sparse training"", ""butterfly"", ""low-rank"", ""Lottery Tickets"", ""Block sparsity"", ""Hashing"", ""Transformer"", ""ViT"", ""MLP-Mixer""]","We propose a simple sparse training method, which can speed up model training in wall-clock time with no drop in accuracy.",2112.00029,cs.LG,2021-11-30 19:00:03+00:00,2021-11-30 19:00:03+00:00
Ng8wWGXXIXh,2022,Reject,False,On Invariance Penalties for Risk Minimization,"['Kia Khezeli', 'Arno Blaas', 'Frank Soboczenski', 'Nicholas Chia', 'John Kalantari']","[""domain generalization"", ""out-of-distribution generalization"", ""invariant risk minimization"", ""invariant representation learning""]","Building on the work of Arjovsky et al. (2019), we propose a novel invariance penalty and demonstrate its efficacy in improving OoD generalization both on synthetic and real-world datasets.",,,,
NgZKCRKaY3J,2021,Reject,False,Mitigating bias in calibration error estimation,"[""Rebecca Roelofs"", ""Nicholas Cain"", ""Jonathon Shlens"", ""Michael Curtis Mozer""]","[""calibration error"", ""uncertainty estimation"", ""statistical bias""]",We highlight estimation bias in standard calibration error metrics and propose a less biased metric based on monotonic binning.,,,,
NgmcJ66xQz_,2022,Reject,False,Divide and Explore: Multi-Agent Separate Exploration with Shared Intrinsic Motivations,"['Xiao Jing', 'Zhenwei Zhu', 'Hongliang Li', 'Xin Pei', 'Yoshua Bengio', 'Tong Che', 'Hongyong Song']","[""Deep Reinforcement Learning"", ""Exploration"", ""Intrinsic Motivation"", ""Distributed Learning""]","Divide and Explore trains multiple concurrent exploring agents, and successfully guides each agent exploring different regions of state space with shared intrinsic motivations while keeping exploring the boundary.",,,,
Nh7CtbyoqV5,2022,Accept (Poster),False,Normalization of Language Embeddings for Cross-Lingual Alignment,"['Prince Osei Aboagye', 'Yan Zheng', 'Chin-Chia Michael Yeh', 'Junpeng Wang', 'Wei Zhang', 'Liang Wang', 'Hao Yang', 'Jeff Phillips']","[""cross-lingual word embeddings"", ""natural language processing""]",Our embedding normalization subsumes existing approaches and consistently improves cross-lingual alignment. ,,,,
Nj8EIrSu5O,2021,Reject,False,Divide-and-Conquer Monte Carlo Tree Search,"[""Giambattista Parascandolo"", ""Lars Holger Buesing"", ""Josh Merel"", ""Leonard Hasenclever"", ""John Aslanides"", ""Jessica B Hamrick"", ""Nicolas Heess"", ""Alexander Neitz"", ""Theophane Weber""]","[""MCTS"", ""planning"", ""goal-directed planning"", ""divide and conquer""]",,,,,
NjF772F4ZZR,2021,Accept (Poster),False,Learning the Pareto Front with Hypernetworks,"[""Aviv Navon"", ""Aviv Shamsian"", ""Ethan Fetaya"", ""Gal Chechik""]","[""Multi-objective optimization"", ""multi-task learning""]",A novel approach for learning the entire Pareto front using hypernetworks,,,,
NkZq4OEYN-,2022,Accept (Poster),False,Sound Adversarial Audio-Visual Navigation,"['Yinfeng Yu', 'Wenbing Huang', 'Fuchun Sun', 'Changan Chen', 'Yikai Wang', 'Xiaohong Liu']",[],This work aims to do an adversarial sound intervention for robust audio-visual navigation.,,,,
NlObxR0rosG,2022,Accept (Poster),False,Practical Integration via Separable Bijective Networks,"['Christopher M Bender', 'Patrick Emmanuel', 'Michael K. Reiter', 'Junier Oliva']","[""integration"", ""flow"", ""likelihood"", ""classification"", ""regression"", ""out of distribution"", ""regularization""]",We explore a method that enables learning over hypervolumes within the data space.,,,,
NlrFDOgRRH,2021,Reject,True,Distributed Associative Memory Network with Association Reinforcing Loss,"[""Taewon Park"", ""Inchul Choi"", ""Minho Lee""]","[""memory augmented neural network"", ""distributed memory"", ""memorization"", ""relational reasoning""]",Memory augmented neural network enhancing strategy.,2007.10637,cs.LG,2020-07-21 07:34:33+00:00,2021-08-27 04:43:06+00:00
Nn4BjABPRPN,2022,Reject,False,Encoding Event-Based Gesture Data With a Hybrid SNN Guided Variational Auto-encoder,"['Kenneth Michael Stewart', 'Andreea Danielescu', 'Timothy Shea', 'Emre Neftci']","[""Neuromorphic Computing"", ""Variational Auto-encoders"", ""Representation Learning"", ""Spiking Neural Networks"", ""Self-supervised Learning""]",We present a novel algorithm for encoding and learning the latent representations of event-based gesture data with a proof of concept in Intel's Loihi neuromorphic hardware.,,,,
NoB8YgRuoFU,2022,Accept (Poster),True,PI3NN: Out-of-distribution-aware Prediction Intervals from Three Neural Networks,"['Siyan Liu', 'Pei Zhang', 'Dan Lu', 'Guannan Zhang']",[],,2108.02327,cs.LG,2021-08-05 00:55:20+00:00,2021-10-12 20:09:51+00:00
NoE4RfaOOa,2022,Reject,False,Where can quantum kernel methods make a big difference?,"['Muhao Guo', 'Yang Weng']","[""Kernel"", ""Quantum"", ""Classification""]",Where can quantum kernel methods make a big difference?,,,,
NomEDgIEBwE,2021,Accept (Poster),True,Improving Transformation Invariance in Contrastive Representation Learning,"[""Adam Foster"", ""Rattana Pukdee"", ""Tom Rainforth""]","[""contrastive learning"", ""representation learning"", ""transformation invariance""]",We propose methods to strengthen the invariance properties of representations obtained by contrastive learning using novel gradient regularization during training and feature averaging at test time.,2010.09515,cs.LG,2020-10-19 13:49:29+00:00,2021-03-22 14:20:51+00:00
Nq5zyAUD65,2021,Reject,False,Smooth Activations and Reproducibility in Deep Networks,"[""Gil I Shamir"", ""Dong Lin"", ""Lorenzo Coviello""]","[""Deep networks"", ""activation functions"", ""reproducibility""]","We propose a new family of activations, Smooth ReLU (or SmeLU), that provide better accuracy-reproducibility tradeoffs in deep networks.",,,,
NqDLrS73nG,2022,Reject,False,Transliteration: A Simple Technique For Improving Multilingual Language Modeling ,"['Ibraheem Muhammad Moosa', 'Mahmud Elahi Akhter', 'Ashfia Binte Habib']","[""Multilingual Language Model"", ""Natural Language Processing"", ""Transliteration"", ""Underrepresented Language Modeling""]",Transliteration a simple technique to improve multilingual language model performance. ,2201.12501,cs.CL,2022-01-29 05:48:42+00:00,2022-01-29 05:48:42+00:00
NqPW1ZJjXDJ,2021,Reject,False,NASOA: Towards Faster Task-oriented Online Fine-tuning,"[""Hang Xu"", ""Ning Kang"", ""Gengwei Zhang"", ""Xiaodan Liang"", ""Zhenguo Li""]","[""Fine-tuning"", ""AutoML"", ""NAS""]",We propose a Neural Architecture Search and Online Adaption framework named NASOA towards a faster task-oriented fine-tuning upon the request of users.,,,,
NqWY3s0SILo,2021,Reject,False,Differentiable Graph Optimization for Neural Architecture Search,"[""Chengyue Huang"", ""Lingfei Wu"", ""Yadong Ding"", ""Siliang Tang"", ""Fangli Xu"", ""Chang Zong"", ""Chilie Tan"", ""Yueting Zhuang""]","[""Neural Architecture Search"", ""Graph Structure Learning""]",,,,,
NrB52z3eOTY,2022,Reject,False,Effective Uncertainty Estimation with Evidential Models for Open-World Recognition,"['Charles CorbiÃ¨re', 'Marc Lafon', 'Nicolas THOME', 'Matthieu Cord', 'Patrick Perez']","[""deep learning"", ""uncertainty estimation"", ""evidential models"", ""misclassification detection"", ""out-of-distribution detection"", ""confidence learning""]",We leverage evidential models to define a measure which quantify both in-distribution and out-of-distribution uncertainties.,,,,
NrN8XarA2Iz,2021,Reject,False,Learning to Dynamically Select Between Reward Shaping Signals,"[""Alexander Politowicz"", ""Bing Liu""]","[""selection"", ""automatic"", ""reward"", ""shaping"", ""reinforcement learning""]","Reinforcement learning can be accelerated through online, value-based selection between multiple shaping reward signals.",,,,
NrkAAcMpRoT,2022,Reject,True,C-MinHash: Improving Minwise Hashing with Circulant Permutation,"['Xiaoyun Li', 'Ping Li']",[],,2109.03337,stat.ML,2021-09-07 21:06:33+00:00,2021-09-07 21:06:33+00:00
Ns8v4jHGyAV,2021,Reject,False,Matrix Shuffle-Exchange Networks for Hard 2D Tasks,"[""Em\u012bls Ozoli\u0146\u0161"", ""Karlis Freivalds"", ""Agris \u0160ostaks""]",[],,,,,
NsMLjcFaO8O,2021,Accept (Poster),False,WaveGrad: Estimating Gradients for Waveform Generation,"[""Nanxin Chen"", ""Yu Zhang"", ""Heiga Zen"", ""Ron J Weiss"", ""Mohammad Norouzi"", ""William Chan""]","[""vocoder"", ""diffusion"", ""score matching"", ""text-to-speech"", ""gradient estimation"", ""waveform generation""]","This paper introduces WaveGrad, a conditional model for waveform generation through estimating gradients of the data density.",,,,
NudBMY-tzDr,2022,Accept (Oral),False,Natural Language Descriptions of Deep Features,"['Evan Hernandez', 'Sarah Schwettmann', 'David Bau', 'Teona Bagashvili', 'Antonio Torralba', 'Jacob Andreas']",[],,2201.11114,cs.CV,2022-01-26 18:48:02+00:00,2022-01-26 18:48:02+00:00
Nus6fOfh1HW,2022,Reject,False,On the Relationship between Heterophily and Robustness of Graph Neural Networks,"['Jiong Zhu', 'Junchen Jin', 'Donald Loveland', 'Michael T Schaub', 'Danai Koutra']","[""graph neural networks"", ""adversarial attacks"", ""heterophily"", ""structural perturbation"", ""robustness"", ""relation""]","We explore the interplay between heterophily & robustness in GNNs, and show that 1) effective structural attacks on homophilous graphs increase heterophily, 2) heterophilous GNN designs can be combined with defense mechanisms for improved robustness.",,,,
NuzF7PHTKRw,2022,Reject,False,EAT-C: Environment-Adversarial sub-Task Curriculum for Efficient Reinforcement Learning,"['Shuang Ao', 'Tianyi Zhou', 'Jing Jiang', 'Guodong Long', 'Xuan Song', 'Chengqi Zhang']","[""reinforcement learning"", ""curriculum learning"", ""sub-tasks"", ""adversarial environment"", ""path planning""]","We propose a auto-curriculum for RL where a co-operative path planner, an adversarial environment generator and the RL are jointly trained to improve both the learning efficency and the robustness to the environment.  ",,,,
NyJ2KIN8P17,2022,Accept (Poster),False,Neural Program Synthesis with Query,"['Di Huang', 'Rui Zhang', 'Xing Hu', 'Xishan Zhang', 'Pengwei Jin', 'Nan Li', 'Zidong Du', 'Qi Guo', 'Yunji Chen']",[],We propose a query-based framework for the interactive program synthesis.,,,,
NzTU59SYbNq,2021,Accept (Oral),False,EigenGame: PCA as a Nash Equilibrium,"[""Ian Gemp"", ""Brian McWilliams"", ""Claire Vernade"", ""Thore Graepel""]","[""pca"", ""principal components analysis"", ""nash"", ""games"", ""eigendecomposition"", ""svd"", ""singular value decomposition""]",We formulate the solution to PCA as the Nash of a suitable game with accompanying algorithm that we demonstrate on a 200TB dataset.,,,,
O-6Pm_d_Q-,2021,Accept (Poster),True,Deep Networks and the Multiple Manifold Problem,"[""Sam Buchanan"", ""Dar Gilboa"", ""John Wright""]","[""deep learning"", ""overparameterized neural networks"", ""low-dimensional structure""]","We prove a finite-time generalization result for deep fully-connected neural networks trained by gradient descent to classify structured data, where the required width, depth, and sample complexity depend only on intrinsic properties of the data.",2008.11245,stat.ML,2020-08-25 19:20:00+00:00,2021-05-06 06:55:39+00:00
O-XJwyoIF-k,2021,Accept (Spotlight),True,Minimum Width for Universal Approximation,"[""Sejun Park"", ""Chulhee Yun"", ""Jaeho Lee"", ""Jinwoo Shin""]","[""universal approximation"", ""neural networks""]",We establish the tight bound on width for the universal approximability of neural network.,2006.08859,cs.LG,2020-06-16 01:24:21+00:00,2020-06-16 01:24:21+00:00
O-r8LOR-CCA,2022,Accept (Poster),False,Open-World Semi-Supervised Learning,"['Kaidi Cao', 'Maria Brbic', 'Jure Leskovec']","[""deep learning"", ""semi-supervised learning"", ""novel class discovery"", ""clustering""]","We propose a pipeline that recognizes previously seen classes and discovers novel, never-before-seen classes at the same time.",,,,
O0g6uPDLW7,2022,Reject,True,On the Adversarial Robustness of Vision Transformers,"['Rulin Shao', 'Zhouxing Shi', 'Jinfeng Yi', 'Pin-Yu Chen', 'Cho-Jui Hsieh']","[""vision transformer (ViT)"", ""adversarial robustness""]",This work provides the first and comprehensive study on the robustness of vision transformers (ViTs) against adversarial perturbations.,2103.15670,cs.CV,2021-03-29 14:48:24+00:00,2021-10-14 23:09:48+00:00
O1DEtITim__,2022,Accept (Spotlight),False,"Learning Pruning-Friendly Networks via Frank-Wolfe: One-Shot, Any-Sparsity, And No Retraining","['Lu Miao', 'Xiaolong Luo', 'Tianlong Chen', 'Wuyang Chen', 'Dong Liu', 'Zhangyang Wang']","[""Pruning"", ""Frank-Wolfe""]","We propose a novel and state-of-the-art one-shot pruning method, which can generate sparse networks at any pruning ratio in one pruning and without any retraining.",,,,
O1pkU_4yWEt,2021,Reject,False,Distantly supervised end-to-end medical entity extraction from electronic health records with human-level quality,"[""Alexander Nesterov"", ""Dmitry Umerenkov""]","[""entity extraction"", ""medical entity extraction"", ""named entity recognition"", ""named entity normalization"", ""electronic health records"", ""unsupervised learning"", ""distant supervision.""]",We propose a method of medical entity extraction as a single-step multi-label classification task with distant supervision labels and achieve human-level extraction quality for most frequent entities.,,,,
O2s9k4h0x7L,2022,Reject,True,A Deep Latent Space Model for Directed Graph Representation Learning,"['Hanxuan Yang', 'Qingchao Kong', 'Wenji Mao']","[""graph representation learning"", ""directed graph"", ""latent space model"", ""variational autoencoder""]","We propose a VAE-based deep generative model for directed graph representation learning, which can generate multiple highly interpretable node representations.",2106.11721,cs.LG,2021-06-22 12:41:19+00:00,2021-06-22 12:41:19+00:00
O358nrve1W,2021,Reject,False,Neurally Guided Genetic Programming for Turing Complete Programming by Example,"[""Alexander Newton Wild"", ""Barry Porter""]","[""Code Synthesis"", ""Neural Code Synthesis"", ""Genetic Programming"", ""Programming By Example""]","This paper demonstrates that the use of genetic programming, guided by neural networks to provide search hints, is able to synthesise complex programs in a Turing-complete language -- up to and including the synthesis of sorting algorithms.",,,,
O3Y56aqpChA,2021,Accept (Oral),True,Self-training For Few-shot Transfer Across Extreme Task Differences,"[""Cheng Perng Phoo"", ""Bharath Hariharan""]","[""few-shot learning"", ""self-training"", ""cross-domain few-shot learning""]",Self-training a source domain classifier on unlabeled data from the target domain improves cross-domain few-shot transfer. ,2010.07734,cs.CV,2020-10-15 13:23:59+00:00,2021-03-17 16:11:57+00:00
O3bqkf_Puys,2021,Accept (Poster),False,PSTNet: Point Spatio-Temporal Convolution on Point Cloud Sequences,"[""Hehe Fan"", ""Xin Yu"", ""Yuhang Ding"", ""Yi Yang"", ""Mohan Kankanhalli""]","[""Point cloud"", ""spatio-temporal modeling"", ""video analysis"", ""action recognition"", ""semantic segmentation"", ""convolutional neural network""]","This paper proposes a point spatio-temporal (PST) convolution, which decomposes space and time, to learn representations of raw point cloud sequences in a spatio-temporally hierarchical manner.",,,,
O476oWmiNNp,2022,Accept (Poster),False,Scaling the Depth of Vision Transformers via the Fourier Domain Analysis,"['Peihao Wang', 'Wenqing Zheng', 'Tianlong Chen', 'Zhangyang Wang']","[""Deep ViT"", ""Spectral Analysis"", ""Attention Collapse"", ""Patch Diversity""]","In this paper, we investigate the scalability issue with ViT via Fourier domain analysis and propose two practical solutions by scaling different frequency components of attention and feature maps.",,,,
O50443AsCP,2022,Accept (Poster),True,TAPEX: Table Pre-training via Learning a Neural SQL Executor,"['Qian Liu', 'Bei Chen', 'Jiaqi Guo', 'Morteza Ziyadi', 'Zeqi Lin', 'Weizhu Chen', 'Jian-Guang Lou']","[""table pre-training"", ""sythetic pre-training"", ""SQL execution"", ""table-based question answering"", ""table-based fact verification""]","This work performs table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries and their execution results.",2107.07653,cs.CL,2021-07-16 00:40:11+00:00,2021-11-24 13:37:12+00:00
O5Wr-xX0U2y,2022,Reject,False,Deep Reinforcement Learning for Equal Risk Option Pricing and Hedging under Dynamic Expectile Risk Measures,"['Saeed Marzban', 'Erick Delage', 'Jonathan Li']","[""Deep reinforcement learning"", ""risk averse Markov decision processes"", ""expectile risk measures"", ""derivative pricing""]",This paper extends for the first time a model-free off-policy actor-critic algorithm to the problem of solving a risk averse Markov decision process and applies it to calculate the equal risk prices of financial derivatives in an incomplete market.,,,,
O6LPudowNQm,2021,Accept (Poster),False,INT: An Inequality Benchmark for Evaluating Generalization in Theorem Proving,"[""Yuhuai Wu"", ""Albert Jiang"", ""Jimmy Ba"", ""Roger Baker Grosse""]","[""Theorem proving"", ""Synthetic benchmark dataset"", ""Generalization"", ""Transformers"", ""Graph neural networks"", ""Monte Carlo Tree Search""]","We introduce INT, a synthetic INequality Theorem proving benchmark, to tackle the data sparsity and out-of-distribution problems for theorem proving and benchmarked transformer-based and GNN-based agents' generalization performance.",,,,
O7ms4LFdsX,2021,Accept (Spotlight),False,Disentangled Recurrent Wasserstein Autoencoder ,"[""Jun Han"", ""Martin Renqiang Min"", ""Ligong Han"", ""Li Erran Li"", ""Xuan Zhang""]","[""Sequential  Representation Learning"", ""Disentanglement"", ""Recurrent Generative Model""]",We propose the first recurrent Wasserstein Autoencoder for learning disentangled representations of sequential data with theoretical analysis.,2101.07496,cs.LG,2021-01-19 07:43:25+00:00,2021-01-19 07:43:25+00:00
O9DAoNnYVlM,2022,Reject,True,Federated Learning via Plurality Vote,"['Kai Yue', 'Richeng Jin', 'Chau-Wai Wong', 'Huaiyu Dai']","[""Federated Learning via Plurality Vote""]",,2110.02998,cs.LG,2021-10-06 18:16:22+00:00,2021-10-06 18:16:22+00:00
O9bnihsFfXU,2021,Accept (Poster),True,Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning,"[""Aviral Kumar"", ""Rishabh Agarwal"", ""Dibya Ghosh"", ""Sergey Levine""]","[""deep Q-learning"", ""data-efficient RL"", ""rank-collapse"", ""offline RL""]",Identifies and studies feature matrix rank collapse (i.e. implicit regularization) in deep Q-learning methods.,2010.14498,cs.LG,2020-10-27 17:55:16+00:00,2021-10-25 03:10:12+00:00
OAdGsaptOXy,2021,Reject,False,Pretrain Knowledge-Aware Language Models,"[""Corbin L Rosset"", ""Chenyan Xiong"", ""Minh Phan"", ""Xia Song"", ""Paul N. Bennett"", ""saurabh tiwary""]","[""Pretraining"", ""Natural Language Generation"", ""GPT-2"", ""QA"", ""Knowledge Graph""]","Without changing the transformer architecture, we can pack more knowledge into GPT-2 parameters by signaling the existence of entities, leading to better QA performance. ",,,,
OBI5QuStBz3,2021,Reject,False,Improved Communication Lower Bounds for Distributed Optimisation,"[""Janne H. Korhonen"", ""Dan Alistarh""]","[""distributed optimization"", ""lower bounds"", ""upper bounds"", ""communication complexity""]",We give the first tight bounds for the communication complexity of optimizing a sum of quadratic functions in a distributed setting; the result has non-trivial extensions and implications for the fundamental limits of distributed optimization.,,,,
OBwsUF4nFye,2022,Reject,False,Private Multi-Task Learning: Formulation and Applications to Federated Learning,"['Shengyuan Hu', 'Steven Wu', 'Virginia Smith']","[""privacy preserving machine learning"", ""large scale machine learning"", ""multi-task learning""]",In this work we formalize the task-level privacy notion in MTL and then propose an algorithm to obtain JDP in MTL.,,,,
OCRKCul3eKN,2021,Reject,False,Addressing Extrapolation Error in Deep Offline Reinforcement Learning,"[""Caglar Gulcehre"", ""Sergio G\u00f3mez Colmenarejo"", ""ziyu wang"", ""Jakub Sygnowski"", ""Thomas Paine"", ""Konrad Zolna"", ""Yutian Chen"", ""Matthew Hoffman"", ""Razvan Pascanu"", ""Nando de Freitas""]","[""Addressing Extrapolation Error in Deep Offline Reinforcement Learning""]",We are proposing methods to address extrapolation error in deep offline reinforcement learning.,,,,
OCgCYv7KGZe,2022,Reject,False,Auto-Encoding Inverse Reinforcement Learning,"['Kaifeng Zhang', 'Rui Zhao', 'Ziming Zhang', 'Yang Gao']","[""Adversarial Imitation Learning"", ""Inverse Reinforcement Learning"", ""Auto-Encoding""]",A new adversarial imitation learning method based on encoding-decoding process. ,,,,
OCm0rwa1lx1,2021,Reject,True,Addressing Some Limitations of Transformers with Feedback Memory,"[""Angela Fan"", ""Thibaut Lavril"", ""Edouard Grave"", ""Armand Joulin"", ""Sainbayar Sukhbaatar""]","[""Feedback"", ""Memory"", ""Transformers""]",Transformers have shortcomings - limited memory and limited state update - but Feedback Memory is a straightforward way to resolve these. ,2002.09402,cs.LG,2020-02-21 16:37:57+00:00,2021-01-25 13:12:00+00:00
ODKwX19UjOj,2021,Reject,False,Unsupervised Hierarchical Concept Learning,"[""Sumegh Roychowdhury"", ""Sumedh Anand Sontakke"", ""Mausoom Sarkar"", ""Nikaash Puri"", ""Milan Aggarwal"", ""Pinkesh Badjatiya"", ""Balaji Krishnamurthy"", ""Laurent Itti""]","[""hierarchical learning"", ""unsupervised learning"", ""unsupervised hierarchical learning"", ""video representation learning"", ""learning from demonstrations""]",,,,,
OD_dnx57ksK,2022,Reject,False,Momentum Conserving Lagrangian Neural Networks,"['Ravinder Bhattoo', 'Sayan Ranu', 'N M Anoop Krishnan']",[],,,,,
ODnCiZujily,2022,Reject,False,DeepSplit: Scalable Verification of Deep Neural Networks via Operator Splitting,"['Shaoru Chen', 'Eric Wong', 'J Zico Kolter', 'Mahyar Fazlyab']","[""neural network verification"", ""operator splitting"", ""ADMM""]",Verify robustness of deep neural networks via operator splitting to promote scalability,,,,
OEgDatKuz2O,2021,Reject,False,EMTL: A Generative Domain Adaptation Approach,"[""Jianfeng Zhang"", ""Illyyne Saffar"", ""Aladin Virmaux"", ""Bal\u00e1zs K\u00e9gl""]","[""unsupervised domain adaptation"", ""EM"", ""generative model"", ""density estimation"", ""deep learning"", ""transfer learning""]",,,,,
OGbbY4qmir5,2022,Reject,False,Neurally boosted supervised spectral clustering,"['Ali Parviz', 'Ioannis Koutis']","[""Supervised Node Classification"", ""Spectral Embedding"", ""Social Graphs"", ""Neural Models""]",Scalable neural model leveraging geometric properties of spectral embeddings for improved classification performance.,,,,
OGg9XnKxFAH,2021,Accept (Poster),False,Training independent subnetworks for robust prediction,"[""Marton Havasi"", ""Rodolphe Jenatton"", ""Stanislav Fort"", ""Jeremiah Zhe Liu"", ""Jasper Snoek"", ""Balaji Lakshminarayanan"", ""Andrew Mingbo Dai"", ""Dustin Tran""]","[""Efficient ensembles"", ""robustness""]","We show that a deep neural network can be trained to give multiple independent predictions simultaneously, which results in a computationally efficient ensemble model.",,,,
OHgnfSrn2jv,2021,Accept (Poster),True,Efficient Wasserstein Natural Gradients for Reinforcement Learning,"[""Ted Moskovitz"", ""Michael Arbel"", ""Ferenc Huszar"", ""Arthur Gretton""]","[""reinforcement learning"", ""optimization""]","We develop novel, efficient estimators for the Wasserstein natural gradient applied to reinforcement learning that improve the efficiency and performance of advanced baselines.",2010.05380,cs.LG,2020-10-12 00:50:17+00:00,2021-03-18 10:41:34+00:00
OIs3SxU5Ynl,2022,Accept (Spotlight),True,VAE Approximation Error: ELBO and Exponential Families,"['Alexander Shekhovtsov', 'Dmitrij Schlesinger', 'Boris Flach']",[],VAEs have an inductive bias towards RBMs and generalized linear models,2102.09310,cs.LG,2021-02-18 12:54:42+00:00,2021-10-08 08:32:49+00:00
OItp-Avs6Iy,2021,Reject,False,Concentric Spherical GNN for 3D Representation Learning,"[""James S Fox"", ""Bo Zhao"", ""Sivasankaran Rajamanickam"", ""Rampi Ramprasad"", ""Le Song""]","[""spherical cnn"", ""GNN"", ""graph convolution"", ""rotation equivariance"", ""3D""]",We propose a spherical GNN based on concentric spheres representation for 3D representation learning.,,,,
OJiM1R3jAtZ,2021,Reject,False,AWAC: Accelerating Online Reinforcement Learning with Offline Datasets,"[""Ashvin Nair"", ""Murtaza Dalal"", ""Abhishek Gupta"", ""Sergey Levine""]","[""reinforcement learning""]","We study RL pretraining from offline datasets and fine-tuning with online interaction, identifying issues with existing methods and proposing a new RL algorithm, AWAC, that is effective in this setting..",,,,
OJm3HZuj4r7,2022,Accept (Poster),False,Convergent and Efficient Deep Q Learning Algorithm,"['Zhikang T. Wang', 'Masahito Ueda']","[""DQN"", ""reinforcement learning"", ""convergence""]",,,,,
OKhFyMVz6t7,2022,Reject,False,Deconfounding to Explanation Evaluation in Graph Neural Networks,"['Yingxin Wu', 'Xiang Wang', 'An Zhang', 'Xia Hu', 'Fuli Feng', 'Xiangnan He', 'Tat-Seng Chua']","[""Graph Neural Networks"", ""Explanation Evaluation"", ""Out-of-distribution"", ""front-door Adjustment""]","To evaluate explanations of graph neural networks faithfully, we devise a deconfounding subgraph evaluation framework.",,,,
OLOr1K5zbDu,2021,Reject,False,"Triple-Search: Differentiable Joint-Search of Networks, Precision, and Accelerators","[""Yonggan Fu"", ""Yongan Zhang"", ""Haoran You"", ""Yingyan Lin""]","[""neural architecture search"", ""network hardware co-design""]","We propose the Triple-Search framework to jointly search network structure, precision and hardware architecture in a differentiable manner.",,,,
OLrVttqVt2,2021,Reject,False,Model-Targeted Poisoning Attacks with Provable Convergence,"[""Fnu Suya"", ""Saeed Mahloujifar"", ""David Evans"", ""Yuan Tian""]","[""adversarial machine learning"", ""data poisoning attack"", ""convergence""]",We propose a model-targeted poisoning attack with a provable convergence to any achievable target model. ,,,,
OMNB1G5xzd4,2021,Accept (Poster),True,Model-Based Offline Planning,"[""Arthur Argenson"", ""Gabriel Dulac-Arnold""]","[""off-line reinforcement learning"", ""model-based reinforcement learning"", ""model-based control"", ""reinforcement learning"", ""model predictive control"", ""robotics""]","This approach adapts model-based reinforcement learning to offline regimes with little data, and shows state of the art control in offline scenarios.",2008.05556,cs.LG,2020-08-12 20:06:52+00:00,2021-03-17 17:22:51+00:00
OM_lYiHXiCL,2022,Accept (Poster),True,AEVA: Black-box Backdoor Detection Using Adversarial Extreme Value Analysis,"['Junfeng Guo', 'Ang Li', 'Cong Liu']",[],,2110.14880,cs.LG,2021-10-28 04:36:48+00:00,2021-11-21 04:38:17+00:00
OMizHuea_HB,2021,Accept (Poster),False,Active Contrastive Learning of Audio-Visual Video Representations,"[""Shuang Ma"", ""Zhaoyang Zeng"", ""Daniel McDuff"", ""Yale Song""]","[""self-supervised learning"", ""contrastive representation learning"", ""active learning"", ""audio-visual representation"", ""video recognition""]",We propose an active learning approach to improve negative sampling for contrastive learning and demonstrate it on learning audio-visual representations from videos.,,,,
OMxLn4t03FG,2022,Reject,False,Training Multi-Layer Over-Parametrized Neural Network in Subquadratic Time,"['Zhao Song', 'Lichen Zhang', 'Ruizhe Zhang']","[""Deep learning"", ""optimization"", ""over-parametrization""]",Training multi-layer overparametrized network using second-order method in subquadratic time per iteration,2112.07628,cs.LG,2021-12-14 18:13:36+00:00,2021-12-14 18:13:36+00:00
ONBPHFZ7zG4,2021,Accept (Poster),False,Temporally-Extended Îµ-Greedy Exploration,"[""Will Dabney"", ""Georg Ostrovski"", ""Andre Barreto""]","[""reinforcement learning"", ""exploration""]","We discuss a new framework for option-based exploration, present a thorough empirical study of a simple, generally applicable set of options within this framework, and observe improved performance over state-of-the-art agents and exploration methods.",,,,
ONTz_GFWkFR,2022,Reject,False,A Sampling-Free Approximation of Gaussian Variational Auto-Encoders,"['Felix Petersen', 'Christian Borgelt', 'Hilde Kuehne', 'Oliver Deussen']",[],,,,,
OOsR8BzCnl5,2021,Accept (Poster),False,Trusted Multi-View Classification,"[""Zongbo Han"", ""Changqing Zhang"", ""Huazhu Fu"", ""Joey Tianyi Zhou""]","[""Multi-Modal Learning"", ""Multi-View Learning"", ""Uncertainty Machine Learning""]",,,,,
OPyWRrcjVQw,2021,Accept (Poster),True,Shapley explainability on the data manifold,"[""Christopher Frye"", ""Damien de Mijolla"", ""Tom Begley"", ""Laurence Cowton"", ""Megan Stanley"", ""Ilya Feige""]",[],"We present drawbacks of model explanations that do not respect the data manifold, and introduce two methods for on-manifold explainability.",2006.01272,cs.LG,2020-06-01 21:20:04+00:00,2021-02-22 17:09:23+00:00
OQ08SN70M1V,2021,Accept (Poster),True,Better Fine-Tuning by Reducing Representational Collapse,"[""Armen Aghajanyan"", ""Akshat Shrivastava"", ""Anchit Gupta"", ""Naman Goyal"", ""Luke Zettlemoyer"", ""Sonal Gupta""]","[""finetuning"", ""nlp"", ""representational learning"", ""glue""]","We present a lightweight augmentation to standard fine-tuning which outperforms previous methods across the board (i.e. SOTA on 3 summarization tasks, XNLI, RoBERTa on GLUE) while being computationally cheaper than other fine-tuning approaches.",2008.03156,cs.LG,2020-08-06 02:13:16+00:00,2020-08-06 02:13:16+00:00
OQL_tkK1vqO,2022,Reject,False,ZARTS: On Zero-order Optimization for Neural Architecture Search,"['Xiaoxing Wang', 'Wenxuan Guo', 'Junchi Yan', 'Xiaokang Yang', 'Jianlin Su']",[],,,,,
OSynkDOWbk2,2021,Reject,False,First-Order Optimization Algorithms via Discretization of Finite-Time Convergent Flows,"[""Mouhacine Benosman"", ""Orlando Romero"", ""Anoop Cherian""]","[""Finite-time optimization"", ""dynamical systems"", ""deep neural networks optimization""]",Discretization of dynamical systems-based optimization algorithms with application to deep neural networks optimization.,,,,
OT3mLgR8Wg8,2022,Accept (Poster),False,IFR-Explore: Learning Inter-object Functional Relationships in 3D Indoor Scenes,"['QI LI', 'Kaichun Mo', 'Yanchao Yang', 'Hang Zhao', 'Leonidas Guibas']","[""Inter-object Functional Relationship"", ""Learning Interactive Policy for Exploration"", ""Interactive Perception"", ""3D Scene Understanding""]",We formulate a novel problem of learning inter-object functional relationships in 3D indoor environments and propose a novel method that combines prior knowledge modeling and interactive policy learning to solve the task.,2112.05298,cs.CV,2021-12-10 02:10:54+00:00,2021-12-18 03:12:46+00:00
OUz_9TiTv9j,2022,Accept (Poster),False,A Zest of LIME: Towards Architecture-Independent Model Distances,"['Hengrui Jia', 'Hongyu Chen', 'Jonas Guan', 'Ali Shahin Shamsabadi', 'Nicolas Papernot']","[""model distance"", ""model stealing"", ""machine unlearning"", ""fairwashing""]","We propose an architecture-independent distance metric that measures the similarity between ML models by comparing their global behaviors, approximated using LIME.",,,,
OWZVD-l-ZrC,2022,Accept (Poster),False,Reward Uncertainty for Exploration in Preference-based Reinforcement Learning,"['Xinran Liang', 'Katherine Shu', 'Kimin Lee', 'Pieter Abbeel']",[],,,,,
OXRZeMmOI7a,2022,Accept (Poster),False,Topological Experience Replay,"['Zhang-Wei Hong', 'Tao Chen', 'Yen-Chen Lin', 'Joni Pajarinen', 'Pulkit Agrawal']","[""Deep reinforcement learning"", ""experience replay""]",We rearrange the update order of experience for training the Q-function by a dependency graph.,,,,
OY1A8ejQgEX,2022,Accept (Poster),False,Mention Memory: incorporating textual knowledge into Transformers through entity mention attention,"['Michiel de Jong', 'Yury Zemlyanskiy', 'Nicholas FitzGerald', 'Fei Sha', 'William W. Cohen']","[""NLP"", ""Entities and Relations"", ""Memory""]",Incorporate information from text corpus into Transformer model through within-model attention over table of entity mention representations.,,,,
OZ_2rF2D4Nw,2022,Reject,False,Kokoyi: Executable LaTeX for End-to-end Deep Learning,"['Minjie Wang', 'Haoming Lu', 'Yu Gai', 'Lesheng Jin', 'Zihao Ye', 'Zheng Zhang']",[],,,,,
OZgVHzdKicb,2021,Reject,False,Reinforcement Learning with Bayesian Classifiers: Efficient Skill Learning from Outcome Examples,"[""Kevin Li"", ""Abhishek Gupta"", ""Vitchyr H. Pong"", ""Ashwin Reddy"", ""Aurick Zhou"", ""Justin Yu"", ""Sergey Levine""]","[""Reinforcement Learning"", ""Goal Reaching"", ""Bayesian Classification"", ""Reward Inference""]",Bayesian classifiers allow efficient reinforcement learning and reward inference from outcome examples,,,,
O_OJoU4_yj,2022,Reject,False,Stabilized Self-training with Negative Sampling on Few-labeled Graph Data,"['Ziang Zhou', 'Jieming Shi', 'Shengzhong Zhang', 'Zengfeng Huang', 'Qing Li']",[],,,,,
Oc-Aedbjq0,2021,Reject,False,Model Compression via Hyper-Structure Network,"[""Shangqian Gao"", ""Feihu Huang"", ""Heng Huang""]",[],,,,,
OcKMT-36vUs,2022,Accept (Poster),False,A Loss Curvature Perspective on Training Instabilities of Deep Learning Models,"['Justin Gilmer', 'Behrooz Ghorbani', 'Ankush Garg', 'Sneha Kudugunta', 'Behnam Neyshabur', 'David Cardoze', 'George Edward Dahl', 'Zachary Nado', 'Orhan Firat']","[""Optimization"", ""Deep Learning"", ""Training Instability"", ""Curvature"", ""Loss Landscape"", ""Hessian""]",Our results suggest a unifying perspective on how disparate mitigation strategies for training instability ultimately address poor conditioning.,,,,
OcTUl1kc_00,2021,Reject,False,Are Graph Convolutional Networks Fully Exploiting the Graph Structure?,"[""Davide Buffelli"", ""Fabio Vandin""]","[""Graph Representation Learning"", ""Graph Neural Networks"", ""Random Walks""]",,,,,
OcvjQ3yqgTG,2022,Reject,False,ImpressLearn: Continual Learning via Combined Task Impressions,"['Dhrupad Bhardwaj', 'Julia Kempe', 'Artem M Vysogorets', 'Angela Teng', 'Evaristus Ezekwem']","[""Catastrophic forgetting"", ""Continual learning"", ""Neural networks"", ""Masking""]",A novel deep learning approach for continual learning that counters catastrophic forgetting using several orders of magnitude fewer parameters than prevailing methods.,,,,
Oe2XI-Aft-k,2021,Reject,False,Perturbation Type Categorization for Multiple $\ell_p$ Bounded Adversarial Robustness,"[""Pratyush Maini"", ""Xinyun Chen"", ""Bo Li"", ""Dawn Song""]","[""adversarial examples"", ""robustness"", ""multiple perturbation types""]",We introduce a method that performs Perturbation Type Categorization for Robustness against multiple perturbation types,,,,
Oecm1tBcguW,2021,Reject,False,Meta-Learning Bayesian Neural Network Priors Based on PAC-Bayesian Theory,"[""Jonas Rothfuss"", ""Martin Josifoski"", ""Andreas Krause""]","[""meta-learning"", ""life-long learning"", ""transfer"", ""bayesian neural networks"", ""prior"", ""few-shot learning"", ""pac-bayes"", ""generalization bound""]",A principled and scalable meta-learning algorithm for Bayesian neural network priors based on PAC-Bayesian learning thory.,,,,
Og7kVwRVStV,2021,Reject,False,SGD on Neural Networks learns Robust Features before Non-Robust,"[""Vikram Nitin""]","[""neural networks"", ""gradient descent"", ""sgd"", ""adversarial"", ""robustness"", ""features""]","From the perspective of adversarially robust and non-robust features, neural network training follows two very distinct pathways.",,,,
OgCcfc1m0TO,2022,Reject,False,Learning to Prompt for Vision-Language Models,"['Kaiyang Zhou', 'Jingkang Yang', 'Chen Change Loy', 'Ziwei Liu']","[""vision-language models"", ""prompt learning"", ""computer vision"", ""transfer learning""]",A continuous prompt learning approach that facilitates the deployment of pre-trained vision-language models like CLIP in downstream datasets.,,,,
Ogga20D2HO-,2021,Accept (Poster),False,FedMix: Approximation of Mixup under Mean Augmented Federated Learning,"[""Tehrim Yoon"", ""Sumin Shin"", ""Sung Ju Hwang"", ""Eunho Yang""]","[""federated learning"", ""mixup""]","We introduce a new federated framework, Mean Augmented Federated Learning (MAFL), and propose an efficient algorithm, Federated Mixup (FedMix), which shows good performance on difficult non-iid situations.",2107.00233,cs.LG,2021-07-01 06:14:51+00:00,2021-07-01 06:14:51+00:00
Oh1r2wApbPv,2022,Accept (Poster),False,Contextualized Scene Imagination for Generative Commonsense Reasoning,"['PeiFeng Wang', 'Jonathan Zamora', 'Junfeng Liu', 'Filip Ilievski', 'Muhao Chen', 'Xiang Ren']","[""Commonsense reasoning"", ""constrained text generation"", ""knowledge representation""]",This work aims at tackling generative commonsense reasoning by allowing machines to imagine a reasonable scene before generating text.,2112.06318,cs.CL,2021-12-12 20:38:08+00:00,2021-12-16 19:59:50+00:00
OhytAdNSzO-,2022,Reject,False,An Investigation on Hardware-Aware Vision Transformer Scaling,"['Chaojian Li', 'Kyungmin Kim', 'Bichen Wu', 'Peizhao Zhang', 'Hang Zhang', 'Xiaoliang Dai', 'Peter Vajda', 'Yingyan Lin']","[""Model Scaling"", ""Vision Transformer""]","An investigation on scaling Vision Transformer to answer (1) ""can these scaling strategies be transferred across different real hardware devices?""; (2) ""can these scaling strategies be transferred to different ViT variants and tasks?"".",,,,
Oi-Kh379U0,2021,Reject,False,Generalizing and Tensorizing Subgraph Search in the Supernet,"[""Hansi Yang"", ""quanming yao""]","[""deep learning"", ""neural architecture search"", ""tensor decomposition""]",We broaden the horizon of existing supernet-based NAS methods. We generalize supernet to other deep learning tasks that have graph-like structures and propose to solve them in a unified framework of supernet based on tensor network.,,,,
Oj2hGyJwhwX,2021,Reject,False,SelfNorm and CrossNorm for Out-of-Distribution Robustness,"[""Zhiqiang Tang"", ""Yunhe Gao"", ""Yi Zhu"", ""Zhi Zhang"", ""Mu Li"", ""Dimitris N. Metaxas""]",[],,,,,
OjPmfr9GkVv,2022,Accept (Poster),False,Enhancing Cross-lingual Transfer by Manifold Mixup,"['Huiyun Yang', 'Huadong Chen', 'Hao Zhou', 'Lei Li']","[""cross-lingual transfer"", ""cross-lingual understanding"", ""manifold mixup""]",We propose the cross-lingual manifold mixup method to improve the cross-lingual transfer.,,,,
OjUsDdCpR5,2021,Reject,False,Inferring Principal Components in the Simplex with Multinomial Variational Autoencoders,"[""James Morton"", ""Justin Silverman"", ""Gleb Tikhonov"", ""Harri L\u00e4hdesm\u00e4ki"", ""Rich Bonneau""]","[""Multinomial variational autoencoders"", ""variational autoencoders"", ""ILR transform"", ""compositional PCA"", ""probabilistic PCA"", ""multinomial logistic normal""]",Multinomial variational autoencoders augmented with the ILR transform can recover principal components in the simplex,,,,
OkB0tlodmH,2022,Reject,False,Q-learning for real time control of heterogeneous microagent collectives,"['Ana Rubio Denniss', 'Laia Freixas Mateu', 'Thomas Gorochowski', 'Sabine Hauert']","[""q-learning"", ""reinforcement learning"", ""microsystems"", ""closed-loop control"", ""optical control""]",Q-learning is used to learn optimal strategies for optically controlling a collection of microscopic biological agents ,,,,
OmtmcPkkhT,2021,Accept (Poster),False,Multiplicative Filter Networks,"[""Rizal Fathony"", ""Anit Kumar Sahu"", ""Devin Willmott"", ""J Zico Kolter""]","[""Deep Architectures"", ""Implicit Neural Representations"", ""Fourier Features""]",,,,,
OnpFa95RVqs,2022,Accept (Poster),False,Surrogate NAS Benchmarks: Going Beyond the Limited Search Spaces of Tabular NAS Benchmarks,"['Arber Zela', 'Julien Niklas Siems', 'Lucas Zimmer', 'Jovita Lukasik', 'Margret Keuper', 'Frank Hutter']","[""neural architecture search"", ""AutoML"", ""benchmarking"", ""surrogate model""]",We present surrogate benchmarks for neural architecture search and a general methodology for constructing them.,,,,
OodqmQT3fir,2021,Reject,False,XLVIN: eXecuted Latent Value Iteration Nets,"[""Andreea Deac"", ""Petar Veli\u010dkovi\u0107"", ""Ognjen Milinkovic"", ""Pierre-Luc Bacon"", ""Jian Tang"", ""Mladen Nikolic""]","[""value iteration"", ""graph neural networks"", ""reinforcement learning""]","We combine contrastive self-supervised learning, graph representation learning and neural algorithm execution to perform value iteration in the latent space, generalising VINs to arbitrary domains.",,,,
Oos98K9Lv-k,2021,Accept (Spotlight),True,Neural Topic Model via Optimal Transport,"[""He Zhao"", ""Dinh Phung"", ""Viet Huynh"", ""Trung Le"", ""Wray Buntine""]","[""topic modelling"", ""optimal transport"", ""document analysis""]","This paper presents a neural topic model via optimal transport, which can discover more coherent and diverse topics and derive better document representations for both regular and short texts.",2008.13537,cs.IR,2020-08-12 06:37:09+00:00,2020-10-16 01:49:09+00:00
Opmqtk_GvYL,2022,Accept (Poster),False,MetaMorph: Learning Universal Controllers with Transformers,"['Agrim Gupta', 'Linxi Fan', 'Surya Ganguli', 'Li Fei-Fei']","[""RL"", ""Modular Robots"", ""Transformers""]","We learn a transformer based general purpose controller for a modular robot design space which can zero-shot generalize to unseen variations in dynamics, kinematics, new morphologies and tasks.",,,,
Oq79NOiZB1H,2021,Reject,False,On the Importance of Sampling in Training GCNs: Convergence Analysis and Variance Reduction,"[""Weilin Cong"", ""Morteza Ramezani"", ""Mehrdad Mahdavi""]","[""Graph neural network"", ""large-scale machine learning"", ""convergence analysis""]",Provide theoretical analysis on sampling-based GCN training and new algorithms to speed up training process.,2103.02696,cs.LG,2021-03-03 21:31:23+00:00,2021-11-01 17:26:18+00:00
OqHtVOo-zy,2022,Reject,False,Estimating Instance-dependent Label-noise Transition Matrix using DNNs,"['Shuo Yang', 'Erkun Yang', 'Bo Han', 'Yang Liu', 'Min Xu', 'Gang Niu', 'Tongliang Liu']",[],,,,,
OqcZu8JIIzS,2022,Accept (Poster),False,Pareto Policy Pool for Model-based Offline Reinforcement Learning,"['Yijun Yang', 'Jing Jiang', 'Tianyi Zhou', 'Jie Ma', 'Yuhui Shi']","[""model-based offline RL"", ""Pareto front"", ""multi-objective optimization"", ""policy pool"", ""model return-uncertainty trade-off""]",We propose a model-based offline RL method that builds a diverse set of optimal policies on Pareto front providing different levels of model return-uncertainty trade-off and it significantly outperforms single-policy methods.,,,,
OqlohL9sVO,2022,Reject,False,Deep Fusion of Multi-attentive Local and Global Features with Higher Efficiency for Image Retrieval,['Baorong Shi'],"[""Image retrieval"", ""Homography learning"", ""Attention"", ""Intermediate supervision""]",,,,,
OqtLIabPTit,2021,Accept (Poster),False,Exploring Balanced Feature Spaces for Representation Learning,"[""Bingyi Kang"", ""Yu Li"", ""Sa Xie"", ""Zehuan Yuan"", ""Jiashi Feng""]","[""Representation Learning"", ""Contrastive Learning"", ""Long-Tailed Recognition""]",,,,,
OtAnbr1OQAW,2021,Reject,True,Diverse Exploration via InfoMax Options,"[""Yuji Kanagawa"", ""Tomoyuki Kaneko""]","[""Reinforcement Learning"", ""Hierachical Reinforcement Learning"", ""Exploration""]","For exploration in RL, we propose a method for learning diverse options end-to-end.",2010.02756,cs.LG,2020-10-06 14:21:05+00:00,2020-10-06 14:21:05+00:00
OtEDS2NWhqa,2022,Accept (Poster),False,Using Graph Representation Learning with Schema Encoders to Measure the Severity of Depressive Symptoms,"['Simin Hong', 'Anthony Cohn', 'David Crossland Hogg']","[""Graph neural networks sentiment analysis node-embedding algorithm  diagnostic prediction task""]","We encode word embeddings by using graph representation learning method, which schematizes context-level depressive features for depression state prediction.",,,,
OthEq8I5v1,2021,Accept (Spotlight),False,Mutual Information State Intrinsic Control,"[""Rui Zhao"", ""Yang Gao"", ""Pieter Abbeel"", ""Volker Tresp"", ""Wei Xu""]","[""Intrinsically Motivated Reinforcement Learning"", ""Intrinsic Reward"", ""Intrinsic Motivation"", ""Deep Reinforcement Learning"", ""Reinforcement Learning""]","Motivated by the self-consciousness concept in psychology, we propose a new intrinsic objective that encourages the agent to have maximum control on the environment.",2103.08107,cs.LG,2021-03-15 03:03:36+00:00,2021-03-15 03:03:36+00:00
Ov_sMNau-PF,2021,Accept (Poster),False,Semantic Re-tuning with Contrastive Tension,"[""Fredrik Carlsson"", ""Amaru Cuba Gyllensten"", ""Evangelia Gogoulou"", ""Erik Ylip\u00e4\u00e4 Hellqvist"", ""Magnus Sahlgren""]","[""Semantic Textual Similarity"", ""Transformers"", ""Language Modelling"", ""Sentence Embeddings"", ""Sentence Representations"", ""Pre-training"", ""Fine-tuning""]","A self-supervised method for learning STS related sentence embedding using pre-trained language models, setting a new SOTA for STS related embedding tasks.",,,,
Ovp8dvB8IBH,2021,Accept (Poster),False,Negative Data Augmentation ,"[""Abhishek Sinha"", ""Kumar Ayush"", ""Jiaming Song"", ""Burak Uzkent"", ""Hongxia Jin"", ""Stefano Ermon""]","[""generative models"", ""self-supervised learning"", ""data augmentation"", ""anomaly detection""]",We propose a framework to do Negative Data Augmentation for generative models and self-supervised learning,2102.05113,cs.CV,2021-02-09 20:28:35+00:00,2021-02-09 20:28:35+00:00
Ow1C7s3UcY,2022,Accept (Poster),False,Vitruvion: A Generative Model of Parametric CAD Sketches,"['Ari Seff', 'Wenda Zhou', 'Nick Richardson', 'Ryan P Adams']","[""generative modeling"", ""CAD"", ""transformers"", ""design"", ""geometric constraints""]",We build a generative model for parametric CAD sketches and use it to perform autocompletion and hand drawing conversion tasks relevant to design.,,,,
Oxdln9khkxv,2022,Reject,False,Learning the Representation of Behavior Styles with Imitation Learning,"['Xiao Liu', 'Meng Wang', 'Zhaorong Wang', 'Yingfeng Chen', 'Yujing Hu', 'Changjie Fan', 'Chongjie Zhang']","[""Imitation Learning"", ""Behavior Style""]","In this paper, we propose a new method to learn the behavior style embeding as well as the policy from the pre-collected demonstrations.",,,,
Oxeka7Z7Hor,2022,Accept (Poster),False,Gaussian Mixture Convolution Networks,"['Adam Celarek', 'Pedro Hermosilla', 'Bernhard Kerbl', 'Timo Ropinski', 'Michael Wimmer']","[""deep learning architecture"", ""gaussian convolution"", ""gaussian mixture"", ""3d""]",Deep learning based on the analytical convolution of multi-dimensional Gaussian mixtures,,,,
OxgLa0VEyg-,2022,Reject,False,Loss Function Learning for Domain Generalization by Implicit Gradient,"['Boyan Gao', 'Henry Gouk', 'Yongxin Yang', 'Timothy Hospedales']","[""meta-learning"", ""loss function learning"", ""Domain Generalisation""]",AutoML discovery of a loss function that can be used as a plug-and-play replacement for cross-entropy to boosts robustness to domain-shift.,,,,
Oy9WeuZD51,2022,Accept (Poster),True,A Statistical Framework for Efficient Out of Distribution Detection in Deep Neural Networks,"['Matan Haroush', 'Tzviel Frostig', 'Ruth Heller', 'Daniel Soudry']","[""out of distribution"", ""DNNs"", ""p-value"", ""hypothesis testing"", ""inductive conformal predictor""]",,2102.12967,cs.LG,2021-02-25 16:14:47+00:00,2021-11-11 08:44:36+00:00
OyDjznG-x2e,2021,Reject,True,Graph Permutation Selection for Decoding of Error Correction Codes using Self-Attention,"[""Nir Raviv"", ""Avi Caciularu"", ""Tomer Raviv"", ""Jacob Goldberger"", ""Yair Be'ery""]","[""decoding"", ""error correcting codes"", ""belief propagation"", ""deep learning""]",,2002.02315,cs.IT,2020-02-06 15:42:08+00:00,2021-02-19 08:27:51+00:00
OzXAw20k_H,2022,Reject,False,Deep Learning of Intrinsically Motivated Options in the Arcade Learning Environment,"['Louis Bagot', 'Kevin Mets', 'Tom De Schepper', 'Peter Hellinckx', 'Steven Latre']","[""reinforcement learning"", ""intrinsic motivation"", ""auxiliary task learning"", ""options"", ""atari""]","We introduce Deep Explore Options to decouple Intrinsic and Extrinsic reward learning in Deep Reinforcement Learning, showcasing learning from multiple intrinsic rewards while achieving excellent performance in Atari.",,,,
Oz_4sa7hKhl,2021,Reject,False,Cluster & Tune: Enhance BERT Performance in Low Resource Text Classification,"[""Eyal Shnarch"", ""Ariel Gera"", ""Alon Halfon"", ""Lena Dankin"", ""Leshem Choshen"", ""Ranit Aharonov"", ""Noam Slonim""]","[""low resource"", ""BERT"", ""clustering""]","we suggest adding an unsupervised intermediate classification step, before finetunning and after pretraining BERT, and show it improves performance for data-constrained cases.",,,,
Ozk9MrX1hvA,2021,Accept (Poster),False,CoDA: Contrast-enhanced and Diversity-promoting Data Augmentation for Natural Language Understanding,"[""Yanru Qu"", ""Dinghan Shen"", ""Yelong Shen"", ""Sandra Sajeev"", ""Weizhu Chen"", ""Jiawei Han""]","[""data augmentation"", ""natural language understanding"", ""consistency training"", ""contrastive learning""]",,,,,
OzyXtIZAzFv,2022,Accept (Poster),False,Task-Induced Representation Learning,"['Jun Yamada', 'Karl Pertsch', 'Anisha Gunjal', 'Joseph J Lim']","[""representation learning"", ""reinforcement learning"", ""transfer learning"", ""visually complex observations""]","We introduce task-induced representation learning, which leverages task information in offline data from prior tasks to learn representations of visually complex scenes that model only task-relevant aspects and enable efficient learning of new tasks.",,,,
P-gDXxGYCib,2022,Reject,False,Feature Selection in the Contrastive Analysis Setting,"['Ethan Weinberger', 'Ian Connick Covert', 'Su-In Lee']","[""Feature selection"", ""contrastive analysis"", ""computational biology""]",We select features better suited for distinguishing between subclasses of a target dataset whose subclasses are determined specifically by variations that are enriched compared to some background..,,,,
P-pPW1nxf1r,2022,Accept (Poster),True,HTLM: Hyper-Text Pre-Training and Prompting of Language Models,"['Armen Aghajanyan', 'Dmytro Okhonko', 'Mike Lewis', 'Mandar Joshi', 'Hu Xu', 'Gargi Ghosh', 'Luke Zettlemoyer']","[""prompting"", ""nlp"", ""representational learning"", ""priming""]",We unlock new state-of-the-art ways of priming and automatically generating prompts by pre-training on simplified HTML.,2107.06955,cs.CL,2021-07-14 19:39:31+00:00,2021-07-14 19:39:31+00:00
P07dq7iSAGr,2022,Accept (Poster),False,Explaining Point Processes by Learning Interpretable Temporal Logic Rules,"['Shuang Li', 'Mingquan Feng', 'Lu Wang', 'Abdelmajid Essofi', 'Yufeng Cao', 'Junchi Yan', 'Le Song']","[""Temporal Point Process"", ""Temporal Logic Rules"", ""Explainable Models""]",We propose a principled method to learn a set of human-readable logic rules to explain temporal point processes. ,,,,
P0EholD6_G,2022,Reject,True,On Hard Episodes in Meta-Learning,"['Samyadeep Basu', 'Amr Sharaf', 'Nicolo Fusi', 'Soheil Feizi']","[""meta-learning"", ""few-shot learning""]",Analysis of hard episodes in meta-learning,2110.11190,cs.LG,2021-10-21 14:58:58+00:00,2021-10-21 14:58:58+00:00
P0p33rgyoE,2021,Accept (Poster),True,Variational Intrinsic Control Revisited,"[""Taehwan Kwon""]","[""Unsupervised reinforcement learning"", ""Information theory""]",Revisitation of Variational Intrinsic Control (VIC) for the optimal behavior of implicit VIC under stochastic dynamics.,2010.03281,cs.LG,2020-10-07 09:00:48+00:00,2021-03-17 14:49:17+00:00
P1QUVhOtEFP,2022,Accept (Poster),True,Topologically Regularized Data Embeddings,"['Robin Vandaele', 'Bo Kang', 'Jefrey Lijffijt', 'Tijl De Bie', 'Yvan Saeys']","[""Embedding"", ""Dimensionality Reduction"", ""Topological Data Analysis"", ""Persistent Homology"", ""Optimization"", ""Regularization""]",A method for incorporating expert prior topological knowledge into data embeddings.,2110.09193,cs.LG,2021-10-18 11:25:47+00:00,2021-12-01 14:34:18+00:00
P1zfguZHowl,2022,Reject,False,Robust Losses for Learning Value Functions,"['Andrew Patterson', 'Victor Liao', 'Martha White']","[""Reinforcement Learning""]","Develops two novel robust loss functions for reinforcement learning, the mean absolute Bellman error and the mean Huber Bellman error, and empirically investigates solutions to these losses as well as algorithms for both prediction and control.",,,,
P3Bh01hBYTH,2022,Accept (Poster),True,X-model: Improving Data Efficiency in Deep Learning with A Minimax Model,"['Ximei Wang', 'Xinyang Chen', 'Jianmin Wang', 'Mingsheng Long']","[""Data Efficiency"", ""Deep Learning"", ""Minimax Model""]",This paper proposes a novel X-Model for improving data efficiency in deep learning with a minimax model.,2110.04572,cs.LG,2021-10-09 13:56:48+00:00,2021-10-09 13:56:48+00:00
P3WG6p6Jnb,2021,Reject,False,Offline Policy Optimization with Variance Regularization,"[""Riashat Islam"", ""Samarth Sinha"", ""Homanga Bharadhwaj"", ""Samin Yeasar Arnob"", ""Zhuoran Yang"", ""Zhaoran Wang"", ""Animesh Garg"", ""Lihong Li"", ""Doina Precup""]","[""reinforcement learning"", ""offline batch RL"", ""off-policy"", ""policy optimization"", ""variance regularization""]",Variance regularization based on stationary state-action distribution corrections in offline policy optimization,,,,
P42rXLGZQ07,2021,Reject,False,Direct Evolutionary Optimization of Variational Autoencoders with Binary Latents,"[""Enrico Guiraud"", ""Jakob Drefs"", ""Jorg Lucke""]","[""variational optimization"", ""variational autoencoders"", ""denoising"", ""evolutionary algorithms""]",We investigate a novel approach to optimize Variational Autoencoders with binary latents which does not alter the discrete latent distribution.,,,,
P5RQfyAmrU,2021,Reject,False, Model-centric data manifold: the data through the eyes of the model,"[""Luca Grementieri"", ""Rita Fioresi""]","[""Deep Learning"", ""Information Geometry"", ""Data Manifold"", ""Fisher matrix""]",We discover that deep ReLU neural network classifiersÂ can see a low-dimensional Riemannian manifold structure on data.,,,,
P63SQE0fVa,2021,Reject,False,ScheduleNet: Learn to Solve MinMax mTSP Using Reinforcement Learning with Delayed Reward,"[""Junyoung Park"", ""Sanzhar Bakhtiyarov"", ""Jinkyoo Park""]",[],"The study introduces RL based approach for constructing the solution to mTSP, and demonstrates the potential that the learned policy can be effectively used to schedule multiple vehicles for solving large-scale, practical, real-world applications",,,,
P6_q1BRxY8Q,2021,Accept (Poster),False,Learning Safe Multi-agent Control with Decentralized Neural Barrier Certificates,"[""Zengyi Qin"", ""Kaiqing Zhang"", ""Yuxiao Chen"", ""Jingkai Chen"", ""Chuchu Fan""]","[""Multi-agent"", ""safe"", ""control barrier function"", ""reinforcement learning""]",We propose a safe and remarkably scalable multi-agent control approach via jointly learning the policy and decentralized control barrier certificates.,2101.05436,cs.MA,2021-01-14 03:17:17+00:00,2021-04-17 05:34:12+00:00
P7FLfMLTSEX,2022,Accept (Poster),False,The Spectral Bias of Polynomial Neural Networks,"['Moulik Choraria', 'Leello Tadesse Dadi', 'Grigorios Chrysos', 'Julien Mairal', 'Volkan Cevher']","[""Deep Neural Networks"", ""Polynomials"", ""Spectral Bias"", ""Neural Tangent Kernel"", ""Deep Image Prior"", ""Infinite Width"", ""Mercer Decomposition""]",We study the spectral bias of polynomial networks and compare it with the spectral bias of standard neural nets using kernel approximations,,,,
P7OVkHEoHOZ,2022,Accept (Poster),True,Hindsight Foresight Relabeling for Meta-Reinforcement Learning,"['Michael Wan', 'Jian Peng', 'Tanmay Gangwani']","[""Reinforcement Learning"", ""Meta-Learning""]","We present HFR, a relabeling method that can be applied to meta-reinforcement learning to boost sample efficiency and performance.",2109.09031,cs.LG,2021-09-18 23:49:14+00:00,2021-09-18 23:49:14+00:00
P84ryxVG6tR,2021,Reject,False,REPAINT: Knowledge Transfer in Deep Actor-Critic Reinforcement Learning,"[""Yunzhe Tao"", ""Sahika Genc"", ""TAO SUN"", ""Sunil Mallya""]","[""reinforcement learning"", ""transfer learning"", ""actor-critic RL"", ""representation transfer"", ""instance transfer"", ""task similarity"", ""MuJoCo"", ""DeepRacer""]","This paper proposes a representation-instance knowledge transfer algorithm for actor-critic reinforcement learning, which significantly reduces the training cost compared to training with no prior knowledge.",,,,
PAsd7_vP4_,2021,Reject,False,Adaptive Discretization for Continuous Control using Particle Filtering Policy Network,"[""Pei Xu"", ""Ioannis Karamouzas""]","[""Reinforcement Learning"", ""Continuous Control"", ""Action Space Discretization"", ""Policy Gradient""]",,,,,
PBfaUXYZzU,2021,Reject,True,Class-Weighted Evaluation Metrics for Imbalanced Data Classification,"[""Akhilesh Gupta"", ""Nesime Tatbul"", ""Ryan Marcus"", ""Shengtian Zhou"", ""Insup Lee"", ""Justin Gottschlich""]","[""Imbalanced data classification"", ""Evaluation metrics"", ""Log parsing"", ""Sentiment analysis""]",We present an evaluation framework for imbalanced data classification that is sensitive to arbitrary skews in class cardinalities and importances.,2010.05995,cs.LG,2020-10-12 19:47:09+00:00,2020-10-12 19:47:09+00:00
PC8u74o7xc2,2022,Reject,False,Embedding models through the lens of Stable Coloring,"['Aditya Desai', 'Shashank Sonkar', 'Anshumali Shrivastava', 'Richard Baraniuk']",[],We propose unified theoretical framework underlying the state-of-the art embedding models,,,,
PDYs7Z2XFGv,2022,Accept (Poster),False,Omni-Scale CNNs: a simple and effective kernel size configuration for time series classification,"['Wensi Tang', 'Guodong Long', 'Lu Liu', 'Tianyi Zhou', 'Michael Blumenstein', 'Jing Jiang']","[""Time series classification""]","To extract features from time series data in proper time scales, many complicated scales searching or weighting methods have been proposed, but we will show that this could have been done via a very simple structure.",,,,
PEcNk5Bad7z,2021,Reject,True,Learning Irreducible Representations of Noncommutative Lie Groups,"[""Noah Shutty"", ""Casimir Wierzynski""]","[""equivariance"", ""object tracking"", ""equivariant neural networks"", ""deep learning"", ""point cloud"", ""lie group"", ""lie algebra"", ""lorentz group"", ""poincar\u00e9 group""]",We automate an essential task in equivariant deep learning and apply Lorentz-equivariance to object tracking.,2006.00724,cs.LG,2020-06-01 05:14:29+00:00,2020-10-04 00:58:16+00:00
PGGjnBiQ84G,2022,Reject,False,Learning Surface Parameterization for Document Image Unwarping,"['Sagnik Das', 'Ke Ma', 'Zhixin Shu', 'Dimitris Samaras']","[""implicit functions"", ""texture mapping"", ""surface parameterization""]",Learning surface parameterization using rendering loss and multiview images,,,,
PGmqOzKEPZN,2021,Reject,True,Non-Negative Bregman Divergence Minimization for Deep Direct Density Ratio Estimation,"[""Masahiro Kato"", ""Takeshi Teshima""]","[""density ratio estimation"", ""bregman divergence""]",Proposing the non-negative Bregman divergence minimization for density ratio estimation,2006.06979,cs.LG,2020-06-12 07:39:03+00:00,2021-07-17 09:25:37+00:00
PH5PH9ZO_4,2021,Accept (Poster),False,Generating Adversarial Computer Programs using Optimized Obfuscations,"[""Shashank Srikant"", ""Sijia Liu"", ""Tamara Mitrovska"", ""Shiyu Chang"", ""Quanfu Fan"", ""Gaoyuan Zhang"", ""Una-May O'Reilly""]","[""Machine Learning (ML) for Programming Languages (PL)/Software Engineering (SE)"", ""Adversarial computer programs"", ""Program obfuscation"", ""Combinatorial optimization"", ""Differentiable program generator"", ""Models for code""]",A differentiable generator of adversarial computer programs which can deceive ML models trained on computer programs.,2103.11882,cs.LG,2021-03-18 10:47:15+00:00,2021-03-18 10:47:15+00:00
PHugX0j2xcE,2022,Reject,False,Predictive Maintenance for Optical Networks in Robust Collaborative Learning  ,"['Khouloud Abdelli', 'JOO YEON CHO']","[""predictive maintenance"", ""federated learning"", ""machine learning"", ""anomaly detection"", ""multi-party computation"", ""autoencoder""]",We propose a robust collaborative learning framework for predictive maintenance on cross-vendor in a dishonest setting and confirm the performance by experiments.,,,,
PI_CwQparl_,2021,Reject,False,Image Modeling with Deep Convolutional Gaussian Mixture Models,"[""Alexander Gepperth"", ""Benedikt Pf\u00fclb""]","[""Gaussian Mixture Model"", ""Deep Learning"", ""Unsupervised Representation Learning"", ""Sampling""]","We present a deep Gaussian Mixture Model, leveraging typical CNN concepts like convolutions and pooling for describing images at a manageable computational cost.",2104.12686,cs.CV,2021-04-19 12:08:53+00:00,2021-04-19 12:08:53+00:00
PKubaeJkw3,2021,Accept (Oral),False,Rethinking Architecture Selection in Differentiable NAS,"[""Ruochen Wang"", ""Minhao Cheng"", ""Xiangning Chen"", ""Xiaocheng Tang"", ""Cho-Jui Hsieh""]",[],,2108.04392,cs.LG,2021-08-10 00:53:39+00:00,2021-08-10 00:53:39+00:00
PLDOnFoVm4,2022,Accept (Spotlight),False,Reinforcement Learning under a Multi-agent Predictive State Representation Model: Method and Theory,"['Zhi Zhang', 'Zhuoran Yang', 'Han Liu', 'Pratap Tokekar', 'Furong Huang']","[""Multi-agent Reinforcement Learning"", ""Predictive State Representation"", ""Dynamic Interaction Graph""]","We propose a new algorithm for MARL under a multi-agent predictive state representation model, where we incorporate a dynamic interaction graph; we provide the theoretical guarantees of our model and run various experiments to support our algorithm.",,,,
PO0SuuafSX,2021,Reject,False,3D Scene Compression through Entropy  Penalized Neural Representation Functions,"[""Thomas Bird"", ""Johannes Ball\u00e9"", ""Saurabh Singh"", ""Philip Chou""]","[""scene representation"", ""compression"", ""neural rendering"", ""entropy coding""]",Compressing neural representation functions by penalizing the entropy of the reparameterized weights results in a small and useful renderer,,,,
POTMtpYI1xH,2022,Accept (Poster),False,Discovering Latent Concepts Learned in BERT,"['Fahim Dalvi', 'Abdul Rafae Khan', 'Firoj Alam', 'Nadir Durrani', 'Jia Xu', 'Hassan Sajjad']","[""interpretation"", ""BERT"", ""NLP""]",We approach interpretability from a modelâs perspective by discovering and analyzing latent concepts learned in pre-trained models in an unsupervised fashion. ,,,,
POWv6hDd9XH,2021,Accept (Poster),False,BRECQ: Pushing the Limit of Post-Training Quantization by Block Reconstruction,"[""Yuhang Li"", ""Ruihao Gong"", ""Xu Tan"", ""Yang Yang"", ""Peng Hu"", ""Qi Zhang"", ""Fengwei Yu"", ""Wei Wang"", ""Shi Gu""]","[""Post Training Quantization"", ""Mixed Precision"", ""Second-order analysis""]",,2102.05426,cs.LG,2021-02-10 13:46:16+00:00,2021-07-25 09:34:39+00:00
PObuuGVrGaZ,2021,Accept (Poster),False,Is Label Smoothing Truly Incompatible with Knowledge Distillation: An Empirical Study,"[""Zhiqiang Shen"", ""Zechun Liu"", ""Dejia Xu"", ""Zitian Chen"", ""Kwang-Ting Cheng"", ""Marios Savvides""]","[""label smoothing"", ""knowledge distillation"", ""image classification"", ""neural machine translation"", ""binary neural networks""]",This work empirically clarifies a recently discovered perspective that label smoothing is incompatible with knowledge distillation. Project page: http://zhiqiangshen.com/projects/LS_and_KD/index.html.,2104.00676,cs.LG,2021-04-01 17:59:12+00:00,2021-04-01 17:59:12+00:00
POvMvLi91f,2022,Accept (Spotlight),False,DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization,"['Aviral Kumar', 'Rishabh Agarwal', 'Tengyu Ma', 'Aaron Courville', 'George Tucker', 'Sergey Levine']","[""Q-learning"", ""offline RL"", ""regularization""]",We show that implicit regularization effects can lead to poor performance in value-based offline RL and propose an explicit regularizer to mitigate these effects.,2112.04716,cs.LG,2021-12-09 06:01:01+00:00,2021-12-09 06:01:01+00:00
POxF-LEqnF,2022,Accept (Poster),False,You Mostly Walk Alone: Analyzing Feature Attribution in Trajectory Prediction,"['Osama Makansi', 'Julius Von KÃ¼gelgen', 'Francesco Locatello', 'Peter Vincent Gehler', 'Dominik Janzing', 'Thomas Brox', 'Bernhard SchÃ¶lkopf']","[""Feature Attribution"", ""Shapley values"", ""Trajectory Prediction"", ""Causality""]","We propose a Shapley value-based method for attributing trajectory prediction performance to different input features and show on common benchmark datasets that existing models do not use interaction information, contrary to their claims.",,,,
PP4KyAaBoBK,2021,Reject,True,Human Perception-based Evaluation Criterion for Ultra-high Resolution Cell Membrane Segmentation,"[""Ruohua Shi"", ""Wenyao Wang"", ""Zhixuan Li"", ""Liuyuan He"", ""Kaiwen Sheng"", ""Lei Ma"", ""Kai Du"", ""Tingting Jiang"", ""Tiejun Huang""]","[""Neuroscience"", ""Connectomics"", ""Human perception"", ""EM dataset"", ""Membrane segmentation"", ""Evaluation criterion""]",We established the largest annotated ultra-high resolution EM dataset for the cell membrane with multiple iterative annotations and propose a perceptual-based evaluation criterion to measure the quality of cell membrane segmentation results.,2010.08209,cs.CV,2020-10-16 07:39:17+00:00,2020-10-16 07:39:17+00:00
PQ2Cel-1rJh,2021,Reject,False,Pea-KD: Parameter-efficient and accurate Knowledge Distillation,"[""IKHYUN CHO"", ""U Kang""]","[""BERT"", ""Deep Learning"", ""Natural Language Processing"", ""Transformer"", ""Knowledge Distillation"", ""Parameter Sharing""]",It introduces a new Knowledge Distillation method. It improves the performance of the student model with 2 main modules:  novel parameter sharing and new pretraining which uses the teacher model's predictions. ,,,,
PQQp7AJwz3,2022,Accept (Poster),False,Particle Stochastic Dual Coordinate Ascent: Exponential convergent algorithm for mean field neural network optimization,"['Kazusato Oko', 'Taiji Suzuki', 'Atsushi Nitanda', 'Denny Wu']","[""Neural Network Optimization"", ""Mean field Regime"", ""Overparameterization""]",Proposed a new algorithm for optimizing two-layer neural network in the mean field regime that achieves exponential convergence in regularized empirical risk minimization (w.r.t. outer loop iterations).,,,,
PQTW3iG4sC-,2022,Accept (Poster),False,On feature learning in shallow and multi-layer neural networks with global convergence guarantees,"['Zhengdao Chen', 'Eric Vanden-Eijnden', 'Joan Bruna']","[""neural networks"", ""feature learning"", ""gradient descent"", ""global convergence""]",Gradient flow can induce feature learning in shallow and multi-layer neural networks while admitting non-asymptotic guarantees of global convergence.,,,,
PQlC91XxqK5,2021,Reject,False,Segmenting Natural Language Sentences via Lexical Unit Analysis,"[""Yangming Li"", ""lemao liu"", ""Shuming Shi""]","[""Neural Sequence Labeling"", ""Neural Sequence Segmentation"", ""Dynamic Programming""]","We propose LUA, a novel framework for neural sequence segmentation, which facilitates globally optimal training and inference.",2012.05418,cs.CL,2020-12-10 02:31:52+00:00,2021-04-16 08:30:03+00:00
PRZoSmCinhf,2022,Accept (Spotlight),False,Constrained Policy Optimization via Bayesian World Models,"['Yarden As', 'Ilnura Usmanova', 'Sebastian Curi', 'Andreas Krause']","[""Reinforcement learning"", ""Constrained Markov decision processes"", ""Constrained policy optimization"", ""Bayesian model-based RL""]",Solving constrained Markov decision processes with Bayesian model-based reinforcement learning.,,,,
PRr_3HPakQ,2021,Reject,False,Learning to Generate Questions by Recovering Answer-containing Sentences,"[""Seohyun Back"", ""Akhil Kedia"", ""Sai Chetan Chinthakindi"", ""Haejun Lee"", ""Jaegul Choo""]","[""Question Generation"", ""Question Answering"", ""Data Augmentation"", ""Machine Reading Comprehension""]","Improve Question Generation by pre-training on generating answer-containing sentences and dynamically predicting number of answers, achieving SOTA in MS MARCO, NewsQA.",,,,
PS3IMnScugk,2021,Accept (Poster),True,Learning to Recombine and Resample Data For Compositional Generalization,"[""Ekin Aky\u00fcrek"", ""Afra Feyza Aky\u00fcrek"", ""Jacob Andreas""]","[""compositional generalization"", ""data augmentation"", ""language processing"", ""sequence models"", ""generative modeling""]","This paper investigates a data augmentation procedure based on two weaker principles: recombination and resampling, and finds that it is sufficient to induce many of the compositional generalizations studied in previous work. ",2010.03706,cs.CL,2020-10-08 00:36:33+00:00,2021-06-08 00:43:04+00:00
PTRo58zPt3P,2022,Accept (Poster),False,Inductive Relation Prediction Using Analogy Subgraph Embeddings,"['Jiarui Jin', 'Yangkun Wang', 'Kounianhua Du', 'Weinan Zhang', 'Zheng Zhang', 'David Wipf', 'Yong Yu', 'Quan Gan']","[""Link Prediction"", ""Relation Modelling"", ""Heterogeneous Graphs"", ""Knowledge Graphs""]","In this paper, we propose GraphANGEL, a novel relation prediction framework that predicts (new) relations between each node pair by checking whether the subgraphs containing the pair are similar to other subgraphs containing the considered relation.",,,,
PULSD5qI2N1,2021,Accept (Oral),True,Optimal Rates for Averaged Stochastic Gradient Descent under Neural Tangent Kernel Regime,"[""Atsushi Nitanda"", ""Taiji Suzuki""]","[""stochastic gradient descent"", ""two-layer neural network"", ""over-parameterization"", ""neural tangent kernel""]",This is the first paper to overcome technical challenges of achieving the optimal convergence rate under the NTK regime.,2006.12297,stat.ML,2020-06-22 14:31:37+00:00,2021-06-11 14:51:53+00:00
PUkhWz65dy5,2021,Accept (Spotlight),False,Discovering a set of policies for the worst case reward,"[""Tom Zahavy"", ""Andre Barreto"", ""Daniel J Mankowitz"", ""Shaobo Hou"", ""Brendan O'Donoghue"", ""Iurii Kemaev"", ""Satinder Singh""]",[],Discovering a set of diverse RL policies by optimising the robustness of the set,,,,
PVJ6j87gOHz,2022,Accept (Poster),False,CoMPS: Continual Meta Policy Search,"['Glen Berseth', 'Zhiwei Zhang', 'Grace Zhang', 'Chelsea Finn', 'Sergey Levine']","[""Reinforcement Learning""]","Cotinual meta-reinforcement learning accelerates task learning, via repeated meta off-policy search.",2112.04467,cs.LG,2021-12-08 18:53:08+00:00,2021-12-08 18:53:08+00:00
PXDdWQDBsCG,2021,Reject,False,Shape Defense,"[""ali borji""]","[""adversarial robustness"", ""adversarial defense"", ""adversarial attack"", ""shape"", ""background subtraction""]","Inspired by human vision, we propose two adversarial defense methods that utilize shape, and show that edge redetection makes models robust to adversarial attacks such as FGSM and PGD-40.",,,,
PYAFKBc8GL4,2021,Reject,True,Client Selection in Federated Learning: Convergence Analysis and Power-of-Choice Selection Strategies,"[""Yae Jee Cho"", ""Jianyu Wang"", ""Gauri Joshi""]","[""distributed optimization"", ""federated learning"", ""client selection""]",,2010.01243,cs.LG,2020-10-03 01:04:17+00:00,2020-10-03 01:04:17+00:00
P__qBPffIlK,2021,Reject,True,Adversarial representation learning for synthetic replacement of private attributes,"[""John Martinsson"", ""Edvin Listo Zec"", ""Daniel Gillblad"", ""Olof Mogren""]","[""Deep learning"", ""privacy"", ""generative adversarial networks""]","Explores if realistic synthetic replacement of sensitive attributes leads to stronger privacy, and empirically studies the privacy vs. utility trade-off for learned privacy preserving image transformations.",2006.08039,cs.LG,2020-06-14 22:07:19+00:00,2021-02-08 13:53:41+00:00
PaQhL90tLmX,2022,Reject,False,Robust Deep Neural Networks for Heterogeneous Tabular Data ,"['Vadim Borisov', 'Klaus Broelemann', 'Enkelejda Kasneci', 'Gjergji. Kasneci']","[""Deep Learning"", ""Deep Neural Networks"", ""Tabular Data"", ""Gradient Boosted Decision Trees""]",Making deep neural networks robust to tabular data quality issues by utilizing decision tree ensembles for data encoding.,,,,
PbEHqvFtcS,2021,Accept (Poster),False,Byzantine-Resilient Non-Convex Stochastic Gradient Descent,"[""Zeyuan Allen-Zhu"", ""Faeze Ebrahimianghazani"", ""Jerry Li"", ""Dan Alistarh""]","[""distributed machine learning"", ""distributed deep learning"", ""robust deep learning"", ""non-convex optimization"", ""Byzantine resilience""]","New algorithm for non-convex distributed optimization against Byzantine attacks, with strong theoretical guarantees, and improves on the performance of prior methods for training deep neural networks against Byzantine attacks.",,,,
Pbj8H_jEHYv,2021,Accept (Spotlight),False,Orthogonalizing Convolutional Layers with the Cayley Transform,"[""Asher Trockman"", ""J Zico Kolter""]","[""orthogonal layers"", ""Lipschitz constrained networks"", ""adversarial robustness""]",,,,,
PcBVjfeLODY,2021,Reject,False,Constraining Latent Space to Improve Deep Self-Supervised e-Commerce Products Embeddings for Downstream Tasks,"[""Cristian Cardellino"", ""Rafael Carrascosa""]","[""representation learning"", ""deep learning"", ""self-supervised learning""]",,,,,
PcUprce4TM2,2021,Reject,False,CAFE: Catastrophic Data Leakage in Federated Learning,"[""Xiao Jin"", ""Ruijie Du"", ""Pin-Yu Chen"", ""Tianyi Chen""]",[],,,,,
Pd_oMxH8IlF,2021,Accept (Oral),False,Iterated learning for emergent systematicity in VQA,"[""Ankit Vani"", ""Max Schwarzer"", ""Yuchen Lu"", ""Eeshan Dhekane"", ""Aaron Courville""]","[""iterated learning"", ""cultural transmission"", ""neural module network"", ""clevr"", ""shapes"", ""vqa"", ""visual question answering"", ""systematic generalization"", ""compositionality""]",We use iterated learning to encourage the emergence of structure in the generated programs for neural module networks.,2105.01119,cs.LG,2021-05-03 18:44:06+00:00,2021-05-03 18:44:06+00:00
PdauS7wZBfC,2021,Reject,False,Predictive Coding Approximates Backprop along Arbitrary Computation Graphs,"[""Beren Millidge"", ""Alexander Tschantz"", ""Christopher Buckley""]","[""Predictive Coding"", ""Backprop"", ""Biological plausibility"", ""neural networks""]",We show that predictive coding algorithms from neuroscience can be setup to approximate the backpropagation of error algorithm on any computational graph.,,,,
PeG-8G5ua3W,2022,Reject,False,Normalized Attention Without Probability Cage,"['Oliver Paul Richter', 'Roger Wattenhofer']","[""Attention"", ""Transformers"", ""Neural Architecture"", ""Aggregators""]",The softmax in attention limits the expressiveness of the Transformer architecture and using normalization instead yields increased robustness with respect to hyperparameters. ,,,,
PeT5p3ocagr,2021,Reject,False,PGPS : Coupling Policy Gradient with Population-based Search,"[""Namyong Kim"", ""Hyunsuk Baek"", ""Hayong Shin""]","[""Reinforcement Learning"", ""Population-based Search"", ""Policy Gradient"", ""Combining PG with PS""]",,,,,
Peg7mkjzvyP,2021,Reject,False,iPTR: Learning a representation for interactive program translation retrieval,"[""Binger Chen"", ""Ziawasch Abedjan""]",[],This paper presents a program translation engine that leverages a novel representation based on structural features of programming languages and pretrained autoencodes to effectively retrieve the best possible translation of a given input program.,2103.12797,cs.SE,2021-03-23 19:01:43+00:00,2021-03-23 19:01:43+00:00
Pfj3SXBCbVQ,2022,Reject,False,On the Effectiveness of Quasi Character-Level Models for Machine Translation,"['Salvador CarriÃ³n Ponz', 'Francisco Casacuberta Nolla']","[""Deep learning"", ""Neural Machine Translation"", ""Subword-level vocabulary""]",Quasi character-level Transformers seem to be advantageous in low-resource scenarios,,,,
PgNEYaIc81Q,2022,Accept (Poster),False,ComPhy: Compositional Physical Reasoning of Objects and Events from Videos,"['Zhenfang Chen', 'Kexin Yi', 'Yunzhu Li', 'Mingyu Ding', 'Antonio Torralba', 'Joshua B. Tenenbaum', 'Chuang Gan']","[""Compositional"", ""Intutive Physics"", ""Video Reasoning"", ""Neural-Symbolic""]",We introduce a new dataset for Compositional Physical Reasoning,,,,
PghuCwnjF6y,2021,Reject,False,TaskSet: A Dataset of Optimization Tasks,"[""Luke Metz"", ""Niru Maheswaranathan"", ""Ruoxi Sun"", ""C. Daniel Freeman"", ""Ben Poole"", ""Jascha Sohl-Dickstein""]","[""optimizers"", ""meta-learning""]",We construct a dataset of a thousand optimization tasks then use this to explore generalization in a simple meta-learning application.,,,,
Pgq5GE_-ph,2021,Reject,False,Video Prediction with Variational Temporal Hierarchies,"[""Vaibhav Saxena"", ""Jimmy Ba"", ""Danijar Hafner""]","[""latent dynamics"", ""temporal abstraction"", ""video prediction"", ""probabilistic modeling"", ""variational inference"", ""deep learning""]","We introduce and investigate the properties of a temporally-abstract latent dynamics model, trained using a variational objective, for long-horizon video prediction.",,,,
PhV-qfEi3Mr,2021,Reject,False,Improving the accuracy of neural networks in analog computing-in-memory systems by a generalized quantization method,"[""Lingjun Dai"", ""Qingtian Zhang"", ""Huaqiang Wu""]","[""analog computing-in-memory"", ""quantization algorithm"", ""deep neural networks""]",We improve the accuracy of neural networks in analog computing-in-memory systems by a generalized quantization method,,,,
PiDkqc9saaL,2022,Reject,False,Lower Bounds on the Robustness of Fixed Feature Extractors to Test-time Adversaries,"['Arjun Nitin Bhagoji', 'Daniel Cullina', 'Ben Zhao']","[""robustness"", ""lower bounds""]",Analytical method to determine the robustness of fixed feature extractors to adversarial examples,,,,
PiKUvDj5jyN,2021,Reject,False,Relational Learning with Variational Bayes,"[""Kuang-Hung Liu""]","[""Relational learning"", ""unsupervised learning"", ""variational inference"", ""probabilistic graphical model""]",We propose an unsupervised learning method for addressing the relational learning problem where we learn the underlying relationship between a pair of data irrespective of the nature of those data.,,,,
PilZY3omXV2,2022,Accept (Poster),False,CoST: Contrastive Learning of Disentangled Seasonal-Trend Representations for Time Series Forecasting,"['Gerald Woo', 'Chenghao Liu', 'Doyen Sahoo', 'Akshat Kumar', 'Steven Hoi']","[""Time Series"", ""Representation Learning"", ""Forecasting"", ""Self-Supervised Learning""]",,2202.01575,cs.LG,2022-02-03 13:17:38+00:00,2022-02-03 13:17:38+00:00
PkqwRo2wjuW,2021,Reject,False,Learning Axioms to Compute Verifiable Symbolic Expression Equivalence Proofs Using Graph-to-Sequence Networks,"[""Steven James Kommrusch"", ""Louis-Noel Pouchet"", ""Theo Barolett""]","[""Graph Neural Network"", ""Symbolic Proofs"", ""Graph-to-Sequence""]",Using a graph-to-sequence model to learn to prove semantic equivalence between two complex linear algebra expressions represented as typed trees.,,,,
PlFtf_pnkZu,2022,Reject,False,Examining Scaling and Transfer of Language Model Architectures for Machine Translation,"['Biao Zhang', 'Behrooz Ghorbani', 'Ankur Bapna', 'Yong Cheng', 'Xavier Garcia', 'Jonathan Shen', 'Orhan Firat']","[""language modeling"", ""machine translation"", ""prefixlm"", ""causallm"", ""model scaling"", ""zero-shot transfer""]","We thoroughly explore language modeling for machine translation in terms of model architecture, model scaling and cross-lingual transfer",2202.00528,cs.CL,2022-02-01 16:20:15+00:00,2022-02-02 10:48:56+00:00
PlKWVd2yBkY,2022,Accept (Poster),False,Pseudo Numerical Methods for Diffusion Models on Manifolds,"['Luping Liu', 'Yi Ren', 'Zhijie Lin', 'Zhou Zhao']","[""diffusion model"", ""generative model"", ""numerical method"", ""manifold""]","We propose PNDMs, a new kind of numerical method, to accelerate diffusion models on manifolds.",,,,
PmUGXmOY1wK,2021,Reject,False,GL-Disen: Global-Local disentanglement for unsupervised learning of graph-level representations,"[""Thilini Cooray"", ""Ngai-man Cheung"", ""Wei Lu""]","[""Unsupervised Graph Representations"", ""Disentanglement Learning"", ""GNN"", ""Unsupervised Learning""]",A global graph level and local patch level disentanglement mechanism for unsupervised graph representation learning,,,,
PmVfnB0nkqr,2021,Reject,False,Autonomous Learning of Object-Centric Abstractions for High-Level Planning,"[""Steven James"", ""Benjamin Rosman"", ""George Konidaris""]","[""reinforcement learning"", ""planning"", ""PDDL"", ""multitask"", ""transfer"", ""objects""]",We show how to learn an object-centric representation from pixels that can be used by a classical planner. ,,,,
PoP96DrBHnl,2021,Reject,False,Gradient descent temporal difference-difference learning,"[""Rong Zhu"", ""James Murray""]","[""temporal difference learning"", ""gradient-descent based temporal difference"", ""Off-policy"", ""regularization""]",We provide gradient descent temporal difference-difference learning in order to accelerate gradient descent temporal difference learning by introducing second-order differences in successive parameter updates.,,,,
Pobz_8y2Q2_,2022,Reject,False,BANANA: a Benchmark for the Assessment of Neural Architectures for Nucleic Acids,"['Luca Salvatore Lorello', 'Andrea Galassi', 'Paolo Torroni']","[""bioinformatics"", ""language modeling"", ""natural language processing"", ""dataset"", ""benchmark"", ""dna"", ""rna""]","We present BANANA, a benchmark consisting of six classification tasks assessing language understanding performance in the DNA and RNA domains.",,,,
PpOtGYNVT6A,2021,Reject,False,A Probabilistic Model for Discriminative and Neuro-Symbolic Semi-Supervised Learning,"[""Carl Allen"", ""Ivana Balazevic"", ""Timothy Hospedales""]","[""semi-supervised learning"", ""probabilistic model"", ""neuro-symbolic learning""]",A probabilistic model for discriminative and neuro-symbolic semi-supervised learning.,,,,
PpshD0AXfA,2021,Accept (Poster),False,Generative Time-series Modeling with Fourier Flows,"[""Ahmed Alaa"", ""Alex James Chan"", ""Mihaela van der Schaar""]",[],,,,,
PrvaKdJcKhX,2021,Reject,False,Differentiable Approximations for Multi-resource Spatial Coverage Problems,"[""Nitin Kamra"", ""Yan Liu""]","[""Multi-agent coverage"", ""Multi-resource coverage"", ""Areal coverage"", ""Differentiable approximations""]","Tractable approximations for a large class of spatial coverage objectives and their gradients using a combination of Newton-Leibniz theorem, spatial discretization and implicit boundary differentiation.",,,,
PrzjugOsDeE,2021,Accept (Poster),False,CcGAN: Continuous Conditional Generative Adversarial Networks for Image Generation,"[""Xin Ding"", ""Yongwei Wang"", ""Zuheng Xu"", ""William J Welch"", ""Z. Jane Wang""]","[""Conditional generative adversarial networks"", ""image generation"", ""continuous and scalar conditions""]","This work proposes the continuous conditional generative adversarial network (CcGAN), the first generative model for image generation conditional on continuous, scalar conditions (termed as regression labels). ",,,,
Ps_m_Uwcu-E,2022,Reject,True,Layer-wise Adaptive Model Aggregation for Scalable Federated Learning,"['Sunwoo Lee', 'Tuo Zhang', 'Chaoyang He', 'Salman Avestimehr']","[""federated learning"", ""model aggregation"", ""neural network""]",Layer-wise adaptive model aggregation scheme for communication-efficient Federated Learning.,2110.10302,cs.LG,2021-10-19 22:49:04+00:00,2022-01-03 17:58:47+00:00
PsdsEbzxZWr,2021,Reject,False,Analyzing and Improving Generative Adversarial Training for Generative Modeling and Out-of-Distribution Detection,"[""Xuwang Yin"", ""Shiying li"", ""Gustavo Rohde""]","[""Adversarial Training"", ""Generative Modeling"", ""Out-of-Distribution Detection"", ""GANs"", ""Generative adversarial networks""]",Theoretical understanding of the generative adversarial training method and extending its application to generative modeling and out-of-distribution detection,,,,
PtSAD3caaA2,2022,Accept (Poster),True,Maximum Entropy RL (Provably) Solves Some Robust RL Problems,"['Benjamin Eysenbach', 'Sergey Levine']","[""reinforcement learning"", ""robustness"", ""maximum entropy""]",Maximum Entropy RL (provably) solves some robust RL problems.,2103.06257,cs.LG,2021-03-10 18:45:48+00:00,2021-03-10 18:45:48+00:00
Ptaz_zIFbX,2021,Accept (Poster),False,Prediction and generalisation over directed actions by grid cells,"[""Changmin Yu"", ""Timothy Behrens"", ""Neil Burgess""]","[""Computational neuroscience"", ""grid cells"", ""normative models""]","Extending existing normative prediction models of grid cells to directed transitions, and provide a unifying framework for mechanistic and normative models of grid cells.",,,,
PtuQ8bk9xF5,2022,Reject,False,Learning to Act with Affordance-Aware Multimodal Neural SLAM,"['Zhiwei Jia', 'Kaixiang Lin', 'Yizhou Zhao', 'Qiaozi Gao', 'Govind Thattai', 'Gaurav S. Sukhatme']","[""Language-Guided Task Completion"", ""Multimodal learning"", ""Neural SLAM.""]",,,,,
PuG6vCSbrV9,2021,Reject,False,Density estimation on low-dimensional manifolds: an inflation-deflation approach,"[""Christian Horvat""]","[""Normalizing Flow"", ""Density Estimation"", ""low-dimensional manifolds"", ""noise"", ""normal space""]",,,,,
PvVbsAmxdlZ,2021,Reject,False,Causal Inference Q-Network: Toward Resilient Reinforcement Learning,"[""Chao-Han Huck Yang"", ""Danny I-Te Hung"", ""Yi Ouyang"", ""Pin-Yu Chen""]","[""Deep Reinforcement Learning"", ""Causal Inference"", ""Robust Reinforcement Learning"", ""Adversarial Robustness""]",We propose a causal inference based DRL algorithm called causal inference Q-network (CIQ) under interferences toward resilient learning. ,,,,
Px7xIKHjmMS,2021,Reject,False,Beyond GNNs: A Sample Efficient Architecture for Graph Problems,"[""Pranjal Awasthi"", ""Abhimanyu Das"", ""Sreenivas Gollapudi""]","[""Graph Neural Networks"", ""Deep Learning Theory"", ""Graph Connectivity"", ""Minimum Spanning Trees""]","We propose a new provably sample efficient GNN architecture for learning many fundamental graph problems, with sample complexity that scales poly-logarithmically in the graph size. ",,,,
PxTIG12RRHS,2021,Accept (Oral),False,Score-Based Generative Modeling through Stochastic Differential Equations,"[""Yang Song"", ""Jascha Sohl-Dickstein"", ""Diederik P Kingma"", ""Abhishek Kumar"", ""Stefano Ermon"", ""Ben Poole""]","[""generative models"", ""score-based generative models"", ""stochastic differential equations"", ""score matching"", ""diffusion""]","A general framework for training and sampling from score-based models that unifies and generalizes previous methods, allows likelihood computation, and enables controllable generation.",,,,
Py4VjN6V2JX,2021,Reject,False,Contrastive Self-Supervised Learning of Global-Local Audio-Visual Representations,"[""Shuang Ma"", ""Zhaoyang Zeng"", ""Daniel McDuff"", ""Yale Song""]","[""Contrastive learning"", ""self-supervised learning"", ""video representation learning"", ""audio-visual representation learning"", ""multimodal representation learning""]",We propose a contrastive self-supervised approach to learn global and local video representations and show that it generalizes well to both classification and localization tasks.,,,,
Py8WbvKH_wv,2022,Reject,True,DRIBO: Robust Deep Reinforcement Learning via Multi-View Information Bottleneck,"['Jiameng Fan', 'Wenchao Li']","[""Representation Learning"", ""Deep Reinforcement Learning"", ""Information Bottleneck""]",We propose a robust representation learning approach for RL to extract only task-relevant from raw pixels using the multi-view information bottleneck principle.,2102.13268,cs.AI,2021-02-26 02:24:36+00:00,2021-06-08 15:14:44+00:00
PyBp6nFfzuj,2022,Reject,False,UNCERTAINTY QUANTIFICATION USING VARIATIONAL INFERENCE FOR BIOMEDICAL IMAGE SEGMENTATION,['Abhinav Sagar'],[],,,,,
Pz_dcqfcKW8,2021,Accept (Poster),False,Dual-mode ASR: Unify and Improve Streaming ASR with Full-context Modeling,"[""Jiahui Yu"", ""Wei Han"", ""Anmol Gulati"", ""Chung-Cheng Chiu"", ""Bo Li"", ""Tara N Sainath"", ""Yonghui Wu"", ""Ruoming Pang""]","[""Speech Recognition"", ""Streaming ASR"", ""Low-latency ASR"", ""Dual-mode ASR""]","Dual-mode ASR unifies and improves Streaming ASR with full-context modeling, simplifying the development and deployment workflow and improving both latency and accuracy.",,,,
PzcvxEMzvQC,2022,Accept (Oral),False,GeoDiff: A Geometric Diffusion Model for Molecular Conformation Generation,"['Minkai Xu', 'Lantao Yu', 'Yang Song', 'Chence Shi', 'Stefano Ermon', 'Jian Tang']","[""molecular conformation generation"", ""deep generative models"", ""diffusion probabilistic models""]","A novel probabilistic diffusion framework to generate accurate and diverse molecular conformations, achieving state-of-the-art results on conformation generation and property prediction",,,,
Pzj6fzU6wkj,2021,Accept (Poster),True,IsarStep: a Benchmark for High-level Mathematical Reasoning,"[""Wenda Li"", ""Lei Yu"", ""Yuhuai Wu"", ""Lawrence C. Paulson""]","[""mathematical reasoning"", ""dataset"", ""benchmark"", ""reasoning"", ""transformer""]",We present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. ,2006.09265,cs.LO,2020-06-13 21:09:23+00:00,2021-03-24 16:45:18+00:00
Q1aiM7sCi1,2021,Reject,True,Fuzzy c-Means Clustering for Persistence Diagrams,"[""Thomas Davies"", ""Jack Aspinall"", ""Bryan Wilder"", ""Long Tran-Thanh""]","[""Topological data analysis"", ""fuzzy clustering""]","We develop fuzzy clustering for the space of persistence diagrams, with experiments on lattice structures and decision boundaries.",2006.02796,cs.LG,2020-06-04 11:45:20+00:00,2021-02-15 13:00:53+00:00
Q1jmmQz72M2,2021,Accept (Poster),False,Neural Delay Differential Equations,"[""Qunxi Zhu"", ""Yao Guo"", ""Wei Lin""]","[""Delay differential equations"", ""neural networks""]","We propose a new class of continuous-depth neural networks with delay, named as Neural Delay Differential Equations and having better representation capability outperforming the Neural ODEs.",,,,
Q2iaAc-4I1v,2021,Reject,False,Causal Curiosity: RL Agents Discovering Self-supervised Experiments for Causal Representation Learning,"[""Sumedh Anand Sontakke"", ""Arash Mehrjou"", ""Theofanis Karaletsos"", ""Laurent Itti"", ""Bernhard Sch\u00f6lkopf""]","[""Causal Representation Learning"", ""Unsupervised/Self-Supervised Reinforcement Learning""]",We teach RL agents to perform self-supervised experiments to discover the causal processes like gravity and friction that affect their environment. ,,,,
Q42O1Qaho5N,2022,Reject,False,$G^3$: Representation Learning and Generation for Geometric Graphs,"['Han Huang', 'Stefan C Schonsheck', 'Rongjie Lai', 'Jie Chen']","[""Deep Learning"", ""Generative Models"", ""Graph Neural Networks""]",,,,,
Q42f0dfjECO,2022,Accept (Poster),False,Differentially Private Fine-tuning of Language Models,"['Da Yu', 'Saurabh Naik', 'Arturs Backurs', 'Sivakanth Gopi', 'Huseyin A Inan', 'Gautam Kamath', 'Janardhan Kulkarni', 'Yin Tat Lee', 'Andre Manoel', 'Lukas Wutschitz', 'Sergey Yekhanin', 'Huishuai Zhang']","[""differential privacy"", ""large language models"", ""fine-tuning""]","We show that by combining recent advances in NLP, parameter-efficiency, privacy accounting, and using larger models, one can privately fine-tune models whose utility approaches that of non-private models.",,,,
Q4EUywJIkqr,2021,Accept (Poster),False,Contemplating Real-World Object Classification,"[""ali borji""]","[""object recognition"", ""deep learning"", ""ObjectNet"", ""Robustness""]",We address whether current deep learning models are able to solve object recognition in real world and how robust they are to synthetic and natural distribution shifts.,2103.05137,cs.CV,2021-03-08 23:29:59+00:00,2021-03-27 18:50:02+00:00
Q5ZxoD2LqcI,2021,Reject,False,On the use of linguistic similarities to improve Neural Machine Translation for African Languages,"[""Tikeng Notsawo Pascal"", ""NANDA ASSOBJIO Brice Yvan"", ""James Assiene""]","[""Machine Translation"", ""Multilingualism"", ""Linguistic similarity"", ""Dataset"", ""African languages"", ""Multi-task learning""]","In this work, we show that performing multi-task learning on a cluster of similar languages leads to a strong boost of performance in translating individual pairs inside this cluster.",,,,
Q5uh1Nvv5dm,2022,Accept (Poster),False,AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain Adaptation,"['David Berthelot', 'Rebecca Roelofs', 'Kihyuk Sohn', 'Nicholas Carlini', 'Alexey Kurakin']","[""unsupervised domain adaptation"", ""semi-supervised learning"", ""semi-supervised domain adaptation""]","We introduce AdaMatch, a unified solution that achieves state-of-the-art results for unsupervised domain adaptation (UDA), semi-supervised learning (SSL), and semi-supervised domain adaptation (SSDA).",,,,
Q76Y7wkiji,2022,Accept (Poster),True,Boosting the Certified Robustness of L-infinity Distance Nets,"['Bohang Zhang', 'Du Jiang', 'Di He', 'Liwei Wang']","[""Adversarial Robustness"", ""Certified Defense"", ""Lipschitz Network""]",We design a new training strategy that significantly boosts the performance of $\ell_\infty$-distance nets and establishes new state-of-the-art certified robustness.,2110.06850,cs.LG,2021-10-13 16:43:25+00:00,2022-01-03 16:32:51+00:00
Q83vFlie_Pr,2022,Accept (Poster),False,"Bandit Learning with Joint Effect of Incentivized Sampling, Delayed Sampling Feedback, and Self-Reinforcing User Preferences","['Tianchen Zhou', 'Jia Liu', 'Chaosheng Dong', 'Yi Sun']",[],,,,,
Q8OjAGkxwP5,2022,Reject,False,Limitations of Active Learning With Deep Transformer Language Models,"[""Mike D'Arcy"", 'Doug Downey']","[""Active Learning"", ""Machine Learning"", ""Natural Language Processing""]","Active learning with large transformers sometimes fails on NLP tasks, but unlike previous work which suggests that it selects harmful outliers, we find evidence that it selects useful but hard-to-optimize examples.",,,,
QB7FkNVAfxa,2021,Reject,False,On the Explicit Role of Initialization on the Convergence and Generalization Properties of Overparametrized Linear Networks,"[""Hancheng Min"", ""Salma Tarmoun"", ""Rene Vidal"", ""Enrique Mallada""]",[],This paper studies the convergence and generalization property of single-hidden-layer linear networks,2105.06351,cs.LG,2021-05-13 15:13:51+00:00,2021-05-13 15:13:51+00:00
QCeFEThVn3,2022,Reject,False,GraphEBM: Towards Permutation Invariant and Multi-Objective Molecular Graph Generation,"['Meng Liu', 'Keqiang Yan', 'Bora Oztekin', 'Shuiwang Ji']","[""molecular graph generation"", ""energy-based models"", ""permutation invariance"", ""multi-objective""]",,,,,
QDDVxweQJy0,2022,Reject,False,Proving Theorems using Incremental Learning and Hindsight Experience Replay,"['Eser AygÃ¼n', 'Laurent Orseau', 'Ankit Anand', 'Xavier Glorot', 'Vlad Firoiu', 'Lei M Zhang', 'Doina Precup', 'Shibl Mourad']","[""theorem proving"", ""incremental learning"", ""hindsight experience replay"", ""transformers""]",We match the performance of a state-of-the-art automated first-order theorem proving system by combining a rudimentary proof search algorithm with incremental learning and hindsight experience replay.,,,,
QDdJhACYrlX,2022,Accept (Poster),True,THOMAS: Trajectory Heatmap Output with learned Multi-Agent Sampling,"['Thomas Gilles', 'Stefano Sabatini', 'Dzmitry Tsishkou', 'Bogdan Stanciulescu', 'Fabien Moutarde']","[""Trajectory prediction"", ""Multi-agent"", ""Motion forecasting"", ""Motion estimation"", ""Autonomous driving""]",We propose a solution for multi-agent coherent multimodal trajectory prediction by learning a recombination of each agent predicted modalities.,2110.06607,cs.CV,2021-10-13 10:05:47+00:00,2022-01-21 11:15:44+00:00
QEBHPRodWYE,2022,Reject,False,InstaHideâs Sample Complexity When Mixing Two Private Images ,"['Baihe Huang', 'Zhao Song', 'Runzhou Tao', 'Ruizhe Zhang', 'Danyang Zhuo']",[],,,,,
QFNIpIrkANz,2022,Reject,False,Learning Invariant Reward Functions through Trajectory Interventions,"['Ivan Ovinnikov', 'Eugene Bykovets', 'Joachim M. Buhmann']",[],,,,,
QFYnKlBJYR,2021,Accept (Poster),False,Reinforcement Learning with Random Delays,"[""Yann Bouteiller"", ""Simon Ramstedt"", ""Giovanni Beltrame"", ""Christopher Pal"", ""Jonathan Binas""]","[""Reinforcement Learning"", ""Deep Reinforcement Learning""]",We propose a framework for Reinforcement Learning with random action and observation delays.,,,,
QHUUrieaqai,2021,Reject,False,LIME: Learning Inductive Bias for Primitives of Mathematical Reasoning,"[""Yuhuai Wu"", ""Markus Norman Rabe"", ""Wenda Li"", ""Jimmy Ba"", ""Roger Baker Grosse"", ""Christian Szegedy""]","[""Theorem proving"", ""Pre-training"", ""Inductive bias"", ""Reasoning.""]","We designed inductive bias of mathematical reasoning in the form of dataset and use pretraining to learn inductive biases, demonstrating significant gains over three mathematical reasoning datasets.",,,,
QIRlze3I6hX,2021,Accept (Oral),False,Learning Cross-Domain Correspondence for Control with Dynamics Cycle-Consistency,"[""Qiang Zhang"", ""Tete Xiao"", ""Alexei A Efros"", ""Lerrel Pinto"", ""Xiaolong Wang""]","[""self-supervised learning"", ""robotics""]","We learn correspondence across domains with different modalities, physics parameters, and morphologies for control tasks (in both simulation and real robot) with Dynamics Cycle-Consistency. ",,,,
QJWVP4CTmW4,2022,Accept (Poster),False,Ada-NETS: Face Clustering via Adaptive Neighbour Discovery in the Structure Space,"['Yaohua Wang', 'Yaobin Zhang', 'Fangyi Zhang', 'Senzhang Wang', 'Ming Lin', 'YuQi Zhang', 'Xiuyu Sun']","[""Face Clustering"", ""Graph Convolutional Networks (GCN)"", ""Computer Vision""]",A novel algorithm named Ada-NETS is proposed to construct the clean graph for GCNs to cluster faces in this paper.,2202.03800,cs.CV,2022-02-08 11:44:45+00:00,2022-02-08 11:44:45+00:00
QJb1-8NH2Ux,2022,Reject,False,Detecting Adversarial Examples Is (Nearly) As Hard As Classifying Them,['Florian Tramer'],"[""Adversarial Examples"", ""Detection"", ""Hardness Reductions""]",Detecting adversarial examples is not any easier than correctly classifying them,,,,
QKEkEFpKBBv,2022,Reject,False,DNBP: Differentiable Nonparametric Belief Propagation,"['Anthony Opipari', 'Jana Pavlasek', 'Chao Chen', 'Shoutian Wang', 'Karthik Desingh', 'Odest Jenkins']","[""Belief Propagation"", ""Bayesian Inference"", ""Nonparametric Inference""]",We present a differentiable approach to learn the probabilistic factors used for inference by a nonparametric belief propagation algorithm.,,,,
QKbS9KXkE_y,2021,Reject,False,Data-efficient Hindsight Off-policy Option Learning,"[""Markus Wulfmeier"", ""Dushyant Rao"", ""Roland Hafner"", ""Thomas Lampe"", ""Abbas Abdolmaleki"", ""Tim Hertweck"", ""Michael Neunert"", ""Dhruva Tirumala"", ""Noah Yamamoto Siegel"", ""Nicolas Heess"", ""Martin Riedmiller""]","[""Hierarchical Reinforcement Learning"", ""Off-Policy"", ""Abstractions"", ""Data-Efficiency""]","We develop an efficient off-policyÂ option learning method, isolate the impact of action and temporal abstraction, demonstrate the importance and challenges of off-policy learning and solve challenging tasks from raw pixels.",,,,
QM4_h99pjCE,2021,Reject,False,Decentralized Deterministic Multi-Agent Reinforcement Learning,"[""Antoine Grosnit"", ""Desmond Cai"", ""Laura Wynter""]","[""multiagent reinforcement learning"", ""MARL"", ""decentralized actor-critic algorithm""]",We provide a provably-convergent decentralized actor-critic algorithm for learning deterministic reinforcement learning policies on continuous action spaces.,2102.09745,cs.LG,2021-02-19 05:10:15+00:00,2021-02-19 05:10:15+00:00
QNW1OrjynpT,2022,Reject,False,Short-term memory in neural language models,"['Kristijan Armeni', 'Christopher Honey', 'Tal Linzen']","[""short-term memory"", ""language models"", ""transformer"", ""lstm"", ""GPT-2""]",,,,,
QO9-y8also-,2021,Accept (Poster),False,Exemplary Natural Images Explain CNN Activations Better than State-of-the-Art Feature Visualization,"[""Judy Borowski"", ""Roland Simon Zimmermann"", ""Judith Schepers"", ""Robert Geirhos"", ""Thomas S. A. Wallis"", ""Matthias Bethge"", ""Wieland Brendel""]","[""evaluation of interpretability"", ""feature visualization"", ""activation maximization"", ""human psychophysics"", ""understanding CNNs"", ""explanation method""]","Using human psychophysical experiments, we show that natural images can be significantly more informative for interpreting neural network activations than a state-of-the-art synthetic feature visualization.",,,,
QQzomPbSV7q,2021,Reject,True,Reducing Class Collapse in Metric Learning with Easy Positive Sampling,"[""Elad Levi"", ""Tete Xiao"", ""Xiaolong Wang"", ""trevor darrell""]",[],,2006.05162,cs.LG,2020-06-09 09:59:25+00:00,2021-08-27 14:13:34+00:00
QRX0nCX_gk,2022,Accept (Poster),False,Multimeasurement Generative Models,"['Saeed Saremi', 'Rupesh Kumar Srivastava']","[""energy based models"", ""Langevin MCMC"", ""score matching"", ""denoising autoencoders"", ""empirical Bayes""]",,2112.09822,stat.ML,2021-12-18 02:11:36+00:00,2021-12-18 02:11:36+00:00
QSMvGB5j5-,2021,Reject,False,Higher-order Structure Prediction in Evolving Graph Simplicial Complexes,"[""Manohar Kaul"", ""Masaaki Imaizumi""]","[""Higher-order"", ""graph simplicial complex"", ""link prediction""]",Predicting future formation of higher-order relationship structures in an evolving graph.,2102.03609,cs.LG,2021-02-06 16:49:02+00:00,2021-02-06 16:49:02+00:00
QTgP9nKmMPM,2021,Reject,False,Decoupled Greedy Learning of Graph Neural Networks,"[""YEWEN WANG"", ""Jian Tang"", ""Yizhou Sun"", ""Guy Wolf""]",[],"We propose decoupled greedy learning method for GNNs (DGL-GNN) that improves training efficiency via parallelization over decoupled modules (e.g., layers) with greedy auxiliary objectives, without significantly compromising model performances.",,,,
QYjO70ACDK,2021,Accept (Spotlight),False,Distributional Sliced-Wasserstein and Applications to Generative Modeling,"[""Khai Nguyen"", ""Nhat Ho"", ""Tung Pham"", ""Hung Bui""]","[""Deep generative models"", ""Sliced Wasserstein"", ""Optimal Transport""]",A new optimal transport distance based on slicing approach and its applications to generative modeling.,,,,
QZaeLBDU03,2021,Reject,True,Learning Movement Strategies for Moving Target Defense,"[""Sailik Sengupta"", ""Subbarao Kambhampati""]","[""Multi-agent Reinforcement Learning"", ""Moving Target Defense"", ""Stackelberg Security""]",Repeated interaction with an environment helps a defender learn robust movement strategies at equilibrium against multiple adversary types.,2007.10457,cs.GT,2020-07-20 20:34:53+00:00,2020-07-20 20:34:53+00:00
Qaw16njk6L,2022,Accept (Poster),False,NASViT: Neural Architecture Search for Efficient Vision Transformers with Gradient Conflict aware Supernet Training,"['Chengyue Gong', 'Dilin Wang', 'Meng Li', 'Xinlei Chen', 'Zhicheng Yan', 'Yuandong Tian', 'qiang liu', 'Vikas Chandra']","[""vision transformer"", ""gradient conflict"", ""neural architecture search""]","we identify one key issue of ViT supernet training that the supernet gradients and the sub-network gradients are likely to disagree with each other, and propose gradient conflict aware training.",,,,
Qb07sqX7dVl,2022,Reject,False,Label Augmentation with Reinforced Labeling for Weak Supervision,"['GÃ¼rkan Solmaz', 'Flavio Cirillo', 'Fabio Maresca', 'Anagha GodeAnilKumar']","[""weak supervision"", ""data programming""]",This paper proposes label augmentation with reinforced labeling for weak supervision by utilizing dataset features in the generative process.,,,,
QbFfqWAEmMr,2022,Reject,False,LASSO: Latent Sub-spaces Orientation for Domain Generalization,"['Long Tung Vuong', 'Trung Quoc Phung', 'Toan Tran', 'Anh Tuan Tran', 'Dinh Phung', 'Trung Le']","[""Domain generalization"", ""Image Classification"", ""machine learning"", ""deep learning""]",,,,,
QcqsxI6rKDs,2021,Reject,False,Meta Gradient Boosting Neural Networks,"[""Manqing Dong"", ""Lina Yao"", ""Xianzhi Wang"", ""Xiwei Xu"", ""Liming Zhu""]","[""meta learning"", ""deep learning""]",,,,,
QdcbUq0-tYM,2022,Reject,False,Universal Controllers with Differentiable Physics for Online System Identification,"['Michelle Guo', 'Wenhao Yu', 'Daniel Ho', 'Jiajun Wu', 'Yunfei Bai', 'Karen Liu', 'Wenlong Lu']",[],,,,,
Qe_de8HpWK,2021,Reject,False,GenQu: A Hybrid System for Learning Classical Data in Quantum States,"[""Samuel A. Stein"", ""Ray Marie Tischio"", ""Betis Baheri"", ""Yiwen Chen"", ""Ying Mao"", ""Qiang Guan"", ""Ang Li"", ""Bo Fang""]","[""Quantum Machine Learning"", ""Qubits"", ""Kernel Methods"", ""Deep Neural Network""]","We propose GenQu, a hybrid and general-purpose quantum system for learning classical data in quantum states",,,,
QevkqHTK3DJ,2022,Reject,False,Compressing Transformer-Based Sequence to Sequence Models With Pre-trained Autoencoders for Text Summarization,"['Ala Alam Falaki', 'Robin Gras']","[""Transformer"", ""Automatic Text Summarization"", ""sequence-to-sequence"", ""Compression""]",Proposing an approach to compress transformer-based sequence-to-sequence models' encoder latent representation with minimal loss.,,,,
QfEssgaXpm,2021,Reject,False,Reinforcement Learning for Control with Probabilistic Stability Guarantee,"[""Minghao Han"", ""Zhipeng Zhou"", ""Lixian Zhang"", ""Jun Wang"", ""Wei Pan""]","[""control"", ""Lyapunov stability"", ""REINFORCE"", ""finite-sample bounds""]",Sample-based stability condition and the associated finite sample bound for reinforcement learning control. ,,,,
QfTXQiGYudJ,2021,Accept (Spotlight),False,Stabilized Medical Image Attacks,"[""Gege Qi"", ""Lijun GONG"", ""Yibing Song"", ""Kai Ma"", ""Yefeng Zheng""]","[""Healthcare"", ""Biometrics""]",We propose a stabilized adversarial attack method for medical image analysis.,2103.05232,cs.CV,2021-03-09 05:40:30+00:00,2021-03-09 05:40:30+00:00
Qg2vi4ZbHM9,2022,Accept (Oral),True,StyleAlign: Analysis and Applications of Aligned StyleGAN Models,"['Zongze Wu', 'Yotam Nitzan', 'Eli Shechtman', 'Dani Lischinski']","[""StyleGAN"", ""transfer learning"", ""fine tuning"", ""model alignment"", ""image-to-image translation"", ""image morphing""]",Analysis and applications of aligned generative models,2110.11323,cs.CV,2021-10-21 17:55:16+00:00,2021-10-21 17:55:16+00:00
QguFu30t0d,2022,Reject,True,FedGEMS: Federated Learning of Larger Server Models via Selective Knowledge Fusion,"['Sijie Cheng', 'Jingwen Wu', 'Yanghua Xiao', 'Yang Liu', 'Yang Liu']","[""Federated Learning"", ""Knowledge Distillation""]",,2110.11027,cs.LG,2021-10-21 10:06:44+00:00,2021-12-07 09:38:57+00:00
QhHMf5J5Jom,2022,Reject,True,A Scaling Law for Syn-to-Real Transfer: How Much Is Your Pre-training Effective?,"['Hiroaki Mikami', 'Kenji Fukumizu', 'Shogo Murai', 'Shuji Suzuki', 'Yuta Kikuchi', 'Taiji Suzuki', 'Shin-ichi Maeda', 'Kohei Hayashi']","[""Transfer learning"", ""Computer vision"", ""Scaling law"", ""Pre-training"", ""Synthetic-to-real""]",We derive a simple scaling law that predicts the performance of transfer learning from the amount of pre-training data.,2108.11018,cs.LG,2021-08-25 02:29:28+00:00,2021-10-08 20:57:04+00:00
QjINdYOfq0b,2021,Reject,False,ABS: Automatic Bit Sharing for Model Compression,"[""Jing Liu"", ""Bohan Zhuang"", ""Peng Chen"", ""Yong Guo"", ""Chunhua Shen"", ""Jianfei Cai"", ""Mingkui Tan""]","[""Quantization"", ""Pruning"", ""Model Compression"", ""AutoML""]","We present a novel super-bit model, a single-path method, to automatically search for optimal model compression configurations.",2101.04935,cs.CV,2021-01-13 08:28:21+00:00,2021-02-15 12:07:31+00:00
QjOQkpzKbNk,2022,Accept (Poster),False,Distilling GANs with Style-Mixed Triplets for X2I Translation with Limited Data,"['Yaxing Wang', 'Joost van de weijer', 'Lu Yu', 'SHANGLING JUI']","[""Transfer learning"", ""image synthesis"", ""limited data.""]",One transfer learning method generalizes varying kinds of  conditional image synthesization tasks. ,,,,
Qk-Wq5AIjpq,2021,Accept (Poster),True,PAC Confidence Predictions for Deep Neural Network Classifiers,"[""Sangdon Park"", ""Shuo Li"", ""Insup Lee"", ""Osbert Bastani""]","[""classification"", ""calibration"", ""probably approximated correct guarantee"", ""fast DNN inference"", ""safe planning""]","We propose a novel algorithm for constructing predicted classification confidences for DNNs that comes with provable correctness guarantees, and demonstrate how our predicted confidences can be used to enable downstream guarantees in two settings.",2011.00716,cs.LG,2020-11-02 04:09:17+00:00,2021-03-17 19:51:37+00:00
QkRV50TZyP,2022,Accept (Poster),False,Beyond ImageNet Attack: Towards Crafting Adversarial Examples for Black-box Domains,"['Qilong Zhang', 'Xiaodan Li', 'YueFeng Chen', 'Jingkuan Song', 'Lianli Gao', 'Yuan He', ""Hui Xue'""]","[""practice black-box attack"", ""cross-domain transferability""]",We propose an effective method that can craft adversarial examples for black-box domain.,,,,
QkRbdiiEjM,2021,Accept (Poster),True,AdaGCN: Adaboosting Graph Convolutional Networks into Deep Models,"[""Ke Sun"", ""Zhanxing Zhu"", ""Zhouchen Lin""]","[""Graph Neural Networks"", ""AdaBoost""]",We propose a novel RNN-like deep graph neural network architecture by incorporating AdaBoost into the computation of network.,1908.05081,cs.LG,2019-08-14 11:41:09+00:00,2021-03-15 10:19:52+00:00
QkfMWTl520U,2022,Reject,False,When do Convolutional Neural Networks Stop Learning?,"['SAHAN AHMAD', 'Aminul Islam']","[""Deep Learning"", ""Convolutional Neural Network"", ""CNN"", ""Epoch"", ""Training"", ""Data""]",When do Convolutional Neural Networks Stop Learning?,,,,
Qm7R_SdqTpT,2021,Accept (Poster),False,Diverse Video Generation using a Gaussian Process Trigger,"[""Gaurav Shrivastava"", ""Abhinav Shrivastava""]","[""video synthesis"", ""future frame generation"", ""video generation"", ""gaussian process priors"", ""diverse video generation""]","Diverse future frame synthesis by modeling the diversity of future states using a Gaussian Process, and using Bayesian inference to sample diverse future states.",2107.04619,cs.CV,2021-07-09 18:15:16+00:00,2021-07-09 18:15:16+00:00
Qm8UNVCFdh,2021,Accept (Poster),False,What Can You Learn From Your Muscles? Learning Visual Representation from Human Interactions,"[""Kiana Ehsani"", ""Daniel Gordon"", ""Thomas Hai Dang Nguyen"", ""Roozbeh Mottaghi"", ""Ali Farhadi""]","[""representation learning"", ""computer vision""]",We learn a muscly-supervised visual representation from human's interactions with the visual world.,,,,
QmKblFEgQJ,2022,Reject,False, DIGRAC: Digraph Clustering Based on Flow Imbalance,"['Yixuan He', 'Gesine Reinert', 'Mihai Cucuringu']","[""flow imbalance"", ""directed networks"", ""graph neural networks"", ""clustering"", ""directed stochastic block models""]",We devise a novel digraph clustering GNN framework based on flow imbalance.,,,,
QnzSSoqmAvB,2021,Reject,False,Playing Nondeterministic Games through Planning with a Learned Model,"[""Thomas Willkens"", ""Jordan Pollack""]","[""reinforcement learning"", ""alphazero"", ""muzero"", ""mcts"", ""planning"", ""search""]",The paper presents an extension of the MuZero algorithm for nondeterministic games.,,,,
QoWatN-b8T,2021,Accept (Poster),False,"Kanerva++: Extending the Kanerva Machine With Differentiable, Locally Block Allocated Latent Memory","[""Jason Ramapuram"", ""Yan Wu"", ""Alexandros Kalousis""]","[""memory"", ""generative model"", ""latent variable"", ""heap allocation""]",Differentiable block allocated latent memory model for generative modeling.,2103.03905,cs.NE,2021-02-20 18:40:40+00:00,2021-03-16 09:38:06+00:00
QpNz8r_Ri2Y,2021,Accept (Poster),False,Representation Balancing Offline Model-based Reinforcement Learning,"[""Byung-Jun Lee"", ""Jongmin Lee"", ""Kee-Eung Kim""]","[""Reinforcement Learning"", ""Model-based Reinforcement Learning"", ""Offline Reinforcement Learning"", ""Batch Reinforcement Learning"", ""Off-policy policy evaluation""]","We present RepB-SDE, a framework for balancing the model representation with stationary distribution estimation, aiming at obtaining a model robust to the distribution shift that arises in off-policy and offline RL.",,,,
QpT9Q_NNfQL,2021,Reject,False,NeurWIN: Neural Whittle Index Network for Restless Bandits via Deep RL,"[""Khaled Nakhleh"", ""Santosh Ganji"", ""Ping-Chun Hsieh"", ""I-Hong Hou"", ""Srinivas Shakkottai""]","[""deep reinforcement learning"", ""restless bandits"", ""Whittle index""]",New deep RL algorithm for learning the Whittle index of a restless arm independently of other arms.,2110.02128,cs.LG,2021-10-05 15:58:23+00:00,2021-10-05 15:58:23+00:00
QpU7n-6l0n,2021,Reject,False,On the Consistency Loss for Leveraging Augmented Data to Learn Robust and Invariant Representations,"[""Haohan Wang"", ""Zeyi Huang"", ""Xindi Wu"", ""Eric Xing""]","[""robustness"", ""invariance"", ""data augmentation"", ""consistency loss""]","We show that consistency loss when using data augmentation is important to learn robust and invariant representations, and show that squared $\ell_2$ norm regularization is the best candidate",,,,
Qpik5XBv_1-,2021,Reject,False,Language Controls More Than Top-Down Attention: Modulating Bottom-Up Visual Processing with Referring Expressions,"[""Ozan Arkan Can"", ""Ilker Kesen"", ""Deniz Yuret""]","[""Referring Expression Understanding"", ""Language-Vision Problems"", ""Grounded Language Understanding""]",We modulate both top-down and bottom-up visual processing with referring expressions.,,,,
Qr0aRliE_Hb,2021,Accept (Poster),False,Simple Augmentation Goes a Long Way: ADRL for DNN Quantization,"[""Lin Ning"", ""Guoyang Chen"", ""Weifeng Zhang"", ""Xipeng Shen""]","[""Reinforcement Learning"", ""Quantization"", ""mixed precision"", ""augmented deep reinforcement learning"", ""DNN""]",Augments the neural networks in Deep Reinforcement Learning(DRL) with a complementary scheme to boost the performance of learning and solve the common low convergence problem in the early stage of DRL,,,,
QtTKTdVrFBB,2021,Accept (Spotlight),False,Random Feature Attention,"[""Hao Peng"", ""Nikolaos Pappas"", ""Dani Yogatama"", ""Roy Schwartz"", ""Noah Smith"", ""Lingpeng Kong""]","[""Attention"", ""transformers"", ""machine translation"", ""language modeling""]","We propose a random-feature-based attention that scales linearly in sequence length, and performs on par with strong transformer baselines on language modeling and machine translation.",,,,
QuObT9BTWo,2022,Accept (Poster),False,Preference Conditioned Neural Multi-objective Combinatorial Optimization,"['Xi Lin', 'Zhiyuan Yang', 'Qingfu Zhang']","[""Multiobjective Combinatorial Optimization"", ""Combinatorial Optimization"", ""Neural Combinatorial Optimization"", ""Multiobjective Optimization""]",We propose a learning-based method to approximate the whole Pareto set for multi-objective combinatorial optimization problems with a single model.,,,,
Qu_XudmGajz,2022,Reject,False,Structured Uncertainty in the Observation Space of Variational Autoencoders,"['James Langley', 'Miguel Monteiro', 'Charles Jones', 'Nick Pawlowski', 'Ben Glocker']",[],,,,,
QubpWYfdNry,2021,Accept (Poster),False,Domain-Robust Visual Imitation Learning with Mutual Information Constraints,"[""Edoardo Cetin"", ""Oya Celiktutan""]","[""Imitation Learning"", ""Reinforcement Learning"", ""Observational Imitation"", ""Third-Person Imitation"", ""Mutual Information"", ""Domain Adaption"", ""Machine Learning""]","Imitation of visual expert demonstrations robust to appearance and embodiment mismatch, working for high dimensional control problems.",2103.05079,cs.LG,2021-03-08 21:18:58+00:00,2021-03-08 21:18:58+00:00
Qun8fv4qSby,2021,Accept (Poster),True,Transient Non-stationarity and Generalisation in Deep Reinforcement Learning,"[""Maximilian Igl"", ""Gregory Farquhar"", ""Jelena Luketina"", ""Wendelin Boehmer"", ""Shimon Whiteson""]","[""Reinforcement Learning"", ""Generalization""]",We find that transient non-stationarity can worsen generalization in reinforcement learning and propose a method to overcome this effeect.,2006.05826,cs.LG,2020-06-10 13:26:31+00:00,2021-09-22 08:03:34+00:00
QvTH9nN2Io,2022,Reject,False,Relative Entropy Gradient Sampler for Unnormalized Distributions,"['Xingdong Feng', 'Yuan Gao', 'Jian Huang', 'Yuling Jiao', 'Xu Liu']","[""Density ratio estimation"", ""gradient flow"", ""neural networks"", ""particles"", ""velocity fields""]",We proposed a novel sampling method for unnormalized distributions based on relative entropy gradient flow and neural network approximation.,,,,
QxQkG-gIKJM,2021,Reject,False,Optimistic Exploration with Backward Bootstrapped Bonus for Deep Reinforcement Learning,"[""Chenjia Bai"", ""Lingxiao Wang"", ""Peng Liu"", ""Zhaoran Wang"", ""Jianye HAO"", ""Yingnan Zhao""]","[""optimistic exploration"", ""backward bootstrapped bonus"", ""posterior sampling"", ""reinforcement learning""]",,,,,
Qycd9j5Qp9J,2022,Accept (Poster),False,Understanding the Variance Collapse of SVGD in High Dimensions,"['Jimmy Ba', 'Murat A Erdogdu', 'Marzyeh Ghassemi', 'Shengyang Sun', 'Taiji Suzuki', 'Denny Wu', 'Tianzong Zhang']","[""Stein Variational Gradient Descent"", ""Approximate Inference"", ""Particle-based Variational Inference""]",Qualitative and quantitative analysis of the variance collapse phenomenon of SVGD in high dimensions. ,,,,
QzKDLiosEd,2021,Reject,False,Can one hear the shape of a neural network?: Snooping the GPU via Magnetic Side Channel,"[""Henrique Teles Maia"", ""Chang Xiao"", ""Dingzeyu Li"", ""Eitan Grinspun"", ""Changxi Zheng""]","[""side channel"", ""model extraction"", ""GPU"", ""magnetic induction"", ""sensors""]",We  examine  the  magnetic  flux  emanating  from  a  graphics  processing  unitâs (GPUâs) power cable and find that this signal betrays the detailed topology and hyperparameters of a black-box neural network model.,2109.07395,cs.CR,2021-09-15 16:00:05+00:00,2021-09-15 16:00:05+00:00
R-I5CUDOAp7,2022,Reject,False,STORM: Sketch Toward Online Risk Minimization,"['Gaurav Gupta', 'Benjamin Coleman', 'John Chen', 'Anshumali Shrivastava']",[],A very compressed sketch for Empirical risk minimization.,,,,
R-piejobttn,2022,Reject,False,Mixture Representation Learning with Coupled Autoencoders,"['Yeganeh Marghi', 'Rohan Gala', 'Uygar SÃ¼mbÃ¼l']","[""Mixture representation"", ""high-dimensional categorical variable"", ""unsupervised learning"", ""constrained variational framework"", ""neuronal diversity"", ""single-cell RNA sequencing"", ""cell types""]",We propose a novel unsupervised variational framework using multiple interacting autoencoders to discover interpretable discrete and continuous latent variables describing neuronal identity in single-cell omic datasets.,,,,
R0AzpCND-M_,2022,Reject,False,Model-Agnostic Meta-Attack: Towards Reliable Evaluation of Adversarial Robustness,"['Xiao Yang', 'Yinpeng Dong', 'Wenzhao Xiang', 'Tianyu Pang', 'Hang Su', 'Jun Zhu']","[""Adversarial attacks"", ""robust evaluation""]",We propose a model-agnostic meta-attack approach to learn stronger adversarial attack algorithms for reliable evaluation of adversarial robustness.,,,,
R0a0kFI3dJx,2021,Accept (Poster),False,Adaptive Extra-Gradient Methods for Min-Max Optimization and Games,"[""Kimon Antonakopoulos"", ""Veronica Belmega"", ""Panayotis Mertikopoulos""]","[""min-max optimization"", ""games"", ""mirror-prox"", ""adaptive methods"", ""regime agnostic methods""]",We develop an adaptive mirror-prox method for min-max problems and games that achieves order-optimal rates in both smooth and non-smooth problems.,,,,
R0xRE2MU2uA,2022,Reject,True,Graph Piece: Efficiently Generating High-Quality Molecular Graphs with Substructures,"['Xiangzhe Kong', 'Zhixing Tan', 'Yang Liu']",[],,2106.15098,cs.LG,2021-06-29 05:26:18+00:00,2021-12-19 07:59:46+00:00
R11xJsRjA-W,2022,Reject,False,The Connection between Out-of-Distribution Generalization and Privacy of ML Models,"['Divyat Mahajan', 'Shruti Tople', 'Amit Sharma']","[""membership inference attacks"", ""privacy attacks"", ""model privacy"", ""out-of-distribution generalization"", ""domain generalization""]","Better out-of-distribution generalization does not guarantee membership privacy for a ML model, learning stable features is the key.",,,,
R2AN-rz4j_X,2022,Reject,False,Continual Learning in Deep Networks: an Analysis of the Last Layer,"['Timothee LESORT', 'Thomas George', 'Irina Rish']","[""Continual Learning"", ""Linear Models""]",We analyze training of the output layer in various continual learning scenarios with a fixed feature extractor.,,,,
R2ZlTVPx0Gk,2021,Accept (Poster),False,DICE: Diversity in Deep Ensembles via Conditional Redundancy Adversarial Estimation,"[""Alexandre Rame"", ""Matthieu Cord""]","[""Deep Learning"", ""Deep Ensembles"", ""Information Theory"", ""Information Bottleneck"", ""Adversarial Learning""]","Driven by arguments from information theory, we introduce a new learning strategy for deep ensembles that increases diversity among members: we adversarially prevent features from being conditionally redundant, i.e., predictable from each other.",2101.05544,cs.LG,2021-01-14 10:53:26+00:00,2021-01-14 10:53:26+00:00
R2aCiGQ9Qc,2022,Reject,True,Two Sides of the Same Coin: Heterophily and Oversmoothing in Graph Convolutional Neural Networks,"['Yujun Yan', 'Milad Hashemi', 'Kevin Swersky', 'Yaoqing Yang', 'Danai Koutra']","[""graph convolutional neural networks"", ""node classification"", ""heterophily"", ""oversmoothing""]",The heterophily and oversmoothing problems in GCNs are inherently correlated.,2102.06462,cs.LG,2021-02-12 11:52:34+00:00,2021-11-24 05:29:57+00:00
R332S76RjxS,2022,Accept (Poster),True,A global convergence theory for deep ReLU implicit networks via over-parameterization,"['Tianxiang Gao', 'Hailiang Liu', 'Jia Liu', 'Hridesh Rajan', 'Hongyang Gao']","[""Deep learning"", ""Deep implicit learning"", ""deep equilibrium model"", ""gradient descent"", ""stochastic gradient descent"", ""over-parameterization""]","For a ReLU activated implicit neural network with infinitely many layers, we prove that randomly initialized gradient descent with a fixed step-size converges to a global minimum at a linear rate if the width m is the squared sample size n.",2110.05645,cs.LG,2021-10-11 23:22:50+00:00,2021-10-11 23:22:50+00:00
R3Y9yq49seb,2022,Reject,False,Wavelet Feature Maps Compression for Low Bandwidth Convolutional Neural Networks,"['Yair Zohav', 'Shahaf E Finder', 'Maor Ashkenazi', 'Eran Treister']","[""Convolutional Neural Networks"", ""Quantization"", ""Wavelet Transform""]","In this paper, we suggest a wavelet compressed convolution as a better alternative to aggressive activation map quantization in high-resolution CNNs.",,,,
R3zqNwzAVsC,2022,Reject,False,Learning an Ethical Module for Bias Mitigation of pre-trained Models,"['Jean-RÃ©my Conti', 'Nathan Noiry', 'Stephan CLEMENCON', 'Vincent Despiegel', 'StÃ©phane Gentric']","[""Deep Learning"", ""Bias"", ""Fairness"", ""Facial Recognition.""]",,,,,
R43miizWtUN,2021,Reject,False,Analysing the Update step in Graph Neural Networks via Sparsification,"[""changmin wu"", ""Johannes F. Lutzeyer"", ""Michalis Vazirgiannis""]","[""graph neural network architectures"", ""message-passing neural networks"", ""neural network sparsification"", ""deep learning""]",We propose a series of parsimonous GNN models by successively sparsifying the Update step in existing GNN architectures and find that the Update step can be sparsified almost arbitrarily resulting in smaller and cheaper models in practice,,,,
R4aWTjmrEKM,2021,Accept (Spotlight),False,Iterative Empirical Game Solving via Single Policy Best Response,"[""Max Smith"", ""Thomas Anthony"", ""Michael Wellman""]","[""Empirical Game Theory"", ""Reinforcement Learning"", ""Multiagent Learning""]","On each epoch, train against a single opponent policy rather than a distribution; reducing variance and focusing training on salient strategic knowledge.",,,,
R5M7Mxl1xZ,2021,Reject,False,Minimal Geometry-Distortion Constraint for Unsupervised Image-to-Image Translation,"[""Jiaxian Guo"", ""Jiachen Li"", ""Mingming Gong"", ""Huan Fu"", ""Kun Zhang"", ""Dacheng Tao""]","[""Unsupervised image translation"", ""Geometry distortion""]",We propose the Minimal Geometry-Distortion Constraint to promote the consistency of geometry structures and reduce the unwanted distortions in I2I translation.,,,,
R5sVzzXhW8n,2022,Reject,True,Demystifying How Self-Supervised Features Improve Training from Noisy Labels,"['Hao Cheng', 'Zhaowei Zhu', 'Xing Sun', 'Yang Liu']","[""Learning with noisy labels"", ""Self-Supervised Learning""]",Our work provides theoretical analyses and experiments to show why and how self-supervised features improve training from noisy labels.,2110.09022,cs.LG,2021-10-18 05:41:57+00:00,2022-02-05 13:08:58+00:00
R612wi_C-7w,2022,Reject,False,Stable cognitive maps for Path Integration emerge from fusing visual and proprioceptive sensors,"['Arnaud Fanthomme', 'RÃ©mi Monasson']","[""RNNs""]",,,,,
R6hvtDTQmb,2022,Reject,False,Adapting Stepsizes by Momentumized Gradients Improves Optimization and Generalization,"['Yizhou Wang', 'Yue Kang', 'Can Qin', 'Huan Wang', 'Yi Xu', 'Yulun Zhang', 'Yun Fu']","[""Deep Learning Optimizer"", ""Neural Network Optimization"", ""Neural Network Generalization""]","We propose AdaMomentum as a new optimizer for machine learning, which is as fast as adaptive gradient methods while generalizing much better.",,,,
R6tNszN_QfA,2021,Reject,False,Adversarial Problems for Generative Networks,"[""Kalliopi Basioti"", ""George V. Moustakides""]","[""generative networks"", ""adversarial generative networks""]",,,,,
R79ZGjHhv6p,2022,Accept (Poster),False,Toward Faithful Case-based Reasoning through Learning Prototypes in a Nearest Neighbor-friendly Space.,"['Seyed Omid Davoudi', 'Majid Komeili']","[""case-based reasoning"", ""interpretable machine learning"", ""explainable artificial intelligence"", ""xai"", ""prototype learning""]",Offering better prototype explanations using a nearest-neighbor friendly embedding space.,,,,
R7aFOrR0b2,2021,Reject,False,Dataset Curation Beyond Accuracy,"[""Johan Bjorck"", ""Carla P Gomes""]","[""crowd-sourcing"", ""calibration"", ""dataset"", ""uncertainty""]","We demonstrate that dataset properties such as imbalanced datasets and noisy labels influence not only accuracy, but also calibration.",,,,
R8sQPpGCv0,2022,Accept (Poster),False,"Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation","['Ofir Press', 'Noah Smith', 'Mike Lewis']",[],We show that our simple position method enables transformer LMs to efficiently and accurately perform inference on longer sequences than they were trained on. ,,,,
R9Ht8RZK3qY,2022,Reject,False,FED-$\chi^2$: Secure Federated Correlation Test,"['Lun Wang', 'Qi Pang', 'Shuai Wang', 'Dawn Song']","[""Federated Analytics"", ""Hypothesis Test""]","We propose FED-$\chi^2$, the first secure federated hypothesis testing protocol.",,,,
RA-zVvZLYIy,2022,Reject,False,MLP-based architecture with variable length input for automatic speech recognition,"['Jin Sakuma', 'Tatsuya Komatsu', 'Robin Scheibler']","[""MLP"", ""automatic speech recognition""]",We propose three MLP-based architectures suitable for sequences of arbitrary lengths.,,,,
RAW9tCdVxLj,2022,Accept (Poster),False,Zero-CL: Instance and Feature decorrelation for negative-free symmetric contrastive learning,"['Shaofeng Zhang', 'Feng Zhu', 'Junchi Yan', 'Rui Zhao', 'Xiaokang Yang']","[""Self supervised learning"", ""representation learning""]",We develop two contrastive learning methods to prevent collapses in symmetric architecture without negative pairs.,,,,
RAoBtzlwtCC,2022,Reject,False,Provable Federated Adversarial Learning via Min-max Optimization,"['Xiaoxiao Li', 'Zhao Song', 'Jiaming Yang']","[""Federated Learning"", ""Adversarial Training"", ""Optimization"", ""Non-Convex""]","We formulate a general form of federated adversarial learning with a proposed loss and corresponding min-max optimization scheme, further show its convergence. ",,,,
RB0iNPXIj60,2021,Reject,False,BBRefinement: an universal scheme to improve precision of box object detectors,"[""Petr Hurtik"", ""Marek Vajgl""]","[""object detection"", ""deep neural networks"", ""refinement""]",BBRefinement is a universal upgrade for existing object detectors to improve their accuracy via refinement of the detected bounding boxes.,,,,
RB_2cor6d-w,2022,Reject,False,"Towards Physical, Imperceptible Adversarial Attacks via Adversarial Programs","['Itai Mesery', 'Dana Drachsler Cohen']","[""Adversarial Attacks"", ""Adversarial Patches"", ""Adversarial Programs"", ""Program Synthesis""]",Multi-patch adversarial programs that are competitive with the C&W attack but with up to 10x fewer perturbed pixels,,,,
RCZqv9NXlZ,2022,Accept (Poster),False,Offline Reinforcement Learning with Value-based Episodic Memory,"['Xiaoteng Ma', 'Yiqin Yang', 'Hao Hu', 'Jun Yang', 'Chongjie Zhang', 'Qianchuan Zhao', 'Bin Liang', 'Qihan Liu']","[""Reinforcement Learning"", ""Offline Learning"", ""Episodic Memory Control""]",We propose a new offline RL method which uses expectile value learning and memory-based planning.,,,,
RDiiCiIH3_B,2021,Reject,False,A framework for learned CountSketch,"[""Simin Liu"", ""Tianrui Liu"", ""Ali Vakilian"", ""Yulin Wan"", ""David Woodruff""]","[""Compression"", ""sketching""]",We propose a framework for learning sparse sketches and applying them while maintaining approximation guarantees. ,,,,
RDlLMjLJXdq,2022,Accept (Poster),True,Learning Temporally Latent Causal Processes from General Temporal Data,"['Weiran Yao', 'Yuewen Sun', 'Alex Ho', 'Changyin Sun', 'Kun Zhang']",[],Propose two provable conditions and training framework with which temporally latent causal processes are identifiable from observed variables.,2110.05428,stat.ML,2021-10-11 17:16:19+00:00,2022-02-08 21:47:39+00:00
RDpTZpubOh7,2021,Reject,True,Safety Aware Reinforcement Learning (SARL),"[""Santiago Miret"", ""Somdeb Majumdar"", ""Carroll Wainwright""]","[""Reinforcement Learning"", ""Safe RL"", ""Probabilistic Distance Metrics""]",A generalizable and portable framework for safe reinforcement learning ,2010.02846,cs.LG,2020-10-06 16:08:28+00:00,2020-10-06 16:08:28+00:00
RGJbergVIoO,2021,Accept (Oral),False,On the mapping between Hopfield networks and Restricted Boltzmann Machines,"[""Matthew Smart"", ""Anton Zilman""]","[""Hopfield Networks"", ""Restricted Boltzmann Machines"", ""Statistical Physics""]",Hopfield networks with correlated patterns can be mapped to Restricted Boltzmann Machines with orthogonal weights. ,2101.11744,cs.LG,2021-01-27 23:49:48+00:00,2021-03-06 02:08:12+00:00
RGeQOjc58d,2021,Reject,True,Improved Gradient based Adversarial Attacks for Quantized Networks,"[""Kartik Gupta"", ""Thalaiyasingam Ajanthan""]","[""binary neural network"", ""gradient masking"", ""fake robustness"", ""temperature scaling"", ""adversarial attack"", ""signal propagation""]","In this work, we systematically study the robustness of quantized networks against gradient based adversarial attacks and propose PGD++ attack variants to overcome existing gradient masking issues in BNNs.",2003.13511,cs.CV,2020-03-30 14:34:08+00:00,2020-03-30 14:34:08+00:00
RGrj2uWTLWY,2022,Reject,False,PI-GNN: Towards Robust Semi-Supervised Node Classification against Noisy Labels,"['Xuefeng Du', 'Tian Bian', 'Yu Rong', 'Bo Han', 'Tongliang Liu', 'Tingyang Xu', 'Wenbing Huang', 'Junzhou Huang']",[],,,,,
RHY_9ZVcTa_,2021,Reject,False,On Linear Identifiability of Learned Representations,"[""Geoffrey Roeder"", ""Luke Metz"", ""Diederik P Kingma""]","[""identifiability analysis"", ""deep learning"", ""representation learning"", ""probabilistic discriminative models""]",,,,,
RJkAHKp7kNZ,2022,Accept (Oral),False,Vision-Based Manipulators Need to Also See from Their Hands,"['Kyle Hsu', 'Moo Jin Kim', 'Rafael Rafailov', 'Jiajun Wu', 'Chelsea Finn']","[""reinforcement learning"", ""observation space"", ""out-of-distribution generalization"", ""visuomotor control"", ""robotics"", ""manipulation""]",Appropriately designing the observation space of a vision-based manipulator and regularizing its representations leads to clear gains in learning stability and out-of-distribution generalization.,,,,
RLRXCV6DbEJ,2021,Accept (Spotlight),False,Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images,"[""Rewon Child""]","[""VAE"", ""generative modeling"", ""deep learning"", ""likelihood-based models""]","We argue deeper VAEs should perform better, implement one, and show it outperforms all PixelCNN-based autoregressive models in likelihood, while being substantially more efficient.",2011.10650,cs.LG,2020-11-20 21:35:31+00:00,2021-03-16 18:33:19+00:00
RLtqs6pzj1-,2022,Accept (Poster),True,Deep Ensembling with No Overhead for either Training or Testing: The All-Round Blessings of Dynamic Sparsity,"['Shiwei Liu', 'Tianlong Chen', 'Zahra Atashgahi', 'Xiaohan Chen', 'Ghada Sokar', 'Elena Mocanu', 'Mykola Pechenizkiy', 'Zhangyang Wang', 'Decebal Constantin Mocanu']","[""efficient ensemble"", ""FreeTickets"", ""dynamic sparse training"", ""deep ensemble"", ""dynamic sparsity""]","We propose an efficient ensemble learning framework FreeTickets via dynamic spasity, which is more efficient to train and inference than a single dense model, while matching the performance of the naive dense ensemble.",2106.14568,cs.LG,2021-06-28 10:48:20+00:00,2022-02-07 12:21:13+00:00
RMv-5wMMrE3,2022,Reject,False,Cell2State: Learning Cell State Representations From Barcoded Single-Cell Gene-Expression Transitions ,"['Yu Wu', 'Joseph Chahn Kim', 'Chengzhuo Ni', 'Le Cong', 'Mengdi Wang']",[],,,,,
RNf9AgtRtL,2022,Reject,False,Continuous Control With Ensemble Deep Deterministic Policy Gradients,"['Piotr Januszewski', 'Mateusz Olko', 'MichaÅ KrÃ³likowski', 'Jakub Swiatkowski', 'Marcin Andrychowicz', 'Åukasz KuciÅski', 'Piotr MiÅoÅ']","[""deep learning"", ""reinforcement learning"", ""ensemble learning"", ""MuJoCo"", ""continuous control"", ""stable performance"", ""deterministic policy gradient""]","We conduct an empirical analysis of multiple tools from the RL toolbox in the continuous control setting and propose Ensemble Deep Deterministic Policy Gradients (ED2), which achieves state-of-the-art performance.",,,,
RNnKhz25N1O,2022,Reject,False,Low-Cost Algorithmic Recourse for Users With Uncertain Cost Functions,"['Prateek Yadav', 'Peter Hase', 'Mohit Bansal']","[""Explainability"", ""Interpretability"", ""Counterfactuals"", ""Algorithmic Recourse"", ""Black-box Models"", ""Machine Learning"", ""Accountability"", ""Consumer Protection"", ""Adverse Action Notices""]",Providing individualized recourse to users with unknown feature preferences and cost functions.,,,,
ROpoUxw23oP,2022,Reject,False,Differentiable Hyper-parameter Optimization,"['Bozhou Chen', 'Hongzhi Wang', 'Chenmin Ba']","[""Hyper-parameter Optimization""]",We fine-tune channel size and some other hyper-parameters differentiable in a single training session by making these hyper-parameters differentiable.,,,,
RQ3xUXjZWMO,2022,Reject,False,Implicit Jacobian regularization weighted with impurity of probability output,"['Sungyoon Lee', 'Jinseong Park', 'Jaewook Lee']","[""deep learning"", ""gradient descent"", ""implicit bias"", ""implicit regularization"", ""Hessian"", ""sharpness""]",We have found implicit regularization effects in gradient descent on the Jacobian norm weighted with the impurity of the probability output.,,,,
RQ428ZptQfU,2022,Accept (Poster),False,A Deep Variational Approach to Clustering Survival Data,"['Laura Manduchi', 'RiÄards MarcinkeviÄs', 'Michela C. Massi', 'Thomas Weikert', 'Alexander Sauter', 'Verena Gotta', 'Timothy MÃ¼ller', 'Flavio Vasella', 'Marian C. Neidert', 'Marc Pfister', 'Bram Stieltjes', 'Julia E Vogt']","[""survival analysis"", ""clustering"", ""healthcare"", ""variational autoencoders"", ""deep generative models""]",We introduce a novel semi-supervised probabilistic approach to cluster survival data,,,,
RQIvNJDHwy,2022,Reject,True,Improving Neural Network Generalization via Promoting Within-Layer Diversity,"['Firas Laakom', 'Jenni Raitoharju', 'Alexandros Iosifidis', 'Moncef Gabbouj']","[""deep learning"", ""regularization"", ""overfitting"", ""learning theory"", ""neural network""]",We propose an additional loss for neural network training promoting within-layer diversity. We provide theoretical analysis and extensive empirical study confirming the superiority of the proposed approach.,2106.06012,cs.LG,2021-06-10 19:14:45+00:00,2021-06-10 19:14:45+00:00
RQLLzMCefQu,2022,Accept (Oral),True,Provably Filtering Exogenous Distractors using Multistep Inverse Dynamics,"['Yonathan Efroni', 'Dipendra Misra', 'Akshay Krishnamurthy', 'Alekh Agarwal', 'John Langford']","[""Reinforcement Learning Theory"", ""Invariant Representation"", ""Rich Observation Reinforcement Learning"", ""Exogenous Noise"", ""Inverse Dynamics""]",,2110.08847,cs.LG,2021-10-17 15:21:27+00:00,2021-10-17 15:21:27+00:00
RRGVCN8kjim,2022,Accept (Poster),False,Sparse DETR: Efficient End-to-End Object Detection with Learnable Sparsity,"['Byungseok Roh', 'JaeWoong Shin', 'Wuhyun Shin', 'Saehoon Kim']","[""Transformer Query Sparsification Mechanism"", ""Efficient End-to-End Object Detection""]",Sparse DETR is an efficient end-to-end object detector that sparsifies encoder queries by using the learnable decoder attention map predictor. It achieves better performance than Deformable DETR even with only 10% encoder queries on the COCO dataset.,2111.14330,cs.CV,2021-11-29 05:22:46+00:00,2021-11-29 05:22:46+00:00
RRj7DcsPjT,2022,Reject,False,Revisiting Layer-wise Sampling in Fast Training for Graph Convolutional Networks,"['Yifan Chen', 'Tianning Xu', 'Dilek Hakkani-Tur', 'Di Jin', 'Yun Yang', 'Ruoqing Zhu']","[""GCN"", ""efficient GCN"", ""sampling""]",We revisit two issues in past layer-wise sampling methods.,,,,
RSU17UoKfJF,2021,Accept (Poster),False,R-GAP: Recursive Gradient Attack on Privacy,"[""Junyi Zhu"", ""Matthew B. Blaschko""]","[""privacy leakage from gradients"", ""federated learning"", ""collaborative learning""]",,,,,
RShaMexjc-x,2022,Accept (Poster),True,Semi-relaxed Gromov-Wasserstein divergence and applications on graphs,"['CÃ©dric Vincent-Cuaz', 'RÃ©mi Flamary', 'Marco Corneli', 'Titouan Vayer', 'Nicolas Courty']","[""Optimal Transport"", ""Graph Learning""]","A new transport based divergence between structured data induced by the relaxation of a mass constraint of the Gromov-Wasserstein problem, leading to new SOTA performances for unsupervised ML applications on graphs.",2110.02753,cs.LG,2021-10-06 13:38:31+00:00,2022-01-04 11:05:23+00:00
RSn0s-T-qoy,2021,Reject,False,Multi-View Disentangled Representation,"[""Zongbo Han"", ""Changqing Zhang"", ""Huazhu Fu"", ""Qinghua Hu"", ""Joey Tianyi Zhou""]",[],,,,,
RVANVvSi8MZ,2021,Reject,False,Weighted Line Graph Convolutional Networks,"[""Hongyang Gao"", ""Shuiwang Ji""]","[""Line graph""]","In this work, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges.",,,,
RVdN1-eDZ1b,2022,Reject,False,Plug-In Inversion: Model-Agnostic Inversion for Vision with Data Augmentations,"['Amin Ghiasi', 'Hamid Kazemi', 'Steven Reich', 'Chen Zhu', 'Micah Goldblum', 'Tom Goldstein']",[],,2201.12961,cs.CV,2022-01-31 02:12:45+00:00,2022-01-31 02:12:45+00:00
RW_GTtTfHJ6,2022,Reject,True,Causal Reinforcement Learning using Observational and Interventional Data,"['Maxime Gasse', 'Damien GRASSET', 'Guillaume Gaudron', 'Pierre-Yves Oudeyer']","[""reinforcement learning"", ""causality"", ""confounding""]","We formulate reinforcement learning as a causal problem, and present a provably efficient method to address a scenario where offline data originating from a confounded policy is available for training.",2106.14421,cs.LG,2021-06-28 06:58:20+00:00,2021-06-28 06:58:20+00:00
RXQ-FPbQYVn,2022,Accept (Poster),False,Anti-Concentrated Confidence Bonuses For Scalable Exploration,"['Jordan T. Ash', 'Cyril Zhang', 'Surbhi Goel', 'Akshay Krishnamurthy', 'Sham M. Kakade']","[""deep reinforcement learning"", ""reinforcement learning"", ""bandits"", ""exploration""]",,,,,
RayUtcIlGz,2021,Reject,False,Training Invertible Linear Layers through Rank-One Perturbations,"[""Andreas Kr\u00e4mer"", ""Jonas K\u00f6hler"", ""Frank Noe""]","[""Parameter Perturbation"", ""Reparameterization"", ""Invertible Neural Networks"", ""Normalizing Flows"", ""Rank-one update""]",Optimization of general invertible matrices via parameterized perturbations.,,,,
RbVp8ieInU7,2022,Reject,True,Low-rank Matrix Recovery with Unknown Correspondence,"['Zhiwei Tang', 'Tsung-Hui Chang', 'Xiaojing Ye', 'Hongyuan Zha']","[""low-rank matrix recovery"", ""optimal transport"", ""min-max optimization"", ""permutation matrix""]","We study an important and practical matrix recovery problem that is less probed in the existing literature from both theoretical and algorithmic aspects, and propose a highly efficient algorithm that works well in many scenarios.",2110.07959,cs.LG,2021-10-15 09:27:50+00:00,2021-10-18 03:10:41+00:00
RcJHy18g1M,2021,Reject,False,Outlier Preserving Distribution Mapping Autoencoders ,"[""Walter Gerych"", ""Elke Rundensteiner"", ""Emmanuel Agu""]",[],A novel type of autoencoder that encourages outliers in the feature space to be easily identifiable in the latent space ,,,,
RcjRb9pEQ-Q,2021,Reject,False,Fine-grained Synthesis of Unrestricted Adversarial Examples,"[""Omid Poursaeed"", ""Tianxing Jiang"", ""Yordanos Abraham Goshu"", ""Harry Yang"", ""Serge Belongie"", ""Ser-Nam Lim""]","[""adversarial examples"", ""unrestricted attacks"", ""generative models"", ""adversarial training"", ""generative adversarial networks""]","A novel approach for fine-grained generation of unrestricted adversarial examples in classification, segmentation and detection which improves the model's performance on clean images.",,,,
Rcmk0xxIQV,2021,Accept (Poster),True,QPLEX: Duplex Dueling Multi-Agent Q-Learning,"[""Jianhao Wang"", ""Zhizhou Ren"", ""Terry Liu"", ""Yang Yu"", ""Chongjie Zhang""]","[""Multi-agent reinforcement learning"", ""Value factorization"", ""Dueling structure""]",A novel multi-agent Q-learning algorithm with a complete IGM (Individual-Global-Max) function class.,2008.01062,cs.LG,2020-08-03 17:52:09+00:00,2021-10-04 01:36:59+00:00
Rd138pWXMvG,2021,Accept (Poster),True,A statistical theory of cold posteriors in deep neural networks,"[""Laurence Aitchison""]","[""Bayesian inference"", ""cold posteriors"", ""sgld""]",We develop a generative model of dataset curation that explains the cold-posterior effect,2008.05912,stat.ML,2020-08-13 13:46:58+00:00,2021-04-27 14:33:30+00:00
RdJVFCHjUMI,2022,Accept (Poster),True,An Explanation of In-context Learning as Implicit Bayesian Inference,"['Sang Michael Xie', 'Aditi Raghunathan', 'Percy Liang', 'Tengyu Ma']","[""in-context learning"", ""language modeling"", ""pre-training"", ""GPT-3""]","In-context learning emerges both theoretically and empirically when the pretraining distribution is a mixture distribution, resulting in the language model implicitly performing Bayesian inference in its forward pass.",2111.02080,cs.CL,2021-11-03 09:12:33+00:00,2021-12-18 17:52:54+00:00
RdhjoXl-SDG,2021,Reject,False,Multiscale Invertible Generative Networks for High-Dimensional Bayesian Inference,"[""Shumao Zhang"", ""Thomas Hou"", ""Pengchuan Zhang""]",[],,,,,
RepN5K31PT3,2021,Reject,False,On the Dynamic Regret of Online Multiple Mirror Descent,"[""Nima Eshraghi"", ""and Ben Liang""]","[""Online learning"", ""Online Convex Optimization"", ""Mirror Descent""]",,,,,
Rf58LPCwJj0,2022,Accept (Poster),False,Optimal Representations for Covariate Shift,"['Yangjun Ruan', 'Yann Dubois', 'Chris J. Maddison']","[""distribution shift"", ""domain generalization"", ""representation learning"", ""self-supervised learning"", ""invariance"", ""robustness""]",We give a simple variational objective whose optima are exactly the set of representations that are robust under covariate shift,2201.00057,cs.LG,2021-12-31 21:02:24+00:00,2021-12-31 21:02:24+00:00
RftryyYyjiG,2022,Accept (Poster),False,Exploring extreme parameter compression for pre-trained language models,"['Benyou Wang', 'Yuxin Ren', 'Lifeng Shang', 'Xin Jiang', 'Qun Liu']","[""pre-trained language models"", ""tensor decomposition"", ""compression"", ""BERT""]",,,,,
RgDq8-AwvtN,2021,Reject,True,"Model-Based Robust Deep Learning: Generalizing to Natural, Out-of-Distribution Data","[""Alexander Robey"", ""Hamed Hassani"", ""George J. Pappas""]","[""robustness"", ""out-of-distribution generalization"", ""natural variation"", ""deep learning""]","We provide algorithms that can be used to significantly improve robustness against natural, out-of-distribution shifts in the data distribution.",2005.10247,cs.LG,2020-05-20 13:46:31+00:00,2020-11-02 13:20:37+00:00
Rh3khfuQUYk,2022,Reject,False,Iterative Decoding for Compositional Generalization in Transformers,"['Luana Ruiz', 'Joshua Ainslie', 'Santiago Ontanon']","[""compositional generalization"", ""transformer"", ""compositionality"", ""deep learning"", ""NLP""]","This paper introduces iterative decoding, an alternative to seq2seq learning that (i) improves transformer compositional generalization and (ii) evidences that, in general, seq2seq transformers do not learn iterations that are not unrolled.",,,,
RhB1AdoFfGE,2022,Accept (Poster),True,Sample and Computation Redistribution for Efficient Face Detection,"['Jia Guo', 'Jiankang Deng', 'Alexandros Lattas', 'Stefanos Zafeiriou']","[""efficient face detection"", ""computation redistribution"", ""sample redistribution""]",We search for optimised computation distribution and training sample distribution for the task of face detection.,2105.04714,cs.CV,2021-05-10 23:51:14+00:00,2021-05-10 23:51:14+00:00
Rhl8IoYzdSI,2021,Reject,False,ChePAN: Constrained Black-Box Uncertainty Modelling with Quantile Regression,"[""Axel Brando"", ""Joan Gimeno"", ""Jose Antonio Rodriguez-Serrano"", ""Jordi Vitria""]","[""Uncertainty modelling"", ""Deep Learning"", ""Black Box"", ""Aleatoric"", ""Quantile Regression"", ""Chebyshev Polynomial"", ""Neural networks""]","ChePAN allows us to model the aleatoric uncertainty constrained to an existing pointwise preditictive system considered as a black box, i.e. without making assumptions about its internal structure.",,,,
Rhsu5qD36cL,2021,Accept (Spotlight),False,Sequential Density Ratio Estimation for Simultaneous Optimization of Speed and Accuracy,"[""Akinori F Ebihara"", ""Taiki Miyagawa"", ""Kazuyuki Sakurai"", ""Hitoshi Imaoka""]","[""Sequential probability ratio test"", ""Early classification"", ""Density ratio estimation""]","With a novel sequential density estimation algorithm, we relax critical assumptions of the classical Sequential Probability Ratio Test to be applicable in various real-world scenarios.",,,,
Rivn22SJjg9,2022,Reject,False,Contrastive Embeddings for Neural Architectures,"['Daniel Hesslow', 'Iacopo Poli']",[],,,,,
Rj-x5_ej6B,2022,Reject,False,Partial Information as Full: Reward Imputation with Sketching in Bandits,"['Xiao Zhang', 'Ninglu Shao', 'Zihua Si', 'Jun Xu', 'Wenhan Wang', 'hanjing su', 'Ji-Rong Wen']","[""reward imputation"", ""bandit"", ""sketching"", ""regret analysis""]",,,,,
RjMtFbmETG,2022,Reject,False,Resmax: An Alternative Soft-Greedy Operator for Reinforcement Learning,"['Erfan Miahi', 'Revan MacQueen', 'Alex Ayoub', 'Abbas Masoumzadeh', 'Martha White']","[""exploration"", ""reinforcement learning"", ""action-value methods"", ""soft-greedy operator"", ""softmax"", ""mellowmax"", ""epsilon-greedy"", ""suboptimality gap""]","We propose resmax, a new soft-greedy operator for reinforment learning, which is a non-expansion and avoids overemphasis, making it a desirable replacement for the Boltzmann softmax operator.",,,,
RkqYJw5TMD7,2021,Reject,False,Test-Time Adaptation and Adversarial Robustness,"[""Xi Wu"", ""Yang Guo"", ""Tianqi Li"", ""Jiefeng Chen"", ""Qicheng Lao"", ""Yingyu Liang"", ""Somesh Jha""]","[""test-time adaptation"", ""adversarial robustness"", ""unsupervised domain adaptation"", ""threat model"", ""maximin game""]",Study the interaction between test-time adaptation and adversarial robustness.,,,,
Rld-9OxQ6HU,2021,Reject,False,MC-LSTM: Mass-conserving LSTM,"[""Pieter-Jan Hoedt"", ""Frederik Kratzert"", ""Daniel Klotz"", ""Christina Halmich"", ""Markus Holzleitner"", ""Grey Nearing"", ""Sepp Hochreiter"", ""G\u00fcnter Klambauer""]","[""LSTM"", ""RNN"", ""mass-conservation"", ""neural arithmetic units"", ""inductive bias"", ""hydrology""]",We present a mass-conserving variant of LSTM that excels as neural arithmetic units and at flood forecasting,,,,
RmB-88r9dL,2021,Accept (Oral),False,VCNet and Functional Targeted Regularization For Learning Causal Effects of Continuous Treatments,"[""Lizhen Nie"", ""Mao Ye"", ""qiang liu"", ""Dan Nicolae""]","[""causal inference"", ""continuous treatment effect"", ""doubly robustness""]",We propose a varying coefficient network and a functional targeted regularization for estimating continuous treatment.,2103.07861,cs.LG,2021-03-14 07:37:28+00:00,2021-03-14 07:37:28+00:00
RmB-zwXOIVC,2021,Reject,True,Imitation with Neural Density Models,"[""Kuno Kim"", ""Akshat Jindal"", ""Yang Song"", ""Jiaming Song"", ""Yanan Sui"", ""Stefano Ermon""]","[""Imitation Learning"", ""Reinforcement Learning"", ""Density Estimation"", ""Density Model"", ""Maximum Entropy RL"", ""Mujoco""]",New Imitation Learning framework based on density estimation that achieves good demonstration efficiency,2010.09808,cs.LG,2020-10-19 19:38:36+00:00,2020-10-19 19:38:36+00:00
RmcPm9m3tnk,2021,Accept (Poster),False,Generative Scene Graph Networks,"[""Fei Deng"", ""Zhuo Zhi"", ""Donghun Lee"", ""Sungjin Ahn""]","[""object-centric representations"", ""generative modeling"", ""scene generation"", ""variational autoencoders""]",We propose the first object-centric generative model capable of unsupervised scene graph discovery from multi-object scenes without access to predefined parts.,,,,
Ro_zAjZppv,2022,Accept (Poster),True,Tracking the risk of a deployed model and detecting harmful distribution shifts,"['Aleksandr Podkopaev', 'Aaditya Ramdas']","[""Distribution shift"", ""sequential testing""]",,2110.06177,stat.ML,2021-10-12 17:21:41+00:00,2021-11-28 23:18:32+00:00
RovX-uQ1Hua,2021,Accept (Poster),True,Text Generation by Learning from Demonstrations,"[""Richard Yuanzhe Pang"", ""He He""]","[""text generation"", ""learning from demonstrations"", ""nlp""]",,2009.07839,cs.CL,2020-09-16 17:58:37+00:00,2021-03-03 03:43:28+00:00
RpprvYz0xTM,2021,Reject,False,A Flexible Framework for Discovering Novel Categories with Contrastive Learning,"[""Xuhui Jia"", ""Kai Han"", ""Yukun Zhu"", ""Bradley Green""]","[""deep learning"", ""novel classes"", ""clustering"", ""self-supervised learning"", ""unsupervised learning""]",A flexible end-to-end framework to discover novel categories in single- or multi-modal unlabelled data.,,,,
Rq31tXaqXq,2021,Reject,False,VideoFlow: A Framework for Building Visual Analysis Pipelines,"[""Yue Wu"", ""Jianqiang Huang"", ""Jiangjie Zhen"", ""Guokun Wang"", ""Chen Shen"", ""Chang Zhou"", ""Xian-Sheng Hua""]","[""Computation graph"", ""Resource"", ""Computer vision"", ""Deep learning"", ""Framework"", ""Software""]","a flexible, efficient, extensible and secure framework to build visual analysis pipelines for both the academia and industry.",,,,
RqCC_00Bg7V,2021,Accept (Poster),False,Blending MPC & Value Function Approximation for Efficient Reinforcement Learning,"[""Mohak Bhardwaj"", ""Sanjiban Choudhury"", ""Byron Boots""]","[""reinforcement learning"", ""model-predictive control""]",A framework for blending model-predictive control and model-free value function learning to systematically trade-off bias due to approximate dynamics models and value functions learned from real data,2012.05909,cs.LG,2020-12-10 11:32:01+00:00,2021-04-13 18:07:49+00:00
RrIqhkFEpec,2021,Reject,True,Isometric Autoencoders,"[""Amos Gropp"", ""Matan Atzmon"", ""Yaron Lipman""]","[""manifold learning"", ""autoencoders""]",Introducing Isometric Autoencoder: a regularizer that promotes isometry of the decoder and pseudo-inverse of the encoder.,2006.09289,cs.LG,2020-06-16 16:31:57+00:00,2020-10-03 19:20:46+00:00
RrSuwzJfMQN,2021,Reject,False,TOWARDS NATURAL ROBUSTNESS AGAINST ADVERSARIAL EXAMPLES,"[""Haoyu Chu"", ""Shikui Wei"", ""Yao Zhao""]",[],,2012.02452,cs.LG,2020-12-04 08:12:38+00:00,2020-12-04 08:12:38+00:00
RriDjddCLN,2022,Accept (Poster),False,Language-driven Semantic Segmentation,"['Boyi Li', 'Kilian Q Weinberger', 'Serge Belongie', 'Vladlen Koltun', 'Rene Ranftl']","[""language-driven"", ""semantic segmentation"", ""zero-shot"", ""transformer""]",We present a language-driven approach that enables synthesis of zero-shot semantic segmentation models from arbitrary label sets at test time.,,,,
RtNpzLdHUAW,2021,Reject,False,Stochastic Subset Selection for Efficient Training and Inference of Neural Networks,"[""Andreis Bruno"", ""Tuan Nguyen"", ""Juho Lee"", ""Eunho Yang"", ""Sung Ju Hwang""]","[""efficient deep learning"", ""meta learning"", ""efficient training"", ""data compression"", ""instance selection""]",We learn a stochastic subset selection model for instance and pixel selection that reduces computational and storage cost.,,,,
Rty5g9imm7H,2022,Accept (Poster),False,Transformer Embeddings of Irregularly Spaced Events and Their Participants,"['Hongyuan Mei', 'Chenghao Yang', 'Jason Eisner']","[""irregular time series"", ""generative Transformers"", ""neuro-symbolic architectures"", ""logic programming""]",We design a generative continuous-time Transformer for embedding irregularly spaced events and their participants. ,,,,
RuC5ilX2m6O,2022,Reject,True,Local Patch AutoAugment with Multi-Agent Collaboration,"['Shiqi Lin', 'Tao Yu', 'Ruoyu Feng', 'Xin Li', 'Xin Jin', 'Zhibo Chen']","[""Automatic Data Augmentation"", ""Multi-Agent Reinforcement Learning""]","We propose a new automated data augmentation method, dubbed Patch AutoAugment, which aims to search for the joint optimal augmentation policies for patches in a multi-agent reinforcement learning manner.",2103.11099,cs.CV,2021-03-20 05:10:05+00:00,2021-10-18 08:52:45+00:00
RuUdMAU-XbI,2021,Reject,False,Dynamic Graph: Learning Instance-aware Connectivity for Neural Networks,"[""Kun Yuan"", ""Quanquan Li"", ""Dapeng Chen"", ""Aojun Zhou"", ""Junjie Yan""]","[""dynamic network"", ""data-dependent"", ""complete graph""]",Dynamic Graph Networks promote the model capacity by performing instance-aware connectivity for neural networks.,,,,
Rupm2vTg1pe,2022,Reject,False,The Infinite Contextual Graph Markov Model,"['Daniele Castellana', 'Federico Errica', 'Davide Bacciu', 'Alessio Micheli']","[""graph neurals networks"", ""graph classification"", ""probabilistic models""]",We design a deep probabilistic model for graphs that automatically selects most of its hyper-parameters,,,,
RwQZd8znR10,2021,Reject,True,Intrinsically Guided Exploration in Meta Reinforcement Learning,"[""Jin Zhang"", ""Jianhao Wang"", ""Hao Hu"", ""Tong Chen"", ""Yingfeng Chen"", ""Changjie Fan"", ""Chongjie Zhang""]","[""Meta reinforcement learning"", ""Exploration"", ""Information gain""]","We propose a novel meta-RL algorithm that incorporates information-theoretic intrinsic motivations, and achieves efficient exploration in both meta-training and adaptation.",2006.08170,cs.AI,2020-06-15 06:56:18+00:00,2021-11-12 03:15:55+00:00
Rw_vo-wIAa,2021,Reject,False,Multi-agent Policy Optimization with Approximatively Synchronous Advantage Estimation,"[""Lipeng Wan"", ""Xuwei Song"", ""Xuguang Lan"", ""Nanning Zheng""]","[""multi-agent reinforcement learning"", ""policy optimization"", ""advantage estimation"", ""credit assignment""]",,2012.03488,cs.LG,2020-12-07 07:29:19+00:00,2021-05-08 07:13:37+00:00
Rx9luEzcSoy,2022,Reject,False,Lottery Image Prior,"['Qiming Wu', 'Xiaohan Chen', 'Yifan Jiang', 'Pan Zhou', 'Zhangyang Wang']",[],,,,,
Rx_nbGdtRQD,2022,Reject,False,Coherent and Consistent Relational Transfer Learning with Autoencoders,"['Harald Stromfelt', 'Luke Dickens', 'Artur Garcez', 'Alessandra Russo']",[],,,,,
RxplU3vmBx,2022,Accept (Spotlight),False,Looking Back on Learned Experiences  For Class/task Incremental Learning,"['Mozhgan PourKeshavarzi', 'Guoying Zhao', 'Mohammad Sabokrou']","[""Deepl Learning"", ""Class Incremental learning"", ""Continual learning"", ""Experiences""]",,,,,
S0NsaRIxvQ,2022,Reject,False,Adversarial Style Transfer for Robust Policy Optimization in Reinforcement Learning,"['Md Masudur Rahman', 'Yexiang Xue']","[""Deep Reinforcement Learning"", ""Generalization in Reinforcement Learning""]",,,,,
S0UdquAnr9k,2021,Accept (Spotlight),False,Locally Free Weight Sharing for Network Width Search,"[""Xiu Su"", ""Shan You"", ""Tao Huang"", ""Fei Wang"", ""Chen Qian"", ""Changshui Zhang"", ""Chang Xu""]",[],One-shot locally free weight sharing supernet for searching optimal network width,2102.05258,cs.CV,2021-02-10 04:36:09+00:00,2021-02-24 13:31:12+00:00
S11KBYclx,2017,Accept (Poster),False,Learning Curve Prediction with Bayesian Neural Networks,"[""Aaron Klein"", ""Stefan Falkner"", ""Jost Tobias Springenberg"", ""Frank Hutter""]","[""Deep learning"", ""Applications""]",We present a general probabilistic method based on Bayesian neural networks to predit learning curves of iterative machine learning methods.,,,,
S1347ot3b,2018,Reject,False,Exploring Sentence Vectors Through Automatic Summarization,"[""Adly Templeton"", ""Jugal Kalita""]","[""Sentence Vectors"", ""Vector Semantics"", ""Automatic Summarization""]",A comparison and detailed analysis of various sentence embedding models through the real-world task of automatic summarization.,1810.07320,cs.CL,2018-10-16 23:57:37+00:00,2018-10-16 23:57:37+00:00
S13wCE9xx,2017,Reject,False,Riemannian Optimization for Skip-Gram Negative Sampling,"[""Alexander Fonarev"", ""Alexey Grinchuk"", ""Gleb Gusev"", ""Pavel Serdyukov"", ""Ivan Oseledets""]","[""Natural language processing"", ""Unsupervised Learning""]",We train word embeddings optimizing Skip-Gram Negative Sampling objective (known by word2vec) via Riemannian low-rank optimization framework,,,,
S14EogZAZ,2018,Reject,False,Acquiring Target Stacking Skills by Goal-Parameterized Deep Reinforcement Learning,"[""Wenbin Li"", ""Jeannette Bohg"", ""Mario Fritz""]",[],,,,,
S14g5s09tm,2019,Reject,False,Unseen Action Recognition with Unpaired Adversarial Multimodal Learning,"[""AJ Piergiovanni"", ""Michael S. Ryoo""]",[],,,,,
S14h9sCqYm,2019,Reject,False,Weakly-supervised Knowledge Graph Alignment with Adversarial Learning,"[""Meng Qu"", ""Jian Tang"", ""Yoshua Bengio""]","[""Knowledge Graph Alignment"", ""Generative Adversarial Network"", ""Weakly Supervised""]",This paper studies weakly-supervised knowledge graph alignment with adversarial training frameworks.,1907.03179,cs.LG,2019-07-06 20:31:13+00:00,2019-07-06 20:31:13+00:00
S1680_1Rb,2018,Reject,False,CAYLEYNETS: SPECTRAL GRAPH CNNS WITH COMPLEX RATIONAL FILTERS,"[""Ron Levie"", ""Federico Monti"", ""Xavier Bresson"", ""Michael M. Bronstein""]","[""Deep Learning"", ""Spectral Graph Convolutional Neural Networks""]",A spectral graph convolutional neural network with spectral zoom properties.,,,,
S16FPMgRZ,2018,Reject,False,Tensor Contraction & Regression Networks,"[""Jean Kossaifi"", ""Zack Chase Lipton"", ""Aran Khanna"", ""Tommaso Furlanello"", ""Anima Anandkumar""]","[""tensor contraction"", ""tensor regression"", ""network compression"", ""deep neural networks""]","We propose tensor contraction and low-rank tensor regression layers to preserve and leverage the multi-linear structure throughout the network, resulting in huge space savings with little to no impact on performance.",,,,
S17mtzbRb,2018,Reject,False,Forced Apart: Discovering Disentangled Representations Without Exhaustive Labels,"[""Alexey Romanov"", ""Anna Rumshisky""]","[""learning representation"", ""clustering"", ""loss""]",A novel loss component that forces the network to learn a representation that is well-suited for clustering during training for a classification task.,,,,
S18Su--CW,2018,Accept (Poster),False,Thermometer Encoding: One Hot Way To Resist Adversarial Examples,"[""Jacob Buckman"", ""Aurko Roy"", ""Colin Raffel"", ""Ian Goodfellow""]","[""Adversarial examples"", ""robust neural networks""]",Input discretization leads to robustness against adversarial examples,,,,
S191YzbRZ,2018,Reject,False,Prototype Matching Networks for Large-Scale Multi-label  Genomic Sequence Classification,"[""Jack Lanchantin"", ""Arshdeep Sekhon"", ""Ritambhara Singh"", ""Yanjun Qi""]","[""bioinformatics"", ""multi-label classification"", ""matching networks"", ""prototypes"", ""memory networks"", ""attention""]",We combine the matching network framework for few shot learning into a large scale multi-label model for genomic sequence classification.,,,,
S19dR9x0b,2018,Accept (Poster),False,Alternating Multi-bit Quantization for Recurrent Neural Networks,"[""Chen Xu"", ""Jianqiang Yao"", ""Zhouchen Lin"", ""Wenwu Ou"", ""Yuanbin Cao"", ""Zhirong Wang"", ""Hongbin Zha""]","[""Alternating Minimization"", ""Quantized Recurrent Neural Network"", ""Binary Search Tree""]",We propose a  new  quantization method and apply it to quantize RNNs for both compression and acceleration,,,,
S19eAF9ee,2017,Reject,False,Structured Sequence Modeling with Graph Convolutional Recurrent Networks,"[""Youngjoo Seo"", ""Micha\u00ebl Defferrard"", ""Pierre Vandergheynst"", ""Xavier Bresson""]","[""Structured prediction""]",This paper introduces a neural network to model graph-structured sequences,,,,
S1AG8zYeg,2017,Reject,False,Sentence Ordering using Recurrent Neural Networks,"[""Lajanugen Logeswaran"", ""Honglak Lee"", ""Dragomir Radev""]","[""Natural language processing"", ""Deep learning"", ""Applications""]",We consider the problem of organizing a given collection of sentences into a coherent order.,,,,
S1ANxQW0b,2018,Accept (Poster),False,Maximum a Posteriori Policy Optimisation,"[""Abbas Abdolmaleki"", ""Jost Tobias Springenberg"", ""Yuval Tassa"", ""Remi Munos"", ""Nicolas Heess"", ""Martin Riedmiller""]","[""Reinforcement Learning"", ""Variational Inference"", ""Control""]",,1806.06920,cs.LG,2018-06-14 12:46:23+00:00,2018-06-14 12:46:23+00:00
S1Auv-WRZ,2018,Invite to Workshop Track,False,Data Augmentation Generative Adversarial Networks,"[""Anthreas Antoniou"", ""Amos Storkey"", ""Harrison Edwards""]",[],Conditional GANs trained to generate data augmented samples of their conditional inputs used to enhance vanilla classification and one shot learning systems such as matching networks and pixel distance,,,,
S1Bb3D5gg,2017,Accept (Oral),False,Learning End-to-End Goal-Oriented Dialog,"[""Antoine Bordes"", ""Y-Lan Boureau"", ""Jason Weston""]",[],A new open dataset and testbed for training and evaluating end-to-end dialog systems in goal-oriented scenarios.,,,,
S1Bm3T_lg,2017,Invite to Workshop Track,False,Compositional Kernel Machines,"[""Robert Gens"", ""Pedro Domingos""]","[""Computer vision"", ""Supervised Learning""]",We propose a kernel method that combats the curse of dimensionality with an exponential number of virtual training instances efficiently composed from transformed sub-regions of the original ones.,,,,
S1CChZ-CZ,2018,Accept (Oral),False,Ask the Right Questions: Active Question Reformulation with Reinforcement Learning,"[""Christian Buck"", ""Jannis Bulian"", ""Massimiliano Ciaramita"", ""Wojciech Gajewski"", ""Andrea Gesmundo"", ""Neil Houlsby"", ""Wei Wang.""]","[""machine translation"", ""paraphrasing"", ""question answering"", ""reinforcement learning"", ""agents""]",We propose an agent that sits between the user and a black box question-answering system and which learns to reformulate questions to elicit the best possible answers,,,,
S1D8MPxA-,2018,Accept (Poster),False,Viterbi-based Pruning for Sparse Matrix with Fixed and High Index Compression Ratio,"[""Dongsoo Lee"", ""Daehyun Ahn"", ""Taesu Kim"", ""Pierce I. Chuang"", ""Jae-Joon Kim""]","[""pruning"", ""sparse matrix"", ""memory footprint"", ""model size"", ""model compression""]",We present a new pruning method and sparse matrix format to enable high index compression ratio and parallel index decoding process.,,,,
S1DWPP1A-,2018,Accept (Poster),False,Unsupervised Learning of Goal Spaces for Intrinsically Motivated Goal Exploration,"[""Alexandre P\u00e9r\u00e9"", ""S\u00e9bastien Forestier"", ""Olivier Sigaud"", ""Pierre-Yves Oudeyer""]","[""exploration; autonomous goal setting; diversity; unsupervised learning; deep neural network""]","We propose a novel Intrinsically Motivated Goal Exploration architecture with unsupervised learning of goal space representations, and evaluate how various implementations enable the discovery of a diversity of policies.",,,,
S1Dh8Tg0-,2018,Accept (Poster),False,Fix your classifier: the marginal value of training the last weight layer,"[""Elad Hoffer"", ""Itay Hubara"", ""Daniel Soudry""]",[],You can fix the classifier in neural networks without losing accuracy,,,,
S1E3Ko09F7,2019,Accept (Poster),False,L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data,"[""Jianbo Chen"", ""Le Song"", ""Martin J. Wainwright"", ""Michael I. Jordan""]","[""Model Interpretation"", ""Feature Selection""]","We develop two linear-complexity algorithms for model-agnostic model interpretation based on the Shapley value, in the settings where the contribution of features to the target is well-approximated by a graph-structured factorization.",,,,
S1E64jC5tm,2019,Reject,False,The Forward-Backward Embedding of Directed Graphs,"[""Thomas Bonald"", ""Nathan De Lara""]","[""Graph embedding"", ""SVD"", ""random walk"", ""co-clustering""]",,,,,
S1EERs09YQ,2019,Accept (Poster),False,Discovery of Natural Language Concepts in Individual Units of CNNs,"[""Seil Na"", ""Yo Joong Choe"", ""Dong-Hyun Lee"", ""Gunhee Kim""]","[""interpretability of deep neural networks"", ""natural language representation""]",We show that individual units in CNN representations learned in NLP tasks are selectively responsive to natural language concepts.,,,,
S1EHOsC9tX,2019,Accept (Poster),False,Towards the first adversarially robust neural network model on MNIST,"[""Lukas Schott"", ""Jonas Rauber"", ""Matthias Bethge"", ""Wieland Brendel""]","[""adversarial examples"", ""MNIST"", ""robustness"", ""deep learning"", ""security""]",,,,,
S1EfylZ0Z,2018,Reject,False,Anomaly Detection with Generative Adversarial Networks,"[""Lucas Deecke"", ""Robert Vandermeulen"", ""Lukas Ruff"", ""Stephan Mandt"", ""Marius Kloft""]","[""Anomaly Detection"", ""Generative Adversarial Networks"", ""Deep Learning"", ""Inverse Problems""]",We propose a method for anomaly detection with GANs by searching the generator's latent space for good sample representations.,,,,
S1Euwz-Rb,2018,Accept (Poster),False,Compositional Attention Networks for Machine Reasoning,"[""Drew A. Hudson"", ""Christopher D. Manning""]","[""Deep Learning"", ""Reasoning"", ""Memory"", ""Attention"", ""VQA"", ""CLEVR"", ""Recurrent Neural Networks"", ""Module Networks"", ""Compositionality""]","We present a novel architecture, based on dynamic memory, attention and composition for the task of machine reasoning.",,,,
S1EwLkW0W,2018,Reject,False,"Dissecting Adam: The Sign, Magnitude and Variance of Stochastic Gradients","[""Lukas Balles"", ""Philipp Hennig""]","[""Stochastic Optimization"", ""Deep Learning""]",Analyzing the popular Adam optimizer,,,,
S1EzRgb0W,2018,Reject,False,Explaining the Mistakes of Neural Networks with Latent Sympathetic Examples,"[""Riaan Zoetmulder"", ""Efstratios Gavves"", ""Peter O'Connor""]","[""Deep learning"", ""Adversarial Examples"", ""Difference Target Propagation"", ""Generative Modelling"", ""Classifiers"", ""Explaining"", ""Sympathetic Examples""]",New way of explaining why a neural network has misclassified an image,,,,
S1FFLWWCZ,2018,Reject,False,"LSD-Net: Look, Step and Detect for Joint Navigation and Multi-View Recognition with Deep Reinforcement Learning","[""N dinesh reddy""]",[],,,,,
S1FQEfZA-,2018,Reject,False,A Classification-Based Perspective on GAN Distributions,"[""Shibani Santurkar"", ""Ludwig Schmidt"", ""Aleksander Madry""]","[""Generative adversarial networks"", ""classification"", ""benchmark"", ""mode collapse"", ""diversity""]",We propose new methods for evaluating and quantifying the quality of synthetic GAN distributions from the perspective of classification tasks,,,,
S1GDXzb0b,2018,Reject,False,Model-based imitation learning from state trajectories,"[""Subhajit Chaudhury"", ""Daiki Kimura"", ""Tadanobu Inoue"", ""Ryuki Tachibana""]","[""Model based reinforcement learning"", ""Imitation learning"", ""dynamics model""]",Learning to imitate an expert in the absence of optimal actions learning a dynamics model while exploring the environment.,,,,
S1GUgxgCW,2018,Reject,False,Latent Topic Conversational Models,"[""Tsung-Hsien Wen"", ""Minh-Thang Luong""]","[""conversational modeling"", ""dialogue"", ""chitchat"", ""open-domain dialogue"", ""topic model"", ""neural variational inference"", ""human evaluation"", ""latent variable model"", ""gaussian reparameterisation trick""]","Latent Topic Conversational Model, a hybrid of seq2seq and neural topic model to generate more diverse and interesting responses.",,,,
S1G_cj05YQ,2019,Reject,False,Activity Regularization for Continual Learning,"[""Quang H. Pham"", ""Steven C. H. Hoi""]","[""continual learning"", ""regularization""]",This paper develops a novel regularization for continual learning,,,,
S1GcHsAqtm,2019,Reject,False,Adaptive Pruning of Neural Language Models for Mobile Devices,"[""Raphael Tang"", ""Jimmy Lin""]","[""Inference-time pruning"", ""Neural Language Models""]",,,,,
S1GkToR5tm,2019,Accept (Poster),False,Discriminator Rejection Sampling,"[""Samaneh Azadi"", ""Catherine Olsson"", ""Trevor Darrell"", ""Ian Goodfellow"", ""Augustus Odena""]","[""GANs"", ""rejection sampling""]",We use a GAN discriminator to perform an approximate rejection sampling scheme on the output of the GAN generator.,,,,
S1HEBe_Jl,2017,Reject,False,Learning to Protect Communications with Adversarial Neural Cryptography,"[""Mart\u00edn Abadi"", ""David G. Andersen""]",[],Adversarial training of neural networks to learn rudimentary forms of encryption with no pre-specified algorithms,,,,
S1HcOI5le,2017,Reject,False,OMG: Orthogonal Method of Grouping With Application of K-Shot Learning,"[""Haoqi Fan"", ""Yu Zhang"", ""Kris M. Kitani""]",[],,,,,
S1HlA-ZAZ,2018,Accept (Poster),False,The Kanerva Machine: A Generative Distributed Memory,"[""Yan Wu"", ""Greg Wayne"", ""Alex Graves"", ""Timothy Lillicrap""]","[""memory"", ""generative model"", ""inference"", ""neural network"", ""hierarchical model""]",A generative memory model that combines slow-learning neural networks and a fast-adapting linear Gaussian model as memory.,,,,
S1J0E-71l,2017,Reject,False,Surprisal-Driven Feedback in Recurrent Networks,"[""Kamil Rocki""]","[""Unsupervised Learning"", ""Applications"", ""Deep learning""]","In this paper, we add surprisal as additional input to RNN , which take into account past error information when making new predictions. We extend SOTA on character-level language modelling, achieving 1.37 bits/char on wikipedia dataset.",,,,
S1J2ZyZ0Z,2018,Accept (Poster),False,Interpretable Counting for Visual Question Answering,"[""Alexander Trott"", ""Caiming Xiong"", ""Richard Socher""]","[""Counting"", ""VQA"", ""Object detection""]",We perform counting for visual question answering; our model produces interpretable outputs by counting directly from detected objects.,,,,
S1JG13oee,2017,Reject,False,b-GAN: Unified Framework of Generative Adversarial Networks,"[""Masatosi Uehara"", ""Issei Sato"", ""Masahiro Suzuki"", ""Kotaro Nakayama"", ""Yutaka Matsuo""]","[""Deep learning"", ""Unsupervised Learning""]",New Unified Framework of Generative Adversarial Networks using Bregman divergence beyond f-GAN,,,,
S1JHhv6TW,2018,Accept (Oral),False,Boosting Dilated Convolutional Networks with Mixed Tensor Decompositions,"[""Nadav Cohen"", ""Ronen Tamari"", ""Amnon Shashua""]","[""Deep Learning"", ""Expressive Efficiency"", ""Dilated Convolutions"", ""Tensor Decompositions""]","We introduce the notion of mixed tensor decompositions, and use it to prove that interconnecting dilated convolutional networks boosts their expressive power.",,,,
S1Jhfftgx,2017,Reject,False,Enforcing constraints on outputs with unconstrained inference,"[""Jay Yoon Lee"", ""Michael L. Wick"", ""Jean-Baptiste Tristan""]","[""Natural language processing"", ""Structured prediction"", ""Deep learning""]","An inference method for enforcing hard constraints on the outputs of neural networks without combinatorial search, with applications in NLP and structured prediction.",,,,
S1LVSrcge,2017,Accept (Poster),False,Variable Computation in Recurrent Neural Networks,"[""Yacine Jernite"", ""Edouard Grave"", ""Armand Joulin"", ""Tomas Mikolov""]","[""Natural language processing"", ""Deep learning""]","We show that an RNN can learn to control the amount of computation it does at each time step, leading to better efficiency and performance as well as discovering time patterns of interest.",,,,
S1LXVnxRb,2018,Invite to Workshop Track,False,Cross-Corpus Training with TreeLSTM for the Extraction of Biomedical Relationships from Text,"[""Legrand Jo\u00ebl"", ""Yannick Toussaint"", ""Chedy Ra\u00efssi"", ""Adrien Coulet""]","[""Relationships Extraction"", ""Deep Learning"", ""TreeLSTM"", ""NLP""]",,,,,
S1M6Z2Cctm,2019,Accept (Poster),False,Harmonic Unpaired Image-to-image Translation,"[""Rui Zhang"", ""Tomas Pfister"", ""Jia Li""]","[""unpaired image-to-image translation"", ""cyclegan"", ""smoothness constraint""]",Smooth regularization over sample graph for unpaired image-to-image translation results in significantly improved consistency,,,,
S1MAriC5F7,2019,Reject,False,Massively Parallel Hyperparameter Tuning,"[""Liam Li"", ""Kevin Jamieson"", ""Afshin Rostamizadeh"", ""Ekaterina Gonina"", ""Moritz Hardt"", ""Ben Recht"", ""Ameet Talwalkar""]","[""hyperparameter optimization"", ""automl""]",,,,,
S1MB-3RcF7,2019,Reject,False,Multi-objective training of Generative Adversarial Networks with multiple discriminators,"[""Isabela Albuquerque"", ""Jo\u00e3o Monteiro"", ""Thang Doan"", ""Breandan Considine"", ""Tiago Falk"", ""Ioannis Mitliagkas""]","[""Generative Adversarial Networks"", ""Multi-objective optimization"", ""Generative models""]","We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. ",,,,
S1MQ6jCcK7,2019,Reject,False,ChoiceNet: Robust Learning by  Revealing Output Correlations,"[""Sungjoon Choi"", ""Sanghoon Hong"", ""Kyungjae Lee"", ""Sungbin Lim""]","[""Robust Deep Learning"", ""weakly supervised learning""]",,,,,
S1MeM2RcFm,2019,Reject,False,BlackMarks: Black-box Multi-bit Watermarking for Deep Neural Networks,"[""Huili Chen"", ""Bita Darvish Rouhani"", ""Farinaz Koushanfar""]","[""Digital Watermarking"", ""IP Protection"", ""Deep Neural Networks""]",Proposing the first watermarking framework for multi-bit signature embedding and extraction using the outputs of the DNN. ,,,,
S1NHaMW0b,2018,Reject,False,ShakeDrop regularization,"[""Yoshihiro Yamada"", ""Masakazu Iwamura"", ""Koichi Kise""]",[],,,,,
S1OufnIlx,2017,Invite to Workshop Track,False,Adversarial examples in the physical world,"[""Alexey Kurakin"", ""Ian J. Goodfellow"", ""Samy Bengio""]","[""Supervised Learning"", ""Computer vision""]",,,,,
S1Ow_e-Rb,2018,Reject,False,How do deep convolutional neural networks learn from raw audio waveforms?,"[""Yuan Gong"", ""Christian Poellabauer""]","[""Convolutional neural networks"", ""Audio processing"", ""Speech processing""]",,,,,
S1PWi_lC-,2018,Reject,False,Multi-task Learning on MNIST Image Datasets,"[""Po-Chen Hsieh"", ""Chia-Ping Chen""]","[""multi-task learning"", ""MNIST"", ""image recognition""]",multi-task learning works ,,,,
S1Q79heRW,2018,Reject,False,Unsupervised Learning of Entailment-Vector Word Embeddings,"[""James Henderson""]","[""word embeddings"", ""natural language semantics"", ""entailment"", ""unsupervised learning"", ""distributional semantics""]","We train word embeddings based on entailment instead of similarity, successfully predicting lexical entailment.",,,,
S1QefL5ge,2017,Invite to Workshop Track,False,Online Structure Learning for Sum-Product Networks with Gaussian Leaves,"[""Wilson Hsu"", ""Agastya Kalra"", ""Pascal Poupart""]","[""Unsupervised Learning"", ""Deep learning""]",This paper describes the first online structure learning technique for continuous SPNs with Gaussian leaves.,,,,
S1RP6GLle,2017,Accept (Oral),False,Amortised MAP Inference for Image Super-resolution,"[""Casper Kaae S\u00f8nderby"", ""Jose Caballero"", ""Lucas Theis"", ""Wenzhe Shi"", ""Ferenc Husz\u00e1r""]","[""Theory"", ""Computer vision"", ""Deep learning""]",Probabilisticly motivated image superresolution using a projection to the subspace of valid solutions,,,,
S1TER2oll,2017,Accept (Poster),False,FILTER SHAPING FOR CONVOLUTIONAL NEURAL NETWORKS,"[""Xingyi Li"", ""Fuxin Li"", ""Xiaoli Fern"", ""Raviv Raich""]",[],,,,,
S1TgE7WR-,2018,Invite to Workshop Track,False,Covariant Compositional Networks For Learning Graphs,"[""Risi Kondor"", ""Truong Son Hy"", ""Horace Pan"", ""Brandon M. Anderson"", ""Shubhendu Trivedi""]","[""graph neural networks"", ""message passing"", ""label propagation"", ""high order representation""]",A general framework for creating covariant graph neural networks,,,,
S1VWjiRcKX,2019,Accept (Poster),False,Universal Successor Features Approximators,"[""Diana Borsa"", ""Andre Barreto"", ""John Quan"", ""Daniel J. Mankowitz"", ""Hado van Hasselt"", ""Remi Munos"", ""David Silver"", ""Tom Schaul""]","[""reinforcement learning"", ""zero-shot transfer"", ""successor features"", ""universal value functions"", ""general value functions""]",,,,,
S1VaB4cex,2017,Accept (Poster),False,FractalNet: Ultra-Deep Neural Networks without Residuals,"[""Gustav Larsson"", ""Michael Maire"", ""Gregory Shakhnarovich""]",[],,,,,
S1WRibb0Z,2018,Accept (Poster),False,Expressive power of recurrent neural networks,"[""Valentin Khrulkov"", ""Alexander Novikov"", ""Ivan Oseledets""]","[""Recurrent Neural Networks"", ""Tensor Train"", ""tensor decompositions"", ""expressive power""]",We prove the exponential efficiency of recurrent-type neural networks over shallow networks.,,,,
S1X7nhsxl,2017,Accept (Poster),False,Improving Generative Adversarial Networks with Denoising Feature Matching,"[""David Warde-Farley"", ""Yoshua Bengio""]","[""Deep learning"", ""Unsupervised Learning""]",Use a denoiser trained on discriminator features to train better generators.,,,,
S1XXq6lRW,2018,Reject,False,Zero-shot Cross Language Text Classification,"[""Dan Svenstrup"", ""Jonas Meinertz Hansen"", ""Ole Winther""]","[""Cross Language Text Classification"", ""Neural Networks"", ""Machine Learning""]",Cross Language Text Classification by universal encoding,,,,
S1XolQbRW,2018,Accept (Poster),False,Model compression via distillation and quantization,"[""Antonio Polino"", ""Razvan Pascanu"", ""Dan Alistarh""]","[""quantization"", ""distillation"", ""model compression""]","Obtains state-of-the-art accuracy for quantized, shallow nets by leveraging distillation. ",,,,
S1Y0td9ee,2017,Invite to Workshop Track,False,Shift Aggregate Extract Networks,"[""Francesco Orsini"", ""Daniele Baracchi"", ""Paolo Frasconi""]","[""Supervised Learning""]",Shift Aggregate Extract Networks for learning on social network data,,,,
S1Y7OOlRZ,2018,Reject,False,Massively Parallel Hyperparameter Tuning,"[""Lisha Li"", ""Kevin Jamieson"", ""Afshin Rostamizadeh"", ""Katya Gonina"", ""Moritz Hardt"", ""Benjamin Recht"", ""Ameet Talwalkar""]","[""parallel hyperparameter tuning"", ""deep learning""]",,,,,
S1_pAu9xl,2017,Accept (Poster),False,Trained Ternary Quantization,"[""Chenzhuo Zhu"", ""Song Han"", ""Huizi Mao"", ""William J. Dally""]","[""Deep learning""]",Ternary Neural Network with accuracy close to or even higher than the full-precision one,,,,
S1c2cvqee,2017,Accept (Poster),False,Designing Neural Network Architectures using Reinforcement Learning,"[""Bowen Baker"", ""Otkrist Gupta"", ""Nikhil Naik"", ""Ramesh Raskar""]","[""Deep learning"", ""Reinforcement Learning""]",A Q-learning algorithm for automatically generating neural nets,,,,
S1cZsf-RW,2018,Accept (Poster),False,WHAI: Weibull Hybrid Autoencoding Inference for Deep Topic Modeling,"[""Hao Zhang"", ""Bo Chen"", ""Dandan Guo"", ""Mingyuan Zhou""]",[],,,,,
S1dIzvclg,2017,Accept (Poster),False,A recurrent neural network without chaos,"[""Thomas Laurent"", ""James von Brecht""]",[],,,,,
S1di0sfgl,2017,Accept (Poster),False,Hierarchical Multiscale Recurrent Neural Networks,"[""Junyoung Chung"", ""Sungjin Ahn"", ""Yoshua Bengio""]","[""Natural language processing"", ""Deep learning""]",Propose a recurrent neural network architecture that can discover the underlying hierarchical structure in the temporal data.,,,,
S1e-0kBYPB,2020,Reject,False,Can I Trust the Explainer? Verifying Post-Hoc Explanatory Methods,"[""Oana-Maria Camburu*"", ""Eleonora Giunchiglia*"", ""Jakob Foerster"", ""Thomas Lukasiewicz"", ""Phil Blunsom""]","[""explainability"", ""neural networks""]",An evaluation framework based on a real-world neural network for post-hoc explanatory methods,,,,
S1e0ZlHYDB,2020,Reject,True,Progressive Compressed Records: Taking a Byte Out of Deep Learning Data,"[""Michael Kuchnik"", ""George Amvrosiadis"", ""Virginia Smith""]","[""Deep Learning"", ""Storage"", ""Bandwidth"", ""Compression""]","We propose a simple, general, and space-efficient data format to accelerate deep learning training by allowing sample fidelity to be dynamically selected at training time",1911.00472,cs.LG,2019-11-01 17:28:56+00:00,2021-08-11 21:43:44+00:00
S1e1EAEFPB,2020,Reject,False,Perceptual Regularization: Visualizing and Learning Generalizable Representations,"[""Hongzhou Lin"", ""Joshua Robinson"", ""Stefanie Jegelka""]","[""regularization"", ""representation learning"", ""visualization""]",,,,,
S1e2agrFvS,2020,Accept (Spotlight),False,Geom-GCN: Geometric Graph Convolutional Networks,"[""Hongbin Pei"", ""Bingzhe Wei"", ""Kevin Chen-Chuan Chang"", ""Yu Lei"", ""Bo Yang""]","[""Deep Learning"", ""Graph Convolutional Network"", ""Network Geometry""]","For graph neural networks, the aggregation on a graph can benefit from a continuous space underlying the graph.",2002.05287,cs.LG,2020-02-13 00:03:09+00:00,2020-02-14 01:47:35+00:00
S1e3g1rtwB,2020,Reject,False,The fairness-accuracy landscape of neural classifiers,"[""Susan Wei"", ""Marc Niethammer""]",[],,,,,
S1e4Q6EtDH,2020,Reject,False,Tensorized Embedding Layers for Efficient Model Compression,"[""Oleksii Hrinchuk"", ""Valentin Khrulkov"", ""Leyla Mirvakhabova"", ""Ivan Oseledets""]","[""Embedding layers compression"", ""tensor networks"", ""low-rank factorization""]",Embedding layers are factorized with Tensor Train decomposition to reduce their memory footprint.,,,,
S1e4jkSKvB,2020,Accept (Spotlight),False,The intriguing role of module criticality in the generalization of deep networks,"[""Niladri Chatterji"", ""Behnam Neyshabur"", ""Hanie Sedghi""]","[""Module Criticality Phenomenon"", ""Complexity Measure"", ""Deep Learning""]","We study the phenomenon that some modules of DNNs are more critical than others. Our analysis leads us to propose a complexity measure, that is able to explain the superior generalization performance of some architectures over others.",,,,
S1e5YC4KPS,2020,Reject,False,Winning Privately: The Differentially Private Lottery Ticket Mechanism,"[""Lovedeep Gondara"", ""Ke Wang"", ""Ricardo Silva Carvalho""]","[""Differentially private neural networks"", ""lottery ticket hypothesis"", ""differential privacy""]",An end-to-end differentially private extension of the lottery ticket mechanism,2002.11613,cs.LG,2020-02-16 06:15:54+00:00,2020-02-16 06:15:54+00:00
S1eALyrYDH,2020,Accept (Talk),False,RNA Secondary Structure Prediction By Learning Unrolled Algorithms,"[""Xinshi Chen"", ""Yu Li"", ""Ramzan Umarov"", ""Xin Gao"", ""Le Song""]","[""RNA secondary structure prediction"", ""learning algorithm"", ""deep architecture design"", ""computational biology""]","A DL model for RNA secondary structure prediction, which uses an unrolled algorithm in the architecture to enforce constraints.",2002.05810,cs.LG,2020-02-13 23:21:25+00:00,2020-02-13 23:21:25+00:00
S1eB3sRqtm,2019,Reject,False,Exploring Curvature Noise in Large-Batch Stochastic Optimization,"[""Yeming Wen"", ""Kevin Luk"", ""Maxime Gazeau"", ""Guodong Zhang"", ""Harris Chan"", ""Jimmy Ba""]","[""optimization"", ""large-batch training"", ""generalization"", ""noise covariance""]",Engineer large-batch training such that we retain fast training while achieving better generalization.,,,,
S1eBzhRqK7,2019,Reject,False,Evolutionary-Neural Hybrid Agents for Architecture Search,"[""Krzysztof Maziarz"", ""Andrey Khorlin"", ""Quentin de Laroussilhe"", ""Andrea Gesmundo""]","[""Evolutionary"", ""Architecture Search"", ""NAS""]","We propose a class of Evolutionary-Neural hybrid agents, that retain the best qualities of the two approaches.",,,,
S1eEdj0cK7,2019,Reject,False,On the Relationship between Neural Machine Translation and Word Alignment,"[""Xintong Li"", ""Lemao Liu"", ""Guanlin Li"", ""Max Meng"", ""Shuming Shi""]","[""Neural Machine Translation"", ""Word Alignment"", ""Neural Network"", ""Pointwise Mutual Information""]",It proposes methods to induce word alignment for neural machine translation (NMT) and uses them to interpret the relationship between NMT and word alignment.,,,,
S1eEmn05tQ,2019,Reject,False,Uncertainty in Multitask Transfer Learning,"[""Alexandre Lacoste"", ""Boris Oreshkin"", ""Wonchang Chung"", ""Thomas Boquet"", ""Negar Rostamzadeh"", ""David Krueger""]","[""Multi Task"", ""Transfer Learning"", ""Hierarchical Bayes"", ""Variational Bayes"", ""Meta Learning"", ""Few Shot learning""]",A scalable method for learning an expressive prior over neural networks across multiple tasks.,,,,
S1eFtj0cKQ,2019,Reject,False,Generative Models from the perspective of Continual Learning,"[""Timoth\u00e9e Lesort"", ""Hugo Caselles-Dupr\u00e9"", ""Michael Garcia-Ortiz"", ""Jean-Fran\u00e7ois Goudou"", ""David Filliat""]","[""Generative Models"", ""Continual Learning""]",A comparative study of generative models on Continual Learning scenarios.,,,,
S1eIw0NFvr,2020,Reject,False,Selective Brain Damage: Measuring the Disparate Impact of Model Pruning,"[""Sara Hooker"", ""Yann Dauphin"", ""Aaron Courville"", ""Andrea Frome""]","[""machine learning""]",Pruning deep neural networks has a non-uniform impact; certain classes and exemplars are systematically more impacted by the introduction of sparsity. ,,,,
S1eK3i09YQ,2019,Accept (Poster),True,Gradient Descent Provably Optimizes Over-parameterized Neural Networks,"[""Simon S. Du"", ""Xiyu Zhai"", ""Barnabas Poczos"", ""Aarti Singh""]","[""theory"", ""non-convex optimization"", ""overparameterization"", ""gradient descent""]",We prove gradient descent achieves zero training loss with a linear rate on over-parameterized neural networks.,1810.02054,cs.LG,2018-10-04 04:47:47+00:00,2019-02-05 01:59:59+00:00
S1eL4kBYwr,2020,Reject,True,UNITER: Learning UNiversal Image-TExt Representations,"[""Yen-Chun Chen"", ""Linjie Li"", ""Licheng Yu"", ""Ahmed El Kholy"", ""Faisal Ahmed"", ""Zhe Gan"", ""Yu Cheng"", ""Jingjing Liu""]","[""Self-supervised Representation Learning"", ""Large-scale Pre-training"", ""Vision and Language""]","We introduce UNITER, a UNiversal Image-TExt Representation, learned through large-scale pre-training over image-text datasets, achieves state-of-the-art results across six Vision-and-Language tasks over nine datasets.",1909.11740,cs.CV,2019-09-25 20:02:54+00:00,2020-07-17 22:19:59+00:00
S1eOHo09KX,2019,Accept (Poster),False,Opportunistic Learning: Budgeted Cost-Sensitive Learning from Data Streams,"[""Mohammad Kachuee"", ""Orpaz Goldstein"", ""Kimmo K\u00e4rkk\u00e4inen"", ""Sajad Darabi"", ""Majid Sarrafzadeh""]","[""Cost-Aware Learning"", ""Feature Acquisition"", ""Reinforcement Learning"", ""Stream Learning"", ""Deep Q-Learning""]",An online algorithm for cost-aware feature acquisition and prediction,,,,
S1eQuCVFvB,2020,Reject,False,Machine Truth Serum,"[""Tianyi Luo"", ""Yang Liu""]","[""Ensemble method"", ""Classification"", ""Machine Truth Serum"", ""Minority"", ""Machine Learning""]",This paper proposes two machine learning aided methods HMTS and DMTS to detect when the aggregated minority opinion should be taken as the final prediction instead of majority.,,,,
S1eRbANtDB,2020,Accept (Poster),False,Learning to Link,"[""Maria-Florina Balcan"", ""Travis Dick"", ""Manuel Lang""]","[""Data-driven Algorithm Configuration"", ""Metric Learning"", ""Linkage Clustering"", ""Learning Algorithms""]",We show how to use data to automatically learn low-loss linkage procedures and metrics for specific clustering applications.,,,,
S1eRya4KDB,2020,Reject,False,A novel Bayesian estimation-based word embedding model for sentiment analysis,"[""Jingyao Tang"", ""Yun Xue"", ""Ziwen Wang"", ""Haoliang Zhao""]","[""sentiment analysis"", ""sentiment word embeddings"", ""maximum likelihood estimation"", ""Bayesian estimation""]",We use sentiment probabilities to incorporate the sentiment information of words into the word embeddings and use Bayesian estimation to derive sentiment probabilities.,,,,
S1eSoeSYwr,2020,Reject,True,Deep Evidential Uncertainty,"[""Alexander Amini"", ""Wilko Schwarting"", ""Ava Soleimany"", ""Daniela Rus""]","[""Evidential deep learning"", ""Uncertainty estimation"", ""Epistemic uncertainty""]","Fast, calibrated uncertainty estimation for neural networks without sampling",1910.02600,cs.LG,2019-10-07 04:11:34+00:00,2020-11-24 16:37:04+00:00
S1eVe2AqKX,2019,Reject,False,PCNN: Environment Adaptive Model Without Finetuning,"[""Boyuan Feng"", ""Kun Wan"", ""Shu Yang"", ""Yufei Ding""]","[""Class skew"", ""Runtime adaption""]",,,,,
S1eWbkSFPS,2020,Reject,False,"GRAPHS, ENTITIES, AND STEP MIXTURE","[""Kyuyong Shin"", ""Wonyoung Shin"", ""Jung-Woo Ha"", ""Sunyoung Kwon""]","[""Graph Neural Network"", ""Random Walk"", ""Attention""]",Simple and effective graph neural network with mixture of random walk steps and attention,2005.08485,cs.LG,2020-05-18 06:57:02+00:00,2020-06-24 05:46:48+00:00
S1eX-nA5KX,2019,Reject,False,VHEGAN: Variational Hetero-Encoder Randomized GAN for Zero-Shot Learning,"[""Hao Zhang"", ""Bo Chen"", ""Long Tian"", ""Zhengjue Wang"", ""Mingyuan Zhou""]","[""Deep generative models"", ""deep topic modeling"", ""generative adversarial learning"", ""variational encoder"", ""zero-short learning""]",,,,,
S1eYHoC5FX,2019,Accept (Poster),False,DARTS: Differentiable Architecture Search,"[""Hanxiao Liu"", ""Karen Simonyan"", ""Yiming Yang""]","[""deep learning"", ""autoML"", ""neural architecture search"", ""image classification"", ""language modeling""]","We propose a differentiable architecture search algorithm for both convolutional and recurrent networks, achieving competitive performance with the state of the art using orders of magnitude less computation resources.",,,,
S1eYKlrYvr,2020,Reject,False,Diagnosing the Environment Bias in Vision-and-Language Navigation,"[""Yubo Zhang"", ""Hao Tan"", ""Mohit Bansal""]","[""vision-and-language navigation"", ""generalization"", ""environment bias diagnosis""]",Diagnosing and reducing the seen-unseen performance gap in vision-and-language navigation,2005.03086,cs.CL,2020-05-06 19:24:33+00:00,2020-05-06 19:24:33+00:00
S1eYchEtwH,2020,Reject,False,Learning Human Postural Control with Hierarchical Acquisition Functions,"[""Nils Rottmann"", ""Tjasa Kunavar"", ""Jan Babic"", ""Jan Peters"", ""Elmar Rueckert""]","[""Human Postural Control Model"", ""Hierarchical Bayesian Optimization"", ""Acquisition Function""]",This paper presents a computational model for efficient human postural control adaptation based on hierarchical acquisition functions with well-known features. ,,,,
S1eZOeBKDS,2020,Reject,False,Deep Spike Decoder (DSD),"[""Emrah Adamey"", ""Tarin Ziyaee"", ""Nishanth Alapati"", ""Jun Ye""]","[""self-supervised"", ""deep learning"", ""spike sorting"", ""EMG"", ""sEMG"", ""autoencoder"", ""inductive bias""]",We built an unsupervised spike sorting algorithm using deep learning with biophysics baked in.,,,,
S1eZYeHFDS,2020,Accept (Spotlight),False,Deep Learning For Symbolic Mathematics,"[""Guillaume Lample"", ""Fran\u00e7ois Charton""]","[""symbolic"", ""math"", ""deep learning"", ""transformers""]","We train a neural network to compute function integrals, and to solve complex differential equations.",1912.01412,cs.SC,2019-12-02 15:05:24+00:00,2019-12-02 15:05:24+00:00
S1e_9xrFvS,2020,Accept (Spotlight),False,Energy-based models for atomic-resolution protein conformations,"[""Yilun Du"", ""Joshua Meier"", ""Jerry Ma"", ""Rob Fergus"", ""Alexander Rives""]","[""energy-based model"", ""transformer"", ""energy function"", ""protein conformation""]",Energy-based models trained on crystallized protein structures predict native side chain configurations and automatically discover molecular energy features.,2004.13167,cs.LG,2020-04-27 20:45:12+00:00,2020-04-27 20:45:12+00:00
S1e_H3AqYQ,2019,Reject,False,Exploiting Cross-Lingual Subword Similarities in Low-Resource Document Classification,"[""Mozhi Zhang"", ""Yoshinari Fujinuma"", ""Jordan Boyd-Graber""]","[""cross-lingual transfer"", ""character-based method"", ""low-resource language""]",We propose a cross-lingual document classification framework for related language pairs.,,,,
S1e__ANKvB,2020,Reject,False,Molecular Graph Enhanced Transformer for Retrosynthesis Prediction,"[""Kelong Mao"", ""Peilin Zhao"", ""Tingyang Xu"", ""Yu Rong"", ""Xi Xiao"", ""Junzhou Huang""]",[],,,,,
S1e_ssC5F7,2019,Reject,False,Hyper-Regularization: An Adaptive Choice for the Learning Rate in Gradient Descent,"[""Guangzeng Xie"", ""Hao Jin"", ""Dachao Lin"", ""Zhihua Zhang""]","[""Adaptive learning rate"", ""novel framework""]",,,,,
S1ecYANtPr,2020,Reject,False,Representation Learning Through Latent Canonicalizations,"[""Or Litany"", ""Ari Morcos"", ""Srinath Sridhar"", ""Leonidas Guibas"", ""Judy Hoffman""]","[""representation learning"", ""latent canonicalization"", ""sim2real"", ""few shot"", ""disentanglement""]",We introduce latent canonicalizers: linear transformations meant to structure latent representations for improved sim2real adaptation,,,,
S1ecm2C9K7,2019,Accept (Poster),False,Feature-Wise Bias Amplification,"[""Klas Leino"", ""Emily Black"", ""Matt Fredrikson"", ""Shayak Sen"", ""Anupam Datta""]","[""bias"", ""bias amplification"", ""classification""]",,,,,
S1ef6JBtPr,2020,Reject,False,Probabilistic View of Multi-agent Reinforcement Learning: A Unified Approach,"[""Shubham Gupta"", ""Ambedkar Dukkipati""]","[""multi-agent reinforcement learning"", ""maximum entropy reinforcement learning""]",A probabilistic framework for multi-agent reinforcement learning,,,,
S1efAp4YvB,2020,Reject,False,Interpreting video features: a comparison of 3D convolutional networks and convolutional LSTM networks,"[""Joonatan M\u00e4ntt\u00e4ri*"", ""Sofia Broom\u00e9*"", ""John Folkesson"", ""Hedvig Kjellstr\u00f6m""]","[""interpretability"", ""spatiotemporal"", ""video"", ""features"", ""saliency"", ""temporal""]",We investigate what spatiotemporal features are focused on in video data by two models that are principally different in the way that they model temporal dependencies.,,,,
S1efxTVYDr,2020,Accept (Talk),False,Data-dependent Gaussian Prior Objective for Language Generation,"[""Zuchao Li"", ""Rui Wang"", ""Kehai Chen"", ""Masso Utiyama"", ""Eiichiro Sumita"", ""Zhuosheng Zhang"", ""Hai Zhao""]","[""Gaussian Prior Objective"", ""Language Generation""]","We introduce an extra data-dependent Gaussian prior objective to augment the current MLE training, which is designed to capture the prior knowledge in the ground-truth data.",,,,
S1eik6EtPB,2020,Reject,True,Towards A Unified Min-Max Framework for Adversarial Exploration and Robustness,"[""Jingkang Wang"", ""Tianyun Zhang"", ""Sijia Liu"", ""Pin-Yu Chen"", ""Jiacen Xu"", ""Makan Fardad"", ""Bo Li""]","[""Ensemble attack"", ""adversarial training"", ""diversity promotion""]",A unified min-max optimization framework for adversarial attack and defense,1906.03563,cs.LG,2019-06-09 04:32:13+00:00,2021-11-01 17:21:53+00:00
S1ej8o05tm,2019,Reject,False,Object detection deep learning networks for Optical Character Recognition,"[""Christopher Bourez"", ""Aurelien Coquard""]","[""OCR"", ""object detection"", ""RCNN"", ""Yolo""]",Yolo / RCNN neural network for object detection adapted to the task of OCR,,,,
S1ejj64YvS,2020,Reject,False,Good Semi-supervised VAE Requires Tighter Evidence Lower Bound,"[""Haozhe Feng"", ""Kezhi Kong"", ""Tianye Zhang"", ""Siyue Xue"", ""Wei Chen""]","[""VAE"", ""Semi-supervised Learning"", ""ELBO"", ""Generative Model""]","we propose OSPOT-VAE, a one-stage deep generative model that unifies the generation and classification loss in one ELBO framework and achieves a tighter ELBO.",,,,
S1ekaT4tDB,2020,Reject,False,Why Convolutional Networks Learn Oriented Bandpass Filters: A Hypothesis,"[""Richard P. Wildes""]","[""convolutional networks"", ""computer vision"", ""oriented bandpass filters"", ""linear systems theory""]",This paper offers a hypothesis for why convolutional networks learn oriented bandpass filters when applied to image understanding.,,,,
S1el9TEKPB,2020,Reject,False,Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism Principled Robust Deep Neural Nets,"[""Thu Dinh*"", ""Bao Wang*"", ""Andrea L. Bertozzi"", ""Stanley J. Osher"", ""Jack Xin""]","[""Sparse Network"", ""Model Compression"", ""Adversarial Training""]",We focus on a co-design of efficient DNN compression algorithms and sparse neural architectures for robust and accurate deep learning. Such a co-design enables us to advance the goal of accommodating both sparsity and robustness.,,,,
S1elRa4twS,2020,Reject,False,Pre-training as Batch Meta Reinforcement Learning with tiMe ,"[""Quan Vuong"", ""Shuang Liu"", ""Minghua Liu"", ""Kamil Ciosek"", ""Hao Su"", ""Henrik Iskov Christensen""]","[""Reinforcement Learning"", ""Deep Reinforcement Learning"", ""Meta Reinforcement Learning"", ""Batch Reinforcement Learning"", ""Transfer Learning""]",Pre-training in RL from purely existing and observational data. Generalization to unseen MDPs.,,,,
S1emOTNKvS,2020,Reject,False,Robust Graph Representation Learning via Neural Sparsification,"[""Cheng Zheng"", ""Bo Zong"", ""Wei Cheng"", ""Dongjin Song"", ""Jingchao Ni"", ""Wenchao Yu"", ""Haifeng Chen"", ""Wei Wang""]",[],,,,,
S1en0sRqKm,2019,Reject,False,On the Computational Inefficiency of Large Batch Sizes for Stochastic Gradient Descent,"[""Noah Golmant"", ""Nikita Vemuri"", ""Zhewei Yao"", ""Vladimir Feinberg"", ""Amir Gholami"", ""Kai Rothauge"", ""Michael Mahoney"", ""Joseph Gonzalez""]","[""Deep learning"", ""large batch training"", ""scaling rules"", ""stochastic gradient descent""]",Large batch training results in rapidly diminishing returns in wall-clock time to convergence to find a good model.,,,,
S1enmaVFvS,2020,Reject,True,Data-Driven Approach to Encoding and Decoding 3-D Crystal Structures,"[""Jordan Hoffmann"", ""Louis Maestrati"", ""Yoshihide Sawada"", ""Jian Tang"", ""Jean Michel Sellier"", ""Yoshua Bengio""]",[],,1909.00949,cs.LG,2019-09-03 04:36:13+00:00,2019-09-03 04:36:13+00:00
S1eq9yrYvH,2020,Reject,False,Subjective Reinforcement Learning for Open Complex Environments,"[""Zhile Yang*"", ""Haichuan Gao*"", ""Xin Su"", ""Shangqi Guo"", ""Feng Chen""]","[""reinforcement learning theory"", ""subjective learning""]",,,,,
S1eqj1SKvr,2020,Reject,False,TOWARDS FEATURE SPACE ADVERSARIAL ATTACK,"[""Qiuling Xu"", ""Guanhong Tao"", ""Siyuan Cheng"", ""Lin Tan"", ""Xiangyu Zhang""]",[],,,,,
S1erHoR5t7,2019,Accept (Poster),False, The relativistic discriminator: a key element missing from standard GAN,"[""Alexia Jolicoeur-Martineau""]","[""AI"", ""deep learning"", ""generative models"", ""GAN""]",Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.,,,,
S1erpeBFPB,2020,Accept (Poster),False,How to 0wn the NAS in Your Spare Time,"[""Sanghyun Hong"", ""Michael Davinroy"", ""Yi\u01e7itcan Kaya"", ""Dana Dachman-Soled"", ""Tudor Dumitra\u015f""]","[""Reconstructing Novel Deep Learning Systems""]","We design an algorithm that reconstructs the key components of a novel deep learning system by exploiting a small amount of information leakage from a cache side-channel attack, Flush+Reload.",,,,
S1ervgHFwS,2020,Reject,True,Adversarial Training Generalizes Data-dependent Spectral Norm Regularization,"[""Kevin Roth"", ""Yannic Kilcher"", ""Thomas Hofmann""]","[""Adversarial Robustness"", ""Adversarial Training"", ""Spectral Norm Regularization""]",We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks.,1906.01527,cs.LG,2019-06-04 15:40:28+00:00,2020-10-23 14:26:39+00:00
S1esMkHYPr,2020,Accept (Poster),False,GraphAF: a Flow-based Autoregressive Model for Molecular Graph Generation,"[""Chence Shi*"", ""Minkai Xu*"", ""Zhaocheng Zhu"", ""Weinan Zhang"", ""Ming Zhang"", ""Jian Tang""]","[""Molecular graph generation"", ""deep generative models"", ""normalizing flows"", ""autoregressive models""]",A flow-based autoregressive model for molecular graph generation. Reaching state-of-the-art results on molecule generation and properties optimization.,,,,
S1et1lrtwr,2020,Reject,True,Unsupervised Meta-Learning for Reinforcement Learning,"[""Abhishek Gupta"", ""Benjamin Eysenbach"", ""Chelsea Finn"", ""Sergey Levine""]","[""Meta-Learning"", ""Reinforcement Learning""]",Meta-learning on self-proposed task distributions to speed up reinforcement learning without human specified task distributions ,1806.04640,cs.LG,2018-06-12 16:48:52+00:00,2020-04-30 16:55:56+00:00
S1et8gBKwH,2020,Reject,False,Semi-supervised Pose Estimation with Geometric Latent Representations,"[""Luis A. Perez Rey"", ""Dmitri Jarnikov"", ""Mike Holenderski""]","[""Semi-supervised learning"", ""pose estimation"", ""angle estimation"", ""variational autoencoders""]",Semi-supervised method for identifying planar rotations for limited amount of labelled data. ,,,,
S1evHerYPr,2020,Accept (Spotlight),False,Improving Generalization in Meta Reinforcement Learning using Learned Objectives,"[""Louis Kirsch"", ""Sjoerd van Steenkiste"", ""Juergen Schmidhuber""]","[""meta reinforcement learning"", ""meta learning"", ""reinforcement learning""]","We introduce MetaGenRL, a novel meta reinforcement learning algorithm. Unlike prior work, MetaGenRL can generalize to new environments that are entirely different from those used for meta-training.",,,,
S1ewjhEFwr,2020,Reject,False,Storage Efficient and Dynamic Flexible Runtime Channel Pruning via Deep Reinforcement Learning,"[""Jianda Chen"", ""Shangyu Chen"", ""Sinno Jialin Pan""]",[],,,,,
S1exA2NtDB,2020,Accept (Poster),True,ES-MAML: Simple Hessian-Free Meta Learning,"[""Xingyou Song"", ""Wenbo Gao"", ""Yuxiang Yang"", ""Krzysztof Choromanski"", ""Aldo Pacchiano"", ""Yunhao Tang""]","[""ES"", ""MAML"", ""evolution"", ""strategies"", ""meta"", ""learning"", ""gaussian"", ""perturbation"", ""reinforcement"", ""learning"", ""adaptation""]","We provide a new framework for MAML in the ES/blackbox setting, and show that it allows deterministic and linear policies, better exploration, and non-differentiable adaptation operators.",1910.01215,cs.LG,2019-09-25 19:28:33+00:00,2020-07-07 15:49:16+00:00
S1ey2sRcYQ,2019,Reject,False,Direct Optimization through $\arg \max$  for  Discrete Variational Auto-Encoder,"[""Guy Lorberbom"", ""Tamir Hazan""]","[""discrete variational auto encoders"", ""generative models"", ""perturbation models""]",,,,,
S1fDssA5Y7,2019,Reject,False,Distributionally Robust Optimization Leads to Better Generalization: on SGD and Beyond,"[""Jikai Hou"", ""Kaixuan Huang"", ""Zhihua Zhang""]","[""distributionally robust optimization"", ""deep learning"", ""SGD"", ""learning theory""]",,,,,
S1fHmlbCW,2018,Reject,False,Neural Networks for irregularly observed continuous-time Stochastic Processes,"[""Francois W. Belletti"", ""Alexander Ku"", ""Joseph E. Gonzalez""]","[""Deep Learning"", ""Stochastic Processes"", ""Time Series Analysis""]",Neural architectures providing representations of irregularly observed signals that provably enable signal reconstruction.,,,,
S1fQSiCcYm,2019,Accept (Poster),False,Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer,"[""David Berthelot*"", ""Colin Raffel*"", ""Aurko Roy"", ""Ian Goodfellow""]","[""autoencoders"", ""interpolation"", ""unsupervised learning"", ""representation learning"", ""adversarial learning""]",We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.,,,,
S1fUpoR5FQ,2019,Accept (Poster),False,Quasi-hyperbolic momentum and Adam for deep learning,"[""Jerry Ma"", ""Denis Yarats""]","[""sgd"", ""momentum"", ""nesterov"", ""adam"", ""qhm"", ""qhadam"", ""optimization""]",Mix plain SGD and momentum (or do something similar with Adam) for great profit.,,,,
S1fcY-Z0-,2018,Reject,False,Bayesian Hypernetworks,"[""David Krueger"", ""Chin-Wei Huang"", ""Riashat Islam"", ""Ryan Turner"", ""Alexandre Lacoste"", ""Aaron Courville""]","[""variational inference"", ""bayesian inference"", ""deep networks""]",We propose Bayesian hypernetworks: a framework for approximate Bayesian inference in neural networks.,,,,
S1fcnoR9K7,2019,Reject,False,Learning with Random Learning Rates.,"[""L\u00e9onard Blier"", ""Pierre Wolinski"", ""Yann Ollivier""]","[""step size"", ""stochastic gradient descent"", ""hyperparameter tuning""]","We test stochastic gradient descent with random per-feature learning rates in neural networks, and find performance comparable to using SGD with the optimal learning rate, alleviating the need for learning rate tuning.",,,,
S1fduCl0b,2018,Reject,False,Lifelong Generative Modeling,"[""Jason Ramapuram"", ""Magda Gregorova"", ""Alexandros Kalousis""]","[""Lifelong"", ""Generative Modeling"", ""Variational Autoencoder"", ""VAE"", ""Catastrophic Interference""]",Lifelong distributional learning through a student-teacher architecture coupled with a cross model posterior regularizer.,,,,
S1g2JnRcFX,2019,Accept (Poster),True,Local SGD Converges Fast and Communicates Little,"[""Sebastian U. Stich""]","[""optimization"", ""communication"", ""theory"", ""stochastic gradient descent"", ""SGD"", ""mini-batch"", ""local SGD"", ""parallel restart SGD"", ""distributed training""]",We prove that parallel local SGD achieves linear speedup with much lesser communication than parallel mini-batch SGD.,1805.09767,math.OC,2018-05-24 16:38:51+00:00,2019-05-03 12:58:04+00:00
S1g2V3Cct7,2019,Reject,False,Experience replay for continual learning,"[""David Rolnick"", ""Arun Ahuja"", ""Jonathan Schwarz"", ""Timothy P. Lillicrap"", ""Greg Wayne""]","[""continual learning"", ""catastrophic forgetting"", ""lifelong learning"", ""behavioral cloning"", ""reinforcement learning"", ""interference"", ""stability-plasticity""]","We show that, in continual learning settings, catastrophic forgetting can be avoided by applying off-policy RL to a mixture of new and replay experience, with a behavioral cloning loss.",,,,
S1g2skStPB,2020,Accept (Talk),False,Causal Discovery with Reinforcement Learning,"[""Shengyu Zhu"", ""Ignavier Ng"", ""Zhitang Chen""]","[""causal discovery"", ""structure learning"", ""reinforcement learning"", ""directed acyclic graph""]",We apply reinforcement learning to score-based causal discovery and achieve promising results on both synthetic and real datasets,,,,
S1g490VKvB,2020,Reject,False,The Dynamics of Signal Propagation in Gated Recurrent Neural Networks,"[""Dar Gilboa"", ""Bo Chang"", ""Minmin Chen"", ""Greg Yang"", ""Samuel S. Schoenholz"", ""Ed H. Chi"", ""Jeffrey Pennington""]","[""recurrent neural networks"", ""theory of deep learning""]","We calculate conditions for signal propagation in LSTMs and GRUs, and use these to predict trainability of networks on long sequence tasks and construct initialization schemes that improve performance on such tasks. ",,,,
S1g6xeSKDS,2020,Accept (Poster),False,Mixed-curvature Variational Autoencoders,"[""Ondrej Skopek"", ""Octavian-Eugen Ganea"", ""Gary B\u00e9cigneul""]","[""variational autoencoders"", ""riemannian manifolds"", ""non-Euclidean geometry""]",Variational Autoencoders with latent spaces modeled as products of constant curvature Riemannian manifolds improve on image reconstruction over single-manifold variants.,1911.08411,cs.LG,2019-11-19 17:30:45+00:00,2020-02-13 00:05:33+00:00
S1g7tpEYDS,2020,Accept (Poster),False,From Variational to Deterministic Autoencoders,"[""Partha Ghosh"", ""Mehdi S. M. Sajjadi"", ""Antonio Vergari"", ""Michael Black"", ""Bernhard Scholkopf""]","[""Unsupervised learning"", ""Generative Models"", ""Variational Autoencoders"", ""Regularization""]","Deterministic regularized autoencoders can learn a smooth, meaningful latent space as VAEs without having to force some arbitrarily chosen prior (i.e., Gaussian).",,,,
S1g8K1BFwS,2020,Accept (Poster),False,Probability Calibration for Knowledge Graph Embedding Models,"[""Pedro Tabacof"", ""Luca Costabello""]","[""knowledge graph embeddings"", ""probability calibration"", ""calibration"", ""graph representation learning"", ""knowledge graphs""]",We propose a novel method to calibrate knowledge graph embedding models without the need of negative examples.,1912.10000,cs.AI,2019-12-20 18:31:33+00:00,2020-02-13 10:38:54+00:00
S1g9N2A5FX,2019,Reject,False,Interpretable Continual Learning,"[""Tameem Adel"", ""Cuong V. Nguyen"", ""Richard E. Turner"", ""Zoubin Ghahramani"", ""Adrian Weller""]","[""Interpretability"", ""Continual Learning""]","The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. ",,,,
S1gARiAcFm,2019,Reject,False,Modeling Dynamics of Biological Systems with Deep Generative Neural Networks,"[""Scott Gigante"", ""David van Dijk"", ""Kevin R. Moon"", ""Alexander Strzalkowski"", ""Katie Ferguson"", ""Guy Wolf"", ""Smita Krishnaswamy""]","[""neural networks"", ""markovian dynamics"", ""single-cell biology"", ""calcium imaging"", ""stochastic dynamics"", ""generative models""]","Dynamics Modeling Networks (DyMoN) offer advantages in representation, generation, visualization and feature extraction over shallow learning techniques for modeling stochastic dynamical systems in biology.",,,,
S1gBgnR9Y7,2019,Reject,False,End-to-end learning of pharmacological assays from high-resolution microscopy images,"[""Markus Hofmarcher"", ""Elisabeth Rumetshofer"", ""Sepp Hochreiter"", ""G\u00fcnter Klambauer""]","[""Convolutional Neural Networks"", ""High-resolution images"", ""Multiple-Instance Learning"", ""Drug Discovery"", ""Molecular Biology""]",,,,,
S1gBz2C9tX,2019,Reject,False,Importance Resampling for Off-policy Policy Evaluation,"[""Matthew Schlegel"", ""Wesley Chung"", ""Daniel Graves"", ""Martha White""]","[""Reinforcement Learning"", ""Off-policy policy evaluation"", ""importance resampling"", ""importance sampling""]",A resampling approach for off-policy policy evaluation in reinforcement learning.,,,,
S1gDCiCqtQ,2019,Reject,False,Learning Representations in Model-Free Hierarchical Reinforcement Learning,"[""Jacob Rafati"", ""David Noelle""]","[""Reinforcement Learning"", ""Model-Free Hierarchical Reinforcement Learning"", ""Subgoal Discovery"", ""Unsupervised Learning"", ""Temporal Difference"", ""Temporal Abstraction"", ""Intrinsic Motivation"", ""Markov Decision Processes"", ""Deep Reinforcement Learning"", ""Optimization""]","We offer an original approach to model-free deep hierarchical reinforcement learning, including unsupervised subgoal discovery and unified temporal abstraction and intrinsic motivation learning. ",,,,
S1gEFkrtvH,2020,Reject,False,BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation,"[""Jin-Young  Kim"", ""Sung-Bae Cho""]","[""variational autoencoder"", ""latent space"", ""basis"", ""disentangled representation""]",Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra,,,,
S1gEIerYwH,2020,Accept (Poster),False,Transferring Optimality Across Data Distributions via Homotopy Methods,"[""Matilde Gargiani"", ""Andrea Zanelli"", ""Quoc Tran Dinh"", ""Moritz Diehl"", ""Frank Hutter""]","[""deep learning"", ""numerical optimization"", ""transfer learning""]","We propose a new homotopy-based method to transfer ""optimality knowledge"" across different data distributions in order to speed up training of deep models.  ",,,,
S1gFvANKDS,2020,Accept (Spotlight),True,Asymptotics of Wide Networks from Feynman Diagrams,"[""Ethan Dyer"", ""Guy Gur-Ari""]",[],A general method for computing the asymptotic behavior of wide networks using Feynman diagrams,1909.11304,cs.LG,2019-09-25 06:29:20+00:00,2019-09-25 06:29:20+00:00
S1gKA6NtPS,2020,Reject,False,Deep symbolic regression,"[""Brenden K. Petersen""]","[""symbolic regression"", ""reinforcement learning"", ""automated machine learning""]","A deep learning approach to symbolic regression, in which an autoregressive RNN emits a distribution over expressions that is optimized using reinforcement learning",,,,
S1gKkpNKwH,2020,Reject,True,Reinforcement Learning with Chromatic Networks,"[""Xingyou Song"", ""Krzysztof Choromanski"", ""Jack Parker-Holder"", ""Yunhao Tang"", ""Wenbo Gao"", ""Aldo Pacchiano"", ""Tamas Sarlos"", ""Deepali Jain"", ""Yuxiang Yang""]","[""reinforcement"", ""learning"", ""chromatic"", ""networks"", ""partitioning"", ""efficient"", ""neural"", ""architecture"", ""search"", ""weight"", ""sharing"", ""compactification""]","We show that ENAS with ES-optimization in RL is highly scalable, and use it to compactify neural network policies by weight sharing.",1907.06511,cs.NE,2019-07-10 16:57:50+00:00,2021-04-06 17:00:42+00:00
S1gLBgBtDH,2020,Reject,False,SLM Lab: A Comprehensive Benchmark and Modular Software Framework for Reproducible Deep Reinforcement Learning,"[""Wah Loon Keng"", ""Laura Graesser"", ""Milan Cvitkovic""]","[""reinforcement learning"", ""machine learning"", ""benchmark"", ""reproducibility"", ""software"", ""framework"", ""implementation issues"", ""parallelization"", ""software platforms""]",We introduce a new software framework (SLM Lab) for reinforcement learning and use it to produce a massive performance benchmark of RL algorithms.,,,,
S1gN8yrYwB,2020,Reject,False,AUGMENTED POLICY GRADIENT METHODS FOR EFFICIENT REINFORCEMENT LEARNING,"[""Kai Lagemann"", ""Gregor Roering"", ""Christoph Henke"", ""Rene Vossen"", ""Frank Hees""]","[""model-free reinforcement learning"", ""model-based reinforcement learning"", ""Baysian neural network"", ""deep learning"", ""reinforcement learning""]",,,,,
S1gNc3NtvB,2020,Reject,True,Learning Algorithmic Solutions to Symbolic Planning Tasks with a Neural Computer,"[""Daniel Tanneberg"", ""Elmar Rueckert"", ""Jan Peters""]",[],A novel neural computer architecture that learns transferable abstract strategies to symbolic planning tasks as algorithmic solutions with evolution strategies.,1911.00926,cs.NE,2019-10-30 17:02:13+00:00,2020-06-03 11:21:39+00:00
S1gOpsCctm,2019,Accept (Poster),False,Learning Finite State Representations of Recurrent Policy Networks,"[""Anurag Koul"", ""Alan Fern"", ""Sam Greydanus""]","[""recurrent neural networks"", ""finite state machine"", ""quantization"", ""interpretability"", ""autoencoder"", ""moore machine"", ""reinforcement learning"", ""imitation learning"", ""representation"", ""Atari"", ""Tomita""]",Extracting a finite state machine from a recurrent neural network via quantization for the purpose of interpretability with experiments on Atari.,,,,
S1gQ5sRcFm,2019,Reject,False,Consistent Jumpy Predictions for Videos and Scenes,"[""Ananya Kumar"", ""S. M. Ali Eslami"", ""Danilo Rezende"", ""Marta Garnelo"", ""Fabio Viola"", ""Edward Lockhart"", ""Murray Shanahan""]","[""jumpy predictions"", ""generative models"", ""scene reconstruction"", ""video prediction"", ""variational auto-encoders"", ""DRAW""]",We present a model for consistent 3D reconstruction and jumpy video prediction e.g. producing image frames multiple time-steps in the future without generating intermediate frames.,,,,
S1gR2ANFvB,2020,Reject,False,Model Comparison of Beer data classification using an electronic nose,"[""Mohammed Abdi"", ""Aminat Adebiyi"", ""Andrea Fasoli"", ""Alberto Mannari"", ""Ronald Labby"", ""Luisa Bozano""]","[""Electronic Nose"", ""EVA"", ""modular"", ""olfaction"", ""sensitivity"", ""selectivity"", ""analyte"", ""temperature oscillated waveforms"", ""features"", ""fingerprint""]",On this paper we will discuss the process of sniffing volatile organic compounds from liquid beer samples and exploring various machine learning models,,,,
S1gSj0NKvB,2020,Accept (Talk),False,Comparing Rewinding and Fine-tuning in Neural Network Pruning,"[""Alex Renda"", ""Jonathan Frankle"", ""Michael Carbin""]","[""pruning"", ""sparsity"", ""fine-tuning"", ""lottery ticket""]","Instead of fine-tuning after pruning, rewind weights or learning rate schedule to their values earlier in training and retrain from there to achieve higher accuracy when pruning neural networks.",2003.02389,cs.LG,2020-03-05 00:53:18+00:00,2020-03-05 00:53:18+00:00
S1gTAp4FDB,2020,Reject,False,Neural-Guided Symbolic Regression with Asymptotic Constraints,"[""Li Li"", ""Minjie Fan"", ""Rishabh Singh"", ""Patrick Riley""]","[""symbolic regression"", ""program synthesis"", ""monte carlo tree search""]",,,,,
S1gTwJSKvr,2020,Reject,False,OPTIMAL BINARY QUANTIZATION FOR DEEP NEURAL NETWORKS,"[""Hadi Pouransari"", ""Oncel Tuzel""]","[""Binary Neural Networks"", ""Quantization""]",,,,,
S1gUVjCqKm,2019,Reject,False,Unsupervised classification into unknown number of classes,"[""Sungyeob Han"", ""Daeyoung Kim"", ""Jungwoo Lee""]","[""unsupervised learning""]",,,,,
S1gUsoR9YX,2019,Accept (Poster),False,Multilingual Neural Machine Translation with Knowledge Distillation,"[""Xu Tan"", ""Yi Ren"", ""Di He"", ""Tao Qin"", ""Zhou Zhao"", ""Tie-Yan Liu""]","[""NMT"", ""Multilingual NMT"", ""Knowledge Distillation""]",We proposed a knowledge distillation based method to boost the accuracy of multilingual neural machine translation.,,,,
S1gV6AVKwB,2020,Reject,False,Cross Domain Imitation Learning,"[""Kun Ho Kim"", ""Yihong Gu"", ""Jiaming Song"", ""Shengjia Zhao"", ""Stefano Ermon""]","[""Imitation Learning"", ""Domain Adaptation"", ""Reinforcement Learning"", ""Zeroshot Learning"", ""Machine Learning"", ""Artificial Intelligence""]",Imitation learning across domains with discrepancies such as embodiment and viewpoint mismatch. ,,,,
S1gWz2CcKX,2019,Reject,False,Neural MMO: A massively multiplayer game environment for intelligent agents,"[""Joseph Suarez"", ""Yilun Du"", ""Phillip Isola"", ""Igor Mordatch""]","[""MMO"", ""Multiagent"", ""Game"", ""Reinforcement Learning"", ""Platform"", ""Framework"", ""Niche Formation"", ""Exploration""]",An MMO-inspired research game platform for studying emergent behaviors of large populations in a complex environment,,,,
S1gXiaEYvr,2020,Reject,False,Prototype Recalls for Continual Learning,"[""Mengmi Zhang"", ""Tao Wang"", ""Joo Hwee Lim"", ""Jiashi Feng""]","[""continual learning"", ""catastrophic forgetting"", ""prototypes"", ""image classification"", ""few-shot continual learning""]",Prototype recall: a method to prevent catastrophic forgetting in few-shot image classification task,,,,
S1g_EsActm,2019,Reject,False,ATTENTION INCORPORATE NETWORK: A NETWORK CAN ADAPT VARIOUS DATA SIZE,"[""Liangbo He"", ""Hao Sun""]","[""attention mechanism"", ""various image size""]",,,,,
S1g_S0VYvr,2020,Reject,False,Learning to Combat Compounding-Error in Model-Based Reinforcement Learning,"[""Chenjun Xiao"", ""Yifan Wu"", ""Chen Ma"", ""Dale Schuurmans"", ""Martin M\u00fcller""]","[""reinforcement learning"", ""model-based RL""]",,,,,
S1g_t1StDB,2020,Reject,True,Self-Educated Language Agent with Hindsight Experience Replay for Instruction Following,"[""Geoffrey Cideron"", ""Mathieu Seurin"", ""Florian Strub"", ""Olivier Pietquin""]","[""Language"", ""reinforcement learning"", ""instruction following"", ""Hindsight Experience Replay""]",,1910.09451,cs.LG,2019-10-21 15:31:29+00:00,2020-12-10 16:01:45+00:00
S1gd7nCcF7,2019,Reject,False,Self-Supervised Generalisation with Meta Auxiliary Learning,"[""Shikun Liu"", ""Edward Johns"", ""Andrew Davison""]","[""meta learning"", ""auxiliary learning"", ""multi-task learning"", ""self-supervised learning""]","We propose Meta AuXiliary Learning (MAXL), a learning framework which can automatically generate auxiliary tasks to improve generalisation of the principal task in a self-supervised manner. ",,,,
S1geJhC9Km,2019,Reject,False,Feature quantization for parsimonious and interpretable predictive models,"[""Adrien EHRHARDT"", ""Vincent VANDEWALLE"", ""Christophe BIERNACKI"", ""Philippe HEINRICH""]","[""discretization"", ""grouping"", ""interpretability"", ""shallow neural networks""]",We tackle discretization of continuous features and grouping of factor levels as a representation learning problem and provide a rigorous way of estimating the best quantization to yield good performance and interpretability.,,,,
S1gfu3EtDr,2020,Reject,False,EgoMap: Projective mapping and structured egocentric memory for Deep RL,"[""Edward Beeching"", ""Christian Wolf"", ""Jilles Dibangoye"", ""Olivier Simonin""]","[""Reinforcement Learning"", ""Deep Learning"", ""Computer Vision"", ""Robotics"", ""Neural Memory""]",We demonstrate the improvement in generalization performance achieved when spatially structured memory and projective geometry are included in a Deep RL agent's architecture.,2002.02286,cs.LG,2020-01-24 09:59:59+00:00,2020-02-07 14:00:39+00:00
S1ghzlHFPS,2020,Reject,False,Informed Temporal Modeling via Logical Specification of Factorial LSTMs,"[""Hongyuan Mei"", ""Guanghui Qin"", ""Minjie Xu"", ""Jason Eisner""]","[""factorized LSTM"", ""temporal point process"", ""event streams"", ""structural bias"", ""Datalog""]",Factorize LSTM states and zero-out/tie LSTM weight matrices according to real-world structural biases expressed by Datalog programs.,,,,
S1giVsRcYm,2019,Reject,False,Count-Based Exploration with the Successor Representation,"[""Marlos C. Machado"", ""Marc G. Bellemare"", ""Michael Bowling""]","[""reinforcement learning"", ""successor representation"", ""exploration"", ""atari""]","We propose the idea of using the norm of the successor representation an exploration bonus in reinforcement learning. In hard exploration Atari games, our the deep RL algorithm matches the performance of recent pseudo-count-based methods.",,,,
S1giro05t7,2019,Reject,False,Reducing Overconfident Errors outside the Known Distribution,"[""Zhizhong Li"", ""Derek Hoiem""]","[""Machine learning safety"", ""confidence"", ""overconfidence"", ""unknown domain"", ""novel distribution"", ""generalization"", ""distillation"", ""ensemble"", ""underrepresentation""]","Deep networks are more likely to be confidently wrong when testing on unexpected data. We propose an experimental methodology to study the problem, and two methods to reduce confident errors on unknown input distributions.",,,,
S1glGANtDr,2020,Accept (Spotlight),False,Doubly Robust Bias Reduction in Infinite Horizon Off-Policy Estimation,"[""Ziyang Tang*"", ""Yihao Feng*"", ""Lihong Li"", ""Dengyong Zhou"", ""Qiang Liu""]","[""off-policy evaluation"", ""infinite horizon"", ""doubly robust"", ""reinforcement learning""]",We develop a new doubly robust estimator based on the infinite horizon density ratio and off policy value estimation.,,,,
S1gmrxHFvB,2020,Accept (Poster),False,AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty,"[""Dan Hendrycks*"", ""Norman Mu*"", ""Ekin Dogus Cubuk"", ""Barret Zoph"", ""Justin Gilmer"", ""Balaji Lakshminarayanan""]","[""robustness"", ""uncertainty""]","We obtain state-of-the-art on robustness to data shifts, and we maintain calibration under data shift even though even when accuracy drops",,,,
S1gmvyHFDS,2020,Reject,False,Provenance detection through learning transformation-resilient watermarking,"[""Jamie Hayes"", ""Krishnamurthy Dvijotham"", ""Yutian Chen"", ""Sander Dieleman"", ""Pushmeet Kohli"", ""Norman Casagrande""]","[""watermarking"", ""provenance detection""]",Develop a method to detect the provenance of signals that have undergone adversarial transformations.,,,,
S1gnxaVFDB,2020,Reject,True,EDUCE: Explaining model Decision through Unsupervised Concepts Extraction,"[""Diane Bouchacourt"", ""Ludovic Denoyer""]","[""Interpretability"", ""explainability"", ""text processing""]",We propose a new self-interpretable model that performs output prediction and simultaneously provides an explanation in terms of the presence of semantically meaningful concepts in the input. We experiment on multiple text processing tasks.,1905.11852,cs.LG,2019-05-28 14:33:19+00:00,2019-09-27 14:16:30+00:00
S1gqraNKwB,2020,Reject,False,Contextual Inverse Reinforcement Learning,"[""Philip Korsunsky"", ""Stav Belogolovsky"", ""Tom Zahavy"", ""Chen Tessler"", ""Shie Mannor""]","[""Contextual MDP"", ""Inverse Reinforcement Learning"", ""Reinforcement Learning"", ""Mirror Descent""]",We analyze contextual Markov decision processes in an inverse reinforcement learning setting. We propose and analyze several algorithms both theoretically and empirically.,,,,
S1grRoR9tQ,2019,Reject,False,Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation,"[""Wei Deng"", ""Xiao Zhang"", ""Faming Liang"", ""Guang Lin""]","[""generalized stochastic approximation"", ""stochastic gradient Markov chain Monte Carlo"", ""adaptive algorithm"", ""EM algorithm"", ""convolutional neural networks"", ""Bayesian inference"", ""sparse prior"", ""spike and slab prior"", ""local trap""]",a robust Bayesian deep learning algorithm to infer complex posteriors with latent variables,,,,
S1gtclSFvr,2020,Reject,False,Neural Phrase-to-Phrase Machine Translation,"[""Jiangtao"", ""Feng"", ""Lingpeng Kong"", ""Po-sen Huang"", ""Chong"", ""Wang"", ""Da"", ""Huang Jiayuan"", ""Mao"", ""Kan"", ""Qiao"", ""Dengyong"", ""Zhou""]",[],,,,,
S1gvg0NYvH,2020,Reject,False,Mean Field Models for Neural Networks in Teacher-student Setting,"[""Lexing Ying"", ""Yuandong Tian""]","[""mean field model"", ""optimal transport"", ""ResNet""]",We discuss mean field models for two-layer fully-connected networks and ResNet models and characterize stationary distributions in the teacher-student setting.,,,,
S1gwC1StwS,2020,Reject,False,Barcodes as summary of objective functions' topology,"[""Serguei Barannikov"", ""Alexander Korotin"", ""Dmitry Oganesyan"", ""Daniil Emtsev"", ""Evgeny Burnaev""]","[""Barcodes"", ""canonical form invariants"", ""loss surface"", ""gradient complexes""]",We apply canonical forms of gradient complexes (barcodes) to explore neural networks loss surfaces.,,,,
S1gyl6Vtvr,2020,Reject,False,MaskConvNet: Training Efficient ConvNets from Scratch via Budget-constrained Filter Pruning,"[""Raden Mu'az Mun'im"", ""Jie Lin"", ""Vijay Chandrasekhar"", ""Koichi Shinoda""]","[""Structured Pruning"", ""Sparsity Regularization"", ""Budget-Aware""]",,,,,
S1j4RqYxg,2017,Reject,False,Efficient Calculation of Polynomial Features on Sparse Matrices,"[""Andrew Nystrom"", ""John Hughes""]","[""Supervised Learning""]",An algorithm to perform polynomial expansions on CSR matrices that scales with matrix density polynomially.,,,,
S1jBcueAb,2018,Accept (Poster),False,Depthwise Separable Convolutions for Neural Machine Translation,"[""Lukasz Kaiser"", ""Aidan N. Gomez"", ""Francois Chollet""]","[""convolutions"", ""neural machine translation""]",Depthwise separable convolutions improve neural machine translation: the more separable the better.,,,,
S1jE5L5gl,2017,Accept (Poster),False,The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables,"[""Chris J. Maddison"", ""Andriy Mnih"", ""Yee Whye Teh""]","[""Deep learning"", ""Unsupervised Learning"", ""Structured prediction""]",Relaxed reparameterization trick for discrete stochastic units.,,,,
S1jmAotxg,2017,Accept (Poster),False,Stick-Breaking Variational Autoencoders,"[""Eric Nalisnick"", ""Padhraic Smyth""]","[""Deep learning"", ""Unsupervised Learning"", ""Semi-Supervised Learning""]",We define a variational autoencoder variant with stick-breaking latent variables thereby giving it adaptive width.,,,,
S1l-C0NtwS,2020,Accept (Poster),False,Cross-lingual Alignment vs Joint Training: A Comparative Study and A Simple Unified Framework,"[""Zirui Wang*"", ""Jiateng Xie*"", ""Ruochen Xu"", ""Yiming Yang"", ""Graham Neubig"", ""Jaime G. Carbonell""]","[""Cross-lingual Representation""]",We conduct a comparative study of cross-lingual alignment vs joint training methods and unify these two previously exclusive paradigms in a new framework. ,,,,
S1l66nNFvB,2020,Reject,True,Graph Warp Module: an Auxiliary Module for Boosting the Power of Graph Neural Networks in Molecular Graph Analysis,"[""Katsuhiko Ishiguro"", ""Shin-ichi Maeda"", ""Masanori Koyama""]","[""Graph Neural Networks"", ""molecular graph analysis"", ""supernode"", ""auxiliary module""]",Proposing an auxiliary  module with its own I/O that can be attached to a generic GNN of message passing type in order to improve its representation power/ generalization performance on small-graph datasets.,1902.01020,cs.LG,2019-02-04 03:23:40+00:00,2019-05-24 08:00:31+00:00
S1l6ITVKPS,2020,Reject,True,An Explicitly Relational Neural Network Architecture,"[""Murray Shanahan"", ""Kyriacos Nikiforou"", ""Antonia Creswell"", ""Christos Kaplanis"", ""David Barrett"", ""Marta Garnelo""]","[""relational representation""]","We present an end-to-end differentiable architecture that learns to map pixels to predicates, and evaluate it on a suite of simple relational reasoning tasks",1905.10307,cs.LG,2019-05-24 16:03:06+00:00,2020-06-23 13:36:06+00:00
S1l8oANFDH,2020,Accept (Poster),False,Synthesizing Programmatic Policies that Inductively Generalize,"[""Jeevana Priya Inala"", ""Osbert Bastani"", ""Zenna Tavares"", ""Armando Solar-Lezama""]","[""Program synthesis"", ""reinforcement learning"", ""inductive generalization""]",An approach to learn program policies for control tasks that inductively generalize. ,,,,
S1lACa4YDS,2020,Reject,False,Meta-Learning for Variational Inference,"[""Ruqi Zhang"", ""Yingzhen Li"", ""Chris De Sa"", ""Sam Devlin"", ""Cheng Zhang""]","[""Variational inference"", ""Meta-learning""]",,,,,
S1lAOhEKPS,2020,Reject,False,X-Forest: Approximate Random Projection Trees for Similarity Measurement,"[""Yikai Zhao"", ""Peiqing Chen"", ""Zidong Zhao"", ""Tong Yang"", ""Jie Jiang"", ""Bin Cui"", ""Gong Zhang"", ""Steve Uhlig""]",[],,,,,
S1lBTerYwH,2020,Reject,True,Generalized Zero-shot ICD Coding,"[""Congzheng Song"", ""Shanghang Zhang"", ""Najmeh Sadoughi"", ""Pengtao Xie"", ""Eric Xing""]","[""Generalized Zero-shot Learning"", ""ICD Coding"", ""NLP"", ""Generative Model"", ""Deep Learning""]","To solve the generalized zero-shot ICD coding problem, we propose a generative model to generate features that preserve the semantics of the zero-shot codes and exploit the hierarchy structure of the label space.",1909.13154,cs.CL,2019-09-28 21:32:55+00:00,2019-09-28 21:32:55+00:00
S1lBVgHYvr,2020,Reject,False,Towards Certified Defense for Unrestricted Adversarial Attacks,"[""Shengjia Zhao"", ""Yang Song"", ""Stefano Ermon""]","[""Adversarial Defense"", ""Certified Defense"", ""Adversarial Examples""]",,,,,
S1lDV3RcKm,2019,Accept (Poster),False,MisGAN: Learning from Incomplete Data with Generative Adversarial Networks,"[""Steven Cheng-Xian Li"", ""Bo Jiang"", ""Benjamin Marlin""]","[""generative models"", ""missing data""]",This paper presents a GAN-based framework for learning the distribution from high-dimensional incomplete data.,1902.09599,cs.LG,2019-02-25 20:24:35+00:00,2019-02-25 20:24:35+00:00
S1lDkaEFwS,2020,Reject,False,Thwarting finite difference adversarial attacks with output randomization,"[""Haidar Khan"", ""Dan Park"", ""Azer Khan"", ""B\u00fclent Yener""]","[""black box adversarial attacks"", ""adversarial examples"", ""defense"", ""deep learning""]",Black box adversarial attacks are rendered ineffective by simple randomization of neural network outputs.,,,,
S1lEX04tPr,2020,Accept (Poster),True,CM3: Cooperative Multi-goal Multi-stage Multi-agent Reinforcement Learning,"[""Jiachen Yang"", ""Alireza Nakhaei"", ""David Isele"", ""Kikuo Fujimura"", ""Hongyuan Zha""]","[""multi-agent reinforcement learning""]","A modular method for fully cooperative multi-goal multi-agent reinforcement learning, based on curriculum learning for efficient exploration and credit assignment for action-goal interactions.",1809.05188,cs.LG,2018-09-13 21:46:54+00:00,2020-01-24 21:24:17+00:00
S1lF8xHYwS,2020,Reject,True,Unsupervised Domain Adaptation through Self-Supervision,"[""Yu Sun"", ""Eric Tzeng"", ""Trevor Darrell"", ""Alexei A. Efros""]","[""unsupervised domain adaptation""]",We use self-supervision on both domain to align them for unsupervised domain adaptation.,1909.11825,cs.LG,2019-09-26 00:21:16+00:00,2019-09-29 08:09:29+00:00
S1lHfxBFDH,2020,Reject,False,Gumbel-Matrix Routing for Flexible Multi-task Learning,"[""Krzysztof Maziarz"", ""Efi Kokiopoulou"", ""Andrea Gesmundo"", ""Luciano Sbaiz"", ""Gabor Bartok"", ""Jesse Berent""]",[],,,,,
S1lIMn05F7,2019,Accept (Poster),False,A Direct Approach to Robust Deep Learning Using Adversarial Networks,"[""Huaxia Wang"", ""Chun-Nam Yu""]","[""deep learning"", ""adversarial learning"", ""generative adversarial networks""]",Jointly train an adversarial noise generating network with a classification network to provide better robustness to adversarial attacks.,,,,
S1lJv0VYDr,2020,Reject,False,Model Imitation for Model-Based Reinforcement Learning,"[""Yueh-Hua Wu"", ""Ting-Han Fan"", ""Peter J. Ramadge"", ""Hao Su""]","[""Model-Based Reinforcement Learning""]",Our method incorporates WGAN to achieve occupancy measure matching for transition learning.,,,,
S1lKSjRcY7,2019,Reject,False,Improved Gradient Estimators for Stochastic Discrete Variables,"[""Evgeny Andriyash"", ""Arash Vahdat"", ""Bill Macready""]","[""continuous relaxation"", ""discrete stochastic variables"", ""reparameterization trick"", ""variational inference"", ""discrete optimization"", ""stochastic gradient estimation""]",We propose simple ways to reduce bias and complexity of stochastic gradient estimators used for learning distributions over discrete variables.,,,,
S1lN69AT-,2018,Invite to Workshop Track,False,"To Prune, or Not to Prune: Exploring the Efficacy of Pruning for Model Compression","[""Michael H. Zhu"", ""Suyog Gupta""]","[""pruning"", ""model sparsity"", ""model compression"", ""deep learning""]","We demonstrate that large, but pruned models (large-sparse) outperform their smaller, but dense (small-dense) counterparts with identical memory footprint.",,,,
S1lNWertDr,2020,Reject,True,Decoupling Hierarchical Recurrent Neural Networks With Locally Computable Losses,"[""Asier Mujika"", ""Felix Weissenberger"", ""Angelika Steger""]",[],We replace some gradients paths in hierarchical RNN's by an auxiliary loss. We show that this can reduce the memory cost while preserving performance.,1910.05245,cs.LG,2019-10-11 15:25:28+00:00,2019-10-11 15:25:28+00:00
S1lOTC4tDS,2020,Accept (Spotlight),False,Dream to Control: Learning Behaviors by Latent Imagination,"[""Danijar Hafner"", ""Timothy Lillicrap"", ""Jimmy Ba"", ""Mohammad Norouzi""]","[""world model"", ""latent dynamics"", ""imagination"", ""planning by backprop"", ""policy optimization"", ""planning"", ""reinforcement learning"", ""control"", ""representations"", ""latent variable model"", ""visual control"", ""value function""]","We present Dreamer, an agent that learns long-horizon behaviors purely by latent imagination using analytic value gradients.",1912.01603,cs.LG,2019-12-03 18:57:16+00:00,2020-03-17 17:10:58+00:00
S1lPShAqFm,2019,Reject,False,Empirically Characterizing Overparameterization Impact on Convergence,"[""Newsha Ardalani"", ""Joel Hestness"", ""Gregory Diamos""]","[""gradient descent"", ""optimization"", ""convergence time"", ""halting time"", ""characterization""]","Empirically shows that larger models train in fewer training steps, because all factors in weight space traversal improve.",,,,
S1lRg0VKDr,2020,Reject,False,On summarized validation curves and generalization,"[""Mohammad Hashir"", ""Yoshua Bengio"", ""Joseph Paul Cohen""]","[""model selection"", ""deep learning"", ""early stopping"", ""validation curves""]",,,,,
S1lSapVtwS,2020,Accept (Poster),True,Stochastic Conditional Generative Networks with Basis Decomposition,"[""Ze Wang"", ""Xiuyuan Cheng"", ""Guillermo Sapiro"", ""Qiang Qiu""]",[],,1909.11286,cs.CV,2019-09-25 04:37:38+00:00,2020-02-24 19:35:47+00:00
S1lTEh09FQ,2019,Accept (Poster),False,Combinatorial Attacks on Binarized Neural Networks,"[""Elias B Khalil"", ""Amrita Gupta"", ""Bistra Dilkina""]","[""binarized neural networks"", ""combinatorial optimization"", ""integer programming""]",Gradient-based attacks on binarized neural networks are not effective due to the non-differentiability of such networks; Our IPROP algorithm solves this problem using integer optimization,,,,
S1lTg3RcFm,2019,Reject,False,Perception-Aware Point-Based Value Iteration for Partially Observable Markov Decision Processes,"[""Mahsa Ghasemi"", ""Ufuk Topcu""]","[""partially observable Markov decision processes"", ""active perception"", ""submodular optimization"", ""point-based value iteration"", ""reinforcement learning""]",We develop a point-based value iteration solver for POMDPs with active perception and planning tasks.,,,,
S1lTg3RqYQ,2019,Accept (Poster),True,Exemplar Guided Unsupervised Image-to-Image Translation with Semantic Consistency,"[""Liqian Ma"", ""Xu Jia"", ""Stamatios Georgoulis"", ""Tinne Tuytelaars"", ""Luc Van Gool""]","[""image-to-image translation"", ""image generation"", ""domain adaptation""]",We propose the Exemplar Guided & Semantically Consistent Image-to-image Translation (EGSC-IT) network which conditions the translation process on an exemplar image in the target domain.,1805.11145,cs.CV,2018-05-28 19:47:07+00:00,2019-03-13 18:30:30+00:00
S1lVhxSYPH,2020,Reject,False,Ternary MobileNets via Per-Layer Hybrid Filter Banks,"[""Dibakar Gope"", ""Jesse G Beu"", ""Urmish Thakker"", ""Matthew Mattina""]","[""Model compression"", ""ternary quantization"", ""energy-efficient models""]","2x savings in model size, 28% energy reduction for MobileNets on ImageNet at no loss in accuracy using hybrid layers composed of conventional full-precision filters and ternary filters",,,,
S1lVniC5Y7,2019,Reject,False,From Nodes to Networks: Evolving Recurrent Neural Networks,"[""Aditya Rawal"", ""Jason Liang"", ""Risto Miikkulainen""]","[""Recurrent neural networks"", ""evolutionary algorithms"", ""genetic programming""]",Genetic programming to evolve new recurrent nodes for language and music. Uses a LSTM model to predict the performance of the recurrent node. ,,,,
S1lXnhVKPr,2020,Reject,False,Variance Reduced Local SGD with Lower Communication Complexity,"[""Xianfeng Liang"", ""Shuheng Shen"", ""Jingchang Liu"", ""Zhen Pan"", ""Yifei Cheng"", ""Enhong Chen""]","[""variance reduction"", ""local SGD"", ""distributed optimization""]",We prove that the proposed algorithm can achieve linear iteration speedup with lower communication complexity than Local SGD and the experimental results verify our theoretical clarification.,,,,
S1l_ZlrFvS,2020,Reject,True,Why do These Match? Explaining the Behavior of Image Similarity Models,"[""Bryan A. Plummer"", ""Mariya I. Vasileva"", ""Vitali Petsiuk"", ""Kate Saenko"", ""David Forsyth""]","[""explainable artificial intelligence"", ""image similarity"", ""artificial intelligence for fashion""]",A black box approach for explaining the predictions of an image similarity model.,1905.10797,cs.CV,2019-05-26 12:48:23+00:00,2020-08-24 16:14:37+00:00
S1ldO2EFPr,2020,Accept (Spotlight),True,Graph Neural Networks Exponentially Lose Expressive Power for Node Classification,"[""Kenta Oono"", ""Taiji Suzuki""]","[""Graph Neural Network"", ""Deep Learning"", ""Expressive Power""]",We relate the asymptotic behavior of graph neural networks to the graph spectra of underlying graphs and gives principled guidelines for normalizing weights.,1905.10947,cs.LG,2019-05-27 02:59:06+00:00,2021-01-06 13:32:14+00:00
S1lg0jAcYm,2019,Accept (Poster),False,ARM: Augment-REINFORCE-Merge Gradient for Stochastic Binary Networks,"[""Mingzhang Yin"", ""Mingyuan Zhou""]","[""Antithetic sampling"", ""variable augmentation"", ""deep discrete latent variable models"", ""variance reduction"", ""variational auto-encoder""]",An unbiased and low-variance gradient estimator for discrete latent variable models,,,,
S1lhbnRqF7,2019,Accept (Poster),False,Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension,"[""Rajarshi Das"", ""Tsendsuren Munkhdalai"", ""Xingdi Yuan"", ""Adam Trischler"", ""Andrew McCallum""]","[""recurrent graph networks"", ""dynamic knowledge base construction"", ""entity state tracking"", ""machine reading comprehension""]",,,,,
S1lk61BtvB,2020,Reject,True,"``""Best-of-Many-Samples"" Distribution Matching","[""Apratim Bhattacharyya"", ""Mario Fritz"", ""Bernt Schiele""]","[""Distribution Matching"", ""Generative Adversarial Networks"", ""Variational Autoencoders""]",We propose a new objective for training hybrid VAE-GANs which lead to significant improvement in mode coverage and quality.,1909.12598,cs.LG,2019-09-27 10:23:42+00:00,2019-09-27 10:23:42+00:00
S1llBiR5YX,2019,Reject,False,Accidental exploration through value predictors,"[""Tomasz Kisielewski"", ""Damian Le\u015bniak"", ""Maia Pasek""]","[""reinforcement learning"", ""value predictors"", ""exploration""]","We study the biases introduced in common value predictors by the fact that trajectories are, in practice, finite.",,,,
S1lqMn05Ym,2019,Accept (Poster),False,Information asymmetry in KL-regularized RL,"[""Alexandre Galashov"", ""Siddhant M. Jayakumar"", ""Leonard Hasenclever"", ""Dhruva Tirumala"", ""Jonathan Schwarz"", ""Guillaume Desjardins"", ""Wojciech M. Czarnecki"", ""Yee Whye Teh"", ""Razvan Pascanu"", ""Nicolas Heess""]","[""Deep Reinforcement Learning"", ""Continuous Control"", ""RL as Inference""]","Limiting state information for the default policy can improvement performance, in a KL-regularized RL framework where both agent and default policy are optimized together",,,,
S1lslCEYPB,2020,Reject,False,Improved Mutual Information Estimation,"[""Youssef Mroueh*"", ""Igor Melnyk*"", ""Pierre Dognin*"", ""Jerret Ross*"", ""Tom Sercu*""]","[""mutual information"", ""variational bound"", ""kernel methods"", ""Neural estimators"", ""mutual information maximization"", ""self-supervised learning""]",we propose a new variational bound for estimating mutual information and show the strength of our estimator in large-scale self-supervised representation learning through MI maximization.,,,,
S1ltg1rFDS,2020,Accept (Poster),False,Black-box Off-policy Estimation for Infinite-Horizon Reinforcement Learning,"[""Ali Mousavi"", ""Lihong Li"", ""Qiang Liu"", ""Denny Zhou""]","[""reinforcement learning"", ""off-policy estimation"", ""importance sampling"", ""propensity score""]",We present a novel approach for the off-policy estimation problem in infinite-horizon RL.,2003.11126,cs.LG,2020-03-24 21:44:51+00:00,2020-03-24 21:44:51+00:00
S1lukyrKPr,2020,Reject,False,LEX-GAN: Layered Explainable Rumor Detector Based on Generative Adversarial Networks,"[""Mingxi Cheng"", ""Yizhi Li"", ""Shahin Nazarian"", ""Paul Bogdan""]","[""explainable rumor detection"", ""layered generative adversarial networks""]",,,,,
S1lvm305YQ,2019,Accept (Poster),False,TimbreTron: A WaveNet(CycleGAN(CQT(Audio))) Pipeline for Musical Timbre Transfer,"[""Sicong Huang"", ""Qiyang Li"", ""Cem Anil"", ""Xuchan Bao"", ""Sageev Oore"", ""Roger B. Grosse""]","[""Generative models"", ""Timbre Transfer"", ""Wavenet"", ""CycleGAN""]","We present the TimbreTron, a pipeline for perfoming high-quality timbre transfer on musical waveforms using CQT-domain style transfer.",,,,
S1lvn0NtwH,2020,Reject,False,Mutual Exclusivity as a Challenge for Deep Neural Networks,"[""Kanishk Gandhi"", ""Brenden Lake""]","[""Cognitive Science"", ""Deep Learning"", ""Word Learning"", ""Lifelong Learning""]","Children use the mutual exclusivity (ME) bias to learn new words, while standard neural nets show the opposite bias, hindering learning in naturalistic scenarios such as lifelong learning.",,,,
S1lwRjR9YX,2019,Reject,False,Stability of Stochastic Gradient Method with Momentum for Strongly Convex Loss Functions,"[""Ali Ramezani-Kebrya"", ""Ashish Khisti"", ""and Ben Liang""]","[""Generalization Error"", ""Stochastic Gradient Descent"", ""Uniform Stability""]",Stochastic gradient method with momentum generalizes.,,,,
S1lxKlSKPH,2020,Accept (Poster),False,Consistency Regularization for Generative Adversarial Networks,"[""Han Zhang"", ""Zizhao Zhang"", ""Augustus Odena"", ""Honglak Lee""]","[""Generative Adversarial Networks"", ""Consistency Regularization"", ""GAN""]",,,,,
S1ly10EKDS,2020,Accept (Poster),False,Reanalysis of Variance Reduced Temporal Difference Learning,"[""Tengyu Xu"", ""Zhe Wang"", ""Yi Zhou"", ""Yingbin Liang""]","[""Reinforcement Learning"", ""TD learning"", ""Markovian sample"", ""Variance Reduction""]",This paper provides a rigorous study of the variance reduced TD learning and characterizes its advantage over vanilla TD learning,2001.01898,cs.LG,2020-01-07 05:32:43+00:00,2020-01-10 07:22:15+00:00
S1ly2grtvB,2020,Reject,False,IS THE LABEL TRUSTFUL: TRAINING BETTER DEEP LEARNING MODEL VIA UNCERTAINTY MINING NET,"[""Yang Sun"", ""Abhishek Kolagunda"", ""Steven Eliuk"", ""Xiaolong Wang""]","[""Semi-supervised Learning"", ""Robust Learning"", ""Deep Generative Model""]",,,,,
S1lyyANYwr,2020,Reject,False,Constrained Markov Decision Processes via Backward Value Functions,"[""Harsh Satija"", ""Philip Amortila"", ""Joelle Pineau""]","[""Reinforcement Learning"", ""Constrained Markov Decision Processes"", ""Deep Reinforcement Learning""]","We present an on-policy method for solving constrained MDPs that respects trajectory-level constraints by converting them into local state-dependent constraints, and works for both discrete and continuous high-dimensional spaces.",2008.11811,cs.LG,2020-08-26 20:56:16+00:00,2020-08-26 20:56:16+00:00
S1m6h21Cb,2018,Reject,False,The Cramer Distance as a Solution to Biased Wasserstein Gradients,"[""Marc G. Bellemare"", ""Ivo Danihelka"", ""Will Dabney"", ""Shakir Mohamed"", ""Balaji Lakshminarayanan"", ""Stephan Hoyer"", ""Remi Munos""]","[""Probability metrics"", ""Wasserstein metric"", ""stochastic gradient descent"", ""GANs""]","The Wasserstein distance is hard to minimize with stochastic gradient descent, while the Cramer distance can be optimized easily and works just as well.",,,,
S1nQvfgA-,2018,Accept (Poster),False,Semantically Decomposing the Latent Spaces of Generative Adversarial Networks,"[""Chris Donahue"", ""Zachary C. Lipton"", ""Akshay Balsubramani"", ""Julian McAuley""]","[""disentangled representations"", ""generative adversarial networks"", ""generative modeling"", ""image synthesis""]",SD-GANs disentangle latent codes according to known commonalities in a dataset (e.g. photographs depicting the same person).,,,,
S1oWlN9ll,2017,Accept (Poster),False,Loss-aware Binarization of Deep Networks,"[""Lu Hou"", ""Quanming Yao"", ""James T. Kwok""]","[""Deep learning"", ""Applications"", ""Optimization""]",,,,,
S1pWFzbAW,2018,Invite to Workshop Track,False,Weightless: Lossy Weight Encoding For Deep Neural Network Compression,"[""Brandon Reagen"", ""Udit Gupta"", ""Robert Adolf"", ""Michael Mitzenmacher"", ""Alexander Rush"", ""Gu-Yeon Wei"", ""David Brooks""]","[""Deep Neural Network"", ""Compression"", ""Sparsity""]",We propose a new way to compress neural networks using probabilistic data structures.,,,,
S1q_Cz-Cb,2018,Reject,False,Training Neural Machines with Partial Traces,"[""Matthew Mirman"", ""Dimitar Dimitrov"", ""Pavle Djordjevich"", ""Timon Gehr"", ""Martin Vechev""]","[""Neural Abstract Machines"", ""Neural Turing Machines"", ""Neural Random Access Machines"", ""Program Synthesis"", ""Program Induction""]",We increase the amount of trace supervision possible to utilize when training fully differentiable neural machine architectures.,,,,
S1sRrN-CW,2018,Reject,False,Revisiting Knowledge Base Embedding as Tensor Decomposition,"[""Jiezhong Qiu"", ""Hao Ma"", ""Yuxiao Dong"", ""Kuansan Wang"", ""Jie Tang""]","[""Knowledge base embedding""]",,,,,
S1sqHMZCb,2018,Accept (Poster),False,NerveNet: Learning Structured Policy with Graph Neural Networks,"[""Tingwu Wang"", ""Renjie Liao"", ""Jimmy Ba"", ""Sanja Fidler""]","[""reinforcement learning"", ""transfer learning"", ""graph neural network""]",using graph neural network to model structural information of the agents to improve policy and transferability ,,,,
S1tWRJ-R-,2018,Reject,False,Joint autoencoders: a flexible meta-learning framework,"[""Baruch Epstein"", ""Ron Meir"", ""Tomer Michaeli""]","[""transfer learning"", ""domain adaptation"", ""unsupervised learning"", ""autoencoders"", ""multi-task learning""]",A generic framework for handling transfer and multi-task learning using pairs of autoencoders with task-specific and shared weights.,,,,
S1uxsye0Z,2018,Accept (Poster),False,Adaptive Dropout with Rademacher Complexity Regularization,"[""Ke Zhai"", ""Huan Wang""]","[""model complexity"", ""regularization"", ""deep learning"", ""model generalization"", ""adaptive dropout""]",We propose a novel framework to adaptively adjust the dropout rates for the deep neural network based on a Rademacher complexity bound.,,,,
S1v4N2l0-,2018,Accept (Poster),False,Unsupervised Representation Learning by Predicting Image Rotations,"[""Spyros Gidaris"", ""Praveer Singh"", ""Nikos Komodakis""]","[""Unsupervised representation learning""]",,,,,
S1viikbCW,2018,Reject,False,TCAV: Relative concept importance testing with Linear Concept Activation Vectors,"[""Been Kim"", ""Justin Gilmer"", ""Martin Wattenberg"", ""Fernanda Vi\u00e9gas""]",[],"This work aims to provide quantitative answers to the relative importance of concepts of interest via concept activation vectors (CAV). In particular, this framework enables non-machine learning experts to express concepts of interest and test hypotheses using examples (e.g., a set of pictures that illustrate  the concept). We show that CAV can be learned given a relatively small set of examples. Hypothesis testing with CAV can answer whether a particular concept (e.g., gender) is more important in predicting a given class (e.g., doctor) than other sets of concepts. Interpreting networks with CAV does not require any retraining or modification of the network. ",,,,
S1vuO-bCW,2018,Accept (Poster),False,Leave no Trace: Learning to Reset for Safe and Autonomous Reinforcement Learning,"[""Benjamin Eysenbach"", ""Shixiang Gu"", ""Julian Ibarz"", ""Sergey Levine""]","[""manual reset"", ""continual learning"", ""reinforcement learning"", ""safety""]","We propose an autonomous method for safe and efficient reinforcement learning that simultaneously learns a forward and backward policy, with the backward policy resetting the environment for a subsequent attempt.",,,,
S1vyujVye,2017,Reject,False,Deep unsupervised learning through spatial contrasting,"[""Elad Hoffer"", ""Itay Hubara"", ""Nir Ailon""]","[""Unsupervised Learning"", ""Deep learning"", ""Computer vision""]",,,,,
S1x0CnEtvB,2020,Reject,False,AutoGrow: Automatic Layer Growing in Deep Convolutional Networks,"[""Wei Wen"", ""Feng Yan"", ""Hai Li""]","[""Growing"", ""depth"", ""neural networks"", ""automation""]",A method that automatically grows layers in neural networks to discover optimal depth.,,,,
S1x1IkHtPr,2020,Reject,True,A Generative Model for Molecular Distance Geometry,"[""Gregor N. C. Simm"", ""Jos\u00e9 Miguel Hern\u00e1ndez-Lobato""]","[""graph neural networks"", ""variational autoencoders"", ""distance geometry"", ""molecular conformation""]",Neural network based generative model for molecular conformations utilizing Euclidean distance geometry.,1909.11459,stat.ML,2019-09-25 12:56:50+00:00,2020-08-13 17:06:13+00:00
S1x2Fj0qKQ,2019,Accept (Poster),False,Whitening and Coloring Batch Transform for GANs,"[""Aliaksandr Siarohin"", ""Enver Sangineto"", ""Nicu Sebe""]","[""Generative Adversarial Networks"", ""conditional GANs"", ""Batch Normalization""]",,,,,
S1x2PCNKDB,2020,Reject,False,Task-Relevant Adversarial Imitation Learning,"[""Konrad Zolna"", ""Scott Reed"", ""Alexander Novikov"", ""Ziyu Wang"", ""Sergio G\u00f3mez"", ""David Budden"", ""Serkan Cabi"", ""Misha Denil"", ""Nando de Freitas""]","[""adversarial"", ""imitation"", ""robot"", ""manipulation""]","Improve GAIL by preventing the discriminator from exploiting task-irrelevant information, to solve difficult sim robot manipulation tasks from pixels.",,,,
S1x2aiRqFX,2019,Reject,False,Differentiable Expected BLEU for Text Generation,"[""Wentao Wang"", ""Zhiting Hu"", ""Zichao Yang"", ""Haoran Shi"", ""Eric P. Xing""]","[""text generation"", ""BLEU"", ""differentiable"", ""gradient descent"", ""maximum likelihood learning"", ""policy gradient"", ""machine translation""]",A new differentiable expected BLEU objective that is end-to-end trainable with gradient descent for neural text generation models,,,,
S1x4ghC9tQ,2019,Accept (Oral),False,Temporal Difference Variational Auto-Encoder,"[""Karol Gregor"", ""George Papamakarios"", ""Frederic Besse"", ""Lars Buesing"", ""Theophane Weber""]","[""generative models"", ""variational auto-encoders"", ""state space models"", ""temporal difference learning""]","Generative model of temporal data, that builds online belief state, operates in latent space, does jumpy predictions and rollouts of states.",,,,
S1x522NFvS,2020,Reject,False,On unsupervised-supervised risk and one-class neural networks,"[""Christophe Cerisara""]","[""unsupervised training"", ""one-class models""]",,,,,
S1x63TEYvr,2020,Reject,False,Latent Question Reformulation and Information Accumulation for Multi-Hop Machine Reading,"[""Quentin Grail"", ""Julien Perez"", ""Eric Gaussier""]","[""question-answering"", ""machine comprehension"", ""deep learning""]","In this paper, we propose the Latent Question Reformulation Network (LQR-net), a multi-hop and parallel attentive network designed for question-answering tasks that require reasoning capabilities.",,,,
S1x6TlBtwB,2020,Reject,False,Mixture Distributions for Scalable Bayesian Inference,"[""Pranav Poduval"", ""Hrushikesh Loya"", ""Rajat Patel"", ""Sumit Jain""]","[""uncertainty estimation"", ""Deep Ensembles"", ""Adverserial Robustness""]",Scalable Bayesian NN's Alternative to Deep Ensemble,,,,
S1x8WnA5Ym,2019,Reject,False,Learning Diverse Generations using Determinantal Point Processes,"[""Mohamed Elfeki"", ""Camille Couprie"", ""Mohamed Elhoseiny""]","[""Generative Adversarial Networks""]",The addition of a diversity criterion inspired from DPP in the GAN objective avoids mode collapse and leads to better generations. ,,,,
S1xBioR5KX,2019,Reject,False,Parameter efficient training of deep convolutional neural networks by dynamic sparse reparameterization,"[""Hesham Mostafa"", ""Xin Wang""]","[""sparse"", ""reparameterization"", ""overparameterization"", ""convolutional neural network"", ""training"", ""compression"", ""pruning""]","We describe a dynamic sparse reparameterization technique that allow training of a small sparse network to generalize on par with, or better than, a full-sized dense model compressed to the same size.  ",,,,
S1xCPJHtDB,2020,Accept (Spotlight),False,Model Based Reinforcement Learning for Atari,"[""\u0141ukasz Kaiser"", ""Mohammad Babaeizadeh"", ""Piotr Mi\u0142os"", ""B\u0142a\u017cej Osi\u0144ski"", ""Roy H Campbell"", ""Konrad Czechowski"", ""Dumitru Erhan"", ""Chelsea Finn"", ""Piotr Kozakowski"", ""Sergey Levine"", ""Afroz Mohiuddin"", ""Ryan Sepassi"", ""George Tucker"", ""Henryk Michalewski""]","[""reinforcement learning"", ""model based rl"", ""video prediction model"", ""atari""]","We use video prediction models, a model-based reinforcement learning algorithm and 2h of gameplay per game to train agents for 26 Atari games.",,,,
S1xCcpNYPr,2020,Reject,False,Cost-Effective Testing of a Deep Learning Model through Input Reduction,"[""Jianyi Zhou"", ""Feng Li"", ""Jinhao Dong"", ""Hongyu Zhang"", ""Dan Hao""]","[""Software Testing"", ""Deep Learning"", ""Input Data Reduction""]","we propose DeepReduce, a software engineering approach to cost-effective testing of Deep Learning models.",,,,
S1xCuTNYDr,2020,Reject,True,Regularizing Black-box Models for Improved Interpretability,"[""Gregory Plumb"", ""Maruan Al-Shedivat"", ""Eric Xing"", ""Ameet Talwalkar""]","[""Interpretable Machine Learning"", ""Local Explanations"", ""Regularization""]","If you train your model with our regularizers, black-box explanations systems will work better on the resulting model.  Further, its likely that the resulting model will be more accurate as well.  ",1906.01431,cs.LG,2019-05-31 20:18:33+00:00,2019-05-31 20:18:33+00:00
S1xDcSR6W,2018,Reject,False,Hybed: Hyperbolic Neural Graph Embedding,"[""Benjamin Paul Chamberlain"", ""James R Clough"", ""Marc Peter Deisenroth""]","[""embeddings"", ""hyperbolic space"", ""neural networks"", ""geometry""]",We learn neural embeddings of graphs in hyperbolic instead of Euclidean space,,,,
S1xFl64tDr,2020,Accept (Poster),False,Interpretable Complex-Valued Neural Networks for Privacy Protection,"[""Liyao Xiang"", ""Hao Zhang"", ""Haotian Ma"", ""Yifan Zhang"", ""Jie Ren"", ""Quanshi Zhang""]","[""Deep Learning"", ""Privacy Protection"", ""Complex-Valued Neural Networks""]",,,,,
S1xGCAVKvr,2020,Reject,False,LEARNING  TO LEARN  WITH  BETTER  CONVERGENCE,"[""Patrick H. Chen"", ""Sashank Reddi"", ""Sanjiv Kumar"", ""Cho-Jui Hsieh""]",[],,,,,
S1xHfxHtPr,2020,Reject,False,Online Learned Continual Compression with Stacked Quantization Modules,"[""Lucas Caccia"", ""Eugene Belilovsky"", ""Massimo Caccia"", ""Joelle Pineau""]","[""continual learning"", ""lifelong learning""]",We propose an approach for learning to compress online from a non-iid data stream. We argue for the relevance of this problem and show promising results in downstream applications,,,,
S1xI_TEtwS,2020,Reject,False,Amata: An Annealing Mechanism for Adversarial Training Acceleration,"[""Nanyang Ye"", ""Qianxiao Li"", ""Zhanxing Zhu""]",[],Amata: a simple modification to PGD reduces the adversarial training time to 1/2~1/3.,,,,
S1xJ4JHFvS,2020,Reject,False,Acutum: When Generalization Meets Adaptability,"[""Xunpeng Huang"", ""Zhengyang Liu"", ""Zhe Wang"", ""Yue Yu"", ""Lei Li""]","[""optimization"", ""momentum"", ""adaptive gradient methods""]",,,,,
S1xJFREKvB,2020,Reject,False,Amortized Nesterov's Momentum: Robust and Lightweight  Momentum for Deep Learning,"[""Kaiwen Zhou"", ""Yanghua Jin"", ""Qinghua Ding"", ""James Cheng""]","[""momentum"", ""nesterov"", ""optimization"", ""deep learning"", ""neural networks""]","Amortizing Nesterov's momentum for more robust, lightweight and fast deep learning training.",,,,
S1xJikHtDH,2020,Reject,False,Improving Model Compatibility of Generative Adversarial Networks by Boundary Calibration,"[""Si-An Chen"", ""Chun-Liang Li"", ""Hsuan-Tien Lin""]","[""generative adversarial network"", ""GAN"", ""model compatibility"", ""machine learning efficacy""]",We propose an auxiliary loss of GAN which improves the accuracy of classifiers trained on the generated data by leveraging pre-trained classifiers.,2111.02316,cs.LG,2021-11-03 16:08:09+00:00,2021-11-03 16:08:09+00:00
S1xKYJSYwS,2020,Reject,False,VAENAS: Sampling Matters in Neural Architecture Search,"[""Shizheng Qin"", ""Yichen Zhu"", ""Pengfei Hou"", ""Xiangyu Zhang"", ""Wenqiang Zhang"", ""Jian Sun""]",[],,,,,
S1xKd24twB,2020,Accept (Poster),True,SQIL: Imitation Learning via Reinforcement Learning with Sparse Rewards,"[""Siddharth Reddy"", ""Anca D. Dragan"", ""Sergey Levine""]","[""Imitation Learning"", ""Reinforcement Learning""]","A simple and effective alternative to adversarial imitation learning: initialize experience replay buffer with demonstrations, set their reward to +1, set reward for all other data to 0, run Q-learning or soft actor-critic to train.",1905.11108,cs.LG,2019-05-27 10:29:31+00:00,2019-09-25 18:44:47+00:00
S1xLN3C9YX,2019,Accept (Poster),False,Learnable Embedding Space for Efficient Neural Architecture Compression,"[""Shengcao Cao"", ""Xiaofang Wang"", ""Kris M. Kitani""]","[""Network Compression"", ""Neural Architecture Search"", ""Bayesian Optimization"", ""Architecture Embedding""]","We propose a method to incrementally learn an embedding space over the domain of network architectures, to enable the careful selection of architectures for evaluation during compressed architecture search.",1902.00383,cs.CV,2019-02-01 14:54:17+00:00,2019-04-25 15:03:04+00:00
S1xLZ2R5KQ,2019,Reject,False,Maximum a Posteriori on a Submanifold: a General Image Restoration Method with GAN,"[""Fangzhou Luo"", ""Xiaolin Wu""]",[],,,,,
S1xLuRVFvr,2020,Reject,True,Visual Explanation for Deep Metric Learning,"[""Sijie Zhu"", ""Taojiannan Yang"", ""Chen Chen""]","[""Metric Learning"", ""Visual Explanation""]",,1909.12977,cs.CV,2019-09-27 22:30:58+00:00,2021-08-28 21:11:03+00:00
S1xNEhR9KX,2019,Accept (Poster),False,On the Sensitivity of Adversarial Robustness to Input Data Distributions,"[""Gavin Weiguang Ding"", ""Kry Yik Chau Lui"", ""Xiaomeng Jin"", ""Luyu Wang"", ""Ruitong Huang""]","[""adversarial robustness"", ""adversarial training"", ""PGD training"", ""adversarial perturbation"", ""input data distribution""]","Robustness performance of PGD trained models are sensitive to semantics-preserving transformation of image datasets, which implies the trickiness of evaluation of robust learning algorithms in practice.",,,,
S1xNb2A9YX,2019,Accept (Poster),False,Minimal Images in Deep Neural Networks: Fragile Object Recognition in Natural Images,"[""Sanjana Srivastava"", ""Guy Ben-Yosef"", ""Xavier Boix""]",[],,,,,
S1xO4xHFvB,2020,Reject,False,Atomic Compression Networks,"[""Jonas Falkner"", ""Josif Grabocka"", ""Lars Schmidt-Thieme""]","[""Network Compression""]","We advance the state-of-the-art in model compression by proposing Atomic Compression Networks (ACNs), a novel architecture that is constructed by recursive repetition of a small set of neurons.",,,,
S1xRnxSYwS,2020,Reject,False,Goten: GPU-Outsourcing Trusted Execution of Neural Network Training and Prediction,"[""Lucien K.L. Ng"", ""Sherman S.M. Chow"", ""Anna P.Y. Woo"", ""Donald P. H. Wong"", ""Yongjun Zhao""]","[""machine learning"", ""security"", ""privacy"", ""TEE"", ""trusted processors"", ""Intel SGX"", ""GPU"", ""high-performance""]","Leveraging GPU and Intel SGX to protect privacy of training data, model, and queries while achieving high-performance training and prediction",,,,
S1xRxgSFvH,2020,Reject,False,ShardNet: One Filter Set to Rule Them All,"[""Saumya Jetley"", ""Tommaso Cavallari"", ""Philip Torr"", ""Stuart Golodetz""]","[""neural network compression"", ""filter sharing"", ""network interpretability""]","We compress deep CNNs by reusing a single convolutional layer in an iterative manner, thereby reducing their parameter counts by a factor proportional to their depth, whilst leaving their accuracies largely unaffected",,,,
S1xSzyrYDB,2020,Reject,False,Cyclic Graph Dynamic Multilayer Perceptron for Periodic Signals,"[""Mikio Furokawa"", ""Erik Gest"", ""Takayuki Hirano"", ""Kamal Youcef-Toumi""]",[],,,,,
S1xWh1rYwB,2020,Accept (Talk),False,Restricting the Flow: Information Bottlenecks for Attribution,"[""Karl Schulz"", ""Leon Sixt"", ""Federico Tombari"", ""Tim Landgraf""]","[""Attribution"", ""Informational Bottleneck"", ""Interpretable Machine Learning"", ""Explainable AI""]",We apply the informational bottleneck concept to attribution.,2001.00396,stat.ML,2020-01-02 11:24:35+00:00,2020-05-25 14:21:37+00:00
S1xXiREKDB,2020,Reject,False,Adversarial training with perturbation generator networks,"[""Hyeungill Lee"", ""Sungyeob Han"", ""Jungwoo Lee""]","[""Adversarial training"", ""Generative model"", ""Adaptive perturbation generator"", ""Robust optimization""]",We proposed the adaptive adversarial training algorithm with learnable perturbation generator networks.,,,,
S1xaf6VFPB,2020,Reject,False,PDP: A General Neural Framework for Learning SAT Solvers,"[""Saeed Amizadeh"", ""Sergiy Matusevych"", ""Markus Weimer""]","[""Neural SAT solvers"", ""Graph Neural Networks"", ""Neural Message Passing"", ""Unsupervised Learning"", ""Neural Decimation""]","We propose a general neural message passing framework for SAT solving based on the idea of propagation, decimation and prediction (PDP). ",,,,
S1xcx3C5FX,2019,Accept (Poster),False,A Statistical Approach to Assessing Neural Network Robustness,"[""Stefan Webb"", ""Tom Rainforth"", ""Yee Whye Teh"", ""M. Pawan Kumar""]","[""neural network verification"", ""multi-level splitting"", ""formal verification""]","We introduce a statistical approach to assessing neural network robustness that provides an informative notion of how robust a network is, rather than just the conventional binary assertion of whether or not of property is violated.",,,,
S1xh5sYgx,2017,Reject,False,SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size,"[""Forrest N. Iandola"", ""Song Han"", ""Matthew W. Moskewicz"", ""Khalid Ashraf"", ""William J. Dally"", ""Kurt Keutzer""]","[""Computer vision"", ""Deep learning""]",Small CNN models,,,,
S1xiOjC9F7,2019,Reject,False,Graph Matching Networks for Learning the Similarity of Graph Structured Objects,"[""Yujia Li"", ""Chenjie Gu"", ""Thomas Dullien"", ""Oriol Vinyals"", ""Pushmeet Kohli""]","[""Similarity learning"", ""structured objects"", ""graph matching networks""]","We tackle the problem of similarity learning for structured objects with applications in particular in computer security, and propose a new model graph matching networks that excels on this task.",,,,
S1xipR4FPB,2020,Reject,False,Teacher-Student Compression with Generative Adversarial Networks,"[""Ruishan Liu"", ""Nicolo Fusi"", ""Lester Mackey""]",[],,,,,
S1xitgHtvS,2020,Accept (Spotlight),False,Making Sense of Reinforcement Learning and Probabilistic Inference,"[""Brendan O'Donoghue"", ""Ian Osband"", ""Catalin Ionescu""]","[""Reinforcement learning"", ""Bayesian inference"", ""Exploration""]","Popular algorithms that cast ""RL as Inference"" ignore the role of uncertainty and exploration. We highlight the importance of these issues and present a coherent framework for RL and inference that handles them gracefully.",2001.00805,cs.LG,2020-01-03 12:50:42+00:00,2020-11-04 18:12:05+00:00
S1xjJpNYvB,2020,Reject,True,Domain-Agnostic Few-Shot Classification by Learning Disparate Modulators,"[""Yongseok Choi"", ""Junyoung Park"", ""Subin Yi"", ""Dong-Yeon Cho""]","[""Meta-learning"", ""few-shot learning"", ""multi-domain""]",We address multi-domain few-shot classification by building multiple models to represent this complex task distribution in a collective way and simplifying task-specific adaptation as a selection problem from these pre-trained models.,1909.04999,cs.LG,2019-09-11 12:18:15+00:00,2020-09-17 12:09:35+00:00
S1xjdoC9Fm,2019,Reject,False,Offline Deep models calibration with bayesian neural networks,"[""Juan Maro\u00f1as"", ""Roberto Paredes"", ""Daniel Ramos""]","[""calibration"", ""deep models"", ""bayesian neural networks""]",We apply bayesian neural networks to improve calibration,,,,
S1xnXRVFwH,2020,Accept (Poster),True,Playing the lottery with rewards and multiple languages: lottery tickets in RL and NLP,"[""Haonan Yu"", ""Sergey Edunov"", ""Yuandong Tian"", ""Ari S. Morcos""]","[""lottery tickets"", ""nlp"", ""transformer"", ""rl"", ""reinforcement learning""]","We find that the lottery ticket phenomenon is present in both NLP and RL, and find that it can be used to train compressed Transformers to high performance",1906.02768,stat.ML,2019-06-06 18:38:38+00:00,2020-02-25 21:50:07+00:00
S1xoy3CcYX,2019,Reject,False,Adversarial Examples Are a Natural Consequence of Test Error in Noise,"[""Nicolas Ford"", ""Justin Gilmer"", ""Ekin D. Cubuk""]","[""Adversarial examples"", ""generalization""]",Small adversarial perturbations should be expected given observed error rates of models outside the natural data distribution.,,,,
S1xq3oR5tQ,2019,Accept (Oral),False,A Unified Theory of Early Visual Representations from Retina to Cortex through Anatomically Constrained Deep CNNs,"[""Jack Lindsey"", ""Samuel A. Ocko"", ""Surya Ganguli"", ""Stephane Deny""]","[""visual system"", ""convolutional neural networks"", ""efficient coding"", ""retina""]",We reproduced neural representations found in biological visual systems by simulating their neural resource constraints in a deep convolutional model.,,,,
S1xqRTNtDr,2020,Reject,False,Learning a Behavioral Repertoire from Demonstrations,"[""Niels Justesen"", ""Miguel Gonz\u00e1lez Duque"", ""Daniel Cabarcas Jaramillo"", ""Jean-Baptiste Mouret"", ""Sebastian Risi""]","[""Behavioral Repertoires"", ""Imitation Learning"", ""Deep Learning"", ""Adaptation"", ""StarCraft 2""]",BRIL allows a single neural network to learn a repertoire of behaviors from a set of demonstrations that can be precisely modulated.,,,,
S1xsG0VYvB,2020,Reject,False,Understanding the functional and structural differences across excitatory and inhibitory neurons,"[""Sun Minni"", ""Li Ji-An"", ""Theodore Moskovitz"", ""Grace Lindsay"", ""Kenneth Miller"", ""Mario Dipoppa"", ""Guangyu Robert Yang""]","[""Neuroscience""]","Deep nets with excitatory and inhibitory neurons developed functional and structural differences similar to the brain, and here's why.",,,,
S1xtAjR5tX,2019,Accept (Poster),False,Improving Sequence-to-Sequence Learning via Optimal Transport,"[""Liqun Chen"", ""Yizhe Zhang"", ""Ruiyi Zhang"", ""Chenyang Tao"", ""Zhe Gan"", ""Haichao Zhang"", ""Bai Li"", ""Dinghan Shen"", ""Changyou Chen"", ""Lawrence Carin""]","[""NLP"", ""optimal transport"", ""sequence to sequence"", ""natural language processing""]",,,,,
S1xtORNFwH,2020,Accept (Poster),True,FSNet: Compression of Deep Convolutional Neural Networks by Filter Summary,"[""Yingzhen Yang"", ""Jiahui Yu"", ""Nebojsa Jojic"", ""Jun Huan"", ""Thomas S. Huang""]","[""Compression of Convolutional Neural Networks"", ""Filter Summary CNNs"", ""Weight Sharing""]",We present a novel method of compression of deep Convolutional Neural Networks (CNNs) by weight sharing through a new representation of convolutional filters.,1902.03264,cs.LG,2019-02-08 19:26:46+00:00,2020-04-10 08:35:40+00:00
S1xxx64YwH,2020,Reject,False,Ecological Reinforcement Learning,"[""John D. Co-Reyes"", ""Suvansh Sanjeev"", ""Glen Berseth"", ""Abhishek Gupta"", ""Sergey Levine""]","[""non-episodic"", ""environment analysis"", ""reward shaping"", ""curriculum learning""]",,,,,
S1xzyhR9Y7,2019,Reject,False,Improving Sentence Representations with Multi-view Frameworks,"[""Shuai Tang"", ""Virginia R. de Sa""]","[""multi-view"", ""learning"", ""sentence"", ""representation""]",Multi-view learning improves unsupervised sentence representation learning,,,,
S1z9ehAqYX,2019,Reject,False,Shrinkage-based Bias-Variance Trade-off for Deep Reinforcement Learning,"[""Yihao Feng"", ""Hao Liu"", ""Jian Peng"", ""Qiang Liu""]","[""bias-variance trade-off"", ""James-stein estimator"", ""reinforcement learning""]",,,,,
S1zk9iRqF7,2019,Accept (Poster),False,PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees,"[""James Jordon"", ""Jinsung Yoon"", ""Mihaela van der Schaar""]","[""Synthetic data generation"", ""Differential privacy"", ""Generative adversarial networks"", ""Private Aggregation of Teacher ensembles""]",,,,,
S1zlmnA5K7,2019,Reject,False,Where Off-Policy Deep Reinforcement Learning Fails,"[""Scott Fujimoto"", ""David Meger"", ""Doina Precup""]","[""reinforcement learning"", ""off-policy"", ""imitation"", ""batch reinforcement learning""]",We describe conditions where off-policy deep reinforcements algorithms fail and present a solution.,,,,
S1zz2i0cY7,2019,Accept (Poster),False,Integer Networks for Data Compression with Latent-Variable Models,"[""Johannes Ball\u00e9"", ""Nick Johnston"", ""David Minnen""]","[""data compression"", ""variational models"", ""network quantization""]",We train variational models with quantized networks for computational determinism. This enables using them for cross-platform data compression.,,,,
S2UB9PkrEjF,2021,Reject,False,Universal Value Density Estimation for Imitation Learning and Goal-Conditioned Reinforcement Learning,"[""Yannick Schroecker"", ""Charles Lee Isbell""]","[""Imitation Learning"", ""Reinforcement Learning"", ""Universal Value Functions""]",We use density estimation to learn UVFA efficiently. We use this UVFA for GCRL as well as to match an expert's state-action distribution in imitation learning.,,,,
S3qhbZwzq3H,2022,Reject,False,Value-aware transformers for 1.5d data,"['James F Cann', 'Timothy J Roberts', 'Amy R Tso', 'Amy Nelson', 'Parashkev Nachev']",[],,,,,
S5S3eTEmouw,2021,Reject,True,Offline Meta-Reinforcement Learning with Advantage Weighting,"[""Eric Mitchell"", ""Rafael Rafailov"", ""Xue Bin Peng"", ""Sergey Levine"", ""Chelsea Finn""]","[""offline"", ""meta-reinforcement learning"", ""meta-learning"", ""reinforcement learning"", ""maml""]",We motivate and introduce the offline meta-RL problem and describe an effective gradient-based meta-RL algorithm for this setting.,2008.06043,cs.LG,2020-08-13 17:57:14+00:00,2021-07-21 17:33:01+00:00
S5qdnMhf7R,2022,Reject,True,Lightweight Convolutional Neural Networks By Hypercomplex Parameterization,"['Eleonora Grassucci', 'Aston Zhang', 'Danilo Comminiello']","[""Hypercomplex Neural Networks"", ""Lightweight Neural Networks"", ""Quaternion Neural Networks"", ""Parameterized Hypercomplex Convolutions"", ""Hypercomplex Representation Learning""]",We propose a lightweight hypercomplex parameterization of convolutional layers which outperforms real and quaternion-valued neural networks in different application domains.,2110.04176,cs.LG,2021-10-08 14:57:19+00:00,2021-10-08 14:57:19+00:00
S6AtYQLzXOY,2021,Reject,False,Learning Self-Similarity in Space and Time as a Generalized Motion for Action Recognition,"[""Heeseung Kwon"", ""Manjin Kim"", ""Suha Kwak"", ""Minsu Cho""]","[""Action recognition"", ""Video understanding"", ""Motion analysis""]","This paper proposes to learn a generalized, far-sighted motion representations from spatio-temporal self-similarity for video understanding.",2102.07092,cs.CV,2021-02-14 07:32:55+00:00,2021-11-02 15:37:46+00:00
S6eHczgYpnu,2022,Reject,False,Fast and Sample-Efficient Domain Adaptation for Autoencoder-Based End-to-End Communication,"['Jayaram Raghuram', 'Yijing Zeng', 'Dolores Garcia', 'Somesh Jha', 'Suman Banerjee', 'Joerg Widmer', 'Rafael Ruiz']","[""domain adaptation"", ""small target dataset"", ""communication autoencoders"", ""mixture density networks"", ""wireless channel""]",We propose a fast and sample-efficient domain adaptation method for the problem of end-to-end communication based on an autoencoder and mixture density network channel model.,,,,
S724o4_WB3,2021,Accept (Poster),False,When does preconditioning help or hurt generalization?,"[""Shun-ichi Amari"", ""Jimmy Ba"", ""Roger Baker Grosse"", ""Xuechen Li"", ""Atsushi Nitanda"", ""Taiji Suzuki"", ""Denny Wu"", ""Ji Xu""]","[""generalization"", ""second-order optimization"", ""natural gradient descent"", ""high-dimensional asymptotics""]",Characterized the generalization error of preconditioned least squares regression in the overparameterized regime and determined the optimal preconditioner.,,,,
S7Aeama_0s,2021,Reject,False,QRGAN: Quantile Regression Generative Adversarial Networks,"[""Sunyeop Lee"", ""Tuan Anh Nguyen"", ""Dugki Min""]","[""Quantile Regression"", ""Generative Adversarial Networks (GANs)"", ""Frechet Inception Distance (FID)"", ""Generative Neural Networks""]",A novel generative adversarial network with quantile regression for a significant improvement of model robustness and generation performance,,,,
S7vWxSkqv_M,2022,Reject,False,Evaluating Predictive Distributions: Does Bayesian Deep Learning Work?,"['Ian Osband', 'Zheng Wen', 'Seyed Mohammad Asghari', 'Xiuyuan Lu', 'Morteza Ibrahimi', 'Vikranth Dwaracherla', 'Dieterich Lawson', ""Brendan O'Donoghue"", 'Botao Hao', 'Benjamin Van Roy']","[""Deep Learning"", ""Bayesian"", ""Uncertainty"", ""Testbed"", ""Opensource Code""]","This paper introduces The Neural Testbed, which evaluates posterior predictive distributions beyond marginals.",,,,
S874XAIpkR-,2022,Accept (Poster),False,The Essential Elements of Offline RL via Supervised Learning,"['Scott Emmons', 'Benjamin Eysenbach', 'Ilya Kostrikov', 'Sergey Levine']","[""reinforcement learning"", ""deep reinforcement learning"", ""offline reinforcement learning""]",Experimentally evaluating when and why supervised learning solves offline RL,,,,
S9MPX7ejmv,2021,Reject,False,Approximating Pareto Frontier through Bayesian-optimization-directed Robust Multi-objective Reinforcement Learning,"[""Xiangkun He"", ""Jianye HAO"", ""Dong Li"", ""Bin Wang"", ""Wulong Liu""]","[""Reinforcement Learning"", ""Multi\u2013objective Optimization"", ""Adversarial Machine Learning"", ""Bayesian Optimization""]",We proposed a novel approach to approximate a representation for robust Pareto frontier through Bayesian-optimization-directed robust multi-objective reinforcement learning.,,,,
SC6JbEviuD0,2022,Reject,False,White Paper Assistance: A Step Forward Beyond the Shortcut Learning,"['Xuan Cheng', 'Tianshu Xie', 'XiaoMin Wang', 'MingHui Liu', 'Jiali Deng', 'Ming Liu']","[""Shortcut Learning"", ""Bias"", ""Classification"", ""Imbalanced Classification"", ""Robustness""]",,,,,
SCSonHu4p0W,2022,Reject,False,Knowledge Based Multilingual Language Model,"['Linlin Liu', 'Xin Li', 'Ruidan He', 'Lidong Bing', 'Shafiq Joty', 'Luo Si']","[""Language Model"", ""Knowledge"", ""Multilingual""]",We present a novel framework to pretrain knowledge based multilingual language models (KMLMs). ,,,,
SCn0mgEIwh,2022,Reject,False,Learnability and Expressiveness in Self-Supervised Learning,"['Yuchen Lu', 'Zhen Liu', 'Alessandro Sordoni', 'Aristide Baratin', 'Romain Laroche', 'Aaron Courville']","[""Self-supervised Learning"", ""Learnability"", ""Intrinsic Dimension"", ""Representation Learning""]",We analyze self-supervised representation learning through the lens of expressiveness and learnability.,,,,
SF9o3-yP1WR,2022,Reject,False,Robust and Personalized Federated Learning with Spurious Features: an Adversarial Approach,"['Xiaoyang Wang', 'Han Zhao', 'Klara Nahrstedt', 'Oluwasanmi O Koyejo']","[""federated learning"", ""personalization"", ""spurious features""]",We propose a strategy to preventing personalized federated learning models from entangling spurious features based on the adversarial transferability between the global and personalized models.,,,,
SGOma2sAF7Q,2022,Reject,False,LCS: Learning Compressible Subspaces for Adaptive Network Compression at Inference Time,"['Maxwell Horton', 'Elvis Nunez', 'Anish Prabhu', 'Anurag Ranjan', 'Ali Farhadi', 'Mohammad Rastegari']","[""network subspace"", ""compression"", ""post-training"", ""pruning"", ""quantization"", ""efficient""]","We learn ""compressible subspaces of networks,"" which can be queried after training for networks optimized for efficiency or accuracy.",,,,
SHbhHHfePhP,2022,Accept (Poster),False,Constrained Graph Mechanics Networks,"['Wenbing Huang', 'Jiaqi Han', 'Yu Rong', 'Tingyang Xu', 'Fuchun Sun', 'Junzhou Huang']",[],,,,,
SHnXjI3vTJ,2022,Reject,False,Self-Supervised Prime-Dual Networks for Few-Shot Image Classification,"['Wenming Cao', 'Qifan Liu', 'Guang Liu', 'Zhihai He']","[""few-shot learning"", ""prime-dual network"", ""self-supervision""]",,,,,
SHvF5xaueVn,2021,Accept (Poster),True,GAN2GAN: Generative Noise Learning for Blind Denoising with Single Noisy Images,"[""Sungmin Cha"", ""Taeeon Park"", ""Byeongjoon Kim"", ""Jongduk Baek"", ""Taesup Moon""]","[""blind denoising"", ""unsupervised learning"", ""iterative training"", ""generative learning""]",We devise GAN2GAN method that trains a blind denoiser solely based on the single noisy images. ,1905.10488,eess.IV,2019-05-25 00:16:09+00:00,2021-07-04 09:16:19+00:00
SIKV0_MrZlr,2022,Accept (Poster),False,Auto-Transfer: Learning to Route Transferable Representations,"['Keerthiram Murugesan', 'Vijay Sadashivaiah', 'Ronny Luss', 'Karthikeyan Shanmugam', 'Pin-Yu Chen', 'Amit Dhurandhar']","[""Feature routing"", ""Transferable Representations""]",This paper offers a novel transfer method that uses a routing function to select source-target pairs as well as aggregation functions that combine source and target features (as opposed to matching source to target features).,,,,
SJ-C6JbRW,2018,Accept (Poster),False,Mastering the Dungeon: Grounded Language Learning by Mechanical Turker Descent,"[""Zhilin Yang"", ""Saizheng Zhang"", ""Jack Urbanek"", ""Will Feng"", ""Alexander Miller"", ""Arthur Szlam"", ""Douwe Kiela"", ""Jason Weston""]",[],,,,,
SJ-uGHcee,2017,Reject,False,Efficient iterative policy optimization,"[""Nicolas Le Roux""]",[],,,,,
SJ19eUg0-,2018,Reject,False,BLOCK-DIAGONAL HESSIAN-FREE OPTIMIZATION FOR TRAINING NEURAL NETWORKS,"[""Huishuai Zhang"", ""Caiming Xiong"", ""James Bradbury"", ""Richard Socher""]","[""deep learning"", ""second-order optimization"", ""hessian free""]",,,,,
SJ1Xmf-Rb,2018,Accept (Poster),False,FearNet: Brain-Inspired Model for Incremental Learning,"[""Ronald Kemker"", ""Christopher Kanan""]","[""Incremental Learning"", ""Lifelong Learning"", ""Supervised Learning"", ""Catastrophic Forgetting"", ""Brain-Inspired"", ""Neural Networks""]","FearNet is a memory efficient neural-network, inspired by memory formation in the mammalian brain, that is capable of incremental class learning without catastrophic forgetting.",1711.10563,cs.LG,2017-11-28 21:26:15+00:00,2018-02-23 20:32:27+00:00
SJ1fQYlCZ,2018,Reject,False,Training with Growing Sets: A Simple Alternative to Curriculum Learning and Self Paced Learning,"[""Melike Nur Mermer"", ""Mehmet Fatih Amasyali""]","[""Neural networks"", ""Curriculum learning"", ""Self paced learning""]",We propose that training with growing sets stage-by-stage provides an optimization for neural networks.,,,,
SJ1nzBeA-,2018,Accept (Poster),False,Multi-Task Learning for Document Ranking and Query Suggestion,"[""Wasi Uddin Ahmad"", ""Kai-Wei Chang"", ""Hongning Wang""]","[""Multitask Learning"", ""Document Ranking"", ""Query Suggestion""]",,,,,
SJ25-B5eg,2017,Accept (Poster),False,The Neural Noisy Channel,"[""Lei Yu"", ""Phil Blunsom"", ""Chris Dyer"", ""Edward Grefenstette"", ""Tomas Kocisky""]","[""Natural language processing"", ""Deep learning"", ""Semi-Supervised Learning""]",We formulate sequence to sequence transduction as a noisy channel decoding  problem and use recurrent neural networks to parameterise the source and channel  models.,,,,
SJ3dBGZ0Z,2018,Reject,False,LSH Softmax: Sub-Linear Learning and Inference of the Softmax Layer in Deep Architectures,"[""Daniel Levy"", ""Danlu Chan"", ""Stefano Ermon""]","[""LSH"", ""softmax"", ""deep"", ""learning"", ""sub"", ""linear"", ""efficient"", ""GPU""]","we present LSH Softmax, a softmax approximation layer for sub-linear learning and inference with strong theoretical guarantees; we showcase both its applicability and efficiency by evaluating on a real-world task: language modeling.",,,,
SJ3rcZcxl,2017,Accept (Oral),False,Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic,"[""Shixiang Gu"", ""Timothy Lillicrap"", ""Zoubin Ghahramani"", ""Richard E. Turner"", ""Sergey Levine""]","[""Deep learning"", ""Reinforcement Learning""]","We propose Q-Prop, a novel policy gradient method with an off-policy critic as control variate, that is more sample efficient than TRPO-GAE and more stable than DDPG, the state-of-the-art on-policy and off-policy methods.",,,,
SJ4Z72Rctm,2019,Reject,False,Composing Entropic Policies using Divergence Correction,"[""Jonathan J Hunt"", ""Andre Barreto"", ""Timothy P Lillicrap"", ""Nicolas Heess""]","[""maximum entropy RL"", ""policy composition"", ""deep rl""]","Two new methods for combining entropic policies: maximum entropy generalized policy improvement, and divergence correction.",,,,
SJ4vTjRqtQ,2019,Reject,False,Dynamic Planning Networks,"[""Norman L. Tasfi"", ""Miriam Capretz""]","[""reinforcement learning"", ""planning"", ""deep learning""]",,,,,
SJ60SbW0b,2018,Reject,False,Modeling Latent Attention Within Neural Networks,"[""Christopher Grimm"", ""Dilip Arumugam"", ""Siddharth Karamcheti"", ""David Abel"", ""Lawson L.S. Wong"", ""Michael L. Littman""]","[""deep learning"", ""neural network"", ""attention"", ""attention mechanism"", ""interpretability"", ""visualization""]",We develop a technique to visualize attention mechanisms in arbitrary neural networks. ,,,,
SJ6yPD5xg,2017,Accept (Oral),False,Reinforcement Learning with Unsupervised Auxiliary Tasks,"[""Max Jaderberg"", ""Volodymyr Mnih"", ""Wojciech Marian Czarnecki"", ""Tom Schaul"", ""Joel Z Leibo"", ""David Silver"", ""Koray Kavukcuoglu""]",[],,,,,
SJ71VXZAZ,2018,Reject,False,Learning To Generate Reviews and Discovering Sentiment,"[""Alec Radford"", ""Rafal Jozefowicz"", ""Ilya Sutskever""]","[""unsupervised learning"", ""representation learning"", ""deep learning""]",Byte-level recurrent language models learn high-quality domain specific representations of text.,,,,
SJ8BZTjeg,2017,Reject,False,Unsupervised Learning Using Generative Adversarial Training And Clustering,"[""Vittal Premachandran"", ""Alan L. Yuille""]",[],,,,,
SJ8M9yup-,2018,Reject,False,On Optimality Conditions for Auto-Encoder Signal Recovery,"[""Devansh Arpit"", ""Yingbo Zhou"", ""Hung Q. Ngo"", ""Nils Napp"", ""Venu Govindaraju""]","[""Auto Encoder"", ""Signal Recovery"", ""Sparse Coding""]",,,,,
SJA7xfb0b,2018,Accept (Poster),False,Sobolev GAN,"[""Youssef Mroueh"", ""Chun-Liang Li"", ""Tom Sercu"", ""Anant Raj"", ""Yu Cheng""]","[""GAN theory"", ""Integral Probability Metrics"", ""elliptic PDE and diffusion"", ""GAN for discrete sequences"", ""semi-supervised learning.""]",We define a new Integral Probability Metric (Sobolev IPM) and show how it can be used for training GANs for text generation and semi-supervised learning.,,,,
SJAr0QFxe,2017,Reject,False,Demystifying ResNet,"[""Sihan Li"", ""Jiantao Jiao"", ""Yanjun Han"", ""Tsachy Weissman""]","[""Deep learning"", ""Optimization"", ""Theory""]",,,,,
SJBr9Mcxl,2017,Reject,False,Understanding trained CNNs by indexing neuron selectivity,"[""Ivet Rafegas"", ""Maria Vanrell"", ""Lu\u00eds A. Alexandre""]","[""Computer vision"", ""Deep learning""]",,,,,
SJCPLLpaW,2018,Reject,False,Exploring the Hidden Dimension in Accelerating Convolutional Neural Networks,"[""Zhihao Jia"", ""Sina Lin"", ""Charles R. Qi"", ""Alex Aiken""]","[""Parallelism of Convolutional Neural Networks"", ""Accelerating Convolutional Neural Networks""]","To the best of our knowledge, DeePa is the first deep learning framework that controls and optimizes the parallelism of CNNs in all parallelizable dimensions at the granularity of each layer.",,,,
SJCq_fZ0Z,2018,Reject,False,Sparse Attentive Backtracking: Long-Range Credit Assignment in Recurrent Networks,"[""Nan Rosemary Ke"", ""Anirudh Goyal"", ""Olexa Bilaniuk"", ""Jonathan Binas"", ""Laurent Charlin"", ""Chris Pal"", ""Yoshua Bengio""]","[""recurrent neural networks"", ""long-term dependencies"", ""back-propagation through time"", ""truncated back-propagation"", ""biological inspiration"", ""self-attention""]",Towards Efficient Credit Assignment in Recurrent Networks without Backpropagation Through Time,,,,
SJCscQcge,2017,Reject,False,Simple Black-Box Adversarial Perturbations for Deep Networks,"[""Nina Narodytska"", ""Shiva Kasiviswanathan""]","[""Computer vision"", ""Deep learning""]","Simple, but highly effective, adversarial attacks on deep neural networks even in the absence of any internal knowledge about the network",,,,
SJD8YjCpW,2018,Reject,False,Balanced and Deterministic Weight-sharing Helps Network Performance,"[""Oscar Chang"", ""Hod Lipson""]","[""Weight-sharing"", ""Weight sharing"", ""Weight tying"", ""neural networks"", ""entropy"", ""hash function"", ""hash table"", ""balance"", ""sparse"", ""sparsity"", ""hashednets""]","Studied the role of weight sharing in neural networks using hash functions, found that a balanced and deterministic hash function helps network performance.",,,,
SJDJNzWAZ,2018,Invite to Workshop Track,False,Time-Dependent Representation for Neural Event Sequence Prediction,"[""Yang Li"", ""Nan Du"", ""Samy Bengio""]","[""Neural sequence prediction"", ""Embedding"", ""LSTM"", ""Regularization""]",Proposed methods for time-dependent event representation and regularization for sequence prediction; Evaluated these methods on five datasets that involve a range of sequence prediction tasks.,,,,
SJDYgPgCZ,2018,Reject,False,Understanding Local Minima in Neural Networks by Loss Surface Decomposition,"[""Hanock Kwak"", ""Byoung-Tak Zhang""]","[""neural network"", ""local minima"", ""global minima"", ""saddle point"", ""optimization"", ""loss surface"", ""rectified linear unit"", ""loss surface decomposition"", ""gradient descent""]",The loss surface of neural networks is a disjoint union of regions where every local minimum is a global minimum of the corresponding region.,,,,
SJDaqqveg,2017,Accept (Poster),False,An Actor-Critic Algorithm for Sequence Prediction,"[""Dzmitry Bahdanau"", ""Philemon Brakel"", ""Kelvin Xu"", ""Anirudh Goyal"", ""Ryan Lowe"", ""Joelle Pineau"", ""Aaron Courville"", ""Yoshua Bengio""]","[""Natural language processing"", ""Deep learning"", ""Reinforcement Learning"", ""Structured prediction""]",Adapting Actor-Critic methods from reinforcement learning to structured prediction,,,,
SJFM0ZWCb,2018,Reject,False,Deep Temporal Clustering: Fully unsupervised learning of time-domain features,"[""Naveen Sai Madiraju"", ""Seid M. Sadat"", ""Dimitry Fisher"", ""Homa Karimabadi""]","[""Unsupervised deep learning"", ""Temporal clustering"", ""Event Visualization""]","A fully unsupervised method, to naturally integrate dimensionality reduction and temporal clustering into a single end to end learning framework.",,,,
SJG1wjRqFQ,2019,Reject,False,Discrete Structural Planning for Generating Diverse Translations,"[""Raphael Shu"", ""Hideki Nakayama""]","[""machine translation"", ""syntax"", ""diversity"", ""code learning""]",Learning discrete structural representation to control sentence generation and obtain diverse outputs,,,,
SJG6G2RqtX,2019,Accept (Poster),False,Value Propagation Networks,"[""Nantas Nardelli"", ""Gabriel Synnaeve"", ""Zeming Lin"", ""Pushmeet Kohli"", ""Philip H. S. Torr"", ""Nicolas Usunier""]","[""Reinforcement Learning"", ""Value Iteration"", ""Navigation"", ""Convolutional Neural Networks"", ""Learning to plan""]",We present planners based on convnets that are sample-efficient and that generalize to larger instances of navigation and pathfinding problems.,,,,
SJGCiw5gl,2017,Accept (Poster),False,Pruning Convolutional Neural Networks for Resource Efficient Inference,"[""Pavlo Molchanov"", ""Stephen Tyree"", ""Tero Karras"", ""Timo Aila"", ""Jan Kautz""]","[""Deep learning"", ""Transfer Learning""]",New approach for removing unnecessary conv neurons from network. Work is focused on how to estimate importance fast and efficiently by Taylor expantion.,,,,
SJGPL9Dex,2017,Accept (Poster),False,Understanding Trainable Sparse Coding with Matrix Factorization,"[""Thomas Moreau"", ""Joan Bruna""]","[""Theory"", ""Deep learning"", ""Optimization""]","We analyse the mechanisms which permit to accelerate sparse coding resolution using the problem structure, as it is the case in LISTA.",,,,
SJGvns0qK7,2019,Accept (Poster),False,Bayesian Policy Optimization for Model Uncertainty,"[""Gilwoo Lee"", ""Brian Hou"", ""Aditya Mandalika"", ""Jeongseok Lee"", ""Sanjiban Choudhury"", ""Siddhartha S. Srinivasa""]","[""Bayes-Adaptive Markov Decision Process"", ""Model Uncertainty"", ""Bayes Policy Optimization""]",We formulate model uncertainty in Reinforcement Learning as a continuous Bayes-Adaptive Markov Decision Process and present a method for practical and scalable Bayesian policy optimization.,,,,
SJGyFiRqK7,2019,Reject,False,Decoupling Gating from Linearity,"[""Yonathan Fiat"", ""Eran Malach"", ""Shai Shalev-Shwartz""]","[""Artificial Neural Networks"", ""Neural Networks"", ""ReLU"", ""GaLU"", ""Deep Learning""]",We propose Gated Linear Unit networks â a model that performs similarly to ReLU networks on real data while being much easier to analyze theoretically.,,,,
SJIA6ZWC-,2018,Reject,False,Stochastic Hyperparameter Optimization through Hypernetworks,"[""Jonathan Lorraine"", ""David Duvenaud""]","[""hypernetworks"", ""hyperparameter optimization"", ""metalearning"", ""neural networks"", ""Bayesian optimization"", ""game theory"", ""optimization""]",We train a neural network to output approximately optimal weights as a function of hyperparameters.,,,,
SJICXeWAb,2018,Reject,False,Depth separation and weight-width trade-offs for sigmoidal neural networks,"[""Amit Deshpande"", ""Navin Goyal"", ""Sushrut Karmalkar""]","[""depth separation"", ""neural networks"", ""weights-width trade-off""]",depth-2-vs-3 separation for sigmoidal neural networks over general distributions,,,,
SJIMPr9eg,2017,Reject,False,Boosted Residual Networks,"[""Alan Mosca"", ""George D. Magoulas""]",[],,,,,
SJJKxrsgl,2017,Accept (Poster),False,Emergence of foveal image sampling from learning to attend in visual scenes,"[""Brian Cheung"", ""Eric Weiss"", ""Bruno Olshausen""]","[""Computer vision"", ""Deep learning"", ""Supervised Learning""]",We show a foveal sampling lattice similar to those observed in biology emerges from our model and task.,,,,
SJJN38cge,2017,Reject,False,Distributed Transfer Learning for Deep Convolutional Neural Networks by Basic Probability Assignment,"[""Arash Shahriari""]","[""Deep learning"", ""Transfer Learning"", ""Supervised Learning"", ""Optimization""]",,,,,
SJJQVZW0b,2018,Accept (Poster),False,Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning,"[""Tianmin Shu"", ""Caiming Xiong"", ""Richard Socher""]","[""Hierarchical Policy"", ""Interpretable Policy"", ""Deep Reinforcement Learning"", ""Multi-task Reinforcement Learning"", ""Skill Acquisition"", ""Language Grounding""]",A novel hierarchical policy network which can reuse previously learned skills alongside and as subcomponents of new skills by discovering the underlying relations between skills.,,,,
SJJinbWRZ,2018,Accept (Poster),False,Model-Ensemble Trust-Region Policy Optimization,"[""Thanard Kurutach"", ""Ignasi Clavera"", ""Yan Duan"", ""Aviv Tamar"", ""Pieter Abbeel""]","[""model-based reinforcement learning"", ""model ensemble"", ""reinforcement learning"", ""model bias""]",Deep Model-Based RL that works well.,,,,
SJJySbbAZ,2018,Accept (Poster),False,Training GANs with Optimism,"[""Constantinos Daskalakis"", ""Andrew Ilyas"", ""Vasilis Syrgkanis"", ""Haoyang Zeng""]","[""GANs"", ""Optimistic Mirror Decent"", ""Cycling"", ""Last Iterate Convergence"", ""Optimistic Adam""]",We propose the use of optimistic mirror decent to address cycling problems in the training of GANs. We also introduce the Optimistic Adam algorithm,,,,
SJLhxnRqFQ,2019,Reject,False,Adversarially Learned Mixture Model,"[""Andrew Jesson"", ""C\u00e9cile Low-Kam"", ""Tanya Nair"", ""Florian Soudan"", ""Florent Chandelier"", ""Nicolas Chapados""]","[""Unsupervised"", ""Semi-supervised"", ""Generative"", ""Adversarial"", ""Clustering""]",The AMM is the first fully adversarially optimized method to model the conditional dependence between categorical and continuous latent variables.,,,,
SJLlmG-AZ,2018,Accept (Poster),False,Understanding image motion with group representations ,"[""Andrew Jaegle"", ""Stephen Phillips"", ""Daphne Ippolito"", ""Kostas Daniilidis""]","[""vision"", ""motion"", ""recurrent neural networks"", ""self-supervised learning"", ""unsupervised learning"", ""group theory""]",We propose of method of using group properties to learn a representation of motion without labels and demonstrate the use of this method for representing 2D and 3D motion.,,,,
SJLy_SxC-,2018,Reject,False,Log-DenseNet: How to Sparsify a DenseNet,"[""Hanzhang Hu"", ""Debadeepta Dey"", ""Allie Del Giorno"", ""Martial Hebert"", ""J. Andrew Bagnell""]","[""DenseNet"", ""sparse shortcut connections"", ""network architecture"", ""scene parsing"", ""image classification""]","We show shortcut connections should be placed in patterns that minimize between-layer distances during backpropagation, and design networks that achieve log L distances using L log(L) connections.",,,,
SJMBM2RqKQ,2019,Reject,False,Uncertainty-guided Lifelong Learning in Bayesian Networks,"[""Sayna Ebrahimi"", ""Mohamed Elhoseiny"", ""Trevor Darrell"", ""Marcus Rohrbach""]","[""lifelong learning"", ""continual learning"", ""sequential learning""]","We formulate lifelong learning in the Bayesian-by-Backprop framework, exploiting the parameter uncertainty in two settings: for pruning network parameters and in importance weight based continual learning.",,,,
SJMGPrcle,2017,Accept (Poster),False,Learning to Navigate in Complex Environments,"[""Piotr Mirowski"", ""Razvan Pascanu"", ""Fabio Viola"", ""Hubert Soyer"", ""Andy Ballard"", ""Andrea Banino"", ""Misha Denil"", ""Ross Goroshin"", ""Laurent Sifre"", ""Koray Kavukcuoglu"", ""Dharshan Kumaran"", ""Raia Hadsell""]","[""Deep learning"", ""Reinforcement Learning""]","We proposed a deep RL method, augmented with memory and auxiliary learning targets, for training agents to navigate within large and visually rich environments that include frequently changing start and goal locations",,,,
SJMO2iCct7,2019,Reject,False,A NOVEL VARIATIONAL FAMILY FOR HIDDEN NON-LINEAR MARKOV MODELS,"[""Daniel Hernandez Diaz"", ""Antonio Khalil Moretti"", ""Ziqiang Wei"", ""Shreya Saxena"", ""John Cunningham"", ""Liam Paninski""]","[""variational inference"", ""time series"", ""nonlinear dynamics"", ""neuroscience""]",We propose a new variational inference algorithm for time series and a novel variational family  endowed with nonlinear dynamics.,,,,
SJMZRsC9Y7,2019,Reject,False,A NON-LINEAR  THEORY FOR SENTENCE EMBEDDING,"[""Hichem Mezaoui"", ""Isar Nejadgholi""]","[""sentence embedding"", ""generative models""]",,,,,
SJMeTo09YQ,2019,Reject,False,Guided Exploration in Deep Reinforcement Learning,"[""Sahisnu Mazumder"", ""Bing Liu"", ""Shuai Wang"", ""Yingxuan Zhu"", ""Xiaotian Yin"", ""Lifeng Liu"", ""Jian Li"", ""Yongbing Huang""]","[""deep reinforcement learning"", ""guided exploration"", ""RL training speed up""]",introduces a guided action exploration mechanism that drastically speed up RL training,,,,
SJMnG2C9YX,2019,Reject,False,Complementary-label learning for arbitrary losses and models,"[""Takashi Ishida"", ""Gang Niu"", ""Aditya Krishna Menon"", ""Masashi Sugiyama""]","[""complementary labels"", ""weak supervision""]","From now on, you can train ResNet and DenseNet, even if no class label given for training is correct!",,,,
SJNDWNOlg,2017,Reject,False,What Is the Best Practice for CNNs Applied to Visual Instance Retrieval?,"[""Jiedong Hao"", ""Jing Dong"", ""Wei Wang"", ""Tieniu Tan""]","[""Computer vision"", ""Deep learning""]",,,,,
SJNRHiAcYX,2019,Reject,False,Boosting Trust Region Policy Optimization by Normalizing flows Policy,"[""Yunhao Tang"", ""Shipra Agrawal""]","[""Reinforcement Learning"", ""Normalizing Flows""]",Normalizing flows policy to improve TRPO and ACKTR,,,,
SJNceh0cFX,2019,Reject,False,A   RECURRENT NEURAL CASCADE-BASED MODEL FOR CONTINUOUS-TIME DIFFUSION PROCESS,"[""Sylvain Lamprier""]","[""Information Diffusion"", ""Recurrent Neural Network"", ""Black Box Inference""]",,,,,
SJOl4DlCZ,2018,Reject,False,Classifier-to-Generator Attack: Estimation of Training Data Distribution from Classifier,"[""Kosuke Kusano"", ""Jun Sakuma""]","[""Security"", ""Privacy"", ""Model Publication"", ""Generative Adversarial Networks""]",Estimation of training data distribution from trained classifier using GAN.,,,,
SJPpHzW0-,2018,Reject,False,Influence-Directed Explanations for Deep Convolutional Networks,"[""Anupam Datta"", ""Matt Fredrikson"", ""Klas Leino"", ""Linyi Li"", ""Shayak Sen""]","[""Deep neural networks"", ""convolutional networks"", ""influence measures"", ""explanations""]","We present an influence-directed approach to constructing explanations for the behavior of deep convolutional networks, and show how it can be used to answer a broad set of questions that could not be addressed by prior work.",,,,
SJQHjzZ0-,2018,Accept (Poster),False,Quantitatively Evaluating GANs With Divergences Proposed for Training,"[""Daniel Jiwoong Im"", ""He Ma"", ""Graham W. Taylor"", ""Kristin Branson""]","[""Generative adversarial networks""]",An empirical evaluation on generative adversarial networks,,,,
SJQNqLFgl,2017,Reject,False,Deep Convolutional Neural Network Design Patterns,"[""Leslie N. Smith"", ""Nicholay Topin""]",[],We take a high-level view of the network architectures as the basis for discovering universal principles of the design of convolutional neural network architecture.. ,,,,
SJQO7UJCW,2018,Reject,False,Adversarial Learning for Semi-Supervised Semantic Segmentation,"[""Wei-Chih Hung"", ""Yi-Hsuan Tsai"", ""Yan-Ting Liou"", ""Yen-Yu Lin"", ""Ming-Hsuan Yang""]","[""semantic segmentation"", ""adversarial learning"", ""semi-supervised learning"", ""self-taught learning""]",,,,,
SJRpRfKxx,2017,Accept (Poster),False,Recurrent Mixture Density Network for Spatiotemporal Visual Attention,"[""Loris Bazzani"", ""Hugo Larochelle"", ""Lorenzo Torresani""]","[""Computer vision"", ""Deep learning"", ""Applications""]",,,,,
SJSVuReCZ,2018,Reject,False,SHADE: SHAnnon DEcay Information-Based Regularization for Deep Learning,"[""Michael Blot"", ""Thomas Robert"", ""Nicolas Thome"", ""Matthieu Cord""]",[],,,,,
SJTB5GZCb,2018,Invite to Workshop Track,False,Extending the Framework of Equilibrium Propagation to General Dynamics,"[""Benjamin Scellier"", ""Anirudh Goyal"", ""Jonathan Binas"", ""Thomas Mesnard"", ""Yoshua Bengio""]","[""Deep Learning"", ""Backpropagation"", ""Fixed Point Recurrent Neural Network"", ""Biologically Plausible Learning"", ""Feedback Alignment"", ""Dynamical System"", ""Gradient-Free Optimization""]",We describe a biologically plausible learning algorithm for fixed point recurrent networks without tied weights,,,,
SJTQLdqlg,2017,Accept (Poster),False,Learning to Remember Rare Events,"[""Lukasz Kaiser"", ""Ofir Nachum"", ""Aurko Roy"", ""Samy Bengio""]","[""Deep learning""]",We introduce a memory module for life-long learning that adds one-shot learning capability to any supervised neural network.,,,,
SJU4ayYgl,2017,Accept (Poster),False,Semi-Supervised Classification with Graph Convolutional Networks,"[""Thomas N. Kipf"", ""Max Welling""]","[""Deep learning"", ""Semi-Supervised Learning""]",Semi-supervised classification with a CNN model for graphs. State-of-the-art results on a number of citation network datasets.,,,,
SJUX_MWCZ,2018,Invite to Workshop Track,False,Predict Responsibly: Increasing Fairness by Learning to Defer,"[""David Madras"", ""Toniann Pitassi"", ""Richard Zemel""]","[""Fairness"", ""IDK"", ""Calibration"", ""Automated decision-making"", ""Transparency"", ""Accountability""]","Incorporating the ability to say I-don't-know can improve the fairness of a classifier without sacrificing too much accuracy, and this improvement magnifies when the classifier has insight into downstream decision-making.",,,,
SJUdkecgx,2017,Reject,False,,"[""""]",[],We propose: ,,,,
SJVHY9lCb,2018,Reject,False,"Learning to Select: Problem, Solution, and Applications","[""Heechang Ryu"", ""Donghyun Kim"", ""Hayong Shin""]","[""Selection Problem"", ""Job Dispatching"", ""Convolution Neural Network""]",,,,,
SJVmjjR9FX,2019,Accept (Poster),False,Variational Bayesian Phylogenetic Inference,"[""Cheng Zhang"", ""Frederick A. Matsen IV""]","[""Bayesian phylogenetic inference"", ""Variational inference"", ""Subsplit Bayesian networks""]","The first variational Bayes formulation of phylogenetic inference, a challenging inference problem over structures with intertwined discrete and continuous components",,,,
SJZ2Mf-0-,2018,Invite to Workshop Track,False,Adaptive Memory Networks,"[""Daniel Li"", ""Asim Kadav""]","[""Memory Networks"", ""Dynamic Networks"", ""Faster Inference"", ""Reasoning"", ""QA""]",Memory networks with faster inference,,,,
SJZAb5cel,2017,Reject,False,A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks,"[""Kazuma Hashimoto"", ""Caiming Xiong"", ""Yoshimasa Tsuruoka"", ""Richard Socher""]","[""Natural language processing"", ""Deep learning""]",A single deep multi-task learning model for five different NLP tasks.,,,,
SJZsR7kCZ,2018,Reject,False,Iterative Deep Compression : Compressing Deep Networks for Classification and Semantic Segmentation,"[""Sugandha Doda"", ""Vitor Fortes Rey"", ""Dr. Nadereh Hatami"", ""Prof. Dr. Paul Lukowicz""]",[],,,,,
SJ_QCYqle,2017,Reject,False,Semi-Supervised Detection of Extreme Weather Events in Large Climate Datasets,"[""Evan Racah"", ""Christopher Beckham"", ""Tegan Maharaj"", ""Prabhat"", ""Christopher Pal""]","[""Semi-Supervised Learning"", ""Applications"", ""Computer vision""]",Semi-supervised 3D CNN's improve bounding box detection of weather events in climate simulations compared to supervised approaches.,,,,
SJa1Nk10b,2018,Reject,False,Anytime Neural Network: a Versatile Trade-off Between Computation and Accuracy,"[""Hanzhang Hu"", ""Debadeepta Dey"", ""Martial Hebert"", ""J. Andrew Bagnell""]","[""anytime"", ""neural network"", ""adaptive prediction"", ""budgeted prediction""]","By focusing more on the final predictions in anytime predictors (such as the very recent Multi-Scale-DenseNets), we make small anytime models to outperform large ones that don't have such focus. ",,,,
SJa9iHgAZ,2018,Accept (Poster),False,Residual Connections Encourage Iterative Inference,"[""Stanis\u0142aw Jastrzebski"", ""Devansh Arpit"", ""Nicolas Ballas"", ""Vikas Verma"", ""Tong Che"", ""Yoshua Bengio""]","[""residual network"", ""iterative inference"", ""deep learning""]",Residual connections really perform iterative inference,,,,
SJaP_-xAb,2018,Accept (Poster),False,Deep Learning with Logged Bandit Feedback,"[""Thorsten Joachims"", ""Adith Swaminathan"", ""Maarten de Rijke""]","[""Batch Learning from Bandit Feedback"", ""Counterfactual Learning""]",The paper proposes a new output layer for deep networks that permits the use of logged contextual bandit feedback for training. ,,,,
SJahqJZAW,2018,Reject,False,Stabilizing GAN Training with Multiple Random Projections,"[""Behnam Neyshabur"", ""Srinadh Bhojanapalli"", ""Ayan Chakrabarti""]","[""generative adversarial networks"", ""stable training"", ""low-dimensional projections"", ""deep learning""]","Stable GAN training in high dimensions by using an array of discriminators, each with a low dimensional view of generated samples",,,,
SJc1hL5ee,2017,Reject,False,FastText.zip: Compressing text classification models,"[""Armand Joulin"", ""Edouard Grave"", ""Piotr Bojanowski"", ""Matthijs Douze"", ""Herve Jegou"", ""Tomas Mikolov""]","[""Natural language processing"", ""Supervised Learning"", ""Applications""]",Compressing text classification models,,,,
SJcKhk-Ab,2018,Accept (Poster),False,Can recurrent neural networks warp time?,"[""Corentin Tallec"", ""Yann Ollivier""]","[""RNN""]",Proves that gating mechanisms provide invariance to time transformations. Introduces and tests a new initialization for LSTMs from this insight.,1804.11188,cs.LG,2018-03-23 09:17:35+00:00,2018-03-23 09:17:35+00:00
SJd0EAy0b,2018,Reject,False,Generalized Graph Embedding Models,"[""Qiao Liu"", ""Xiaohui Yang"", ""Rui Wan"", ""Shouzhong Tu"", ""Zufeng Wu""]","[""representation learning"", ""knowledge graphs"", ""relational inference"", ""link prediction"", ""multi-label classification"", ""knowledge base completion""]",Generalized Graph Embedding Models,,,,
SJdCUMZAW,2018,Reject,False,Data-efficient Deep Reinforcement Learning for Dexterous Manipulation,"[""Ivo Popov"", ""Nicolas Heess"", ""Timothy P. Lillicrap"", ""Roland Hafner"", ""Gabriel Barth-Maron"", ""Matej Vecerik"", ""Thomas Lampe"", ""Tom Erez"", ""Yuval Tassa"", ""Martin Riedmiller""]","[""Reinforcement learning"", ""robotics"", ""dexterous manipulation"", ""off-policy learning""]",Data-efficient deep reinforcement learning can be used to learning precise stacking policies.,,,,
SJe-HkBKDS,2020,Reject,False,Amharic Text Normalization with Sequence-to-Sequence Models,"[""Seifedin Shifaw Mohamed"", ""Solomon Teferra Abate (PhD)""]","[""Text Normalization"", ""Sequence-to-Sequence Model"", ""Encoder-Decoder""]",,,,,
SJe2so0qF7,2019,Reject,False,Learning data-derived privacy preserving representations from information metrics,"[""Martin Bertran"", ""Natalia Martinez"", ""Afroditi Papadaki"", ""Qiang Qiu"", ""Miguel Rodrigues"", ""Guillermo Sapiro""]","[""Machine learning"", ""privacy"", ""adversarial training"", ""information theory"", ""data-driven privacy""]",Learning privacy-preserving transformations from data. A collaborative approach,,,,
SJe3HiC5KX,2019,Accept (Poster),True,LEARNING FACTORIZED REPRESENTATIONS FOR OPEN-SET DOMAIN ADAPTATION,"[""Mahsa Baktashmotlagh"", ""Masoud Faraki"", ""Tom Drummond"", ""Mathieu Salzmann""]","[""Open Set Domain Adaptation""]",,1805.12277,cs.CV,2018-05-31 01:08:20+00:00,2018-05-31 01:08:20+00:00
SJe3KCNKPr,2020,Reject,False,Dual-module Inference for Efficient Recurrent Neural Networks,"[""Liu Liu"", ""Lei Deng"", ""Shuangchen Li"", ""Jingwei Zhang"", ""Yihua Yang"", ""Zhenyu Gu"", ""Yufei Ding"", ""Yuan Xie""]","[""memory-efficient RNNs"", ""dynamic execution"", ""computation skipping""]",We accelerate RNN inference by dynamically reducing redundant memory access using a mixture of accurate and approximate modules.,,,,
SJe5P6EYvS,2020,Accept (Talk),True,Mogrifier LSTM,"[""G\u00e1bor Melis"", ""Tom\u00e1\u0161 Ko\u010disk\u00fd"", ""Phil Blunsom""]","[""lstm"", ""language modelling""]",An LSTM extension with state-of-the-art language modelling results.,1909.01792,cs.CL,2019-09-04 13:32:23+00:00,2020-01-29 14:12:52+00:00
SJe8DsR9tm,2019,Reject,False,Dynamic Early Terminating of Multiply Accumulate Operations for Saving Computation Cost in Convolutional Neural Networks,"[""Yu-Yi Su"", ""Yung-Chih Chen"", ""Xiang-Xiu Wu"", ""Shih-Chieh Chang""]","[""Convolutional neural network"", ""Early terminating"", ""Dynamic model optimization""]",,,,,
SJe9qT4YPr,2020,Reject,False,RISE and DISE: Two Frameworks for Learning from Time Series with Missing Data,"[""Alberto Garcia-Duran"", ""Robert West""]","[""Time Series"", ""Missing Data"", ""RNN""]","Two frameworks for learning from time series with missing data: (1) RISE generalizes multiple previous imputation-based methods, (2) DISE avoids imputation by using time information in representation learning",,,,
SJe9rh0cFX,2019,Accept (Poster),False,On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks,"[""Yukun Ding"", ""Jinglan Liu"", ""Jinjun Xiong"", ""Yiyu Shi""]","[""Quantized Neural Networks"", ""Universial Approximability"", ""Complexity Bounds"", ""Optimal Bit-width""]",This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.,,,,
SJeC2TNYwB,2020,Reject,True,Unsupervised Out-of-Distribution Detection with Batch Normalization,"[""Jiaming Song"", ""Yang Song"", ""Stefano Ermon""]",[],,1910.09115,cs.LG,2019-10-21 02:14:16+00:00,2019-10-21 02:14:16+00:00
SJeD3CEFPH,2020,Accept (Talk),False,Meta-Q-Learning,"[""Rasool Fakoor"", ""Pratik Chaudhari"", ""Stefano Soatto"", ""Alexander J. Smola""]","[""meta reinforcement learning"", ""propensity estimation"", ""off-policy""]",MQL is a simple off-policy meta-RL algorithm that recycles data from the meta-training replay buffer to adapt to new tasks.,,,,
SJeFNlHtPS,2020,Reject,False,Hidden incentives for self-induced distributional shift,"[""David Scott Krueger"", ""Tegan Maharaj"", ""Shane Legg"", ""Jan Leike""]","[""distributional shift"", ""safety"", ""incentives"", ""specification"", ""content recommendation"", ""reinforcement learning"", ""online learning"", ""ethics""]",Performance metrics are incomplete specifications; the ends don't always justify the means.,,,,
SJeFNoRcFQ,2019,Reject,False,Traditional and Heavy Tailed Self Regularization in Neural Network Models,"[""Charles H. Martin"", ""Michael W. Mahoney""]","[""statistical mechanics"", ""self-regularization"", ""random matrix"", ""glassy behavior"", ""heavy-tailed""]","See the abstract.  (For the revision, the paper is identical, except for a 59 page Supplementary Material, which can serve as a stand-along technical report version of the paper.)",,,,
SJeF_h4FwB,2020,Reject,False,Label Cleaning with Likelihood Ratio Test,"[""Songzhu Zheng"", ""Pengxiang Wu"", ""Aman Goswami"", ""Mayank Goswami"", ""Dimitris Metaxas"", ""Chao Chen""]","[""Deep Learning""]",Use likelihood ratio test to perform label correction ,,,,
SJeHwJSYvH,2020,Reject,True,Learning De-biased Representations with Biased Representations,"[""Hyojin Bahng"", ""Sanghyuk Chun"", ""Sangdoo Yun"", ""Jaegul Choo"", ""Seong Joon Oh""]","[""Generalization"", ""Bias"", ""Dataset bias""]",,1910.02806,cs.CV,2019-10-07 14:11:13+00:00,2020-06-30 11:51:02+00:00
SJeItTEKvr,2020,Reject,False,MULTI-LABEL METRIC LEARNING WITH BIDIRECTIONAL REPRESENTATION DEEP NEURAL NETWORKS,"[""Tao Zheng"", ""Ivor Tsang"", ""Xin Yao""]","[""metric learning"", ""representation learning"", ""multi-label classification"", ""multi-output""]",,,,,
SJeLIgBKPS,2020,Accept (Talk),True,Gradient Descent Maximizes the Margin of Homogeneous Neural Networks,"[""Kaifeng Lyu"", ""Jian Li""]","[""margin"", ""homogeneous"", ""gradient descent""]",We study the implicit bias of gradient descent and prove under a minimal set of assumptions that the parameter direction of homogeneous models converges to KKT points of a natural margin maximization problem.,1906.05890,cs.LG,2019-06-13 18:52:00+00:00,2020-12-29 05:33:37+00:00
SJeLO34KwS,2020,Reject,False,Dimensional Reweighting Graph Convolution Networks,"[""Xu Zou"", ""Qiuye Jia"", ""Jianwei Zhang"", ""Chang Zhou"", ""Zijun Yao"", ""Hongxia Yang"", ""Jie Tang""]","[""graph convolutional networks"", ""representation learning"", ""mean field theory"", ""variance reduction"", ""node classification""]","We propose a simple yet effective reweighting scheme for GCNs, theoretically supported by the mean field theory.",,,,
SJeLopEYDH,2020,Accept (Poster),False,V4D: 4D Convolutional Neural Networks for Video-level Representation Learning,"[""Shiwen Zhang"", ""Sheng Guo"", ""Weilin Huang"", ""Matthew R. Scott"", ""Limin Wang""]","[""video-level representation learning"", ""video action recognition"", ""4D CNNs""]","A novel 4D CNN structure for video-level representation learning, surpassing  recent 3D CNNs.",2002.07442,cs.CV,2020-02-18 09:27:41+00:00,2020-02-18 09:27:41+00:00
SJeNz04tDS,2020,Accept (Poster),True,Overlearning Reveals Sensitive Attributes,"[""Congzheng Song"", ""Vitaly Shmatikov""]","[""privacy"", ""censoring representation"", ""transfer learning""]","Overlearning means that a model trained for a seemingly simple objective implicitly learns to recognize attributes and concepts that are (1) not part of the learning objective, and (2) sensitive from a privacy or bias perspective.",1905.11742,cs.LG,2019-05-28 11:16:02+00:00,2020-02-08 23:45:05+00:00
SJeOAJStwB,2020,Reject,False,On Federated Learning of Deep Networks from Non-IID Data: Parameter Divergence and the Effects of Hyperparametric Methods,"[""Heejae Kim"", ""Taewoo Kim"", ""Chan-Hyun Youn""]","[""Federated learning"", ""Iterative parameter averaging"", ""Deep networks"", ""Decentralized non-IID data"", ""Hyperparameter optimization methods""]","We investigate the internal reasons of our observations, the diminishing effects of the well-known hyperparameter optimization methods on federated learning from decentralized non-IID data.",,,,
SJeQEp4YDH,2020,Accept (Poster),False,GAT: Generative Adversarial Training for Adversarial Example Detection and Robust Classification,"[""Xuwang Yin"", ""Soheil Kolouri"", ""Gustavo K Rohde""]","[""adversarial example detection"", ""adversarial examples classification"", ""robust optimization"", ""ML security"", ""generative modeling"", ""generative classification""]",We propose an objective that could be used for training adversarial example detection and robust classification systems.,,,,
SJeQGJrKwH,2020,Reject,False,DS-VIC: Unsupervised Discovery of Decision States for Transfer in RL,"[""Nirbhay Modhe"", ""Prithvijit Chattopadhyay"", ""Mohit Sharma"", ""Abhishek Das"", ""Devi Parikh"", ""Dhruv Batra"", ""Ramakrishna Vedantam""]","[""reinforcement learning"", ""probabilistic inference"", ""variational inference"", ""intrinsic control"", ""transfer learning""]","Identify decision states (where agent can take actions that matter) without reward supervision, use it for transfer.",,,,
SJeQdeBtwB,2020,Reject,False,Adversarially learned anomaly detection for time series data,"[""Alexander Geiger"", ""Alfredo Cuesta-Infante"", ""Kalyan Veeramachaneni""]","[""anomaly detection"", ""gan""]",The paper describes an approach for GAN based anomaly detection in time series data,,,,
SJeQi1HKDH,2020,Reject,False,Learning with Social Influence through  Interior Policy Differentiation,"[""Hao Sun"", ""Bo Dai"", ""Jiankai Sun"", ""Zhenghao Peng"", ""Guodong Xu"", ""Dahua Lin"", ""Bolei Zhou""]","[""Reinforcement Learning"", ""Social Uniqueness"", ""Policy Differentiation""]",A new RL algorithm called Interior Policy Differentiation is proposed to learn a collection of diverse policies for a given primal task.,,,,
SJeS16EKPr,2020,Reject,False,Learning relevant features for statistical inference,"[""C\u00e9dric B\u00e9ny""]","[""unsupervised learning"", ""non-parametric probabilistic model"", ""singular value decomposition"", ""fisher information metric"", ""chi-squared distance""]","Given bipartite data and two neural nets, this new objective based on Fisher information teaches them to extract the most correlated features, which can then be used to do inference.",,,,
SJeT_oRcY7,2019,Reject,False,Localized random projections challenge benchmarks for bio-plausible deep learning,"[""Bernd Illing"", ""Wulfram Gerstner"", ""Johanni Brea""]","[""deep learning"", ""bio-plausibility"", ""random projections"", ""spiking networks"", ""unsupervised learning"", ""MNIST"", ""spike timing dependent plasticity""]",Spiking networks using localized random projections and STDP challenge current MNIST benchmark models for bio-plausible deep learning,1905.04101,cs.NE,2019-02-27 13:16:28+00:00,2019-06-17 15:54:19+00:00
SJeUAj05tQ,2019,Reject,False,DADAM: A consensus-based distributed adaptive gradient method for online optimization,"[""Parvin Nazari"", ""Davoud Ataee Tarzanagh"", ""George Michailidis""]",[],,,,,
SJeUm1HtDH,2020,Reject,False,Swoosh! Rattle! Thump! - Actions that Sound,"[""Dhiraj Gandhi"", ""Abhinav Gupta"", ""Lerrel Pinto""]","[""Sound"", ""Action"", ""Audio Representations""]",We explore and study the synergies between sound and action.,2007.01851,cs.RO,2020-07-03 17:57:54+00:00,2020-07-03 17:57:54+00:00
SJeW-A4tDS,2020,Reject,False,Detecting malicious PDF using CNN,"[""Raphael Fettaya"", ""Yishay Mansour""]","[""Cybersecurity"", ""Convolutional Neural Network"", ""Malware""]",,2007.12729,cs.CR,2020-07-24 18:27:45+00:00,2020-08-02 10:15:50+00:00
SJeWHlSYDB,2020,Reject,False,SPREAD  DIVERGENCE,"[""Mingtian Zhang"", ""David Barber"", ""Thomas Bird"", ""Peter Hayes"", ""Raza Habib""]","[""divergence minimization"", ""generative model"", ""variational inference""]",A new divergence family dealing with distributions with different supports for training implicit generative models.,,,,
SJeX2aVFwH,2020,Reject,False,Project and Forget: Solving Large Scale Metric Constrained Problems,"[""Anna C. Gilbert"", ""Rishi Sonthalia""]","[""metric constrained problems"", ""metric learning"", ""metric nearness"", ""correlation clustering"", ""Bregman projection"", ""cutting planes"", ""large scale optimization""]",We can solve large-scale metric-constrained optimization problems provably with Project and Forget.,,,,
SJeXJANFPr,2020,Reject,False,Regularizing Deep Multi-Task Networks using Orthogonal Gradients,"[""Mihai Suteu"", ""Yi-ke Guo""]","[""multi-task learning"", ""gradient regularization"", ""orthogonal gradients""]",We propose a novel gradient regularization term that minimizes task interference by enforcing near orthogonal gradients.,,,,
SJeXSo09FQ,2019,Accept (Poster),False,Learning Localized Generative Models for 3D Point Clouds via Graph Convolution,"[""Diego Valsesia"", ""Giulia Fracastoro"", ""Enrico Magli""]","[""GAN"", ""graph convolution"", ""point clouds""]",A GAN using graph convolution operations with dynamically computed graphs from hidden features,,,,
SJeY-1BKDS,2020,Accept (Poster),False,"Understanding l4-based Dictionary Learning: Interpretation, Stability, and Robustness","[""Yuexiang Zhai"", ""Hermish Mehta"", ""Zhengyuan Zhou"", ""Yi Ma""]","[""L4-norm Maximization"", ""Robust Dictionary Learning""]","We compare the l4-norm based dictionary learning with PCA, ICA and show its stability as well as robustness.",,,,
SJeYe0NtvH,2020,Accept (Poster),True,Neural Text Generation With Unlikelihood Training,"[""Sean Welleck"", ""Ilia Kulikov"", ""Stephen Roller"", ""Emily Dinan"", ""Kyunghyun Cho"", ""Jason Weston""]","[""language modeling"", ""machine learning""]",,1908.04319,cs.LG,2019-08-12 18:09:04+00:00,2019-09-26 23:57:44+00:00
SJe_D1SYvr,2020,Reject,False,Partial Simulation for Imitation Learning,"[""Nir Baram"", ""Shie Mannor""]","[""Reinforcement Learning"", ""Imitation Learning"", ""Behavior Cloning"", ""Partial Simulation""]","A formulation of solving imitation problems using RL, without requiring full knowledge about the state dynamics",,,,
SJecKyrKPH,2020,Reject,False,ICNN: INPUT-CONDITIONED FEATURE REPRESENTATION LEARNING FOR TRANSFORMATION-INVARIANT NEURAL NETWORK,"[""Suraj Tripathi"", ""Chirag Singh"", ""Abhay Kumar""]","[""Transformation-invariance"", ""Reconstruction"", ""Run-time Convolution Filter generation""]",,,,,
SJeeL04KvH,2020,Reject,False,Robust Federated Learning Through Representation Matching and Adaptive Hyper-parameters,"[""Hesham Mostafa""]","[""federated learning"", ""hyper-parameter tuning"", ""regularization""]","We describe a cheap, online, and automated hyper-parameter tuning scheme for Federated learning settings and a novel mechanism for mitigating model divergence in the presence of non-iid client data.",1912.13075,cs.LG,2019-12-30 20:19:20+00:00,2019-12-30 20:19:20+00:00
SJefGpEtDB,2020,Reject,False,A Dynamic Approach to Accelerate Deep Learning Training,"[""John Osorio"", ""Adri\u00e0 Armejach"", ""Eric Petit"", ""Marc Casas""]","[""reduced precision"", ""bfloat16"", ""CNN"", ""DNN"", ""dynamic precision"", ""mixed precision""]",Dynamic precision technique to train deep neural networks,,,,
SJefPkSFPr,2020,Reject,False,Regulatory Focus: Promotion and Prevention Inclinations in Policy Search,"[""Lanxin Lei"", ""Zhizhong Li"", ""Xiaoyang Li"", ""Cong Qiu"", ""Dahua Lin""]","[""Reinforcement Learning"", ""Regulatory Focus"", ""Promotion and Prevention"", ""Exploration""]",We implemented and tested the regulatory fit theory from psychology in RL using order statistics over path ensembles.,,,,
SJegkkrYPS,2020,Reject,False,Starfire: Regularization-Free Adversarially-Robust Structured Sparse Training,"[""Noah Gamboa"", ""Kais Kudrolli"", ""Anand Dhoot"", ""Ardavan Pedram""]","[""Structured Sparsity"", ""Sparsity"", ""Training"", ""Compression"", ""Adversarial"", ""Regularization"", ""Acceleration""]","This paper studies structured sparse training of CNNs that leads to fixed, sparse weight matrices after a set number of epochs.",,,,
SJekyhCctQ,2019,Reject,False,Detecting Adversarial Examples Via Neural Fingerprinting,"[""Sumanth Dathathri"", ""Stephan Zheng"", ""Yisong Yue"", ""Richard M. Murray""]","[""Adversarial Attacks"", ""Deep Neural Networks""]","Novel technique for detecting adversarial examples -- robust across gradient-based and gradient-free attacks, AUC-ROC >95%",,,,
SJem8lSFwB,2020,Accept (Poster),False,Dynamic Model Pruning with Feedback,"[""Tao Lin"", ""Sebastian U. Stich"", ""Luis Barba"", ""Daniil Dmitriev"", ""Martin Jaggi""]","[""network pruning"", ""dynamic reparameterization"", ""model compression""]",,2006.07253,cs.LG,2020-06-12 15:07:08+00:00,2020-06-12 15:07:08+00:00
SJeoE0VKDS,2020,Reject,False,Novelty Search in representational space for sample efficient exploration,"[""Ruo Yu Tao"", ""Vincent Fran\u00e7ois-Lavet"", ""Joelle Pineau""]","[""Reinforcement Learning"", ""Exploration""]",We conduct exploration using intrinsic rewards that are based on a weighted distance of nearest neighbors in representational space.,2009.13579,cs.LG,2020-09-28 18:51:52+00:00,2020-10-21 19:48:33+00:00
SJeq9JBFvH,2020,Accept (Poster),False,Deep probabilistic subsampling for task-adaptive compressed sensing,"[""Iris A.M. Huijben"", ""Bastiaan S. Veeling"", ""Ruud J.G. van Sloun""]",[],,,,,
SJeqs6EFvB,2020,Accept (Spotlight),False,HOPPITY: LEARNING GRAPH TRANSFORMATIONS TO DETECT AND FIX BUGS IN PROGRAMS,"[""Elizabeth Dinella"", ""Hanjun Dai"", ""Ziyang Li"", ""Mayur Naik"", ""Le Song"", ""Ke Wang""]","[""Bug Detection"", ""Program Repair"", ""Graph Neural Network"", ""Graph Transformation""]",An learning-based approach for detecting and fixing bugs in Javascript,,,,
SJequsCqKQ,2019,Reject,False,Cautious Deep Learning,"[""Yotam Hechtlinger"", ""Barnabas Poczos"", ""Larry Wasserman""]","[""Deep Learning"", ""Classification"", ""Prediction"", ""Cautious Methods""]","New way to do classification using P(X|Y) instead P(Y|X) which results with cautious prediciton outputing ""I don't know"" for outliers. ",,,,
SJerEhR5Km,2019,Reject,False,Novel positional encodings to enable tree-structured transformers,"[""Vighnesh Leonardo Shiv"", ""Chris Quirk""]","[""program translation"", ""tree structures"", ""transformer""]","We develop novel positional encodings for tree-structured data, enabling transformers to be applied to tree structured problems.",,,,
SJetQpEYvB,2020,Accept (Poster),True,LEARNING EXECUTION THROUGH NEURAL CODE FUSION,"[""Zhan Shi"", ""Kevin Swersky"", ""Daniel Tarlow"", ""Parthasarathy Ranganathan"", ""Milad Hashemi""]","[""code understanding"", ""graph neural networks"", ""learning program execution"", ""execution traces"", ""program performance""]",,1906.07181,cs.LG,2019-06-17 20:05:48+00:00,2020-03-11 03:11:50+00:00
SJeuueSYDH,2020,Reject,False,Distributed Training Across the World,"[""Ligeng Zhu"", ""Yao Lu"", ""Yujun Lin"", ""Song Han""]","[""Distributed Training"", ""Bandwidth""]",Conventional distributed learning is only performed inside cluster because of latency requirements. We scale the distributed training across the world under high latency network.,,,,
SJev6JBtvH,2020,Reject,False,Testing For Typicality with Respect to an Ensemble of Learned Distributions,"[""Forrest Laine"", ""Claire Tomlin""]","[""anomaly detection"", ""density estimation"", ""generative models""]",We show theoretically and empirically that testing for typicality with respect to an ensemble of learned distributions can account for learning error in the hypothesis testing. ,,,,
SJexHkSFPS,2020,Accept (Poster),False,Thinking While Moving: Deep Reinforcement Learning with Concurrent Control,"[""Ted Xiao"", ""Eric Jang"", ""Dmitry Kalashnikov"", ""Sergey Levine"", ""Julian Ibarz"", ""Karol Hausman"", ""Alexander Herzog""]","[""deep reinforcement learning"", ""continuous-time"", ""robotics""]","Reinforcement learning formulation that allows agents to think and act at the same time, demonstrated on real-world robotic grasping.",2004.06089,cs.LG,2020-04-13 17:49:29+00:00,2020-04-25 21:19:45+00:00
SJezGp4YPr,2020,Accept (Poster),True,Geometric Insights into the Convergence of Nonlinear TD Learning,"[""David Brandfonbrener"", ""Joan Bruna""]","[""TD"", ""nonlinear"", ""convergence"", ""value estimation"", ""reinforcement learning""]",,1905.12185,cs.LG,2019-05-29 02:47:43+00:00,2020-02-11 16:15:04+00:00
SJf6BhAqK7,2019,Reject,False,Variadic Learning by Bayesian Nonparametric Deep Embedding,"[""Kelsey R Allen"", ""Hanul Shin"", ""Evan Shelhamer"", ""Josh B. Tenenbaum""]","[""meta-learning"", ""metric learning"", ""bayesian nonparametrics"", ""few-shot learning"", ""deep learning""]","We address any-shot, any-way learning with multi-modal prototypes by connecting bayesian nonparametrics and deep metric learning",,,,
SJfFTjA5KQ,2019,Reject,False,Unification of  Recurrent   Neural Network Architectures and Quantum Inspired Stable Design ,"[""Murphy Yuezhen Niu"", ""Lior Horesh"", ""Michael O'Keeffe"", ""Isaac Chuang""]","[""theory and analysis of RNNs architectures"", ""reversibe evolution"", ""stability of deep neural network"", ""learning representations of outputs or states"", ""quantum inspired embedding""]","We provide theoretical proof of various recurrent neural network designs representable dynamics' nonlinearity and memory scale, and propose a new RNN ansatz inspired by quantum physics.",,,,
SJfHg2A5tQ,2019,Reject,False,BNN+: Improved Binary Network Training,"[""Sajad Darabi"", ""Mouloud Belbahri"", ""Matthieu Courbariaux"", ""Vahid Partovi Nia""]","[""Binary Network"", ""Binary Training"", ""Model Compression"", ""Quantization""]",The paper presents an improved training mechanism for obtaining binary networks with smaller accuracy drop that helps close the gap with it's full precision counterpart,,,,
SJfPFjA9Fm,2019,Accept (Poster),False,ACCELERATING NONCONVEX LEARNING VIA REPLICA EXCHANGE LANGEVIN DIFFUSION,"[""Yi Chen"", ""Jinglin Chen"", ""Jing Dong"", ""Jian Peng"", ""Zhaoran Wang""]",[],,,,,
SJfZKiC5FX,2019,Accept (Poster),False,Dynamically Unfolding Recurrent Restorer: A Moving Endpoint Control Method for Image Restoration,"[""Xiaoshuai Zhang"", ""Yiping Lu"", ""Jiaying Liu"", ""Bin Dong""]","[""image restoration"", ""differential equation""]",We propose a novel method to handle image degradations of different levels by learning a diffusion terminal time. Our model can generalize to unseen degradation level and different noise statistic.,,,,
SJf_XhCqKm,2019,Reject,False,Open Loop Hyperparameter Optimization and Determinantal Point Processes,"[""Jesse Dodge"", ""Kevin Jamieson"", ""Noah Smith""]","[""hyperparameter optimization"", ""black box optimization""]",We address fully parallel hyperparameter optimization with Determinantal Point Processes. ,,,,
SJfb5jCqKm,2019,Accept (Poster),False,Bias-Reduced Uncertainty Estimation for Deep Neural Classifiers,"[""Yonatan Geifman"", ""Guy Uziel"", ""Ran El-Yaniv""]","[""Uncertainty estimation"", ""Deep learning""]",We use snapshots from the training process to improve any uncertainty estimation method of a DNN classifier.,,,,
SJg013C5KX,2019,Reject,False,Teaching to Teach by Structured Dark Knowledge,"[""Ziliang Chen"", ""Keze Wang"", ""Liang Lin""]","[""teaching to teach"", ""dark knowledge"", ""curriculum learning"", ""teaching""]","We newly proposed ``teaching to teach, to educate a better teacher to teach a better student by introducing structured dark knowledge.",,,,
SJg1lxrYwS,2020,Reject,False,PatchFormer: A neural architecture for self-supervised representation learning on images,"[""Aravind Srinivas"", ""Pieter Abbeel""]","[""Unsupervised Learning"", ""Representation Learning"", ""Transformers""]",Decoding pixels can still work for representation learning on images,,,,
SJg2j0VFPB,2020,Reject,False,Knowledge Graph Embedding: A Probabilistic Perspective and Generalization Bounds,"[""Ondrej Kuzelka"", ""Yuyi Wang""]","[""knowledge graph embedding"", ""generalization bounds""]",We prove bounds on expected error of knowledge graph embedding methods from certain class and under certain assumptions.,,,,
SJg498clg,2017,Reject,False,Neural Graph Machines: Learning Neural Networks Using Graphs,"[""Thang D. Bui"", ""Sujith Ravi"", ""Vivek Ramavajjala""]","[""Semi-Supervised Learning"", ""Natural language processing"", ""Applications""]",,,,,
SJg4Y3VFPS,2020,Reject,False,Group-Connected Multilayer Perceptron Networks,"[""Mohammad Kachuee"", ""Sajad Darabi"", ""Shayan Fazeli"", ""Majid Sarrafzadeh""]",[],An architecture to learn and exploit expressive feature combinations,1912.09600,cs.LG,2019-12-20 00:49:07+00:00,2020-11-25 16:56:55+00:00
SJg5J6NtDr,2020,Accept (Poster),True,"Watch, Try, Learn: Meta-Learning from Demonstrations and Rewards","[""Allan Zhou"", ""Eric Jang"", ""Daniel Kappler"", ""Alex Herzog"", ""Mohi Khansari"", ""Paul Wohlhart"", ""Yunfei Bai"", ""Mrinal Kalakrishnan"", ""Sergey Levine"", ""Chelsea Finn""]","[""meta-learning"", ""reinforcement learning"", ""imitation learning""]",,1906.03352,cs.LG,2019-06-07 22:46:35+00:00,2020-01-30 23:13:01+00:00
SJg6nj09F7,2019,Reject,False,NEURAL MALWARE CONTROL WITH DEEP REINFORCEMENT LEARNING,"[""Yu Wang"", ""Jack W. Stokes"", ""Mady Marinescu""]","[""malware"", ""execution"", ""control"", ""deep reinforcement learning""]",A deep reinforcement learning-based system is proposed to control when to halt the emulation of an unknown file and to improve the detection rate of a deep malware classifier.,,,,
SJg7IsC5KQ,2019,Reject,False,On the Convergence and Robustness of Batch Normalization,"[""Yongqiang Cai"", ""Qianxiao Li"", ""Zuowei Shen""]","[""Batch normalization"", ""Convergence analysis"", ""Gradient descent"", ""Ordinary least squares"", ""Deep neural network""]",We mathematically analyze the effect of batch normalization on a simple model and obtain key new insights that applies to general supervised learning.,,,,
SJg7KhVKPH,2020,Accept (Poster),False,Depth-Adaptive Transformer,"[""Maha Elbayad"", ""Jiatao Gu"", ""Edouard Grave"", ""Michael Auli""]","[""Deep learning"", ""natural language processing"", ""sequence modeling""]",Sequence model that dynamically adjusts the amount of computation for each input.,,,,
SJg7spEYDS,2020,Accept (Poster),True,Generative Ratio Matching Networks,"[""Akash Srivastava"", ""Kai Xu"", ""Michael U. Gutmann"", ""Charles Sutton""]","[""deep generative model"", ""deep learning"", ""maximum mean discrepancy"", ""density ratio estimation""]","MMD-based, saddle-point optimisation free, stable-to-train generative model that beats GAN on generative quality without playing any  zero-sum games.",1806.00101,stat.ML,2018-05-31 21:06:03+00:00,2020-02-15 02:06:36+00:00
SJg9z6VFDr,2020,Reject,False,Ordinary differential equations on graph networks,"[""Juntang Zhuang"", ""Nicha Dvornek"", ""Xiaoxiao Li"", ""James S. Duncan""]","[""Graph Networks"", ""Ordinary differential equation""]",Apply ordinary differential equation model on graph structured data,,,,
SJgBQaVKwH,2020,Reject,True,Effective Use of Variational Embedding Capacity in Expressive End-to-End Speech Synthesis,"[""Eric Battenberg"", ""Soroosh Mariooryad"", ""Daisy Stanton"", ""RJ Skerry-Ryan"", ""Matt Shannon"", ""David Kao"", ""Tom Bagby""]","[""Speech Synthesis"", ""Deep Generative Models"", ""Latent Variable Models"", ""Unsupervised Representation Learning""]","We introduce techniques that increase the versatility of variational models of speech, allowing the same model to perform well on multiple tasks, including prosody and style transfer. ",1906.03402,cs.CL,2019-06-08 06:59:56+00:00,2019-10-25 23:53:38+00:00
SJgBra4YDS,2020,Reject,True,"Manifold Modeling in Embedded Space: A Perspective for Interpreting ""Deep Image Prior""","[""Tatsuya Yokota"", ""Hidekata Hontani"", ""Qibin Zhao"", ""Andrzej Cichocki""]","[""Deep image prior"", ""Manifold model"", ""Auto-encoder"", ""Convolutional neural network"", ""Delay-embedding"", ""Hankelization"", ""Tensor completion"", ""Image inpainting"", ""Supperresolution""]",We propose a new auto-encoder incorporated with multiway delay-embedding transform toward interpreting deep image prior.,1908.02995,cs.CV,2019-08-08 10:05:09+00:00,2020-01-21 08:14:35+00:00
SJgCEpVtvr,2020,Reject,False,DYNAMIC SELF-TRAINING FRAMEWORK  FOR GRAPH CONVOLUTIONAL NETWORKS,"[""Ziang Zhou"", ""Shenzhong Zhang"", ""Zengfeng Huang""]","[""self-training"", ""semi-supervised learning"", ""graph convolutional networks""]",Propose a novel self-training framework which performs well in few-label cases combined with GCN.,,,,
SJgEl3A5tm,2019,Accept (Poster),False,CAMOU: Learning Physical Vehicle Camouflages to Adversarially Attack Detectors in the Wild,"[""Yang Zhang"", ""Hassan Foroosh"", ""Philip David"", ""Boqing Gong""]","[""Adversarial Attack"", ""Object Detection"", ""Synthetic Simulation""]",We propose a method to learn physical vehicle camouflage to adversarially attack object detectors in the wild. We find our camouflage effective and transferable.,,,,
SJgIPJBFvH,2020,Accept (Poster),False,Fantastic Generalization Measures and Where to Find Them,"[""Yiding Jiang*"", ""Behnam Neyshabur*"", ""Hossein Mobahi"", ""Dilip Krishnan"", ""Samy Bengio""]","[""Generalization"", ""correlation"", ""experiments""]","We empirically study generalization measures over more than 2000 models, identify common pitfall in existing practice of studying generalization measures and provide some new bounds based on measures in our study.",,,,
SJgMK64Ywr,2020,Accept (Poster),True,AssembleNet: Searching for Multi-Stream Neural Connectivity in Video Architectures,"[""Michael S. Ryoo"", ""AJ Piergiovanni"", ""Mingxing Tan"", ""Anelia Angelova""]","[""video representation learning"", ""video understanding"", ""activity recognition"", ""neural architecture search""]",We search for multi-stream neural architectures with better connectivity and spatio-temporal interactions for video understanding.,1905.13209,cs.CV,2019-05-30 17:51:03+00:00,2020-05-27 15:56:37+00:00
SJgNkpVFPr,2020,Reject,True,VILD: Variational Imitation Learning with Diverse-quality Demonstrations,"[""Voot Tangkaratt"", ""Bo Han"", ""Mohammad Emtiyaz Khan"", ""Masashi Sugiyama""]","[""Imitation learning"", ""inverse reinforcement learning"", ""noisy demonstrations""]",We propose an imitation learning method to learn from diverse-quality demonstrations collected by demonstrators with different level of expertise.,1909.06769,cs.LG,2019-09-15 09:42:33+00:00,2019-09-15 09:42:33+00:00
SJgNwi09Km,2019,Accept (Poster),False,Learning Latent Superstructures in Variational Autoencoders for Deep Multidimensional Clustering,"[""Xiaopeng Li"", ""Zhourong Chen"", ""Leonard K. M. Poon"", ""Nevin L. Zhang""]","[""latent tree model"", ""variational autoencoder"", ""deep learning"", ""latent variable model"", ""bayesian network"", ""structure learning"", ""stepwise em"", ""message passing"", ""graphical model"", ""multidimensional clustering"", ""unsupervised learning""]",We investigate a variant of variational autoencoders where there is a superstructure of discrete latent variables on top of the latent features.,,,,
SJgSflHKDr,2020,Reject,False,The Frechet Distance of training and test distribution predicts the generalization gap,"[""Julian Zilly"", ""Hannes Zilly"", ""Oliver Richter"", ""Roger Wattenhofer"", ""Andrea Censi"", ""Emilio Frazzoli""]","[""Generalization"", ""Transfer learning"", ""Frechet distance"", ""Optimal transport"", ""Domain adaptation"", ""Distribution shift"", ""Invariance""]",The Frechet Distance between train and test distribution correlates with the change in performance for functions that are not invariant to the shift.,,,,
SJgTps0qtQ,2019,Reject,False,Exploiting Environmental Variation to Improve Policy Robustness in  Reinforcement Learning,"[""Siddharth Mysore"", ""Robert Platt"", ""Kate Saenko""]","[""Reinforcement Learning"", ""Policy Robustness"", ""Policy generalization"", ""Automated Curriculum""]","By formulating the learning curriculum as a bandit problem, we present a principled approach to motivating policy robustness in continuous controls tasks.",,,,
SJgVHkrYDH,2020,Accept (Poster),False,Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering,"[""Akari Asai"", ""Kazuma Hashimoto"", ""Hannaneh Hajishirzi"", ""Richard Socher"", ""Caiming Xiong""]","[""Multi-hop Open-domain Question Answering"", ""Graph-based Retrieval"", ""Multi-step Retrieval""]",Graph-based recurrent retriever that learns to retrieve reasoning paths over Wikipedia Graph outperforms the most recent state of the art on HotpotQA by more than 14 points.,1911.10470,cs.CL,2019-11-24 08:27:42+00:00,2020-02-14 07:43:06+00:00
SJgVU0EKwS,2020,Accept (Poster),False,Precision Gating: Improving Neural Network Efficiency with Dynamic Dual-Precision Activations,"[""Yichi Zhang"", ""Ritchie Zhao"", ""Weizhe Hua"", ""Nayun Xu"", ""G. Edward Suh"", ""Zhiru Zhang""]","[""deep learning"", ""neural network"", ""dynamic quantization"", ""dual precision"", ""efficient gating""]","We propose precision gating (PG), an end-to-end trainable dynamic dual-precision quantization technique for deep neural networks.",2002.07136,cs.CV,2020-02-17 18:54:37+00:00,2020-05-29 03:10:27+00:00
SJgWQPcxl,2017,Reject,False,Multi-view Generative Adversarial Networks,"[""Micka\u00ebl Chen"", ""Ludovic Denoyer""]","[""Deep learning"", ""Supervised Learning""]","We describe the MV-BiGAN model able to perform density estimation from multiple views, and to update its prediction when additional views are provided",,,,
SJgXs1HtwH,2020,Reject,True,TreeCaps: Tree-Structured Capsule Networks for Program Source Code Processing,"[""Vinoj Jayasundara"", ""Nghi Duy Quoc Bui"", ""Lingxiao Jiang"", ""David Lo""]","[""Program Classification"", ""Capsule Networks"", ""Deep Learning""]",,1910.12306,cs.LG,2019-10-27 17:28:00+00:00,2019-10-27 17:28:00+00:00
SJgaRA4FPH,2020,Accept (Poster),False,"Generative Models for Effective ML on Private, Decentralized Datasets","[""Sean Augenstein"", ""H. Brendan McMahan"", ""Daniel Ramage"", ""Swaroop Ramaswamy"", ""Peter Kairouz"", ""Mingqing Chen"", ""Rajiv Mathews"", ""Blaise Aguera y Arcas""]","[""generative models"", ""federated learning"", ""decentralized learning"", ""differential privacy"", ""privacy"", ""security"", ""GAN""]","Generative Models + Federated Learning + Differential Privacy gives data scientists a way to analyze private, decentralized data (e.g., on mobile devices) where direct inspection is prohibited.",1911.06679,cs.LG,2019-11-15 14:56:44+00:00,2020-02-04 22:38:20+00:00
SJgdnAVKDH,2020,Accept (Poster),True,Revisiting Self-Training for Neural Sequence Generation,"[""Junxian He"", ""Jiatao Gu"", ""Jiajun Shen"", ""Marc'Aurelio Ranzato""]","[""self-training"", ""semi-supervised learning"", ""neural sequence generatioin""]","We revisit self-training as a semi-supervised learning method for neural sequence generation problem, and show that self-training can be quite successful with injected noise.",1909.13788,cs.LG,2019-09-30 15:30:00+00:00,2020-10-18 22:49:31+00:00
SJgdpxHFvH,2020,Reject,False,Meta-Learning Initializations for Image Segmentation,"[""Sean M. Hendryx"", ""Andrew B. Leach"", ""Paul D. Hein"", ""Clayton T. Morrison""]","[""meta-learning"", ""image segmentation""]",We show that model agnostic meta-learning extends to the high dimensionality and dense prediction of image segmentation.,1912.06290,cs.LG,2019-12-13 01:58:36+00:00,2020-05-07 23:33:07+00:00
SJgf6Z-0W,2018,Reject,False,Predicting Multiple Actions for Stochastic Continuous Control,"[""Sanjeev Kumar"", ""Christian Rupprecht"", ""Federico Tombari"", ""Gregory D. Hager""]","[""Reinforcement Learning"", ""DDPG"", ""Multiple Action Prediction""]","We introduce a novel reinforcement learning algorithm, that predicts multiple actions and samples from them.",,,,
SJggZnRcFQ,2019,Accept (Poster),False,Learning Programmatically Structured Representations with Perceptor Gradients,"[""Svetlin Penkov"", ""Subramanian Ramamoorthy""]","[""representation learning"", ""structured representations"", ""symbols"", ""programs""]",,,,,
SJgiNo0cKX,2019,Reject,False,Multiple Encoder-Decoders Net for Lane Detection,"[""Yuetong Du"", ""Xiaodong Gu"", ""Junqin Liu"", ""Liwen He""]",[],,,,,
SJgmR0NKPr,2020,Accept (Poster),False,Training Recurrent Neural Networks Online by Learning Explicit State Variables,"[""Somjit Nath"", ""Vincent Liu"", ""Alan Chan"", ""Xin Li"", ""Adam White"", ""Martha White""]","[""Recurrent Neural Network"", ""Partial Observability"", ""Online Prediction"", ""Incremental Learning""]",,,,,
SJgn3lBtwH,2020,Reject,False,Re-Examining Linear Embeddings for High-dimensional Bayesian Optimization,"[""Benjamin Letham"", ""Roberto Calandra"", ""Akshara Rai"", ""Eytan Bakshy""]","[""Bayesian optimization"", ""high-dimensional"", ""Gaussian process""]","We study the use of linear embeddings for high-dimensional Bayesian optimization, identify issues that have caused poor performance, and develop new techniques for improving optimization performance in the embedding.",,,,
SJgn464tPB,2020,Reject,False,Stabilizing Off-Policy Reinforcement Learning with Conservative Policy Gradients,"[""Chen Tessler"", ""Nadav Merlis"", ""Shie Mannor""]","[""Deep Reinforcement Learning"", ""Variance Reduction"", ""Policy Gradient""]","We propose a conservative update rule for off-policy policy-gradient methods (e.g., DDPG) in order to reduce the variance of the training regime.",,,,
SJgndT4KwB,2020,Accept (Spotlight),True,Finite Depth and Width Corrections to the Neural Tangent Kernel,"[""Boris Hanin"", ""Mihai Nica""]","[""Neural Tangent Kernel"", ""Finite Width Corrections"", ""Random ReLU Net"", ""Wide Networks"", ""Deep Networks""]",The neural tangent kernel in a randomly initialized ReLU net is non-trivial fluctuations as long as the depth and width are comparable. ,1909.05989,cs.LG,2019-09-13 00:21:53+00:00,2019-09-13 00:21:53+00:00
SJgob6NKvH,2020,Accept (Poster),True,RTFM: Generalising to New Environment Dynamics via Reading,"[""Victor Zhong"", ""Tim Rockt\u00e4schel"", ""Edward Grefenstette""]","[""reinforcement learning"", ""policy learning"", ""reading comprehension"", ""generalisation""]",We show language understanding via reading is promising way to learn policies that generalise to new environments.,1910.08210,cs.CL,2019-10-18 00:49:15+00:00,2021-02-01 20:46:03+00:00
SJgs1n05YQ,2019,Reject,False,Learning and Planning with a Semantic Model,"[""Yi Wu"", ""Yuxin Wu"", ""Aviv Tamar"", ""Stuart Russell"", ""Georgia Gkioxari"", ""Yuandong Tian""]","[""deep reinforcement learning"", ""generalization"", ""semantic structure"", ""model-based""]",We propose a hybrid model-based & model-free approach using semantic information to improve DRL generalization in man-made environments.,,,,
SJgs8TVtvr,2020,Reject,True,Mixture-of-Experts Variational Autoencoder for clustering and generating from similarity-based representations,"[""Andreas Kopf"", ""Vincent Fortuin"", ""Vignesh Ram Somnath"", ""Manfred Claassen""]","[""Variational Autoencoder"", ""Clustering"", ""Generative model""]",,1910.07763,cs.LG,2019-10-17 08:21:28+00:00,2020-12-18 14:23:42+00:00
SJgsCjCqt7,2019,Accept (Poster),False,Variational Autoencoders with Jointly Optimized Latent Dependency Structure,"[""Jiawei He"", ""Yu Gong"", ""Joseph Marino"", ""Greg Mori"", ""Andreas Lehrmann""]","[""deep generative models"", ""structure learning""]",We propose a method for learning latent dependency structure in variational autoencoders.,,,,
SJgvl6EFwH,2020,Reject,False,InfoCNF: Efficient Conditional Continuous Normalizing Flow Using Adaptive Solvers,"[""Tan M. Nguyen"", ""Animesh Garg"", ""Richard G. Baraniuk"", ""Anima Anandkumar""]","[""continuous normalizing flows"", ""conditioning"", ""adaptive solvers"", ""gating networks""]","We propose the InfoCNF, an efficient conditional CNF that employs gating networks to learn the error tolerances of the ODE solvers  ",1912.03978,cs.LG,2019-12-09 11:37:22+00:00,2019-12-09 11:37:22+00:00
SJgw51HFDr,2020,Reject,False,Sparse Weight Activation Training,"[""Md Aamir Raihan"", ""Tor M. Aamodt""]","[""Sparsity"", ""Training"", ""Acceleration"", ""Pruning"", ""Compression""]",We sparsified computation by up to 70-80% in both forward and backward passes during CNN training with minimal loss in accuracy.,,,,
SJgwNerKvB,2020,Accept (Spotlight),True,Continual learning with hypernetworks,"[""Johannes von Oswald"", ""Christian Henning"", ""Jo\u00e3o Sacramento"", ""Benjamin F. Grewe""]","[""Continual Learning"", ""Catastrophic Forgetting"", ""Meta Model"", ""Hypernetwork""]",,1906.00695,cs.LG,2019-06-03 10:45:08+00:00,2020-02-12 14:56:57+00:00
SJgw_sRqFQ,2019,Accept (Poster),False,The Unusual Effectiveness of Averaging in GAN Training,"[""Yasin Yaz{\\i}c{\\i}"", ""Chuan-Sheng Foo"", ""Stefan Winkler"", ""Kim-Hui Yap"", ""Georgios Piliouras"", ""Vijay Chandrasekhar""]","[""Generative Adversarial Networks (GANs)"", ""Moving Average"", ""Exponential Moving Average"", ""Convergence"", ""Limit Cycles""]",,,,,
SJgwf04KPr,2020,Reject,True,Confidence-Calibrated Adversarial Training: Towards Robust Models Generalizing Beyond the Attack Used During Training,"[""David Stutz"", ""Matthias Hein"", ""Bernt Schiele""]","[""Adversarial Training"", ""Adversarial Examples"", ""Adversarial Robustness"", ""Confidence Calibration""]",This paper introduces confidence-calibrated adversarial training to generalize adversarial robustness to attacks not used during training.,1910.06259,cs.LG,2019-10-14 16:38:03+00:00,2020-06-30 12:03:44+00:00
SJgwzCEKwH,2020,Accept (Poster),False,Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,"[""Pu Zhao"", ""Pin-Yu Chen"", ""Payel Das"", ""Karthikeyan Natesan Ramamurthy"", ""Xue Lin""]","[""mode connectivity"", ""adversarial robustness"", ""backdoor attack"", ""error-injection attack"", ""evasion attacks"", ""loss landscapes""]","A novel approach using mode connectivity in loss landscapes to mitigate adversarial effects, repair tampered models, and evaluate adversarial robustness",2005.00060,cs.LG,2020-04-30 19:12:50+00:00,2020-07-03 03:49:28+00:00
SJgzLkBKPB,2020,Accept (Poster),False,Explain Your Move: Understanding Agent Actions Using Specific and Relevant Feature Attribution,"[""Nikaash Puri"", ""Sukriti Verma"", ""Piyush Gupta"", ""Dhruv Kayastha"", ""Shripad Deshmukh"", ""Balaji Krishnamurthy"", ""Sameer Singh""]","[""Deep Reinforcement Learning"", ""Saliency maps"", ""Chess"", ""Go"", ""Atari"", ""Interpretable AI"", ""Explainable AI""]","We propose a model-agnostic approach to explain the behaviour of black-box deep RL agents, trained to play Atari and board games, by highlighting relevant portions of the input state.",1912.12191,cs.CV,2019-12-23 07:52:15+00:00,2020-04-03 20:27:29+00:00
SJgzXaNFwS,2020,Reject,False,HyperEmbed:  Tradeoffs Between Resources and Performance in NLP Tasks with Hyperdimensional Computing enabled embedding of n-gram statistics ,"[""Pedro Alonso"", ""Kumar Shridhar"", ""Denis Kleyko"", ""Evgeny Osipov"", ""Marcus Liwicki""]","[""NLP"", ""Hyperdimensional computing"", ""n-gram statistics"", ""word representation"", ""semantic hashing""]",Tradeoffs Between Resources and Performance in NLP Tasks with Hyperdimensional Computing enabled embedding of n-gram statistics ,2003.01821,cs.CL,2020-03-03 22:44:10+00:00,2021-05-31 19:28:49+00:00
SJi9WOeRb,2018,Accept (Poster),False,Gradient Estimators for Implicit Models,"[""Yingzhen Li"", ""Richard E. Turner""]","[""Implicit Models"", ""Approximate Inference"", ""Deep Learning""]","We introduced a novel gradient estimator using Stein's method, and compared with other methods on learning implicit models for approximate inference and image generation.",,,,
SJiFvr9el,2017,Reject,False,Linear Time Complexity Deep Fourier Scattering Network and Extension to Nonlinear Invariants,"[""Randall Balestriero"", ""Herve Glotin""]","[""Unsupervised Learning"", ""Applications"", ""Deep learning""]",This paper proposes an extension of the Scattering Network in the Fourier domain and with nonlinear invariant computation for fast and scalable unsupervised representations,,,,
SJiHOSeR-,2018,Reject,False,Contextual memory bandit for pro-active dialog engagement,"[""julien perez"", ""Tomi Silander""]","[""contextual bandit"", ""memory network"", ""proactive dialog engagement""]",,,,,
SJiHXGWAZ,2018,Accept (Poster),True,Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting,"[""Yaguang Li"", ""Rose Yu"", ""Cyrus Shahabi"", ""Yan Liu""]","[""Traffic prediction"", ""spatiotemporal forecasting"", ""diffusion"", ""graph convolution"", ""random walk"", ""long-term forecasting""]",A neural sequence model that learns to forecast on a directed graph.,1707.01926,cs.LG,2017-07-06 18:20:59+00:00,2018-02-22 19:52:51+00:00
SJk01vogl,2017,Reject,False,Adversarial examples for generative models,"[""Jernej Kos"", ""Ian Fischer"", ""Dawn Song""]","[""Computer vision"", ""Unsupervised Learning""]",Exploration of ways to attack generative models with adversarial examples and why someone might want to do that.,,,,
SJkXfE5xx,2017,Accept (Poster),False,Revisiting Classifier Two-Sample Tests,"[""David Lopez-Paz"", ""Maxime Oquab""]","[""Theory"", ""Unsupervised Learning""]","Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.",,,,
SJky6Ry0W,2018,Reject,False,Learning Independent Causal Mechanisms,"[""Giambattista Parascandolo"", ""Mateo Rojas Carulla"", ""Niki Kilbertus"", ""Bernhard Schoelkopf""]",[],,,,,
SJl1o2NFwS,2020,Reject,True,Understanding and Improving Transformer From a Multi-Particle Dynamic System Point of View,"[""Yiping Lu"", ""Zhuohan Li"", ""Di He"", ""Zhiqing Sun"", ""Bin Dong"", ""Tao Qin"", ""Liwei Wang"", ""Tie-Yan Liu""]","[""Transformer"", ""Ordinary Differential Equation"", ""Multi-Particle Dynamic System"", ""Natural Language Processing""]",,1906.02762,cs.LG,2019-06-06 18:10:08+00:00,2019-06-06 18:10:08+00:00
SJl28R4YPr,2020,Reject,False,Graph Neural Networks for Reasoning 2-Quantified Boolean Formulas,"[""Fei Wang"", ""Zhanfu Yang"", ""Ziliang Chen"", ""Guannan Wei"", ""Tiark Rompf""]","[""Graph Neural Networks"", ""2-Quantified Boolean Formula"", ""Symbolic Reasoning""]",Learn GNN-based 2QBF solvers and GNN-based 2QBF heuristics,,,,
SJl2niR9KQ,2019,Accept (Poster),False,Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer,"[""Hsueh-Ti Derek Liu"", ""Michael Tao"", ""Chun-Liang Li"", ""Derek Nowrouzezahrai"", ""Alec Jacobson""]","[""adversarial examples"", ""norm-balls"", ""differentiable renderer""]","Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.",,,,
SJl2ps0qKQ,2019,Reject,False,Learning to Decompose Compound Questions with Reinforcement Learning,"[""Haihong Yang"", ""Han Wang"", ""Shuang Guo"", ""Wei Zhang"", ""Huajun Chen""]","[""Compound Question Decomposition"", ""Reinforcement Learning"", ""Knowledge-Based Question Answering"", ""Learning-to-decompose""]",We propose a learning-to-decompose agent that helps simple-question answerers to answer compound question over knowledge graph.,,,,
SJl3CANKvB,2020,Reject,False,A SIMPLE AND EFFECTIVE FRAMEWORK FOR PAIRWISE DEEP METRIC LEARNING,"[""Qi Qi"", ""Yan Yan"", ""Zixuan Wu"", ""Xiaoyu Wang"", ""Tianbao Yang""]","[""Deep Metric Learning"", ""Distributionally Robust Optimization""]",We provide a general and flexible framework based on distributionally robust optimization for deep metric learning which is robust to imbalanced data pair.,,,,
SJl3h2EYvS,2020,Reject,True,CLAREL: classification via retrieval loss for zero-shot learning,"[""Boris N. Oreshkin"", ""Negar Rostamzadeh"", ""Pedro O. Pinheiro"", ""Christopher Pal""]","[""zero-shot learning"", ""representation learning"", ""fine-grained classification""]",We propose an instance-based deep metric learning approach in joint visual and textual space. We show that per-image semantic supervision leads to substantial improvement over class-only supervision in zero shot classification.,1906.11892,cs.CV,2019-05-31 22:24:53+00:00,2020-04-05 14:59:22+00:00
SJl47yBYPS,2020,Reject,False,Towards Simplicity in Deep Reinforcement Learning: Streamlined Off-Policy Learning,"[""Che Wang"", ""Yanqiu Wu"", ""Quan Vuong"", ""Keith Ross""]","[""Deep Reinforcement Learning"", ""Sample Efficiency"", ""Off-Policy Algorithms""]",We propose a new DRL off-policy algorithm achieving state-of-the-art performance. ,,,,
SJl5Np4tPr,2020,Accept (Spotlight),False,Cross-Domain Few-Shot Classification via Learned Feature-Wise Transformation,"[""Hung-Yu Tseng"", ""Hsin-Ying Lee"", ""Jia-Bin Huang"", ""Ming-Hsuan Yang""]",[],,2001.08735,cs.CV,2020-01-23 18:55:43+00:00,2020-03-09 08:58:10+00:00
SJl7DsR5YQ,2019,Reject,False,ReNeg and Backseat Driver: Learning from demonstration with continuous human feedback,"[""Zoe Papakipos"", ""Jacob Beck"", ""Michael Littman""]","[""learning from demonstration"", ""imitation learning"", ""behavioral cloning"", ""reinforcement learning"", ""off-policy"", ""continuous control"", ""autonomous vehicles"", ""deep learning"", ""machine learning"", ""policy gradient""]",We introduce a novel framework for learning from demonstration that uses continuous human feedback; we evaluate this framework on continuous control for autonomous vehicles.,,,,
SJl8J30qFX,2019,Reject,False,Learning Global Additive Explanations for Neural Nets Using Model Distillation,"[""Sarah Tan"", ""Rich Caruana"", ""Giles Hooker"", ""Paul Koch"", ""Albert Gordo""]","[""global interpretability"", ""additive explanations"", ""model distillation"", ""neural nets"", ""tabular data""]",We propose to leverage model distillation to learn global additive explanations in the form of feature shapes (that are more expressive than feature attributions) for models such as neural nets trained on tabular data.,,,,
SJl8gnAqtX,2019,Reject,False,Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring,"[""Du Su"", ""Ali Yekkehkhany"", ""Yi Lu"", ""Wenmiao Lu""]","[""personalized learning"", ""e-learning"", ""text embedding"", ""Skip-gram"", ""imbalanced data set"", ""data level classification methods""]","We propose the Prob2Vec method for problem embedding used in a personalized e-learning tool in addition to a data level classification method, called negative pre-training, for cases where the training data set is imbalanced.",,,,
SJl98sR5tX,2019,Reject,True,Interactive Agent Modeling by Learning to Probe,"[""Tianmin Shu"", ""Caiming Xiong"", ""Ying Nian Wu"", ""Song-Chun Zhu""]","[""Agent Modeling"", ""Theory of Mind"", ""Deep Reinforcement Learning"", ""Multi-agent Reinforcement Learning""]",We propose an interactive agent modeling framework by learning a probing policy to diversify task settings and to incite new behaviors of a target agent for a better modeling of the target agent.,1810.00510,cs.AI,2018-10-01 02:55:07+00:00,2018-10-01 02:55:07+00:00
SJl9PTNYDS,2020,Reject,False,NPTC-net: Narrow-Band Parallel Transport Convolutional Neural Network on Point Clouds,"[""Pengfei Jin"", ""Tianhao Lai"", ""Rongjie Lai"", ""Bin Dong""]","[""geometric convolution"", ""point cloud"", ""parallel transport""]",We propose the Narrow-Band Parallel Transport Convolution (NPTC) using a specifically defined connection on a voxelized narrow-band approximation of point cloud data and further propose a deep convolutional neural network based on NPTC .,,,,
SJlDDnVKwS,2020,Reject,False,Improving Evolutionary Strategies with Generative Neural Networks,"[""Louis Faury"", ""Cl\u00e9ment Calauz\u00e8nes"", ""Olivier Fercoq""]","[""black-box optimization"", ""evolutionary strategies"", ""generative neural networks""]",We propose a new algorithm leveraging the expressiveness of Generative Neural Networks to improve Evolutionary Strategies algorithms.,,,,
SJlEs1HKDr,2020,Reject,False,Attentive Sequential Neural Processes,"[""Jaesik Yoon"", ""Gautam Singh"", ""Sungjin Ahn""]","[""meta-learning"", ""neural processes"", ""attention"", ""sequential modeling""]","We introduce a new model, Attentive Sequential Neural Processes, that resolves the problem of augmenting attention mechanism on SNP.",,,,
SJlHwkBYDH,2020,Accept (Poster),True,Nesterov Accelerated Gradient and Scale Invariance for Adversarial Attacks,"[""Jiadong Lin"", ""Chuanbiao Song"", ""Kun He"", ""Liwei Wang"", ""John E. Hopcroft""]","[""adversarial examples"", ""adversarial attack"", ""transferability"", ""Nesterov accelerated gradient"", ""scale invariance""]",We proposed a Nesterov Iterative Fast Gradient Sign Method (NI-FGSM) and a Scale-Invariant attack Method (SIM) that can boost the transferability of adversarial examples for image classification.,1908.06281,cs.LG,2019-08-17 10:03:05+00:00,2020-02-03 02:58:31+00:00
SJlJSaEFwS,2020,Reject,False,Robust Cross-lingual Embeddings from Parallel Sentences ,"[""Ali Sabet"", ""Prakhar Gupta"", ""Jean-Baptiste Cordonnier"", ""Robert West"", ""Martin Jaggi""]","[""Cross-lingual embeddings"", ""sent2vec"", ""word2vec"", ""bilingual"", ""word translation"", ""sentence retrieval"", ""text"", ""NLP"", ""word vectors"", ""sentence vectors""]",Joint method for learning cross-lingual embeddings with state-of-art performance for cross-lingual tasks and mono-lingual quality,1912.12481,cs.CL,2019-12-28 16:18:33+00:00,2020-05-01 17:02:33+00:00
SJlJegHFvH,2020,Reject,False,Address2vec: Generating vector embeddings for blockchain analytics,"[""Ali Hussein"", ""Samiiha Nalwooga""]","[""crypto-currency"", ""bitcoin"", ""blockchain"", ""2vec""]",a 2vec model for cryptocurrency transaction graphs,,,,
SJlKrkSFPH,2020,Accept (Poster),False,A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES,"[""Krishnamurthy (Dj) Dvijotham"", ""Jamie Hayes"", ""Borja Balle"", ""Zico Kolter"", ""Chongli Qin"", ""Andras Gyorgy"", ""Kai Xiao"", ""Sven Gowal"", ""Pushmeet Kohli""]","[""verification of machine learning"", ""certified robustness of neural networks""]",Develop a general framework to establish certified robustness of ML models against various classes of adversarial perturbations,,,,
SJlM0JSFDr,2020,Reject,False,A Theoretical Analysis of  Deep Q-Learning,"[""Zhuoran Yang"", ""Yuchen Xie"", ""Zhaoran Wang""]","[""reinforcement learning"", ""deep Q network"", ""minimax-Q learning"", ""zero-sum Markov Game""]",We provide a characterization of the sample complexity of Q-learning and minimax Q-learning with deep neural networks,,,,
SJlNnhVYDr,2020,Reject,False,Soft Token Matching for Interpretable Low-Resource Classification,"[""Federico Errica"", ""Fabrizio Silvestri"", ""Bora Edizel"", ""Sebastian Riedel"", ""Ludovic Denoyer"", ""Vassilis Plachouras""]","[""low-resource classification"", ""semantic matching"", ""error boosting"", ""text classification"", ""natural language processing""]","We propose a model to efficiently tackle low resource classification, which leverages additional information in the input to guide the learning process.",,,,
SJlOq34Kwr,2020,Reject,False,Unsupervised Intuitive Physics from Past Experiences,"[""Sebastien Ehrhardt"", ""Aron Monszpart"", ""Niloy Mitra"", ""Andrea Vedaldi""]","[""Intuitive physics"", ""Deep learning""]",,,,,
SJlPOCEKvH,2020,Reject,False,Compressing BERT: Studying the Effects of Weight Pruning on Transfer Learning,"[""Mitchell A Gordon"", ""Kevin Duh"", ""Nicholas Andrews""]","[""compression"", ""pruning"", ""pre-training"", ""BERT"", ""language modeling"", ""transfer learning"", ""ML"", ""NLP""]",,,,,
SJlRDCVtwr,2020,Reject,False,Simplicial Complex Networks,"[""Mohammad Firouzi"", ""Sadra Boreiri"", ""Hamed Firouzi""]","[""topological data analysis"", ""supervised learning"", ""simplicial approximation""]",A novel method for supervised learning through subdivisioning the input space along with function approximation.,,,,
SJlRF04YwB,2020,Reject,False,Generating Semantic Adversarial Examples with Differentiable Rendering,"[""Lakshya Jain"", ""Steven Chen"", ""Wilson Wu"", ""Uyeong Jang"", ""Varun Chandrasekaran"", ""Sanjit Seshia"", ""Somesh Jha""]","[""semantic adversarial examples"", ""inverse graphics"", ""differentiable rendering""]",Generating Semantic Adversarial Examples with Differentiable Rendering,,,,
SJlRUkrFPS,2020,Accept (Poster),True,Learning transport cost from subset correspondence,"[""Ruishan Liu"", ""Akshay Balsubramani"", ""James Zou""]",[],,1909.13203,cs.LG,2019-09-29 05:28:28+00:00,2021-07-30 23:15:20+00:00
SJlRWC4FDB,2020,Reject,True,Adversarial Attacks on Copyright Detection Systems,"[""Parsa Saadatpanah"", ""Ali Shafahi"", ""Tom Goldstein""]",[],Adversarial examples can fool YouTube's copyright detection system,1906.07153,cs.LG,2019-06-17 17:57:04+00:00,2019-06-20 17:44:20+00:00
SJlVVAEKwS,2020,Reject,False,Adversarial Imitation Attack,"[""Mingyi Zhou"", ""Jing Wu"", ""Yipeng Liu"", ""Xiaolin Huang"", ""Shuaicheng Liu"", ""Liaqat Ali"", ""Xiang Zhang"", ""Ce Zhu""]","[""Adversarial examples"", ""Security"", ""Machine learning"", ""Deep neural network"", ""Computer vision""]",A novel adversarial imitation attack to fool machine learning models.,,,,
SJlVY04FwH,2020,Accept (Poster),True,Convergence of Gradient Methods on Bilinear Zero-Sum Games,"[""Guojun Zhang"", ""Yaoliang Yu""]","[""GAN"", ""gradient algorithm"", ""convergence"", ""min-max optimization"", ""bilinear game""]","We systematically analyze the convergence of popular gradient algorithms for solving bilinear games, with both simultaneous and alternating updates.",1908.05699,cs.LG,2019-08-15 18:27:14+00:00,2020-03-03 21:10:54+00:00
SJlVn6NKPB,2020,Reject,False,Representation Learning for Remote Sensing: An Unsupervised Sensor Fusion Approach,"[""Aidan M. Swope"", ""Xander H. Rudelis"", ""Kyle T. Story""]","[""unsupervised learning"", ""representation learning"", ""deep learning"", ""remote sensing"", ""sensor fusion""]",Multiple sensor views imply a self-supervised task for learning what things are in aerial imagery without labels,,,,
SJlWyerFPS,2020,Reject,False,DeepXML: Scalable & Accurate Deep Extreme Classification for Matching User Queries to Advertiser Bid Phrases,"[""Kunal Dahiya"", ""Anshul Mittal"", ""Deepak Saini"", ""Kushal Dave"", ""Himanshu Jain"", ""Sumeet Agarwal"", ""Manik Varma""]","[""extreme multi label learning"", ""extreme classification"", ""deep extreme multi label learning"", ""deep extreme classification"", ""large output space""]",Scalable and accurate deep multi label learning with millions of labels.,,,,
SJlYqRNKDS,2020,Reject,True,Blockwise Adaptivity:  Faster Training and Better Generalization in Deep Learning,"[""Shuai Zheng"", ""James T. Kwok""]","[""optimization"", ""deep learning"", ""blockwise adaptivity""]",We propose a blockwise adaptive gradient descent method that enjoys faster convergence and better generalization than its coordinate-wise counterpart.,1905.09899,cs.LG,2019-05-23 20:06:10+00:00,2019-05-23 20:06:10+00:00
SJlbGJrtDB,2020,Accept (Poster),False,Dynamic Sparse Training: Find Efficient Sparse Network From Scratch With Trainable Masked Layers,"[""Junjie LIU"", ""Zhe XU"", ""Runbin SHI"", ""Ray C. C. Cheung"", ""Hayden K.H. So""]","[""neural network pruning"", ""sparse learning"", ""network compression"", ""architecture search""]",We present a novel network pruning method that can find the optimal sparse structure during the training process with trainable pruning threshold,,,,
SJlbvp4YvS,2020,Reject,False,Risk Averse Value Expansion for Sample Efficient and Robust Policy Learning,"[""Bo Zhou"", ""Fan Wang"", ""Hongsheng Zeng"", ""Hao Tian""]","[""reinforcement learning"", ""model-based RL"", ""risk-sensitive"", ""sample efficiency""]",We extend the model-based value expansion methods with risk-averse learning and achieve state-of-the-art results on challenging continuous control benchmarks.,,,,
SJlbyCNtPr,2020,Reject,False,"Long-term planning, short-term adjustments","[""Hamed Khorasgani"", ""Chi Zhang"", ""Chetan Gupta"", ""Susumu Serita""]","[""Deep Reinforcement Learning"", ""Control""]",This paper proposes a new deep reinforcement learning algorithm that can be easily adjusted to achieve new short-term goals without retraining the network. ,,,,
SJldZ2RqFX,2019,Reject,False,D-GAN: Divergent generative adversarial network for positive unlabeled learning and counter-examples generation,"[""Florent CHIARONI. Mohamed-Cherif RAHAL. Nicolas HUEBER. Fr\u00e9d\u00e9ric DUFAUX.""]","[""Representation learning. Generative Adversarial Network (GAN). Positive Unlabeled learning. Image classification""]",A new two-stage positive unlabeled learning approach with GAN,,,,
SJldu6EtDS,2020,Reject,False,Wasserstein Adversarial Regularization (WAR) on label noise,"[""Bharath Damodaran"", ""Kilian Fatras"", ""Sylvain Lobry"", ""R\u00e9mi Flamary"", ""Devis Tuia"", ""Nicolas Courty""]","[""Label Noise"", ""Adversarial regularization"", ""Wasserstein""]",We present a novel method for handling label noise through an adversarial regularization incorporating a Wasserstein distance,,,,
SJleNCNtDH,2020,Accept (Poster),False,Intrinsic Motivation for Encouraging Synergistic Behavior,"[""Rohan Chitnis"", ""Shubham Tulsiani"", ""Saurabh Gupta"", ""Abhinav Gupta""]","[""reinforcement learning"", ""intrinsic motivation"", ""synergistic"", ""robot manipulation""]","We propose a formulation of intrinsic motivation that is suitable as an exploration bias in synergistic multi-agent tasks, by encouraging agents to affect the world in ways that would not be achieved if they were acting individually.",2002.05189,cs.LG,2020-02-12 19:34:51+00:00,2020-02-12 19:34:51+00:00
SJlgOjAqYQ,2019,Reject,False,A quantifiable testing of global translational invariance in Convolutional and Capsule Networks,"[""Weikai Qi""]","[""Translational invariance"", ""CNN"", ""Capsule Network""]",Testing of global translational invariance in Convolutional and Capsule Networks,,,,
SJlgTJHKwB,2020,Reject,False,Continual Learning with Delayed Feedback,"[""THEIVENDIRAM PRANAVAN"", ""TERENCE SIM""]",[],,,,,
SJlh2jR9FX,2019,Reject,False,Learning with Reflective Likelihoods,"[""Adji B. Dieng"", ""Kyunghyun Cho"", ""David M. Blei"", ""Yann LeCun""]","[""new learning criterion"", ""penalized maximum likelihood"", ""posterior inference in deep generative models"", ""input forgetting issue"", ""latent variable collapse issue""]","Training deep probabilistic models with maximum likelihood often leads to ""input forgetting"". We identify a potential cause and propose a new learning criterion to alleviate the issue.",,,,
SJlh8CEYDB,2020,Accept (Poster),True,Learn to Explain Efficiently via Neural Logic Inductive Learning,"[""Yuan Yang"", ""Le Song""]","[""inductive logic programming"", ""interpretability"", ""attention""]",An efficient differentiable ILP model that learns first-order logic rules that can explain the data.,1910.02481,cs.AI,2019-10-06 17:20:31+00:00,2020-02-18 19:01:05+00:00
SJlhPMWAW,2018,Reject,False,GraphVAE: Towards Generation of Small Graphs Using Variational Autoencoders,"[""Martin Simonovsky"", ""Nikos Komodakis""]","[""graph"", ""generative model"", ""autoencoder""]",We demonstate an autoencoder for graphs.,,,,
SJloA0EYDr,2020,Reject,False,AâMCTS: SEARCH WITH THEORETICAL GUARANTEE USING POLICY AND VALUE FUNCTIONS,"[""Xian Wu"", ""Yuandong Tian"", ""Lexing Ying""]","[""tree search"", ""reinforcement learning"", ""value neural network"", ""policy neural network""]",theoretical and experimental results for novel tree search algorithm that efficiently finds optimal policy,,,,
SJlpM3RqKQ,2019,Reject,False,Expanding the Reach of Federated Learning by Reducing Client Resource Requirements,"[""Sebastian Caldas"", ""Jakub Kone\u010dn\u00fd"", ""Brendan McMahan"", ""Ameet Talwalkar""]",[],,,,,
SJlpYJBKvH,2020,Accept (Spotlight),False,Measuring the Reliability of Reinforcement Learning Algorithms,"[""Stephanie C.Y. Chan"", ""Samuel Fishman"", ""Anoop Korattikara"", ""John Canny"", ""Sergio Guadarrama""]","[""reinforcement learning"", ""metrics"", ""statistics"", ""reliability""]",A novel set of metrics for measuring reliability of reinforcement learning algorithms (+ accompanying statistical tests),,,,
SJlpy64tvB,2020,Reject,False,Attacking Lifelong Learning Models with Gradient Reversion,"[""Yunhui Guo"", ""Mingrui Liu"", ""Yandong Li"", ""Liqiang Wang"", ""Tianbao Yang"", ""Tajana Rosing""]","[""lifelong learning"", ""adversarial learning""]",Extensive evaluation of the robustness of episodic lifelong learning algorithm under traditional adversarial attacks and the proposed gradient reversion attack. ,,,,
SJlsFpVtDB,2020,Accept (Poster),False,Continual Learning with Bayesian Neural Networks for Non-Stationary Data,"[""Richard Kurle"", ""Botond Cseke"", ""Alexej Klushyn"", ""Patrick van der Smagt"", ""Stephan G\u00fcnnemann""]","[""Continual Learning"", ""Online Variational Bayes"", ""Non-Stationary Data"", ""Bayesian Neural Networks"", ""Variational Inference"", ""Lifelong Learning"", ""Concept Drift"", ""Episodic Memory""]","This work addresses continual learning for non-stationary data, using Bayesian neural networks and memory-based online variational Bayes.",,,,
SJlt6oA9Fm,2019,Reject,False,Selective Convolutional Units: Improving CNNs via Channel Selectivity,"[""Jongheon Jeong"", ""Jinwoo Shin""]","[""convolutional neural networks"", ""channel-selectivity"", ""channel re-wiring"", ""bottleneck architectures"", ""deep learning""]","We propose a new module that improves any ResNet-like architectures by enforcing ""channel selective"" behavior to convolutional layers",,,,
SJlxglSFPB,2020,Reject,False,Efficacy of Pixel-Level OOD Detection for Semantic Segmentation,"[""Matt Angus"", ""Krzysztof Czarnecki"", ""Rick Salay""]","[""Out-of-Distribution Detection"", ""Semantic Segmentation"", ""Deep Learning""]",Evaluating pixel-level out-of-distribution detection methods on two new real world datasets using PSPNet and DeeplabV3+.,1911.02897,cs.CV,2019-11-07 13:37:38+00:00,2019-11-07 13:37:38+00:00
SJlyta4YPS,2020,Reject,False,DeepEnFM: Deep neural networks with Encoder enhanced Factorization Machine,"[""Qiang Sun"", ""Zhinan Cheng"", ""Yanwei Fu"", ""Wenxuan Wang"", ""Yu-Gang Jiang"", ""Xiangyang Xue""]","[""CTR"", ""Attention"", ""Transformer"", ""Encoder""]",DNN and Encoder enhanced FM with bilinear attention and max-pooling for CTR,,,,
SJmAXkgCb,2018,Reject,False,DNN Feature Map Compression using Learned Representation over GF(2),"[""Denis A. Gudovskiy"", ""Alec Hodgkinson"", ""Luca Rigazio""]","[""feature map"", ""representation"", ""compression"", ""quantization"", ""finite-field""]",Feature map compression method that converts quantized activations into binary vectors followed by nonlinear dimensionality reduction layers embedded into a DNN,,,,
SJme6-ZR-,2018,Reject,False,A Deep Learning Approach for Survival Clustering without End-of-life Signals,"[""S Chandra Mouli"", ""Bruno Ribeiro"", ""Jennifer Neville""]","[""Survival Analysis"", ""Kuiper statistics"", ""model-free""]","The goal of survival clustering is to map subjects into clusters. Without end-of-life signals, this is a challenging task. To address this task we propose a new loss function by modifying the Kuiper statistics.",,,,
SJn0sLgRb,2018,Reject,False,Data Augmentation by Pairing Samples for Images Classification,"[""Hiroshi Inoue""]","[""Data augmentation"", ""Image classification""]",,,,,
SJqaCVLxx,2017,Reject,False,New Learning Approach By Genetic Algorithm In A Convolutional Neural Network For Pattern Recognition,"[""Mohammad Ali Mehrolhassani"", ""Majid Mohammadi""]","[""Deep learning"", ""Supervised Learning"", ""Optimization"", ""Computer vision""]",Implement new approach without exerting backpropagation in learning of CNN is useful for parallel processing Like GPU.,,,,
SJtChcgAW,2018,Reject,False,Cheap DNN Pruning with Performance Guarantees ,"[""Konstantinos Pitas"", ""Mike Davies"", ""Pierre Vandergheynst""]","[""pruning"", ""generalisation error"", ""DC optimisation""]",A fast pruning algorithm for fully connected DNN layers with theoretical analysis of degradation in Generalisation Error.,,,,
SJtfOEn6-,2018,Reject,False,ResBinNet: Residual Binary Neural Network,"[""Mohammad Ghasemzadeh"", ""Mohammad Samragh"", ""Farinaz Koushanfar""]","[""Binary Neural Networks"", ""Residual Binarization"", ""Deep Learning""]",Residual Binary Neural Networks significantly improve the convergence rate and inference accuracy of the binary neural networks.,,,,
SJttqw5ge,2017,Reject,False,Communicating Hierarchical Neural Controllers for Learning Zero-shot Task Generalization,"[""Junhyuk Oh"", ""Satinder Singh"", ""Honglak Lee"", ""Pushmeet Kohli""]","[""Reinforcement Learning"", ""Deep learning""]",,,,,
SJu63o10b,2018,Reject,False,UNSUPERVISED METRIC LEARNING VIA NONLINEAR FEATURE SPACE TRANSFORMATIONS,"[""Pin Zhang"", ""Bibo Shi"", ""JundongLiu""]","[""Metric Learning"", ""K-means"", ""CPD"", ""Clustering""]", a nonlinear unsupervised metric learning framework to boost the performance of clustering algorithms.,,,,
SJvYgH9xe,2017,Accept (Poster),False,Automatic Rule Extraction from Long Short Term Memory Networks,"[""W. James Murdoch"", ""Arthur Szlam""]","[""Natural language processing"", ""Deep learning"", ""Applications""]","We introduce a word importance score for LSTMs, and show that we can use it to replicate an LSTM's performance using a simple, rules-based classifier.",,,,
SJvrXqvaZ,2018,Reject,False,Adversary A3C for Robust Reinforcement Learning,"[""Zhaoyuan Gu"", ""Zhenzhong Jia"", ""Howie Choset""]","[""Adversary"", ""Robust"", ""Reinforcement Learning"", ""A3C""]",,,,,
SJvu-GW0b,2018,Reject,False,Graph2Seq: Scalable Learning Dynamics for Graphs,"[""Shaileshh Bojja Venkatakrishnan"", ""Mohammad Alizadeh"", ""Pramod Viswanath""]",[],,,,,
SJw03ceRW,2018,Reject,False,GENERATIVE LOW-SHOT NETWORK EXPANSION,"[""Adi Hayat"", ""Mark Kliger"", ""Shachar Fleishman"", ""Daniel Cohen-Or""]","[""Low-Shot Learning"", ""class incremental learning"", ""Network expansion"", ""Generative model"", ""Distillation""]"," In this paper, we address the problem of Low-shot network-expansion learning",,,,
SJx-j64FDr,2020,Accept (Poster),False,In Search for a SAT-friendly Binarized Neural Network Architecture,"[""Nina Narodytska"", ""Hongce Zhang"", ""Aarti Gupta"", ""Toby Walsh""]","[""verification"", ""Boolean satisfiability"", ""Binarized Neural Networks""]",Formal analysis of  Binarized Neural Networks ,,,,
SJx0PAEFDS,2020,Reject,False,Underwhelming Generalization Improvements From Controlling Feature Attribution,"[""Joseph D Viviano"", ""Becks Simpson"", ""Francis Dutil"", ""Yoshua Bengio"", ""Joseph Paul Cohen""]","[""interpretability"", ""medical"", ""generalization"", ""saliency""]","There is hope that one can diagnose and fix overfitting in classifiers by studying and guiding their saliency maps, but we developed multiple methods to do this well and only see a minor positive effect on generalization.",,,,
SJx0oAEYwH,2020,Reject,False,Cover Filtration and Stable Paths in the Mapper,"[""Dustin L. Arendt"", ""Matthew Broussard"", ""Bala Krishnamoorthy"", ""Nathaniel Saul""]","[""cover and nerve"", ""Jaccard distance"", ""stable paths in filtration"", ""Mapper"", ""recommender systems"", ""explainable machine learning""]","A new filtration from a SINGLE cover, with applications to movie recommendations and explainable machine learning",,,,
SJx0q1rtvS,2020,Accept (Poster),False,Robust anomaly detection and backdoor attack detection via differential privacy,"[""Min Du"", ""Ruoxi Jia"", ""Dawn Song""]","[""outlier detection"", ""novelty detection"", ""backdoor attack detection"", ""system log anomaly detection"", ""differential privacy""]","This paper shows that differential privacy could improve the utility of outlier detection, novelty detection and backdoor attack detection, through both a theoretical analysis and extensive experimental results (constructed and real-world).",1911.07116,cs.LG,2019-11-16 23:32:20+00:00,2019-11-16 23:32:20+00:00
SJx1URNKwH,2020,Accept (Poster),True,MetaPix: Few-Shot Video Retargeting,"[""Jessica Lee"", ""Deva Ramanan"", ""Rohit Girdhar""]","[""Meta-learning"", ""Few-shot Learning"", ""Generative Adversarial Networks"", ""Video Retargeting""]","Video retargeting typically requires large amount of target data to be effective, which may not always be available; we propose a metalearning approach that improves over popular baselines while producing temporally coherent frames.",1910.04742,cs.CV,2019-10-10 17:51:44+00:00,2020-03-24 21:09:45+00:00
SJx37TEtDH,2020,Reject,False,Why ADAM Beats SGD for Attention Models	,"[""Jingzhao Zhang"", ""Sai Praneeth Karimireddy"", ""Andreas Veit"", ""Seungyeon Kim"", ""Sashank J Reddi"", ""Sanjiv Kumar"", ""Suvrit Sra""]","[""Optimization"", ""ADAM"", ""Deep learning""]",Adaptive methods provably beat SGD in training attention models due to existence of heavy tailed noise.,1912.03194,math.OC,2019-12-06 15:58:29+00:00,2020-10-23 08:07:04+00:00
SJx4O34YvS,2020,Reject,True,Semantics Preserving Adversarial Attacks,"[""Ousmane Amadou Dia"", ""Elnaz Barshan"", ""Reza Babanezhad""]","[""black-box adversarial attacks"", ""stein variational inference"", ""adversarial images and tex""]",Generating semantically meaningful adversarial examples beyond simple norm balls in an efficient and effective way using generative models.,1903.03905,stat.ML,2019-03-10 02:48:46+00:00,2019-12-21 13:02:43+00:00
SJx4Ogrtvr,2020,Reject,False,Random Bias Initialization Improving Binary Neural Network Training,"[""Xinlin Li"", ""Vahid Partovi Nia""]","[""Binarized Neural Network"", ""Activation function"", ""Initialization"", ""Neural Network Acceleration""]","Improve saturating activations (sigmoid, tanh, htanh etc.) and Binarized Neural Network with Bias Initialization",,,,
SJx5kn0cK7,2019,Reject,False,HAPPIER: Hierarchical Polyphonic Music Generative RNN,"[""Tianyang Zhao"", ""Xiaoxuan Ma"", ""Honglin Ma"", ""Yizhou Wang""]","[""hierarchical model"", ""RNN"", ""generative model"", ""automatic composing""]",,,,,
SJx63jRqFm,2019,Accept (Poster),True,Diversity is All You Need: Learning Skills without a Reward Function,"[""Benjamin Eysenbach"", ""Abhishek Gupta"", ""Julian Ibarz"", ""Sergey Levine""]","[""reinforcement learning"", ""unsupervised learning"", ""skill discovery""]","We propose an algorithm for learning useful skills without a reward function, and show how these skills can be used to solve downstream tasks.",1802.06070,cs.AI,2018-02-16 18:57:57+00:00,2018-10-09 23:19:52+00:00
SJx7Jrtgl,2017,Reject,False,Deep Unsupervised Clustering with Gaussian Mixture Variational Autoencoders,"[""Nat Dilokthanakul"", ""Pedro A. M. Mediano"", ""Marta Garnelo"", ""Matthew C.H. Lee"", ""Hugh Salimbeni"", ""Kai Arulkumaran"", ""Murray Shanahan""]","[""Unsupervised Learning"", ""Deep learning""]",We study a variant of the variational autoencoder model with a Gaussian mixture as prior distribution and discuss its optimization difficulties and capabilities for unsupervised clustering.,,,,
SJx94o0qYX,2019,Reject,False,Precision Highway for Ultra Low-precision Quantization,"[""Eunhyeok Park"", ""Dongyoung Kim"", ""Sungjoo Yoo"", ""Peter Vajda""]","[""neural network"", ""quantization"", ""optimization"", ""low-precision"", ""convolutional network"", ""recurrent network""]",precision highway; a generalized concept of high-precision information flow for sub 4-bit quantization ,,,,
SJx9GQb0-,2018,Accept (Poster),False,Improving the Improved Training of Wasserstein GANs: A Consistency Term and Its Dual Effect,"[""Xiang Wei"", ""Boqing Gong"", ""Zixia Liu"", ""Wei Lu"", ""Liqiang Wang""]","[""GAN"", ""WGAN""]",,,,,
SJx9ngStPH,2020,Accept (Poster),False,NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search,"[""Arber Zela"", ""Julien Siems"", ""Frank Hutter""]","[""Neural Architecture Search"", ""Deep Learning"", ""Computer Vision""]",,2001.10422,cs.LG,2020-01-28 15:50:22+00:00,2020-04-12 22:48:28+00:00
SJxAlgrYDr,2020,Reject,False,City Metro Network Expansion with Reinforcement Learning,"[""Yu Wei"", ""Minjia Mao"", ""Xi Zhao"", ""Jianhua Zou""]",[],,,,,
SJxCsj0qYX,2019,Reject,False,Stackelberg GAN: Towards Provable Minimax Equilibrium via Multi-Generator Architectures,"[""Hongyang Zhang"", ""Susu Xu"", ""Jiantao Jiao"", ""Pengtao Xie"", ""Ruslan Salakhutdinov"", ""Eric P. Xing""]","[""generative adversarial nets"", ""minimax duality gap"", ""equilibrium""]","We study the problem of alleviating the instability issue in the GAN training procedure via new architecture design, with theoretical guarantees.",,,,
SJxDDpEKvH,2020,Accept (Poster),True,Counterfactuals uncover the modular structure of deep generative models,"[""Michel Besserve"", ""Arash Mehrjou"", ""R\u00e9my Sun"", ""Bernhard Sch\u00f6lkopf""]","[""generative models"", ""causality"", ""counterfactuals"", ""representation learning"", ""disentanglement"", ""generalization"", ""unsupervised learning""]",We develop a framework to find modular internal representations in generative models and manipulate then to generate counterfactual examples.,1812.03253,cs.LG,2018-12-08 01:57:27+00:00,2019-12-12 13:50:30+00:00
SJxDKerKDS,2020,Reject,False,Reinforcement Learning with Structured Hierarchical Grammar Representations of Actions,"[""Petros Christodoulou"", ""Robert Lange"", ""Ali Shafti"", ""A. Aldo Faisal""]","[""Hierarchical Reinforcement Learning"", ""Action Representations"", ""Macro-Actions"", ""Action Grammars""]","We use grammar inference techniques to compose primitive actions into temporal abstractions, creating a hierarchical reinforcement learning structure that consistently improves sample efficiency.",,,,
SJxE3jlA-,2018,Reject,False,Now I Remember! Episodic Memory For Reinforcement Learning,"[""Ricky Loynd"", ""Matthew Hausknecht"", ""Lihong Li"", ""Li Deng""]","[""Reinforcement learning"", ""Deep learning"", ""Episodic memory""]",Implementing and evaluating episodic memory for RL.,,,,
SJxE8erKDH,2020,Accept (Poster),False,Latent Normalizing Flows for Many-to-Many Cross-Domain Mappings,"[""Shweta Mahajan"", ""Iryna Gurevych"", ""Stefan Roth""]",[],,2002.06661,cs.CV,2020-02-16 19:49:30+00:00,2020-02-16 19:49:30+00:00
SJxFN3RcFX,2019,Reject,False,Functional Bayesian Neural Networks for Model Uncertainty Quantification,"[""Nanyang Ye"", ""Zhanxing Zhu""]",[],,,,,
SJxFWRVKDr,2020,Reject,False,Characterizing Missing Information in Deep Networks Using Backpropagated Gradients,"[""Gukyeong Kwon"", ""Mohit Prabhushankar"", ""Dogancan Temel"", ""Ghassan AlRegib""]","[""Representation learning"", ""Missing Information in Deep Networks"", ""Gradient-based Representation""]",We propose a gradient-based representation for characterizing information that deep networks have not learned.,,,,
SJxHMaEtwB,2020,Reject,True,Domain-invariant Learning using Adaptive Filter Decomposition,"[""Ze Wang"", ""Xiuyuan Cheng"", ""Guillermo Sapiro"", ""Qiang Qiu""]",[],,1909.11285,cs.LG,2019-09-25 04:35:04+00:00,2020-09-28 23:31:44+00:00
SJxIkkSKwB,2020,Reject,True,Learning in Confusion: Batch Active Learning with Noisy Oracle,"[""Gaurav Gupta"", ""Anit Kumar Sahu"", ""Wan-Yi Lin""]","[""Active Learning"", ""Noisy Oracle"", ""Model Uncertainty"", ""Image classification""]",We address the active learning in batch setting with noisy oracles and use model uncertainty to encode the decision quality of active learning algorithm during acquisition.,1909.12473,cs.LG,2019-09-27 02:33:30+00:00,2020-10-28 21:00:27+00:00
SJxIm0VtwH,2020,Accept (Poster),False,Towards Better Understanding of Adaptive Gradient Algorithms in Generative Adversarial Nets,"[""Mingrui Liu"", ""Youssef Mroueh"", ""Jerret Ross"", ""Wei Zhang"", ""Xiaodong Cui"", ""Payel Das"", ""Tianbao Yang""]","[""Generative Adversarial Nets"", ""Adaptive Gradient Algorithms""]","This paper provides novel analysis of adaptive gradient algorithms for solving non-convex non-concave min-max problems as GANs, and explains the reason why adaptive gradient methods outperform its non-adaptive counterparts by empirical studies.",1912.11940,math.OC,2019-12-26 22:10:10+00:00,2020-12-25 02:17:20+00:00
SJxJtiRqt7,2019,Reject,False,Generating Images from Sounds Using Multimodal Features and GANs,"[""Jeonghyun Lyu"", ""Takashi Shinozaki"", ""Kaoru Amano""]","[""deep learning"", ""machine learning"", ""multimodal"", ""generative adversarial networks""]",We propose a method of converting from the sound domain into the image domain based on multimodal features and stacked GANs.,,,,
SJxNzgSKvH,2020,Reject,False,Selective sampling for accelerating  training of deep neural networks,"[""Berry Weinstein"", ""Shai Fine"", ""Yacov Hel-Or""]",[],,1911.06996,cs.LG,2019-11-16 08:49:13+00:00,2019-11-16 08:49:13+00:00
SJxRKT4Fwr,2020,Reject,False,"Cross-Dimensional Self-Attention for Multivariate, Geo-tagged Time Series Imputation","[""Jiawei Ma*"", ""Zheng Shou*"", ""Alireza Zareian"", ""Hassan Mansour"", ""Anthony Vetro"", ""Shih-Fu Chang""]","[""self-attention"", ""cross-dimensional"", ""multivariate time series"", ""imputation""]","A novel self-attention mechanism for multivariate, geo-tagged time series imputation.",,,,
SJxSDxrKDr,2020,Accept (Talk),False,Adversarial Training and Provable Defenses: Bridging the Gap,"[""Mislav Balunovic"", ""Martin Vechev""]","[""adversarial examples"", ""adversarial training"", ""provable defense"", ""convex relaxations"", ""deep learning""]",We propose a novel combination of adversarial training and provable defenses which produces a model with state-of-the-art accuracy and certified robustness on CIFAR-10. ,,,,
SJxSOJStPr,2020,Accept (Poster),False,A Neural Dirichlet Process Mixture Model for Task-Free Continual Learning,"[""Soochan Lee"", ""Junsoo Ha"", ""Dongsu Zhang"", ""Gunhee Kim""]","[""continual learning"", ""task-free"", ""task-agnostic""]",We propose an expansion-based approach for task-free continual learning for the first time. Our model consists of a set of neural network experts and expands the number of experts under the Bayesian nonparametric principle.,2001.00689,cs.LG,2020-01-03 02:07:31+00:00,2020-01-14 23:32:01+00:00
SJxTZeHFPH,2020,Reject,False,The Intriguing Effects of Focal Loss on the Calibration of Deep Neural Networks,"[""Jishnu Mukhoti"", ""Viveka Kulharia"", ""Amartya Sanyal"", ""Stuart Golodetz"", ""Philip Torr"", ""Puneet Dokania""]",[],,,,,
SJxTroR9F7,2019,Accept (Poster),False,Supervised Policy Update for Deep Reinforcement Learning,"[""Quan Vuong"", ""Yiming Zhang"", ""Keith W. Ross""]","[""Deep Reinforcement Learning""]","first posing and solving the sample efficiency optimization problem in the non-parameterized policy space, and then solving a supervised regression problem to find a parameterized policy that is near the optimal non-parameterized policy.",,,,
SJxUjlBtwB,2020,Accept (Spotlight),True,Reconstructing continuous distributions of 3D protein structure from cryo-EM images,"[""Ellen D. Zhong"", ""Tristan Bepler"", ""Joseph H. Davis"", ""Bonnie Berger""]","[""generative models"", ""proteins"", ""3D reconstruction"", ""cryo-EM""]",We propose a deep generative model of volumes for 3D cryo-EM reconstruction from unlabelled 2D images and show that it can learn can learn continuous deformations in protein structure.,1909.05215,q-bio.QM,2019-09-11 17:13:06+00:00,2020-02-15 04:31:46+00:00
SJxWS64FwH,2020,Accept (Poster),False,Deep Network Classification by Scattering and Homotopy Dictionary Learning,"[""John Zarka"", ""Louis Thiry"", ""Tomas Angles"", ""Stephane Mallat""]","[""dictionary learning"", ""scattering transform"", ""sparse coding"", ""imagenet""]",A scattering transform followed by supervised dictionary learning reaches a higher accuracy than AlexNet on ImageNet.,,,,
SJxZnR4YvB,2020,Accept (Poster),True,Distributed Bandit Learning: Near-Optimal Regret with Efficient Communication,"[""Yuanhao Wang"", ""Jiachen Hu"", ""Xiaoyu Chen"", ""Liwei Wang""]","[""Theory"", ""Bandit Algorithms"", ""Communication Efficiency""]",,1904.06309,cs.LG,2019-04-12 16:32:17+00:00,2019-05-29 02:05:10+00:00
SJx_QJHYDB,2020,Reject,False,Finding Winning Tickets with Limited (or No) Supervision,"[""Mathilde Caron"", ""Ari Morcos"", ""Piotr Bojanowski"", ""Julien Mairal"", ""Armand Joulin""]","[""Lottery Tickets Hypothesis"", ""Self-Supervised Learning"", ""Deep Learning"", ""Image Recognition""]",Finding winning tickets does not require much supervision or data.,,,,
SJxbHkrKDH,2020,Accept (Poster),False,Evolutionary Population Curriculum for Scaling Multi-Agent Reinforcement Learning,"[""Qian Long*"", ""Zihan Zhou*"", ""Abhinav Gupta"", ""Fei Fang"", ""Yi Wu\u2020"", ""Xiaolong Wang\u2020""]","[""multi-agent reinforcement learning"", ""evolutionary learning"", ""curriculum learning""]",,,,,
SJxeI6EYwS,2020,Reject,False,Simple and Effective Stochastic Neural Networks,"[""Tianyuan Yu"", ""Yongxin Yang"", ""Da Li"", ""Timothy Hospedales"", ""Tao Xiang""]","[""stochastic neural networks"", ""pruning"", ""adversarial defence"", ""label noise""]",In this paper we propose a simple and effective stochastic neural network (SE-SNN) architecture for discriminative learning by directly modeling activation uncertainty and encouraging high activation variability.,,,,
SJxfxnA9K7,2019,Reject,False,Structured Prediction using cGANs with Fusion Discriminator,"[""Faisal Mahmood"", ""Wenhao Xu"", ""Nicholas J. Durr"", ""Jeremiah W. Johnson"", ""Alan Yuille""]","[""Generative Adversarial Networks"", ""GANs"", ""conditional GANs"", ""Discriminator"", ""Fusion""]",We propose a novel way to incorporate conditional image information into the discriminator of GANs using feature fusion that can be used for structured prediction tasks.,,,,
SJxhNTNYwB,2020,Accept (Poster),False,Black-Box Adversarial Attack with Transferable Model-based Embedding,"[""Zhichao Huang"", ""Tong Zhang""]","[""adversarial examples"", ""black-box attack"", ""embedding""]","We present a new method that combines transfer-based and scored black-box adversarial attack, improving the success rate and query efficiency of black-box adversarial attack across different network architectures.",1911.07140,cs.LG,2019-11-17 03:10:49+00:00,2020-01-05 12:39:05+00:00
SJxjPxSYDH,2020,Reject,False,Discriminative Variational Autoencoder for Continual Learning with Generative Replay,"[""Woo-Young Kang"", ""Cheol-Ho Han"", ""Byoung-Tak Zhang""]","[""Continual learning"", ""Generative replay"", ""Variational Autoencoder""]",,,,,
SJxmfgSYDB,2020,Reject,False,Representing Unordered Data Using Multiset Automata and Complex Numbers,"[""Justin DeBenedetto"", ""David Chiang""]","[""sets"", ""multisets"", ""automata"", ""complex numbers"", ""position encodings""]",Automata for multisets and complex numbers give a new way of thinking about DeepSets and Transformer position encodings.,2001.00610,cs.FL,2020-01-02 20:04:45+00:00,2020-08-28 14:11:26+00:00
SJxpsxrYPS,2020,Accept (Spotlight),False,PROGRESSIVE LEARNING AND DISENTANGLEMENT OF HIERARCHICAL REPRESENTATIONS,"[""Zhiyuan Li"", ""Jaideep Vitthal Murkute"", ""Prashnna Kumar Gyawali"", ""Linwei Wang""]","[""generative model"", ""disentanglement"", ""progressive learning"", ""VAE""]",We proposed a progressive learning method to improve learning and disentangling latent representations at different levels of abstraction.,2002.10549,cs.LG,2020-02-24 21:19:38+00:00,2020-02-24 21:19:38+00:00
SJxrKgStDH,2020,Accept (Poster),False,SCALOR: Generative World Models with Scalable Object Representations,"[""Jindong Jiang*"", ""Sepehr Janghorbani*"", ""Gerard De Melo"", ""Sungjin Ahn""]",[],,,,,
SJxsV2R5FQ,2019,Accept (Poster),False,Learning sparse relational transition models,"[""Victoria Xia"", ""Zi Wang"", ""Kelsey Allen"", ""Tom Silver"", ""Leslie Pack Kaelbling""]","[""Deictic reference"", ""relational model"", ""rule-based transition model""]",A new approach that learns a representation for describing transition models in complex uncertaindomains using relational rules. ,,,,
SJxstlHFPH,2020,Accept (Talk),False,Differentiable Reasoning over a Virtual Knowledge Base,"[""Bhuwan Dhingra"", ""Manzil Zaheer"", ""Vidhisha Balachandran"", ""Graham Neubig"", ""Ruslan Salakhutdinov"", ""William W. Cohen""]","[""Question Answering"", ""Multi-Hop QA"", ""Deep Learning"", ""Knowledge Bases"", ""Information Extraction"", ""Data Structures for QA""]",Differentiable multi-hop access to a textual knowledge base of indexed contextual representations,2002.10640,cs.CL,2020-02-25 03:13:32+00:00,2020-02-25 03:13:32+00:00
SJxu5iR9KQ,2019,Accept (Poster),False,Learning to Schedule Communication in Multi-agent Reinforcement Learning,"[""Daewoo Kim"", ""Sangwoo Moon"", ""David Hostallero"", ""Wan Ju Kang"", ""Taeyoung Lee"", ""Kyunghwan Son"", ""Yung Yi""]","[""Multi agent reinforcement learning"", ""deep reinforcement learning"", ""Communication""]",,,,,
SJxy5A4twS,2020,Reject,False,Superbloom: Bloom filter meets Transformer,"[""John Anderson"", ""Qingqing Huang"", ""Walid Krichene"", ""Steffen Rendle"", ""Li Zhang""]","[""Bloom filter"", ""Transformer"", ""word pieces"", ""contextual embeddings""]",We apply Transformer on Bloom filter digests and show it achieves good quality.,2002.04723,cs.LG,2020-02-11 22:52:40+00:00,2020-02-11 22:52:40+00:00
SJxyCRVKvB,2020,Reject,False,Granger Causal Structure Reconstruction from Heterogeneous Multivariate Time Series,"[""Yunfei Chu"", ""Xiaowei Wang"", ""Chunyan Feng"", ""Jianxin Ma"", ""Jingren Zhou"", ""Hongxia Yang""]","[""causal inference"", ""Granger causality"", ""time series"", ""inductive"", ""LSTM"", ""attention""]",We propose a network architecture that inductively reconstructs Granger causality via a prototypical Granger causal attention mechanism.,,,,
SJxzFySKwH,2020,Accept (Poster),True,On the Equivalence between Positional Node Embeddings and Structural Graph Representations,"[""Balasubramaniam Srinivasan"", ""Bruno Ribeiro""]","[""Graph Neural Networks"", ""Structural Graph Representations"", ""Node Embeddings"", ""Relational Learning"", ""Invariant Theory"", ""Theory"", ""Deep Learning"", ""Representational Power"", ""Graph Isomorphism""]",We develop the foundations of a unifying theoretical framework connecting node embeddings and structural graph representations through invariant theory,1910.00452,cs.LG,2019-10-01 14:37:22+00:00,2020-09-22 01:08:22+00:00
SJxzPsAqFQ,2019,Reject,False,Multi-turn Dialogue Response Generation in an Adversarial Learning Framework,"[""Oluwatobi O. Olabiyi"", ""Alan Salimov"", ""Anish Khazane"", ""Erik T. Mueller""]","[""dialogue models"", ""adversarial networks"", ""dialogue generation""]",,,,,
SJyEH91A-,2018,Accept (Poster),False,Learning Wasserstein Embeddings,"[""Nicolas Courty"", ""R\u00e9mi Flamary"", ""M\u00e9lanie Ducoffe""]","[""Wasserstein distance"", ""metric embedding"", ""Siamese architecture""]",We show that it is possible to fastly approximate Wasserstein distances computation by finding an appropriate embedding where Euclidean distance emulates the Wasserstein distance,,,,
SJyVzQ-C-,2018,Accept (Poster),False,Fraternal Dropout,"[""Konrad Zolna"", ""Devansh Arpit"", ""Dendi Suhubdy"", ""Yoshua Bengio""]","[""fraternal dropout"", ""activity regularization"", ""recurrent neural networks"", ""RNN"", ""LSTM"", ""faster convergence""]",We propose to train two identical copies of an recurrent neural network (that share parameters) with different dropout masks while minimizing the difference between their (pre-softmax) predictions.,,,,
SJyfrl-0b,2018,Invite to Workshop Track,False,Fast Node Embeddings: Learning Ego-Centric Representations,"[""Tiago Pimentel"", ""Adriano Veloso"", ""Nivio Ziviani""]","[""Graph"", ""Node Embeddings"", ""Distributed Representations"", ""Learning Representations""]",A faster method for generating node embeddings that employs a number of permutations over a node's immediate neighborhood as context to generate its representation.,,,,
SJz1x20cFQ,2019,Accept (Poster),False,Hierarchical RL Using an Ensemble of Proprioceptive Periodic Policies,"[""Kenneth Marino"", ""Abhinav Gupta"", ""Rob Fergus"", ""Arthur Szlam""]",[],,,,,
SJz6MnC5YQ,2019,Reject,True,DEEP GRAPH TRANSLATION,"[""Xiaojie Guo"", ""Lingfei Wu"", ""Liang Zhao""]",[],,1805.09980,cs.LG,2018-05-25 04:56:07+00:00,2018-06-22 16:06:37+00:00
SJzCSf9xg,2017,Accept (Poster),False,On Detecting Adversarial Perturbations,"[""Jan Hendrik Metzen"", ""Tim Genewein"", ""Volker Fischer"", ""Bastian Bischoff""]","[""Computer vision"", ""Deep learning"", ""Supervised Learning""]",We present and evaluate an approach for detecting adversarial perturbations in images based on attaching a small subnetwork to a deep neural network that is trained specifically to detect adversarial perturbations.,,,,
SJzMATlAZ,2018,Reject,False,Deep Continuous Clustering,"[""Sohil Atul Shah"", ""Vladlen Koltun""]","[""clustering"", ""dimensionality reduction""]",A clustering algorithm that performs joint nonlinear dimensionality reduction and clustering by optimizing a global continuous objective.,,,,
SJzR2iRcK7,2019,Accept (Poster),False,Multi-class classification without multi-class labels,"[""Yen-Chang Hsu"", ""Zhaoyang Lv"", ""Joel Schlosser"", ""Phillip Odom"", ""Zsolt Kira""]","[""classification"", ""unsupervised learning"", ""semi-supervised learning"", ""problem reduction"", ""weak supervision"", ""cross-task"", ""learning"", ""deep learning"", ""neural network""]",,,,,
SJzRZ-WCZ,2018,Accept (Poster),False,Latent Space Oddity: on the Curvature of Deep Generative Models,"[""Georgios Arvanitidis"", ""Lars Kai Hansen"", ""S\u00f8ren Hauberg""]","[""Generative models"", ""Riemannian Geometry"", ""Latent Space""]",,,,,
SJzSgnRcKX,2019,Accept (Poster),False,What do you learn from context? Probing for sentence structure in contextualized word representations,"[""Ian Tenney"", ""Patrick Xia"", ""Berlin Chen"", ""Alex Wang"", ""Adam Poliak"", ""R Thomas McCoy"", ""Najoung Kim"", ""Benjamin Van Durme"", ""Samuel R. Bowman"", ""Dipanjan Das"", ""Ellie Pavlick""]","[""natural language processing"", ""word embeddings"", ""transfer learning"", ""interpretability""]","We probe for sentence structure in ELMo and related contextual embedding models. We find existing models efficiently encode syntax and show evidence of long-range dependencies, but only offer small improvements on semantic tasks.",,,,
SJzYdsAqY7,2019,Reject,False,Spatial-Winograd Pruning Enabling Sparse Winograd Convolution,"[""Jiecao Yu"", ""Jongsoo Park"", ""Maxim Naumov""]","[""deep learning"", ""convolutional neural network"", ""pruning"", ""Winograd convolution""]","To accelerate the computation of convolutional neural networks, we propose a new two-step pruning technique which achieves a higher Winograd-domain weight sparsity without changing the network structure.",,,,
SJzmJEq6W,2018,Reject,False,Learning non-linear transform with discriminative and minimum information loss priors,"[""Dimche Kostadinov"", ""Slava Voloshynovskiy""]","[""transform learning"", ""sparse representation"", ""discrimininative prior"", ""information preservation"", ""discrimination power""]",,,,,
SJzqpj09YQ,2019,Accept (Poster),False,Spectral Inference Networks: Unifying Deep and Spectral Learning,"[""David Pfau"", ""Stig Petersen"", ""Ashish Agarwal"", ""David G. T. Barrett"", ""Kimberly L. Stachenfeld""]","[""spectral learning"", ""unsupervised learning"", ""manifold learning"", ""dimensionality reduction""]","We show how to learn spectral decompositions of linear operators with deep learning, and use it for unsupervised learning without a generative model.",,,,
SJzuHiA9tQ,2019,Reject,False,Generative Adversarial Network Training is a Continual Learning Problem,"[""Kevin J Liang"", ""Chunyuan Li"", ""Guoyin Wang"", ""Lawrence Carin""]","[""Generative Adversarial Networks"", ""Continual Learning"", ""Deep Learning""]",Generative Adversarial Network Training is a Continual Learning Problem.,,,,
SJzvDjAcK7,2019,Reject,False,Intriguing Properties of Learned Representations,"[""Amartya Sanyal"", ""Varun Kanade"", ""Philip H. Torr""]","[""deep learning"", ""low rank representations"", ""adversarial robustness""]",Imposing a low rank structure on learned representations in deep networks yields a lot of interesting benefits.,,,,
SJzwvoCqF7,2019,Reject,True,"On Tighter Generalization Bounds for Deep Neural Networks: CNNs, ResNets, and Beyond","[""Xingguo Li"", ""Junwei Lu"", ""Zhaoran Wang"", ""Jarvis Haupt"", ""Tuo Zhao""]","[""deep learning"", ""generalization error bound"", ""convolutional neural networks""]",,1806.05159,cs.LG,2018-06-13 17:35:55+00:00,2019-07-03 18:24:09+00:00
SK7A5pdrgov,2021,Accept (Poster),False,CausalWorld: A Robotic Manipulation Benchmark for Causal Structure and Transfer Learning,"[""Ossama Ahmed"", ""Frederik Tr\u00e4uble"", ""Anirudh Goyal"", ""Alexander Neitz"", ""Manuel Wuthrich"", ""Yoshua Bengio"", ""Bernhard Sch\u00f6lkopf"", ""Stefan Bauer""]","[""reinforcement learning"", ""transfer learning"", ""sim2real transfer"", ""domain adaptation"", ""causality"", ""generalization"", ""robotics""]",A benchmark to address the challenge of agents transferring their learned skills to related environments; primarily for causal structure and transfer learning.,,,,
SLz5sZjacp,2022,Accept (Poster),True,Evaluating Disentanglement of Structured Latent Representations,['RaphaÃ«l Dang-Nhu'],[],"We introduce the first metric for evaluating disentanglement at individual hierarchy levels of a structured latent representation, and apply it to object-centric generative models.",2101.04041,cs.LG,2021-01-11 17:24:01+00:00,2022-01-29 18:35:07+00:00
SN2bkl9f69,2022,Reject,False,"Multi-Tailed, Multi-Headed, Spatial Dynamic Memory refined Text-to-Image Synthesis","['Amrit Diggavi Seshadri', 'Balaraman Ravindran']","[""Text-to-Image Generation"", ""Computer Vision""]",We propose a novel architecture for text-to-image generation and show that our method performs favourably against the previous state-of-the-art,,,,
SO73JUgks8,2021,Reject,True,AUBER: Automated BERT Regularization,"[""Hyun Dong Lee"", ""Seongmin Lee"", ""U Kang""]","[""BERT Regularization"", ""Reinforcement Learning"", ""Automated Regularization""]",We propose a method to automatically regularize BERT to improve its accuracy via reinforcement learning.,2009.14409,cs.AI,2020-09-30 03:32:55+00:00,2020-09-30 03:32:55+00:00
SOVSJZ9PTO7,2021,Reject,True,JAKET: Joint Pre-training of Knowledge Graph and Language Understanding,"[""Donghan Yu"", ""Chenguang Zhu"", ""Yiming Yang"", ""Michael Zeng""]","[""Pre-training"", ""Knowledge Graph"", ""Language Understanding"", ""Graph Neural Network""]",A joint pre-training framework which models both the knowledge graph and text and can easily adapt to unseen knowledge graphs in new domains during fine-tuning,2010.00796,cs.CL,2020-10-02 05:53:36+00:00,2020-10-02 05:53:36+00:00
SP5RHi-rdlJ,2021,Reject,False,Sparse Binary Neural Networks,"[""Riccardo Schiavone"", ""Maria A Zuluaga""]","[""Binary Neural Networks"", ""Sparsity"", ""Deep Neural Network Compression""]",,,,,
SPhswbiXpJQ,2021,Reject,False,Deep Data Flow Analysis,"[""Chris Cummins"", ""Zacharias Fisches"", ""Tal Ben-Nun"", ""Torsten Hoefler"", ""Hugh Leather"", ""Michael O'Boyle""]","[""program representations"", ""program analysis"", ""compilers"", ""graph neural networks""]",A graph representation for programs that enables more powerful reasoning about program semantics and improved performance on downstream compiler tasks.,,,,
SPyxaz_h9Nd,2021,Reject,False,PareCO: Pareto-aware Channel Optimization for Slimmable Neural Networks,"[""Rudy Chin"", ""Ari S. Morcos"", ""Diana Marculescu""]","[""Adaptive Neural Network"", ""Slimmable Neural Network"", ""Channel Optimization"", ""Neural Architecture Search"", ""Convolutional Neural Network"", ""Image Classification""]",,,,,
SQ7EHTDyn9Y,2021,Reject,False,On Nondeterminism and Instability in Neural Network Optimization,"[""Cecilia Summers"", ""Michael J. Dinneen""]","[""Nondeterminism"", ""Instability""]","We analyze the variability of training neural networks, show much of it is due to a previously-unknown instability in optimization, and demonstrate a promising approach for reducing it.",2103.04514,cs.LG,2021-03-08 02:28:18+00:00,2021-07-10 21:58:40+00:00
SQfqNwVoWu,2021,Reject,False,Approximate Probabilistic Inference with Composed Flows,"[""Jay Whang"", ""Erik Lindgren"", ""Alex Dimakis""]","[""normalizing flow"", ""probabilistic inference"", ""variational inference"", ""inverse problem""]",A new algorithm for performing approximate probabilistic inference on a joint distribution defined by a normalizing flow model.,,,,
SRDuJssQud,2021,Accept (Spotlight),False,Neural Approximate Sufficient Statistics for Implicit Models,"[""Yanzhi Chen"", ""Dinghuai Zhang"", ""Michael U. Gutmann"", ""Aaron Courville"", ""Zhanxing Zhu""]","[""likelihood-free inference"", ""bayesian inference"", ""mutual information"", ""representation learning"", ""summary statistics""]",We learn low-dimensional near-sufficient statistics for implicit models by infomax principle without estimating the density or even the density ratio.,,,,
SRzz6RtOdKR,2021,Reject,False,Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression,"[""Vincent Mai"", ""Waleed Khamies"", ""Liam Paull""]","[""Regression"", ""Noisy labels"", ""Supervised Learning"", ""Uncertainty"", ""Variance"", ""Heteroscedastic"", ""Privileged Information""]",A method to reduce the effect of heteroscedastic noisy labels in regression by weighting them based on their variance and the variance of the other samples in the minibatch.,2107.04497,cs.LG,2021-07-09 15:39:31+00:00,2021-07-09 15:39:31+00:00
SS8F6tFX3-,2022,Accept (Poster),True,Evaluating Model-Based Planning and Planner Amortization for Continuous Control,"['Arunkumar Byravan', 'Leonard Hasenclever', 'Piotr Trochim', 'Mehdi Mirza', 'Alessandro Davide Ialongo', 'Yuval Tassa', 'Jost Tobias Springenberg', 'Abbas Abdolmaleki', 'Nicolas Heess', 'Josh Merel', 'Martin Riedmiller']","[""Model-based Reinforcement Learning"", ""Planning"", ""Robotics"", ""Model Predictive Control"", ""Learning""]",We combine MPC with model-free RL and evaluate on continuous control tasks from scratch and in transfer settings; our results show that model-free RL is a strong baseline in single task settings and model-based methods shine in multi-goal tasks.,2110.03363,cs.RO,2021-10-07 12:00:40+00:00,2021-10-07 12:00:40+00:00
STFJBXDTSlT,2022,Reject,False,Identity-Disentangled Adversarial Augmentation for Self-supervised Learning,"['Kaiwen Yang', 'Tianyi Zhou', 'Xinmei Tian', 'Dacheng Tao']","[""identity disentanglement"", ""contrastive learning"", ""data augmentation"", ""self-supervised learning""]",We propose an identity-disentangled adversarial data augmentation strategy that can generate hard but identity-preserved augmentation for more efficient and effective self-supervised learning.,,,,
SUyxNGzUsH,2021,Reject,False,VilNMN: A Neural Module Network approach to Video-Grounded Language Tasks,"[""Hung Le"", ""Nancy F. Chen"", ""Steven Hoi""]","[""neural modular networks"", ""video-grounded dialogues"", ""dialogue understanding"", ""video understanding"", ""video QA"", ""video-grounded language tasks""]","We propose VilNMN, a novel neural module network approach for video-grounded language tasks, which achieves strong performance in both video QA and video-grounded dialogue tasks. ",,,,
SVP44gujOBL,2021,Reject,False,A Simple Approach To Define Curricula For Training Neural Networks,"[""Vinu Sankar Sadasivan"", ""Anirban Dasgupta""]","[""Curriculum learning"", ""neural networks""]","We introduce a simple, unsupervised approach to score the difficulty of examples using statistical measures for curriculum learning, and analyze it with the help of a dynamic curriculum learning framework that we design.",,,,
SVcEx6SC_NL,2022,Reject,False,Adversarial Robustness as a Prior for Learned Representations,"['Logan Engstrom', 'Andrew Ilyas', 'Shibani Santurkar', 'Dimitris Tsipras', 'Brandon Tran', 'Aleksander Madry']","[""adversarial robustness"", ""representation learning""]",We show that training models to be adversarially robust induces better-behaved representation layers by looking at two standard representation learning tasks.,,,,
SVey0ddzC4,2022,Reject,True,Connecting Graph Convolution and Graph PCA,"['Lingxiao Zhao', 'Leman Akoglu']","[""Graph Convolutional Network"", ""graph regularization"", ""GNN initialization"", ""graph-based PCA""]","A theoretical connection btwn. graph regularization & graph convolution, and practical contributions (new stacking model and first initialization strategy for GNNs) based on this discovery.",2006.12294,cs.LG,2020-06-22 14:27:02+00:00,2021-03-02 18:08:13+00:00
SVsLxTfHa1,2021,Reject,False,Towards Multi-Sense Cross-Lingual Alignment of Contextual Embeddings,"[""Linlin Liu"", ""Thien Hai Nguyen"", ""Shafiq Joty"", ""Lidong Bing"", ""Luo Si""]",[],,2103.06459,cs.CL,2021-03-11 04:55:35+00:00,2021-03-11 04:55:35+00:00
SVwbKmEg7M,2022,Reject,False,Unsupervised Neural Machine Translation with Generative Language Models Only,"['Jesse Michael Han', 'Igor Babuschkin', 'Harrison Edwards', 'Arvind Neelakantan', 'Tao Xu', 'Stanislas Polu', 'Alex Ray', 'Pranav Shyam', 'Aditya Ramesh', 'Alec Radford', 'Ilya Sutskever']","[""unsupervised"", ""machine translation"", ""language modeling"", ""few-shot learning""]",,,,,
SXoheAR0Gz,2021,Reject,True,Fast Partial Fourier Transform,"[""Yong-chan Park"", ""Jun-Gi Jang"", ""U Kang""]","[""Fourier transform"", ""time series"", ""signal processing"", ""anomaly detection"", ""machine learning""]","We propose a fast Partial Fourier Transform (PFT),  an efficient algorithm for computing only a part of Fourier coefficients. ",2008.12559,cs.LG,2020-08-28 10:01:49+00:00,2020-08-28 10:01:49+00:00
SYB4WrJql1n,2022,Accept (Poster),False,On the Existence of Universal Lottery Tickets,"['Rebekka Burkholz', 'Nilanjana Laha', 'Rajarshi Mukherjee', 'Alkis Gotovos']","[""theory"", ""deep learning"", ""lottery tickets"", ""universality""]",We formalize a notion of strong universal lottery tickets and prove their existence as subnetworks of randomly initialized neural networks.,2111.11146,cs.LG,2021-11-22 12:12:00+00:00,2021-11-22 12:12:00+00:00
SYuJXrXq8tw,2022,Accept (Poster),False,Sparsity Winning Twice: Better Robust Generalization from More Efficient Training,"['Tianlong Chen', 'Zhenyu Zhang', 'pengjun wang', 'Santosh Balachandra', 'Haoyu Ma', 'Zehao Wang', 'Zhangyang Wang']",[],,,,,
SZ3wtsXfzQR,2021,Accept (Poster),False,Theoretical bounds on estimation error for meta-learning,"[""James Lucas"", ""Mengye Ren"", ""Irene Raissa KAMENI KAMENI"", ""Toniann Pitassi"", ""Richard Zemel""]","[""meta learning"", ""few-shot"", ""minimax risk"", ""lower bounds"", ""learning theory""]",We prove novel minimax risk lower bounds and upper bounds for meta learners,,,,
SZRqWWB4AAh,2022,Reject,False,SABAL: Sparse Approximation-based Batch Active Learning,"['Maohao Shen', 'Bowen Jiang', 'Jacky Y. Zhang', 'Oluwasanmi O Koyejo']","[""active learning"", ""Bayesian active learning"", ""batch active learning""]",We propose a novel and general framework that formulates the batch active learning as a sparse approximation problem.,,,,
SaKO6z6Hl0c,2022,Accept (Poster),False,Unsupervised Semantic Segmentation by Distilling Feature Correspondences,"['Mark Hamilton', 'Zhoutong Zhang', 'Bharath Hariharan', 'Noah Snavely', 'William T. Freeman']","[""Unsupervised Semantic Segmentation"", ""Unsupervised Learning"", ""Deep Features"", ""Contrastive Learning"", ""Visual Transformers"", ""Cocostuff"", ""Cityscapes"", ""Semantic Segmentation""]",We use the correlations between self-supervised visual features to perform unsupervised semantic segmentation.,,,,
Sb4hTI15hUZ,2022,Reject,False,Data-oriented Scene Recognition,"['Zhinan Qiao', 'Xiaohui Yuan', 'Chaoning Zhang', 'Jianfang Shi', 'Jian Xia']","[""data-oriented design"", ""computer vision"", ""scene recognition"", ""image recognition""]",,,,,
SbV8J9JHb6,2022,Reject,False,Soteria: In search of efficient neural networks for private inference,"['Anshul Aggarwal', 'Trevor E Carlson', 'Reza Shokri', 'Shruti Tople']",[],,,,,
Sc8cY4Jpi3s,2021,Reject,True,Towards Practical Second Order Optimization for Deep Learning,"[""Rohan Anil"", ""Vineet Gupta"", ""Tomer Koren"", ""Kevin Regan"", ""Yoram Singer""]","[""large scale distributed deep learning"", ""second order optimization"", ""bert"", ""resnet"", ""criteo"", ""transformer"", ""machine translation""]",We outperform state-of-the-art first-order optimizers on a variety of tasks using a distributed second-order method.,2002.09018,cs.LG,2020-02-20 20:51:33+00:00,2021-03-05 06:29:48+00:00
SeFiP8YAJy,2021,Reject,False,Better Together: Resnet-50 accuracy with $13 \times $ fewer parameters and at $3 \times $ speed,"[""Utkarsh Nath"", ""Shrinu Kushagra""]","[""Deep neural networks"", ""Theory of deep networks"", ""deep regularization"", ""Neural network compression""]",A new paradigm to train neural network with theoretical guarentees and empirical evaluation.,,,,
SgEhFeRyzEZ,2022,Reject,True,Convergence Analysis and Implicit Regularization of Feedback Alignment for Deep Linear Networks,"['Manuela Girotti', 'Ioannis Mitliagkas', 'Gauthier Gidel']","[""feedback alignement"", ""optimization"", ""convergence guarantees"", ""implicit regularization""]",we present convergence results for the Feedback Alignment algorithm and we analyze incremental learning phenomena,2110.10815,cs.LG,2021-10-20 22:57:03+00:00,2021-10-20 22:57:03+00:00
Shjmp-QK8Y-,2021,Reject,False,Prior Knowledge Representation for Self-Attention Networks,"[""Kehai Chen"", ""Rui Wang"", ""Masao Utiyama"", ""Eiichiro Sumita""]","[""Prior Knowledge"", ""Universal Representation"", ""Self-Attention Networks"", ""Neural Machine Translation""]",This work explores a universal prior knowledge representation aproach to self-attention networks,,,,
SidzxAb9k30,2022,Accept (Spotlight),False,Near-Optimal Reward-Free Exploration for Linear Mixture MDPs with Plug-in Solver,"['Xiaoyu Chen', 'Jiachen Hu', 'Lin Yang', 'Liwei Wang']","[""reward-free exploration"", ""model-based reinforcement learning"", ""learning theory""]",We propose near-optimal exploration algorithms for reward-free exploration with plug-in solver.,,,,
Siwm2BaNiG,2021,Reject,False,Modal Uncertainty Estimation via Discrete Latent Representations,"[""Di Qiu"", ""Zhanghan Ke"", ""Peng Su"", ""Lok Ming Lui""]","[""uncertainty estimation"", ""one -to-many mapping"", ""conditional generative model"", ""discrete latent space"", ""medical image segmentation""]",We use a conditional generative model with discrete latent representation to solve the one-to-many mapping problem with faithful uncertainty estimates.,,,,
SjGRJ4vSZlP,2022,Reject,False,Near-Optimal Algorithms for Autonomous Exploration and Multi-Goal Stochastic Shortest Path,"['Haoyuan Cai', 'Tengyu Ma', 'Simon Shaolei Du']","[""Reinforcement learning theory"", ""autonomous exploration""]",We obtain near-optimal sample complexity upper bounds and the first minimax lower bound for autonomous exploration.,,,,
Sk-oDY9ge,2017,Accept (Poster),False,Diet Networks: Thin Parameters for Fat Genomics,"[""Adriana Romero"", ""Pierre Luc Carrier"", ""Akram Erraqabi"", ""Tristan Sylvain"", ""Alex Auvolat"", ""Etienne Dejoie"", ""Marc-Andr\u00e9 Legault"", ""Marie-Pierre Dub\u00e9"", ""Julie G. Hussin"", ""Yoshua Bengio""]","[""Deep learning"", ""Unsupervised Learning"", ""Supervised Learning"", ""Applications""]","Drastically reducing the number of parameters, when the number of input features is orders of magnitude larger than the number of training examples, such as in genomics.",,,,
Sk03Yi10Z,2018,Reject,False,An Ensemble of Retrieval-Based and Generation-Based Human-Computer Conversation Systems.,"[""Yiping Song"", ""Rui Yan"", ""Cheng-Te Li"", ""Jian-Yun Nie"", ""Ming Zhang"", ""Dongyan Zhao""]","[""conversation systems"", ""retrieval method"", ""generation method""]",A novel ensemble of retrieval-based and generation-based for open-domain conversation systems.,,,,
Sk0pHeZAW,2018,Reject,False,Sparse Regularized Deep Neural Networks For Efficient Embedded Learning,"[""Jia Bi""]","[""Sparse representation"", ""Compression Deep Learning Models"", ""L1 regularisation"", ""Optimisation.""]",Compression of Deep neural networks deployed on embedded device. ,,,,
Sk1NTfZAb,2018,Reject,False,Key Protected Classification for GAN Attack Resilient Collaborative Learning,"[""Mert B\u00fclent Sar\u0131y\u0131ld\u0131z"", ""Ramazan G\u00f6kberk Cinbi\u015f"", ""Erman Ayday""]","[""privacy preserving deep learning"", ""collaborative learning"", ""adversarial attack""]",,,,,
Sk2Im59ex,2017,Accept (Poster),False,Unsupervised Cross-Domain Image Generation,"[""Yaniv Taigman"", ""Adam Polyak"", ""Lior Wolf""]","[""Computer vision"", ""Deep learning"", ""Unsupervised Learning"", ""Transfer Learning""]",,,,,
Sk2iistgg,2017,Reject,False,Non-linear Dimensionality Regularizer for Solving Inverse Problems,"[""Ravi Garg"", ""Anders Eriksson"", ""Ian Reid""]","[""Computer vision"", ""Optimization"", ""Structured prediction""]",Predicting causal factors of an inverse problem which lie near unknown low-dimensional non-linear manifold defined by a mercer kernel.,,,,
Sk2u1g-0-,2018,Accept (Oral),False,Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments,"[""Maruan Al-Shedivat"", ""Trapit Bansal"", ""Yura Burda"", ""Ilya Sutskever"", ""Igor Mordatch"", ""Pieter Abbeel""]","[""reinforcement learning"", ""nonstationarity"", ""meta-learning"", ""transfer learning"", ""multi-agent""]",,,,,
Sk36NgFeg,2017,Reject,False,Filling in the details: Perceiving from low fidelity visual input,"[""Farahnaz A. Wick"", ""Michael L. Wick"", ""Marc Pomplun""]","[""Deep learning"", ""Computer vision"", ""Semi-Supervised Learning""]",Using generative models to create images from impoverished input similar to those received by our visual cortex,,,,
Sk4jFoA9K7,2019,Accept (Poster),False,PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks,"[""Jan Svoboda"", ""Jonathan Masci"", ""Federico Monti"", ""Michael Bronstein"", ""Leonidas Guibas""]","[""peernet"", ""peernets"", ""graph"", ""geometric deep learning"", ""adversarial"", ""perturbation"", ""defense"", ""peer regularization""]",,,,,
Sk4w0A0Tb,2018,Invite to Workshop Track,False,Rotational Unit of Memory ,"[""Rumen Dangovski"", ""Li Jing"", ""Marin Soljacic""]","[""RNN"", ""unitary approach"", ""associative memory"", ""language modeling""]",A novel RNN model which outperforms significantly the current frontier of models in a variety of sequential tasks.,,,,
Sk6fD5yCb,2018,Accept (Poster),False,Espresso: Efficient Forward Propagation for Binary Deep Neural Networks,"[""Fabrizio Pedersoli"", ""George Tzanetakis"", ""Andrea Tagliasacchi""]","[""binary deep neural networks"", ""optimized implementation"", ""bitwise computations""]",state-of-the-art computational performance implementation of binary neural networks,,,,
Sk7KsfW0-,2018,Accept (Poster),False,Lifelong Learning with Dynamically Expandable Networks,"[""Jaehong Yoon"", ""Eunho Yang"", ""Jeongtae Lee"", ""Sung Ju Hwang""]","[""Transfer learning"", ""Lifelong learning"", ""Selective retraining"", ""Dynamic network expansion""]",We propose a novel deep network architecture that can dynamically decide its network capacity as it trains on a lifelong learning scenario.,,,,
Sk7cHb-C-,2018,Reject,False,Representing dynamically: An active process for describing sequential data,"[""Juan Sebastian Olier"", ""Emilia Barakova"", ""Matthias Rauterberg"", ""Carlo Regazzoni""]","[""Generative Models"", ""Latent representations"", ""Predictive coding"", ""Recurrent networks"", ""Sequential data""]",A method that build representations of sequential data and its dynamics through generative models with an active process,,,,
Sk8J83oee,2017,Reject,False,Generative Adversarial Parallelization,"[""Daniel Jiwoong Im"", ""He Ma"", ""Chris Dongjoo Kim"", ""Graham Taylor""]","[""Unsupervised Learning""]",Creating Synergy with Multiple Generative Adversarial Networks,,,,
Sk8csP5ex,2017,Reject,False,The loss surface of residual networks: Ensembles and the role of batch normalization,"[""Etai Littwin"", ""Lior Wolf""]","[""Deep learning"", ""Theory""]",Residual nets are dynamic ensembles,,,,
Sk9yuql0Z,2018,Accept (Poster),False,Mitigating Adversarial Effects Through Randomization,"[""Cihang Xie"", ""Jianyu Wang"", ""Zhishuai Zhang"", ""Zhou Ren"", ""Alan Yuille""]","[""adversarial examples""]",,,,,
SkA-IE06W,2018,Accept (Poster),False,When is a Convolutional Filter Easy to Learn?,"[""Simon S. Du"", ""Jason D. Lee"", ""Yuandong Tian""]","[""deep learning"", ""convolutional neural network"", ""non-convex optimization"", ""convergence analysis""]",We prove randomly initialized (stochastic) gradient descent learns a convolutional filter in polynomial time.,,,,
SkAK2jg0b,2018,Reject,False,An Out-of-the-box Full-network Embedding for Convolutional Neural Networks,"[""Dario Garcia-Gasulla"", ""Armand Vilalta"", ""Ferran Par\u00e9s"", ""Jonatan Moreno"", ""Eduard Ayguad\u00e9"", ""Jes\u00fas Labarta"", ""Ulises Cort\u00e9s"", ""Toyotaro Suzumura""]","[""Embedding spaces"", ""feature extraction"", ""transfer learning.""]",We present a full-network embedding of CNN which outperforms single layer embeddings for transfer learning tasks.,,,,
SkB-_mcel,2017,Accept (Poster),False,Central Moment Discrepancy (CMD) for Domain-Invariant Representation Learning,"[""Werner Zellinger"", ""Thomas Grubinger"", ""Edwin Lughofer"", ""Thomas Natschl\u00e4ger"", ""Susanne Saminger-Platz""]","[""Transfer Learning"", ""Deep learning"", ""Computer vision""]",A new method for hidden activation distribution matching in the context of domain adaptation.,,,,
SkBHr1WRW,2018,Reject,False,Ego-CNN: An Ego Network-based Representation of Graphs Detecting Critical Structures,"[""Ruo-Chun Tzeng"", ""Shan-Hung Wu""]","[""graph embedding"", ""CNN""]",,,,,
SkBYYyZRZ,2018,Invite to Workshop Track,False,Searching for Activation Functions,"[""Prajit Ramachandran"", ""Barret Zoph"", ""Quoc V. Le""]","[""meta learning"", ""activation functions""]","We use search techniques to discover novel activation functions, and our best discovered activation function, f(x) = x * sigmoid(beta * x), outperforms ReLU on a number of challenging tasks like ImageNet.",,,,
SkBcLugC-,2018,Reject,False,Fast and Accurate Inference with Adaptive Ensemble Prediction for Deep Networks,"[""Hiroshi Inoue""]","[""ensemble"", ""confidence level""]",,,,,
SkBsEQYll,2017,Reject,False,Learning similarity preserving representations with neural similarity and context encoders,"[""Franziska Horn"", ""Klaus-Robert M\u00fcller""]","[""Natural language processing"", ""Unsupervised Learning"", ""Supervised Learning""]",Neural network way of doing kernel PCA and an extension of word2vec to compute out-of-vocabulary embeddings and distinguish between multiple meanings of a word based on its local context.,,,,
SkCILwqex,2017,Reject,False,Exploring LOTS in Deep Neural Networks,"[""Andras Rozsa"", ""Manuel Gunther"", ""Terrance E. Boult""]","[""Deep learning"", ""Computer vision""]","We introduce layerwise origin-target synthesis (LOTS) that can be used for visualizing internal representations of deep neural networks, and for adversarial example generation.",,,,
SkC_7v5gx,2017,Reject,False,The Power of Sparsity in Convolutional Neural Networks,"[""Soravit Changpinyo"", ""Mark Sandler"", ""Andrey Zhmoginov""]","[""Deep learning"", ""Supervised Learning""]",Sparse random connections that allow savings to be harvested and that are very effective at compressing CNNs.,,,,
SkE6PjC9KX,2019,Accept (Poster),False,Attentive Neural Processes,"[""Hyunjik Kim"", ""Andriy Mnih"", ""Jonathan Schwarz"", ""Marta Garnelo"", ""Ali Eslami"", ""Dan Rosenbaum"", ""Oriol Vinyals"", ""Yee Whye Teh""]","[""Neural Processes"", ""Conditional Neural Processes"", ""Stochastic Processes"", ""Regression"", ""Attention""]","A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.",,,,
SkERSm-0-,2018,Reject,False,Preliminary theoretical troubleshooting in Variational Autoencoder,"[""Shiqi Liu"", ""Qian Zhao"", ""Xiangyong Cao"", ""Deyu Meng"", ""Zilu Ma"", ""Tao Yu""]","[""variational autoencoder"", ""information theory"", ""noise modelling"", ""representation learning"", ""generative model"", ""disentanglement""]",This paper tries to preliminarily address the disentanglement theoretically in the idealistic situation and practically through noise modelling perspective in the realistic case.,,,,
SkEYojRqtm,2019,Accept (Poster),False,Representation Degeneration Problem in Training Natural Language Generation Models,"[""Jun Gao"", ""Di He"", ""Xu Tan"", ""Tao Qin"", ""Liwei Wang"", ""Tieyan Liu""]","[""Natural Language Processing"", ""Representation Learning""]",,,,,
SkEqro0ctQ,2019,Accept (Poster),False,Hierarchical interpretations for neural network predictions,"[""Chandan Singh"", ""W. James Murdoch"", ""Bin Yu""]","[""interpretability"", ""natural language processing"", ""computer vision""]","We introduce and validate hierarchical local interpretations, the first technique to automatically search for and display important interactions for individual predictions made by LSTMs and CNNs.",,,,
SkF2D7g0b,2018,Reject,False,Exploring the Space of Black-box Attacks on Deep Neural Networks,"[""Arjun Nitin Bhagoji"", ""Warren He"", ""Bo Li"", ""Dawn Song""]","[""adversarial machine learning"", ""black-box attacks""]",Query-based black-box attacks on deep neural networks with adversarial success rates matching white-box attacks,,,,
SkFAWax0-,2018,Accept (Poster),False,VoiceLoop: Voice Fitting and Synthesis via a Phonological Loop,"[""Yaniv Taigman"", ""Lior Wolf"", ""Adam Polyak"", ""Eliya Nachmani""]","[""Voice Synthesis"", ""Multi-Speaker"", ""Differentiable Memory"", ""Text-to-Speech""]",,,,,
SkFEGHx0Z,2018,Reject,False,Nearest Neighbour Radial Basis Function Solvers for Deep Neural Networks,"[""Benjamin J. Meyer"", ""Ben Harwood"", ""Tom Drummond""]",[],,,,,
SkFqf0lAZ,2018,Accept (Poster),False,Memory Architectures in Recurrent Neural Network Language Models,"[""Dani Yogatama"", ""Yishu Miao"", ""Gabor Melis"", ""Wang Ling"", ""Adhiguna Kuncoro"", ""Chris Dyer"", ""Phil Blunsom""]",[],,,,,
SkFvV0yC-,2018,Reject,False,Network Iterative Learning for Dynamic Deep Neural Networks via Morphism,"[""Tao Wei"", ""Changhu Wang"", ""Chang Wen Chen""]","[""Network Iterative Learning"", ""Morphism""]",,,,,
SkGH2oRcYX,2019,Reject,False,DEEP ADVERSARIAL FORWARD MODEL,"[""Morgan Funtowicz"", ""Tomi Silander"", ""Arnaud Sors"", ""Julien Perez""]","[""forward model"", ""adversarial learning""]",,,,,
SkGNrnC9FQ,2019,Reject,False,Manifold Alignment via Feature Correspondence,"[""Jay S. Stanley III"", ""Guy Wolf"", ""Smita Krishnaswamy""]","[""graph signal processing"", ""graph alignment"", ""manifold alignment"", ""spectral graph wavelet transform"", ""diffusion geometry"", ""harmonic analysis""]",We propose a method for aligning the latent features learned from different datasets using harmonic correlations.,,,,
SkGQujR5FX,2019,Reject,False,DANA: Scalable Out-of-the-box Distributed ASGD Without Retuning,"[""Ido Hakimi"", ""Saar Barkai"", ""Moshe Gabel"", ""Assaf Schuster""]","[""distributed"", ""asynchronous"", ""gradient staleness"", ""nesterov"", ""optimization"", ""out-of-the-box"", ""stochastic gradient descent"", ""sgd"", ""imagenet"", ""distributed training"", ""neural networks"", ""deep learning""]",A new distributed asynchronous SGD algorithm that achieves state-of-the-art accuracy on existing architectures without any additional tuning or overhead.,,,,
SkGT6sRcFX,2019,Reject,False,Infinitely Deep Infinite-Width Networks,"[""Jovana Mitrovic"", ""Peter Wirnsberger"", ""Charles Blundell"", ""Dino Sejdinovic"", ""Yee Whye Teh""]","[""Infinite-width networks"", ""initialisation"", ""kernel methods"", ""reproducing kernel Hilbert spaces"", ""Gaussian processes""]","We propose a method for the construction of arbitrarily deep infinite-width networks, based on which we derive a novel weight initialisation scheme for finite-width networks and demonstrate its competitive performance.",,,,
SkGpW3C5KX,2019,Reject,False,Heated-Up Softmax Embedding,"[""Xu Zhang"", ""Felix Xinnan Yu"", ""Svebor Karaman"", ""Wei Zhang"", ""Shih-Fu Chang""]",[],,,,,
SkGtjjR5t7,2019,Reject,False,Learning to Drive by Observing the Best and Synthesizing the Worst,"[""Mayank Bansal"", ""Alex Krizhevsky"", ""Abhijit Ogale""]","[""Imitation Learning"", ""End-to-End Driving"", ""Learning to drive"", ""Autonomous Driving""]",This work explores how far we can take (supervised) imitation learning for the task of driving a car.,,,,
SkGuG2R5tm,2019,Accept (Poster),False,Spreading vectors for similarity search,"[""Alexandre Sablayrolles"", ""Matthijs Douze"", ""Cordelia Schmid"", ""Herv\u00e9 J\u00e9gou""]","[""dimensionality reduction"", ""similarity search"", ""indexing"", ""differential entropy""]","We learn a neural network that uniformizes the input distribution, which leads to competitive indexing performance in high-dimensional space",,,,
SkHDoG-Cb,2018,Accept (Poster),False,Simulated+Unsupervised Learning With Adaptive Data Generation and Bidirectional Mappings,"[""Kangwook Lee"", ""Hoon Kim"", ""Changho Suh""]",[],,,,,
SkHkeixAW,2018,Reject,False,Regularization for Deep Learning: A Taxonomy,"[""Jan Kuka\u010dka"", ""Vladimir Golkov"", ""Daniel Cremers""]","[""neural networks"", ""deep learning"", ""regularization"", ""data augmentation"", ""network architecture"", ""loss function"", ""dropout"", ""residual learning"", ""optimization""]","Systematic categorization of regularization methods for deep learning, revealing their similarities.",,,,
SkHl6MWC-,2018,Invite to Workshop Track,False,Regularization Neural Networks via Constrained Virtual  Movement Field,"[""Zhendong Zhang"", ""Cheolkon Jung""]",[],,,,,
SkJKHMW0Z,2018,Reject,False,Recurrent Relational Networks for complex relational reasoning,"[""Rasmus Berg Palm"", ""Ulrich Paquet"", ""Ole Winther""]","[""relational reasoning"", ""graph neural networks""]","We introduce Recurrent Relational Networks, a powerful and general neural network module for relational reasoning, and use it to solve 96.6% of the hardest Sudokus and 19/20 BaBi tasks.",,,,
SkJd_y-Cb,2018,Reject,False,Word2net: Deep Representations of Language,"[""Maja Rudolph"", ""Francisco Ruiz"", ""David Blei""]","[""neural language models"", ""word embeddings"", ""neural networks""]",Word2net is a novel method for learning neural network representations of words that can use syntactic information to learn better semantic features.,,,,
SkJeEtclx,2017,Reject,False,Memory-augmented Attention Modelling for Videos,"[""Rasool Fakoor"", ""Abdel-rahman Mohamed"", ""Margaret Mitchell"", ""Sing Bing Kang"", ""Pushmeet Kohli""]","[""Deep learning"", ""Multi-modal learning"", ""Computer vision""]",We propose a novel memory-based attention model for video description,,,,
SkMON20ctX,2019,Reject,False,On the Trajectory of Stochastic Gradient Descent in the Information Plane,"[""Emilio Rafael Balda"", ""Arash Behboodi"", ""Rudolf Mathar""]","[""Stochastic gradient descent"", ""Deep neural networks"", ""Entropy"", ""Information theory"", ""Markov chains"", ""Hidden Markov process.""]","We look at SGD as a trajectory in the space of probability measures, show its connection to Markov processes, propose a simple Markov model of SGD learning, and experimentally compare it with SGD using information theoretic quantities. ",,,,
SkMQg3C5K7,2019,Accept (Poster),False,A Convergence Analysis of Gradient Descent for Deep Linear Neural Networks,"[""Sanjeev Arora"", ""Nadav Cohen"", ""Noah Golowich"", ""Wei Hu""]","[""Deep Learning"", ""Learning Theory"", ""Non-Convex Optimization""]","We analyze gradient descent for deep linear neural networks, providing a guarantee of convergence to global optimum at a linear rate.",,,,
SkMuPjRcKQ,2019,Accept (Poster),False,Feed-forward Propagation in Probabilistic Neural Networks with Categorical and Max Layers,"[""Alexander Shekhovtsov"", ""Boris Flach""]","[""probabilistic neural network"", ""uncertainty"", ""dropout"", ""bayesian"", ""softmax"", ""argmax"", ""logsumexp""]","Approximating mean and variance of the NN output over noisy input / dropout / uncertain parameters. Analytic approximations for argmax, softmax and max layers.",,,,
SkMwpiR9Y7,2019,Accept (Poster),False,Measuring and regularizing networks in function space,"[""Ari Benjamin"", ""David Rolnick"", ""Konrad Kording""]","[""function space"", ""Hilbert space"", ""empirical characterization"", ""multitask learning"", ""catastrophic forgetting"", ""optimization"", ""natural gradient""]",We find movement in function space is not proportional to movement in parameter space during optimization. We propose a new natural-gradient style optimizer to address this.,,,,
SkMx_iC9K7,2019,Reject,False,DelibGAN: Coarse-to-Fine Text Generation via Adversarial Network,"[""Ke Wang"", ""Xiaojun Wan""]","[""unsupervised text generation"", ""coarse-to-fine generator"", ""multiple instance discriminator"", ""GAN"", ""DelibGAN""]","A novel adversarial learning framework, namely DelibGAN, is proposed for generating high-quality sentences without supervision.",,,,
SkNQeiRpb,2018,Reject,False,Training Deep AutoEncoders for Recommender Systems,"[""Oleksii Kuchaiev"", ""Boris Ginsburg""]","[""autoencoder"", ""recommendations"", ""collaborative filtering"", ""selu""]",This paper demonstrates how to train deep autoencoders end-to-end to achieve SoA results on time-split Netflix data set.,,,,
SkNSOjR9Y7,2019,Reject,False,Training Variational Auto Encoders with Discrete Latent Representations using Importance Sampling,"[""Alexander Bartler"", ""Felix Wiewel"", ""Bin Yang"", ""Lukas Mauch""]","[""Variational Auto Encoder"", ""Importance Sampling"", ""Discrete latent representation""]","We propose an easy method to train Variational Auto Encoders (VAE) with discrete latent representations, using importance sampling",,,,
SkNSehA9FQ,2019,Reject,False,Open Vocabulary Learning on Source Code with a Graph-Structured Cache,"[""Milan Cvitkovic"", ""Badal Singh"", ""Anima Anandkumar""]","[""deep learning"", ""graph neural network"", ""open vocabulary"", ""natural language processing"", ""source code"", ""abstract syntax tree"", ""code completion"", ""variable naming""]","We show that caching out-of-vocabulary words in a graph, with edges connecting them to their usages, and processing it with a graph neural network improves performance on supervised learning tasks on computer source code.",,,,
SkNksoRctQ,2019,Accept (Poster),False,Fluctuation-dissipation relations for stochastic gradient descent,"[""Sho Yaida""]","[""stochastic gradient descent"", ""adaptive method"", ""loss surface"", ""Hessian""]","We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.",,,,
SkOb1Fl0Z,2018,Invite to Workshop Track,False,A Flexible Approach to Automated RNN Architecture Generation,"[""Martin Schrimpf"", ""Stephen Merity"", ""James Bradbury"", ""Richard Socher""]","[""reinforcement learning"", ""architecture search"", ""ranking function"", ""recurrent neural networks"", ""recursive neural networks""]","We define a flexible DSL for RNN architecture generation that allows RNNs of varying size and complexity and propose a ranking function that represents RNNs as recursive neural networks, simulating their performance to decide on the most promising architectures.",,,,
SkPoRg10b,2018,Reject,False,Rethinking generalization requires revisiting old ideas: statistical mechanics approaches and complex learning behavior,"[""Charles H. Martin"", ""Michael W. Mahoney""]",[],Rethinking generalization requires revisiting old ideas: statistical mechanics approaches and complex learning behavior,,,,
SkRsFSRpb,2018,Invite to Workshop Track,False,GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks,"[""Alessandro Bay"", ""Biswa Sengupta""]",[],,,,,
SkT5Yg-RZ,2018,Accept (Poster),False,Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play,"[""Sainbayar Sukhbaatar"", ""Zeming Lin"", ""Ilya Kostrikov"", ""Gabriel Synnaeve"", ""Arthur Szlam"", ""Rob Fergus""]","[""self-play"", ""automatic curriculum"", ""intrinsic motivation"", ""unsupervised learning"", ""reinforcement learning""]",Unsupervised learning for reinforcement learning using an automatic curriculum of self-play,,,,
SkUfhuFsvK-,2021,Reject,False,FASG: Feature Aggregation Self-training GCN for Semi-supervised Node Classification,"[""Gongpei Zhao"", ""Tao Wang"", ""Yidong Li"", ""Yi Jin""]",[],,,,,
SkVRTj0cYQ,2019,Reject,False,Differentially Private Federated Learning: A Client Level Perspective,"[""Robin C. Geyer"", ""Tassilo J. Klein"", ""Moin Nabi""]","[""Machine Learning"", ""Federated Learning"", ""Privacy"", ""Security"", ""Differential Privacy""]",Ensuring that models learned in federated fashion do not reveal a client's participation.,,,,
SkVe3iA9Ym,2019,Reject,False,Beyond Winning and Losing: Modeling Human Motivations and Behaviors with Vector-valued Inverse Reinforcement Learning,"[""Baoxiang Wang"", ""Tongfang Sun"", ""Xianjun Sam Zheng""]",[],,,,,
SkVhlh09tX,2019,Accept (Oral),False,Pay Less Attention with Lightweight and Dynamic Convolutions,"[""Felix Wu"", ""Angela Fan"", ""Alexei Baevski"", ""Yann Dauphin"", ""Michael Auli""]","[""Deep learning"", ""sequence to sequence learning"", ""convolutional neural networks"", ""generative models""]",Dynamic lightweight convolutions are competitive to self-attention on language tasks.,,,,
SkVqXOxCb,2018,Accept (Poster),False,Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields,"[""Thomas Unterthiner"", ""Bernhard Nessler"", ""Calvin Seward"", ""G\u00fcnter Klambauer"", ""Martin Heusel"", ""Hubert Ramsauer"", ""Sepp Hochreiter""]","[""Deep Learning"", ""Generative Adversarial Network"", ""GAN"", ""Generative Model"", ""Potential Field""]",Coulomb GANs can optimally learn a distribution by posing the distribution learning problem as optimizing a potential field,,,,
SkXIrV9le,2017,Invite to Workshop Track,False,Perception Updating Networks: On architectural constraints for interpretable video generative models,"[""Eder Santana"", ""Jose C Principe""]","[""Structured prediction"", ""Unsupervised Learning""]","Decoupled ""what"" and ""where"" variational statistical framework and equivalent multi-stream network ",,,,
SkYMnLxRW,2018,Reject,False,Weighted Transformer Network for Machine Translation,"[""Karim Ahmed"", ""Nitish Shirish Keskar"", ""Richard Socher""]","[""transformer"", ""branching"", ""attention"", ""machine translation""]",Using branched attention with learned combination weights outperforms the baseline transformer for machine translation tasks.,,,,
SkYXvCR6W,2018,Reject,False,Compact Encoding of Words for Efficient Character-level Convolutional Neural Networks Text Classification,"[""Wemerson Marinho"", ""Luis Marti"", ""Nayat Sanchez-pi""]","[""Character Level Convolutional Networks"", ""Text Classification"", ""Word Compressing""]",Using Compressing tecniques to Encoding of Words is a possibility for faster training of CNN and dimensionality reduction of representation,,,,
SkYbF1slg,2017,Accept (Poster),False,An Information-Theoretic Framework for Fast and Robust Unsupervised Learning via Neural Population Infomax,"[""Wentao Huang"", ""Kechen Zhang""]","[""Unsupervised Learning"", ""Theory"", ""Deep learning""]",We present a novel information-theoretic framework for fast and robust unsupervised Learning via information maximization for neural population coding.,,,,
SkYibHlRb,2018,Reject,False,SQLNet: Generating Structured Queries From Natural Language Without Reinforcement Learning,"[""Xiaojun Xu"", ""Chang Liu"", ""Dawn Song""]",[],,,,,
SkZ-BnyCW,2018,Reject,False,Learning Deep Generative Models With Discrete Latent Variables,"[""Hengyuan Hu"", ""Ruslan Salakhutdinov""]","[""deep generative models"", ""deep learning""]",,,,,
SkZxCk-0Z,2018,Accept (Poster),False,Can Neural Networks Understand Logical Entailment?,"[""Richard Evans"", ""David Saxton"", ""David Amos"", ""Pushmeet Kohli"", ""Edward Grefenstette""]","[""structure"", ""neural networks"", ""logic"", ""dataset""]",We introduce a new dataset of logical entailments for the purpose of measuring models' ability to capture and exploit the structure of logical expressions against an entailment prediction task.,,,,
SkaPsfZ0W,2018,Reject,False,Network of Graph Convolutional Networks Trained on Random Walks,"[""Sami Abu-El-Haija"", ""Amol Kapoor"", ""Bryan Perozzi"", ""Joonseok Lee""]","[""Graph Convolution"", ""Deep Learning"", ""Network of Networks""]","We make a network of Graph Convolution Networks, feeding each a different power of the adjacency matrix, combining all their representation into a classification sub-network, achieving state-of-the-art on semi-supervised node classification.",,,,
Skdvd2xAZ,2018,Accept (Poster),False,A Scalable Laplace Approximation for Neural Networks,"[""Hippolyt Ritter"", ""Aleksandar Botev"", ""David Barber""]","[""deep learning"", ""neural networks"", ""laplace approximation"", ""bayesian deep learning""]",We construct a Kronecker factored Laplace approximation for neural networks that leads to an efficient matrix normal distribution over the weights.,,,,
Ske-ih4FPS,2020,Reject,False,Unsupervised Few Shot Learning via Self-supervised Training,"[""Zilong Ji"", ""Xiaolong Zou"", ""Tiejun Huang"", ""Si Wu""]","[""few shot learning"", ""self-supervised learning"", ""meta-learning""]",,,,,
Ske1-209Y7,2019,Reject,False,Probabilistic Model-Based Dynamic Architecture Search,"[""Nozomu Yoshinari"", ""Kento Uchida"", ""Shota Saito"", ""Shinichi Shirakawa"", ""Youhei Akimoto""]","[""architecture search"", ""stochastic natural gradient"", ""convolutional neural networks""]",We present an efficient neural network architecture search method based on stochastic natural gradient method via probabilistic modeling.,,,,
Ske25sC9FQ,2019,Reject,False,Robustness and Equivariance of Neural Networks,"[""Amit Deshpande"", ""Sandesh Kamath"", ""K.V.Subrahmanyam""]","[""robust"", ""adversarial"", ""equivariance"", ""rotations"", ""GCNNs"", ""CNNs"", ""steerable"", ""neural networks""]",Robustness to rotations comes at the cost of robustness of pixel-wise adversarial perturbations.,,,,
Ske31kBtPr,2020,Accept (Talk),False,Mathematical Reasoning in Latent Space,"[""Dennis Lee"", ""Christian Szegedy"", ""Markus Rabe"", ""Sarah Loos"", ""Kshitij Bansal""]","[""machine learning"", ""formal reasoning""]",Learning to reason about higher order logic formulas in the latent space.,,,,
Ske5UANYDB,2020,Reject,True,Benefit of Interpolation in Nearest Neighbor Algorithms,"[""Yue Xing"", ""Qifan Song"", ""Guang Cheng""]","[""Data Interpolation"", ""Multiplicative Constant"", ""W-Shaped Double Descent"", ""Nearest Neighbor Algorithm""]",,1909.11720,stat.ML,2019-09-25 19:24:24+00:00,2019-09-25 19:24:24+00:00
Ske5r3AqK7,2019,Accept (Poster),False,Poincare Glove: Hyperbolic Word Embeddings,"[""Alexandru Tifrea*"", ""Gary Becigneul*"", ""Octavian-Eugen Ganea*""]","[""word embeddings"", ""hyperbolic spaces"", ""poincare ball"", ""hypernymy"", ""analogy"", ""similarity"", ""gaussian embeddings""]",We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.,,,,
Ske6qJSKPH,2020,Reject,False,Scheduling the Learning Rate Via Hypergradients: New Insights and a New Algorithm,"[""Michele Donini"", ""Luca Franceschi"", ""Orchid Majumder"", ""Massimiliano Pontil"", ""Paolo Frasconi""]","[""automl"", ""hyperparameter optimization"", ""learning rate"", ""deep learning""]",MARTHE: a new method to fit task-specific learning rate schedules from the perspective of hyperparameter optimization,,,,
Ske6wiAcKQ,2019,Reject,True,Real-time Neural-based Input Method,"[""Jiali Yao"", ""Raphael Shu"", ""Xinjian Li"", ""Katsutoshi Ohtsuki"", ""Hideki Nakayama""]","[""input method"", ""language model"", ""neural network"", ""softmax""]",,1810.09309,cs.CL,2018-10-19 12:57:37+00:00,2018-10-19 12:57:37+00:00
Ske7ToC5Km,2019,Reject,True,Graph2Seq: Scalable Learning Dynamics for Graphs,"[""Shaileshh Bojja Venkatakrishnan"", ""Mohammad Alizadeh"", ""Pramod Viswanath""]","[""graph neural networks"", ""scalable representations"", ""combinatorial optimization"", ""reinforcement learning""]","Today's neural networks for graphs do not generalize to graphs that are much bigger than the training graphs. We propose graph2seq, a method that represents vertices as time-series sequences instead of fixed-sized vectors for improved generalization.",1802.04948,cs.LG,2018-02-14 04:04:41+00:00,2018-10-09 15:00:04+00:00
Ske9VANKDH,2020,Reject,False,An Optimization Principle Of Deep Learning?,"[""Cheng Chen"", ""Junjie Yang"", ""Yi Zhou""]",[],,,,,
SkeATxrKwH,2020,Reject,True,"Generative Hierarchical Models for Parts, Objects, and Scenes","[""Fei Deng"", ""Zhuo Zhi"", ""Sungjin Ahn""]",[],,1910.09119,cs.LG,2019-10-21 02:28:16+00:00,2019-10-21 02:28:16+00:00
SkeAaJrKDS,2020,Accept (Poster),False,Combining Q-Learning and Search with Amortized Value Estimates,"[""Jessica B. Hamrick"", ""Victor Bapst"", ""Alvaro Sanchez-Gonzalez"", ""Tobias Pfaff"", ""Theophane Weber"", ""Lars Buesing"", ""Peter W. Battaglia""]","[""model-based RL"", ""Q-learning"", ""MCTS"", ""search""]","We propose a model-based method called ""Search with Amortized Value Estimates"" (SAVE) which leverages both real and planned experience by combining Q-learning with Monte-Carlo Tree Search, achieving strong performance with very small search budgets.",1912.02807,cs.LG,2019-12-05 18:54:23+00:00,2020-01-10 13:59:10+00:00
SkeBBJrFPH,2020,Reject,False,Characterize and Transfer Attention in Graph Neural Networks,"[""Mufei Li"", ""Hao Zhang"", ""Xingjian Shi"", ""Minjie Wang"", ""Yixing Guan"", ""Zheng Zhang""]","[""Graph Neural Networks"", ""Graph Attention Networks"", ""Attention"", ""Transfer Learning"", ""Empirical Study""]",An analytic paradigm for studying attention in graph neural networks and an approach to perform transfer learning for graph sparsification,,,,
SkeFl1HKwr,2020,Accept (Poster),False,Empirical Studies on the Properties of Linear Regions in Deep Neural Networks,"[""Xiao Zhang"", ""Dongrui Wu""]","[""deep learning"", ""linear region"", ""optimization""]",,2001.01072,cs.LG,2020-01-04 12:47:58+00:00,2020-04-28 19:08:06+00:00
SkeGvaEtPr,2020,Reject,False,Neural Markov Logic Networks,"[""Giuseppe Marra"", ""Ond\u0159ej Ku\u017eelka""]","[""Statistical Relational Learning"", ""Markov Logic Networks""]", We introduce a statistical relational learning system that borrows ideas from Markov logic but learns an implicit representation of rules as a neural network.,,,,
SkeHuCVFDr,2020,Accept (Poster),False,BERTScore: Evaluating Text Generation with BERT,"[""Tianyi Zhang*"", ""Varsha Kishore*"", ""Felix Wu*"", ""Kilian Q. Weinberger"", ""Yoav Artzi""]","[""Metric"", ""Evaluation"", ""Contextual Embedding"", ""Text Generation""]","We propose BERTScore, an automatic evaluation metric for text generation, which correlates better with human judgments and provides stronger model selection performance than existing metrics.",,,,
SkeIyaVtwB,2020,Accept (Poster),False,Exploration in Reinforcement Learning with Deep Covering Options,"[""Yuu Jinnai"", ""Jee Won Park"", ""Marlos C. Machado"", ""George Konidaris""]","[""Reinforcement learning"", ""temporal abstraction"", ""exploration""]",We introduce a method to automatically discover task-agnostic options that encourage exploration for reinforcement learning.,,,,
SkeJ6iR9Km,2019,Reject,False,Variational Sparse Coding,"[""Francesco Tonolini"", ""Bjorn Sand Jensen"", ""Roderick Murray-Smith""]","[""Variational Auto-Encoders"", ""Sparse Coding"", ""Variational Inference""]",We explore the intersection of VAEs and sparse coding.,,,,
SkeJPertPS,2020,Reject,False,Collaborative Training of Balanced Random Forests for Open Set Domain Adaptation,"[""Jongbin Ryu"", ""Jiun Bae"", ""Jongwoo Lim""]",[],,2002.03642,cs.CV,2020-02-10 10:43:20+00:00,2020-02-10 10:43:20+00:00
SkeK3s0qKQ,2019,Accept (Poster),False,Episodic Curiosity through Reachability,"[""Nikolay Savinov"", ""Anton Raichuk"", ""Damien Vincent"", ""Raphael Marinier"", ""Marc Pollefeys"", ""Timothy Lillicrap"", ""Sylvain Gelly""]","[""deep learning"", ""reinforcement learning"", ""curiosity"", ""exploration"", ""episodic memory""]","We propose a novel model of curiosity based on episodic memory and the ideas of reachability which allows us to overcome the known ""couch-potato"" issues of prior work.",,,,
SkeKtyHYPS,2020,Reject,False,Data Augmentation in Training CNNs: Injecting Noise to Images,"[""Murtaza Eren Akbiyik""]","[""deep learning"", ""data augmentation"", ""convolutional neural networks"", ""noise"", ""image processing"", ""SSIM""]",Ideal methodology to inject noise to input data during CNN training,,,,
SkeL6sCqK7,2019,Reject,False,REPRESENTATION COMPRESSION AND GENERALIZATION IN DEEP NEURAL NETWORKS,"[""Ravid Shwartz-Ziv"", ""Amichai Painsky"", ""Naftali Tishby""]","[""Deep neural network"", ""information theory"", ""training dynamics""]",Introduce an information theoretic viewpoint on the behavior of deep networks optimization processes and their generalization abilities,,,,
SkeNlJSKvS,2020,Reject,False,Shallow VAEs with RealNVP Prior Can Perform as Well as Deep Hierarchical VAEs,"[""Haowen Xu"", ""Wenxiao Chen"", ""Jinlin Lai"", ""Zhihan Li"", ""Youjian Zhao"", ""Dan Pei""]","[""Variational Auto-encoder"", ""RealNVP"", ""learnable prior""]","We show that VAE with learned RealNVP prior and just one latent variable can have better test NLLs than some deep hierarchical VAEs with powerful posteriors, on several datasets.",,,,
SkeP3yBFDS,2020,Reject,False,Reducing Computation in Recurrent Networks by Selectively Updating State Neurons,"[""Thomas Hartvigsen"", ""Cansu Sen"", ""Xiangnan Kong"", ""Elke Rundensteiner""]","[""recurrent neural networks"", ""conditional computation"", ""representation learning""]",We show that conditionally computing individual dimensions of an RNN's hidden state depending on input data at each time step from scratch with no assumptions leads to higher accuracy with far fewer computations than state-of-the-art approach.,,,,
SkeQniAqK7,2019,Reject,False,Combining Learned Representations for Combinatorial Optimization,"[""Saavan Patel"", ""Sayeef Salahuddin""]","[""Generative Models"", ""Restricted Boltzmann Machines"", ""Transfer Learning"", ""Compositional Learning""]",We use combinations of RBMs to solve number factorization and combinatorial optimization problems.,,,,
SkeRTsAcYm,2019,Accept (Poster),False,Phase-Aware Speech Enhancement with Deep Complex U-Net,"[""Hyeong-Seok Choi"", ""Jang-Hyun Kim"", ""Jaesung Huh"", ""Adrian Kim"", ""Jung-Woo Ha"", ""Kyogu Lee""]","[""speech enhancement"", ""deep learning"", ""complex neural networks"", ""phase estimation""]",This paper proposes a novel complex masking method for speech enhancement along with a loss function for efficient phase estimation.,,,,
SkeUG30cFQ,2019,Reject,False,The Expressive Power of Deep Neural Networks with Circulant Matrices,"[""Alexandre Araujo"", ""Benjamin Negrevergne"", ""Yann Chevaleyre"", ""Jamal Atif""]","[""deep learning"", ""circulant matrices"", ""universal approximation""]",We provide a theoretical study of the properties of Deep circulant-diagonal ReLU Networks and demonstrate that they are bounded width universal approximators.,,,,
SkeVsiAcYm,2019,Accept (Poster),False,Generative predecessor models for sample-efficient imitation learning,"[""Yannick Schroecker"", ""Mel Vecerik"", ""Jon Scholz""]","[""Imitation Learning"", ""Generative Models"", ""Deep Learning""]",,,,,
SkeWc2EKPH,2020,Reject,False,Model-free Learning Control of Nonlinear Stochastic Systems with Stability Guarantee,"[""Minghao Han"", ""Yuan Tian"", ""Lixian Zhang"", ""Jun Wang"", ""Wei Pan""]","[""Reinforcement learning"", ""nonlinear stochastic system"", ""Lyapunov""]",A stability guaranteed reinforcement learning framework for the stabilization and tracking problems in discrete-time nonlinear stochastic systems,,,,
SkeXL0NKwH,2020,Reject,False,Low Rank Training of Deep Neural Networks for Emerging Memory Technology,"[""Albert Gural"", ""Phillip Nadeau"", ""Mehul Tikekar"", ""Boris Murmann""]","[""low rank training"", ""kronecker sum"", ""emerging memory"", ""non-volatile memory"", ""rram"", ""reram"", ""federated learning""]",We use Kronecker sum approximations for low-rank training to address challenges in training neural networks on edge devices that utilize emerging memory technologies.,2009.03887,cs.LG,2020-09-08 17:59:56+00:00,2021-07-15 03:06:18+00:00
SkeXehR9t7,2019,Reject,False,Graph2Seq: Graph to Sequence Learning with Attention-Based Neural Networks,"[""Kun Xu"", ""Lingfei Wu"", ""Zhiguo Wang"", ""Yansong Feng"", ""Michael Witbrock"", ""Vadim Sheinin""]","[""Graph Encoder"", ""Graph Decoder"", ""Graph2Seq"", ""Graph Attention""]",Graph to Sequence Learning with Attention-Based Neural Networks,,,,
SkeYUkStPr,2020,Reject,False,Deep Lifetime Clustering,"[""S Chandra Mouli"", ""Leonardo Teixeira"", ""Jennifer Neville"", ""Bruno Ribeiro""]","[""Lifetime Clustering"", ""Deep Learning"", ""Survival Distributions"", ""Kuiper two-sample test""]",We propose a neural network based lifetime clustering model that maximizes divergence between empirical lifetime distributions of clusters.,,,,
SkeZisA5t7,2019,Accept (Poster),False,Adaptive Estimators Show Information Compression in Deep Neural Networks,"[""Ivan Chelombiev"", ""Conor Houghton"", ""Cian O'Donnell""]","[""deep neural networks"", ""mutual information"", ""information bottleneck"", ""noise"", ""L2 regularization""]",We developed robust mutual information estimates for DNNs and used them to observe compression in networks with non-saturating activation functions,,,,
Sked_0EYwB,2020,Reject,False,Objective Mismatch in Model-based Reinforcement Learning,"[""Nathan Lambert"", ""Brandon Amos"", ""Omry Yadan"", ""Roberto Calandra""]","[""Model-based Reinforcement learning"", ""dynamics model"", ""reinforcement learning""]","We define, explore, and begin to address the objective mismatch issue in model-based reinforcement learning.",2002.04523,cs.LG,2020-02-11 16:26:07+00:00,2021-04-19 03:02:59+00:00
Skeh-xBYDH,2020,Reject,True,On Symmetry and Initialization for Neural Networks,"[""Ido Nachum"", ""Amir Yehudayoff""]","[""Neural Network Theory"", ""Symmetry""]","When initialized properly, neural networks can learn the simple class of symmetric functions; when initialized randomly, they fail.  ",1907.00560,cs.LG,2019-07-01 06:03:05+00:00,2019-07-01 06:03:05+00:00
Skeh1krtvH,2020,Reject,False,WaveFlow: A Compact Flow-based Model for Raw Audio,"[""Wei Ping"", ""Kainan Peng"", ""Kexin Zhao"", ""Zhao Song""]","[""flow-based models"", ""raw audio"", ""waveforms"", ""speech synthesis"", ""generative models""]",,1912.01219,cs.SD,2019-12-03 07:00:13+00:00,2020-06-24 20:10:12+00:00
SkejkR4KDr,2020,Reject,False,Layer Flexible Adaptive Computation Time for Recurrent Neural Networks,"[""Lida Zhang"", ""Diego Klabjan""]",[],,,,,
Skek-TVYvr,2020,Reject,False,A Uniform Generalization Error Bound for Generative Adversarial Networks,"[""Hao Chen"", ""Zhanfeng Mo"", ""Qingyi Gao"", ""Zhouwang Yang"", ""Xiao Wang""]","[""GANs"", ""Uniform Generalization Bound"", ""Deep Learning"", ""Weight normalization""]",This theoretical issue establishes a uniform generalization error bound on GANs.,,,,
Skeke3C5Fm,2019,Accept (Poster),False,Multilingual Neural Machine Translation With Soft Decoupled Encoding,"[""Xinyi Wang"", ""Hieu Pham"", ""Philip Arthur"", ""Graham Neubig""]",[],,,,,
SkelJnRqt7,2019,Reject,False,Neural separation of observed and unobserved distributions,"[""Tavi Halperin"", ""Ariel Ephrat"", ""Yedid Hoshen""]","[""source separation"", ""non-adversarial training"", ""source unmixing"", ""iterative neural training"", ""generative modeling""]",An iterative neural method for extracting signals that are only observed mixed with other signals,,,,
SkenUj0qYm,2019,Reject,False,Semi-supervised Learning with Multi-Domain Sentiment Word Embeddings,"[""Ran Tian"", ""Yash Agrawal"", ""Kento Watanabe"", ""Hiroya Takamura""]",[],,,,,
Skep6TVYDB,2020,Accept (Spotlight),False,Gradientless Descent: High-Dimensional Zeroth-Order Optimization,"[""Daniel Golovin"", ""John Karro"", ""Greg Kochanski"", ""Chansoo Lee"", ""Xingyou Song"", ""Qiuyi Zhang""]","[""Zeroth Order Optimization""]",Gradientless Descent is a provably efficient gradient-free algorithm that is monotone-invariant and fast for high-dimensional zero-th order optimization.,1911.06317,cs.LG,2019-11-14 18:58:13+00:00,2020-05-18 20:08:57+00:00
Skeq30NFPr,2020,Reject,True,Stochastic Mirror Descent on Overparameterized Nonlinear Models,"[""Navid Azizan"", ""Sahin Lale"", ""Babak Hassibi""]","[""deep learning"", ""optimization"", ""overparameterized"", ""stochastic gradient descent"", ""mirror descent""]",,1906.03830,cs.LG,2019-06-10 08:01:27+00:00,2019-06-10 08:01:27+00:00
Skerzp4KPS,2020,Reject,False,Adaptive Data Augmentation with Deep Parallel Generative Models,"[""Boli Fang"", ""Miao Jiang"", ""Abhirag Nagpure"", ""Jerry Shen""]",[],We propose an adaptive DA strategy based on generative models that improves model performances across machine learning and computer vision tasks.,,,,
SkeuexBtDr,2020,Accept (Spotlight),False,Learning from Rules Generalizing Labeled Exemplars,"[""Abhijeet Awasthi"", ""Sabyasachi Ghosh"", ""Rasna Goyal"", ""Sunita Sarawagi""]","[""Learning from Rules"", ""Learning from limited labeled data"", ""Weakly Supervised Learning""]",Coupled rule-exemplar supervision and a implication loss helps to jointly learn to denoise rules and imply labels.,2004.06025,cs.LG,2020-04-13 15:57:54+00:00,2020-05-15 15:56:59+00:00
SkeuipVKDH,2020,Reject,False,RTC-VAE: HARNESSING THE PECULIARITY OF TOTAL CORRELATION  IN LEARNING DISENTANGLED REPRESENTATIONS,"[""Ze Cheng"", ""Juncheng B Li"", ""Chenxu Wang"", ""Jixuan Gu"", ""Hao Xu"", ""Xinjian Li"", ""Florian Metze""]","[""Total Correlation"", ""VAEs"", ""Disentanglement""]",diagnosed all the problem of STOA VAEs theoretically and qualitatively,,,,
SkevphEYPB,2020,Reject,False,POP-Norm: A Theoretically Justified and More Accelerated Normalization Approach,"[""Hanyang Peng"", ""Shiqi Yu""]","[""Batch Normalization"", ""Optimization"", ""Accelerate Training""]",,,,,
SkexNpNFwS,2020,Reject,True,Potential Flow Generator with $L_2$ Optimal Transport Regularity for Generative Models,"[""Liu Yang"", ""George Em Karniadakis""]","[""generative models"", ""optimal transport"", ""GANs"", ""flow-based models""]","We propose a special generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models.",1908.11462,cs.LG,2019-08-29 22:00:49+00:00,2019-08-29 22:00:49+00:00
Skey4eBYPS,2020,Accept (Talk),False,Convolutional Conditional Neural Processes,"[""Jonathan Gordon"", ""Wessel P. Bruinsma"", ""Andrew Y. K. Foong"", ""James Requeima"", ""Yann Dubois"", ""Richard E. Turner""]","[""Neural Processes"", ""Deep Sets"", ""Translation Equivariance""]",We extend deep sets to functional embeddings and Neural Processes to include translation equivariant members,,,,
SkeyppEFvS,2020,Accept (Spotlight),True,CoPhy: Counterfactual Learning of Physical Dynamics,"[""Fabien Baradel"", ""Natalia Neverova"", ""Julien Mille"", ""Greg Mori"", ""Christian Wolf""]","[""intuitive physics"", ""visual reasoning""]",,1909.12000,cs.CV,2019-09-26 09:34:48+00:00,2020-04-07 12:48:26+00:00
SkezP1HYvS,2020,Reject,False,Diagonal Graph Convolutional Networks with Adaptive Neighborhood Aggregation,"[""Jie Zhang"", ""Yuxiao Dong"", ""Jie Tang""]","[""data mining"", ""graph convolutional networks""]",,,,,
Skf-oo0qt7,2019,Reject,False,On Generalization Bounds of a Family of Recurrent Neural Networks,"[""Minshuo Chen"", ""Xingguo Li"", ""Tuo Zhao""]","[""Recurrent Neural Networks"", ""MGU"", ""LSTM"", ""Generalization Bound"", ""PAC-Learning""]",,,,,
SkfMWhAqYQ,2019,Accept (Poster),False,Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet,"[""Wieland Brendel"", ""Matthias Bethge""]","[""interpretability"", ""representation learning"", ""bag of features"", ""deep learning"", ""object recognition""]","Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.",,,,
SkfNU2e0Z,2018,Reject,False,Statestream: A toolbox to explore layerwise-parallel deep neural networks,"[""Volker Fischer""]","[""model-parallel"", ""parallelization"", ""software platform""]","We define a concept of layerwise model-parallel deep neural networks, for which layers operate in parallel, and provide a toolbox to design, train, evaluate, and on-line interact with these networks.",,,,
SkfTIj0cKX,2019,Reject,False,Purchase as Reward : Session-based  Recommendation by Imagination Reconstruction,"[""Qibing Li"", ""Xiaolin Zheng""]","[""recommender systems"", ""reinforcement learning"", ""predictive learning"", ""self-supervised RL"", ""model-based planning""]",We propose the IRN architecture to augment sparse and delayed purchase reward for session-based recommendation.,,,,
SkffVjUaW,2018,Reject,False,Building effective deep neural networks one feature at a time,"[""Martin Mundt"", ""Tobias Weis"", ""Kishore Konda"", ""Visvanathan Ramesh""]","[""convolution neural networks"", ""architecture search"", ""meta-learning"", ""representational capacity""]",A bottom-up algorithm that expands CNNs starting with one feature per layer to architectures with sufficient representational capacity.,,,,
SkfhIo0qtQ,2019,Reject,False,Volumetric Convolution: Automatic Representation Learning in Unit Ball,"[""Sameera Ramasinghe"", ""Salman Khan"", ""Nick Barnes""]","[""convolution"", ""unit sphere"", ""3D object recognition""]",A novel convolution operator for automatic representation learning inside unit ball,,,,
SkfrvsA9FX,2019,Accept (Poster),False,Reward Constrained Policy Optimization,"[""Chen Tessler"", ""Daniel J. Mankowitz"", ""Shie Mannor""]","[""reinforcement learning"", ""markov decision process"", ""constrained markov decision process"", ""deep learning""]","For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.",,,,
Skg2pkHFwS,2020,Reject,False,Emergence of Collective Policies Inside Simulations with Biased Representations,"[""Jooyeon Kim"", ""Alice Oh""]","[""collective policy"", ""biased representation"", ""model-based RL"", ""simulation"", ""imagination"", ""virtual environment""]",We propose learning of the collective policy solely in simulation so that agents' biases (analoguous to human's cognitive biases) are complemented by one another. ,,,,
Skg3104FDS,2020,Reject,False,First-Order Preconditioning via Hypergradient Descent,"[""Ted Moskovitz"", ""Rui Wang"", ""Janice Lan"", ""Sanyam Kapoor"", ""Thomas Miconi"", ""Jason Yosinski"", ""Aditya Rawal""]","[""optimization"", ""deep learning"", ""hypgergradient""]",We introduce a computationally-efficient method for learning a preconditioning matrix for optimization via hypergradient descent.,,,,
Skg5r1BFvB,2020,Reject,False,"Continuous Control with Contexts, Provably","[""Simon Du"", ""Mengdi Wang"", ""Ruosong Wang"", ""Lin F. Yang""]","[""continuous control"", ""learning"", ""context""]",We give a provably efficient algorithm for linear quadratic regulator with contexts.,,,,
Skg8gJBFvr,2020,Reject,False,Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing,"[""Dinghuai Zhang*"", ""Mao Ye*"", ""Chengyue Gong*"", ""Zhanxing Zhu"", ""Qiang Liu""]","[""Adversarial Certification"", ""Randomized Smoothing"", ""Functional Optimization""]","We improve existing certification results with a new certification framework by reformulating the original problem to a functional optimization one, and design a new distribution family which suits this task better through this framework.",,,,
Skg9aAEKwH,2020,Reject,True,Visual Hide and Seek,"[""Boyuan Chen"", ""Shuran Song"", ""Hod Lipson"", ""Carl Vondrick""]","[""Embodied Learning"", ""Self-supervised Learning"", ""Reinforcement Learning""]","We train an agent to hide from a predator, and experiments suggest useful representations emerge.",1910.07882,cs.AI,2019-10-15 01:27:09+00:00,2019-10-15 01:27:09+00:00
Skg9jnVFvH,2020,Reject,False,Progressive Upsampling Audio Synthesis via Effective Adversarial Training,"[""Youngwoo Cho"", ""Minwook Chang"", ""Gerard Jounghyun Kim"", ""Jaegul Choo""]","[""audio synthesis"", ""sound effect generation"", ""generative adversarial network"", ""progressive training"", ""raw-waveform""]","We proposed a novel raw-waveform generation method, which uses only 5% of the parameters of the existing model while maintaining the output quality.",,,,
SkgC6TNFvr,2020,Accept (Poster),False,Reinforced active learning for image segmentation,"[""Arantxa Casanova"", ""Pedro O. Pinheiro"", ""Negar Rostamzadeh"", ""Christopher J. Pal""]","[""semantic segmentation"", ""active learning"", ""reinforcement learning""]",Learning a labeling policy with reinforcement learning to reduce labeling effort for the task of semantic segmentation,2002.06583,cs.CV,2020-02-16 14:03:06+00:00,2020-02-16 14:03:06+00:00
SkgCV205tQ,2019,Reject,False,Accelerating first order optimization algorithms,"[""Ange tato"", ""Roger nkambou""]","[""Optimization"", ""Optimizer"", ""Adam"", ""Gradient Descent""]",,,,,
SkgE8sRcK7,2019,Reject,False,Sample Efficient Deep Neuroevolution in Low Dimensional Latent Space,"[""Bin Zhou"", ""Jiashi Feng""]","[""Neuroevolution"", ""Reinforcement Learning""]",,,,,
SkgEaj05t7,2019,Accept (Poster),False,On the Relation Between the Sharpest Directions of DNN Loss and the SGD Step Length,"[""Stanis\u0142aw Jastrz\u0119bski"", ""Zachary Kenton"", ""Nicolas Ballas"", ""Asja Fischer"", ""Yoshua Bengio"", ""Amos Storkey""]","[""optimization"", ""generalization"", ""theory of deep learning"", ""SGD"", ""hessian""]","SGD is steered early on in training towards a region in which its step is too large compared to curvature, which impacts the rest of training. ",,,,
SkgGCkrKvH,2020,Accept (Poster),False,Decentralized Deep Learning with Arbitrary Communication Compression,"[""Anastasia Koloskova*"", ""Tao Lin*"", ""Sebastian U Stich"", ""Martin Jaggi""]",[],"We propose Choco-SGD---decentralized SGD with compressed communication---for non-convex objectives and show its strong performance in various deep learning applications (on-device learning, datacenter case).",,,,
SkgGjRVKDS,2020,Accept (Poster),False,Towards Stabilizing Batch Statistics in Backward Propagation of Batch Normalization,"[""Junjie Yan"", ""Ruosi Wan"", ""Xiangyu Zhang"", ""Wei Zhang"", ""Yichen Wei"", ""Jian Sun""]","[""batch normalization"", ""small batch size"", ""backward propagation""]",We propose a novel normalization method to handle small batch size cases.,2001.06838,cs.CV,2020-01-19 14:41:22+00:00,2020-04-08 10:06:09+00:00
SkgJOAEtvr,2020,Reject,False,INTERNAL-CONSISTENCY CONSTRAINTS FOR EMERGENT COMMUNICATION,"[""Charles Lovering"", ""Ellie Pavlick""]","[""Emergent Communication"", ""Speaker-Listener Models""]",Internal-consistency constraints improve agents ability to develop emergent protocols that generalize across communicative roles.,,,,
SkgKO0EtvS,2020,Accept (Poster),True,Neural Execution of Graph Algorithms,"[""Petar Veli\u010dkovi\u0107"", ""Rex Ying"", ""Matilde Padovano"", ""Raia Hadsell"", ""Charles Blundell""]","[""Graph Neural Networks"", ""Graph Algorithms"", ""Learning to Execute"", ""Program Synthesis"", ""Message Passing Neural Networks"", ""Deep Learning""]","We supervise graph neural networks to imitate intermediate and step-wise outputs of classical graph algorithms, recovering highly favourable insights.",1910.10593,stat.ML,2019-10-23 14:50:45+00:00,2020-01-15 16:47:33+00:00
SkgKzh0cY7,2019,Reject,False,Unsupervised Video-to-Video Translation,"[""Dina Bashkirova"", ""Ben Usman"", ""Kate Saenko""]","[""Generative Adversarial Networks"", ""Computer Vision"", ""Deep Learning""]","Proposed new task, datasets and baselines; 3D Conv CycleGAN preserves object properties across frames; batch structure in frame-level methods matters.",,,,
SkgODpVFDr,2020,Reject,False,Incorporating Horizontal Connections in Convolution by Spatial Shuffling,"[""Ikki Kishida"", ""Hideki Nakayama""]","[""shuffle"", ""convolution"", ""receptive field"", ""classification"", ""horizontal connections""]",We propose spatially shuffled convolution that the regular convolution incorporates the information from outside of its receptive field.,,,,
SkgOzlrKvH,2020,Reject,True,The Role of Embedding Complexity in Domain-invariant Representations,"[""Ching-Yao Chuang"", ""Antonio Torralba"", ""Stefanie Jegelka""]","[""domain adaptation"", ""domain-invariant representations"", ""model complexity"", ""theory"", ""deep learning""]",We study the effect of the embedding complexity in learning domain-invariant representations and develop a strategy that mitigates sensitivity to it.,1910.05804,cs.LG,2019-10-13 18:20:25+00:00,2019-10-13 18:20:25+00:00
SkgQBn0cF7,2019,Accept (Poster),False,Modeling the Long Term Future in Model-Based Reinforcement Learning,"[""Nan Rosemary Ke"", ""Amanpreet Singh"", ""Ahmed Touati"", ""Anirudh Goyal"", ""Yoshua Bengio"", ""Devi Parikh"", ""Dhruv Batra""]","[""model-based reinforcement learning"", ""variation inference""]","incorporating, in the model, latent variables that encode future content improves the long-term prediction accuracy, which is critical for better planning in model-based RL.",1903.01599,stat.ML,2019-03-05 00:15:21+00:00,2019-03-16 17:10:08+00:00
SkgQwpVYwH,2020,Reject,False,"Credible Sample Elicitation by Deep Learning, for Deep Learning","[""Yang Liu"", ""Zuyue Fu"", ""Zhuoran Yang"", ""Zhaoran Wang""]",[],This paper proposes a deep learning aided method to elicit credible samples from self-interested agents. ,,,,
SkgRW64twr,2020,Reject,False,Deep Multi-View Learning via Task-Optimal CCA,"[""Heather D. Couture"", ""Roland Kwitt"", ""J.S. Marron"", ""Melissa Troester"", ""Charles M. Perou"", ""Marc Niethammer""]","[""multi-view"", ""components analysis"", ""CCA"", ""representation learning"", ""deep learning""]","Learn a projection to a shared latent space that is also discriminative, improving cross-view classification, regularization with a second view during training, and multi-view prediction.",,,,
SkgS2lBFPS,2020,Reject,False,A Bilingual Generative Transformer for Semantic Sentence Embedding,"[""John Wieting"", ""Graham Neubig"", ""Taylor Berg-Kirkpatrick""]","[""sentence embedding"", ""semantic similarity"", ""multilingual"", ""latent variables"", ""vae""]",,1911.03895,cs.CL,2019-11-10 10:48:09+00:00,2020-11-19 17:21:10+00:00
SkgSXUKxx,2017,Reject,False,An Analysis of Feature Regularization for Low-shot Learning,"[""Zhuoyuan Chen"", ""Han Zhao"", ""Xiao Liu"", ""Wei Xu""]","[""Deep learning"", ""Computer vision""]",An analysis of adding regularization for low-shot learning,,,,
SkgTR3VFvH,2020,Reject,False,Pipelined Training with Stale Weights of Deep Convolutional Neural Networks,"[""Lifu Zhang"", ""Tarek S. Abdelrahman""]","[""Distributed CNN Training"", ""Pipelined Backpropagation"", ""Training with Stale Weights""]",Accelerating CNN training on a Pipeline of Accelerators with Stale Weights,1912.12675,cs.DC,2019-12-29 15:28:13+00:00,2019-12-29 15:28:13+00:00
SkgToo0qFm,2019,Reject,False,Transferrable End-to-End Learning for Protein Interface Prediction,"[""Raphael J. L. Townshend"", ""Rishi Bedi"", ""Ron O. Dror""]","[""transfer learning"", ""protein interface prediction"", ""deep learning"", ""structural biology""]",We demonstrate the first successful application of transfer learning to atomic-level data in order to build a state-of-the-art end-to-end learning model for the protein interface prediction problem.,,,,
SkgVRiC9Km,2019,Reject,False,Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations,"[""Alex Lamb"", ""Jonathan Binas"", ""Anirudh Goyal"", ""Dmitriy Serdyuk"", ""Sandeep Subramanian"", ""Ioannis Mitliagkas"", ""Yoshua Bengio""]","[""adversarial examples"", ""adversarial training"", ""autoencoders"", ""hidden state""]",Better adversarial training by learning to map back to the data manifold with autoencoders in the hidden states.  ,,,,
SkgWIxSFvr,2020,Reject,False,FLAT MANIFOLD VAES,"[""Nutan Chen"", ""Alexej Klushyn"", ""Francesco Ferroni"", ""Justin Bayer"", ""Patrick van der Smagt""]",[],,,,,
SkgWeJrYwr,2020,Reject,False,Efficient Wrapper Feature Selection using Autoencoder and Model Based Elimination,"[""Sharan Ramjee"", ""Aly El Gamal""]","[""Wrapper Feature Selection"", ""AMBER"", ""Ranker Model"", ""Generative Training"", ""Wireless Subsampling""]",,,,,
SkgZNnR5tX,2019,Reject,False,Uncovering Surprising Behaviors in Reinforcement Learning via Worst-case Analysis,"[""Avraham Ruderman"", ""Richard Everett"", ""Bristy Sikder"", ""Hubert Soyer"", ""Jonathan Uesato"", ""Ananya Kumar"", ""Charlie Beattie"", ""Pushmeet Kohli""]","[""Reinforcement learning"", ""Adversarial examples"", ""Navigation"", ""Evaluation"", ""Analysis""]",We find environment settings in which SOTA agents trained on navigation tasks display extreme failures suggesting failures in generalization.,,,,
Skgaia4tDH,2020,Reject,False,Localized Generations with Deep Neural Networks for Multi-Scale Structured Datasets,"[""Yoshihiro Nagano"", ""Shiro Takagi"", ""Yuki Yoshida"", ""Masato Okada""]","[""Variational autoencoder"", ""Local learning"", ""Model-agnostic meta-learning"", ""Disentangled representation""]",Generalized Variational Autoencoder to be applicable to the dataset with local structure while keeping to avoid a heavy computation by the meta-learning with structural similarity assumption.,,,,
Skgb5h4KPH,2020,Reject,True,Frequency Principle: Fourier Analysis Sheds Light on Deep Neural Networks,"[""Zhi-Qin John Xu"", ""Yaoyu Zhang"", ""Tao Luo"", ""Yanyang Xiao"", ""Zheng Ma""]","[""deep learning"", ""training behavior"", ""Fourier analysis"", ""generalization""]","In real problems, we found that DNNs often fit target functions from low to high frequencies during the training process.",1901.06523,cs.LG,2019-01-19 13:37:39+00:00,2019-09-20 07:39:43+00:00
SkgbmyHFDS,2020,Reject,False,What Can Learned Intrinsic Rewards Capture?,"[""Zeyu Zheng"", ""Junhyuk Oh"", ""Matteo Hessel"", ""Zhongwen Xu"", ""Manuel Kroiss"", ""Hado van Hasselt"", ""David Silver"", ""Satinder Singh""]","[""reinforcement learning"", ""deep reinforcement learning"", ""intrinsic movitation""]",,,,,
Skgeip4FPr,2020,Reject,False,Neural networks are a priori biased towards Boolean functions with low entropy,"[""Chris Mingard"", ""Joar Skalse"", ""Guillermo Valle-P\u00e9rez"", ""David Mart\u00ednez-Rubio"", ""Vladimir Mikulik"", ""Ard A. Louis""]","[""class imbalance"", ""perceptron"", ""inductive bias"", ""simplicity bias"", ""initialization""]","We show that neural networks are biased towards functions with high class imbalance (low entropy) at initialization; we prove the exact form of the bias for the perceptron, and some properties for multi-layer networks",,,,
SkgewU5ll,2017,Reject,False,GRAM: Graph-based Attention Model for Healthcare Representation Learning,"[""Edward Choi"", ""Mohammad Taha Bahadori"", ""Le Song"", ""Walter F. Stewart"", ""Jimeng Sun""]","[""Deep learning"", ""Applications""]",We propose a novel attention mechanism on graphs to learn representations for medical concepts from both data and medical ontologies to cope with insufficient data volume.,,,,
Skgfr1rYDH,2020,Reject,False,SoftAdam: Unifying SGD and Adam for better stochastic gradient descent,"[""Abraham J. Fetterman"", ""Christina H. Kim"", ""Joshua Albrecht""]","[""Optimization"", ""SGD"", ""Adam"", ""Generalization"", ""Deep Learning""]",An algorithm for unifying SGD and Adam and empirical study of its performance,,,,
Skgge3R9FQ,2019,Reject,False,Controlling Over-generalization and its Effect on Adversarial Examples Detection and Generation,"[""Mahdieh Abbasi"", ""Arezoo Rajabi"", ""Azadeh Sadat Mozafari"", ""Rakesh B. Bobba"", ""Christian Gagn\u00e9""]","[""Convolutional Neural Networks"", ""Adversarial Instances"", ""Out-distribution Samples"", ""Rejection Option"", ""Over-generalization""]",Properly training CNNs with dustbin class increase their robustness to adversarial attacks and their capacity to deal with out-distribution samples.,,,,
SkghBoR5FX,2019,Reject,False,Adversarial Attacks for Optical Flow-Based Action Recognition Classifiers,"[""Nathan Inkawhich"", ""Matthew Inkawhich"", ""Hai Li"", ""Yiran Chen""]","[""adversarial attacks"", ""action recognition"", ""video classification""]",The paper describes adversarial attacks for action recognition classifiers that explicitly attack along the time dimension.,,,,
SkghN205KQ,2019,Reject,False,"Search-Guided, Lightly-supervised Training of  Structured Prediction Energy Networks","[""Amirmohammad Rooshenas"", ""Dongxu Zhang"", ""Gopal Sharma"", ""Andrew McCallum""]","[""structured prediction energy networks"", ""indirect supervision"", ""search-guided training"", ""reward functions""]",,1812.09603,cs.LG,2018-12-22 21:06:02+00:00,2019-11-11 17:36:24+00:00
SkgiX2Aqtm,2019,Reject,False,PIE: Pseudo-Invertible Encoder,"[""Jan Jetze Beitler"", ""Ivan Sosnovik"", ""Arnold Smeulders""]","[""Invertible Mappings"", ""Bijectives"", ""Dimensionality reduction"", ""Autoencoder""]",New Class of Autoencoders with pseudo invertible architecture,,,,
SkgjKR4YwH,2020,Reject,False,MixUp as Directional Adversarial Training,"[""Guillaume Perrault-Archambault"", ""Yongyi Mao"", ""Hongyu Guo"", ""Richong Zhang""]","[""MixUp"", ""Adversarial Training"", ""Untied MixUp""]","We present a novel interpretation of MixUp as belonging to a class highly analogous to adversarial training, and on this basis we introduce a simple generalization which outperforms MixUp",,,,
SkgkJn05YX,2019,Reject,False,RANDOM MASK: Towards Robust Convolutional Neural Networks,"[""Tiange Luo"", ""Tianle Cai"", ""Mengxiao Zhang"", ""Siyu Chen"", ""Liwei Wang""]","[""adversarial examples"", ""robust machine learning"", ""cnn structure"", ""metric"", ""deep feature representations""]","We propose a technique that modifies CNN structures to enhance robustness while keeping high test accuracy, and raise doubt on whether current definition of adversarial examples is appropriate by generating adversarial examples able to fool humans.",,,,
SkglVlSFPS,2020,Reject,False,Uncertainty - sensitive learning and planning with ensembles,"[""Piotr Mi\u0142o\u015b"", ""\u0141ukasz Kuci\u0144ski"", ""Konrad Czechowski"", ""Piotr Kozakowski"", ""Maciej Klimek""]","[""deep reinfocement learning"", ""mcts"", ""ensembles"", ""uncertainty""]",,,,,
SkgpBJrtvS,2020,Accept (Poster),True,Contrastive Representation Distillation,"[""Yonglong Tian"", ""Dilip Krishnan"", ""Phillip Isola""]","[""Knowledge Distillation"", ""Representation Learning"", ""Contrastive Learning"", ""Mutual Information""]",Representation/knowledge distillation by maximizing mutual information between teacher and student,1910.10699,cs.LG,2019-10-23 17:59:18+00:00,2020-01-18 10:09:39+00:00
Skgq1ANFDB,2020,Reject,False,Curvature-based Robustness Certificates against Adversarial Examples,"[""Sahil Singla"", ""Soheil Feizi""]","[""Adversarial examples"", ""Robustness certificates"", ""Adversarial attacks"", ""Machine Learning Security""]",,,,,
SkgsACVKPH,2020,Accept (Poster),False,Picking Winning Tickets Before Training by Preserving Gradient Flow,"[""Chaoqi Wang"", ""Guodong Zhang"", ""Roger Grosse""]","[""neural network"", ""pruning before training"", ""weight pruning""]",We introduced a pruning criterion for pruning networks before training by preserving gradient flow.,2002.07376,cs.LG,2020-02-18 05:14:47+00:00,2020-08-07 00:02:33+00:00
SkgscaNYPS,2020,Accept (Poster),False,The asymptotic spectrum of the Hessian of DNN throughout training,"[""Arthur Jacot"", ""Franck Gabriel"", ""Clement Hongler""]","[""theory of deep learning"", ""loss surface"", ""training"", ""fisher information matrix""]",Description of the limiting spectrum of the Hesian of the loss surface of DNNs in the infinite-width limit.,,,,
SkgtbaVYvH,2020,Reject,False,AutoLR: A Method for Automatic Tuning of Learning Rate,"[""Nipun Kwatra"", ""V Thejas"", ""Nikhil Iyer"", ""Ramachandran Ramjee"", ""Muthian Sivathanu""]","[""Automatic Learning Rate"", ""Deep Learning"", ""Generalization"", ""Stochastic Optimization""]","We present a method to automatically tune learning rate while training DNNs, and achieve or beat generalization accuracy of SOTA learning rates schedules for ImageNet (Resnet-50), Cifar-10 (Resnet-18), IWSLT (Transformer), Squad (Bert)",,,,
SkguE30ct7,2019,Reject,False,Neural Model-Based Reinforcement Learning for Recommendation,"[""Xinshi Chen"", ""Shuang Li"", ""Hui Li"", ""Shaohua Jiang"", ""Le Song""]","[""Generative adversarial user model"", ""Recommendation system"", ""combinatorial recommendation policy"", ""model-based reinforcement learning"", ""deep Q-networks""]",A new insight of designing a RL recommendation policy based on a generative adversarial user model.,,,,
SkgvvCVtDS,2020,Reject,False,DeepSimplex: Reinforcement Learning of Pivot Rules Improves the Efficiency of Simplex Algorithm in Solving Linear Programming Problems,"[""Varun Suriyanarayana"", ""Onur Tavaslioglu"", ""Ankit B. Patel"", ""Andrew J. Schaefer""]","[""Simplex Algorithm"", ""Pivoting Rules"", ""Reinforcement Learning"", ""Combinatorial Optimization"", ""Supervised Learning"", ""Travelling Salesman Problem""]","Learning pivoting rules of the simplex algorithm for solving linear programs to improve the solution times, demonstrated on linear approximations of travelling salesman problem.",,,,
Skgvy64tvr,2020,Accept (Spotlight),True,Enhancing Adversarial Defense by k-Winners-Take-All,"[""Chang Xiao"", ""Peilin Zhong"", ""Changxi Zheng""]","[""adversarial defense"", ""activation function"", ""winner takes all""]","We propose a simple change to existing neural network structures for better defending against gradient-based adversarial attacks, using the k-winners-take-all activation function.",1905.10510,cs.LG,2019-05-25 03:36:40+00:00,2019-10-29 00:27:18+00:00
Skgxcn4YDS,2020,Accept (Poster),False,LAMOL: LAnguage MOdeling for Lifelong Language Learning,"[""Fan-Keng Sun*"", ""Cheng-Hao Ho*"", ""Hung-Yi Lee""]","[""NLP"", ""Deep Learning"", ""Lifelong Learning""]",Language modeling for lifelong language learning.,,,,
Skgy464Kvr,2020,Accept (Poster),True,Detecting and Diagnosing Adversarial Images with Class-Conditional Capsule Reconstructions,"[""Yao Qin"", ""Nicholas Frosst"", ""Sara Sabour"", ""Colin Raffel"", ""Garrison Cottrell"", ""Geoffrey Hinton""]","[""Adversarial Examples"", ""Detection of adversarial attacks""]",,1907.02957,cs.LG,2019-07-05 17:57:57+00:00,2020-02-18 05:05:45+00:00
SkgzYiRqtX,2019,Reject,False,Graph Neural Networks with Generated Parameters for Relation Extraction,"[""Hao Zhu"", ""Yankai Lin"", ""Zhiyuan Liu"", ""Jie Fu"", ""Tat-seng Chua and Maosong Sun""]","[""Graph Neural Networks"", ""Relational Reasoning""]","A graph neural network model with parameters generated from natural languages, which can perform multi-hop reasoning. ",,,,
Skh4jRcKQ,2019,Accept (Poster),False,Understanding Straight-Through Estimator in Training Activation Quantized Neural Nets,"[""Penghang Yin"", ""Jiancheng Lyu"", ""Shuai Zhang"", ""Stanley Osher"", ""Yingyong Qi"", ""Jack Xin""]","[""straight-through estimator"", ""quantized activation"", ""binary neuron""]",We make theoretical justification for the concept of straight-through estimator.,,,,
SkhQHMW0W,2018,Accept (Poster),False,Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training,"[""Yujun Lin"", ""Song Han"", ""Huizi Mao"", ""Yu Wang"", ""Bill Dally""]","[""distributed training""]",we find 99.9% of the gradient exchange in distributed SGD is redundant; we reduce the communication bandwidth by two orders of magnitude without losing accuracy. ,,,,
SkhU2fcll,2017,Accept (Poster),False,Deep Multi-task Representation Learning: A Tensor Factorisation Approach,"[""Yongxin Yang"", ""Timothy M. Hospedales""]",[],A multi-task representation learning framework that learns cross-task sharing structure at every layer in a deep network.,,,,
SkiCjzNTZ,2018,Reject,False,Spontaneous Symmetry Breaking in Deep Neural Networks,"[""Ricky Fok"", ""Aijun An"", ""Xiaogang Wang""]","[""deep learning"", ""physics"", ""field theory""]",Closed form results for deep learning in the layer decoupling limit applicable to Residual Networks,,,,
Skj8Kag0Z,2018,Accept (Poster),False,Stabilizing Adversarial Nets with Prediction Methods,"[""Abhay Yadav"", ""Sohil Shah"", ""Zheng Xu"", ""David Jacobs"", ""Tom Goldstein""]","[""adversarial networks"", ""optimization""]","We present a simple modification to the alternating SGD method, called a prediction step, that improves the stability of adversarial networks.",,,,
Skk3Jm96W,2018,Invite to Workshop Track,False,Some Considerations on Learning to Explore via Meta-Reinforcement Learning,"[""Bradly Stadie"", ""Ge Yang"", ""Rein Houthooft"", ""Xi Chen"", ""Yan Duan"", ""Yuhuai Wu"", ""Pieter Abbeel"", ""Ilya Sutskever""]","[""reinforcement learning"", ""rl"", ""exploration"", ""meta learning"", ""meta reinforcement learning"", ""curiosity""]",Modifications to MAML and RL2 that should allow for better exploration. ,,,,
SkkTMpjex,2017,Accept (Poster),False,Distributed Second-Order Optimization using Kronecker-Factored Approximations,"[""Jimmy Ba"", ""Roger Grosse"", ""James Martens""]","[""Deep learning"", ""Optimization""]",Fixed typos pointed out by AnonReviewer1 and AnonReviewer4 and added the experiments in Fig. 6 showing the poor scaling of batch normalized SGD using a batch size of 2048 on googlenet. ,,,,
Skl-fyHKPH,2020,Reject,False,A Mean-Field Theory for Kernel Alignment with Random Features in Generative Adverserial Networks,"[""Masoud Badiei Khuzani"", ""Liyue Shen"", ""Shahin Shahrampour"", ""Lei Xing""]","[""Kernel Learning"", ""Generative Adversarial Networks"", ""Mean Field Theory""]",We propose a novel method to learn the kernel in MMD GANs and prove theoretical results for its performance. ,,,,
Skl1HCNKDr,2020,Reject,False,Learning Generative Models using Denoising Density Estimators,"[""Siavash Bigdeli"", ""Geng Lin"", ""Tiziano Portenier"", ""Andrea Dunbar"", ""Matthias Zwicker""]","[""generative probabilistic models"", ""denoising autoencoders"", ""neural density estimation""]","A novel approach to train generative models including density estimation; different from normalizing and continuous flows, VAEs, or autoregressive models.",,,,
Skl3M20qYQ,2019,Reject,False,Non-Synergistic Variational Autoencoders,"[""Gonzalo Barrientos"", ""Sten Sootla""]","[""vae"", ""unsupervised learning""]",Minimising the synergistic mutual information within the latents and the data for the task of disentanglement using the VAE framework.,,,,
Skl3SkSKDr,2020,Reject,False,Generating valid Euclidean distance matrices,"[""Moritz Hoffmann"", ""Frank Noe""]","[""euclidean distance matrices"", ""wgan"", ""point clouds"", ""molecular structures""]",We introduce a neural network architecture which builds on the generation of Euclidean distance matrices to one-shot generate molecular structures and potentially other forms of point clouds.,,,,
Skl4LTEtDS,2020,Reject,True,Growing Action Spaces,"[""Gregory Farquhar"", ""Laura Gustafson"", ""Zeming Lin"", ""Shimon Whiteson"", ""Nicolas Usunier"", ""Gabriel Synnaeve""]","[""reinforcement learning"", ""curriculum learning"", ""multi-agent reinforcement learning""]",Progressively growing the available action space is a great curriculum for learning agents,1906.12266,cs.LG,2019-06-28 15:35:11+00:00,2019-06-28 15:35:11+00:00
Skl4mRNYDr,2020,Accept (Poster),True,"Deep Imitative Models for Flexible Inference, Planning, and Control","[""Nicholas Rhinehart"", ""Rowan McAllister"", ""Sergey Levine""]","[""imitation learning"", ""planning"", ""autonomous driving""]","In this paper, we propose Imitative Models to combine the benefits of IL and goal-directed planning: probabilistic predictive models of desirable behavior able to plan interpretable expert-like trajectories to achieve specified goals.",1810.06544,cs.LG,2018-10-15 17:51:03+00:00,2019-10-01 00:13:58+00:00
Skl6k209Ym,2019,Reject,False,Alignment Based Mathching Networks for One-Shot Classification and Open-Set Recognition,"[""Paresh Malalur"", ""Tommi Jaakkola""]",[],,,,,
Skl6peHFwS,2020,Reject,False,Best feature performance in codeswitched hate speech texts,"[""Edward Ombui"", ""Lawrence Muchemi"", ""Peter Wagacha""]","[""Hate Speech"", ""Code-switching"", ""feature selection"", ""representation learning""]",Analysis of features and algorithm performance on codeswitched language datasets,,,,
Skl8EkSFDr,2020,Reject,False,Self-Supervised GAN Compression,"[""Chong Yu"", ""Jeff Pool""]","[""compression"", ""pruning"", ""generative adversarial networks"", ""GAN""]","Existing pruning methods fail when applied to GANs tackling complex tasks, so we present a simple and robust method to prune generators that works well for a wide variety of networks and tasks.",2007.01491,cs.LG,2020-07-03 04:18:54+00:00,2020-07-12 16:43:57+00:00
SklD9yrFPS,2020,Accept (Spotlight),False,Neural Tangents: Fast and Easy Infinite Neural Networks in Python,"[""Roman Novak"", ""Lechao Xiao"", ""Jiri Hron"", ""Jaehoon Lee"", ""Alexander A. Alemi"", ""Jascha Sohl-Dickstein"", ""Samuel S. Schoenholz""]","[""Infinite Neural Networks"", ""Gaussian Processes"", ""Neural Tangent Kernel"", ""NNGP"", ""NTK"", ""Software Library"", ""Python"", ""JAX""]",Keras for infinite neural networks.,1912.02803,stat.ML,2019-12-05 18:51:57+00:00,2019-12-05 18:51:57+00:00
SklEEnC5tQ,2019,Accept (Poster),False,DISTRIBUTIONAL CONCAVITY REGULARIZATION FOR GANS,"[""Shoichiro Yamaguchi"", ""Masanori Koyama""]","[""Generative Adversarial Networks"", ""regularization"", ""optimal transport"", ""functional gradient"", ""convex analysis""]",,,,,
SklE_CNFPr,2020,Reject,False,Zeroth Order Optimization by a Mixture of Evolution Strategies,"[""Jun-Kun Wang"", ""Xiaoyun Li"", ""Ping Li""]",[],,,,,
SklEhlHtPr,2020,Reject,False,DeepPCM: Predicting Protein-Ligand Binding using Unsupervised Learned Representations,"[""Paul Kim"", ""Robin Winter"", ""Djork-Arn\u00e9 Clevert""]","[""Unsupervised Representation Learning"", ""Computational biology"", ""computational chemistry"", ""protein-ligand binding""]",We report a new methodological framework which uses unsupervised-learned representations of proteins and compounds to significantly outperform methods based on handcrafted features for the impactful protein-ligand binding task. ,,,,
SklGryBtwr,2020,Accept (Poster),True,Environmental drivers of systematicity and generalization in a situated agent,"[""Felix Hill"", ""Andrew Lampinen"", ""Rosalia Schneider"", ""Stephen Clark"", ""Matthew Botvinick"", ""James L. McClelland"", ""Adam Santoro""]","[""systematicitiy"", ""systematic"", ""generalization"", ""combinatorial"", ""agent"", ""policy"", ""language"", ""compositionality""]",We isolate the environmental and training factors that contribute to emergent systematic generalization in a situated language-learning agent,1910.00571,cs.AI,2019-10-01 17:51:45+00:00,2020-02-19 13:16:22+00:00
SklKcRNYDH,2020,Accept (Poster),True,Extreme Tensoring for Low-Memory Preconditioning ,"[""Xinyi Chen"", ""Naman Agarwal"", ""Elad Hazan"", ""Cyril Zhang"", ""Yi Zhang""]","[""optimization"", ""deep learning""]",,1902.04620,cs.LG,2019-02-12 20:24:01+00:00,2019-02-12 20:24:01+00:00
SklM1xStPB,2020,Reject,False,Copy That! Editing Sequences by Copying Spans,"[""Sheena Panthaplackel"", ""Miltiadis Allamanis"", ""Marc Brockschmidt""]","[""span copying"", ""sequence generation"", ""editing"", ""code repair""]",Sequence-to-sequence models that copy long spans from the input.,2006.04771,cs.LG,2020-06-08 17:42:18+00:00,2020-12-14 10:03:21+00:00
SklOUpEYvB,2020,Accept (Poster),True,Identifying through Flows for Recovering Latent Representations,"[""Shen Li"", ""Bryan Hooi"", ""Gim Hee Lee""]","[""Representation learning"", ""identifiable generative models"", ""nonlinear-ICA""]",,1909.12555,cs.LG,2019-09-27 08:37:13+00:00,2020-04-26 07:21:45+00:00
SklOypVKvS,2020,Reject,False,A Data-Efficient Mutual Information Neural Estimator for Statistical Dependency Testing,"[""Xiao Lin"", ""Indranil Sur"", ""Samuel A. Nastase"", ""Uri Hasson"", ""Ajay Divakaran"", ""Mohamed R. Amer""]","[""mutual information"", ""fMRI"", ""inter-subject correation"", ""mutual information neural estimation"", ""meta-learning"", ""statistical test of dependency""]","A new & practical statistical test of dependency using neural networks, benchmarked on synthetic and a real fMRI datasets.",,,,
SklR6aEtwH,2020,Reject,False,Neural Architecture Search by Learning Action Space for Monte Carlo Tree Search,"[""Linnan Wang"", ""Saining Xie"", ""Teng Li"", ""Rodrigo Fonseca"", ""Yuandong Tian""]","[""MCTS"", ""Neural Architecture Search"", ""Search""]",A new model that learns latent actions for MCTS to the application of neural architecture search,,,,
SklR_iCcYm,2019,Reject,False,Faster Training by Selecting Samples Using Embeddings,"[""Santiago Gonzalez"", ""Joshua Landgraf"", ""Risto Miikkulainen""]","[""Machine Learning"", ""Embeddings"", ""Training Time"", ""Optimization"", ""Autoencoders""]",Training is sped up by using a dataset that has been subsampled through embedding analysis.,,,,
SklSQgHFDS,2020,Reject,True,Scheduled Intrinsic Drive: A Hierarchical Take on Intrinsically Motivated Exploration,"[""Jingwei Zhang"", ""Niklas Wetzel"", ""Nicolai Dorka"", ""Joschka Boedecker"", ""Wolfram Burgard""]","[""Reinforcement Learning"", ""Exploration"", ""Intrinsic Motivation"", ""Sparse Rewards""]",A new intrinsic reward signal based on successor features and a novel way to combine extrinsic and intrinsic reward.,1903.07400,cs.LG,2019-03-18 12:52:57+00:00,2019-06-21 15:41:14+00:00
SklTQCNtvS,2020,Accept (Poster),False,Sign-OPT: A Query-Efficient Hard-label Adversarial Attack,"[""Minhao Cheng"", ""Simranjit Singh"", ""Patrick H. Chen"", ""Pin-Yu Chen"", ""Sijia Liu"", ""Cho-Jui Hsieh""]",[],,,,,
SklVEnR5K7,2019,Reject,False,Making Convolutional Networks Shift-Invariant Again,"[""Richard Zhang""]","[""convolutional networks"", ""signal processing"", ""shift"", ""translation"", ""invariance"", ""equivariance""]","Modern networks are not shift-invariant, due to naive downsampling; we apply a signal processing tool -- anti-aliasing low-pass filtering before downsampling -- to improve shift-invariance",,,,
SklVI1HKvH,2020,Reject,False,Sample-Based Point Cloud Decoder Networks,"[""Erich Merrill"", ""Alan Fern""]","[""point cloud"", ""autoencoder""]",We present and evaluate sampling-based point cloud decoders that outperform the baseline MLP approach by better matching the semantics of point clouds.,,,,
SklViCEFPH,2020,Reject,False,Simple is Better: Training an End-to-end Contract Bridge Bidding Agent without Human Knowledge,"[""Qucheng Gong"", ""Yu Jiang"", ""Yuandong Tian""]","[""Contract Bridge"", ""Bidding"", ""Selfplay"", ""AlphaZero""]","State-of-the-art contract bridge bidding agent, learned from selfplay without human knowledge",,,,
SklVqa4YwH,2020,Reject,True,Realism Index: Interpolation in Generative Models With Arbitrary Prior,"[""\u0141ukasz Struski"", ""Jacek Tabor"", ""Igor Podolak"", ""Aleksandra Nowak"", ""Krzysztof Maziarz""]",[],,1904.03445,cs.LG,2019-04-06 13:47:48+00:00,2019-09-26 19:27:18+00:00
SklXvs0qt7,2019,Reject,False,Curiosity-Driven Experience Prioritization via Density Estimation,"[""Rui Zhao"", ""Volker Tresp""]","[""Curiosity-Driven"", ""Experience Prioritization"", ""Hindsight Experience"", ""Reinforcement Learning""]","Our paper proposes a curiosity-driven prioritization framework for RL agents, which improves both performance and sample-efficiency.",,,,
SklcFsAcKX,2019,Reject,False,Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior,"[""Reinhard Heckel"", ""Wen Huang"", ""Paul Hand"", ""Vladislav Voroninski""]","[""non-convex optimization"", ""denoising"", ""generative neural network""]","By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.",,,,
SklckhR5Ym,2019,Reject,False,Improved Language Modeling by Decoding the Past,"[""Siddhartha Brahma""]","[""language modeling"", ""regularization"", ""LSTM""]",Decoding the last token in the context using the predicted next token distribution acts as a regularizer and improves language modeling.,,,,
SklcyJBtvB,2020,Reject,False,Off-policy Bandits with Deficient Support,"[""Noveen Sachdeva"", ""Yi Su"", ""Thorsten Joachims""]","[""Recommender System"", ""Search Engine"", ""Counterfactual Learning""]",,2006.09438,cs.LG,2020-06-16 18:30:02+00:00,2020-06-16 18:30:02+00:00
Skld1aVtPB,2020,Reject,False,Deep Mining: Detecting Anomalous Patterns in Neural Network Activations with Subset Scanning,"[""Skyler Speakman"", ""Celia Cintas"", ""Victor Akinwande"", ""Srihari Sridharan"", ""Edward McFowland III""]","[""anomalous pattern detection"", ""subset scanning"", ""node activations"", ""adversarial noise""]",We efficiently find a subset of images that have higher than expected activations for some subset of nodes.  These images appear more anomalous and easier to detect when viewed as a group. ,,,,
Sklf1yrYDr,2020,Accept (Poster),False,BatchEnsemble: an Alternative Approach to Efficient Ensemble and Lifelong Learning,"[""Yeming Wen"", ""Dustin Tran"", ""Jimmy Ba""]","[""deep learning"", ""ensembles""]","We introduced BatchEnsemble, an efficient method for ensembling and lifelong learning which can be used to improve the accuracy and uncertainty of any neural network like typical ensemble methods.",2002.06715,cs.LG,2020-02-17 00:00:59+00:00,2020-02-20 03:38:44+00:00
SklfY6EFDH,2020,Reject,False,Representation Quality Explain Adversarial Attacks,"[""Danilo Vasconcellos Vargas"", ""Shashank Kotyan"", ""Moe Matsuki""]","[""Representation Metrics"", ""Adversarial Machine Learning"", ""One-Pixel Attack"", ""DeepFool"", ""CapsNet""]",,,,,
SklgHoRqt7,2019,Reject,False,Metric-Optimized Example Weights,"[""Sen Zhao"", ""Mahdi Milani Fard"", ""Maya Gupta""]",[],,,,,
SklgTkBKDr,2020,Reject,False,Neural Non-additive Utility Aggregation,"[""Markus Zopf""]",[],We propose two new neural architectures that explicitly model latent intermediate element utilities for non-additive set utility estimation.,,,,
SklgfkSFPH,2020,Reject,False,On PAC-Bayes Bounds for Deep Neural Networks using the Loss Curvature,"[""Konstantinos Pitas""]","[""PAC-Bayes"", ""Hessian"", ""curvature"", ""lower bound"", ""Variational Inference""]","For PAC-Bayes when modeling the prior and posterior as multivariate Gaussians, we show that for specific cases of DNNs it is impossible to prove generalization, assuming a second order Taylor expansion of the empirical loss is tight.",,,,
Sklgs0NFvr,2020,Accept (Spotlight),False,Learning The Difference That Makes A Difference With Counterfactually-Augmented Data,"[""Divyansh Kaushik"", ""Eduard Hovy"", ""Zachary Lipton""]","[""humans in the loop"", ""annotation artifacts"", ""text classification"", ""sentiment analysis"", ""natural language inference""]","Humans in the loop revise documents to accord with counterfactual labels, resulting resource helps to reduce reliance on spurious associations.",,,,
SklibJBFDB,2020,Reject,True,Evaluating Semantic Representations of Source Code,"[""Yaza Wainakh"", ""Moiz Rauf"", ""Michael Pradel""]","[""embeddings"", ""representation"", ""source code"", ""identifiers""]",A benchmark to evaluate neural embeddings of identifiers in source code.,1910.05177,cs.LG,2019-10-11 13:34:30+00:00,2021-01-14 10:07:16+00:00
SklkDkSFPB,2020,Accept (Poster),True,BlockSwap: Fisher-guided Block Substitution for Network Compression on a Budget,"[""Jack Turner"", ""Elliot J. Crowley"", ""Michael O'Boyle"", ""Amos Storkey"", ""Gavin Gray""]","[""model compression"", ""architecture search"", ""efficiency"", ""budget"", ""convolutional neural networks""]",A simple and effective method for reducing large neural networks to flexible parameter targets based on block substitution.,1906.04113,cs.LG,2019-06-10 16:39:53+00:00,2020-01-23 16:05:59+00:00
Skln2A4YDB,2020,Accept (Poster),False,Model-Augmented Actor-Critic: Backpropagating through Paths,"[""Ignasi Clavera"", ""Yao Fu"", ""Pieter Abbeel""]","[""reinforcement learning"", ""model-based"", ""actor-critic"", ""pathwise""]",Policy gradient through backpropagation through time using learned models and Q-functions. SOTA results in reinforcement learning benchmark environments.,,,,
SklnVAEFDB,2020,Reject,False,BERT-AL: BERT for Arbitrarily Long Document Understanding,"[""Ruixuan Zhang"", ""Zhuoyu Wei"", ""Yu Shi"", ""Yining Chen""]",[],,,,,
SkloDJSFPH,2020,Reject,False,Neural Approximation of an Auto-Regressive Process through Confidence Guided Sampling,"[""YoungJoon Yoo"", ""Sanghyuk Chun"", ""Jaejun Yoo"", ""Sangdoo Yun"", ""Jung Woo Ha""]","[""Neural approximation method"", ""Auto-regressive model"", ""Sequential sample generation""]",We propose a effective confidence-based approximation method that can be plugged in to various auto-regressive models with a proved convergence.,,,,
SkloDjAqYm,2019,Accept (Poster),False,LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos,"[""Elke Kirschbaum"", ""Manuel Hau\u00dfmann"", ""Steffen Wolf"", ""Hannah Sonntag"", ""Justus Schneider"", ""Shehabeldin Elzoheiry"", ""Oliver Kann"", ""Daniel Durstewitz"", ""Fred A Hamprecht""]","[""VAE"", ""unsupervised learning"", ""neuronal assemblies"", ""calcium imaging analysis""]","We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.",,,,
Sklqvo0qt7,2019,Reject,False,A Priori Estimates  of the Generalization Error for Two-layer Neural Networks,"[""Lei Wu"", ""Chao Ma"", ""Weinan E""]","[""Over-parameterization"", ""A priori estimates"", ""Path norm"", ""Neural networks"", ""Generalization error"", ""Approximation error""]",,,,,
Sklr9i09KQ,2019,Reject,False,Neural Networks for Modeling Source Code Edits,"[""Rui Zhao"", ""David Bieber"", ""Kevin Swersky"", ""Daniel Tarlow""]","[""Neural Networks"", ""Program Synthesis"", ""Source Code Modeling""]",Neural networks for source code that model changes being made to the code-base rather than static snapshots of code.,,,,
SklrrhRqFX,2019,Reject,False,Learning Physics Priors for Deep Reinforcement Learing,"[""Yilun Du"", ""Karthik Narasimhan""]","[""Model-Based Reinforcement Learning"", ""Intuitive Physics""]",We propose a new approach to pre-train a physics prior from raw videos and incorporate it into an RL framework that allows for better learning and efficient generalization.,1905.04819,cs.LG,2019-05-13 01:16:16+00:00,2019-07-11 13:11:19+00:00
SklsBJHKDS,2020,Reject,False,Model Inversion Networks for Model-Based Optimization,"[""Aviral Kumar"", ""Sergey Levine""]","[""data-driven optimization"", ""model-based optimization""]",We propose a novel approach to solve data-driven model-based optimization problems in both passive and active settings that can scale to high-dimensional input spaces.,1912.13464,cs.LG,2019-12-31 18:06:49+00:00,2019-12-31 18:06:49+00:00
Sklsm20ctX,2019,Accept (Poster),False,Competitive experience replay,"[""Hao Liu"", ""Alexander Trott"", ""Richard Socher"", ""Caiming Xiong""]","[""reinforcement learning"", ""sparse reward"", ""goal-based learning""]",a novel method to learn with sparse reward using adversarial reward re-labeling,,,,
Skltqh4KvB,2020,Reject,False,Are there any 'object detectors' in the hidden layers of CNNs trained to identify objects or scenes?,"[""Ella M. Gale"", ""Nicholas Martin"", ""Ryan Blything"", ""Anh Nguyen"", ""Jeffrey S. Bowers""]","[""neural networks"", ""localist coding"", ""selectivity"", ""object detectors"", ""CCMAS"", ""CNNs"", ""activation maximisation"", ""information representation"", ""network dissection"", ""interpretabillity"", ""signal detection""]","Looking for object detectors using many different selectivity measures; CNNs are slightly selective , but not enough to be termed object detectors.",2007.01062,cs.CV,2020-07-02 12:33:37+00:00,2020-07-02 12:33:37+00:00
SkluFgrFwH,2020,Reject,False,Learning Mahalanobis Metric Spaces via Geometric Approximation Algorithms,"[""Diego Ihara"", ""Neshat Mohammadi"", ""Anastasios Sidiropoulos""]","[""Metric Learning"", ""Geometric Algorithms"", ""Approximation Algorithms""]",Fully parallelizable and adversarial-noise resistant metric learning algorithm with theoretical guarantees.,,,,
Skluy2RcK7,2019,Reject,False,Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet,"[""Ella M. Gale"", ""Anh Nguyen"", ""Ryan Blything"", ""Nicholas Martin and Jeffrey S. Bowers""]","[""AlexNet"", ""neural networks"", ""selectivity"", ""localist"", ""distributed"", ""represenataion"", ""precision"", ""measures of selectivity"", ""object detectors"", ""single directions"", ""network analysis""]","Common selectivity metrics overestimate the selectivity of units, true object detectors are extremely rare, but class selectivity does increase with depth. ",,,,
Sklv5iRqYX,2019,Accept (Poster),False,Multi-Domain Adversarial Learning,"[""Alice Schoenauer-Sebag"", ""Louise Heinrich"", ""Marc Schoenauer"", ""Michele Sebag"", ""Lani F. Wu"", ""Steve J. Altschuler""]","[""multi-domain learning"", ""domain adaptation"", ""adversarial learning"", ""H-divergence"", ""deep representation learning"", ""high-content microscopy""]",Adversarial Domain adaptation and Multi-domain learning: a new loss to handle multi- and single-domain classes in the semi-supervised setting.,,,,
SklwGlHFvH,2020,Reject,False,Learning Curves for Deep Neural Networks: A field theory perspective,"[""Omry Cohen"", ""Or Malka"", ""Zohar Ringel""]","[""Gaussian Processes"", ""Neural Tangent Kernel"", ""Learning Curves"", ""Field Theory"", ""Statistical Mechanics"", ""Generalization"", ""Deep neural networks""]",Nice and accurate predictions for DNN learning curves using a novel field theory approach  ,,,,
Sklyn6EYvH,2020,Reject,False,Disentangled Representation Learning with Sequential Residual Variational Autoencoder,"[""Nanxiang Li"", ""Shabnam Ghaffarzadegan"", ""Liu Ren""]","[""Disentangled Representation Learning"", ""Variational Autoencoder"", ""Residual Learning""]",,,,,
SklzIjActX,2019,Reject,False,HIGHLY EFFICIENT 8-BIT LOW PRECISION INFERENCE OF CONVOLUTIONAL NEURAL NETWORKS,"[""Haihao Shen"", ""Jiong Gong"", ""Xiaoli Liu"", ""Guoming Zhang"", ""Ge Jin"", ""and Eric Lin""]","[""8-bit low precision inference"", ""convolutional neural networks"", ""statistical accuracy"", ""8-bit Winograd convolution""]",We present a general technique toward 8-bit low precision inference of convolutional neural networks. ,,,,
SkmM6M_pW,2018,Reject,False,Egocentric Spatial Memory Network,"[""Mengmi Zhang"", ""Keng Teck Ma"", ""Joo Hwee Lim"", ""Shih-Cheng Yen"", ""Qi Zhao"", ""Jiashi Feng""]","[""spatial memory"", ""egocentric vision"", ""deep neural network"", ""navigation""]",first deep neural network for modeling Egocentric Spatial Memory inspired by neurophysiological discoveries of navigation cells in mammalian brain,,,,
SkmiegW0b,2018,Invite to Workshop Track,False,Challenges in Disentangling Independent Factors of Variation,"[""Attila  Szabo"", ""Qiyang  Hu"", ""Tiziano  Portenier"", ""Matthias  Zwicker"", ""Paolo  Favaro""]","[""disentangling"", ""factors"", ""attribute"", ""transfer"", ""autoencoder"", ""GAN""]","It is a mostly theoretical paper that describes the challenges in disentangling factors of variation, using autoencoders and GAN.",,,,
Skn9Shcxe,2017,Accept (Poster),False,Highway and Residual Networks learn Unrolled Iterative Estimation,"[""Klaus Greff"", ""Rupesh K. Srivastava"", ""J\u00fcrgen Schmidhuber""]","[""Theory"", ""Deep learning"", ""Supervised Learning""]",,,,,
SknC0bW0-,2018,Reject,False,Continuous-fidelity Bayesian Optimization with Knowledge Gradient,"[""Jian Wu"", ""Peter I. Frazier""]","[""Continuous fidelity"", ""Bayesian optimization"", ""fast"", ""knowledge gradient"", ""hyperparameter optimization""]",We propose a Bayes-optimal Bayesian optimization algorithm for hyperparameter tuning by exploiting cheap approximations.,,,,
Skp1ESxRZ,2018,Accept (Poster),False,Towards Synthesizing Complex Programs From Input-Output Examples,"[""Xinyun Chen"", ""Chang Liu"", ""Dawn Song""]",[],,,,,
SkpSlKIel,2017,Accept (Poster),False,Why Deep Neural Networks for Function Approximation?,"[""Shiyu Liang"", ""R. Srikant""]",[],,,,,
Skq89Scxx,2017,Accept (Poster),False,SGDR: Stochastic Gradient Descent with Warm Restarts,"[""Ilya Loshchilov"", ""Frank Hutter""]","[""Deep learning"", ""Optimization""]",We propose a simple warm restart technique for stochastic gradient descent to improve its anytime performance.,,,,
SkqMSCHxe,2017,Reject,False,PREDICTION OF POTENTIAL HUMAN INTENTION USING SUPERVISED COMPETITIVE LEARNING,"[""Masayoshi Ishikawa"", ""Mariko Okude"", ""Takehisa Nishida & Kazuo Muto""]","[""Computer vision"", ""Deep learning"", ""Supervised Learning"", ""Applications""]",,,,,
SkqV-XZRZ,2018,Reject,False,Variational Bi-LSTMs,"[""Samira Shabanian"", ""Devansh Arpit"", ""Adam Trischler"", ""Yoshua Bengio""]",[],,,,,
SkrHeXbCW,2018,Reject,False,Learning Representations for Faster Similarity Search,"[""Ludwig Schmidt"", ""Kunal Talwar""]",[],We show how to get good representations from the point of view of Simiarity Search.,,,,
Sks3zF9eg,2017,Reject,False,Taming the waves: sine as activation function in deep neural networks,"[""Giambattista Parascandolo"", ""Heikki Huttunen"", ""Tuomas Virtanen""]","[""Theory"", ""Deep learning"", ""Optimization"", ""Supervised Learning""]","Why nets with sine as activation function are difficult to train in theory. Also, they often don't use the periodic part if not needed, but when it's beneficial they might learn faster",,,,
Sks9_ajex,2017,Accept (Poster),False,Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer,"[""Sergey Zagoruyko"", ""Nikos Komodakis""]","[""Computer vision"", ""Deep learning"", ""Supervised Learning""]",,,,,
SksY3deAW,2018,Reject,False,Learning Deep ResNet Blocks Sequentially using Boosting Theory,"[""Furong Huang"", ""Jordan T. Ash"", ""John Langford"", ""Robert E. Schapire""]","[""residual network"", ""boosting theory"", ""training error guarantee""]",We prove a multiclass boosting theory for the ResNet architectures which simultaneously creates a new technique for multiclass boosting and provides a new algorithm for ResNet-style architectures.,,,,
SktLlGbRZ,2018,Reject,False,CyCADA: Cycle-Consistent Adversarial Domain Adaptation,"[""Judy Hoffman"", ""Eric Tzeng"", ""Taesung Park"", ""Jun-Yan Zhu"", ""Phillip Isola"", ""Kate Saenko"", ""Alyosha Efros"", ""Trevor Darrell""]","[""domain adaptation"", ""unsupervised learning"", ""classification"", ""semantic segmentation""]",An unsupervised domain adaptation approach which adapts at both the pixel and feature levels,,,,
Sktm4zWRb,2018,Reject,False,Soft Value Iteration Networks for Planetary Rover Path Planning,"[""Max Pflueger"", ""Ali Agha"", ""Gaurav S. Sukhatme""]","[""value iteration networks"", ""robotics"", ""space robotics"", ""imitation learning"", ""convolutional neural networks"", ""path planning""]","We propose an improvement to value iteration networks, with applications to planetary rover path planning.",,,,
SkuqA_cgx,2017,Invite to Workshop Track,False,Automated Generation of Multilingual Clusters for the Evaluation of Distributed Representations,"[""Philip Blair"", ""Yuval Merhav"", ""Joel Barry""]","[""Natural language processing"", ""Applications""]",Applying simple heuristics to the Wikidata entity graph results in a high-quality semantic similarity dataset.,,,,
Skvd-myR-,2018,Reject,False,Learning Non-Metric Visual Similarity for Image Retrieval,"[""Noa Garcia"", ""George Vogiatzis""]","[""image retrieval"", ""visual similarity"", ""non-metric learning""]",Similarity network to learn a non-metric visual similarity estimation between a pair of images,,,,
Skvgqgqxe,2017,Accept (Poster),False,Learning to Compose Words into Sentences with Reinforcement Learning,"[""Dani Yogatama"", ""Phil Blunsom"", ""Chris Dyer"", ""Edward Grefenstette"", ""Wang Ling""]",[],,,,,
Skw0n-W0Z,2018,Accept (Poster),False,Temporal Difference Models: Model-Free Deep RL for Model-Based Control,"[""Vitchyr Pong*"", ""Shixiang Gu*"", ""Murtaza Dalal"", ""Sergey Levine""]","[""model-based reinforcement learning"", ""model-free reinforcement learning"", ""temporal difference learning"", ""predictive learning"", ""predictive models"", ""optimal control"", ""off-policy reinforcement learning"", ""deep learning"", ""deep reinforcement learning"", ""q learning""]","We show that a special goal-condition value function trained with model free methods can be used within model-based control, resulting in substantially better sample efficiency and performance.",,,,
SkwAEQbAb,2018,Reject,False,A novel method to determine the number of latent dimensions with SVD,"[""Asana Neishabouri"", ""Michel Desmarais""]","[""SVD"", ""Latent Dimensions"", ""Dimension Reductions"", ""Machine Learning""]","In this study, we introduce a novel method that relies on SVD to discover the number of latent dimensions.",,,,
SkwSJ99ex,2017,Reject,False,DeepRebirth: A General Approach for Accelerating Deep Neural Network Execution on Mobile Devices,"[""Dawei Li"", ""Xiaolong Wang"", ""Deguang Kong"", ""Mooi Choo Chuah""]",[],,,,,
Skx24yHFDr,2020,Reject,False,Discovering Topics With Neural Topic Models Built From PLSA Loss,"[""sileye ba""]","[""neural network"", ""topic model"", ""neural topic model"", ""bag-of-words"", ""PLSA""]","We propose a neural topic model that is built using documents, words, and topics embedding together with PLSA independence assumptions. ",,,,
Skx5txzb0W,2018,Reject,False,A Boo(n) for Evaluating Architecture Performance,"[""Ondrej Bajgar"", ""Rudolf Kadlec"", ""and Jan Kleindienst""]","[""evaluation"", ""methodology""]","We point out important problems with the common practice of using the best single model performance for comparing deep learning architectures, and we propose a method that corrects these flaws.",,,,
Skx6WaEYPH,2020,Reject,True,Bandlimiting Neural Networks Against Adversarial Attacks,"[""Yuping Lin"", ""Kasra Ahmadi K. A."", ""Hui Jiang""]","[""adversarial examples"", ""adversarial attack defense"", ""neural network"", ""Fourier analysis""]","An insight into the reason of adversarial vulnerability, an effective defense method against adversarial attacks.",1905.12797,cs.LG,2019-05-30 00:34:50+00:00,2019-05-30 00:34:50+00:00
Skx73lBFDS,2020,Reject,False,Combining graph and sequence information to learn protein representations,"[""Hassan Kan\u00e9"", ""Mohamed Coulibali"", ""Pelkins Ajanoh"", ""Ali Abdalla""]","[""NLP"", ""Protein"", ""Representation Learning""]",We learn protein representations by integrating data from physical interaction and amino acid sequence,,,,
Skx82ySYPH,2020,Accept (Poster),False,Neural Outlier Rejection for Self-Supervised Keypoint Learning,"[""Jiexiong Tang"", ""Hanme Kim"", ""Vitor Guizilini"", ""Sudeep Pillai"", ""Rares Ambrus""]","[""Self-Supervised Learning"", ""Keypoint Detection"", ""Outlier Rejection"", ""Deep Learning""]","Learning to extract distinguishable keypoints from a proxy task, outlier rejection.",1912.10615,cs.CV,2019-12-23 04:37:50+00:00,2019-12-23 04:37:50+00:00
SkxANsC9tQ,2019,Reject,True,Learning Graph Representations by Dendrograms,"[""Thomas Bonald"", ""Bertrand Charpentier""]","[""Graph"", ""hierarchical clustering"", ""dendrogram"", ""quality metric"", ""reconstruction"", ""entropy""]",Novel quality metric for hierarchical graph clustering,1807.05087,cs.SI,2018-07-13 13:51:52+00:00,2018-07-13 13:51:52+00:00
SkxBUpEKwH,2020,Accept (Poster),True,Vid2Game: Controllable Characters Extracted from Real-World Videos,"[""Oran Gafni"", ""Lior Wolf"", ""Yaniv Taigman""]",[],,1904.08379,cs.LG,2019-04-17 17:26:14+00:00,2019-04-17 17:26:14+00:00
SkxG-CVFDH,2020,Reject,False,GraphMix: Regularized Training of Graph Neural Networks for Semi-Supervised Learning,"[""Vikas Verma"", ""Meng Qu"", ""Alex Lamb"", ""Yoshua Bengio"", ""Juho Kannala"", ""Jian Tang""]","[""Regularization"", ""Graph Neural Networks"", ""Mixup"", ""Manifold Mixup"", ""Semi-supervised Object Classification over graph Data""]","Regularization techniques for training Graph Neural Networks. We show that with our  simple method, the state-of-the-art  results can be achieved even with simpler Graph Neural Network architectures, at virtullay no additional computation cost.",,,,
SkxHRySFvr,2020,Reject,False,LEARNING TO IMPUTE: A GENERAL FRAMEWORK FOR SEMI-SUPERVISED LEARNING,"[""Wei-Hong Li"", ""Chuan-Sheng Foo"", ""Hakan Bilen""]","[""Semi-supervised Learning"", ""Meta-Learning"", ""Learning to label""]","We proposed a general learning-to-learn framework for semi-supervised learning, which can be used for both classification and regression tasks.",1912.10364,cs.LG,2019-12-22 00:27:21+00:00,2020-09-24 13:53:04+00:00
SkxJ-309FQ,2019,Reject,False,Hallucinations in Neural Machine Translation,"[""Katherine Lee"", ""Orhan Firat"", ""Ashish Agarwal"", ""Clara Fannjiang"", ""David Sussillo""]","[""nmt"", ""translate"", ""dynamics"", ""rnn""]","We introduce and analyze the phenomenon of ""hallucinations"" in NMT, or spurious translations unrelated to source text, and propose methods to reduce its frequency.",,,,
SkxJ8REYPH,2020,Accept (Poster),True,SlowMo: Improving Communication-Efficient Distributed SGD with Slow Momentum,"[""Jianyu Wang"", ""Vinayak Tantia"", ""Nicolas Ballas"", ""Michael Rabbat""]","[""distributed optimization"", ""decentralized training methods"", ""communication-efficient distributed training with momentum"", ""large-scale parallel SGD""]",SlowMo improves the optimization and generalization performance of communication-efficient decentralized algorithms without sacrificing speed.,1910.00643,cs.LG,2019-10-01 20:06:48+00:00,2020-02-19 20:00:02+00:00
SkxKPDv5xl,2017,Accept (Poster),False,SampleRNN: An Unconditional End-to-End Neural Audio Generation Model,"[""Soroush Mehri"", ""Kundan Kumar"", ""Ishaan Gulrajani"", ""Rithesh Kumar"", ""Shubham Jain"", ""Jose Sotelo"", ""Aaron Courville"", ""Yoshua Bengio""]","[""Speech"", ""Deep learning"", ""Unsupervised Learning"", ""Applications""]",Novel model for unconditional audio generation task using hierarchical multi-scale RNNs and autoregressive MLP.,,,,
SkxLFaNKwB,2020,Accept (Poster),False,Computation Reallocation for Object Detection,"[""Feng Liang"", ""Chen Lin"", ""Ronghao Guo"", ""Ming Sun"", ""Wei Wu"", ""Junjie Yan"", ""Wanli Ouyang""]","[""Neural Architecture Search"", ""Object Detection""]",We propose CR-NAS to reallocate engaged  computation resources in different resolution and spatial position.,1912.11234,cs.CV,2019-12-24 07:19:04+00:00,2019-12-24 07:19:04+00:00
SkxMjxHYPS,2020,Reject,False,Filter redistribution templates for iteration-lessconvolutional model reduction,"[""Ramon Izquierdo Cordova"", ""Walterio Mayol Cuevas""]","[""Model reduction"", ""Pruning"", ""filter distribution""]",,,,,
SkxOhANKDr,2020,Reject,False,Generative Cleaning Networks with Quantized Nonlinear Transform  for  Deep Neural Network Defense,"[""Jianhe Yuan"", ""Zhihai He""]","[""Adversarial Defense"", ""Adversarial Attack""]",Defense against adversarial attacks.,,,,
SkxQp1StDH,2020,Accept (Poster),True,Low-dimensional statistical manifold embedding of directed graphs,"[""Thorben Funke"", ""Tian Guo"", ""Alen Lancic"", ""Nino Antulov-Fantulin""]","[""graph embedding"", ""information geometry"", ""graph representations""]","We propose a novel node embedding of directed graphs to statistical manifolds and analyze connections to divergence, geometry and efficient learning procedure.",1905.10227,cs.LG,2019-05-24 13:35:48+00:00,2020-02-06 18:59:25+00:00
SkxSv6VFvS,2020,Accept (Poster),False,Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation,"[""Hang Gao"", ""Xizhou Zhu"", ""Stephen Lin"", ""Jifeng Dai""]","[""Effective Receptive Fields"", ""Deformation Modeling"", ""Dynamic Inference""]",Don't deform your convolutions -- deform your kernels.,,,,
SkxUrTVKDH,2020,Reject,False,Split LBI for Deep Learning: Structural Sparsity via Differential Inclusion Paths,"[""Yanwei Fu"", ""Chen Liu"", ""Donghao Li"", ""Xinwei Sun"", ""Jinshan ZENG"", ""Yuan Yao""]",[],"SplitLBI is applied to deep learning to explore model structural sparsity, achieving state-of-the-art performance in ImageNet-2012 and unveiling effective subnet architecture.",,,,
SkxV0RVYDH,2020,Reject,False,Versatile Anomaly Detection with Outlier Preserving Distribution Mapping Autoencoders,"[""Walter Gerych"", ""Elke Rundensteiner"", ""Emmanuel Agu""]","[""Anomaly detection"", ""outliers"", ""deep learning"", ""distribution mapping"", ""wasserstein autoencoders""]",An extension of Wasserstein autoencoders such that anomalies in the feature-space remain anomalies in the latent space ,,,,
SkxV7kHKvr,2020,Reject,False,TWIN GRAPH CONVOLUTIONAL NETWORKS: GCN WITH DUAL GRAPH SUPPORT FOR SEMI-SUPERVISED LEARNING,"[""Feng Shi"", ""Yizhou Zhao"", ""Ziheng Xu"", ""Tianyang Liu"", ""Song-Chun Zhu""]","[""Graph"", ""Neural Networks"", ""Deep Learning"", ""semi-supervised learning""]",A primal dual graph neural network model for semi-supervised learning,,,,
SkxW23NtPH,2020,Reject,True,GDP: Generalized Device Placement for Dataflow Graphs,"[""Yanqi Zhou"", ""Sudip Roy"", ""Amirali Abdolrashidi"", ""Daniel Wong"", ""Peter C. Ma"", ""Qiumin Xu"", ""Ming Zhong"", ""Hanxiao Liu"", ""Anna Goldie"", ""Azalia Mirhoseini"", ""James Laudon""]","[""device placement"", ""reinforcement learning"", ""graph neural networks"", ""transformer""]",The first end-to-end device placement that can be generalized to unseen graphs. ,1910.01578,cs.LG,2019-09-28 04:13:57+00:00,2019-09-28 04:13:57+00:00
SkxWnkStvS,2020,Reject,False,Searching for Stage-wise Neural Graphs In the Limit,"[""Xin Zhou"", ""Dejing Dou"", ""Boyang Li""]","[""neural architecture search"", ""graphon"", ""random graphs""]",Graphon is a good search space for neural architecture search and empirically produces good networks.,1912.12860,cs.LG,2019-12-30 09:17:23+00:00,2019-12-30 09:17:23+00:00
SkxXCi0qFX,2019,Accept (Poster),True,ProMP: Proximal Meta-Policy Search,"[""Jonas Rothfuss"", ""Dennis Lee"", ""Ignasi Clavera"", ""Tamim Asfour"", ""Pieter Abbeel""]","[""Meta-Reinforcement Learning"", ""Meta-Learning"", ""Reinforcement-Learning""]",A novel and theoretically grounded meta-reinforcement learning algorithm,1810.06784,cs.LG,2018-10-16 01:43:51+00:00,2018-12-21 13:10:34+00:00
SkxXg2C5FX,2019,Accept (Poster),False,"Don't Settle for Average, Go for the Max: Fuzzy Sets and Max-Pooled Word Vectors","[""Vitalii Zhelezniak"", ""Aleksandar Savkov"", ""April Shen"", ""Francesco Moramarco"", ""Jack Flann"", ""Nils Y. Hammerla""]","[""word vectors"", ""sentence representations"", ""distributed representations"", ""fuzzy sets"", ""bag-of-words"", ""unsupervised learning"", ""word vector compositionality"", ""max-pooling"", ""Jaccard index""]",Max-pooled word vectors with fuzzy Jaccard set similarity are an extremely competitive baseline for semantic similarity; we propose a simple dynamic variant that performs even better.,,,,
SkxXwo0qYm,2019,Reject,False,An Automatic Operation Batching Strategy for the Backward Propagation of Neural Networks Having Dynamic Computation Graphs,"[""Yuchen Qiao"", ""Kenjiro Taura""]","[""Automatic Operation Batching"", ""Dynamic Computation Graphs""]",,,,,
SkxYOiCqKX,2019,Reject,False,Pixel Chem: A Representation for Predicting Material Properties with Neural Network,"[""Shuqian Ye"", ""Yanheng Xu"", ""Jiechun Liang"", ""Hao Xu"", ""Shuhong Cai"", ""Shixin Liu"", ""Xi Zhu""]","[""material property prediction"", ""neural network"", ""material structure representation"", ""chemistry""]","Proposed a unified, physics based representation of material structures to predict various properties with neural netwoek.",,,,
SkxZFoAqtQ,2019,Reject,False,Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning,"[""Damien Sileo"", ""Tim Van de Cruys"", ""Camille Pradel"", ""Philippe Muller""]","[""Statistical Relational Learning"", ""Sentence Embedding"", ""Composition functions"", ""Natural Language Inference"", ""InferSent"", ""SentEval"", ""ComplEx""]",We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity,,,,
SkxaueHFPB,2020,Reject,False,Implicit competitive regularization in GANs,"[""Florian Schaefer"", ""Hongkai Zheng"", ""Anima Anandkumar""]","[""GAN"", ""competitive optimization"", ""game theory""]",Training GANs by modeling networks as agents acting with limited information and in awareness of their opponent imposes an implicit regularization that leads to stable convergence and prevents mode collapse.,,,,
SkxbDsR9Ym,2019,Reject,False,RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding,"[""Danushka Bollegala"", ""Huda Hakami"", ""Yuichi Yoshida"", ""Ken-ichi Kawarabayashi""]","[""relation representations"", ""natural language processing"", ""theoretical analysis"", ""knowledge graphs""]",We present a theoretically proven generative model of knowledge graph embedding. ,,,,
SkxcSpEKPS,2020,Reject,False,Generative Adversarial Networks For Data Scarcity Industrial Positron Images With Attention,"[""Mingwei Zhu"", ""Min Zhao"", ""Min Yao"", ""Ruipeng Guo""]",[],"adversarial nets, attention mechanism, positron images, data scarcity",,,,
SkxcZCNKDS,2020,Reject,True,"If MaxEnt RL is the Answer, What is the Question?","[""Benjamin Eysenbach"", ""Sergey Levine""]","[""reinforcement learning"", ""maximum entropy"", ""POMDP""]",We show that MaxEnt RL implicitly solves control problems with variability in rewards.,1910.01913,cs.LG,2019-10-04 12:50:34+00:00,2019-10-04 12:50:34+00:00
Skxd6gSYDS,2020,Accept (Poster),True,Query-efficient Meta Attack to Deep Neural Networks,"[""Jiawei Du"", ""Hu Zhang"", ""Joey Tianyi Zhou"", ""Yi Yang"", ""Jiashi Feng""]","[""Adversarial attack"", ""Meta learning""]",,1906.02398,cs.CV,2019-06-06 03:49:00+00:00,2020-02-15 03:51:45+00:00
SkxgnnNFvH,2020,Accept (Poster),True,Poly-encoders: Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring,"[""Samuel Humeau"", ""Kurt Shuster"", ""Marie-Anne Lachaux"", ""Jason Weston""]",[],,1905.01969,cs.CL,2019-04-22 02:18:00+00:00,2020-03-25 22:53:51+00:00
SkxlElBYDS,2020,Reject,False,Continual Learning via Principal Components Projection,"[""Gyuhak Kim"", ""Bing Liu""]","[""Neural network"", ""continual learning"", ""catastrophic forgetting"", ""lifelong learning""]",,,,,
Skxn-JSYwr,2020,Reject,False,EXPLOITING SEMANTIC COHERENCE TO IMPROVE PREDICTION IN SATELLITE SCENE IMAGE ANALYSIS: APPLICATION TO DISEASE DENSITY ESTIMATION,"[""Rahman Sanya"", ""Gilbert Maiga"", ""Ernest Mwebaze""]","[""semantic coherence"", ""satellite scene image analysis"", ""convolutional neural networks"", ""disease density""]",Approach for improving prediction accuracy by learning deep features over neighboring scene images in satellite scene image analysis.,,,,
SkxoqRNKwr,2020,Reject,False,Adversarial Privacy Preservation under Attribute Inference Attack,"[""Han Zhao"", ""Jianfeng Chi"", ""Yuan Tian"", ""Geoffrey J. Gordon""]",[],,,,,
SkxpDT4YvS,2020,Reject,False,Policy Optimization with Stochastic Mirror Descent,"[""Long Yang"", ""Gang Zheng"", ""Zavier Zhang"", ""Yu Zhang"", ""Qian Zheng"", ""Jun Wen"", ""Gang Pana sample efficient policy gradient method with stochastic mirror descent.""]","[""reinforcement learning"", ""policy gradient"", ""stochastic variance reduce gradient"", ""sample efficiency"", ""stochastic mirror descent""]",We propose a sample efficient policy gradient method with stochastic mirror descent via conducting a variance reduced policy gradient estimator. ,,,,
SkxpxJBKwS,2020,Accept (Spotlight),True,Emergent Tool Use From Multi-Agent Autocurricula,"[""Bowen Baker"", ""Ingmar Kanitscheider"", ""Todor Markov"", ""Yi Wu"", ""Glenn Powell"", ""Bob McGrew"", ""Igor Mordatch""]",[],,1909.07528,cs.LG,2019-09-17 00:17:02+00:00,2020-02-11 00:56:50+00:00
SkxqZngC-,2018,Reject,False,A Bayesian Nonparametric Topic Model with Variational Auto-Encoders,"[""Xuefei Ning"", ""Yin Zheng"", ""Zhuxi Jiang"", ""Yu Wang"", ""Huazhong Yang"", ""Junzhou Huang""]","[""topic model"", ""Bayesian nonparametric"", ""variational auto-encoder"", ""document modeling""]","A Bayesian Nonparametric Topic Model with Variational Auto-Encoders which achieves the state-of-the-arts on public benchmarks in terms of perplexity, topic coherence and retrieval tasks.",,,,
Skxuk1rFwB,2020,Accept (Poster),True,Towards Stable and Efficient Training of Verifiably Robust Neural Networks,"[""Huan Zhang"", ""Hongge Chen"", ""Chaowei Xiao"", ""Sven Gowal"", ""Robert Stanforth"", ""Bo Li"", ""Duane Boning"", ""Cho-Jui Hsieh""]","[""Robust Neural Networks"", ""Verifiable Training"", ""Certified Adversarial Defense""]","We propose a new certified adversarial training method, CROWN-IBP, that achieves state-of-the-art robustness for L_inf norm adversarial perturbations.",1906.06316,cs.LG,2019-06-14 17:44:40+00:00,2019-11-27 11:03:27+00:00
Skxw-REFwS,2020,Reject,False,Unsupervised Progressive Learning and the STAM Architecture,"[""James Smith"", ""Constantine Dovrolis""]","[""continual learning"", ""unsupervised learning"", ""online learning""]",We introduce Unsupervised  Progressive  Learning  (UPL) and evaluate a neuro-inspired architecture: Self-Taught Associative Memory (STAM).,,,,
SkxxIs0qY7,2019,Reject,False,CoT: Cooperative Training for Generative Modeling of Discrete Data,"[""Sidi Lu"", ""Lantao Yu"", ""Siyuan Feng"", ""Yaoming Zhu"", ""Weinan Zhang"", ""Yong Yu""]","[""Generative Models"", ""Sequence Modeling"", ""Text Generation""]","We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.",,,,
SkxxtgHKPS,2020,Accept (Poster),True,On Generalization Error Bounds of Noisy Gradient Methods for Non-Convex Learning,"[""Jian Li"", ""Xuanyuan Luo"", ""Mingda Qiao""]","[""learning theory"", ""generalization"", ""nonconvex learning"", ""stochastic gradient descent"", ""Langevin dynamics""]","We give some generalization error bounds of noisy gradient methods such as SGLD, Langevin dynamics, noisy momentum and so forth.",1902.00621,cs.LG,2019-02-02 02:15:25+00:00,2020-02-29 03:36:22+00:00
SkxybANtDB,2020,Accept (Poster),False,Dynamic Time Lag Regression: Predicting What & When,"[""Mandar Chandorkar"", ""Cyril Furtlehner"", ""Bala Poduval"", ""Enrico Camporeale"", ""Michele Sebag""]","[""Dynamic Time-Lag Regression"", ""Time Delay"", ""Regression"", ""Time Series""]",We propose a new regression framework for temporal phenomena having non-stationary time-lag dependencies.,,,,
SkxzSgStPS,2020,Reject,False,Exploration via Flow-Based Intrinsic Rewards,"[""Hsuan-Kung Yang"", ""Po-Han Chiang"", ""Min-Fong Hong"", ""Chun-Yi Lee""]","[""reinforcement learning"", ""exploration"", ""curiosity"", ""optical flow"", ""intrinsic rewards""]",,,,,
SkyQWDcex,2017,Reject,False,A Context-aware Attention Network for Interactive Question Answering,"[""Huayu Li"", ""Martin Renqiang Min"", ""Yong Ge"", ""Asim Kadav""]","[""Deep learning"", ""Natural language processing"", ""Applications""]",A self-adaptive QA model aware of what it knows and what it does not know for interactive question answering.,,,,
SkymMAxAb,2018,Reject,False,AirNet: a machine learning dataset for air quality forecasting,"[""Songgang Zhao"", ""Xingyuan Yuan"", ""Da Xiao"", ""Jianyuan Zhang"", ""Zhouyuan Li""]",[],,,,,
Skz-3j05tm,2019,Reject,False,Graph Convolutional Network with Sequential Attention For Goal-Oriented Dialogue Systems,"[""Suman Banerjee"", ""Mitesh M. Khapra""]","[""Goal-oriented Dialogue Systems"", ""Graph Convolutional Networks""]",We propose a Graph Convolutional Network based encoder-decoder model with sequential attention for goal-oriented dialogue systems.,,,,
Skz3Q2CcFX,2019,Reject,False,Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae,"[""Piero Molino"", ""Yang Wang"", ""Jiawei Zhang""]","[""visualization"", ""embeddings"", ""representations"", ""t-sne"", ""natural"", ""language"", ""processing"", ""machine"", ""learning"", ""algebra""]",We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.,,,,
SkzK4iC5Ym,2019,Reject,False,Diminishing Batch Normalization,"[""Yintai Ma"", ""Diego Klabjan""]","[""deep learning"", ""learning theory"", ""convergence analysis"", ""batch normalization""]","We propose a extension of the batch normalization, show a first-of-its-kind convergence analysis for this extension and show in numerical experiments that it has better performance than the original batch normalizatin.",,,,
Skz_WfbCZ,2018,Accept (Poster),True,A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks,"[""Behnam Neyshabur"", ""Srinadh Bhojanapalli"", ""Nathan Srebro""]","[""Neural Networks"", ""Generalization"", ""PAC-Bayes"", ""Sharpness""]",,1707.09564,cs.LG,2017-07-29 22:36:35+00:00,2018-02-23 22:30:45+00:00
SkzeJ3A9F7,2019,Reject,False,Beyond Games: Bringing Exploration to Robots in Real-world,"[""Deepak Pathak"", ""Dhiraj Gandhi"", ""Abhinav Gupta""]","[""Exploration"", ""curiosity"", ""manipulation""]",,,,,
SlprFTIQP3,2021,Reject,False,Recall Loss for Imbalanced Image Classification and Semantic Segmentation,"[""Junjiao Tian"", ""Niluthpol Chowdhury Mithun"", ""Zachary Seymour"", ""Han-pang Chiu"", ""Zsolt Kira""]","[""Data Imbalance"", ""Classification"", ""Semantic Segmentation"", ""Deep Learning""]",We proposed a new loss function based on the metric recall for imbalanced classification problems. ,,,,
SlrqM9_lyju,2021,Accept (Poster),False,AutoLRS: Automatic Learning-Rate Schedule by Bayesian Optimization on the Fly,"[""Yuchen Jin"", ""Tianyi Zhou"", ""Liangyu Zhao"", ""Yibo Zhu"", ""Chuanxiong Guo"", ""Marco Canini"", ""Arvind Krishnamurthy""]",[],,2105.10762,cs.LG,2021-05-22 16:41:10+00:00,2021-05-22 16:41:10+00:00
SlxSY2UZQT,2022,Accept (Poster),False,Label-Efficient Semantic Segmentation with Diffusion Models,"['Dmitry Baranchuk', 'Andrey Voynov', 'Ivan Rubachev', 'Valentin Khrulkov', 'Artem Babenko']",[],,,,,
Sm_4MDxPWXf,2021,Reject,False,StructFormer: Joint Unsupervised Induction of Dependency and Constituency Structure from Masked Language Modeling,"[""Yikang Shen"", ""Yi Tay"", ""Che Zheng"", ""Dara Bahri"", ""Donald Metzler"", ""Aaron Courville""]","[""Unsupervised Dependency Parsing"", ""Unsupervised Constituency Parsing"", ""Masked Language Model""]",We propose a novel neural network based model that can do unsupervised dependency and constituency parsing at the same time.,2012.00857,cs.CL,2020-12-01 21:54:51+00:00,2021-07-11 01:10:26+00:00
SncSswKUse,2021,Reject,True,Factorized linear discriminant analysis for phenotype-guided representation learning of neuronal gene expression data,"[""Mu Qiao"", ""Markus Meister""]","[""factorized linear discriminant analysis"", ""phenotype"", ""gene expression"", ""representation learning""]",We describe a novel supervised approach that learns a meaningful representation of neuronal gene expressions based on phenotypes,2010.02171,q-bio.QM,2020-10-05 17:18:56+00:00,2021-03-27 05:53:43+00:00
SnhmiKUPWL,2021,Reject,True,Leveraging Class Hierarchies with Metric-Guided Prototype Learning,"[""Vivien Sainte Fare Garnot"", ""Loic Landrieu""]","[""hierarchical classification"", ""prototypical networks""]","We introduce a new prototypes-based method to model class hierarchies in classification tasks, resulting in a decrease of both the average cost of misclassifications and the overall rate of errors.",2007.03047,cs.LG,2020-07-06 20:22:08+00:00,2020-10-02 15:08:46+00:00
Snqhqz4LdK,2022,Reject,False,Generating Realistic 3D Molecules with an Equivariant Conditional Likelihood Model,"['James P. Roney', 'Paul Maragakis', 'Peter Skopp', 'David E. Shaw']","[""Generative Models"", ""Molecular Graphs"", ""3D Molecules"", ""Drug Discovery"", ""Equivariance""]","We present GEN3D, an equivariant conditional likelihood model that concurrently constructs molecular graphs and associated 3D geometries, improving the state of the art on both tasks.",,,,
So6YAqnqgMj,2022,Accept (Poster),False,EigenGame Unloaded: When playing games is better than optimizing,"['Ian Gemp', 'Brian McWilliams', 'Claire Vernade', 'Thore Graepel']","[""pca"", ""principal components analysis"", ""nash"", ""games"", ""eigendecomposition"", ""svd"", ""singular value decomposition""]","We improve the EigenGame algorithm by removing update bias, enabling further parallelism and better performance.",,,,
Sq0-tgDyHe4,2022,Accept (Poster),False,Local Feature Swapping for Generalization in Reinforcement Learning,"['David Bertoin', 'Emmanuel Rachelson']","[""Reinforcement learning"", ""Generalization"", ""Regularization""]",We propose a simple yet effective layer increasing the generalization abilities of reinforcement learning agents,,,,
Sqv6rs_TRV,2022,Reject,False,WHAT TO DO IF SPARSE REPRESENTATION LEARNING FAILS UNEXPECTEDLY?,"['Jingyi Yuan', 'Haoran Li', 'Erik Blasch', 'Yang Weng']","[""Physical neural network"", ""extrapolation""]",,,,,
Srmggo3b3X6,2021,Accept (Poster),True,"For self-supervised learning, Rationality implies generalization, provably","[""Yamini Bansal"", ""Gal Kaplun"", ""Boaz Barak""]","[""Deep Learning Theory"", ""Generalization Bounds"", ""Self-supervised learning"", ""Representation learning""]",We prove and empirically demonstrate generalization bounds for algorithms that fit a simple classifier on a representation learned via self-supervision; we obtain non-vacuous bounds for such top-performing algorithms on both CIFAR-10 and ImageNet.,2010.08508,cs.LG,2020-10-16 17:07:52+00:00,2020-10-16 17:07:52+00:00
SsHBkfeRF9L,2022,Accept (Poster),True,Neural graphical modelling in continuous-time: consistency guarantees and algorithms,"['Alexis Bellot', 'Kim Branson', 'Mihaela van der Schaar']","[""Dynamical systems"", ""graphical modelling"", ""structure learning""]",We present algorithms and consistency guarantees for graphical modelling in dynamical systems.,2105.02522,stat.ML,2021-05-06 08:48:02+00:00,2022-02-03 15:19:54+00:00
SsPCtEY6yCl,2022,Accept (Spotlight),False,On the Uncomputability of Partition Functions in Energy-Based Sequence Models,"['Chu-Cheng Lin', 'Arya D. McCarthy']","[""energy-based models"", ""turing completeness"", ""model capacity"", ""sequence models"", ""autoregressive models"", ""partition function"", ""parameter estimation"", ""model selection""]",EBMs over sequences have several theoretical limitations as learnable probabilistic sequence models.,,,,
St-53J9ZARf,2022,Accept (Poster),False,Deep AutoAugment,"['Yu Zheng', 'Zhi Zhang', 'Shen Yan', 'Mi Zhang']","[""automated machine learning"", ""data augmentation""]","We propose Deep AutoAugment (DeepAA), a fully automated automated data augmentation methods that outperforms previous automated data augmentation methods.",,,,
St1giarCHLP,2021,Accept (Poster),True,Denoising Diffusion Implicit Models,"[""Jiaming Song"", ""Chenlin Meng"", ""Stefano Ermon""]","[""generative models"", ""variational autoencoders"", ""denoising score matching"", ""variational inference""]","We show and justify a GAN-like iterative generative model with relatively fast sampling, high sample quality and without any adversarial training.",2010.02502,cs.LG,2020-10-06 06:15:51+00:00,2021-11-04 03:52:44+00:00
St6eyiTEHnG,2022,Accept (Poster),False,Consistent Counterfactuals for Deep Models,"['Emily Black', 'Zifan Wang', 'Matt Fredrikson']","[""deep models"", ""deep networks"", ""explainability"", ""counterfactual explanations"", ""consistency"", ""consistent predictions"", ""model duplicity"", ""random initialization""]",Counterfactual explanations are often inconsistent between virtually identical deep models. We introduce a new method to increase consistency while keeping costs low relative to other fixes.,,,,
SuKTLF9stD,2022,Reject,False,Data-Efficient Augmentation for Training Neural Networks,"['Tian Yu Liu', 'Baharan Mirzasoleiman']","[""Data Augmentation"", ""Neural Network"", ""Coresets""]",We theoretically analyze data augmentation and propose a rigorous technique to select subsets of data points that when augmented provide a similar speedup and generalization performance as that of full data augmentation.,,,,
SvFQBlffMB,2022,Reject,False,Pseudo Knowledge Distillation: Towards Learning Optimal Instance-specific Label Smoothing Regularization,"['Peng Lu', 'Ahmad Rashid', 'Ivan Kobyzev', 'Mehdi Rezagholizadeh', 'Philippe Langlais']","[""Knowledge Distillation"", ""Label Smoothing"", ""Supervised Learning"", ""Image Classification"", ""Natural Language Understanding""]",We devise a two-stage optimization problem that leads to a deterministic and interpretable solution for the optimal label smoothing regularization.,,,,
Sva-fwURywB,2021,Reject,False,Efficiently Disentangle Causal Representations,"[""Yuanpeng Li"", ""Joel Hestness"", ""Mohamed Elhoseiny"", ""Liang Zhao"", ""Kenneth Church""]","[""causality"", ""representation learning""]",,,,,
Svfh1_hYEtF,2021,Reject,True,Federated Continual Learning with Weighted Inter-client Transfer,"[""Jaehong Yoon"", ""Wonyong Jeong"", ""Giwoong Lee"", ""Eunho Yang"", ""Sung Ju Hwang""]","[""Continual Learning"", ""Federated Learning"", ""Deep Learning""]","We define a problem of federated continual learning and propose a novel federated continual learning framework, Weighted Inter-client Transfer (FedWeIT).",2003.03196,cs.LG,2020-03-06 13:33:48+00:00,2021-06-14 07:57:18+00:00
SwIp410B6aQ,2022,Accept (Poster),False,On the Role of Neural Collapse in Transfer Learning,"['Tomer Galanti', 'AndrÃ¡s GyÃ¶rgy', 'Marcus Hutter']",[],,2112.15121,cs.LG,2021-12-30 16:36:26+00:00,2022-01-04 04:06:26+00:00
Sy-dQG-Rb,2018,Accept (Poster),False,Neural Speed Reading via Skim-RNN,"[""Minjoon Seo"", ""Sewon Min"", ""Ali Farhadi"", ""Hannaneh Hajishirzi""]","[""Natural Language Processing"", ""RNN"", ""Inference Speed""]",,,,,
Sy-tszZRZ,2018,Reject,False,Bounding and Counting Linear Regions of Deep Neural Networks,"[""Thiago Serra"", ""Christian Tjandraatmadja"", ""Srikumar Ramalingam""]","[""rectifier networks"", ""maxout networks"", ""piecewise linear functions"", ""linear regions"", ""mixed-integer programming""]",We empirically count the number of linear regions of rectifier networks and refine upper and lower bounds.,,,,
Sy0GnUxCb,2018,Accept (Poster),False,Emergent Complexity via Multi-Agent Competition,"[""Trapit Bansal"", ""Jakub Pachocki"", ""Szymon Sidor"", ""Ilya Sutskever"", ""Igor Mordatch""]","[""multi-agent systems"", ""multi-agent competition"", ""self-play"", ""deep reinforcement learning""]",,,,,
Sy1f0e-R-,2018,Reject,False,An empirical study on evaluation metrics of generative adversarial networks,"[""Gao Huang"", ""Yang Yuan"", ""Qiantong Xu"", ""Chuan Guo"", ""Yu Sun"", ""Felix Wu"", ""Kilian Weinberger""]","[""generative adversarial networks"", ""evaluation metric""]",,,,,
Sy1rwtKxg,2017,Reject,False,Parallel Stochastic Gradient Descent with Sound Combiners,"[""Saeed Maleki"", ""Madanlal Musuvathi"", ""Todd Mytkowicz"", ""Yufei Ding""]",[],"This paper proposes SymSGD, a parallel SGD algorithm that retains the sequential semantics of SGD in expectation.",,,,
Sy21R9JAW,2018,Accept (Poster),False,Towards better understanding of gradient-based attribution methods for Deep Neural Networks,"[""Marco Ancona"", ""Enea Ceolini"", ""Cengiz \u00d6ztireli"", ""Markus Gross""]","[""Deep Neural Networks"", ""Attribution methods"", ""Theory of deep learning""]",Four existing backpropagation-based attribution methods are fundamentally similar. How to assess it?,,,,
Sy2fzU9gl,2017,Accept (Poster),False,beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework,"[""Irina Higgins"", ""Loic Matthey"", ""Arka Pal"", ""Christopher Burgess"", ""Xavier Glorot"", ""Matthew Botvinick"", ""Shakir Mohamed"", ""Alexander Lerchner""]",[],"We introduce beta-VAE, a new state-of-the-art framework for automated discovery of interpretable factorised latent representations from raw image data in a completely unsupervised manner.",,,,
Sy2ogebAW,2018,Accept (Poster),False,Unsupervised Neural Machine Translation,"[""Mikel Artetxe"", ""Gorka Labaka"", ""Eneko Agirre"", ""Kyunghyun Cho""]","[""neural machine translation"", ""unsupervised learning""]","We introduce the first successful method to train neural machine translation in an unsupervised manner, using nothing but monolingual corpora",,,,
Sy3XxCx0Z,2018,Invite to Workshop Track,False,Natural Language Inference with External Knowledge,"[""Qian Chen"", ""Xiaodan Zhu"", ""Zhen-Hua Ling"", ""Diana Inkpen""]","[""natural language inference"", ""external knowledge"", ""state of the art""]",the proposed models with external knowledge further improve the state of the art on the SNLI dataset.,,,,
Sy3fJXbA-,2018,Reject,False,Connectivity Learning in Multi-Branch Networks,"[""Karim Ahmed"", ""Lorenzo Torresani""]","[""connectivity learning"", ""multi-branch networks"", ""image categorization""]",In this paper we introduced an algorithm to learn the connectivity of deep multi-branch networks. The approach is evaluated on image categorization where it consistently yields accuracy gains over state-of-the-art models that use fixed connectivity.,,,,
Sy4c-3xRW,2018,Invite to Workshop Track,False,DropMax: Adaptive Stochastic Softmax,"[""Hae Beom Lee"", ""Juho Lee"", ""Eunho Yang"", ""Sung Ju Hwang""]",[],,,,,
Sy4lojC9tm,2019,Reject,False,Dataset Distillation,"[""Tongzhou Wang"", ""Jun-Yan Zhu"", ""Antonio Torralba"", ""Alexei A. Efros""]","[""knowledge distillation"", ""deep learning"", ""few-shot learning"", ""adversarial attack""]","We propose to distill a large dataset into a small set of synthetic data , so networks can achieve close to original performance when trained on these data.",,,,
Sy4tzwqxe,2017,Reject,False,Two Methods for Wild Variational Inference,"[""Qiang Liu"", ""Yihao Feng""]","[""Theory""]",,,,,
Sy5OAyZC-,2018,Reject,False,On the Use of Word Embeddings Alone to Represent Natural Language Sequences,"[""Dinghan Shen"", ""Guoyin Wang"", ""Wenlin Wang"", ""Martin Renqiang Min"", ""Qinliang Su"", ""Yizhe Zhang"", ""Ricardo Henao"", ""Lawrence Carin""]","[""Natural Language Processing"", ""Deep Learning""]",,,,,
Sy6iJDqlx,2017,Accept (Poster),False,"Attend, Adapt and Transfer: Attentive Deep Architecture for Adaptive Transfer from multiple sources in the same domain","[""Janarthanan Rajendran"", ""Aravind Lakshminarayanan"", ""Mitesh M. Khapra"", ""Prasanna P"", ""Balaraman Ravindran""]","[""Deep learning"", ""Reinforcement Learning"", ""Transfer Learning""]",We propose a general architecture for transfer that can avoid negative transfer and transfer selectively from multiple source tasks in the same domain.,,,,
Sy7m72Ogg,2017,Reject,False,An Actor-critic Algorithm for Learning Rate Learning,"[""Chang Xu"", ""Tao Qin"", ""Gang Wang"", ""Tie-Yan Liu""]","[""Deep learning"", ""Reinforcement Learning""]",We propose an algorithm to automatically learn learning rates using actor-critic methods from reinforcement learning.,,,,
Sy8XvGb0-,2018,Accept (Poster),False,Latent Constraints: Learning to Generate Conditionally from Unconditional Generative Models,"[""Jesse Engel"", ""Matthew Hoffman"", ""Adam Roberts""]","[""VAE"", ""GAN"", ""generative networks"", ""conditional generation"", ""latent-variable models""]",A new approach to conditional generation by constraining the latent space of an unconditional generative model.,,,,
Sy8gdB9xx,2017,Accept (Oral),False,Understanding deep learning requires rethinking generalization,"[""Chiyuan Zhang"", ""Samy Bengio"", ""Moritz Hardt"", ""Benjamin Recht"", ""Oriol Vinyals""]","[""Deep learning""]","Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.",,,,
SyAbZb-0Z,2018,Reject,False,Transfer Learning to Learn with Multitask Neural Model Search,"[""Catherine Wong"", ""Andrea Gesmundo""]","[""Learning to Learn"", ""Meta learning"", ""Reinforcement learning"", ""Transfer learning""]","We present Multitask Neural Model Search, a Meta-learner that can design models for multiple tasks simultaneously and transfer learning to unseen tasks.",,,,
SyBBgXWAZ,2018,Reject,False,Optimal transport maps for distribution preserving operations on latent spaces of Generative Models,"[""Eirikur Agustsson"", ""Alexander Sage"", ""Radu Timofte"", ""Luc Van Gool""]","[""Generative Models"", ""GANs"", ""latent space operations"", ""optimal transport""]","Operations in the GAN latent space can induce a distribution mismatch compared to the training distribution, and we address this using optimal transport to match the distributions. ",,,,
SyCSsUDee,2017,Reject,False,Semantic Noise Modeling for Better Representation Learning,"[""Hyo-Eun Kim"", ""Sangheum Hwang"", ""Kyunghyun Cho""]","[""Deep learning"", ""Supervised Learning""]",A novel latent space modeling method to learn better representation,,,,
SyELrEeAb,2018,Accept (Poster),False,Implicit Causal Models for Genome-wide Association Studies,"[""Dustin Tran"", ""David M. Blei""]",[],Implicit models applied to causality and genetics,,,,
SyEiHNKxx,2017,Invite to Workshop Track,False,A Differentiable Physics Engine for Deep Learning in Robotics,"[""Jonas Degrave"", ""Michiel Hermans"", ""Joni Dambre"", ""Francis wyffels""]","[""Deep learning""]",We wrote a framework to differentiate through physics and show that this makes training deep learned controllers for robotics remarkably fast and straightforward,,,,
SyF7Erp6W,2018,Reject,False,Learning to play slot cars and Atari 2600 games in just minutes,"[""Lionel Cordesses"", ""Omar Bentahar"", ""Julien Page""]","[""Artificial Intelligence"", ""Signal processing"", ""Philosophy"", ""Analogy"", ""ALE"", ""Slot Car""]",Continental-philosophy-inspired approach to learn with few data.,,,,
SyG4RiR5Ym,2019,Reject,False,Neural Distribution Learning for generalized time-to-event prediction,"[""Egil Martinsson"", ""Adrian Kim"", ""Jaesung Huh"", ""Jaegul Choo"", ""Jung-Woo Ha""]","[""Deep Learning"", ""Survival Analysis"", ""Event prediction"", ""Time Series"", ""Probabilistic Programming"", ""Density Networks""]",We present a general solution to event prediction that has been there all along; Discrete Time Parametric Survival Analysis.,,,,
SyGT_6yCZ,2018,Reject,False,Simple Fast Convolutional Feature Learning,"[""David Mac\u00eado"", ""Cleber Zanchettin"", ""Teresa Ludermir""]","[""Feature Learning"", ""Convolutional Neural Networks"", ""Visual Recognition""]",A simple fast method for extracting visual features from convolutional neural networks,,,,
SyGjQ30qFX,2019,Reject,False,TopicGAN: Unsupervised Text Generation from Explainable Latent Topics,"[""Yau-Shian Wang"", ""Yun-Nung Chen"", ""Hung-Yi Lee""]","[""unsupervised learning"", ""topic model"", ""text generation""]",,,,,
SyGjjsC5tQ,2019,Accept (Poster),False,Stable Opponent Shaping in Differentiable Games,"[""Alistair Letcher"", ""Jakob Foerster"", ""David Balduzzi"", ""Tim Rockt\u00e4schel"", ""Shimon Whiteson""]","[""multi-agent learning"", ""multiple interacting losses"", ""opponent shaping"", ""exploitation"", ""convergence""]",Opponent shaping is a powerful approach to multi-agent learning but can prevent convergence; our SOS algorithm fixes this with strong guarantees in all differentiable games.,,,,
SyJ7ClWCb,2018,Accept (Poster),False,Countering Adversarial Images using Input Transformations,"[""Chuan Guo"", ""Mayank Rana"", ""Moustapha Cisse"", ""Laurens van der Maaten""]","[""adversarial example"", ""machine learning security"", ""computer vision"", ""image classification""]",We apply a model-agnostic defense strategy against adversarial examples and achieve 60% white-box accuracy and 90% black-box accuracy against major attack algorithms.,,,,
SyJNmVqgg,2017,Invite to Workshop Track,False,Neural Data Filter for Bootstrapping Stochastic Gradient Descent,"[""Yang Fan"", ""Fei Tian"", ""Tao Qin"", ""Tie-Yan Liu""]","[""Reinforcement Learning"", ""Deep learning"", ""Optimization""]",We propose a reinforcement learning based teacher-student framework for filtering training data to boost SGD convergence.,,,,
SyJS-OgR-,2018,Accept (Poster),False,Multi-level Residual Networks from Dynamical Systems View,"[""Bo Chang"", ""Lili Meng"", ""Eldad Haber"", ""Frederick Tung"", ""David Begert""]","[""residual networks"", ""dynamical systems""]",,,,,
SyK00v5xx,2017,Accept (Poster),False,A Simple but Tough-to-Beat Baseline for Sentence Embeddings,"[""Sanjeev Arora"", ""Yingyu Liang"", ""Tengyu Ma""]","[""Natural language processing"", ""Unsupervised Learning""]",A simple unsupervised method for sentence embedding that can get results comparable to sophisticated models like RNN's and LSTM's,,,,
SyKoKWbC-,2018,Invite to Workshop Track,False,Distributional Adversarial Networks,"[""Chengtao Li"", ""David Alvarez-Melis"", ""Keyulu Xu"", ""Stefanie Jegelka"", ""Suvrit Sra""]","[""adversarial learning"", ""generative model"", ""domain adaptation"", ""two-sample test""]","We show that the mode collapse problem in GANs may be explained by a lack of information sharing between observations in a training batch, and propose a distribution-based framework for globally sharing information between gradients that leads to more stable and effective adversarial training.",,,,
SyL9u-WA-,2018,Reject,False,Stabilizing Gradients for Deep Neural Networks via Efficient SVD Parameterization,"[""Jiong Zhang"", ""Qi Lei"", ""Inderjit S. Dhillon""]","[""Recurrent Neural Network"", ""Vanishing Gradient"", ""Exploding Gradient"", ""Linear Algebra"", ""Householder Reflections""]","To solve the gradient vanishing/exploding problems, we proprose an efficient parametrization of the transition matrix of RNN that loses no expressive power, converges faster and has good generalization.",,,,
SyMDXnCcF7,2019,Accept (Poster),False,A Mean Field Theory of Batch Normalization,"[""Greg Yang"", ""Jeffrey Pennington"", ""Vinay Rao"", ""Jascha Sohl-Dickstein"", ""Samuel S. Schoenholz""]","[""theory"", ""batch normalization"", ""mean field theory"", ""trainability""]",Batch normalization causes exploding gradients in vanilla feedforward networks.,1902.08129,cs.NE,2019-02-21 16:36:13+00:00,2019-03-05 21:42:13+00:00
SyMWn05F7,2019,Accept (Poster),False,Learning Exploration Policies for Navigation,"[""Tao Chen"", ""Saurabh Gupta"", ""Abhinav Gupta""]","[""Exploration"", ""navigation"", ""reinforcement learning""]",,,,,
SyMhLo0qKQ,2019,Accept (Poster),False,Distribution-Interpolation Trade off in Generative Models,"[""Damian Le\u015bniak"", ""Igor Sieradzki"", ""Igor Podolak""]","[""generative models"", ""latent distribution"", ""Cauchy distribution"", ""interpolations""]",We theoretically prove that linear interpolations are unsuitable for analysis of trained implicit generative models. ,,,,
SyMras0cFQ,2019,Reject,False,An adaptive homeostatic algorithm for the unsupervised learning of visual features,"[""Victor Boutin"", ""Angelo Franciosini"", ""Laurent Perrinet""]","[""Sparse Coding"", ""Unsupervised Learning"", ""Natural Scene Statistics"", ""Biologically Plausible Deep Networks"", ""Visual Perception"", ""Computer Vision""]",Unsupervised learning is hard and depends on normalisation heuristics. Can we find a simpler approach?,,,,
SyMvJrdaW,2018,Accept (Poster),False,Decoupling the Layers in Residual Networks,"[""Ricky Fok"", ""Aijun An"", ""Zana Rashidi"", ""Xiaogang Wang""]","[""Warped residual networks"", ""residual networks""]",We propose the Warped Residual Network using a parallelizable warp operator for forward and backward propagation to distant layers that trains faster than the original residual neural network. ,,,,
SyNPk2R9K7,2019,Accept (Poster),False,Learning to Describe Scenes with Programs,"[""Yunchao Liu"", ""Zheng Wu"", ""Daniel Ritchie"", ""William T. Freeman"", ""Joshua B. Tenenbaum"", ""Jiajun Wu""]","[""Structured scene representations"", ""program synthesis""]","We present scene programs, a structured scene representation that captures both low-level object appearance and high-level regularity in the scene.",,,,
SyNbRj09Y7,2019,Reject,False,Visual Imitation Learning with Recurrent Siamese Networks,"[""Glen Berseth"", ""Christopher J. Pal""]","[""Reinforcement Learning"", ""Imitation Learning"", ""Deep Learning""]",Learning a vision-based recurrent distance function to allow agents to imitate behaviours from noisy video data.,,,,
SyNvti09KQ,2019,Accept (Poster),False,Visceral Machines: Risk-Aversion in  Reinforcement Learning with Intrinsic Physiological Rewards,"[""Daniel McDuff"", ""Ashish Kapoor""]","[""Reinforcement Learning"", ""Simulation"", ""Affective Computing""]",We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. ,,,,
SyOK1Sg0W,2018,Accept (Poster),False,Adaptive Quantization of Neural Networks,"[""Soroosh Khoram"", ""Jing Li""]","[""Deep Neural Networks"", ""Model Quantization"", ""Model Compression""]",An adaptive method for fixed-point quantization of neural networks based on theoretical analysis rather than heuristics. ,,,,
SyOvg6jxx,2017,Reject,False,#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning,"[""Haoran Tang"", ""Rein Houthooft"", ""Davis Foote"", ""Adam Stooke"", ""Xi Chen"", ""Yan Duan"", ""John Schulman"", ""Filip De Turck"", ""Pieter Abbeel""]","[""Deep learning"", ""Reinforcement Learning"", ""Games""]",We improve exploration in deep reinforcement learning by simply hashing states and assigning bonus rewards according to state counts.,,,,
SyPMT6gAb,2018,Reject,False,Variance Regularized Counterfactual Risk Minimization via Variational Divergence Minimization,"[""Hang Wu""]","[""Counterfactual Inference"", ""Off-Policy Learning"", ""Variance Regularization""]","For off-policy learning with bandit feedbacks, we propose a new variance regularized counterfactual learning algorithm, which has both theoretical foundations and superior empirical performance.",,,,
SyProzZAW,2018,Accept (Poster),False,The power of deeper networks for expressing natural functions,"[""David Rolnick"", ""Max Tegmark""]","[""expressivity of neural networks"", ""depth of neural networks"", ""universal approximators"", ""function approximation"", ""deep learning""]",We prove that deep neural networks are exponentially more efficient than shallow ones at approximating sparse multivariate polynomials.,,,,
SyQq185lg,2017,Accept (Poster),False,Latent Sequence Decompositions,"[""William Chan"", ""Yu Zhang"", ""Quoc Le"", ""Navdeep Jaitly""]","[""Speech"", ""Applications"", ""Natural language processing"", ""Deep learning""]",,,,,
SySaJ0xCZ,2018,Invite to Workshop Track,False,Simple and efficient architecture search for Convolutional Neural Networks,"[""Thomas Elsken"", ""Jan Hendrik Metzen"", ""Frank Hutter""]","[""Deep Learning"", ""Hyperparameter Optimization"", ""Architecture Search"", ""Convolutional Neural Networks"", ""Network Morphism"", ""Network Transformation"", ""SGDR"", ""Cosine annealing"", ""hill climbing""]",We propose a simple and efficent method for architecture search for convolutional neural networks.,,,,
SySisz-CW,2018,Reject,False,On the difference between building and extracting patterns: a causal analysis of deep generative models.,"[""Michel Besserve"", ""Dominik Janzing"", ""Bernhard Schoelkopf""]","[""GAN"", ""VAE"", ""causality""]",We use causal inference to characterise the architecture of generative models,,,,
SySpa-Z0Z,2018,Reject,False,From Information Bottleneck To Activation Norm Penalty,"[""Allen Nie"", ""Mihir Mongia"", ""James Zou""]","[""Deep Learning"", ""Natural Language Processing""]",We derive a norm penalty on the output of the neural network from the information bottleneck perspective,,,,
SyUkxxZ0b,2018,Invite to Workshop Track,False,Adversarial Spheres,"[""Justin Gilmer"", ""Luke Metz"", ""Fartash Faghri"", ""Sam Schoenholz"", ""Maithra Raghu"", ""Martin Wattenberg"", ""Ian Goodfellow""]","[""Adversarial Examples"", ""Deep Learning""]",We hypothesize that the vulnerability of image models to small adversarial perturbation is a naturally occurring result of the high dimensional geometry of the data manifold. We explore and theoretically prove this hypothesis for a simple synthetic dataset.,,,,
SyVOjfbRb,2018,Invite to Workshop Track,False,LSH-SAMPLING BREAKS THE COMPUTATIONAL CHICKEN-AND-EGG LOOP IN ADAPTIVE STOCHASTIC GRADIENT ESTIMATION,"[""Beidi Chen"", ""Yingchen Xu"", ""Anshumali Shrivastava""]","[""Stochastic Gradient Descent"", ""Optimization"", ""Sampling"", ""Estimation""]",We improve the running of all existing gradient descent algorithms.,,,,
SyVU6s05K7,2019,Accept (Poster),False,Deep Frank-Wolfe For Neural Network Optimization,"[""Leonard Berrada"", ""Andrew Zisserman"", ""M. Pawan Kumar""]","[""optimization"", ""conditional gradient"", ""Frank-Wolfe"", ""SVM""]",We train neural networks by locally linearizing them and using a linear SVM solver (Frank-Wolfe) at each iteration.,,,,
SyVVJ85lg,2017,Accept (Poster),False,Paleo: A Performance Model for Deep Neural Networks,"[""Hang Qi"", ""Evan R. Sparks"", ""Ameet Talwalkar""]","[""Deep learning""]",Paleo: An analytical performance model for exploring the space of scalable deep learning systems and quickly diagnosing their effectiveness for a given problem instance.,,,,
SyVVXngRW,2018,Reject,False,Deep Asymmetric Multi-task Feature Learning,"[""Hae Beom Lee"", ""Eunho Yang"", ""Sung Ju Hwang""]",[],,,,,
SyVhg20cK7,2019,Reject,False,Inducing Cooperation via Learning to reshape rewards in semi-cooperative multi-agent reinforcement learning,"[""David Earl Hostallero"", ""Daewoo Kim"", ""Kyunghwan Son"", ""Yung Yi""]","[""multi-agent reinforcement learning"", ""deep reinforcement learning"", ""multi-agent systems""]",We use an peer evaluation mechanism to make semi-cooperative agents learn collaborative strategies in multiagent reinforcement learning settings,,,,
SyVpB2RqFX,2019,Reject,False,INFORMATION MAXIMIZATION AUTO-ENCODING,"[""Dejiao Zhang"", ""Tianchen Zhao"", ""Laura Balzano""]","[""Information maximization"", ""unsupervised learning of hybrid of discrete and continuous representations""]","Information theoretical approach for unsupervised learning of unsupervised learning of a hybrid of discrete and continuous representations, ",,,,
SyVuRiC5K7,2019,Accept (Poster),False,LEARNING TO PROPAGATE LABELS: TRANSDUCTIVE PROPAGATION NETWORK FOR FEW-SHOT LEARNING,"[""Yanbin Liu"", ""Juho Lee"", ""Minseop Park"", ""Saehoon Kim"", ""Eunho Yang"", ""Sung Ju Hwang"", ""Yi Yang""]","[""few-shot learning"", ""meta-learning"", ""label propagation"", ""manifold learning""]",We propose a novel meta-learning framework for transductive inference that classifies the entire test set at once to alleviate the low-data problem.,,,,
SyW2QSige,2017,Reject,False,Towards Information-Seeking Agents,"[""Philip Bachman"", ""Alessandro Sordoni"", ""Adam Trischler""]",[],We investigate the behavior of models trained to answer questions by asking sequences of simple questions.,,,,
SyW4Gjg0W,2018,Reject,False,Kernel Graph Convolutional Neural Nets,"[""Giannis Nikolentzos"", ""Polykarpos Meladianos"", ""Antoine J-P Tixier"", ""Konstantinos Skianis"", ""Michalis Vazirgiannis""]",[],,,,,
SyWvgP5el,2017,Accept (Poster),False,EPOpt: Learning Robust Neural Network Policies Using Model Ensembles,"[""Aravind Rajeswaran"", ""Sarvjeet Ghotra"", ""Balaraman Ravindran"", ""Sergey Levine""]","[""Reinforcement Learning"", ""Applications""]",An ensemble optimization approach to help transfer neural network policies from simulated domains to real-world target domains.,,,,
SyX0IeWAW,2018,Accept (Poster),False,META LEARNING SHARED HIERARCHIES,"[""Kevin Frans"", ""Jonathan Ho"", ""Xi Chen"", ""Pieter Abbeel"", ""John Schulman""]","[""hierarchal reinforcement learning"", ""meta-learning""]",learn hierarchal sub-policies through end-to-end training over a distribution of tasks,,,,
SyYYPdg0-,2018,Reject,False,Counterfactual Image Networks,"[""Deniz Oktay"", ""Carl Vondrick"", ""Antonio Torralba""]","[""computer vision"", ""image segmentation"", ""generative models"", ""adversarial networks"", ""unsupervised learning""]",Weakly-supervised image segmentation using compositional structure of images and generative models.,,,,
SyYe6k-CW,2018,Accept (Poster),False,Deep Bayesian Bandits Showdown:  An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling,"[""Carlos Riquelme"", ""George Tucker"", ""Jasper Snoek""]","[""exploration"", ""Thompson Sampling"", ""Bayesian neural networks"", ""bandits"", ""reinforcement learning"", ""variational inference"", ""Monte Carlo""]",An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling,,,,
SyZI0GWCZ,2018,Accept (Poster),False,Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models,"[""Wieland Brendel *"", ""Jonas Rauber *"", ""Matthias Bethge""]","[""adversarial attacks"", ""adversarial examples"", ""adversarials"", ""robustness"", ""security""]",A novel adversarial attack that can directly attack real-world black-box machine learning models without transfer.,,,,
SyZipzbCb,2018,Accept (Poster),False,Distributed Distributional Deterministic Policy Gradients,"[""Gabriel Barth-Maron"", ""Matthew W. Hoffman"", ""David Budden"", ""Will Dabney"", ""Dan Horgan"", ""Dhruva TB"", ""Alistair Muldal"", ""Nicolas Heess"", ""Timothy Lillicrap""]","[""policy gradient"", ""continuous control"", ""actor critic"", ""reinforcement learning""]","We develop an agent that we call the Distributional Deterministic Deep Policy Gradient algorithm, which achieves state of the art performance on a number of challenging continuous control problems.",,,,
SyZprb5xg,2017,Invite to Workshop Track,False,On Robust Concepts and Small Neural Nets,"[""Amit Deshpande"", ""Sushrut Karmalkar""]","[""Theory""]",an efficient analog of the universal approximation theorem for neural networks over the boolean hypercube,,,,
Sy_MK3lAZ,2018,Reject,False,PARAMETRIZED DEEP Q-NETWORKS LEARNING: PLAYING ONLINE BATTLE ARENA WITH DISCRETE-CONTINUOUS HYBRID ACTION SPACE,"[""Jiechao Xiong"", ""Qing Wang"", ""Zhuoran Yang"", ""Peng Sun"", ""Yang Zheng"", ""Lei Han"", ""Haobo Fu"", ""Xiangru Lian"", ""Carson Eisenach"", ""Haichuan Yang"", ""Emmanuel Ekwedike"", ""Bei Peng"", ""Haoyue Gao"", ""Tong Zhang"", ""Ji Liu"", ""Han Liu""]","[""Deep reinforcement learning"", ""Hybrid action space"", ""DQN"", ""DDPG""]",A DQN and DDPG hybrid algorithm is proposed to deal with the discrete-continuous hybrid action space.,,,,
SybqeKgA-,2018,Reject,False,On Batch Adaptive Training for Deep Learning: Lower Loss and Larger Step Size,"[""Runyao Chen"", ""Kun Wu"", ""Ping Luo""]","[""deep learning"", ""optimization""]","We developed a batch adaptive momentum that can achieve lower loss compared with mini-batch methods after scanning same epochs of data, and it is more robust against large step size.",,,,
Sye0XkBKvS,2020,Accept (Poster),True,SNODE: Spectral Discretization of Neural ODEs for System Identification,"[""Alessio Quaglino"", ""Marco Gallieri"", ""Jonathan Masci"", ""Jan Koutn\u00edk""]","[""Recurrent neural networks"", ""system identification"", ""neural ODEs""]",This paper proposes the use of spectral element methods for fast and accurate training of Neural Ordinary Differential Equations for system identification.,1906.07038,cs.NE,2019-06-17 13:54:30+00:00,2020-01-17 14:43:34+00:00
Sye2doC9tX,2019,Reject,False,Exploration by Uncertainty in Reward Space,"[""Wei-Yang Qu"", ""Yang Yu"", ""Tang-Jie Lv"", ""Ying-Feng Chen"", ""Chang-Jie Fan""]","[""Policy Exploration"", ""Uncertainty in Reward Space""]",Exploration by Uncertainty in Reward Space,,,,
Sye2s2VtDr,2020,Reject,False,Automatically Learning Feature Crossing from Model Interpretation for Tabular Data,"[""Zhaocheng Liu"", ""Qiang Liu"", ""Haoli Zhang""]","[""AutoML"", ""feature crossing"", ""interpretation""]","We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.",,,,
Sye57xStvB,2020,Accept (Poster),False,Never Give Up: Learning Directed Exploration Strategies,"[""Adri\u00e0 Puigdom\u00e8nech Badia"", ""Pablo Sprechmann"", ""Alex Vitvitskyi"", ""Daniel Guo"", ""Bilal Piot"", ""Steven Kapturowski"", ""Olivier Tieleman"", ""Martin Arjovsky"", ""Alexander Pritzel"", ""Andrew Bolt"", ""Charles Blundell""]","[""deep reinforcement learning"", ""exploration"", ""intrinsic motivation""]",We propose a reinforcement learning agent to solve hard exploration games by learning a range of directed exploratory policies. ,,,,
Sye7qoC5FQ,2019,Reject,False,Adversarial Attacks on Node Embeddings,"[""Aleksandar Bojchevski"", ""Stephan G\u00fcnnemann""]","[""node embeddings"", ""adversarial attacks""]",Adversarial attacks on unsupervised node embeddings based on eigenvalue perturbation theory.,,,,
SyeBqsRctm,2019,Reject,False,Step-wise Sensitivity Analysis: Identifying Partially Distributed Representations for Interpretable Deep Learning,"[""Botty Dimanov"", ""Mateja Jamnik""]","[""Interpretability"", ""Interpretable Deep Learning"", ""XAI"", ""dependency graph"", ""sensitivity analysis"", ""outlier detection"", ""instance-specific"", ""model-centric""]",We find dependency graphs between learned representations as a first step towards building decision trees to interpret the representation manifold.,,,,
SyeD0RVtvS,2020,Reject,False,DeepSFM: Structure From Motion Via Deep Bundle Adjustment,"[""Xingkui Wei"", ""Yinda Zhang"", ""Zhuwen Li"", ""Yanwei Fu"", ""Xiangyang Xue""]","[""Computer Vision"", ""Bundle Ajustment"", ""Structure from Motion""]",We design a physical driven deep architecture for depth and pose estimation inspired by Bundle Ajustment.,,,,
SyeHPgHFDr,2020,Reject,False,Finding Deep Local Optima Using Network Pruning,"[""Yangzi Guo"", ""Yiyuan She"", ""Ying Nian Wu"", ""Adrian Barbu""]","[""network pruning"", ""non-convex optimization""]",,,,,
SyeKGgStDB,2020,Reject,False,Training a Constrained Natural Media Painting Agent using Reinforcement Learning ,"[""Biao Jia"", ""Jonathan Brandt"", ""Radomir Mech"", ""Ning Xu"", ""Byungmoon Kim"", ""Dinesh Manocha""]",[],"We train a natural media painting agent using environment model. Based on our painting agent, we present a novel approach to train a constrained painting agent that follows the command encoded in the observation.",,,,
SyeKf30cFQ,2019,Reject,True,A theoretical framework for deep and locally connected ReLU network,"[""Yuandong Tian""]","[""theoretical analysis"", ""deep network"", ""optimization"", ""disentangled representation""]",This paper presents a theoretical framework that models data distribution explicitly for deep and locally connected ReLU network,1809.10829,cs.LG,2018-09-28 02:37:35+00:00,2018-09-28 02:37:35+00:00
SyeLGlHtPS,2020,Reject,True,"Learning vector representation of local content and matrix representation of local motion, with implications for V1","[""Ruiqi Gao"", ""Jianwen Xie"", ""Siyuan Huang"", ""Yufan Ren"", ""Song-Chun Zhu"", ""Ying Nian Wu""]","[""Representation learning"", ""V1"", ""neuroscience""]",,1902.03871,cs.NE,2019-01-24 08:09:19+00:00,2019-12-01 09:18:13+00:00
SyeLno09Fm,2019,Reject,False,Few-Shot Intent Inference via Meta-Inverse Reinforcement Learning,"[""Kelvin Xu"", ""Ellis Ratner"", ""Anca Dragan"", ""Sergey Levine"", ""Chelsea Finn""]","[""Inverse Reinforcement Learning"", ""Meta-Learning"", ""Deep Learning""]",The applicability of inverse reinforcement learning is often hampered by the expense of collecting expert demonstrations; this paper seeks to broaden its applicability by incorporating prior task information through meta-learning.,,,,
SyeMblBtwr,2020,Reject,True,CrossNorm: On Normalization for Off-Policy Reinforcement Learning,"[""Aditya Bhatt"", ""Max Argus"", ""Artemij Amiranashvili"", ""Thomas Brox""]","[""RL"", ""Normalization""]",Use of normalization for deep RL allows for training without target networks and better performance.,1902.05605,cs.LG,2019-02-14 21:05:50+00:00,2019-10-17 15:53:02+00:00
SyeQFiCcF7,2019,Reject,False,Siamese Capsule Networks,"[""James O' Neill""]","[""capsule networks"", ""pairwise learning"", ""few-shot learning"", ""face verification""]",A variant of capsule networks that can be used for pairwise learning tasks. Results shows that Siamese Capsule Networks work well in the few shot learning setting.,,,,
SyeRIgBYDB,2020,Reject,False,Semi-Implicit Back Propagation,"[""Ren Liu"", ""Xiaoqun Zhang""]","[""Optimization"", ""Neural Network"", ""Proximal mapping"", ""Back propagation"", ""Implicit""]","A new scheme in the spirit of error back propagation, with an implicit updates on the parameters sets and semi-implicit updates on the hidden neurons.",2002.03516,math.OC,2020-02-10 03:26:09+00:00,2020-02-10 03:26:09+00:00
SyeUMRNYDr,2020,Reject,False,Generating Dialogue Responses From A Semantic Latent Space,"[""Wei-Jen Ko"", ""Avik Ray"", ""Yilin Shen"", ""Hongxia Jin""]","[""dialog"", ""chatbot"", ""open domain conversation"", ""CCA""]","A novel dialog generation model that learns on a utterance level semantic latent space. The model could learn from semantically similar sentences collectively, thus eliminates the generic response problem.",2010.01658,cs.CL,2020-10-04 19:06:16+00:00,2020-10-04 19:06:16+00:00
SyeYiyHFDH,2020,Reject,False,Convergence Analysis of a Momentum Algorithm with Adaptive Step Size for Nonconvex Optimization,"[""Anas Barakat"", ""Pascal Bianchi""]","[""nonconvex optimization"", ""adaptive methods""]",,1911.07596,math.OC,2019-11-18 13:00:02+00:00,2020-09-24 12:52:11+00:00
SyeZIkrKwS,2020,Reject,False,DyNet: Dynamic Convolution for Accelerating Convolution Neural Networks,"[""Kane Zhang"", ""Jian Zhang"", ""Qiang Wang"", ""Zhao Zhong""]","[""CNNs"", ""dynamic convolution kernel""]",We propose a dynamic convolution method to significantly accelerate inference time of CNNs while maintaining the accuracy.,,,,
Sye_OgHFwH,2020,Accept (Poster),True,Unrestricted Adversarial Examples via Semantic Manipulation,"[""Anand Bhattad"", ""Min Jin Chong"", ""Kaizhao Liang"", ""Bo Li"", ""D. A. Forsyth""]","[""Adversarial Examples"", ""Semantic Manipulation"", ""Image Colorization"", ""Texture Transfer""]",We introduce unrestricted perturbations that manipulate semantically meaningful image-based visual descriptors - color and texture - in order to generate effective and  photorealistic adversarial examples.,1904.06347,cs.CV,2019-04-12 17:59:30+00:00,2020-03-20 17:59:15+00:00
Syeben09FQ,2019,Reject,False,Evaluating GANs via Duality,"[""Paulina Grnarova"", ""Kfir Y Levy"", ""Aurelien Lucchi"", ""Nathanael Perraudin"", ""Thomas Hofmann"", ""Andreas Krause""]","[""Generative Adversarial Networks"", ""GANs"", ""game theory""]",,,,,
SyecdJSKvr,2020,Reject,True,Learning from Label Proportions with Consistency Regularization,"[""Kuen-Han Tsai"", ""Hsuan-Tien Lin""]","[""learning from label proportions"", ""consistency regularization"", ""semi-supervised learning""]",,1910.13188,cs.LG,2019-10-29 10:46:15+00:00,2019-10-29 10:46:15+00:00
SyedHyBFwS,2020,Reject,False,Relative Pixel Prediction For Autoregressive Image Generation,"[""Wang Ling"", ""Chris Dyer"", ""Lei Yu"", ""Lingpeng Kong"", ""Dani Yogatama"", ""Susannah Young""]","[""Image Generation"", ""Autoregressive""]",,,,,
Syee1pVtDS,2020,Reject,False,Distributed Online Optimization with Long-Term Constraints,"[""Deming Yuan"", ""Alexandre Proutiere"", ""Guodong Shi""]",[],,,,,
SyegvgHtwr,2020,Reject,False,Localised Generative Flows,"[""Rob Cornish"", ""Anthony Caterini"", ""George Deligiannidis"", ""Arnaud Doucet""]","[""Deep generative models"", ""normalizing flows"", ""variational inference""]",We use a deep continuous mixture of bijections to improve normalising flows for density estimation.,,,,
SyehMhC9Y7,2019,Reject,True,"Deep Imitative Models for Flexible Inference, Planning, and Control","[""Nicholas Rhinehart"", ""Rowan McAllister"", ""Sergey Levine""]","[""imitation learning"", ""forecasting"", ""computer vision""]","Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control",1810.06544,cs.LG,2018-10-15 17:51:03+00:00,2019-10-01 00:13:58+00:00
Syeil309tX,2019,Reject,False,Optimized Gated Deep Learning Architectures for Sensor Fusion,"[""Myung Seok Shim"", ""Peng Li""]","[""deep learning"", ""convolutional neural network"", ""sensor fusion"", ""activity recognition""]",Optimized gated deep learning architectures for sensor fusion is proposed.,,,,
Syejj0NYvr,2020,Reject,False,Adversarial Interpolation Training: A Simple Approach for Improving Model Robustness,"[""Haichao Zhang"", ""Wei Xu""]","[""adversarial training"", ""adversarial robustness""]","adversarial interpolation training: a simple, intuitive and effective approach for improving model robustness",,,,
SyepHTNFDS,2020,Reject,True,Graph Residual Flow for Molecular Graph Generation,"[""Shion Honda"", ""Hirotaka Akita"", ""Katsuhiko Ishiguro"", ""Toshiki Nakanishi"", ""Kenta Oono""]","[""deep generative model"", ""normalizing flow"", ""graph generation"", ""cheminformatics""]","We propose a residual flow model for molecular graphs, derive the conditions so that the flow is invertible, and show its efficacy in experiments.",1909.13521,cs.LG,2019-09-30 08:43:10+00:00,2019-09-30 08:43:10+00:00
SyerAiCqt7,2019,Reject,False,Hierarchical Bayesian Modeling for Clustering Sparse Sequences in the Context of Group Profiling,"[""Ishani Chakraborty""]","[""Hierarchical Bayesian Modeling"", ""Sparse sequence clustering"", ""Group profiling"", ""User group modeling""]",Hierarchical Bayesian Modeling for Clustering Sparse Sequences ; user group modeling using behavioral data,,,,
Syetja4KPH,2020,Reject,False,Deep Randomized Least Squares Value Iteration,"[""Guy Adam"", ""Tom Zahavy"", ""Oron Anschel"", ""Nahum Shimkin""]","[""Thompson Sampling"", ""Deep Learning"", ""Reinforcement Learning""]",A Deep Learning adaptation of Randomized Least Squares Value Iteration,,,,
Syeu8CNYvS,2020,Reject,False,MODELLING   BIOLOGICAL   ASSAYS   WITH ADAPTIVE DEEP KERNEL LEARNING,"[""Prudencio Tossou"", ""Basile Dura"", ""Daniel Cohen"", ""Mario Marchand"", ""Fran\u00e7ois Laviolette"", ""Alexandre Lacoste""]","[""few-shot learning"", ""few-shot regression"", ""deep kernel learning"", ""biological assay modelling"", ""drug discovery""]",We investigate the modelling of biological assays using deep kernel learning in few-shot settings.,,,,
SyevDaVYwr,2020,Reject,False,Confidence Scores Make Instance-dependent Label-noise Learning Possible,"[""Antonin Berthon"", ""Bo Han"", ""Gang Niu"", ""Tongliang Liu"", ""Masashi Sugiyama""]","[""Instance-dependent label noise"", ""Deep learning""]",Using confidence scores makes the instance-dependent noise model tractable.,2001.03772,cs.LG,2020-01-11 16:15:41+00:00,2021-02-22 23:40:07+00:00
SyevYxHtDB,2020,Accept (Poster),True,Prediction Poisoning: Towards Defenses Against DNN Model Stealing Attacks,"[""Tribhuvanesh Orekondy"", ""Bernt Schiele"", ""Mario Fritz""]","[""model functionality stealing"", ""adversarial machine learning""]",We propose the first approach that can resist DNN model stealing/extraction attacks,1906.10908,cs.LG,2019-06-26 08:32:37+00:00,2020-03-03 10:51:12+00:00
SyeyF0VtDr,2020,Reject,False,Recurrent Event Network : Global Structure Inference Over Temporal Knowledge Graph,"[""Woojeong Jin"", ""He Jiang"", ""Meng Qu"", ""Tong Chen"", ""Changlin Zhang"", ""Pedro\u00a0Szekely"", ""Xiang Ren""]","[""Temporal Knowledge Graphs"", ""Representation Learning"", ""Graph Sequence Inference"", ""Knowledge Graph Completion""]",We propose an autoregressive model to infer graph structures on temporal knowledge graphs.,,,,
Syez3j0cKX,2019,Reject,False,Dissecting an Adversarial framework for Information Retrieval,"[""Ameet Deshpande"", ""Mitesh M.Khapra""]","[""GAN"", ""Deep Learning"", ""Reinforcement Learning""]","Points out problems in loss function used in IRGAN, a recently proposed GAN framework for Information Retrieval. Further, a model motivated by co-training is proposed, which achieves better performance.",,,,
SyezSCNYPB,2020,Reject,False,Disentangled GANs for Controllable Generation of High-Resolution Images,"[""Weili Nie"", ""Tero Karras"", ""Animesh Garg"", ""Shoubhik Debhath"", ""Anjul Patney"", ""Ankit B. Patel"", ""Anima Anandkumar""]","[""Disentangled GANs"", ""controllable generation"", ""high-resolution image synthesis"", ""semantic manipulation"", ""fine-grained factors""]",We propose new GAN architectures that enable disentangled and controllable high-resolution image generation as well as new datasets that will serve as benchmarks for the research community.,,,,
SyezvsC5tX,2019,Reject,False,The loss landscape of overparameterized neural networks,"[""Y. Cooper""]",[],,,,,
Syf9Q209YQ,2019,Reject,False,Manifold regularization with GANs for semi-supervised learning,"[""Bruno Lecouat"", ""Chuan-Sheng Foo"", ""Houssam Zenati"", ""Vijay Chandrasekhar""]","[""semi-supervised learning"", ""generative adversarial networks"", ""manifold regularization""]",,,,,
SyfIfnC5Ym,2019,Accept (Poster),False,Improving the Generalization of Adversarial Training with Domain Adaptation,"[""Chuanbiao Song"", ""Kun He"", ""Liwei Wang"", ""John E. Hopcroft""]","[""adversarial training"", ""domain adaptation"", ""adversarial example"", ""deep learning""]",We propose a novel adversarial training with domain adaptation method that significantly improves the generalization ability on adversarial examples from different attacks.,,,,
SyfXKoRqFQ,2019,Reject,False,Ada-Boundary: Accelerating the DNN Training via Adaptive Boundary Batch Selection,"[""Hwanjun Song"", ""Sundong Kim"", ""Minseok Kim"", ""Jae-Gil Lee""]","[""acceleration"", ""batch selection"", ""convergence"", ""decision boundary""]",We suggest a smart batch selection technique called Ada-Boundary.,,,,
SyfiiMZA-,2018,Invite to Workshop Track,False,Jointly Learning to Construct and Control Agents using Deep Reinforcement Learning,"[""Charles Schaff"", ""David Yunis"", ""Ayan Chakrabarti"", ""Matthew R. Walter""]","[""robot locomotion"", ""reinforcement learning"", ""policy gradients"", ""physical design"", ""deep learning""]",Use deep reinforcement learning to design the physical attributes of a robot jointly with a control policy.,,,,
Syfkm6cgx,2017,Reject,False,Improving Invariance and Equivariance Properties of Convolutional Neural Networks,"[""Christopher Tensmeyer"", ""Tony Martinez""]","[""Deep learning""]",Data augmentation shapes internal network representation and makes predictions robust to input transformations.,,,,
Syfz6sC9tQ,2019,Reject,False,Generative Feature Matching Networks,"[""Cicero Nogueira dos Santos"", ""Inkit Padhi"", ""Pierre Dognin"", ""Youssef Mroueh""]","[""Generative Deep Neural Networks"", ""Feature Matching"", ""Maximum Mean Discrepancy"", ""Generative Adversarial Networks""]",A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.,,,,
Syg-ET4FPS,2020,Accept (Talk),False,Posterior sampling for multi-agent reinforcement learning: solving extensive games with imperfect information,"[""Yichi Zhou"", ""Jialian Li"", ""Jun Zhu""]",[],,,,,
Syg-YfWCW,2018,Accept (Poster),False,Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning,"[""Rajarshi Das"", ""Shehzaad Dhuliawala"", ""Manzil Zaheer"", ""Luke Vilnis"", ""Ishan Durugkar"", ""Akshay Krishnamurthy"", ""Alex Smola"", ""Andrew McCallum""]","[""Knowledge Graphs"", ""Reinforcement Learning"", ""Query Answering""]",We present a RL agent MINERVA which learns to walk on a knowledge graph and answer queries,,,,
Syg6fxrKDB,2020,Reject,False,A Graph Neural Network Assisted Monte Carlo Tree Search Approach to Traveling Salesman Problem,"[""Zhihao Xing"", ""Shikui Tu""]","[""Traveling Salesman Problem"", ""Graph Neural Network"", ""Monte Carlo Tree Search""]",A Graph Neural Network Assisted Monte Carlo Tree Search Approach to Traveling Salesman Problem,,,,
Syg6jTNtDH,2020,Reject,False,Learning Numeral Embedding,"[""Chengyue Jiang"", ""Zhonglin Nian"", ""Kaihao Guo"", ""Shanbo Chu"", ""Yinggong Zhao"", ""Libin Shen"", ""Kewei Tu""]","[""Natural Language Processing"", ""Numeral Embedding"", ""Word Embedding"", ""Out-of-vocabulary Problem""]",We propose two methods for learning better numeral embeddings that solve the numeral out-of-vocabulary (OOV) problem and can be integrated into traditional word embedding training methods. ,2001.00003,cs.CL,2019-12-28 03:15:43+00:00,2020-01-11 14:00:55+00:00
Syg7VaNYPB,2020,Reject,True,Generative Latent Flow,"[""Zhisheng Xiao"", ""Qing Yan"", ""Yali Amit""]","[""Generative Model"", ""Auto-encoder"", ""Normalizing Flow""]","We propose a generative model that combines deterministic Auto-encoders and normalizing flows, and we show that our model's sample quality greatly outperforms that of other AE based generative models.",1905.10485,cs.CV,2019-05-24 23:44:50+00:00,2019-09-22 22:57:15+00:00
SygBIxSFDS,2020,Reject,False,An Empirical and Comparative Analysis of Data Valuation with Scalable Algorithms,"[""Ruoxi Jia"", ""Xuehui Sun"", ""Jiacen Xu"", ""Ce Zhang"", ""Bo Li"", ""Dawn Song""]","[""Data valuation"", ""machine learning""]","We present a scalable algorithm for data valuation, study its utility both empirically and theoretically",,,,
SygD-hCcF7,2019,Accept (Poster),False,Dimensionality Reduction for Representing the Knowledge of Probabilistic Models,"[""Marc T Law"", ""Jake Snell"", ""Amir-massoud Farahmand"", ""Raquel Urtasun"", ""Richard S Zemel""]","[""metric learning"", ""distance learning"", ""dimensionality reduction"", ""bound guarantees""]",dimensionality reduction for cases where examples can be represented as soft probability distributions,,,,
SygD31HFvB,2020,Reject,False,A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization,"[""Guangzeng Xie"", ""Luo Luo"", ""Zhihua Zhang""]","[""convex optimization"", ""lower bound complexity"", ""proximal incremental first-order oracle""]",,,,,
SygEukHYvB,2020,Reject,False,CEB Improves Model Robustness,"[""Ian Fischer"", ""Alex A. Alemi""]","[""Information Theory"", ""Adversarial Robustness""]",Training your model with the Conditional Entropy Bottleneck is easy and makes your model more robust.,,,,
SygGlIBcel,2017,Reject,False,Opening the vocabulary of  neural language models with character-level word representations,"[""Matthieu Labeau"", ""Alexandre Allauzen""]","[""Natural language processing"", ""Deep learning""]",,,,,
SygHGnRqK7,2019,Reject,False,Probabilistic Federated Neural Matching,"[""Mikhail Yurochkin"", ""Mayank Agarwal"", ""Soumya Ghosh"", ""Kristjan Greenewald"", ""Nghia Hoang"", ""Yasaman Khazaeni""]","[""Bayesian nonparametrics"", ""Indian Buffet Process"", ""Federated Learning""]",We propose a Bayesian nonparametric model for federated learning with neural networks.,,,,
SygInj05Fm,2019,Reject,False,Physiological Signal Embeddings (PHASE) via Interpretable Stacked Models,"[""Hugh Chen"", ""Scott Lundberg"", ""Gabe Erion"", ""Su-In Lee""]","[""Representation learning"", ""transfer learning"", ""health"", ""machine learning"", ""physiological signals"", ""interpretation"", ""feature attributions"", ""shapley values"", ""univariate embeddings"", ""LSTMs"", ""XGB"", ""neural networks"", ""stacked models"", ""model pipelines"", ""interpretable stacked models""]",Physiological signal embeddings for prediction performance and hospital transference with a general Shapley value interpretability method for stacked models.,,,,
SygJSiA5YQ,2019,Reject,False,Weak contraction mapping and optimization,"[""Siwei Luo""]","[""Weak contraction mapping"", ""fixed-point theorem"", ""non-convex optimization""]",A gradient-free method is proposed for non-convex optimization problem ,,,,
SygK6sA5tX,2019,Reject,False,Graph Classification with Geometric Scattering,"[""Feng Gao"", ""Guy Wolf"", ""Matthew Hirn""]","[""geometric deep learning"", ""graph neural network"", ""graph classification"", ""scattering""]","We present a new feed forward graph ConvNet based on generalizing the wavelet scattering transform of Mallat, and demonstrate its utility in graph classification and data exploration tasks.",,,,
SygKyeHKDH,2020,Accept (Poster),False,Making Efficient Use of Demonstrations to Solve Hard Exploration Problems,"[""Caglar Gulcehre"", ""Tom Le Paine"", ""Bobak Shahriari"", ""Misha Denil"", ""Matt Hoffman"", ""Hubert Soyer"", ""Richard Tanburn"", ""Steven Kapturowski"", ""Neil Rabinowitz"", ""Duncan Williams"", ""Gabriel Barth-Maron"", ""Ziyu Wang"", ""Nando de Freitas"", ""Worlds Team""]","[""imitation learning"", ""deep learning"", ""reinforcement learning""]","We introduce R2D3, an agent that makes efficient use of demonstrations to solve hard exploration problems in partially observable environments with highly variable initial conditions.",,,,
SygLehCqtm,2019,Accept (Poster),False,Learning protein sequence embeddings using information from structure,"[""Tristan Bepler"", ""Bonnie Berger""]","[""sequence embedding"", ""sequence alignment"", ""RNN"", ""LSTM"", ""protein structure"", ""amino acid sequence"", ""contextual embeddings"", ""transmembrane prediction""]",We present a method for learning protein sequence embedding models using structural information in the form of global structural similarity between proteins and within protein residue-residue contacts.,,,,
SygLu0VtPH,2020,Reject,False,Deep Innovation Protection,"[""Sebastian Risi"", ""Kenneth O. Stanley""]","[""Neuroevolution"", ""innovation protection"", ""world models"", ""genetic algorithm""]",Deep Innovation Protection allows evolving complex world models end-to-end for 3D tasks.,,,,
SygONjRqKm,2019,Reject,False,Amortized Context Vector Inference for Sequence-to-Sequence Networks,"[""Sotirios Chatzis"", ""Kyriacos Tolias"", ""Aristotelis Charalampous""]","[""neural attention"", ""sequence-to-sequence"", ""variational inference""]",A generalisation of context representation in neural attention under the variational inference rationale.,,,,
SygQvs0cFQ,2019,Accept (Poster),False,Variational Smoothing in Recurrent Neural Network Language Models,"[""Lingpeng Kong"", ""Gabor Melis"", ""Wang Ling"", ""Lei Yu"", ""Dani Yogatama""]",[],,,,,
SygRikHtvS,2020,Reject,False,Coresets for Accelerating Incremental Gradient Methods,"[""Baharan Mirzasoleiman"", ""Jeff Bilmes"", ""Jure Leskovec""]",[],,,,,
SygSLlStwS,2020,Reject,False,Consistent Meta-Reinforcement Learning via Model Identification and Experience Relabeling,"[""Russell Mendonca"", ""Xinyang Geng"", ""Chelsea Finn"", ""Sergey Levine""]","[""Meta-Reinforcement Learning"", ""Reinforcement Learning"", ""Off-Policy"", ""Model Based""]",Sample efficient meta-reinforcement learning that extrapolates to out of distribution tasks.,2006.07178,cs.LG,2020-06-12 13:34:46+00:00,2020-06-15 18:34:23+00:00
SygW0TEFwH,2020,Accept (Poster),True,Sign Bits Are All You Need for Black-Box Attacks,"[""Abdullah Al-Dujaili"", ""Una-May O'Reilly""]","[""Black-box adversarial attack models"", ""Deep Nets"", ""Adversarial Examples"", ""Black-Box Optimization"", ""Zeroth-Order Optimization""]","We present a sign-based, rather than magnitude-based, gradient estimation approach that shifts gradient estimation from continuous to binary black-box optimization.",1902.06894,cs.LG,2019-02-19 05:01:23+00:00,2019-04-03 15:22:51+00:00
SygWvAVFPr,2020,Accept (Poster),False,Neural Module Networks for Reasoning over Text,"[""Nitish Gupta"", ""Kevin Lin"", ""Dan Roth"", ""Sameer Singh"", ""Matt Gardner""]","[""question answering"", ""compositionality"", ""neural module networks"", ""multi-step reasoning"", ""reading comprehension""]",This paper extends neural module networks to answer compositional questions against text by introducing differentiable modules that perform reasoning over text and symbols in a probabilistic manner.,1912.04971,cs.CL,2019-12-10 20:36:07+00:00,2020-02-15 19:26:05+00:00
SygXPaEYvH,2020,Accept (Poster),True,VL-BERT: Pre-training of Generic Visual-Linguistic Representations,"[""Weijie Su"", ""Xizhou Zhu"", ""Yue Cao"", ""Bin Li"", ""Lewei Lu"", ""Furu Wei"", ""Jifeng Dai""]","[""Visual-Linguistic"", ""Generic Representation"", ""Pre-training""]","VL-BERT is a simple yet powerful pre-trainable generic representation for visual-linguistic tasks. It is pre-trained on the massive-scale caption dataset and text-only corpus, and can be finetuned for varies down-stream visual-linguistic tasks.",1908.08530,cs.CV,2019-08-22 17:59:30+00:00,2020-02-18 02:59:17+00:00
SygagpEKwB,2020,Accept (Poster),True,Disentangling Factors of Variations Using Few Labels,"[""Francesco Locatello"", ""Michael Tschannen"", ""Stefan Bauer"", ""Gunnar R\u00e4tsch"", ""Bernhard Sch\u00f6lkopf"", ""Olivier Bachem""]",[],,1905.01258,cs.LG,2019-05-03 16:23:49+00:00,2020-02-14 13:24:55+00:00
SygcCnNKwr,2020,Accept (Poster),False,Measuring Compositional Generalization: A Comprehensive Method on Realistic Data,"[""Daniel Keysers"", ""Nathanael Sch\u00e4rli"", ""Nathan Scales"", ""Hylke Buisman"", ""Daniel Furrer"", ""Sergii Kashubin"", ""Nikola Momchev"", ""Danila Sinopalnikov"", ""Lukasz Stafiniak"", ""Tibor Tihon"", ""Dmitry Tsarkov"", ""Xiao Wang"", ""Marc van Zee"", ""Olivier Bousquet""]","[""compositionality"", ""generalization"", ""natural language understanding"", ""benchmark"", ""compositional generalization"", ""compositional modeling"", ""semantic parsing"", ""generalization measurement""]",Benchmark and method to measure compositional generalization by maximizing divergence of compound frequency at small divergence of atom frequency.,1912.09713,cs.LG,2019-12-20 09:32:41+00:00,2020-06-25 06:38:53+00:00
SygcSlHFvS,2020,Reject,False,On Understanding Knowledge Graph Representation,"[""Carl Allen*"", ""Ivana Balazevic*"", ""Timothy M Hospedales""]","[""knowledge graphs"", ""word embedding"", ""representation learning""]",Understanding the structure of knowledge graph representation using insight from word embeddings.,,,,
SygeY1SYvr,2020,Reject,False,Are Few-shot Learning Benchmarks Too Simple ?,"[""Gabriel Huang"", ""Hugo Larochelle"", ""Simon Lacoste-Julien""]","[""few-shot"", ""classification"", ""meta-learning"", ""benchmark"", ""omniglot"", ""miniimagenet"", ""meta-dataset"", ""learning to cluster"", ""learning"", ""cluster"", ""unsupervised""]","Omniglot and miniImageNet are too simple for few-shot learning because we can solve them without using labels during meta-evaluation, as demonstrated with a method called centroid networks",,,,
SygfNCEYDH,2020,Reject,True,Weakly-supervised Knowledge Graph Alignment with Adversarial Learning,"[""Meng Qu"", ""Jian Tang"", ""Yoshua Bengio""]",[],,1907.03179,cs.LG,2019-07-06 20:31:13+00:00,2019-07-06 20:31:13+00:00
Sygg3JHtwB,2020,Reject,False,Step Size Optimization,"[""Gyoung S. Na"", ""Dongmin Hyeon"", ""Hwanjo Yu""]","[""Deep Learning"", ""Step Size Adaptation"", ""Nonconvex Optimization""]",We propose an efficient and effective step size adaptation method for the gradient methods.,,,,
SygkSkSFDB,2020,Reject,False,On the expected running time of nonconvex optimization with early stopping,"[""Thomas Flynn"", ""Kwang Min Yu"", ""Abid Malik"", ""Shinjae Yoo"", ""Nicholas D'Imperio""]","[""non-convex"", ""stopping times"", ""statistics"", ""gradient descent"", ""early stopping""]",How to bound the expected number of iterations before gradient descent finds a stationary point,,,,
SyglyANFDr,2020,Reject,False,SGD with Hardness Weighted Sampling for Distributionally Robust Deep Learning,"[""Lucas Fidon"", ""Sebastien Ourselin"", ""Tom Vercauteren""]","[""distributionally robust optimization"", ""distributionally robust deep learning"", ""over-parameterized deep neural networks"", ""deep neural networks"", ""AI safety"", ""hard example mining""]",An SGD-based method for training deep neural networks with distributionally robust optimization,,,,
Sygn20VtwH,2020,Reject,False,Metagross: Meta Gated Recursive Controller Units for Sequence Modeling,"[""Yi Tay"", ""Yikang Shen"", ""Alvin Chan"", ""Yew Soon Ong""]","[""Deep Learning"", ""Natural Language Processing"", ""Recurrent Neural Networks""]",Recursive Parameterization of Recurrent Models improve performance ,,,,
SygpC6Ntvr,2020,Accept (Poster),False,Minimizing FLOPs to Learn Efficient Sparse Representations,"[""Biswajit Paria"", ""Chih-Kuan Yeh"", ""Ian E.H. Yen"", ""Ning Xu"", ""Pradeep Ravikumar"", ""Barnab\u00e1s P\u00f3czos""]","[""sparse embeddings"", ""deep representations"", ""metric learning"", ""regularization""]","We propose an approach to learn sparse high dimensional representations that are fast to search, by incorporating a surrogate of the number of operations directly into the loss function.",,,,
SygvTcYee,2017,Reject,False,"ParMAC: distributed optimisation of nested functions, with application to binary autoencoders","[""Miguel A. Carreira-Perpinan"", ""Mehdi Alizadeh""]","[""Optimization"", ""Deep learning""]",,,,,
SygvZ209F7,2019,Accept (Poster),False,Biologically-Plausible Learning Algorithms Can Scale to Large Datasets,"[""Will Xiao"", ""Honglin Chen"", ""Qianli Liao"", ""Tomaso Poggio""]","[""biologically plausible learning algorithm"", ""ImageNet"", ""sign-symmetry"", ""feedback alignment""]","Biologically plausible learning algorithms, particularly sign-symmetry, work well on ImageNet",,,,
SygwwGbRW,2018,Accept (Poster),False,Semi-parametric topological memory for navigation,"[""Nikolay Savinov"", ""Alexey Dosovitskiy"", ""Vladlen Koltun""]","[""deep learning"", ""navigation"", ""memory""]","We introduce a new memory architecture for navigation in previously unseen environments, inspired by landmark-based navigation in animals.",,,,
Sygx4305KQ,2019,Reject,False,Small steps and giant leaps: Minimal Newton solvers for Deep Learning,"[""Joao Henriques"", ""Sebastien Ehrhardt"", ""Samuel Albanie"", ""Andrea Vedaldi""]","[""deep learning""]",A fast second-order solver for deep learning that works on ImageNet-scale problems with no hyper-parameter tuning,,,,
SygxYoC5FX,2019,Reject,False,BIGSAGE: unsupervised inductive representation learning of graph via bi-attended sampling and global-biased aggregating,"[""Xin Luo"", ""Hankz Hankui Zhuo""]","[""network embedding"", ""unsupervised learning"", ""inductive learning""]","For unsupervised and inductive network embedding, we propose a novel approach to explore most relevant neighbors and preserve previously learnt knowledge of nodes by utilizing bi-attention architecture and introducing global bias, respectively",,,,
SyhRVm-Rb,2018,Reject,False,Automatic Goal Generation for Reinforcement Learning Agents,"[""David Held"", ""Xinyang Geng"", ""Carlos Florensa"", ""Pieter Abbeel""]","[""Reinforcement Learning"", ""Multi-task Learning"", ""Curriculum Learning""]",We efficiently solve multi-task problems with an automatic curriculum generation algorithm based on a generative model that tracks the learning agent's performance.,,,,
SyhcXjy0Z,2018,Reject,False,APPLICATION OF DEEP CONVOLUTIONAL NEURAL NETWORK TO PREVENT ATM FRAUD BY FACIAL DISGUISE IDENTIFICATION,"[""Suraj Nandkishor Kothawade"", ""Sumit Baburao Tamgale""]","[""Deep Convolutional Neural Network"", ""Disguised Face Identification"", ""Fraudulent Transaction"", ""ATM"", ""Impersonation;""]",Proposed System can prevent impersonators with facial disguises from completing a fraudulent transaction using a pre-trained DCNN.,,,,
Syhr6pxCW,2018,Accept (Poster),False,PixelNN: Example-based Image Synthesis,"[""Aayush Bansal"", ""Yaser Sheikh"", ""Deva Ramanan""]","[""conditional image synthesis"", ""nearest neighbors""]","Pixel-wise nearest neighbors used for generating multiple images from incomplete priors such as a low-res images, surface normals, edges etc.",,,,
Syjha0gAZ,2018,Reject,False,Loss Functions for Multiset Prediction,"[""Sean Welleck"", ""Zixin Yao"", ""Yu Gai"", ""Jialin Mao"", ""Zheng Zhang"", ""Kyunghyun Cho""]","[""machine learning"", ""deep learning"", ""structured prediction"", ""sequential prediction""]","We study the problem of multiset prediction and propose a novel multiset loss function, providing analysis and empirical evidence that demonstrates its effectiveness.",,,,
SyjjD1WRb,2018,Reject,False,Evolutionary Expectation Maximization for Generative Models with Binary Latents,"[""Enrico Guiraud"", ""Jakob Drefs"", ""Joerg Luecke""]","[""unsupervised"", ""learning"", ""evolutionary"", ""sparse"", ""coding"", ""noisyOR"", ""BSC"", ""EM"", ""expectation-maximization"", ""variational EM"", ""optimization""]",We present Evolutionary EM as a novel algorithm for unsupervised training of generative models with binary latent variables that intimately connects variational EM with evolutionary optimization,,,,
SyjsLqxR-,2018,Reject,False,"Universality, Robustness, and Detectability of Adversarial Perturbations under Adversarial Training","[""Jan Hendrik Metzen""]","[""adversarial examples"", ""adversarial training"", ""universal perturbations"", ""safety"", ""deep learning""]","We empirically show that adversarial training is effective for removing universal perturbations, makes adversarial examples less robust to image transformations, and leaves them detectable for a detection approach.",,,,
Syl-_aVtvH,2020,Reject,False,Federated User Representation Learning,"[""Duc Bui"", ""Kshitiz Malik"", ""Jack Goetz"", ""Seungwhan Moon"", ""Honglei Liu"", ""Anuj Kumar"", ""Kang G. Shin""]","[""Machine Learning"", ""Federated Learning"", ""Personalization"", ""User Representation""]","We propose Federated User Representation Learning (FURL), a simple, scalable, privacy-preserving and bandwidth-efficient way to utilize existing neural personalization techniques in the Federated Learning (FL) setting.",,,,
Syl-xpNtwS,2020,Reject,False,Learning Representations in Reinforcement Learning: an Information Bottleneck Approach,"[""Yingjun Pei"", ""Xinwen Hou""]","[""representation learning"", ""reinforcement learning"", ""information bottleneck""]",Derive an information bottleneck framework in reinforcement learning and some simple relevant theories and tools.,,,,
Syl38yrFwr,2020,Reject,False,Near-Zero-Cost Differentially Private Deep Learning with Teacher Ensembles,"[""Lichao Sun"", ""Yingbo Zhou"", ""Jia Li"", ""Richard Socher"", ""Philip S. Yu"", ""Caiming Xiong""]",[],,,,,
Syl3_2JCZ,2018,Reject,False,A Self-Organizing Memory Network,"[""Callie Federer"", ""Joel Zylberberg""]","[""Working Memory"", ""Learning Rules"", ""Stimulus Representations""]",We derived biologically plausible synaptic plasticity learning rules for a recurrent neural network to store stimulus representations. ,,,,
Syl5o2EFPB,2020,Reject,False,Learning Compact Reward for Image Captioning,"[""Nannan Li"", ""Zhenzhong Chen""]","[""image captioning"", ""adversarial learning"", ""inverse reinforcement learning"", ""vision"", ""language""]",a refiened AIRL algorithm that learns compact reward for image captioning ,2003.10925,cs.CV,2020-03-24 15:31:05+00:00,2020-03-24 15:31:05+00:00
Syl6tjAqKX,2019,Reject,False,BEHAVIOR MODULE IN NEURAL NETWORKS,"[""Andrey Sakryukin"", ""Yongkang Wong"", ""Mohan S. Kankanhalli""]","[""Modular Networks"", ""Reinforcement Learning"", ""Task Separation"", ""Representation Learning"", ""Transfer Learning"", ""Adversarial Transfer""]",Extendable Modular Architecture is proposed for developing of variety of Agent Behaviors in DQN.,,,,
Syl7OsRqY7,2019,Accept (Poster),False,Coarse-grain Fine-grain Coattention Network for Multi-evidence Question Answering,"[""Victor Zhong"", ""Caiming Xiong"", ""Nitish Shirish Keskar"", ""Richard Socher""]","[""question answering"", ""reading comprehension"", ""nlp"", ""natural language processing"", ""attention"", ""representation learning""]",A new state-of-the-art model for multi-evidence question answering using coarse-grain fine-grain hierarchical attention.,,,,
Syl89aNYwS,2020,Reject,False,Robust saliency maps with distribution-preserving decoys,"[""Yang Young Lu"", ""Wenbo Guo"", ""Xinyu Xing"", ""William Stafford Noble""]","[""explainable machine learning"", ""explainable AI"", ""deep learning interpretability"", ""saliency maps"", ""perturbation"", ""convolutional neural network""]",We propose a robust saliency method which alleviate the limitations of mainstream competing methods with theoretical soundness,,,,
Syl8Sn0cK7,2019,Accept (Poster),False,Learning a Meta-Solver for Syntax-Guided Program Synthesis,"[""Xujie Si"", ""Yuan Yang"", ""Hanjun Dai"", ""Mayur Naik"", ""Le Song""]","[""Syntax-guided Synthesis"", ""Context Free Grammar"", ""Logical Specification"", ""Representation Learning"", ""Meta Learning"", ""Reinforcement Learning""]",We propose a meta-learning framework that learns a transferable policy from only weak supervision to solve synthesis tasks with different logical specifications and grammars.,,,,
SylCrnCcFX,2019,Accept (Poster),False,"Towards Robust, Locally Linear Deep Networks","[""Guang-He Lee"", ""David Alvarez-Melis"", ""Tommi S. Jaakkola""]","[""robust derivatives"", ""transparency"", ""interpretability""]",A scalable algorithm to establish robust derivatives of deep networks w.r.t. the inputs.,,,,
SylGpT4FPS,2020,Reject,True,Last-iterate convergence rates for min-max optimization,"[""Jacob Abernethy"", ""Kevin A. Lai"", ""Andre Wibisono""]","[""min-max optimization"", ""zero-sum game"", ""saddle point"", ""last-iterate convergence"", ""non-asymptotic convergence"", ""global rates"", ""Hamiltonian"", ""sufficiently bilinear""]",We prove that global linear last-iterate convergence rates are achievable for more general classes of convex-concave min-max optimization problems than had previously been shown.,1906.02027,math.OC,2019-06-05 13:41:36+00:00,2019-10-25 19:20:02+00:00
SylJ1D1C-,2018,Invite to Workshop Track,False,PDE-Net: Learning PDEs from Data,"[""Zichao Long"", ""Yiping Lu"", ""Xianzhong Ma"", ""Bin Dong""]","[""deep convolution network"", ""partial differential equation"", ""physical laws""]","This paper proposes a new feed-forward network, call PDE-Net, to learn PDEs from data. ",,,,
SylKikSYDH,2020,Accept (Poster),False,Compressive Transformers for Long-Range Sequence Modelling,"[""Jack W. Rae"", ""Anna Potapenko"", ""Siddhant M. Jayakumar"", ""Chloe Hillier"", ""Timothy P. Lillicrap""]","[""memory"", ""language modeling"", ""transformer"", ""compression""]","Long-range transformer using a compressive memory, achieves sota in wikitext-103 and enwik8 LM benchmarks, release a new book-level LM benchmark PG-19.",,,,
SylKoo0cKm,2019,Accept (Poster),False,How Important is a Neuron,"[""Kedar Dhamdhere"", ""Mukund Sundararajan"", ""Qiqi Yan""]","[""attribution"", ""saliency"", ""influence""]",,,,,
SylL0krYPS,2020,Accept (Poster),False,Toward Evaluating Robustness of Deep Reinforcement Learning with Continuous Control,"[""Tsui-Wei Weng"", ""Krishnamurthy (Dj) Dvijotham*"", ""Jonathan Uesato*"", ""Kai Xiao*"", ""Sven Gowal*"", ""Robert Stanforth*"", ""Pushmeet Kohli""]","[""deep learning"", ""reinforcement learning"", ""robustness"", ""adversarial examples""]",We study the problem of continuous control agents in deep RL with adversarial attacks and proposed a two-step algorithm based on learned model dynamics. ,,,,
SylLYsCcFm,2019,Accept (Poster),False,Learning to Make Analogies by Contrasting Abstract Relational Structure,"[""Felix Hill"", ""Adam Santoro"", ""David Barrett"", ""Ari Morcos"", ""Timothy Lillicrap""]","[""cognitive science"", ""analogy"", ""psychology"", ""cognitive theory"", ""cognition"", ""abstraction"", ""generalization""]",The most robust capacity for analogical reasoning is induced when networks learn analogies by contrasting abstract relational structures in their input domains.,,,,
SylO2yStDr,2020,Accept (Poster),True,Reducing Transformer Depth on Demand with Structured Dropout,"[""Angela Fan"", ""Edouard Grave"", ""Armand Joulin""]","[""reduction"", ""regularization"", ""pruning"", ""dropout"", ""transformer""]","Layerdrop, a form of structured dropout that allows you to train one model at training time and prune to any desired depth at test time. You can also use this to train even deeper models.",1909.11556,cs.LG,2019-09-25 15:35:03+00:00,2019-09-25 15:35:03+00:00
SylOlp4FvH,2020,Accept (Poster),True,V-MPO: On-Policy Maximum a Posteriori Policy Optimization for Discrete and Continuous Control,"[""H. Francis Song"", ""Abbas Abdolmaleki"", ""Jost Tobias Springenberg"", ""Aidan Clark"", ""Hubert Soyer"", ""Jack W. Rae"", ""Seb Noury"", ""Arun Ahuja"", ""Siqi Liu"", ""Dhruva Tirumala"", ""Nicolas Heess"", ""Dan Belov"", ""Martin Riedmiller"", ""Matthew M. Botvinick""]","[""reinforcement learning"", ""policy iteration"", ""multi-task learning"", ""continuous control""]",A state-value function-based version of MPO that achieves good results in a wide range of tasks in discrete and continuous control.,1909.12238,cs.AI,2019-09-26 16:34:22+00:00,2019-09-26 16:34:22+00:00
SylPMnR9Ym,2019,Accept (Poster),False,Learning what you can do before doing anything,"[""Oleh Rybkin"", ""Karl Pertsch"", ""Konstantinos G. Derpanis"", ""Kostas Daniilidis"", ""Andrew Jaegle""]","[""unsupervised learning"", ""vision"", ""motion"", ""action space"", ""video prediction"", ""variational models""]",We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel composability loss.,,,,
SylR-CEKDS,2020,Reject,True,Modeling question asking using neural program generation,"[""Ziyun Wang"", ""Brenden M. Lake""]","[""question asking"", ""language generation"", ""program induction"", ""reinforcement learning"", ""density estimation"", ""cognitive science""]","We introduce a model of human question asking that combines neural networks and symbolic programs, which can learn to generate good questions with or without supervised examples.",1907.09899,cs.CL,2019-07-23 14:20:21+00:00,2021-05-11 09:04:41+00:00
SylR6n4tPS,2020,Reject,True,Learning to Generate Grounded Visual Captions without Localization Supervision,"[""Chih-Yao Ma"", ""Yannis Kalantidis"", ""Ghassan AlRegib"", ""Peter Vajda"", ""Marcus Rohrbach"", ""Zsolt Kira""]","[""image captioning"", ""video captioning"", ""self-supervised learning"", ""visual grounding""]",We improve visual grounding accuracy for both image and video captioning tasks without using ground-truth grounding annotations.,1906.00283,cs.CV,2019-06-01 20:21:24+00:00,2020-07-17 23:56:28+00:00
SylU3jC5Y7,2019,Reject,True,ADAPTIVE NETWORK SPARSIFICATION VIA DEPENDENT VARIATIONAL BETA-BERNOULLI DROPOUT,"[""Juho Lee"", ""Saehoon Kim"", ""Jaehong Yoon"", ""Hae Beom Lee"", ""Eunho Yang"", ""Sung Ju Hwang""]","[""Bayesian deep learning"", ""network pruning""]",We propose a novel Bayesian network sparsification method that adaptively prunes networks according to inputs.,1805.10896,stat.ML,2018-05-28 12:50:02+00:00,2019-03-04 03:27:59+00:00
SylUiREKvB,2020,Reject,False,Variational Hyper RNN for Sequence Modeling,"[""Ruizhi Deng"", ""Yanshuai Cao"", ""Bo Chang"", ""Leonid Sigal"", ""Greg Mori"", ""Marcus Brubaker""]","[""variational autoencoder"", ""hypernetwork"", ""recurrent neural network"", ""time series""]",We propose a novel probabilistic sequence model that excels at capturing high variability in time series data using hypernetworks.,,,,
SylUzpNFDS,2020,Reject,False,SoftLoc: Robust Temporal Localization under Label Misalignment,"[""Julien Schroeter"", ""Kirill Sidorov"", ""Dave Marshall""]","[""deep learning"", ""temporal localization"", ""robustness"", ""label misalignment"", ""music"", ""time series""]",This work introduces a novel loss function for the robust training of temporal localization DNN in the presence of misaligned labels.,,,,
SylVJTNKDr,2020,Reject,True,Entropy Minimization In Emergent Languages,"[""Eugene Kharitonov"", ""Rahma Chaabouni"", ""Diane Bouchacourt"", ""Marco Baroni""]","[""language emergence""]",,1905.13687,cs.CL,2019-05-31 15:54:41+00:00,2020-06-26 10:03:02+00:00
SylVNerFvr,2020,Accept (Poster),False,Permutation Equivariant Models for Compositional Generalization in Language,"[""Jonathan Gordon"", ""David Lopez-Paz"", ""Marco Baroni"", ""Diane Bouchacourt""]","[""Compositionality"", ""Permutation Equivariance"", ""Language Processing""]","We propose a link between permutation equivariance and compositional generalization, and provide equivariant language models",,,,
SylWNC4FPH,2020,Reject,False,Auto Completion of User Interface Layout Design Using Transformer-Based Tree Decoders,"[""Yang Li"", ""Julien Amelot"", ""Xin Zhou"", ""Samy Bengio"", ""Si Si""]","[""Transformer"", ""decoder"", ""user interface"", ""layout design""]",The paper investigates several Transformer-based decoder models for predicting a complete layout given a partial layout tree.,2001.05308,cs.HC,2020-01-14 17:24:41+00:00,2020-01-14 17:24:41+00:00
Syld53NtvH,2020,Reject,True,Expected Tight Bounds for Robust Deep Neural Network Training,"[""Salman Alsubaihi"", ""Adel Bibi"", ""Modar Alfadly"", ""Abdullah Hamdi"", ""Bernard Ghanem""]","[""network robustness"", ""network verification"", ""interval bound propagation""]","For networks with ReLU activations, we derive output interval bounds, which are tight and true (in expectation) and easy to use in robust training.",1905.12418,cs.LG,2019-05-28 12:07:48+00:00,2021-06-12 22:35:45+00:00
Sylgsn4Fvr,2020,Accept (Poster),True,"To Relieve Your Headache of Training an MRF, Take AdVIL","[""Chongxuan Li"", ""Chao Du"", ""Kun Xu"", ""Max Welling"", ""Jun Zhu"", ""Bo Zhang""]","[""Markov Random Fields"", ""Undirected Graphical Models"", ""Variational Inference"", ""Black-box Infernece""]",We propose a black-box algorithm called AdVIL  to perform inference and learning on a general Markov random field.,1901.08400,cs.LG,2019-01-24 13:39:57+00:00,2020-02-14 02:27:49+00:00
SyljQyBFDH,2020,Accept (Poster),False,Meta-Learning Deep Energy-Based Memory Models,"[""Sergey Bartunov"", ""Jack Rae"", ""Simon Osindero"", ""Timothy Lillicrap""]","[""associative memory"", ""energy-based memory"", ""meta-learning"", ""compressive memory""]",Deep associative memory models using arbitrary neural networks as a storage.,,,,
SylkYeHtwr,2020,Accept (Spotlight),False,SUMO: Unbiased Estimation of Log Marginal Probability for Latent Variable Models,"[""Yucen Luo"", ""Alex Beatson"", ""Mohammad Norouzi"", ""Jun Zhu"", ""David Duvenaud"", ""Ryan P. Adams"", ""Ricky T. Q. Chen""]",[],"We create an unbiased estimator for the log probability of latent variable models, extending such models to a larger scope of applications.",2004.00353,cs.LG,2020-04-01 11:49:30+00:00,2020-07-10 19:42:39+00:00
SylkzaEYPS,2020,Reject,False,Encoder-decoder Network as Loss Function for Summarization,"[""Glen Jeh""]","[""encoder-decoder"", ""summarization"", ""loss functions""]",We present the use of a secondary encoder-decoder as a loss function to help train a summarizer.,,,,
SylpBgrKPH,2020,Reject,False,MissDeepCausal: causal inference from incomplete data using deep latent variable models,"[""Julie Josse"", ""Imke Mayer"", ""Jean-Philippe Vert""]","[""treatment effect estimation"", ""missing values"", ""variational autoencoders"", ""importance sampling"", ""double robustness""]",,,,,
SylurJHFPS,2020,Reject,False,The Detection of Distributional Discrepancy for Text Generation,"[""Xingyuan Chen"", ""Ping Cai"", ""Peng Jin"", ""Haokun Du"", ""Hongjun Wang"", ""Xinyu Dai"", ""Jiajun Chen""]",[],,,,,
SylwBpNKDr,2020,Reject,False,Boosting Network: Learn by Growing Filters and Layers via SplitLBI,"[""Zuyuan Zhong"", ""Chen Liu"", ""Yanwei Fu"", ""Yuan Yao""]",[],,,,,
SylzhkBtDB,2020,Accept (Poster),False,Understanding and Improving Information Transfer in Multi-Task Learning,"[""Sen Wu"", ""Hongyang R. Zhang"", ""Christopher R\u00e9""]","[""Multi-Task Learning""]",A Theoretical Study of Multi-Task Learning with Practical Implications for Improving Multi-Task Training and Transfer Learning,2005.00944,cs.LG,2020-05-02 23:43:52+00:00,2020-05-02 23:43:52+00:00
SyoDInJ0-,2018,Accept (Poster),False,Reinforcement Learning Algorithm Selection,"[""Romain Laroche"", ""Raphael Feraud""]","[""Reinforcement Learning"", ""Multi-Armed Bandit"", ""Algorithm Selection""]",This paper formalises the problem of online algorithm selection in the context of Reinforcement Learning.,,,,
Syoiqwcxx,2017,Reject,False,Local minima in training of deep networks,"[""Grzegorz Swirszcz"", ""Wojciech Marian Czarnecki"", ""Razvan Pascanu""]","[""Theory"", ""Deep learning"", ""Supervised Learning"", ""Optimization""]","As a contribution to the discussion about error surface and the question why ""deep and cheap"" learning works so well we present concrete examples of local minima and obstacles arising in the training of deep models.",,,,
SypU81Ole,2017,Reject,False,Sampling Generative Networks,"[""Tom White""]","[""Unsupervised Learning"", ""Deep learning"", ""Computer vision""]",Demonstrates improved techniques for interpolation and deriving + evaluating attribute vectors in latent spaces applicable to both VAE and GAN models.,,,,
SyqAPeWAZ,2018,Reject,False,CNNs as Inverse Problem Solvers and Double Network Superresolution,"[""Cem TARHAN"", ""G\u00f6zde BOZDA\u011eI AKAR""]","[""superresolution"", ""convolutional neural network"", ""sparse representation"", ""inverse problem""]","After proving that a neuron acts as an inverse problem solver for superresolution and a network of neurons is guarantied to provide a solution, we proposed a double network architecture that performs faster than state-of-the-art.",,,,
SyqShMZRb,2018,Accept (Poster),False,Syntax-Directed Variational Autoencoder for Structured Data,"[""Hanjun Dai"", ""Yingtao Tian"", ""Bo Dai"", ""Steven Skiena"", ""Le Song""]","[""generative model for structured data"", ""syntax-directed generation"", ""molecule and program optimization"", ""variational autoencoder""]","A new generative model for discrete structured data. The proposed stochastic lazy attribute converts the offline semantic check into online guidance for stochastic decoding, which effectively addresses the constraints in syntax and semantics, and also achieves superior performance",,,,
Syr8Qc1CW,2018,Invite to Workshop Track,False,DNA-GAN: Learning Disentangled Representations from Multi-Attribute Images,"[""Taihong Xiao"", ""Jiapeng Hong"", ""Jinwen Ma""]","[""disentangled representations"", ""multi-attribute images"", ""generative adversarial networks""]","We proposed a supervised algorithm, DNA-GAN, to disentangle multiple attributes of images.",,,,
SyrGJYlRZ,2018,Reject,False,YellowFin and the Art of Momentum Tuning,"[""Jian Zhang"", ""Ioannis Mitliagkas"", ""Christopher Re""]","[""adaptive optimizer"", ""momentum"", ""hyperparameter tuning""]",YellowFin is an SGD based optimizer with both momentum and learning rate adaptivity.,,,,
Sys6GJqxl,2017,Accept (Poster),False,Delving into Transferable Adversarial Examples and Black-box Attacks,"[""Yanpei Liu"", ""Xinyun Chen"", ""Chang Liu"", ""Dawn Song""]","[""Computer vision"", ""Deep learning"", ""Applications""]",,,,,
SysEexbRb,2018,Accept (Poster),True,Critical Points of Linear Neural Networks: Analytical Forms and Landscape Properties,"[""Yi Zhou"", ""Yingbin Liang""]","[""neural networks"", ""critical points"", ""analytical form"", ""landscape""]","We provide necessary and sufficient analytical forms for the critical points of the square loss functions for various neural networks, and exploit the analytical forms to characterize the landscape properties for the loss functions of these neural networks.",1710.11205,stat.ML,2017-10-30 19:18:43+00:00,2017-10-30 19:18:43+00:00
Syt0r4bRZ,2018,Reject,False,Tree2Tree Learning with Memory Unit,"[""Ning Miao"", ""Hengliang Wang"", ""Ran Le"", ""Chongyang Tao"", ""Mingyue Shang"", ""Rui Yan"", ""Dongyan Zhao""]",[],,,,,
SyuWNMZ0W,2018,Reject,False,Directing Generative Networks with Weighted Maximum Mean Discrepancy,"[""Maurice Diesendruck"", ""Guy W. Cole"", ""Sinead Williamson""]","[""generative networks"", ""two sample tests"", ""bias correction"", ""maximum mean discrepancy""]","We propose an estimator for the maximum mean discrepancy, appropriate when a target distribution is only accessible via a biased sample selection procedure, and show that it can be used in a generative network to correct for this bias.",,,,
SyunbfbAb,2018,Invite to Workshop Track,False,FigureQA: An Annotated Figure Dataset for Visual Reasoning,"[""Samira Ebrahimi Kahou"", ""Adam Atkinson"", ""Vincent Michalski"", ""\u00c1kos K\u00e1d\u00e1r"", ""Adam Trischler"", ""Yoshua Bengio""]","[""dataset"", ""computer vision"", ""deep learning"", ""visual reasoning"", ""relational reasoning""]","We present a question-answering dataset, FigureQA, as a first step towards developing models that can intuitively recognize patterns from visual representations of data.",,,,
SyvCD-b0W,2018,Reject,False,Autostacker: an Automatic Evolutionary Hierarchical  Machine Learning System,"[""Boyuan Chen"", ""Warren Mo"", ""Ishanu Chattopadhyay"", ""Hod Lipson""]","[""Machine Learning"", ""AutoML""]",Automate machine learning system with efficient search algorithm and innovative structure to provide better model baselines.,,,,
SywUHFcge,2017,Invite to Workshop Track,False, A Theoretical Framework for Robustness of (Deep) Classifiers against Adversarial Samples,"[""Beilun Wang"", ""Ji Gao"", ""Yanjun Qi""]","[""Deep learning""]",We propose a theoretical framework to explain and measure model robustness and harden DNN model against adversarial attacks.,,,,
SywXXwJAb,2018,Accept (Poster),False,Deep Learning and Quantum Entanglement: Fundamental Connections with Implications to Network Design,"[""Yoav Levine"", ""David Yakira"", ""Nadav Cohen"", ""Amnon Shashua""]","[""deep learning"", ""quantum entanglement"", ""quantum physics"", ""many body physics"", ""data correlations"", ""inductive bias"", ""tensor networks""]","Employing quantum entanglement measures for quantifying correlations in deep learning, and using the connection to fit the deep network's architecture to correlations in the data.",,,,
Sywh5KYex,2017,Reject,False,Learning Identity Mappings with Residual Gates,"[""Pedro H. P. Savarese"", ""Leonardo O. Mazza"", ""Daniel R. Figueiredo""]","[""Computer vision"", ""Deep learning"", ""Optimization""]",This paper proposes adding simple gates to layers to make learning identity mappings trivial. It also introduces Gated Plain Networks and Gated Residual Networks.,,,,
Syx-bCEFPS,2020,Reject,False,Synthetic vs Real: Deep Learning on Controlled Noise,"[""Lu Jiang"", ""Di Huang"", ""Weilong Yang""]","[""controlled experiments"", ""robust deep learning"", ""corrupted label"", ""real-world noisy data""]",We establish a benchmark of controlled real noise and reveal several interesting findings about real-world noisy data.,,,,
Syx0Mh05YQ,2019,Accept (Poster),True,Learning Grid Cells as Vector Representation of Self-Position Coupled with Matrix Representation of Self-Motion,"[""Ruiqi Gao"", ""Jianwen Xie"", ""Song-Chun Zhu"", ""Ying Nian Wu""]",[],,1810.05597,stat.ML,2018-10-12 16:34:07+00:00,2019-05-25 00:22:05+00:00
Syx1DkSYwB,2020,Accept (Poster),False,Variance Reduction With Sparse Gradients,"[""Melih Elibol"", ""Lihua Lei"", ""Michael I. Jordan""]","[""optimization"", ""variance reduction"", ""machine learning"", ""deep neural networks""]",We use sparsity to improve the computational complexity of variance reduction methods.,2001.09623,cs.LG,2020-01-27 08:23:58+00:00,2020-01-27 08:23:58+00:00
Syx33erYwH,2020,Reject,False,ASYNCHRONOUS MULTI-AGENT GENERATIVE ADVERSARIAL IMITATION LEARNING,"[""Xin Zhang"", ""Weixiao Huang"", ""Renjie Liao"", ""Yanhua Li""]","[""Multi-agent"", ""Imitation Learning"", ""Inverse Reinforcement Learning""]",This paper extends the multi-agent generative adversarial imitation learning to extensive-form Markov games.,,,,
Syx4_iCqKQ,2019,Reject,False,Polar Prototype Networks,"[""Pascal Mettes"", ""Elise van der Pol"", ""Cees G. M. Snoek""]","[""prototype networks"", ""polar prototypes"", ""output structure""]",This work proposes a class of networks that can jointly perform classification and regression by imposing layout structures in the network output space.,,,,
Syx4wnEtvH,2020,Accept (Poster),True,Large Batch Optimization for Deep Learning: Training BERT in 76 minutes,"[""Yang You"", ""Jing Li"", ""Sashank Reddi"", ""Jonathan Hseu"", ""Sanjiv Kumar"", ""Srinadh Bhojanapalli"", ""Xiaodan Song"", ""James Demmel"", ""Kurt Keutzer"", ""Cho-Jui Hsieh""]","[""large-batch optimization"", ""distributed training"", ""fast optimizer""]",A fast optimizer for general applications and large-batch training.,1904.00962,cs.LG,2019-04-01 16:53:35+00:00,2020-01-03 06:53:00+00:00
Syx5V2CcFm,2019,Accept (Poster),False,Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions,"[""Zaiyi Chen"", ""Zhuoning Yuan"", ""Jinfeng Yi"", ""Bowen Zhou"", ""Enhong Chen"", ""Tianbao Yang""]","[""optimization"", ""sgd"", ""adagrad""]",,,,,
Syx5eT4KDS,2020,Reject,False,Discrete InfoMax Codes for Meta-Learning,"[""Yoonho Lee"", ""Wonjae Kim"", ""Seungjin Choi""]","[""meta-learning"", ""generalization"", ""discrete representations""]","We derive a generalization bound for meta-learning, and propose a meta-learning model that generalizes well",,,,
Syx6bz-Ab,2018,Reject,False,Seq2SQL: Generating Structured Queries From Natural Language Using Reinforcement Learning ,"[""Victor Zhong"", ""Caiming Xiong"", ""Richard Socher""]","[""deep learning"", ""reinforcement learning"", ""dataset"", ""natural language processing"", ""natural language interface"", ""sql""]","We introduce Seq2SQL, which translates questions to SQL queries using rewards from online query execution, and WikiSQL, a SQL table/question/query dataset orders of magnitude larger than existing datasets.",,,,
Syx72jC9tm,2019,Accept (Poster),False,Invariant and Equivariant Graph Networks,"[""Haggai Maron"", ""Heli Ben-Hamu"", ""Nadav Shamir"", ""Yaron Lipman""]","[""graph learning"", ""equivariance"", ""deep learning""]",The paper provides a full characterization of permutation invariant and equivariant linear layers for graph data.,,,,
Syx79eBKwr,2020,Accept (Spotlight),False,A Mutual Information Maximization Perspective of Language Representation Learning,"[""Lingpeng Kong"", ""Cyprien de Masson d'Autume"", ""Lei Yu"", ""Wang Ling"", ""Zihang Dai"", ""Dani Yogatama""]",[],,,,,
Syx7A3NFvH,2020,Accept (Poster),False,Multi-agent Reinforcement Learning for Networked System Control,"[""Tianshu Chu"", ""Sandeep Chinchali"", ""Sachin Katti""]","[""deep reinforcement learning"", ""multi-agent reinforcement learning"", ""decision and control""]",This paper proposes a new formulation and a new communication protocol for networked multi-agent control problems,,,,
Syx7WyBtwB,2020,Reject,True,Interpretations are useful: penalizing explanations to align neural networks with prior knowledge,"[""Laura Rieger"", ""Chandan Singh"", ""W. James Murdoch"", ""Bin Yu""]","[""explainability"", ""deep learning"", ""interpretability"", ""computer vision""]","Explanations are useful now! We introduce CDEP, a technique for penalizing explanations in order to improve predictive accuracy.",1909.13584,cs.LG,2019-09-30 11:02:01+00:00,2020-10-08 12:43:21+00:00
Syx9ET4YPB,2020,Reject,False,Do Image Classifiers Generalize Across Time?,"[""Vaishaal Shankar"", ""Achal Dave"", ""Rebecca Roelofs"", ""Deva Ramanan"", ""Ben Recht"", ""Ludwig Schmidt""]","[""robustness"", ""image classification"", ""distribution shift""]",We systematically measure the sensitivity of image classifiers to temporal perturbations by introducing two human-reviewed benchmarks of similar video frames.,,,,
Syx9Q1rYvH,2020,Reject,False,Mutual Information Maximization for Robust Plannable Representations,"[""Yiming Ding"", ""Ignasi Clavera"", ""Pieter Abbeel""]","[""reinforcement learning"", ""robust learning"", ""model based"", ""planning"", ""representation learning""]",Representational learning objective for planning that is robust to visual distractors,,,,
Syx9rnRcYm,2019,Reject,False,A CASE STUDY ON OPTIMAL DEEP LEARNING MODEL FOR UAVS,"[""Chandan Kumar"", ""Subrahmanyam Vaddi"", ""Aishwarya Sarkar""]","[""Energy Efficiency"", ""Autonomous Flying"", ""Trail Detection""]",case study on optimal deep learning model for UAVs,,,,
SyxAb30cY7,2019,Accept (Poster),False,Robustness May Be at Odds with Accuracy,"[""Dimitris Tsipras"", ""Shibani Santurkar"", ""Logan Engstrom"", ""Alexander Turner"", ""Aleksander Madry""]","[""adversarial examples"", ""robust machine learning"", ""robust optimization"", ""deep feature representations""]","We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.",,,,
SyxBgkBFPS,2020,Reject,False,Guided Adaptive Credit Assignment for Sample Efficient Policy Optimization,"[""Hao Liu"", ""Richard Socher"", ""Caiming Xiong""]","[""credit assignment"", ""sparse reward"", ""policy optimization"", ""sample efficiency""]",A new and general credit assignment method for obtaining sample efficiency of policy optimization in sparse reward setting,,,,
SyxC9TEtPH,2020,Reject,True,Conditional Invertible Neural Networks for Guided Image Generation,"[""Lynton Ardizzone"", ""Carsten L\u00fcth"", ""Jakob Kruse"", ""Carsten Rother"", ""Ullrich K\u00f6the""]","[""Invertible neural networks"", ""generative models"", ""conditional generation""]",,1907.02392,cs.CV,2019-07-04 13:20:57+00:00,2019-07-10 11:10:36+00:00
SyxCqGbRZ,2018,Reject,False,Learning to Treat Sepsis with Multi-Output Gaussian Process Deep Recurrent Q-Networks,"[""Joseph Futoma"", ""Anthony Lin"", ""Mark Sendak"", ""Armando Bedoya"", ""Meredith Clement"", ""Cara O'Brien"", ""Katherine Heller""]","[""Healthcare"", ""Gaussian Process"", ""Deep Reinforcement Learning""]","We combine Multi-output Gaussian processes with deep recurrent Q-networks to learn optimal treatments for sepsis and show improved performance over standard deep reinforcement learning methods,",,,,
SyxD7lrFPH,2020,Reject,False,Frequency Pooling: Shift-Equivalent and Anti-Aliasing Down Sampling,"[""Zhendong Zhang"", ""Cheolkon Jung""]","[""pooling"", ""anti-aliasing"", ""shift-equivalent"", ""frequency""]",,,,,
SyxDXJStPS,2020,Reject,False,Reparameterized Variational Divergence Minimization for Stable Imitation,"[""Dilip Arumugam"", ""Debadeepta Dey"", ""Alekh Agarwal"", ""Asli Celikyilmaz"", ""Elnaz Nouri"", ""Eric Horvitz"", ""Bill Dolan""]","[""Imitation Learning"", ""Reinforcement Learning"", ""Adversarial Learning"", ""Learning from Demonstration""]","The overall goal of this work is to enable sample-efficient imitation from expert demonstrations, both with and without the provision of expert action labels, through the use of f-divergences.",,,,
SyxGoJrtPr,2020,Reject,False,SPROUT: Self-Progressing Robust Training,"[""Minhao Cheng"", ""Pin-Yu Chen"", ""Sijia Liu"", ""Shiyu Chang"", ""Cho-Jui Hsieh"", ""Payel Das""]","[""robustness"", ""robust training"", ""trustworthy machine learning""]","We proposed a new robust training framework that is scalable, effective and comprehensive",2012.11769,cs.LG,2020-12-22 00:45:24+00:00,2020-12-22 00:45:24+00:00
SyxHKjAcYX,2019,Reject,False,Zero-Resource Multilingual Model Transfer: Learning What to Share,"[""Xilun Chen"", ""Ahmed Hassan Awadallah"", ""Hany Hassan"", ""Wei Wang"", ""Claire Cardie""]","[""cross-lingual transfer learning"", ""multilingual transfer learning"", ""zero-resource model transfer"", ""adversarial training"", ""mixture of experts"", ""multilingual natural language understanding""]",A zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.,,,,
SyxIWpVYvr,2020,Accept (Poster),True,Input Complexity and Out-of-distribution Detection with Likelihood-based Generative Models,"[""Joan Serr\u00e0"", ""David \u00c1lvarez"", ""Vicen\u00e7 G\u00f3mez"", ""Olga Slizovskaia"", ""Jos\u00e9 F. N\u00fa\u00f1ez"", ""Jordi Luque""]","[""OOD"", ""generative models"", ""likelihood""]","We pose that generative models' likelihoods are excessively influenced by the input's complexity, and propose a way to compensate it when detecting out-of-distribution inputs",1909.11480,cs.LG,2019-09-25 13:27:53+00:00,2020-01-17 10:38:05+00:00
SyxIterYwS,2020,Reject,False,Dynamical System Embedding for Efficient Intrinsically Motivated Artificial Agents,"[""Ruihan Zhao"", ""Stas Tiomkin"", ""Pieter Abbeel""]","[""intrinsic motivation"", ""empowerment"", ""latent representation"", ""encoder""]",A faster approach to calculate empowerment from images.,1912.02624,cs.LG,2019-12-04 07:48:40+00:00,2020-08-02 23:07:25+00:00
SyxJU64twr,2020,Reject,False,Model Ensemble-Based Intrinsic Reward for Sparse Reward Reinforcement Learning,"[""Giseung Park"", ""Whiyoung Jung"", ""Sungho Choi"", ""Youngchul Sung""]","[""Reinforcement Learning"", ""Intrinsic Reward"", ""Dynamics Model"", ""Ensemble""]","For sparse-reward reinforcement learning, the ensemble of multiple dynamics models is used to generate intrinsic reward designed as the minimum of the surprise.",,,,
SyxKrySYPr,2020,Reject,False,Stabilizing Transformers for Reinforcement Learning,"[""Emilio Parisotto"", ""Francis Song"", ""Jack Rae"", ""Razvan Pascanu"", ""Caglar Gulcehre"", ""Siddhant Jayakumar"", ""Max Jaderberg"", ""Rapha\u00ebl Lopez Kaufman"", ""Aidan Clark"", ""Seb Noury"", ""Matt Botvinick"", ""Nicolas Heess"", ""Raia Hadsell""]","[""Deep Reinforcement Learning"", ""Transformer"", ""Reinforcement Learning"", ""Self-Attention"", ""Memory"", ""Memory for Reinforcement Learning""]","We succeed in stabilizing transformers for training in the RL setting and demonstrate a large improvement over LSTMs on DMLab-30, matching an external memory architecture.",,,,
SyxL2TNtvr,2020,Accept (Poster),False,Unsupervised Model Selection for Variational Disentangled Representation Learning,"[""Sunny Duan"", ""Loic Matthey"", ""Andre Saraiva"", ""Nick Watters"", ""Chris Burgess"", ""Alexander Lerchner"", ""Irina Higgins""]","[""unsupervised disentanglement metric"", ""disentangling"", ""representation learning""]",We introduce a method for unsupervised disentangled model selection for VAE-based disentangled representation learning approaches.,,,,
SyxM51BYPB,2020,Reject,False,A new perspective in understanding of Adam-Type algorithms and beyond,"[""Zeyi Tao"", ""Qi Xia"", ""Qun Li""]","[""Machine Learning"", ""Algorithm"", ""Adam"", ""First-Order Method""]",A new perspective in understanding of Adam-Type algorithms,,,,
SyxMWh09KX,2019,Reject,True,Attentive Task-Agnostic Meta-Learning for Few-Shot Text Classification,"[""Xiang Jiang"", ""Mohammad Havaei"", ""Gabriel Chartrand"", ""Hassan Chouaib"", ""Thomas Vincent"", ""Andrew Jesson"", ""Nicolas Chapados"", ""Stan Matwin""]","[""meta-learning"", ""learning to learn"", ""few-shot learning""]",Meta-learning task-agnostic representations with attention.,1806.00852,cs.LG,2018-06-03 19:16:50+00:00,2018-06-03 19:16:50+00:00
SyxS0T4tvS,2020,Reject,True,RoBERTa: A Robustly Optimized BERT Pretraining Approach,"[""Yinhan Liu"", ""Myle Ott"", ""Naman Goyal"", ""Jingfei Du"", ""Mandar Joshi"", ""Danqi Chen"", ""Omer Levy"", ""Mike Lewis"", ""Luke Zettlemoyer"", ""Veselin Stoyanov""]","[""Deep learning"", ""language representation learning"", ""natural language understanding""]",We evaluate a number of design decisions when pretraining BERT models and propose an improved recipe that achieves state-of-the-art results on many natural language understanding tasks.,1907.11692,cs.CL,2019-07-26 17:48:29+00:00,2019-07-26 17:48:29+00:00
SyxTZ1HYwB,2020,Reject,False,TWO-STEP UNCERTAINTY NETWORK FOR TASKDRIVEN SENSOR PLACEMENT,"[""Yangyang Sun"", ""Yang Zhang"", ""Hassan Foroosh"", ""Shuo Pang""]","[""Uncertainty Estimation"", ""Sensor Placement"", ""Sequential Control"", ""Adaptive Sensing""]",Strategy of sensor placement to maximize the information gain with generative neural network. ,,,,
SyxV9ANFDH,2020,Accept (Poster),False,Economy Statistical Recurrent Units For Inferring Nonlinear Granger Causality,"[""Saurabh Khanna"", ""Vincent Y. F. Tan""]","[""Recurrent neural networks"", ""Granger causality"", ""Causal inference"", ""Statistical Recurrent Unit""]",A new recurrent neural network architecture for detecting pairwise Granger causality between nonlinearly interacting time series. ,1911.09879,cs.LG,2019-11-22 06:40:07+00:00,2020-01-14 04:48:30+00:00
SyxXWC4KPB,2020,Reject,False,Structured consistency loss for semi-supervised semantic segmentation,"[""JongMok Kim"", ""Joo Young Jang"", ""Hyunwoo Park""]","[""semi-supervised learning"", ""semantic segmentation"", ""structured prediction"", ""structured consistency loss""]",We propose a novel structured consistency loss for semi-supervised semantic segmentation,,,,
SyxXhsAcFQ,2019,Reject,False,Cohen Welling bases & SO(2)-Equivariant classifiers using Tensor nonlinearity.,"[""Muthuvel Murugan"", ""K Venkata Subrahmanyam""]","[""group representations"", ""group equivariant networks"", ""tensor product nonlinearity""]",,,,,
SyxYEoA5FX,2019,Reject,False,Invariance and Inverse Stability under ReLU,"[""Jens Behrmann"", ""S\u00f6ren Dittmer"", ""Pascal Fernsel"", ""Peter Maass""]","[""deep neural networks"", ""invertibility"", ""invariance"", ""robustness"", ""ReLU networks""]",We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.,,,,
SyxZJn05YX,2019,Accept (Poster),False,Feature Intertwiner for Object Detection,"[""Hongyang Li"", ""Bo Dai"", ""Shaoshuai Shi"", ""Wanli Ouyang"", ""Xiaogang Wang""]","[""feature learning"", ""computer vision"", ""deep learning""]",(Camera-ready version) A feature intertwiner module to leverage features from one accurate set to help the learning of another less reliable set.,,,,
SyxZOsA9tX,2019,Reject,False,Accelerated Value Iteration via Anderson Mixing,"[""Yujun Li"", ""Chengzhuo Ni"", ""Guangzeng Xie"", ""Wenhao Yang"", ""Shuchang Zhou"", ""Zhihua Zhang""]","[""Reinforcement Learning""]",,,,,
Syx_Ss05tm,2019,Accept (Poster),False,Adversarial Reprogramming of Neural Networks,"[""Gamaleldin F. Elsayed"", ""Ian Goodfellow"", ""Jascha Sohl-Dickstein""]","[""Adversarial"", ""Neural Networks"", ""Machine Learning Security""]",We introduce the first instance of adversarial attacks that reprogram the target model to perform a task chosen by the attacker---without the attacker needing to specify or compute the desired output for each test-time input.,,,,
Syx_f6EFPr,2020,Reject,False,Supervised learning with incomplete data via sparse representations,"[""Cesar F. Caiafa"", ""Ziyao Wang"", ""Jordi Sol\u00e9-Casals"", ""Qibin Zhao""]","[""Incomplete data"", ""supervised learning"", ""sparse representations""]",,2011.14047,cs.LG,2020-11-28 02:20:39+00:00,2021-04-17 20:09:10+00:00
SyxaYsAqY7,2019,Reject,False,Second-Order Adversarial Attack and Certifiable Robustness,"[""Bai Li"", ""Changyou Chen"", ""Wenlin Wang"", ""Lawrence Carin""]",[],,,,,
Syxc1yrKvr,2020,Reject,False,Implicit Î»-Jeffreys Autoencoders: Taking the Best of Both Worlds,"[""Aibek Alanov"", ""Max Kochurov"", ""Artem Sobolev"", ""Daniil Yashkov"", ""Dmitry Vetrov""]","[""Variational Inference"", ""Generative Adversarial Networks""]",We propose a new form of an autoencoding model which incorporates the best properties of variational autoencoders (VAE) and generative adversarial networks (GAN),,,,
SyxdC6NKwH,2020,Reject,False,Uncertainty-Aware Prediction for Graph Neural Networks,"[""Xujiang Zhao"", ""Feng Chen"", ""Shu Hu"", ""jin-Hee Cho""]","[""Uncertainty"", ""Graph Neural Networks"", ""Subjective Logic"", ""Bayesian""]",Multiple Uncertainty Prediction for Graph Neural Networks in Node Classification,2010.12783,cs.LG,2020-10-24 04:56:46+00:00,2020-11-24 23:21:58+00:00
SyxeqhP9ll,2017,Accept (Poster),False,Calibrating Energy-based Generative Adversarial Networks,"[""Zihang Dai"", ""Amjad Almahairi"", ""Philip Bachman"", ""Eduard Hovy"", ""Aaron Courville""]","[""Deep learning""]",,,,,
SyxfEn09Y7,2019,Accept (Poster),False,G-SGD: Optimizing ReLU Neural Networks in its Positively Scale-Invariant Space,"[""Qi Meng"", ""Shuxin Zheng"", ""Huishuai Zhang"", ""Wei Chen"", ""Qiwei Ye"", ""Zhi-Ming Ma"", ""Nenghai Yu"", ""Tie-Yan Liu""]","[""optimization"", ""neural network"", ""irreducible positively scale-invariant space"", ""deep learning""]",,,,,
Syxgbh05tQ,2019,Reject,False,Lyapunov-based Safe Policy Optimization,"[""Yinlam Chow"", ""Ofir Nachum"", ""Mohammad Ghavamzadeh"", ""Edgar Guzman-Duenez""]","[""Reinforcement Learning"", ""Safe Learning"", ""Lyapunov Functions"", ""Constrained Markov Decision Problems""]",Safe Reinforcement Learning Algorithms for Continuous Control,,,,
SyxhVkrYvr,2020,Accept (Poster),False,Towards Verified Robustness under Text Deletion Interventions,"[""Johannes Welbl"", ""Po-Sen Huang"", ""Robert Stanforth"", ""Sven Gowal"", ""Krishnamurthy (Dj) Dvijotham"", ""Martin Szummer"", ""Pushmeet Kohli""]","[""natural language processing"", ""specification"", ""verification"", ""model undersensitivity"", ""adversarial"", ""interval bound propagation""]",Formal verification of a specification on a model's prediction undersensitivity using Interval Bound Propagation,,,,
SyxhaxBKPS,2020,Reject,False,Smart Ternary Quantization,"[""Gregoire Morin"", ""Ryan Razani"", ""Vahid Partovi Nia"", ""Eyyub Sari""]",[],,,,,
Syxi6grFwH,2020,Reject,False,HIPPOCAMPAL NEURONAL REPRESENTATIONS IN CONTINUAL LEARNING,"[""Samia Mohinta"", ""Rui Ponte Costa"", ""Stephane Ciocchi""]",[],,,,,
SyxiRJStwr,2020,Reject,True,Dynamic Scale Inference by Entropy Minimization,"[""Dequan Wang"", ""Evan Shelhamer"", ""Bruno Olshausen"", ""Trevor Darrell""]","[""unsupervised learning"", ""dynamic inference"", ""equivariance"", ""entropy""]",Unsupervised optimization during inference gives top-down feedback to iteratively adjust feedforward prediction of scale variation for more equivariant recognition.,1908.03182,cs.CV,2019-08-08 17:21:20+00:00,2019-08-08 17:21:20+00:00
SyxjVRVKDB,2020,Reject,True,Switched linear projections and inactive state sensitivity for deep neural network interpretability,"[""Lech Szymanski"", ""Brendan McCane"", ""Craig Atkinson""]","[""deep learning"", ""interpretability"", ""artificial neural networks""]","The neurons that are ""off"" in artificial neural networks carry a lot of information about patterns the network is sesitive to. ",1909.11275,cs.LG,2019-09-25 03:43:37+00:00,2020-02-06 22:05:51+00:00
SyxknjC9KQ,2019,Reject,False,Dense Morphological Network: An Universal Function Approximator,"[""Ranjan Mondal"", ""Sanchayan Santra"", ""Bhabatosh Chanda""]","[""Mathematical Morphology"", ""Neural Network"", ""Activation Function"", ""Universal Aproximatimation.""]",Using mophological operation (dilation and erosion) we have defined a class of network which can approximate any continious function. ,,,,
SyxnvsAqFm,2019,Reject,False,Computation-Efficient Quantization Method for Deep Neural Networks,"[""Parichay Kapoor"", ""Dongsoo Lee"", ""Byeongwook Kim"", ""Saehyung Lee""]","[""quantization"", ""binary"", ""ternary"", ""flat minima"", ""model compression"", ""deep learning""]",A simple computation-efficient quantization training method for CNNs and RNNs.,,,,
Syxp-1HtvB,2020,Reject,False,Semantic Hierarchy Emerges in the Deep Generative Representations for Scene Synthesis,"[""Ceyuan Yang"", ""Yujun Shen"", ""Bolei Zhou""]","[""Feature visualization"", ""feature interpretation"", ""generative models""]",We show that highly-structured semantic hierarchy emerges in the deep generative representations as a result for synthesizing scenes.,1911.09267,cs.CV,2019-11-21 03:26:15+00:00,2020-02-11 05:49:15+00:00
SyxrxR4KPS,2020,Accept (Spotlight),False,Deep neuroethology of a virtual rodent,"[""Josh Merel"", ""Diego Aldarondo"", ""Jesse Marshall"", ""Yuval Tassa"", ""Greg Wayne"", ""Bence Olveczky""]","[""computational neuroscience"", ""motor control"", ""deep RL""]","We built a physical simulation of a rodent, trained it to solve a set of tasks, and analyzed the resulting networks.",,,,
Syxss0EYPS,2020,Reject,False,Agent as Scientist: Learning to Verify Hypotheses,"[""Kenneth Marino"", ""Rob Fergus"", ""Arthur Szlam"", ""Abhinav Gupta""]",[],,2006.15762,cs.AI,2020-06-29 01:01:10+00:00,2020-06-29 01:01:10+00:00
Syxt2jC5FX,2019,Accept (Poster),False,From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference,"[""Randall Balestriero"", ""Richard Baraniuk""]","[""Spline"", ""Vector Quantization"", ""Inference"", ""Nonlinearities"", ""Deep Network""]",Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.,,,,
Syxt5oC5YQ,2019,Accept (Poster),False,Aggregated Momentum: Stability Through Passive Damping,"[""James Lucas"", ""Shengyang Sun"", ""Richard Zemel"", ""Roger  Grosse""]","[""momentum"", ""optimization"", ""deep learning"", ""neural networks""]","We introduce a simple variant of momentum optimization which is able to outperform classical momentum, Nesterov, and Adam on deep learning tasks with minimal hyperparameter tuning.",,,,
SyxtJh0qYm,2019,Accept (Poster),False,Variational Autoencoder with Arbitrary Conditioning,"[""Oleg Ivanov"", ""Michael Figurnov"", ""Dmitry Vetrov""]","[""unsupervised learning"", ""generative models"", ""conditional variational autoencoder"", ""variational autoencoder"", ""missing features multiple imputation"", ""inpainting""]",We propose an extension of conditional variational autoencoder that allows conditioning on an arbitrary subset of the features and sampling the remaining ones.,,,,
SyxvSiCcFQ,2019,Reject,False,Neural Network Cost Landscapes as Quantum States,"[""Abdulah Fawaz"", ""Sebastien Piat"", ""Paul Klein"", ""Peter Mountney"", ""Simone Severini""]","[""quantum"", ""neural networks"", ""meta-learning""]",We show that NN parameter and hyperparameter cost landscapes can be generated as quantum states using a single quantum circuit and that these can be used for training and meta-training.,,,,
SyxwW2A5Km,2019,Reject,False,Learning Representations of Categorical Feature Combinations via Self-Attention,"[""Chen Xu"", ""Chengzhen Fu"", ""Peng Jiang"", ""Wenwu Ou""]","[""Learning Representations"", ""Feature Combinations"", ""Self-Attention""]",,,,,
Syxwsp4KDB,2020,Reject,False,TED: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising,"[""Ziyi Yang"", ""Chenguang Zhu"", ""Michael Zeng"", ""Xuedong Huang"", ""Eric Darve""]","[""text summarization"", ""unsupervised learning"", ""natural language processing""]",A new state-of-the-art for unsupervised abstractive text summarization,,,,
SyyGPP0TZ,2018,Accept (Poster),False,Regularizing and Optimizing LSTM Language Models,"[""Stephen Merity"", ""Nitish Shirish Keskar"", ""Richard Socher""]","[""language model"", ""LSTM"", ""regularization"", ""optimization"", ""ASGD"", ""dropconnect""]",Effective regularization and optimization strategies for LSTM-based language models achieves SOTA on PTB and WT2. ,,,,
SyzKd1bCW,2018,Accept (Poster),False,Backpropagation through the Void: Optimizing control variates for black-box gradient estimation,"[""Will Grathwohl"", ""Dami Choi"", ""Yuhuai Wu"", ""Geoff Roeder"", ""David Duvenaud""]","[""optimization"", ""machine learning"", ""variational inference"", ""reinforcement learning"", ""gradient estimation"", ""deep learning"", ""discrete optimization""]",We present a general method for unbiased estimation of gradients of black-box functions of random variables. We apply this method to discrete variational inference and reinforcement learning. ,,,,
SyzVb3CcFX,2019,Accept (Poster),False,Time-Agnostic Prediction: Predicting Predictable Video Frames,"[""Dinesh Jayaraman"", ""Frederik Ebert"", ""Alexei Efros"", ""Sergey Levine""]","[""visual prediction"", ""subgoal generation"", ""bottleneck states"", ""time-agnostic""]","In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent ""bottleneck state"" predictions, which are useful for planning.",,,,
SyzjBiR9t7,2019,Reject,False,MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA,"[""Rudrasis Chakraborty"", ""Jose Bouza"", ""Jonathan Manton"", ""Baba C. Vemuri""]",[],,,,,
Syzn9i05Ym,2019,Reject,False,Learning Neural Random Fields with Inclusive Auxiliary Generators,"[""Yunfu Song"", ""Zhijian Ou""]","[""Neural random fields"", ""Deep generative models"", ""Unsupervised learning"", ""Semi-supervised learning""]",We develop a new approach to learning neural random fields and show that the new approach obtains state-of-the-art sample generation quality and achieves strong semi-supervised learning results on par with state-of-the-art deep generative models.,,,,
SyzrLjA5FQ,2019,Reject,False,Selective Self-Training for semi-supervised Learning,"[""Jisoo Jeong"", ""Seungeui Lee"", ""Nojun Kwak""]","[""deep learning"", ""image recognition"", ""semi-supervised learning""]","Our proposed algorithm does not use all of the unlabeled data for the training, and it rather uses them selectively.",,,,
SzjyTIc5qMP,2021,Reject,False,Information Lattice Learning,"[""Haizi Yu"", ""James Evans"", ""Lav R. Varshney""]",[],,,,,
T-uEidE-Xpv,2022,Reject,False,Contrastive Mutual Information Maximization for Binary Neural Networks,"['Yuzhang Shang', 'Dan Xu', 'Ziliang Zong', 'Liqiang Nie', 'Yan Yan']","[""network compression"", ""network binarization"", ""contrastive learning""]",,,,,
T0B9AoM_bFg,2022,Accept (Poster),False,Improving Mutual Information Estimation with Annealed and Energy-Based Bounds,"['Rob Brekelmans', 'Sicong Huang', 'Marzyeh Ghassemi', 'Greg Ver Steeg', 'Roger Baker Grosse', 'Alireza Makhzani']","[""mutual information estimation"", ""annealed importance sampling"", ""energy-based models""]","We derive new annealed importance sampling and energy-based bounds, resulting in vastly more accurate estimates of mutual information.",,,,
T0GpzBQ1Fg6,2022,Accept (Poster),False,Step-unrolled Denoising Autoencoders for Text Generation,"['Nikolay Savinov', 'Junyoung Chung', 'Mikolaj Binkowski', 'Erich Elsen', 'Aaron van den Oord']","[""generative models"", ""text generation"", ""denoising autoencoders""]",We propose a new generative model of text that unrolls the denoising process during training.,2112.06749,cs.CL,2021-12-13 16:00:33+00:00,2021-12-13 16:00:33+00:00
T0tmb7uhRhD,2021,Reject,False,Model-Agnostic Round-Optimal Federated Learning via Knowledge Transfer,"[""Qinbin Li"", ""Bingsheng He"", ""Dawn Song""]","[""Federated Learning"", ""Communication-Bounded Learning""]",The paper presents a new federated learning framework with a single communication round.,,,,
T1A11E__Az,2022,Reject,False,Few-Shot Classification with Task-Adaptive Semantic Feature Learning,"['Meihong Pan', 'Chunqiu Xia', 'Hongyi Xin', 'Yang Yang', 'Xiaoyong Pan', 'Hong-Bin Shen']","[""few-shot learning"", ""task-adaptive semantic feature learning"", ""feature concatenation"", ""feature fusion.""]",,,,,
T1EMbxGNEJC,2021,Reject,False,RankingMatch: Delving into Semi-Supervised Learning with Consistency Regularization and Ranking Loss,"[""Trung Quang Tran"", ""Mingu Kang"", ""Daeyoung Kim""]","[""BatchMean Triplet Loss"", ""Semi-Supervised Learning"", ""Consistency Regularization"", ""Metric Learning""]","We propose RankingMatch, a novel semi-supervised learning method that encourages the model to produce the same prediction for not only the different augmented versions of the same input but also the samples from the same class.",,,,
T1XmO8ScKim,2021,Accept (Poster),False,Probabilistic Numeric Convolutional Neural Networks,"[""Marc Anton Finzi"", ""Roberto Bondesan"", ""Max Welling""]","[""probabilistic numerics"", ""gaussian processes"", ""discretization error"", ""pde"", ""superpixel"", ""irregularly spaced time series"", ""misssing data"", ""spatial uncertainty""]",We build a neural network which integrates internal discretization error and missing values probabilistically with GPs,,,,
T3RyQtRHebj,2021,Reject,False,Slot Machines: Discovering Winning Combinations of Random Weights in Neural Networks,"[""Maxwell Mbabilla Aladago"", ""Lorenzo Torresani""]","[""initialization"", ""optimization""]","In contrast to traditional weight optimization in a continuous space, we demonstrate the existence of effective random networks whose weights are never updated.",2101.06475,cs.LG,2021-01-16 16:56:48+00:00,2021-06-08 15:10:26+00:00
T3kmOP_cMFB,2021,Reject,False,Boosting One-Point Derivative-Free Online Optimization via Residual Feedback,"[""Yan Zhang"", ""Yi Zhou"", ""Kaiyi Ji"", ""Michael Zavlanos""]","[""zeroth-order optimization"", ""online learning""]",,,,,
T4-65DNlDij,2022,Accept (Poster),False,Deep Attentive Variational Inference,"['Ifigeneia Apostolopoulou', 'Ian Char', 'Elan Rosenfeld', 'Artur Dubrawski']","[""variational inference"", ""approximate inference"", ""deep probabilistic models"", ""deep probabilistic learning"", ""variational autoencoder"", ""probabilistic methods for deep learning"", ""attention""]",,,,,
T4gXBOXoIUr,2021,Reject,False,Contrastive Learning of Medical Visual Representations from Paired Images and Text,"[""Yuhao Zhang"", ""Hang Jiang"", ""Yasuhide Miura"", ""Christopher D Manning"", ""Curtis Langlotz""]","[""visual representation learning"", ""contrastive learning"", ""medical image understanding"", ""natural language processing""]","We propose an unsupervised framework for learning visual representation of medical images from naturally occurring paired images and text data, which markedly improves the data efficiency of training medical image understanding models.",,,,
T58qDGccG56,2021,Reject,False,On the Stability of Multi-branch Network,"[""Huishuai Zhang"", ""Da Yu"", ""Wei Chen"", ""Tie-Yan Liu""]","[""stability"", ""multi-branch network"", ""backward propagation""]",A stability analysis of multi-branch network provides understanding on practical wisdom and leads new STAM aggregation design.,,,,
T6AxtOaWydQ,2021,Accept (Poster),True,$i$-Mix: A Domain-Agnostic Strategy for Contrastive Representation Learning,"[""Kibok Lee"", ""Yian Zhu"", ""Kihyuk Sohn"", ""Chun-Liang Li"", ""Jinwoo Shin"", ""Honglak Lee""]","[""self-supervised learning"", ""unsupervised representation learning"", ""contrastive representation learning"", ""data augmentation"", ""MixUp""]","We propose i-Mix, a simple yet effective domain-agnostic regularization strategy for improving contrastive representation learning.",2010.08887,cs.LG,2020-10-17 23:32:26+00:00,2021-03-18 07:13:31+00:00
T6RYeudzf1,2021,Reject,True,TextSETTR: Label-Free Text Style Extraction and Tunable Targeted Restyling,"[""Parker Riley"", ""Noah Constant"", ""Mandy Guo"", ""Girish Kumar"", ""David Uthus"", ""Zarana Parekh""]","[""style transfer"", ""text style"", ""text generation"", ""generative models"", ""conditional generation""]","We present a technique for training a style transfer model in the complete absence of labels, and showÂ the resulting model can control many different style attributes at test time (sentiment, dialect, formality, etc.).",2010.03802,cs.CL,2020-10-08 07:06:38+00:00,2021-06-23 06:16:15+00:00
T6lAFguUbw,2022,Reject,False,Modeling Bounded Rationality in Multi-Agent Simulations Using Rationally Inattentive Reinforcement Learning,"['Tong Mu', 'Stephan Zheng', 'Alexander R Trott']","[""Reinforcement Learning"", ""Multi-Agent Reinforcement Learning"", ""Bounded Rationality"", ""Rational Inattention"", ""Simulations""]",We propose a novel framework and policy class for modeling bounded rationality in complex multi-agent reinforcement learning simulations.,,,,
T73sfhfzk07,2022,Reject,False,GRODIN: Improved Large-Scale Out-of-Domain detection via Back-propagation,"['Gleb Yengalych', 'Igor E. Kuralenok', 'Vasily A Ershov']","[""Out of distribution"", ""deep learning"", ""gradient"", ""backpropagation""]",,,,,
T8BnDXDTcFZ,2022,Reject,False,Accelerating Training of Deep Spiking Neural Networks with Parameter Initialization,"['Jianhao Ding', 'Jiyuan Zhang', 'Zhaofei Yu', 'Tiejun Huang']","[""spiking neural networks"", ""back-propagationthrough time"", ""parameter initialization""]",An SNN initialization method based on properties of spiking neuron response is proposed to accelerate training and get better accuracy compared with existing methods.,,,,
T8vZHIRTrY,2022,Accept (Spotlight),True,Understanding Domain Randomization for Sim-to-real Transfer,"['Xiaoyu Chen', 'Jiachen Hu', 'Chi Jin', 'Lihong Li', 'Liwei Wang']","[""domain randomization"", ""sim-to-real transfer"", ""learning theory""]","We propose theoretical frameworks for sim-to-real transfer and domain randomization, and provide bounds on the sub-optimality gap of the policy returned by domain randomization.",2110.03239,cs.LG,2021-10-07 07:45:59+00:00,2021-10-07 07:45:59+00:00
T8wHz4rnuGL,2022,Accept (Spotlight),True,RotoGrad: Gradient Homogenization in Multitask Learning,"['AdriÃ¡n Javaloy', 'Isabel Valera']","[""multitask learning"", ""conflicting gradients"", ""negative transfer""]",We propose an algorithm to simultaneously homogenize gradient magnitudes and directions across tasks in MTL.,2103.02631,cs.LG,2021-03-03 19:03:52+00:00,2021-10-06 20:15:38+00:00
TBIzh9b5eaz,2021,Accept (Poster),False,Risk-Averse Offline Reinforcement Learning,"[""N\u00faria Armengol Urp\u00ed"", ""Sebastian Curi"", ""Andreas Krause""]","[""offline"", ""reinforcement learning"", ""risk-averse"", ""risk sensitive"", ""robust"", ""safety"", ""safe""]",We propose the first risk-averse reinforcement learning algorithm in the fully offline setting. ,,,,
TBWA6PLJZQm,2022,Accept (Poster),True,Learning with Noisy Labels Revisited: A Study Using Real-World Human Annotations,"['Jiaheng Wei', 'Zhaowei Zhu', 'Hao Cheng', 'Tongliang Liu', 'Gang Niu', 'Yang Liu']","[""Learning with noisy labels"", ""benchmark"", ""real-world label noise"", ""human annotations""]","In this paper, we revisit the problem of learning from noisy labels using human annotated CIFAR datasets we collected from Amazon Mechanical Turks.",2110.12088,cs.LG,2021-10-22 22:42:11+00:00,2021-10-22 22:42:11+00:00
TBpg4PnXhYH,2022,Accept (Poster),False,SPIRAL: Self-supervised Perturbation-Invariant Representation Learning for Speech Pre-Training,"['Wenyong Huang', 'Zhenhe Zhang', 'Yu Ting Yeung', 'Xin Jiang', 'Qun Liu']","[""Speech Representation Learning"", ""Speech Pre-training"", ""Speech Recognition"", ""Self-supervised Representation Learning""]",,2201.10207,eess.AS,2022-01-25 09:53:36+00:00,2022-01-29 06:41:55+00:00
TCAmP8zKZ6k,2021,Reject,False,Towards a Reliable and Robust Dialogue System for Medical Automatic Diagnosis,"[""Junfan Lin"", ""Lin Xu"", ""Ziliang Chen"", ""Liang Lin""]",[],,,,,
TCl7CbQ29hH,2022,Reject,True,CPT: Colorful Prompt Tuning for Pre-trained Vision-Language Models,"['Yuan Yao', 'Ao Zhang', 'Zhengyan Zhang', 'Zhiyuan Liu', 'Tat-Seng Chua', 'Maosong Sun']","[""Pretrained Vision-language Models"", ""Prompt Tuning"", ""Visual Grounding""]",This paper proposes a cross-modal prompt tuning framework for pre-trained vision-language models.,2109.11797,cs.CV,2021-09-24 08:07:29+00:00,2021-10-08 09:18:15+00:00
TD-5kgf13mH,2022,Reject,False,Sparse MoEs meet Efficient Ensembles,"['James Urquhart Allingham', 'Florian Wenzel', 'Zelda E Mariet', 'Basil Mustafa', 'Joan Puigcerver', 'Neil Houlsby', 'Ghassen Jerfel', 'Vincent Fortuin', 'Balaji Lakshminarayanan', 'Jasper Snoek', 'Dustin Tran', 'Carlos Riquelme Ruiz', 'Rodolphe Jenatton']","[""Ensembles"", ""Sparse MoEs"", ""Robustness"", ""Uncertainty Calibration"", ""OOD detection"", ""Efficient Ensembles"", ""Large scale"", ""Computer vision""]","We analyse and combine sparse MoE models with ensembles, to better understand the interplay between these two kinds of models, resulting in a new algorithm that provides the best of both worlds for vision transformers with up to 2.7B parameters.",,,,
TDDZxmr6851,2021,Reject,True,The large learning rate phase of deep learning,"[""Aitor Lewkowycz"", ""Yasaman Bahri"", ""Ethan Dyer"", ""Jascha Sohl-Dickstein"", ""Guy Gur-Ari""]","[""deep learning"", ""wide networks"", ""training dynamics""]","The loss grows early on in training if the learning rate is large, and understanding this in full requires new theory.",2003.02218,stat.ML,2020-03-04 17:52:48+00:00,2020-03-04 17:52:48+00:00
TETmEkko7e5,2021,Reject,True,Bridging the Gap: Providing Post-Hoc Symbolic Explanations for Sequential Decision-Making Problems with Inscrutable Representations,"[""Sarath Sreedharan"", ""Utkarsh Soni"", ""Mudit Verma"", ""Siddharth Srivastava"", ""Subbarao Kambhampati""]","[""Explanations"", ""Concept based explanations"", ""Learning symbolic representations"", ""Sequential Decision Making"", ""Planning"", ""Reinforcement learning.""]",,2002.01080,cs.AI,2020-02-04 01:37:56+00:00,2021-10-06 00:17:50+00:00
TEt7PsVZux6,2022,Reject,False,I-PGD-AT: Efficient Adversarial Training via Imitating Iterative PGD Attack ,"['Xiaosen Wang', 'Bhavya Kailkhura', 'Krishnaram Kenthapadi', 'Bo Li']","[""Single-step Adversarial Training"", ""Catastrophic Overfitting"", ""Adversarial Robustness"", ""Adversarial Example""]",We propose an efficient adversarial training approach I-PGD-AT by imitating PGD virtually to improve single-step adversarial training effectively.,,,,
TEtO5qiBYvE,2021,Reject,False,Continual Memory: Can We Reason After Long-Term Memorization?,"[""Zhu Zhang"", ""Chang Zhou"", ""Zhou Zhao"", ""Zhijie Lin"", ""Jingren Zhou"", ""Hongxia Yang""]","[""Memory Augmented Neural Networks"", ""Continual Memory"", ""Reasoning After Long-Term Memorization""]","In this paper, we propose the continual memory to explore this ability of reasoning after long-term memorization.",,,,
TGFO0DbD_pk,2021,Accept (Poster),False,Genetic Soft Updates for Policy Evolution in Deep Reinforcement Learning,"[""Enrico Marchesini"", ""Davide Corsi"", ""Alessandro Farinelli""]","[""Deep Reinforcement Learning"", ""Evolutionary Algorithms"", ""Formal Verification"", ""Machine Learning for Robotics""]",We present a novel mixed framework that combines the benefits of Evolutionary Algorithms and any DRL algorithms (including value-based ones); we support our claims on the beneficial policy improvement using recent formal verification tools.,,,,
TH7crDRRND,2022,Reject,False,Revisiting Locality-Sensitive Binary Codes from Random Fourier Features,"['Xiaoyun Li', 'Ping Li']",[],,,,,
THMafOyRVpE,2022,Reject,False,Fully Online Meta-Learning Without Task Boundaries,"['Jathushan Rajasegaran', 'Chelsea Finn', 'Sergey Levine']",[],,,,,
TIdIXIpzhoI,2022,Accept (Spotlight),False,Progressive Distillation for Fast Sampling of Diffusion Models,"['Tim Salimans', 'Jonathan Ho']","[""Diffusion Models"", ""Generative Models"", ""fast sampling""]",Diffusion models now need just 4 sampling steps to produce high quality samples.,2202.00512,cs.LG,2022-02-01 16:07:25+00:00,2022-02-01 16:07:25+00:00
TJSOfuZEd1B,2021,Reject,False,GeDi: Generative Discriminator Guided Sequence Generation,"[""Ben Krause"", ""Akhilesh Deepak Gotmare"", ""Bryan McCann"", ""Nitish Shirish Keskar"", ""Shafiq Joty"", ""richard socher"", ""Nazneen Rajani""]","[""Language modeling"", ""controllable generation"", ""decoding schemes"", ""auto-regressive models"", ""language modeling safety""]",We use smaller language models as generative discriminators to guide generation from larger language models towards desirable attributes. ,,,,
TJzkxFw-mGm,2021,Reject,False,Near-Optimal Regret Bounds for Model-Free RL in Non-Stationary Episodic MDPs,"[""Weichao Mao"", ""Kaiqing Zhang"", ""Ruihao Zhu"", ""David Simchi-Levi"", ""Tamer Basar""]","[""reinforcement learning"", ""non-stationary environment"", ""model-free approach"", ""regret analysis""]",We present a model-free reinforcement learning algorithm that achieves near-optimal dynamic regret in non-stationary episodic MDPs. ,,,,
TK_6nNb_C7q,2021,Accept (Poster),True,Hierarchical Autoregressive Modeling for Neural Video Compression,"[""Ruihan Yang"", ""Yibo Yang"", ""Joseph Marino"", ""Stephan Mandt""]","[""Compression"", ""Video Compression"", ""Generative Models"", ""Autoregressive Models""]",,2010.10258,eess.IV,2020-10-19 03:01:33+00:00,2021-05-04 16:15:53+00:00
TKrlyiqKWB,2022,Reject,False,Prototype Based Classification from Hierarchy to Fairness,"['Mycal Tucker', 'Julie Shah']","[""prototypes"", ""fairness"", ""hierarchy"", ""neural network"", ""encoding""]","A new neural network architecture with sets of prototypes allows us to represent and train concept relationships like fairness and hierarchy, all within one model.",,,,
TLnReGgZEdW,2022,Reject,True,Generalization in Deep RL for TSP Problems via Equivariance and Local Search,"['Wenbin Ouyang', 'Yisen Wang', 'Paul Weng', 'Shaochen Han']","[""Deep Reinforcemenet Learning"", ""Travelling salesman problem"", ""Curriculum Learning"", ""Equivariance"", ""Local Search""]",,2110.03595,cs.LG,2021-10-07 16:20:37+00:00,2021-10-07 16:20:37+00:00
TMUR2ovJfjE,2021,Reject,False,Co-complexity: An Extended Perspective on Generalization Error,"[""Rohan Ghosh"", ""Mehul Motani""]","[""Generalization"", ""Theoretical Machine Learning"", ""Convolutional Neural Networks""]","A novel characterization of generalization error bounds for classification is proposed, which takes into account the nature and constraints of ground-truth label generating functions.",,,,
TN-W4p7H2pK,2022,Reject,False,Conditional Generative Quantile Networks via Optimal Transport and Convex Potentials,"['Jesse Sun', 'Dihong Jiang', 'Yaoliang Yu']","[""Optimal Transport"", ""Generative Models"", ""Quantile Functions"", ""Time-Series Forecasting"", ""Image Generation""]",Novel method for conditional generative quantile modelling that leverages optimal transport theory to generalize the quantile function to the multivariate case.,,,,
TNBTpPO0QX,2022,Reject,False,Monotone deep Boltzmann machines,"['Zhili Feng', 'Ezra Winston', 'J Zico Kolter']","[""Deep Boltzmann machine"", ""mean-field inference"", ""deep equilibrium model""]",,,,,
TNkPBBYFkXg,2021,Accept (Poster),True,HeteroFL: Computation and Communication Efficient Federated Learning for Heterogeneous Clients,"[""Enmao Diao"", ""Jie Ding"", ""Vahid Tarokh""]","[""Federated Learning"", ""Internet of Things"", ""Heterogeneity""]","In this work, we propose a new federated learning framework named HeteroFL to train heterogeneous local models with varying computation complexities.",2010.01264,cs.LG,2020-10-03 02:55:33+00:00,2021-02-19 02:23:35+00:00
TNxKD3z_tPZ,2022,Reject,False,Persistent Homology Captures the Generalization of Neural Networks Without A Validation Set,"['Asier GutiÃ©rrez-FandiÃ±o', 'David PÃ©rez FernÃ¡ndez', 'Jordi Armengol-EstapÃ©', 'Marta Villegas']","[""Neural Networks"", ""Topological Data Analysis"", ""learning"", ""evolution"", ""Persistent Homology""]",We provide a method to monitor the generalization of Neural Networks without validation data.,,,,
TQ75Md-FqQp,2022,Reject,True,Efficient and Modular Implicit Differentiation,"['Mathieu Blondel', 'Quentin Berthet', 'marco cuturi', 'Roy Frostig', 'Stephan Hoyer', 'Felipe Llinares-LÃ³pez', 'Fabian Pedregosa', 'Jean-Philippe Vert']","[""implicit differentiation"", ""bilevel optimization"", ""autodiff"", ""jax""]","A unified, efficient and modular approach for implicit differentiation of optimization problems",2105.15183,cs.LG,2021-05-31 17:45:58+00:00,2021-10-07 08:41:40+00:00
TQt98Ya7UMP,2021,Accept (Poster),False,Balancing Constraints and Rewards with Meta-Gradient D4PG,"[""Dan A. Calian"", ""Daniel J Mankowitz"", ""Tom Zahavy"", ""Zhongwen Xu"", ""Junhyuk Oh"", ""Nir Levine"", ""Timothy Mann""]","[""reinforcement learning"", ""meta-gradients"", ""constraints""]",This paper uses meta-gradients to perform soft-constrained Reinforcement Learning (RL) optimization,,,,
TR-Nj6nFx42,2021,Accept (Poster),False,A PAC-Bayesian Approach to Generalization Bounds for Graph Neural Networks,"[""Renjie Liao"", ""Raquel Urtasun"", ""Richard Zemel""]","[""PAC Bayes"", ""Generalization Bounds"", ""Graph Neural Networks"", ""Graph Convolutional Neural Networks"", ""Message Passing GNNs""]",,2012.07690,cs.LG,2020-12-14 16:41:23+00:00,2020-12-14 16:41:23+00:00
TSRTzJnuEBS,2021,Accept (Poster),False,Anytime Sampling for Autoregressive Models via Ordered Autoencoding,"[""Yilun Xu"", ""Yang Song"", ""Sahaj Garg"", ""Linyuan Gong"", ""Rui Shu"", ""Aditya Grover"", ""Stefano Ermon""]",[],We propose a new family of autoregressive model that enables anytime sampling,2102.11495,cs.LG,2021-02-23 05:13:16+00:00,2021-02-23 05:13:16+00:00
TSrvUnWkjGR,2021,Reject,False,On the Inversion of Deep Generative Models,"[""Aviad Aberdam"", ""Dror Simon"", ""Michael Elad""]","[""Sparse Representation"", ""Inverse Problem"", ""Deep Generative Models"", ""Compressed Sensing""]",We derive theoretical conditions for the invertiblity of deep generative models and introduce a layerwise inversion algorithm with provable guarantees,,,,
TTLwOwNkOfx,2021,Reject,False,Learning Hyperbolic Representations for Unsupervised 3D Segmentation,"[""Joy Hsu"", ""Jeffrey Gu"", ""Gong Her Wu"", ""Wah Chiu"", ""Serena Yeung""]","[""unsupervised learning"", ""representation learning"", ""segmentation"", ""biocomputing""]","We introduce an approach for learning hyperbolic embeddings of 3D data that can model inherent hierarchy within the data, and can be used to achieve state-of-the-art performance for unsupervised 3D segmentation. ",,,,
TTUVg6vkNjK,2021,Accept (Poster),True,RODE: Learning Roles to Decompose Multi-Agent Tasks,"[""Tonghan Wang"", ""Tarun Gupta"", ""Anuj Mahajan"", ""Bei Peng"", ""Shimon Whiteson"", ""Chongjie Zhang""]","[""Multi-Agent Reinforcement Learning"", ""Role-Based Learning"", ""Hierarchical Multi-Agent Learning"", ""Multi-Agent Transfer Learning""]","We propose a scalable role-based multi-agent learning method which effectively discovers roles based on joint action space decomposition according to action effects, establishing a new state of the art on the StarCraft multi-agent benchmark.",2010.01523,cs.LG,2020-10-04 09:20:59+00:00,2020-10-04 09:20:59+00:00
TTnjervir3J,2022,Reject,False,DATA-DRIVEN EVALUATION  OF TRAINING ACTION SPACE FOR REINFORCEMENT LEARNING,"['Rajat Ghosh', 'Debojyoti Dutta', 'Aroosh Sohi', 'Akshay Khole']","[""Reinforcement Learning"", ""Action Selection"", ""Cost Optimization"", ""Shapely""]",A data-driven framework to optimize training action selection for reinforcement learning,,,,
TV9INIrmtWN,2021,Reject,False,Hard Attention Control By Mutual Information Maximization,"[""Himanshu Sahni"", ""Charles Lee Isbell""]","[""reinforcement learning"", ""attention"", ""partial observability"", ""mutual information"", ""information theory""]",How to control a hard attention window using information and solve RL tasks.,,,,
TVHS5Y4dNvM,2022,Reject,False,Patches Are All You Need?,"['Asher Trockman', 'J Zico Kolter']","[""computer vision"", ""vision transformer"", ""mixer"", ""patch embeddings"", ""convolution"", ""convolutional neural network""]",,,,,
TVbDOOr6hL,2021,Reject,False,Variational Auto-Encoder Architectures that Excel at Causal Inference,"[""Negar Hassanpour"", ""Russell Greiner""]","[""Causal Inference"", ""Generative Modelling"", ""Distributional Shift""]",A VAE-based generative approach for causal inference using data from observational studies.,2111.06486,cs.LG,2021-11-11 22:37:43+00:00,2021-11-11 22:37:43+00:00
TVjLza1t4hI,2021,Accept (Poster),True,Representation learning for improved interpretability and classification accuracy of clinical factors from EEG,"[""Garrett Honke"", ""Irina Higgins"", ""Nina Thigpen"", ""Vladimir Miskovic"", ""Katie Link"", ""Sunny Duan"", ""Pramod Gupta"", ""Julia Klawohn"", ""Greg Hajcak""]","[""EEG"", ""ERP"", ""electroencephalography"", ""depression"", ""representation learning"", ""disentanglement"", ""beta-VAE""]","We use disentangled representations of EEG signals to improve performance on clinical classification tasks, provide interpretable recommendations for post-hoc analysis and allow for extraction of ERPs from novel single EEG trajectories.",2010.15274,cs.LG,2020-10-28 23:21:36+00:00,2020-11-17 22:33:13+00:00
TVs3zZOOZ8t,2022,Reject,False,Continuous Deep Q-Learning in Optimal Control Problems: Normalized Advantage Functions Analysis,"['Anton Plaksin', 'Stepan Martyanov']","[""continuous reinforcement learning"", ""deep q-learning"", ""optimal control problems"", ""normalized advantage functions""]",We propose various modification of NAF algorithm for continuous reinforcement learning problems arising from optimal control problems,,,,
TW7d65uYu5M,2022,Accept (Poster),False,Towards Unknown-aware Learning with Virtual Outlier Synthesis,"['Xuefeng Du', 'Zhaoning Wang', 'Mu Cai', 'Yixuan Li']",[],,,,,
TWANKAJ1ZCr,2022,Reject,False,"Learn Together, Stop Apart: a Novel Approach to Ensemble Pruning","['Bulat Ibragimov', 'Gleb Gennadjevich Gusev']","[""ensemble"", ""boosting"", ""regularization"", ""clusterization""]",Adaptive early stopping for boosting models,,,,
TWDczblpqE,2021,Reject,False,Semi-Supervised Audio Representation Learning for Modeling Beehive Strengths,"[""Tony Zhang"", ""Szymon Zmyslony"", ""Sergei Nozdrenkov"", ""Matthew Smith"", ""Brandon Kingsley Hopkins""]","[""bee"", ""beehive"", ""audio"", ""sound"", ""computational ethology"", ""deep learning"", ""representation learning"", ""semi-supervised learning"", ""modeling"", ""population"", ""disease""]","We collected multi-modal observational beehive data, and used semi-supervised audio deep learning to model population and disease states.",,,,
TWTTKlwrUP0,2022,Reject,False,Generating High-Fidelity Privacy-Conscious Synthetic Patient Data for Causal Effect Estimation with Multiple Treatments,"['Jingpu Shi', 'Dong Wang', 'Gino Tesei', 'Beau Norgeot']","[""synthetic data"", ""causal inference"", ""EHR"", ""healthcare"", ""deep generative modeling"", ""treatment effects"", ""model validation"", ""observational patient data"", ""patient privacy""]","In this work, we produce a large-scale and realistic synthetic patient dataset with ground truth for treatment effects to validate causal inference models.",,,,
TXqemS7XEH,2022,Reject,True,M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining,"['Junyang Lin', 'An Yang', 'Jinze Bai', 'Chang Zhou', 'Le Jiang', 'Xianyan Jia', 'Ang Wang', 'Jie Zhang', 'Yong Li', 'Wei Lin', 'Jingren Zhou', 'Hongxia Yang']","[""Extreme-Scale Pretraining"", ""Language Modeling"", ""Natural Language Processing""]",This paper proposes a training strategy for extreme-scale models and demonstrates a practice of pretraining a 10-trillion-parameter model.,2110.03888,cs.LG,2021-10-08 04:24:51+00:00,2021-10-25 06:24:41+00:00
TXsjU8BaibT,2022,Accept (Poster),True,Trigger Hunting with a Topological Prior for Trojan Detection,"['Xiaoling Hu', 'Xiao Lin', 'Michael Cogswell', 'Yi Yao', 'Susmit Jha', 'Chao Chen']","[""Trojan detection"", ""diversity loss"", ""topological prior""]",,2110.08335,cs.CV,2021-10-15 19:47:00+00:00,2021-10-15 19:47:00+00:00
TYXs_y84xRj,2021,Accept (Poster),False,PolarNet: Learning to Optimize Polar Keypoints for Keypoint Based Object Detection,"[""Wu Xiongwei"", ""Doyen Sahoo"", ""Steven HOI""]","[""Object Detection"", ""Deep Learning""]",,,,,
TYw3-OlrRm-,2022,Accept (Poster),True,Network Augmentation for Tiny Deep Learning,"['Han Cai', 'Chuang Gan', 'Ji Lin', 'song han']","[""Tiny Deep Learning""]",a training method for tiny neural networks,2110.08890,cs.CV,2021-10-17 18:48:41+00:00,2021-10-17 18:48:41+00:00
TZeArecH2Nf,2022,Accept (Poster),False,Bridging Recommendation and Marketing via Recurrent Intensity Modeling,"['Yifei Ma', 'Ge Liu', 'Anoop Deoras']","[""Recommender systems"", ""marketing"", ""push notifications"", ""temporal point processes"", ""sequence models""]",We repurpose an item-recommender system to recommend users for item providers for the purpose of content promotion and diversity.,,,,
T_8wHvOkEi9,2022,Reject,False,Self-Organized Polynomial-time Coordination Graphs,"['Weijun Dong', 'Qianlan Yang', 'Zhizhou Ren', 'Jianhao Wang', 'Tonghan Wang', 'Chongjie Zhang']","[""Multi-Agent Reinforcement Learning"", ""Coordination Graphs"", ""Polynomial-time DCOP""]",A novel multi-agent graph-based method that guarantees the polynomial-time greedy policy execution with expressive function representation of a structured graph class.,,,,
T__V3uLix7V,2022,Accept (Poster),True,RegionViT: Regional-to-Local Attention for Vision Transformers,"['Chun-Fu Chen', 'Rameswar Panda', 'Quanfu Fan']","[""vision transformer"", ""image recognition"", ""multi-scale feature""]",A new architecture for vision transformer,2106.02689,cs.CV,2021-06-04 19:57:11+00:00,2021-12-16 22:16:46+00:00
T_p1vd88T87,2022,Reject,False,Neural Implicit Representations for Physical Parameter Inference from a Single Video,"['Florian Hofherr', 'Lukas Koestler', 'Florian Bernard', 'Daniel Cremers']","[""neural implicit representations"", ""physics learning"", ""video interpretation"", ""physical parameter estimation""]",A method combining neural implicit representations with a rich physical model to infer physical parameters from a single short video clip,,,,
T_p2GaXuGeA,2022,Reject,True,Local Calibration: Metrics and Recalibration ,"['Rachel Luo', 'Aadyot Bhatnagar', 'Yu Bai', 'Shengjia Zhao', 'Huan Wang', 'Caiming Xiong', 'Silvio Savarese', 'Stefano Ermon', 'Edward Schmerling', 'Marco Pavone']",[],,2102.10809,cs.LG,2021-02-22 07:22:12+00:00,2021-12-15 05:49:39+00:00
T_uSMSAlgoy,2022,Reject,False,On the Latent Holes ð§ of VAEs for Text Generation,"['Ruizhe Li', 'Xutan Peng', 'Chenghua Lin']","[""Latent Discontinuity"", ""Variational Auto-Encoder"", ""Natural Language Generation"", ""Generative Model""]",,,,,
TaUJl6Kt3rW,2021,Reject,False,SkillBERT: âSkillingâ the BERT to classify skills!,"[""Amber Nigam"", ""Shikha Tyagi"", ""Kuldeep Tyagi"", ""Arpan Saxena""]",[],Learning semantic information from the skill-information of both candidates and jobs that could make hiring an efficient and intuitive process,,,,
TaYhv-q1Xit,2021,Accept (Poster),False,Ringing ReLUs: Harmonic Distortion Analysis of Nonlinear Feedforward Networks,"[""Christian H.X. Ali Mehmeti-G\u00f6pel"", ""David Hartmann"", ""Michael Wand""]","[""deep learning theory"", ""loss landscape"", ""harmonic distortion analysis"", ""network trainability""]",Nonlinearities create high-frequency distortions that affect network trainability.,,,,
Te1aZ2myPIu,2021,Reject,False,Pretrain-to-Finetune Adversarial Training via Sample-wise Randomized Smoothing,"[""Lei Wang"", ""Runtian Zhai"", ""Di He"", ""Liwei Wang"", ""Li Jian""]","[""Adversarial Robustness"", ""Provable Adversarial Defense"", ""Sample-wise Randomized Smoothing.""]",Propose sample-wise randomized smoothing and achieve better accuracy-robustness trade-off.,,,,
Te5ytkqsnl,2022,Accept (Poster),False,Missingness Bias in Model Debugging,"['Saachi Jain', 'Hadi Salman', 'Eric Wong', 'Pengchuan Zhang', 'Vibhav Vineet', 'Sai Vemprala', 'Aleksander Madry']","[""model debugging"", ""vision transformers"", ""missingness""]","We investigate how current missingness approximations for model debugging can impose undesirable biases on the model predictions and hinder our ability to debug models, and we show how transformer-based architectures can side-step these issues.",,,,
TfhfZLQ2EJO,2022,Accept (Poster),False,SURF: Semi-supervised Reward Learning with Data Augmentation for Feedback-efficient Preference-based Reinforcement Learning,"['Jongjin Park', 'Younggyo Seo', 'Jinwoo Shin', 'Honglak Lee', 'Pieter Abbeel', 'Kimin Lee']","[""preference-based reinforcement learning"", ""human-in-the-loop reinforcement learning"", ""deep reinforcement learning"", ""semi-supervised learning""]","We present SURF, a semi-supervised reward learning algorithm with data augmentation for feedback-efficient preference-based RL.",,,,
TfscevJuPNY,2021,Reject,False,Deep $k$-NN Label Smoothing Improves Reproducibility of Neural Network Predictions,"[""Dara Bahri"", ""Heinrich Jiang""]","[""$k$-nearest neighbors"", ""neural networks"", ""label smoothing"", ""churn"", ""reproducibility"", ""stability"", ""robustness""]",Label smoothing by using Deep $k$-NN estimates improves the reproducibility of neural network training.,,,,
TfwF7pqwqdm,2022,Reject,False,On the exploitative behavior of adversarial training against adversarial attacks,"['Ali Rahmati', 'Seyed-Mohsen Moosavi-Dezfooli', 'Huaiyu Dai']",[],,,,,
TgSVWXw22FQ,2021,Accept (Poster),False,Improving Zero-Shot Voice Style Transfer via Disentangled Representation Learning,"[""Siyang Yuan"", ""Pengyu Cheng"", ""Ruiyi Zhang"", ""Weituo Hao"", ""Zhe Gan"", ""Lawrence Carin""]","[""Style Transfer"", ""Mutual Information"", ""Zero-shot Learning"", ""Disentanglement""]",An information-theoretic disentangled representation learning framework for zero-shot voice style transfer.,2103.09420,eess.AS,2021-03-17 03:21:32+00:00,2021-03-17 03:21:32+00:00
Ti2i204vZON,2022,Reject,False,Learning Representations for Pixel-based Control: What Matters and Why?,"['Manan Tomar', 'Utkarsh Aashu Mishra', 'Amy Zhang', 'Matthew E. Taylor']","[""Reinforcement Learning"", ""Representation Learning"", ""Pixel-based Control""]","We propose data-centric view to different representation learning methods in RL, also showing where popular methods fail and why.",,,,
Ti87Pv5Oc8,2021,Accept (Poster),False,Meta-Learning with Neural Tangent Kernels,"[""Yufan Zhou"", ""Zhenyi Wang"", ""Jiayi Xian"", ""Changyou Chen"", ""Jinhui Xu""]","[""meta-learning"", ""neural tangent kernel""]",First work to define meta learning in RKHS induced by Neural Tangent Kernel,,,,
TiGF63rxr8Q,2021,Reject,False,Efficient Reinforcement Learning in Resource Allocation Problems Through Permutation Invariant Multi-task Learning,"[""Desmond Cai"", ""Shiau Hong Lim"", ""Laura Wynter""]",[],"We identify a permutation invariance property of reinforcement learning problems involving sequential resource allocation, provide a theoretical performance bound and use it to define a method to increase sample efficiency for this class of problems.",2102.09361,cs.LG,2021-02-18 14:13:02+00:00,2021-02-18 14:13:02+00:00
TiXl51SCNw8,2021,Accept (Poster),False,BSQ: Exploring Bit-Level Sparsity for Mixed-Precision Neural Network Quantization,"[""Huanrui Yang"", ""Lin Duan"", ""Yiran Chen"", ""Hai Li""]","[""Mixed-precision quantization"", ""bit-level sparsity"", ""DNN compression""]",We propose bit-level sparsity inducing regularizer to induce mixed-percision quantization scheme in DNN with gradient-based training.,2102.10462,cs.LG,2021-02-20 22:37:41+00:00,2021-02-20 22:37:41+00:00
Tio_oO2ga3u,2021,Reject,False,Deep Ensemble Kernel Learning,"[""Devanshu Agrawal"", ""Jacob D Hinkle""]","[""kernel-learning"", ""gaussian-process"", ""Bayesian"", ""ensemble""]","We present a joint training method for neural network ensembles using deep kernel learning with a linear kernel, derive an efficient variational inference framework for it, and show that it is a universal kernel approximator.",,,,
TlPHO_duLv,2021,Reject,False,Towards Noise-resistant Object Detection with Noisy Annotations,"[""Junnan Li"", ""Caiming Xiong"", ""Steven Hoi""]","[""noisy annotation"", ""object detection"", ""label noise""]",We propose a noise-resistant training framework for learning object detectors from noisy annotations with entangled label noise and bounding box noise.,,,,
TlS3LBoDj3Z,2021,Reject,False,QTRAN++: Improved Value Transformation for Cooperative Multi-Agent Reinforcement Learning,"[""Kyunghwan Son"", ""Sungsoo Ahn"", ""Roben D. Delos Reyes"", ""Jinwoo Shin"", ""Yung Yi""]","[""multi-agent reinforcement learning""]",We propose a novel cooperative multi-agent reinforcement learning algorithm with state-of-the-art performance.,,,,
TmUfsLjI-1,2021,Reject,False,Which Model to Transfer? Finding the Needle in the Growing Haystack,"[""Cedric Renggli"", ""Andr\u00e9 Susano Pinto"", ""Luka Rimanic"", ""Joan Puigcerver"", ""Carlos Riquelme Ruiz"", ""Ce Zhang"", ""Mario Lucic""]",[],,,,,
TmkN9JmDJx1,2021,Reject,False,Thinking Like Transformers,"[""Gail Weiss"", ""Yoav Goldberg"", ""Eran Yahav""]","[""transformers"", ""interpretability""]","A proposed computational model for reasoning about transformers, in the form of a programming language, presented with example programs and revisiting of existing works.",2106.06981,cs.LG,2021-06-13 13:04:46+00:00,2021-07-19 11:22:34+00:00
To-R742x7se,2022,Accept (Poster),False,Learning Distributionally Robust Models at Scale via Composite Optimization,"['Farzin Haddadpour', 'Mohammad Mahdi Kamani', 'Mehrdad Mahdavi', 'amin karbasi']","[""Composite Optimization"", ""Distributionally Robust Optimization""]",,,,,
To4Wy2NEM2,2021,Reject,False,Adaptive Optimizers with Sparse Group Lasso,"[""Yun Yue"", ""Suo Tong"", ""Zhen Zhang"", ""Yongchao Liu"", ""Chunyang Wen"", ""Huanjun Bao"", ""Jinjie Gu"", ""Yixiang Mu""]","[""adaptive optimizers"", ""sparse group lasso"", ""DNN models"", ""online optimization""]","We develop a novel framework that adds the regularizers to a family of adaptive optimizers in deep learning, and create a new class of optimizers.",,,,
ToWi1RjuEr8,2021,Reject,False,Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning,"[""Xue Bin Peng"", ""Aviral Kumar"", ""Grace Zhang"", ""Sergey Levine""]","[""reinforcement learning"", ""policy search"", ""offline RL"", ""control""]","This work presents a simple off-policy reinforcement learning algorithm that uses supervised learning methods as subroutines, which can be also be readily applied to offline reinforcement learning.",,,,
Tp7kI90Htd,2021,Accept (Spotlight),False,Generalization in data-driven models of primary visual cortex,"[""Konstantin-Klemens Lurz"", ""Mohammad Bashiri"", ""Konstantin Willeke"", ""Akshay Jagadish"", ""Eric Wang"", ""Edgar Y. Walker"", ""Santiago A Cadena"", ""Taliah Muhammad"", ""Erick Cobos"", ""Andreas S. Tolias"", ""Alexander S Ecker"", ""Fabian H. Sinz""]","[""neuroscience"", ""cognitive science"", ""multitask learning"", ""transfer learning"", ""representation learning"", ""network architecture"", ""computational biology"", ""visual perception""]",We introduce a novel network architecture which sets a new state of the art at predicting neural responses to visual input and successfully learns generalizing features of mouse visual cortex (V1).,,,,
TpJMvo0_pu-,2022,Accept (Poster),False,Curriculum learning as a tool to uncover learning principles in the brain ,"['Daniel R. Kepple', 'Rainer Engelken', 'Kanaka Rajan']","[""curriculum learning"", ""neuroscience""]",We present a novel approach to use curricula to identify principles by which a system learns.,,,,
TqNsv1TuCX9,2022,Accept (Poster),False,"Axiomatic Explanations for Visual Search, Retrieval, and Similarity Learning","['Mark Hamilton', 'Scott Lundberg', 'Stephanie Fu', 'Lei Zhang', 'William T. Freeman']","[""Model Interpretability"", ""Shapley Values"", ""Search Engines"", ""Information Retrieval"", ""Visual Search"", ""Similarity Learning"", ""Metric Learning"", ""Black-box explanations""]","We show that cooperative game theory provides an axiomatic characterization of model interpretability for visual search, retrieval, and similarity learning architectures",,,,
TqQ0oOzJlai,2021,Reject,False,How Important is Importance Sampling for Deep Budgeted Training?,"[""Eric Arazo"", ""Diego Ortego"", ""Paul Albert"", ""Noel O'Connor"", ""Kevin McGuinness""]","[""Budgeted training"", ""importance sampling"", ""data augmentation"", ""deep learning""]",Explore the interactions between importance sampling and data augmentation for budgeted training ,,,,
Tq_H_EDK-wa,2021,Reject,False,Exploiting structured data for learning contagious diseases under incomplete testing,"[""Maggie Makar"", ""Lauren West"", ""David Hooper"", ""Eric Horvitz"", ""Erica Shenoy"", ""John Guttag""]","[""infectious diseases"", ""neural networks"", ""healthcare"", ""regularization"", ""structured data""]",We build models that leverage rich structured data to predict symptomatic and asymptomatic infections of contagious dieases,,,,
TrjbxzRcnf-,2022,Accept (Spotlight),False,Memorizing Transformers,"['Yuhuai Wu', 'Markus Norman Rabe', 'DeLesley Hutchins', 'Christian Szegedy']","[""Transformer"", ""architecture"", ""memorization.""]",We propose to use an external memory module to allow instant utilization of newly acquired knowledge.,,,,
TscS0R8QzfG,2022,Reject,False,PDAML: A Pseudo Domain Adaptation Paradigm for Subject-independent EEG-based Emotion Recognition,"['Yun Luo', 'Gengchen Wei', 'Bao-liang Lu']","[""aBCIs"", ""EEG-based emotion recognition"", ""domain adaptation"", ""domain generalization"", ""meta-learning"", ""adversarial learning""]",A pseudo domain adaptation method for subject-independent EEG-based Emotion Recognition ,,,,
Tt1s9Oi1kCS,2021,Reject,True,Continual Prototype Evolution: Learning Online from Non-Stationary Data Streams,"[""Matthias De Lange"", ""Tinne Tuytelaars""]","[""continual learning"", ""prototypical learning"", ""online learning"", ""incremental learning"", ""deep learning"", ""representation learning"", ""catastrophic forgetting"", ""concept drift""]","Continual Prototype Evolution (CoPE) establishes online adaptation of class-representative prototypes in non-stationary data streams, exploiting latent space representations in a novel loss to enhance the state-of-the-art in continual learning.",2009.00919,cs.CV,2020-09-02 09:39:26+00:00,2021-04-06 10:40:42+00:00
TtYSU29zgR,2021,Accept (Poster),False,Primal Wasserstein Imitation Learning,"[""Robert Dadashi"", ""Leonard Hussenot"", ""Matthieu Geist"", ""Olivier Pietquin""]","[""Reinforcement Learning"", ""Inverse Reinforcement Learning"", ""Imitation Learning"", ""Optimal Transport"", ""Wasserstein distance""]",A new Imitation Learning method based on optimal transport.,,,,
Tu6SpFYWTA,2022,Reject,False,Antonymy-Synonymy Discrimination through the Repelling Parasiamese Neural Network,"['Mathias Etcheverry', 'Dina Wonsever']","[""antitransitivity"", ""parasiamese network"", ""antonymy-synonymy discrimination""]",A state-of-the-art model for antonymy-synonymy discrimination based on repelling the siamese and parasiamese formulations of a same base neural network.,,,,
TuK6agbdt27,2021,Accept (Poster),False,Learning Associative Inference Using Fast Weight Memory,"[""Imanol Schlag"", ""Tsendsuren Munkhdalai"", ""J\u00fcrgen Schmidhuber""]","[""memory-augmented neural networks"", ""tensor product"", ""fast weights""]",We present a Recurrent Neural Network model which is augmented with an associative memory to generalise in a more systematically,2011.07831,cs.LG,2020-11-16 10:01:23+00:00,2021-02-23 17:00:19+00:00
TuR3pmKgERp,2022,Reject,False,Hyperspherical embedding for novel class classification,"['Rafael S. Pereira', 'alexis joly', 'Patrick Valduriez', 'FÃ¡bio Porto']","[""Metric Learning"", ""open set"", ""deep learning""]",An novel metric learning approach which is cheap to optimize and weights for novel classes can be analitically defined.,,,,
Tubzedlc4P,2022,Reject,False,A Statistical Manifold Framework for Point Cloud Data,"['Yonghyeon LEE', 'Seungyeon Kim', 'Jinwon Choi', 'Frank C. Park']","[""Riemannian Geometry"", ""Point Cloud"", ""Autoencoders""]","A new Riemannian geometric structure for the space of point cloud data, using the theory of statistical manifold and information geometry, with applications to point cloud autoencoders.",,,,
TvMrYbWpa7,2022,Reject,False,Instance-Adaptive Video Compression: Improving Neural Codecs by Training on the Test Set,"['Ties van Rozendaal', 'Johann Brehmer', 'Yunfan Zhang', 'Reza Pourreza', 'Taco Cohen']","[""Instance-Adaptive Video Compression: Improving Neural Codecs by Training on the Test Set""]",We improve neural video compression by finetuning a model on each sequence and compressing the model updates efficiently.,,,,
Twf5rUVeU-I,2021,Reject,False,Convergence Analysis of Homotopy-SGD for Non-Convex Optimization,"[""Matilde Gargiani"", ""Andrea Zanelli"", ""Moritz Diehl"", ""Quoc Tran-Dinh"", ""Frank Hutter""]","[""deep learning"", ""numerical optimization"", ""transfer learning""]","In this work, we present and study both theoretically and empirically a novel first-order stochastic algorithm based on a combination of homotopy methods and SGD, called Homotopy-Stochastic Gradient Descent (H-SGD).",,,,
TwkEGci1Y-,2021,Reject,False,On the Role of Pre-training for Meta Few-Shot Learning,"[""Chia-You Chen"", ""Hsuan-Tien Lin"", ""Gang Niu"", ""Masashi Sugiyama""]","[""Meta-Learning"", ""Episodic Training"", ""Pre-training"", ""Disentanglement""]",,,,,
Twm9LnWK-zt,2021,Reject,True,Searching towards Class-Aware Generators for Conditional Generative Adversarial Networks,"[""Peng Zhou"", ""Lingxi Xie"", ""XIAOPENG ZHANG"", ""Bingbing Ni"", ""Qi Tian""]","[""NAS"", ""cGAN""]",We implement a class-aware generator model through NAS.,2006.14208,cs.CV,2020-06-25 07:05:28+00:00,2021-04-06 02:07:12+00:00
TxIXgcP3yp-,2022,Reject,False,Decouple and Reconstruct: Mining Discriminative Features for Cross-domain Object Detection,"['Jiawei Wang', 'Konghuai Shen', 'Shao Ming', 'Jun Yin', 'Ming Liu']","[""domain adaptation"", ""object detection"", ""discriminative feature mining""]",,,,,
TySnJ-0RdKI,2022,Accept (Poster),False,Backdoor Defense via Decoupling the Training Process,"['Kunzhe Huang', 'Yiming Li', 'Baoyuan Wu', 'Zhan Qin', 'Kui Ren']","[""Backdoor Defense"", ""Backdoor Learning""]","We reveal that the hidden backdoors are embedded in the feature space mostly due to the end-to-end supervised training paradigm, based on which we propose a simple yet effective decoupling-based training method for backdoor defense. ",2202.03423,cs.CR,2022-02-05 03:34:01+00:00,2022-02-05 03:34:01+00:00
U-GB_gONqbo,2022,Reject,False,Scalable Hierarchical Embeddings of Complex Networks,"['Nikolaos Nakis', 'Abdulkadir CELIKKANAT', 'Sune Lehmann', 'Morten MÃ¸rup']","[""Graph Representation Learning"", ""Latent Space Model"", ""Complex Networks"", ""Scalable Network embeddings"", ""Link prediction"", ""Low dimension graph representations""]",A novel graph representation learning method relying on the Latent Space Model approach for large scale networks.,,,,
U-_89RnR8F,2022,Reject,True,Meaningfully Explaining Model Mistakes Using Conceptual Counterfactuals,"['Abubakar Abid', 'Mert Yuksekgonul', 'James Zou']","[""interpretability"", ""concept-based explanations"", ""counterfactual explanations""]",We propose conceptual counterfactual explanations to understand model mistakes using human-understandable concepts.,2106.12723,cs.LG,2021-06-24 01:49:55+00:00,2021-10-12 00:51:20+00:00
U0k7XNTiFEq,2022,Accept (Poster),False,Deep Learning without Shortcuts: Shaping the Kernel with Tailored Rectifiers,"['Guodong Zhang', 'Aleksandar Botev', 'James Martens']","[""Neural Network Training"", ""Kernel Approximation for Neural Networks"", ""Neural Network Initialization"", ""Generalization""]",,,,,
U1edbV4kNu_,2022,Reject,False,SWARM Parallelism: Training Large Models Can Be Surprisingly Communication-Efficient,"['Max Ryabinin', 'Tim Dettmers', 'Michael Diskin', 'Alexander Borzunov']","[""distributed training"", ""model-parallel"", ""model parallelism"", ""pipeline"", ""fault tolerance"", ""communication efficiency"", ""volunteer computing""]","We propose SWARM Parallelism â a model-parallel training algorithm designed for swarms of poorly connected, heterogeneous unreliable devices.",,,,
U4XLJhqwNF1,2021,Accept (Poster),False,CO2: Consistent Contrast for Unsupervised Visual Representation Learning,"[""Chen Wei"", ""Huiyu Wang"", ""Wei Shen"", ""Alan Yuille""]","[""unsupervised representation learning"", ""contrastive learning"", ""consistency regularization""]",Introduce a consistency regularization term into unsupervised contrastive learning framework.,,,,
U4uFaLyg7PV,2022,Accept (Poster),False,T-WaveNet: A Tree-Structured Wavelet Neural Network for Time Series Signal Analysis,"['Minhao LIU', 'Ailing Zeng', 'Qiuxia LAI', 'Ruiyuan Gao', 'Min Li', 'Jing Qin', 'Qiang Xu']",[],,,,,
U6Xpa5R-E1,2021,Reject,False,Neural Potts Model,"[""Tom Sercu"", ""Robert Verkuil"", ""Joshua Meier"", ""Brandon Amos"", ""Zeming Lin"", ""Caroline Chen"", ""Jason Liu"", ""Yann LeCun"", ""Alexander Rives""]","[""proteins"", ""potts model"", ""unsupervised learning"", ""amortized optimization"", ""structure prediction""]","We propose the Neural Potts Model objective, which enables a single feedforward model to learn the Potts Model energy landscape across many protein families.",,,,
U7-FJu0iE3t,2021,Reject,True,Succinct Explanations with Cascading Decision Trees,"[""JIALU ZHANG"", ""Mark Santolucito"", ""Ruzica Piskac""]","[""Decision Trees"", ""Explainability"", ""Interpretability""]",We introduce a novel technique for providing more succinct explanations in binary decision trees.,2010.06631,cs.LG,2020-10-13 18:48:39+00:00,2020-10-13 18:48:39+00:00
U850oxFSKmN,2021,Reject,True,Learning Continuous-Time Dynamics by Stochastic Differential Networks,"[""Yingru Liu"", ""Yucheng Xing"", ""Xuewen Yang"", ""Xin Wang"", ""Jing Shi"", ""Di Jin"", ""Zhaoyue Chen""]","[""Continuous-time Stochastic RNN"", ""Neural SDE""]",A continuous-time stochastic recurrent network with controlled neural stochastic differential equations.,2006.06145,cs.LG,2020-06-11 01:40:34+00:00,2021-04-29 14:32:21+00:00
U8pbd00cCWB,2022,Accept (Poster),False,Differentiable Gradient Sampling for Learning Implicit 3D Scene Reconstructions from a Single Image,"['Shizhan Zhu', 'Sayna Ebrahimi', 'Angjoo Kanazawa', 'Trevor Darrell']",[],,,,,
U9zTUXVdoIr,2022,Reject,False,GSmooth: Certified Robustness against Semantic Transformations via Generalized Randomized Smoothing,"['Hao Zhongkai', 'Chengyang Ying', 'Yinpeng Dong', 'Hang Su', 'Jun Zhu']","[""Randomized Smoothing"", ""Adversarial Robustness"", ""Semantic Transformations"", ""Machine Learning""]",We proposed generalized randomized smoothing (GSmooth) for certifying robustness against diverse semantic transformations.,,,,
UAAJMiVjTY_,2021,Reject,False,Abductive Knowledge Induction from Raw Data,"[""Wang-Zhou Dai"", ""Stephen Muggleton""]","[""Neural-Symbolic Model"", ""Inductive Logic Programming"", ""Abduction""]",We propose an approach combining abduction and induction to jointly learn neural models and recursive first-order logic programs with predicate invention.,,,,
UECzHrGio7i,2022,Reject,False,Robust Imitation Learning from Corrupted Demonstrations,"['Liu Liu', 'Ziyang Tang', 'Lanqing Li', 'Dijun Luo']","[""Robust Estimation"", ""Imitation Learning"", ""Reinforcement Learning""]",,2201.12594,cs.LG,2022-01-29 14:21:28+00:00,2022-01-29 14:21:28+00:00
UEtNMTl6yN,2021,Reject,False,Neural Pooling for Graph Neural Networks,"[""Sai Sree Harsha"", ""Deepak Mishra""]","[""graph neural networks"", ""graph pooling"", ""representation learning""]","A novel graph pooling method for graph neural networks, which can generate high quality graph representation.",,,,
UF5cHSBycOt,2022,Reject,True,Learning to Pool in Graph Neural Networks for Extrapolation,"['Jihoon Ko', 'Taehyung Kwon', 'Kijung Shin', 'Juho Lee']","[""Graph Neural Network"", ""Pooling"", ""Extrapolation""]",Proposed a learnable pooling function that enables graph neural networks to extrapolate well on various tasks.,2106.06210,cs.LG,2021-06-11 07:30:26+00:00,2021-10-07 02:31:15+00:00
UFGEelJkLu5,2021,Accept (Poster),False,MixKD: Towards Efficient Distillation of Large-scale Language Models,"[""Kevin J Liang"", ""Weituo Hao"", ""Dinghan Shen"", ""Yufan Zhou"", ""Weizhu Chen"", ""Changyou Chen"", ""Lawrence Carin""]","[""Natural Language Processing"", ""Representation Learning""]","We propose MixKD, a distillation framework leveraging mixup for large-scale language models.",,,,
UFJOP5w0kV,2021,Reject,False,BiGCN: A Bi-directional Low-Pass Filtering Graph Neural Network,"[""Zhixian Chen"", ""Tengfei Ma"", ""Zhihua Jin"", ""Yangqiu Song"", ""Yang Wang""]","[""Graph convolutional networks"", ""graph filtering"", ""Laplacian smooth"", ""ADMM""]","We propose BiGCN, which utilizes additional information from a latent feature graph and represents a graph neural network as a bi-directional low-pass filter.",2101.05519,cs.LG,2021-01-14 09:41:00+00:00,2021-01-14 09:41:00+00:00
UFWnZn2v0bV,2021,Reject,True,LAYER SPARSITY IN NEURAL NETWORKS,"[""Mohamed Hebiri"", ""Johannes Lederer""]",[],,2006.15604,cs.LG,2020-06-28 13:41:59+00:00,2020-06-28 13:41:59+00:00
UFYYol-bRq,2022,Reject,False,ANCER: Anisotropic Certification  via Sample-wise Volume Maximization,"['Francisco Eiras', 'Motasem Alfarra', 'Philip Torr', 'M. Pawan Kumar', 'Puneet K. Dokania', 'Bernard Ghanem', 'Adel Bibi']","[""randomized smoothing"", ""anisotropic certification"", ""deep neural network certification"", ""certified defenses""]","We generalize randomized smoothing to provide certificates for anisotropic regions, setting new state-of-the-art $\ell_1$ and $\ell_2$ certified accuracy on CIFAR-10 and ImageNet, while certifying larger regions.",,,,
UGINpaICVOt,2022,Reject,True,Neural networks with trainable matrix activation functions,"['Yuwen Li', 'Zhengqi Liu', 'Ludmil Zikatanov']","[""neural networks"", ""trainable activation function"", ""function approximation"", ""image classification""]","We propose novel, trainable matrix activation functions (TMAF) which are competitive and robust.",2109.09948,cs.LG,2021-09-21 04:11:26+00:00,2021-10-20 15:59:25+00:00
UH-cmocLJC,2021,Accept (Oral),False,How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks,"[""Keyulu Xu"", ""Mozhi Zhang"", ""Jingling Li"", ""Simon Shaolei Du"", ""Ken-Ichi Kawarabayashi"", ""Stefanie Jegelka""]","[""extrapolation"", ""deep learning"", ""out-of-distribution"", ""graph neural networks"", ""deep learning theory""]",We study how neural networks trained by gradient descent extrapolate.,,,,
UHGbeVORAAf,2021,Reject,False,Multi-Representation Ensemble in Few-Shot Learning,"[""Qing Chen"", ""Jian Zhang""]","[""Ensemble learning"", ""Few shot learning"", ""Multi-representaion""]",,,,,
UI4K-I2ypG,2022,Reject,False,A Survey on Evidential Deep Learning For Single-Pass Uncertainty Estimation,['Dennis Thomas Ulmer'],"[""uncertainty estimation"", ""prior networks"", ""posterior networks"", ""conjugate priors"", ""classification"", ""regression"", ""evidential deep learning"", ""dirichlet""]","Survey on Evidential Deep Learning methods, that, compared to popular alternatives, provide uncertainty estimation in a single forward pass and model and allow to easily quantify distributional uncertainty for out-of-distribution inputs as well.",,,,
UJ9_wmscwk,2022,Reject,True,Learning Graph Representations for Influence Maximization,"['George Panagopoulos', 'Nikolaos Tziortziotis', 'Fragkiskos D. Malliaros', 'Michalis Vazirgiannis']","[""influence maximization"", ""graph neural networks""]",,2108.04623,cs.LG,2021-08-10 12:08:15+00:00,2021-12-10 11:47:27+00:00
UJRFjuJDsIO,2021,Reject,False,Why Convolutional Networks Learn Oriented Bandpass Filters: Theory and Empirical Support,"[""Isma Hadji"", ""Richard Wildes""]",[],,,,,
ULQdiUTHe3y,2021,Accept (Poster),False,Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks,"[""Jan Schuchardt"", ""Aleksandar Bojchevski"", ""Johannes Klicpera"", ""Stephan G\u00fcnnemann""]","[""Robustness certificates"", ""Adversarial robustness"", ""Graph neural networks""]",We fuse multiple single-prediction certificates into a drastically stronger collective certificate leveraging the locality property of Graph Neural Networks.,,,,
ULfq0qR25dY,2022,Accept (Poster),True,Maximum n-times Coverage for Vaccine Design,"['Ge Liu', 'Alexander Dimitrakakis', 'Brandon Carter', 'David Gifford']","[""computational biology"", ""vaccine design"", ""COVID-19"", ""maximum n-times coverage"", ""combinatorial optimization"", ""integer linear programming""]","We introduce the maximum $n$-times coverage problem that selects $k$ overlays to maximize the summed coverage of weighted elements, where each element must be covered at least $n$ times, and show its importance for vaccine design.",2101.10902,q-bio.QM,2021-01-24 22:20:24+00:00,2021-06-15 15:07:02+00:00
UMfhoMtIaP5,2022,Accept (Poster),False,Provably Robust Adversarial Examples,"['Dimitar Iliev Dimitrov', 'Gagandeep Singh', 'Timon Gehr', 'Martin Vechev']","[""Adversarial attacks"", ""Robustness Certification"", ""Abstract Interpretation"", ""Deep Learning""]",We introduce the concept of provably robust adversarial examples $-$ connected input regions constructed from standard adversarial examples and guaranteed to be provably robust to a set of perturbations.,,,,
UOOmHiXetC,2021,Reject,False,Structure and randomness in planning and reinforcement learning,"[""Piotr Kozakowski"", ""Piotr Januszewski"", ""Konrad Czechowski"", ""\u0141ukasz Kuci\u0144ski"", ""Piotr Mi\u0142o\u015b""]","[""reinforcement learning"", ""uncertainty"", ""model-based"", ""MCTS""]",We present a novel planning algorithm based on modern version of MCTS (with neural-network heuristics).,,,,
UORhn0DGIT,2022,Reject,False,Heterogeneous Wasserstein Discrepancy for Incomparable Distributions,"['Mokhtar Z. Alaya', 'Gilles Gasso', 'Maxime Berar', 'Alain Rakotomamonjy']","[""Optimal transport"", ""Wasserstein distance"", ""Incomprable distributions"", ""Generative models""]","A novel optimal transport discrepancy, called heterogenous Wasserstein discrepancy, for comparing probability distributions lying in different spaces.",,,,
UOj0MV__Cr,2022,Reject,False,A Two-Stage Neural-Filter Pareto Front Extractor and the need for Benchmarking,"['Soumyajit Gupta', 'Gurpreet Singh', 'Matthew Lease']","[""Pareto Optimality"", ""Neural nets"", ""Pareto Filter"", ""Interpretability"", ""Benchmarking""]","A two-stage neural Pareto front extractor for non-convex, constrained multi objective problems. ",,,,
UQBEkRO0_-M,2022,Reject,False,Softmax Gradient Tampering: Decoupling the Backward Pass for Improved Fitting,"['Bishshoy Das', 'Milton Mondal', 'Brejesh Lall', 'Shiv Dutt Joshi', 'Sumantra Dutta Roy']","[""gradient tampering"", ""smoothing"", ""softmax"", ""prediction"", ""image classification"", ""neural networks""]",We smooth gradient flow in neural networks using Softmax Gradient Tampering method,,,,
UQQgMRq58O,2022,Reject,False,Understanding Generalized Label Smoothing when Learning with Noisy Labels,"['Jiaheng Wei', 'Hangyu Liu', 'Tongliang Liu', 'Gang Niu', 'Yang Liu']","[""Learning with noisy labels"", ""label smoothing"", ""model confidence""]","This paper provides new understanding for the effects of label smoothing when learning with noisy labels: in contrast to existing work, a negative smoothing rate can be preferred when the label noise rate is high.",,,,
UQz4_jo70Ci,2021,Reject,False,SiamCAN:Simple yet Effective Method to enhance Siamese Short-Term Tracking,"[""Yue Zhao"", ""Zhibin Yu""]","[""Siamese trackers"", ""cross-attention"", ""light structure"", ""anchor-free""]","We propose a  series of simple yet effective method for Siamese trackers to solve similar distractor, scale variation and background  clutters challenge.",,,,
US-TP-xnXI,2021,Accept (Spotlight),False,Structured Prediction as Translation between Augmented Natural Languages,"[""Giovanni Paolini"", ""Ben Athiwaratkun"", ""Jason Krone"", ""Jie Ma"", ""Alessandro Achille"", ""RISHITA ANUBHAI"", ""Cicero Nogueira dos Santos"", ""Bing Xiang"", ""Stefano Soatto""]","[""language models"", ""few-shot learning"", ""transfer learning"", ""structured prediction"", ""generative modeling"", ""sequence to sequence"", ""multi-task learning""]","We propose a unified text-to-text approach to handle a variety of structured prediction tasks in a single model, allowing seamless multi-task training and providing extra benefits on low-resource scenarios. ",2101.05779,cs.LG,2021-01-14 18:32:21+00:00,2021-01-28 22:08:48+00:00
US2rTP5nm_,2022,Accept (Spotlight),False,EntQA: Entity Linking as Question Answering,"['Wenzheng Zhang', 'Wenyue Hua', 'Karl Stratos']","[""Entity linking"", ""open-domain question answering"", ""dense retrieval"", ""reading comprehension"", ""information extraction"", ""natural language processing""]",We frame entity linking as inverse open-domain question answering and solve the dilemma of having to predict mentions before entities.,,,,
USC0-nvGPK,2022,Accept (Poster),False,Information Gain Propagation: a New Way to Graph Active Learning with Soft Labels,"['Wentao Zhang', 'Yexin Wang', 'Zhenbang You', 'Meng Cao', 'Ping Huang', 'Jiulong Shan', 'Zhi Yang', 'Bin CUI']","[""Active Learning"", ""Graph"", ""Information Gain""]",A new way to graph active learning with soft labels,,,,
USCNapootw,2021,Accept (Poster),False,Certify or Predict: Boosting Certified Robustness with Compositional Architectures,"[""Mark Niklas Mueller"", ""Mislav Balunovic"", ""Martin Vechev""]","[""Provable Robustness"", ""Network Architecture"", ""Robustness"", ""Adversarial Accuracy"", ""Certified Robustness""]","We propose a compositional network architecture boosting the certified robustness of an accurate state-of-the-art network, by combining it with a shallow, provable network using a certified, adaptive selection mechanism.",,,,
USIgIY6TNDe,2022,Accept (Poster),False,Graph-based Nearest Neighbor Search in Hyperbolic Spaces,"['Liudmila Prokhorenkova', 'Dmitry Baranchuk', 'Nikolay Bogachev', 'Yury Demidovich', 'Alexander Kolpakov']","[""similarity search"", ""nearest neighbor search"", ""hyperbolic space"", ""graph-based nearest neighbor search""]",Analyze graph-based NNS for hyperbolic spaces theoretically and empirically and show that this method outperforms other existing approaches.,,,,
UTTrevGchy,2022,Reject,False,Learning Diverse Options via InfoMax Termination Critic,"['Yuji Kanagawa', 'Tomoyuki Kaneko']","[""reinforcement learning"", ""hierachical reinforcement learning"", ""options"", ""life long reinforcement learning"", ""skill transfer""]",We aim to learn diverse options via MI maximization to get reusable behavioral blocks.,,,,
UTdxT0g6ZuC,2022,Reject,False,Automatic Forecasting via Meta-Learning,"['Mustafa Abdallah', 'Ryan Rossi', 'Kanak Mahadik', 'Sungchul Kim', 'Handong Zhao', 'Haoliang Wang', 'Saurabh Bagchi']","[""Forecasting Model Selection"", ""Time-series Forecasting"", ""Meta-features""]","We develop a method to determine the best model for time-series forecasting on an unseen dataset, without needing exhaustive evaluation of existing models on this dataset. ",,,,
UV9kN3S4uTZ,2021,Reject,True,Dynamic Relational Inference in Multi-Agent Trajectories,"[""Ruichao Xiao"", ""Manish Kumar Singh"", ""Rose Yu""]","[""deep generative model"", ""relational inference"", ""trajectory modeling"", ""multi-agent learning""]",A deep generative model for dynamically inferring hidden relations in multi-agent trajectories,2007.13524,cs.LG,2020-07-16 19:15:16+00:00,2020-10-08 21:54:29+00:00
UXwlFxVWks,2022,Reject,False,"Divergent representations of ethological visual inputs emerge from supervised, unsupervised, and reinforcement learning","['Grace W Lindsay', 'Josh Merel', 'Thomas D. Mrsic-Flogel', 'Maneesh Sahani']","[""reinforcement learning"", ""transfer learning"", ""representations"", ""dimensionality"", ""sparsity"", ""RSA""]",Reinforcement learning in an embodied agent creates sparser and higher dimensional representations than supervised or unsupervised methods.,,,,
UYDtmk6BMf5,2022,Reject,False,Decomposing Texture and Semantics for Out-of-distribution Detection,"['Jeong-Hyeon Moon', 'Namhyuk Ahn', 'Kyung-Ah Sohn']","[""Out-of-distribution detection"", ""Fourier analysis"", ""Normailzing flow model""]",We propose a novel OOD detection framework that decomposes the definition of the in-distribution as texture and semantics. ,,,,
UYneFzXSJWh,2022,Accept (Oral),False,Fine-Tuning Distorts Pretrained Features and Underperforms Out-of-Distribution,"['Ananya Kumar', 'Aditi Raghunathan', 'Robbie Matthew Jones', 'Tengyu Ma', 'Percy Liang']","[""fine-tuning theory"", ""transfer learning theory"", ""fine-tuning"", ""distribution shift"", ""implicit regularization""]","Fine-tuning does better than linear probing (training a linear classifier on pretrained features) in-distribution, but worse out-of-distribution (OOD)---we analyze why this happens and propose a way to get the benefits of both.",,,,
U_Jog0t3fAu,2022,Reject,False,Iterative Sketching and its Application to Federated Learning,"['Zhao Song', 'Zheng Yu', 'Lichen Zhang']","[""Federated learning"", ""optimization"", ""sketching"", ""differential privacy""]","Federated learning paradigm with iteratively applying sketching and de-sketching, with additive noises for privacy",,,,
U_mat0b9iv,2021,Accept (Poster),False,Multi-Prize Lottery Ticket Hypothesis: Finding Accurate Binary Neural Networks by Pruning A Randomly Weighted Network,"[""James Diffenderfer"", ""Bhavya Kailkhura""]","[""Binary Neural Networks"", ""Pruning"", ""Lottery Ticket Hypothesis""]",A new paradigm for learning compact yet accurate binary neural networks by pruning and quantizing randomly weighted full precision DNNs,2103.09377,cs.LG,2021-03-17 00:31:24+00:00,2021-03-17 00:31:24+00:00
Ua5yGJhfgAg,2021,Reject,False,Safe Reinforcement Learning with Natural Language Constraints,"[""Tsung-Yen Yang"", ""Michael Hu"", ""Yinlam Chow"", ""Peter Ramadge"", ""Karthik R Narasimhan""]","[""Safe reinforcement learning"", ""Language grounding""]","We tackle the problem of learning control policies for tasks when provided with constraints in natural language  (e.g., safety or budget constraints).",,,,
Ua6zuk0WRH,2021,Accept (Oral),False,Rethinking Attention with Performers,"[""Krzysztof Marcin Choromanski"", ""Valerii Likhosherstov"", ""David Dohan"", ""Xingyou Song"", ""Andreea Gane"", ""Tamas Sarlos"", ""Peter Hawkins"", ""Jared Quincy Davis"", ""Afroz Mohiuddin"", ""Lukasz Kaiser"", ""David Benjamin Belanger"", ""Lucy J Colwell"", ""Adrian Weller""]","[""performer"", ""transformer"", ""attention"", ""softmax"", ""approximation"", ""linear"", ""bert"", ""bidirectional"", ""unidirectional"", ""orthogonal"", ""random"", ""features"", ""FAVOR"", ""kernel"", ""generalized"", ""sparsity"", ""reformer"", ""linformer"", ""protein"", ""trembl"", ""uniprot""]","We introduce Performers, linear full-rank-attention Transformers via provable random feature approximation methods, without relying on sparsity or low-rankness.",,,,
Ub1BQTKiwqg,2022,Reject,False,Learning sparse DNNs with soft thresholding of weights during training,"['Antoine Vanderschueren', 'Christophe De Vleeschouwer']","[""pruning"", ""sparse"", ""DNN""]",,,,,
UcDUxjPYWSr,2022,Accept (Oral),False,Transform2Act: Learning a Transform-and-Control Policy for Efficient Agent Design,"['Ye Yuan', 'Yuda Song', 'Zhengyi Luo', 'Wen Sun', 'Kris M. Kitani']","[""Agent Design"", ""Morphology Optimization"", ""Reinforcement Learning""]",We learn a transform-and-control policy to both design and control an agent.,,,,
UcoXdfrORC,2021,Accept (Spotlight),False,Model-Based Visual Planning with Self-Supervised Functional Distances,"[""Stephen Tian"", ""Suraj Nair"", ""Frederik Ebert"", ""Sudeep Dasari"", ""Benjamin Eysenbach"", ""Chelsea Finn"", ""Sergey Levine""]","[""planning"", ""model learning"", ""distance learning"", ""reinforcement learning"", ""robotics""]","We combine model-based planning with dynamical distance learning to solve visual goal-reaching tasks, using random, unlabeled, experience.",2012.15373,cs.LG,2020-12-30 23:59:09+00:00,2020-12-30 23:59:09+00:00
Ucx3DQbC9GH,2022,Accept (Poster),False,What Makes Better Augmentation Strategies? Augment Difficult but Not too Different,"['Jaehyung Kim', 'Dongyeop Kang', 'Sungsoo Ahn', 'Jinwoo Shin']","[""NLP"", ""data augmentation"", ""learning augmentation policy"", ""text classification""]",Effective learning-based augmentation in NLP tasks by constructing difficult but not too different samples ,,,,
Ud3DSz72nYR,2021,Accept (Oral),False,Contrastive Explanations for Reinforcement Learning via Embedded Self Predictions,"[""Zhengxian Lin"", ""Kin-Ho Lam"", ""Alan Fern""]","[""Explainable AI"", ""Deep Reinforcement Learning""]",We introduced the embedded self-prediction (ESP) model for producing meaningful and sound contrastive explanations for RL agents.,,,,
UdxJ2fJx7N0,2022,Accept (Poster),False,Minimax Optimization with Smooth Algorithmic Adversaries,"['Tanner Fiez', 'Chi Jin', 'Praneeth Netrapalli', 'Lillian J Ratliff']","[""Minimax optimization"", ""two player zero sum games"", ""generative adversarial networks"", ""adversarial training""]","We propose a tractable formulation of minimax optimization by modeling the adversary's algorithm, and present new algorithms which are guaranteed to converge and find appropriate stationary points.",,,,
UeE41VsK1KJ,2022,Reject,True,Subjective Learning for Open-Ended Data,"['Tianren Zhang', 'Yizhou Jiang', 'Xin Su', 'Shangqi Guo', 'Feng Chen']","[""Open-ended data"", ""machine learning"", ""supervised learning"", ""data conflict""]",We formalize the problem of learning from open-ended data that implicitly comes from multiple domains and inherently requires multiple functions to fully capture its input-output relations.,2108.12113,cs.LG,2021-08-27 04:18:45+00:00,2021-10-13 03:26:14+00:00
UeRmyymo3kb,2022,Reject,False,GARNET: A Spectral Approach to Robust and Scalable Graph Neural Networks,"['Chenhui Deng', 'Xiuyu Li', 'Zhuo Feng', 'Zhiru Zhang']","[""graph neural networks"", ""adversarial robustness"", ""low-rank approximation"", ""spectral graph theory""]",A scalable spectral method for constructing GNN models robust to graph adversarial attacks on both homophilic and heterophilic graphs.,2201.12741,cs.LG,2022-01-30 06:32:44+00:00,2022-02-01 05:49:28+00:00
UfJn-cstSF,2021,Reject,False,Learned ISTA with Error-based Thresholding for Adaptive Sparse Coding,"[""Li Ziang"", ""Wu Kailun"", ""Yiwen Guo"", ""Changshui Zhang""]","[""Sparse coding"", ""Learned ISTA"", ""Convergence Analysis""]","We advocate an error-based thresholding (EBT) mechanism for LISTA, with superior performance and no extra learnable parameters.",,,,
Uf_WNt41tUA,2021,Reject,False,CorDial: Coarse-to-fine Abstractive Dialogue Summarization with Controllable Granularity,"[""Chien-Sheng Wu"", ""Linqing Liu"", ""Wenhao Liu"", ""Pontus Stenetorp"", ""Caiming Xiong""]","[""dialogue"", ""summarization"", ""controllable generation"", ""natural language processing""]","We propose CorDial, a state-of-the-art dialogue summarization model with coarse-to-fine generation and granularity controllability.",2105.14064,cs.CL,2021-05-28 19:05:36+00:00,2021-06-03 05:16:05+00:00
Ug-bgjgSlKV,2022,Accept (Poster),True,Finding an Unsupervised Image Segmenter in each of your Deep Generative Models,"['Luke Melas-Kyriazi', 'Christian Rupprecht', 'Iro Laina', 'Andrea Vedaldi']","[""unsupervised"", ""generative"", ""deep learning"", ""segmentation"", ""object segmentation""]",We propose an entirely unsupervised method for foreground-background image segmentation based on automatically finding a direction in the latent space of a deep generative model.,2105.08127,cs.CV,2021-05-17 19:34:24+00:00,2021-05-17 19:34:24+00:00
UgNQM-LcVpN,2022,Reject,False,A Modulation Layer to Increase Neural Network Robustness Against Data Quality Issues,"['Mohamed Abdelhack', 'Jiaming Zhang', 'Sandhya Tripathi', 'Bradley A Fritz', 'Michael Avidan', 'Yixin Chen', 'Christopher Ryan King']","[""missing data"", ""modulation"", ""DNN layer"", ""neuromodulation"", ""robustness""]",DNN layer that handles missing data,,,,
Uh0T_Q0pg7r,2021,Reject,False,Active Learning in CNNs via Expected Improvement Maximization,"[""Udai G. Nagpal"", ""David A. Knowles""]","[""active learning"", ""batch-mode active learning"", ""deep learning"", ""convolutional neural networks"", ""supervised learning"", ""regression"", ""classification"", ""MC dropout"", ""computer vision"", ""computational biology""]","An efficient batch-mode active learning algorithm for CNNs is proposed based on acquisition of points expected to maximize the modelâs improvement upon being queried, and is found to perform well across regression and classification tasks.",,,,
UiLl8yjh57,2021,Reject,False,Deep Reinforcement Learning For Wireless Scheduling with Multiclass Services,"[""Apostolos Avranas"", ""Marios Kountouris"", ""Philippe Ciblat""]",[],,2011.13634,cs.LG,2020-11-27 09:49:38+00:00,2021-02-09 21:07:06+00:00
UjynxfqnGWG,2022,Reject,False,Inductive Biases and Variable Creation in Self-Attention Mechanisms,"['Benjamin L. Edelman', 'Surbhi Goel', 'Sham M. Kakade', 'Cyril Zhang']","[""transformers"", ""attention""]",We analyze the inductive bias of self-attention modules through capacity analyses and give evidence that they learn sparse Boolean functions.,,,,
UkgBSwjxwe,2022,Reject,False,Neuro-Symbolic Forward Reasoning,"['Hikaru Shindo', 'Devendra Singh Dhami', 'Kristian Kersting']","[""neuro-symbolic AI"", ""differentiable logic"", ""object-centric reasoning""]",This paper proposes a new neuro-symbolic framework to perform visual reasoning using differentiable first-order logic.,,,,
UmrVpylRExB,2021,Reject,False,Dual-Tree Wavelet Packet CNNs for Image Classification,"[""Hubert Leterme"", ""K\u00e9vin Polisano"", ""Val\u00e9rie Perrier"", ""Karteek Alahari""]","[""convolutional neural networks"", ""wavelet packet transform"", ""dual-tree wavelet packet transform"", ""image classification"", ""deep learning"", ""image processing""]",We introduce the dual-tree wavelet packet transform into convolutional neural networks in order to constrain their behavior while keeping their predicting power.,,,,
UoAFJMzCNM,2021,Reject,False,Multi-agent Deep FBSDE Representation For Large Scale  Stochastic Differential Games,"[""Tianrong Chen"", ""Ziyi Wang"", ""Ioannis Exarchos"", ""Evangelos Theodorou""]","[""Multi-agent Deep FBSDE Representation For Large Scale  Stochastic Differential Games""]","In this paper, we propose a novel and scalable deep learning framework for solving multi-agent stochastic differential game using fictitious play.",,,,
UoNqm70g9HY,2022,Reject,False,Equivalent Distance Geometry Error for Molecular Conformation Comparison,"['Shuwen Yang', 'Tianyu Wen', 'Ziyao Li', 'Guojie Song']","[""molecule"", ""molecular conformation"", ""loss function""]","We propose Equivalent Distance Geometry Error (EDGE), a efficient and effective loss function to measure the discrepancy among molecular conformations, and it can be differentially optimized.",,,,
UoaQUQREMOs,2021,Accept (Poster),False,CT-Net: Channel Tensorization Network for Video Classification,"[""Kunchang Li"", ""Xianhang Li"", ""Yali Wang"", ""Jun Wang"", ""Yu Qiao""]","[""Video Classification"", ""3D Convolution"", ""Channel Tensorization""]","To achieve convolution efficiency and feature-interaction sufficiency,  we propose a Channel Tensorization Network (CT-Net), by treating the channel dimension of input feature as a multiplication of K sub-dimensions.",,,,
Uqu9yHvqlRf,2021,Reject,False,What Preserves the Emergence of Language?,"[""Ziluo Ding"", ""Tiejun Huang"", ""Zongqing Lu""]","[""emergence of language"", ""reinforcement learning""]",,,,,
UseMOjWENv,2022,Accept (Oral),False,MIDI-DDSP: Detailed Control of Musical Performance via Hierarchical Modeling,"['Yusong Wu', 'Ethan Manilow', 'Yi Deng', 'Rigel Swavely', 'Kyle Kastner', 'Tim Cooijmans', 'Aaron Courville', 'Cheng-Zhi Anna Huang', 'Jesse Engel']","[""Audio Synthesis"", ""Generative Model"", ""Hierarchical"", ""DDSP"", ""Music"", ""Audio"", ""Structured Models""]",Controlling musical performance and synthesis with a structured hierarchical generative model,2112.09312,cs.SD,2021-12-17 04:15:42+00:00,2021-12-17 04:15:42+00:00
Ut1vF_q_vC,2021,Accept (Spotlight),False,Are Neural Rankers still Outperformed by Gradient Boosted Decision Trees?,"[""Zhen Qin"", ""Le Yan"", ""Honglei Zhuang"", ""Yi Tay"", ""Rama Kumar Pasumarthi"", ""Xuanhui Wang"", ""Michael Bendersky"", ""Marc Najork""]","[""Learning to Rank"", ""benchmark"", ""neural network"", ""gradient boosted decision trees""]",,,,,
UtGtoS4CYU,2022,Accept (Poster),False,Measuring CLEVRness: Black-box Testing of Visual Reasoning Models,"['Spyridon Mouselinos', 'Henryk Michalewski', 'Mateusz Malinowski']","[""Visual Reasoning"", ""Visual Question Answering"", ""Black Box Testing"", ""Computer Vision""]",Black box testing of visual reasoning models as a two-player game.,,,,
Utc4Yd1RD_s,2021,Reject,False,Towards Defending Multiple Adversarial Perturbations via Gated Batch Normalization,"[""Aishan Liu"", ""Shiyu Tang"", ""Xianglong Liu"", ""Xinyun Chen"", ""Lei Huang"", ""Zhuozhuo Tu"", ""Dawn Song"", ""Dacheng Tao""]","[""adversarial examples"", ""multiple adversarial peturbation types"", ""adversarial robustness""]","To defend multiple adversarial perturbations, we propose the multi-domain hypothesis; guided by that, we propose Gated Batch Normalization (GBN), a novel building block for DNNs that improves robustness against multiple perturbation types.",2012.01654,cs.CV,2020-12-03 02:26:01+00:00,2020-12-03 02:26:01+00:00
Uu1Nw-eeTxJ,2021,Accept (Poster),False,On Learning Universal Representations Across Languages,"[""Xiangpeng Wei"", ""Rongxiang Weng"", ""Yue Hu"", ""Luxi Xing"", ""Heng Yu"", ""Weihua Luo""]","[""universal representation learning"", ""cross-lingual pretraining"", ""hierarchical contrastive learning""]","In this work, we extend pre-trained language models to learn universal representations among multiple languages, and show the effectiveness on cross-lingual understanding and generation.",,,,
UuchYL8wSZo,2021,Accept (Oral),True,Learning Generalizable Visual Representations via Interactive Gameplay,"[""Luca Weihs"", ""Aniruddha Kembhavi"", ""Kiana Ehsani"", ""Sarah M Pratt"", ""Winson Han"", ""Alvaro Herrasti"", ""Eric Kolve"", ""Dustin Schwenk"", ""Roozbeh Mottaghi"", ""Ali Farhadi""]","[""representation learning"", ""deep reinforcement learning"", ""computer vision""]",We show the representation learned through interaction and gameplay generalizes better compared to passive and static representation learning methods.,1912.08195,cs.CV,2019-12-17 18:57:50+00:00,2021-02-25 17:51:31+00:00
UvBPbpvHRj-,2021,Accept (Poster),False,Activation-level uncertainty in deep neural networks,"[""Pablo Morales-Alvarez"", ""Daniel Hern\u00e1ndez-Lobato"", ""Rafael Molina"", ""Jos\u00e9 Miguel Hern\u00e1ndez-Lobato""]","[""Gaussian Processes"", ""Uncertainty estimation"", ""Deep Gaussian Processes"", ""Bayesian Neural Networks""]","We use 1D Gaussian Processes to introduce activation-level uncertainty in neural networks, which overcomes known limitations of (functional) Bayesian neural nets and obtains better results than the related deep Gaussian Processes.",,,,
UvNXZgJAOAP,2022,Reject,False,Sharp Attention for Sequence to Sequence Learning,"['Pei Zhang', 'Hua Liu']","[""Attention mechanism"", ""sequence to sequence learning"", ""reinforcement learning""]",,,,,
UwGY2qjqoLD,2021,Accept (Poster),False,"Heating up decision boundaries: isocapacitory saturation, adversarial scenarios and generalization bounds","[""Bogdan Georgiev"", ""Lukas Franken"", ""Mayukh Mukherjee""]","[""Brownian motion"", ""deep learning theory"", ""decision boundary geometry"", ""curvature estimates"", ""generalization bounds"", ""adversarial attacks/defenses""]","We propose a heat-theoretic/Brownian motion approach to evaluate decision boundary geometry (curvature and density) with further applications in adversarial defenses, compression and generalization estimates.",2101.06061,cs.LG,2021-01-15 11:15:51+00:00,2021-01-15 11:15:51+00:00
UwOMufsTqCy,2021,Reject,False,RRL: A Scalable Classifier for Interpretable Rule-Based Representation Learning,"[""Zhuo Wang"", ""Wei Zhang"", ""Ning Liu"", ""Jianyong Wang""]","[""interpretable representation learning"", ""rule-based model"", ""scalability""]",We propose a scalable classifier and its effective training method for interpretable rule-based representation learning.,2109.15103,cs.LG,2021-09-30 13:07:42+00:00,2021-09-30 13:07:42+00:00
Ux5zdAir9-U,2021,Reject,True,GraphLog: A Benchmark for Measuring Logical Generalization in Graph Neural Networks,"[""Koustuv Sinha"", ""Shagun Sodhani"", ""Joelle Pineau"", ""William L. Hamilton""]","[""graph neural networks"", ""dataset"", ""benchmark"", ""logic""]",,2003.06560,cs.LG,2020-03-14 05:45:55+00:00,2020-03-14 05:45:55+00:00
UxBH9j8IE_H,2022,Reject,False,Revisiting the Lottery Ticket Hypothesis: A Ramanujan Graph Perspective,"['BITHIKA PAL', 'Arindam Biswas', 'Pabitra Mitra', 'BISWAJIT BASU']","[""Deep Neural Networks"", ""Network Pruning"", ""Ramanujan Graphs"", ""Eigenvalue bounds"", ""Spectral Gap""]",A Ramanujan graph perspective to explain the lottery ticket hypothesis,,,,
UxTR9Z2DW8R,2022,Reject,False,Reinforcement Learning State Estimation for High-Dimensional Nonlinear Systems,"['Saviz Mowlavi', 'Mouhacine Benosman', 'Saleh Nabi']","[""Reinforcement learning"", ""partial differential equation"", ""reduced order modeling"", ""closure models"", ""state prediction"", ""state estimation"", ""dynamic mode decomposition.""]",,,,,
Uxppuphg5ZL,2022,Reject,False,Constraint-based graph network simulator,"['Yulia Rubanova', 'Alvaro Sanchez-Gonzalez', 'Tobias Pfaff', 'Peter Battaglia']","[""Physical simulations"", ""graph neural network""]",We introduce a model for physical simulations that uses a graph network to represent a learned constraint.,,,,
Uy6YEI9-6v,2022,Reject,True,Object-Centric Neural Scene Rendering,"['Michelle Guo', 'Alireza Fathi', 'Jiajun Wu', 'Thomas Funkhouser']",[],"We propose to learn object-centric neural scattering functions (OSFs), a representation that models per-object light transport implicitly using a lighting- and view-dependent neural network",2012.08503,cs.CV,2020-12-15 18:55:02+00:00,2020-12-15 18:55:02+00:00
UyBxDoukIB,2022,Reject,True,Teamwork makes von Neumann work:Min-Max Optimization in Two-Team Zero-Sum Games,"['Fivos Kalogiannis', 'Ioannis Panageas', 'Emmanouil-Vasileios Vlatakis-Gkaragkounis']","[""Min-max Optimization"", ""Non-convex Optimization"", ""Multi-agent learning"", ""Multi-agent GANs"", ""Game Theory"", ""Duality Gap""]",First-order methods fail to converge to Mixed Nash Equilibria in Team Zero-Sum Games.,2111.04178,cs.GT,2021-11-07 21:15:35+00:00,2021-11-29 21:46:30+00:00
V09OhBn8iR,2022,Reject,False,Mitigating Dataset Bias Using Per-Sample Gradients From A Biased Classifier,"['Sumyeong Ahn', 'Se-Young Yun']","[""dataset bias"", ""debiasing"", ""representation bias""]",This study proposes a method of alleviating the feature bias problem based on the gradient of the biased classifier.,,,,
V0A5g83gdQ_,2022,Accept (Poster),False,Tuformer: Data-Driven Design of Expressive Transformer by Tucker Tensor Representation,"['Xiaoyu Liu', 'Jiahao Su', 'Furong Huang']","[""Attention Modules"", ""Transformers"", ""Data-driven Model Design"", ""Trainable Heads"", ""Expressive Power"", ""Tensor Methods.""]","We propose Tuformer, a data-driven design of theoretically guaranteed expressive Transformer with trainable heads, inspired by Tucker tensor representation.",,,,
V0LnyelKACB,2022,Reject,False,Accelerating HEP simulations with Neural Importance Sampling,"['Nicolas Deutschmann', 'Niklas GÃ¶tz']","[""Importance Sampling"", ""Normalizing Flows"", ""High-Energy-Physics""]",,,,,
V1N4GEWki_E,2021,Reject,False,Gradient Flow in Sparse Neural Networks and How Lottery Tickets Win,"[""Utku Evci"", ""Yani Ioannou"", ""Cem Keskin"", ""Yann Dauphin""]","[""sparse training"", ""sparsity"", ""pruning"", ""lottery ticket hypothesis"", ""lottery tickets"", ""sparse initialization"", ""initialization"", ""deep learning"", ""gradient flow""]","We show that sparse NNs have poor gradient flow and addressing this issue brings promising results, whereas lottery tickets seem to bypass this issue by effectively relearning the pruning solution.",,,,
V1ZHVxJ6dSS,2021,Accept (Poster),False,DC3: A learning method for optimization with hard constraints,"[""Priya L. Donti"", ""David Rolnick"", ""J Zico Kolter""]","[""approximate constrained optimization"", ""implicit differentiation"", ""optimal power flow"", ""surrogate models""]","We describe a method, DC3, for fast approximate solutions to optimization problems with hard constraints, which enforces feasibility via a differentiable procedure incorporated into a neural network.",,,,
V3C8p78sDa,2022,Accept (Spotlight),False,Exploring the Limits of Large Scale Pre-training,"['Samira Abnar', 'Mostafa Dehghani', 'Behnam Neyshabur', 'Hanie Sedghi']","[""Scaling law"", ""Pre-training"", ""Transfer learning"", ""Large Scale"", ""Vision Transformer"", ""Few Shot"", ""Empirical Investigation""]",We perform a systematic investigation of limits of  large scale pre-training for few-shot and transfer learning in image recognition with a wide range of downstream tasks.,,,,
V3o2w-jDeT5,2021,Reject,False,Multi-Source Unsupervised Hyperparameter Optimization,"[""Masahiro Nomura"", ""Yuta Saito""]","[""Hyperparameter Optimization""]",We enable efficient hyperparameter optimization for an unlabeled task by leveraging information on related tasks.,,,,
V4AVDoFtVM,2021,Reject,False,What About Taking Policy as Input of Value Function: Policy-extended Value Function Approximator,"[""Hongyao Tang"", ""Zhaopeng Meng"", ""Jianye HAO"", ""Chen Chen"", ""Daniel Graves"", ""Dong Li"", ""Wulong Liu"", ""Yaodong Yang""]","[""Reinforcement Learning"", ""Value Function Approximation"", ""Representation Learning""]","We propose Policy-extended Value Function Approximator (PeVFA) which allows values to generalize among policies. Moreover, we propose new approaches for representation learning of RL policy, from which we derive new DRL algorithms.",,,,
V5j-jdoDDP,2021,Accept (Poster),True,Scaling Symbolic Methods using Gradients for Neural Model Explanation,"[""Subham Sekhar Sahoo"", ""Subhashini Venugopalan"", ""Li Li"", ""Rishabh Singh"", ""Patrick Riley""]","[""Neural Model Explanation"", ""SMT Solvers"", ""Symbolic Methods""]",,2006.16322,cs.LG,2020-06-29 19:12:22+00:00,2021-05-05 14:13:39+00:00
V69LGwJ0lIN,2021,Accept (Poster),True,OPAL: Offline Primitive Discovery for Accelerating Offline Reinforcement Learning,"[""Anurag Ajay"", ""Aviral Kumar"", ""Pulkit Agrawal"", ""Sergey Levine"", ""Ofir Nachum""]","[""Offline Reinforcement Learning"", ""Primitive Discovery"", ""Unsupervised Learning""]","An effective way to leverage multimodal offline behavioral data is to extract a continuous space of primitives, and use it for downstream task learning.",2010.13611,cs.LG,2020-10-26 14:31:08+00:00,2021-05-04 19:20:46+00:00
V6BjBgku7Ro,2021,Accept (Poster),False,Planning from Pixels using Inverse Dynamics Models,"[""Keiran Paster"", ""Sheila A. McIlraith"", ""Jimmy Ba""]","[""model based reinforcement learning"", ""deep reinforcement learning"", ""multi-task learning"", ""deep learning"", ""goal-conditioned reinforcement learning""]",GLAMOR learns a latent world model by learning to predict action sequences conditioned on task completion.,2012.02419,cs.LG,2020-12-04 06:07:36+00:00,2020-12-04 06:07:36+00:00
V6WHleb2nV,2021,Reject,True,Data Transfer Approaches to Improve Seq-to-Seq Retrosynthesis,"[""Katsuhiko Ishiguro"", ""Kazuya Ujihara"", ""Ryohto Sawada"", ""Hirotaka Akita"", ""Masaaki Kotera""]","[""retrosynthesis"", ""data transfer"", ""transfer learninig"", ""pre-training"", ""fine-tuning"", ""self-training""]","Data Transfer improves the retrosynthesis models greatly, achieving new SotA with a simpler model. ",2010.00792,cs.LG,2020-10-02 05:27:51+00:00,2020-10-02 05:27:51+00:00
V70cjLuGACn,2022,Reject,False,Closed-loop Control for Online Continual Learning,"['Yaqian Zhang', 'Eibe Frank', 'Bernhard Pfahringer', 'Albert Bifet', 'Nick Jin Sean Lim', 'Alvin Jia']","[""Continual Learnig"", ""Reinforcement learning"", ""Class-incremental Continual Learning"", ""Online Learning""]",This paper proposes a closed-loop continual learning framework to apply reinforcement learning to improve replay-based continual learning methods.,,,,
V7eSbSAz-O8,2022,Reject,False,Benchmarking Machine Learning Robustness in Covid-19 Spike Sequence Classification,"['Sarwan Ali', 'Bikram Sahoo', 'Pin-Yu Chen', 'Murray Patterson']","[""COVID-19"", ""Sequence Classification"", ""Spike Sequences"", ""k-mers"", ""Deep Learning""]","In this paper, we test the robustness of deep learning models by creating adversarial spike sequences corresponding to different variants of coronavirus. We establish rigorous benchmarks for spike sequence classification.",,,,
V8YXffoDUSa,2021,Reject,False,Iterative convergent computation is not a useful inductive bias for ResNets,"[""Samuel Lippl"", ""Benjamin Peters"", ""Nikolaus Kriegeskorte""]","[""Residual neural networks"", ""Recurrent neural networks"", ""Computer vision""]",We present methods to make ResNets more iterative and convergent and demonstrate that this does not provide a useful inductive bias on the examined tasks.,,,,
V8jrrnwGbuc,2021,Accept (Poster),False,On the geometry of generalization and memorization in deep neural networks,"[""Cory Stephenson"", ""suchismita padhy"", ""Abhinav Ganesh"", ""Yue Hui"", ""Hanlin Tang"", ""SueYeon Chung""]","[""deep learning theory"", ""representation learning"", ""statistical physics methods"", ""double descent""]","We analyze the representational geometry of deep neural networks during generalization and memorization, and find the structure across layers of when and where memorization occurs, as well as drivers for this emerging structure.",2105.14602,cs.LG,2021-05-30 19:07:33+00:00,2021-05-30 19:07:33+00:00
VABfTTrrOv,2022,Reject,False,Conjugation Invariant Learning with Neural Networks,"['Aaron Yi Rui Low', 'Subhroshekhar Ghosh', 'Yong Sheng Soh']","[""Learning under group actions"", ""Neural networks"", ""Group representations"", ""Characters"", ""Class functions""]","We contribute a novel paradigm for learning conjugation invariant functions on groups of symmetries involving non-linear approximation by a small alphabet of characters, implemented via neural networks.",,,,
VAmkgdMztWs,2022,Reject,False,"Network robustness as a mathematical property: training, evaluation and attack","['Marco Casadio', 'Matthew L Daggitt', 'Ekaterina Komendantskaya', 'Wen Kokke', 'Robert Stewart']",[],,,,,
VBZJ_3tz-t,2022,Accept (Poster),False,The Unreasonable Effectiveness of Random Pruning: Return of the Most Naive Baseline for Sparse Training,"['Shiwei Liu', 'Tianlong Chen', 'Xiaohan Chen', 'Li Shen', 'Decebal Constantin Mocanu', 'Zhangyang Wang', 'Mykola Pechenizkiy']","[""random pruning"", ""sparse training"", ""static sparse training"", ""layer-wise sparsities"", ""dynamic sparse training""]","We revisit the most naive baseline, random pruning, in sparse training and highlight a perhaps counter-intuitive finding: random pruning can be quite powerful for the sparse training of modern neural networks.",2202.02643,cs.LG,2022-02-05 21:19:41+00:00,2022-02-05 21:19:41+00:00
VCAXR34cp59,2021,Reject,False,On Disentangled Representations Extracted from Pretrained GANs,"[""Valentin Khrulkov"", ""Leyla Mirvakhabova"", ""Ivan Oseledets"", ""Artem Babenko""]","[""Disentanglement"", ""representations"", ""GANs""]",We show that non-disentangled GANs can be used to obtain high quality disentangled representations.,,,,
VCD05OEn7r,2022,Reject,False,CAGE: Probing Causal Relationships in Deep Generative Models,"['Joey Bose', 'Ricardo Pio Monti', 'Aditya Grover']","[""Generative Models"", ""Causality""]","We perform causal discovery in the latent space of a pretrained deep latent variable generative model, exposing its implicit cause-effect relationships learned over two binary variables.",,,,
VD_ozqvBy4W,2021,Accept (Poster),True,CoCon: A Self-Supervised Approach for Controlled Text Generation,"[""Alvin Chan"", ""Yew-Soon Ong"", ""Bill Pung"", ""Aston Zhang"", ""Jie Fu""]","[""Language modeling"", ""text generation"", ""controlled generation"", ""self-supervised learning""]",We propose CoCon to control the content of text generation from LMs by conditioning on content inputs at an interleave layer.,2006.03535,cs.CL,2020-06-05 16:15:46+00:00,2021-03-09 14:23:42+00:00
VDdDvnwFoyM,2022,Reject,False,TimeVAE: A Variational Auto-Encoder for Multivariate Time Series Generation,"['Abhyuday Desai', 'Cynthia Freeman', 'Zuhui Wang', 'Ian Beaver']","[""VAE"", ""Variational Auto Encoder"", ""Time Series"", ""Data Generation"", ""GAN"", ""Generative Adversarial Network""]","We propose a novel architecture for synthetically generating time-series data with the use of Variational Auto-Encoders that allows for interpretability, ability to encode domain knowledge, and demonstrates reduced training times over GAN methods.",,,,
VErQxgyrbfn,2021,Accept (Poster),False,Convex Regularization behind Neural Reconstruction,"[""Arda Sahiner"", ""Morteza Mardani"", ""Batu Ozturkler"", ""Mert Pilanci"", ""John M. Pauly""]","[""neural networks"", ""image reconstruction"", ""denoising"", ""interpretability"", ""robustness"", ""neural reconstruction"", ""convex duality"", ""inverse problems"", ""sparsity"", ""convex optimization""]","This work proposes a finite-dimensional convex dual of a two-layer fully-convolutional ReLU network for denoising problems, and uses it for interpretation of neural network training and predictions.",,,,
VFBjuF8HEp,2022,Accept (Poster),False,Optimizing Few-Step Diffusion Samplers by Gradient Descent,"['Daniel Watson', 'William Chan', 'Jonathan Ho', 'Mohammad Norouzi']",[],"We propose a method to discover fast, high-fidelity samplers for diffusion probabilistic models.",2202.05830,cs.LG,2022-02-11 18:53:18+00:00,2022-02-11 18:53:18+00:00
VG3i3CfFN__,2021,Reject,False,PhraseTransformer: Self-Attention using Local Context for Semantic Parsing,"[""Phuong Minh Nguyen"", ""Vu Tran"", ""Minh Le Nguyen""]","[""phrase transformer"", ""logical form"", ""semantic parsing"", ""neural machine translation"", ""meaning representation""]",PhraseTransformer architecture is capable of a more detailed meaning representation by learning the phrase dependencies instead of single word dependencies in the sentence. ,,,,
VGnOJhd5Q1q,2022,Accept (Poster),False,Sparse Attention with Learning to Hash,"['Zhiqing Sun', 'Yiming Yang', 'Shinjae Yoo']","[""Sparse Attention"", ""Transformer"", ""Learning-to-Hash"", ""Natural Language Processing""]","We propose a new strategy for sparse attention, namely LHA (Learning-to-Hash Attention), which directly learns separate parameterized hash functions for queries and keys, respectively.",,,,
VINWzIM6_6,2022,Reject,False,Contrastive Representation Learning for 3D Protein Structures,"['Pedro Hermosilla', 'Timo Ropinski']","[""representation learning"", ""structural bioinformatics"", ""proteins""]",,,,,
VJnrYcnRc6,2021,Accept (Poster),False,Conditional Generative Modeling via Learning the Latent Space,"[""Sameera Ramasinghe"", ""Kanchana Nisal Ranasinghe"", ""Salman Khan"", ""Nick Barnes"", ""Stephen Gould""]","[""Multimodal Spaces"", ""Conditional Generation"", ""Generative Modeling""]",Conditional generation in continuous multimodal spaces by learning the behavior of latent variables.,,,,
VKtGrkUvCR,2022,Reject,False,Only tails matter: Average-Case Universality and Robustness in the Convex Regime,"['Leonardo Cunha', 'Gauthier Gidel', 'Fabian Pedregosa', 'Courtney Paquette', 'Damien Scieur']","[""optimization"", ""average-case"", ""first-order"", ""random matrix theory"", ""nesterov""]",We do a a complete analysis of average-case convergence in non-strongly convex problems,,,,
VLgmhQDVBV,2022,Accept (Poster),False,Implicit Bias of MSE Gradient Optimization in Underparameterized Neural Networks,"['Benjamin Bowman', 'Guido Montufar']","[""underparameterized regime"", ""spectral bias"", ""neural tangent kernel"", ""implicit bias"", ""implicit regularization"", ""gradient flow""]",Underparameterized networks optimizing MSE learn eigenfunctions of an NTK integral operator at rates corresponding to their eigenvalues.,2201.04738,stat.ML,2022-01-12 23:28:41+00:00,2022-01-12 23:28:41+00:00
VMAesov3dfU,2021,Reject,False,Gradient Descent Resists Compositionality,"[""Yuanpeng Li"", ""Liang Zhao"", ""Joel Hestness"", ""Kenneth Church"", ""Mohamed Elhoseiny""]","[""Compositionality""]",,,,,
VMtftZqMruq,2021,Reject,True,Towards Understanding Linear Value Decomposition in Cooperative Multi-Agent Q-Learning,"[""Jianhao Wang"", ""Zhizhou Ren"", ""Beining Han"", ""Jianing Ye"", ""Chongjie Zhang""]","[""Multi-agent reinforcement learning"", ""Fitted Q-iteration"", ""Value factorization"", ""Credit assignment""]",A theoretical and empirical understanding of cooperative multi-agent Q-learning with linear value decomposition.,2006.00587,cs.LG,2020-05-31 19:14:03+00:00,2021-10-31 06:21:48+00:00
VMuenFh7IpP,2022,Reject,False,What Doesn't Kill You Makes You Robust(er): How to Adversarially Train against Data Poisoning,"['Jonas Geiping', 'Liam H Fowl', 'Gowthami Somepalli', 'Micah Goldblum', 'Michael Moeller', 'Tom Goldstein']","[""Data Poisoning"", ""Poisoning Defenses"", ""Adversarial Training"", ""Empirical Defenses"", ""Robustness"", ""Security""]","Robust training is a good defense against targeted data poisoning, even for strong, adaptive attacks.",,,,
VNJUTmR-CaZ,2021,Reject,False,Learning to Solve Multi-Robot Task Allocation with a Covariant-Attention based Neural Architecture,"[""Steve Paul"", ""Payam Ghassemi"", ""Souma Chowdhury""]","[""Graph neural network"", ""Attention mechanism"", ""Reinforcement learning"", ""Multi-robotic task allocation""]",,,,,
VNXYZjGcsty,2022,Reject,False,Chaining Data - A Novel Paradigm in Artificial Intelligence Exemplified with NMF based Clustering,"['Norman J Mapes', 'Sumeet Dua']","[""NMF"", ""clustering"", ""linking data"", ""chaining data""]",We have fundamentally linked together tables of databases for clustering algorithms and expect this paradigm and those related to it to produce many new insights.,,,,
VNdFPD5wqjh,2022,Reject,False,Generalizable Person Re-identification Without Demographics,"['YiFan Zhang', 'Feng Li', 'Zhang Zhang', 'Liang Wang', 'Dacheng Tao', 'Tieniu Tan']","[""Generalizable Person Re-Identification"", ""Distributionally robust optimization""]","Introduce a novel setting in the Person ReID, that is learning invariant features without demographics. We reformulate the DRO problem as an importance sampling problem, termed Unit DRO, achieving superior performance compared to standard baselines.",,,,
VNqaB1g9393,2022,Accept (Poster),False,Decoupled Adaptation for Cross-Domain Object Detection,"['Junguang Jiang', 'Baixu Chen', 'Jianmin Wang', 'Mingsheng Long']","[""Object Detection"", ""Domain Adaptation"", ""Object Localization"", ""Deep Learning"", ""Transfer Learning""]","To deal with the challenges in cross-domain object detection, we propose D-adapt to decouple the adversarial adaptation and the training of the detector, and also decouple the category adaptation and the bounding box adaptation.",,,,
VPjw9KPWRSK,2022,Accept (Poster),True,Self-Supervised Inference in State-Space Models,"['David Ruhe', 'Patrick ForrÃ©']","[""self-supervision"", ""inference"", ""state-space model"", ""Kalman filter"", ""recurrent neural network""]",,2107.13349,cs.LG,2021-07-28 13:26:14+00:00,2022-01-25 09:09:37+00:00
VQhFC3Ki5C,2022,Reject,False,DEEP GRAPH TREE NETWORKS,"['Nan Wu', 'Chaofan Wang']","[""graph tree networks"", ""graph tree convolution networks"", ""graph tree attention networks"", ""GNNs""]","We propose a self-interpretive deep GNN architecture: Graph Tree Networks, and two models within this architecture: Graph Tree Convolution Networks and Graph Tree Attention Networks with demonstrated state-of-the-art performances.",,,,
VQyHD2R3Aq,2022,Reject,False,SPIDE: A Purely Spike-based Method for Training Feedback Spiking Neural Networks,"['Mingqing Xiao', 'Qingyan Meng', 'Zongpeng Zhang', 'Yisen Wang', 'Zhouchen Lin']","[""spiking neural network"", ""equilibrium state"", ""spike-based training method"", ""neuromorphic engineering""]",,,,,
VRgITLy0l2,2021,Reject,True,A priori guarantees of finite-time convergence for Deep Neural Networks,"[""Anushree Rankawat"", ""Mansi Rankawat"", ""Harshal B. Oza""]",[],,2009.07509,cs.LG,2020-09-16 07:13:16+00:00,2020-09-16 07:13:16+00:00
VSu5WrtLK3q,2022,Reject,False,A Geometric Perspective on Variational Autoencoders,"['ClÃ©ment Chadebec', 'Stephanie Allassonniere']","[""Variational Autoencoders"", ""Riemannian geometry""]","In this paper, we adopt a new approach of the VAE framework and propose to focus on the geometric aspects that a vanilla VAE is able to capture in its latent space.",,,,
VTNjxbFRKly,2022,Accept (Poster),False,Why Propagate Alone? Parallel Use of Labels and Features on Graphs,"['Yangkun Wang', 'Jiarui Jin', 'Weinan Zhang', 'Yang Yongyi', 'Jiuhai Chen', 'Quan Gan', 'Yong Yu', 'Zheng Zhang', 'Zengfeng Huang', 'David Wipf']",[],We analyze a powerful label trick from a theoretical perspective and reduce it to an interpretable form that inspires broader application scenarios.,,,,
VVdmjgu7pKM,2021,Accept (Poster),False,"Factorizing Declarative and Procedural Knowledge in Structured, Dynamical Environments","[""Anirudh Goyal"", ""Alex Lamb"", ""Phanideep Gampa"", ""Philippe Beaudoin"", ""Charles Blundell"", ""Sergey Levine"", ""Yoshua Bengio"", ""Michael Curtis Mozer""]","[""procedural knowledge"", ""declarative knowledge"", ""Systematicity""]",We explore separate factorization of procedural and declarative knowledge in modular recurrent neural networks.  ,,,,
VXqNHWh3LL,2022,Reject,False,Shift-tolerant Perceptual Similarity Metric,"['Abhijay Ghildyal', 'Feng Liu']","[""Computer Vision"", ""Perceptual Similarity Metric"", ""Image Quality Assessment"", ""Robustness"", ""Convolutional Neural Networks"", ""Anti-aliasing""]",We develop a perceptual similarity metric robust to an imperceptible 1-pixel shift in the image and consistent with human judgments on perceptual image similarity.,,,,
VYfotZsQV5S,2021,Reject,False,MISSO: Minimization by Incremental Stochastic Surrogate Optimization for Large Scale Nonconvex and Nonsmooth Problems,"[""Belhal Karimi"", ""Hoi To Wai"", ""Eric Moulines"", ""Ping Li""]","[""nonconvex"", ""optimization"", ""stochastic"", ""sampling"", ""MCMC"", ""majorization-minimization""]","We develop an incremental optimization method with stochastic surrogate functions for nonconvex and nonsmooth problems, providing asymptotic and non-asymptotic guarantees for it.",,,,
VZAgsLaP3or,2022,Reject,False,Practical No-box Adversarial Attacks with Training-free Hybrid Image Transformation,"['Qilong Zhang', 'Chaoning Zhang', 'Jingkuan Song', 'Lianli Gao']","[""no-box attack"", ""training-free"", ""hybrid image transformation""]",Rethinking the classification logic of DNNs and propose a no-box training-free attack,,,,
VZC5Lzyl0le,2022,Reject,False,Automated Mobile Attention KPConv Networks via A Wide & Deep Predictor,"['Tunhou Zhang', 'Mingyuan Ma', 'Feng Yan', 'Hai Li', 'Yiran Chen']","[""3D Point Cloud Classification and segmentation"", ""Neural Architecture Search""]","We introduce MAKPConv module to enable high-performing and efficient learning on 3D point cloud, and automate the design of MAKPConv networks using predictor-based NAS with enhanced neural architecture representations via Wide & Deep predictor.",,,,
VbCVU10R7K,2021,Reject,False,Offline policy selection under Uncertainty,"[""Mengjiao Yang"", ""Bo Dai"", ""Ofir Nachum"", ""George Tucker"", ""Dale Schuurmans""]","[""Off-policy selection"", ""reinforcement learning"", ""Bayesian inference""]","Formally defines offline policy selection in RL, and proposes Bayesian dual policy value posterior inference based on stochastic constraints, which enables a diverse set of policy selection algorithms under a wide range of evaluation metrics.",2012.06919,cs.LG,2020-12-12 23:09:21+00:00,2020-12-12 23:09:21+00:00
VbLH04pRA3,2021,Accept (Poster),False,ECONOMIC HYPERPARAMETER OPTIMIZATION WITH BLENDED SEARCH STRATEGY,"[""Chi Wang"", ""Qingyun Wu"", ""Silu Huang"", ""Amin Saied""]","[""HYPERPARAMETER OPTIMIZATION"", ""COST""]",A low-cost hyperparameter optimization solution by blending global and local search methods with cost-based prioritization,,,,
VcB4QkSfyO,2021,Accept (Poster),False,Estimating Lipschitz constants of monotone deep equilibrium models,"[""Chirag Pabbaraju"", ""Ezra Winston"", ""J Zico Kolter""]","[""deep equilibrium models"", ""Lipschitz constants""]","Monotone deep equilibrium models have Lipschitz constants which are simple to bound and small relative to those of standard DNNs, which suffer with depth.",,,,
Vd7lCMvtLqg,2021,Accept (Poster),True,Anchor & Transform: Learning Sparse Embeddings for Large Vocabularies,"[""Paul Pu Liang"", ""Manzil Zaheer"", ""Yuan Wang"", ""Amr Ahmed""]","[""sparse embeddings"", ""large vocabularies"", ""text classification"", ""language modeling"", ""recommendation systems""]",End-to-end learning of sparse embeddings for large vocabularies with a Bayesian nonparametric interpretation that results in up to 40x smaller embedding tables.,2003.08197,cs.LG,2020-03-18 13:07:51+00:00,2021-03-11 06:11:05+00:00
Ve0Wth3ptT_,2022,Accept (Poster),False,DEGREE: Decomposition Based Explanation for Graph Neural Networks,"['Qizhang Feng', 'Ninghao Liu', 'Fan Yang', 'Ruixiang Tang', 'Mengnan Du', 'Xia Hu']","[""XAI"", ""GNN""]",We propose a new decomposition based explanation for Graph Neural Networks.,,,,
Vfs_2RnOD0H,2021,Accept (Spotlight),True,Dynamic Tensor Rematerialization,"[""Marisa Kirisame"", ""Steven Lyubomirsky"", ""Altan Haan"", ""Jennifer Brennan"", ""Mike He"", ""Jared Roesch"", ""Tianqi Chen"", ""Zachary Tatlock""]","[""Rematerialization"", ""Memory-saving"", ""Runtime Systems"", ""Checkpointing""]","We present an online algorithm for rematerialization (recomputing intermediate activations during backpropagation instead of storing them), which enables training under low memory, finding that it is competitive with offline techniques.",2006.09616,cs.LG,2020-06-17 02:49:59+00:00,2021-03-18 06:20:23+00:00
VimqQq-i_Q,2022,Accept (Poster),False,What Do We Mean by Generalization in Federated Learning?,"['Honglin Yuan', 'Warren Richard Morningstar', 'Lin Ning', 'Karan Singhal']","[""Federated Learning"", ""generalization"", ""heterogeneity""]","We propose a framework for better measuring generalization and heterogeneity in federated learning, apply it for extensive empirical evaluation across six tasks, and make a series of recommendations for future FL works.",,,,
Vjki79-619-,2022,Accept (Poster),False,Proving the Lottery Ticket Hypothesis for Convolutional Neural Networks,"['Arthur da Cunha', 'Emanuele Natale', 'Laurent Viennot']","[""lottery ticket hypothesis"", ""convolutional neural network"", ""network pruning"", ""random subset sum"", ""random neural network""]",We prove the lottery ticket hypothesis for convolutional neural networks,,,,
VjoSeYLAiZN,2022,Reject,False,A NEW BACKBONE FOR HYPERSPECTRAL IMAGE RECONSTRUCTION,"['Jiamian Wang', 'Yulun Zhang', 'Xin Yuan', 'Yun Fu', 'ZHIQIANG TAO']",[],,,,,
VlRqY4sV9FO,2021,Reject,False,Human-interpretable model explainability on high-dimensional data,"[""Damien de Mijolla"", ""Christopher Frye"", ""Markus Kunesch"", ""John Mansir"", ""Ilya Feige""]",[],We adapt Shapley explainability to operate on semantic latent features in order to produce human-interpretable model explanations.,,,,
VnurXbqxr0B,2022,Reject,False,STRIC: Stacked Residuals of Interpretable Components for Time Series Anomaly Detection,"['Luca Zancato', 'Alessandro Achille', 'Giovanni Paolini', 'Alessandro Chiuso', 'Stefano Soatto']","[""Anomaly Detection"", ""Time-Series forecasting"", ""Residual Temporal Convolutional Networks""]",We propose a Deep Learning based anomaly detector model  which is specifically designed to be reliable (robust to overfitting) and provide interpretable time-series forecasting.,,,,
Vog_3GXsgmb,2022,Accept (Poster),False,Discovering Nonlinear PDEs from Scarce Data with Physics-encoded Learning,"['Chengping Rao', 'Pu Ren', 'Yang Liu', 'Hao Sun']","[""Data-driven equation discovery"", ""dynamical system modeling"", ""physics-encoded learning""]",This work seeks to solve the data-driven governing equation discovery problem with a novel physics-encoded learning framework.,2201.12354,cs.LG,2022-01-28 07:49:48+00:00,2022-01-28 07:49:48+00:00
Vq_QHT5kcAK,2022,Reject,True,Greedy Bayesian Posterior Approximation with Deep Ensembles,"['Aleksei Tiulpin', 'Matthew B. Blaschko']","[""Bayesian posterior"", ""deep ensembles"", ""submodular optimization""]",We propose a novel principled method to approximate function space posteriors for Deep Neural Networks.,2105.14275,cs.LG,2021-05-29 11:35:27+00:00,2021-10-10 09:57:14+00:00
VqzVhqxkjH1,2021,Accept (Spotlight),True,Deep Neural Network Fingerprinting by Conferrable Adversarial Examples,"[""Nils Lukas"", ""Yuxuan Zhang"", ""Florian Kerschbaum""]","[""Fingerprinting"", ""Adversarial Examples"", ""Transferability"", ""Conferrability""]","Proposal of a new property called ""conferrability"" for adversarial examples that we use as a method for DNN fingerprinting robust to model extraction.",1912.00888,cs.LG,2019-12-02 16:11:56+00:00,2021-01-20 18:19:24+00:00
VqzXzA9hjaX,2022,Accept (Poster),False,Optimizer Amalgamation,"['Tianshu Huang', 'Tianlong Chen', 'Sijia Liu', 'Shiyu Chang', 'Lisa Amini', 'Zhangyang Wang']","[""Learning to Optimize"", ""Knowledge Amalgamation"", ""Stability-Aware Training""]","We study a new problem named Optimizer Amalgamation: combining a pool of ""teacher"" optimizers into a single ""student"" optimizer which can have stronger problem-specific performance.",,,,
Vr_BTpw3wz,2022,Accept (Poster),False,Hindsight: Posterior-guided training of retrievers for improved open-ended generation,"['Ashwin Paranjape', 'Omar Khattab', 'Christopher Potts', 'Matei Zaharia', 'Christopher D Manning']","[""retrieval"", ""generation"", ""retrieval-augmented generation"", ""open-ended generation"", ""informative conversations"", ""free-form QA"", ""posterior distribution"", ""ELBo""]",We use a posterior-guide retriever to train a retrieval-augmented generation that performs well on open-ended one-to-many generation tasks.,,,,
VrjOFfcnSV8,2022,Accept (Poster),False,Entroformer: A Transformer-based Entropy Model for Learned Image Compression,"['Yichen Qian', 'Xiuyu Sun', 'Ming Lin', 'Zhiyu Tan', 'Rong Jin']","[""Image compression"", ""Entropy Model"", ""Global Dependencies""]","In this work, we propose a novel transformer-based entropy model, termed Entroformer, to capture long-range dependencies in probability distribution estimation effectively and efficiently.",,,,
Vs5NK44aP9P,2022,Accept (Poster),False,Encoding Weights of Irregular Sparsity for Fixed-to-Fixed Model Compression,"['Bae Seong Park', 'Se Jung Kwon', 'Daehwan Oh', 'Byeongwook Kim', 'Dongsoo Lee']","[""Sparse Neural Network"", ""Fixed-to-fixed data compression"", ""Unstructured Pruning""]",We propose a fixed-to-fixed weight compression scheme even when weights are pruned in a fine-grained manner.,,,,
Vt1lpp5Vebd,2022,Reject,True,Maximum Likelihood Estimation for Multimodal Learning with Missing Modality,"['Fei Ma', 'Xiangxiang Xu', 'Shao-Lun Huang', 'Lin Zhang']","[""multimodal learning"", ""missing modality"", ""maximum likelihood estimation""]",We propose an efficient approach based on maximum likelihood estimation to deal with missing modality.,2108.10513,cs.LG,2021-08-24 03:50:54+00:00,2021-08-24 03:50:54+00:00
Vvb-eicR8N,2022,Reject,False,Learning-Augmented Sketches for Hessians ,"['Yi Li', 'Honghao Lin', 'David Woodruff']","[""least squares"", ""convex optimization"", ""iterative Hessian sketch"", ""subspace embedding"", ""learning-augmented sketch""]",We design learned sketches in the context of second order methods and demonstrate their advantages empirically.,,,,
VwSHZgruNEc,2022,Reject,False,Safe Opponent-Exploitation Subgame Refinement,"['Mingyang Liu', 'Chengjie Wu', 'Qihan Liu', 'Yansen Jing', 'Jun Yang', 'Pingzhong Tang', 'Chongjie Zhang']",[],Use subgame refinement to safely exploit the weakness of opponent,,,,
VwU1lyi5nzb,2021,Reject,False,MULTI-SPAN QUESTION ANSWERING USING SPAN-IMAGE NETWORK,"[""Tarik Arici"", ""Hayreddin Ceker"", ""Ismail Baha Tutar""]","[""BERT"", ""deep learning"", ""multi-span answer"", ""question-answering"", ""SQuAD"", ""transformers""]",We build multi-span question-answering models to output the top-N likely answers to questions instead of one answer using SQuAD dataset and Amazon internal dataset.,,,,
Vx8l4vwv94,2022,Reject,False,JOINTLY LEARNING TOPIC SPECIFIC WORD AND DOCUMENT EMBEDDING,"['Farid Uddin', 'Zuping Zhang']","[""Language modeling \u00b7Document embedding \u00b7Natural language processing \u00b7Machine learning""]",The proposed model learns probabilistic topical word embeddings using a document vector as a global context where each word can be part of different underlying topics of the document instead of just a single paragraph vector.,,,,
Vy5WbmrVPaD,2022,Reject,False,Pretext Tasks Selection for Multitask Self-Supervised Speech Representation Learning,"['Salah Zaiem', 'Titouan Parcollet', 'Slim Essid', 'Abdelwahab HEBA']","[""Self-Supervised Learning"", ""Speech Processing"", ""Representation Learning""]",We explore conditional-independance based group pretext-task selection for self-supervised speech representation learning.,,,,
VyDYSMx1sFU,2021,Reject,False,End-to-End on-device Federated Learning: A case study,"[""Hongyi Zhang"", ""Jan Bosch"", ""Helena Holmstr\u00f6m Olsson""]","[""Federated Learning"", ""Machine Learning"", ""End-to-End Learning"", ""Artificial Intelligence""]",,,,,
VyENEGiEYAQ,2021,Reject,False,Cluster-Former: Clustering-based Sparse Transformer for Question Answering,"[""Shuohang Wang"", ""Luowei Zhou"", ""Zhe Gan"", ""Yen-Chun Chen"", ""Yuwei Fang"", ""Siqi Sun"", ""Yu Cheng"", ""Jingjing Liu""]","[""Transformer"", ""Question Answering""]",We propose Cluster-Former to encode long context in question answering tasks and achieve SOTA on several QA datasets.,,,,
VyZRObZ19kt,2022,Reject,False,Learned Index with Dynamic $\epsilon$,"['Daoyuan Chen', 'Wuchao Li', 'Yaliang Li', 'Bolin Ding', 'Kai Zeng', 'Defu Lian', 'Jingren Zhou']","[""Learned Index"", ""Dynamic $\\epsilon$""]","Based on the theoretically derived prediction error bounds, we propose a mathematically-grounded learned index framework with dynamic $\epsilon$, which is efficient, effective and pluggable to existing learned index methods.",,,,
Vzh1BFUCiIX,2022,Accept (Poster),False,ExT5: Towards Extreme Multi-Task Scaling for Transfer Learning,"['Vamsi Aribandi', 'Yi Tay', 'Tal Schuster', 'Jinfeng Rao', 'Huaixiu Steven Zheng', 'Sanket Vaibhav Mehta', 'Honglei Zhuang', 'Vinh Q. Tran', 'Dara Bahri', 'Jianmo Ni', 'Jai Gupta', 'Kai Hui', 'Sebastian Ruder', 'Donald Metzler']","[""Natural Language Processing"", ""Transfer Learning"", ""Multi-task Learning""]","Using a suite of 107 NLP tasks, we show that massively multi-task pre-training can improve downstream performance on NLP tasks, overcoming trends of negative transfer between tasks while fine-tuning.",2111.10952,cs.CL,2021-11-22 02:34:46+00:00,2022-01-29 07:41:54+00:00
W08IqLMlMer,2022,Reject,False,Offline Pre-trained Multi-Agent Decision Transformer,"['Linghui Meng', 'Muning Wen', 'Yaodong Yang', 'chenyang le', 'Xi yun Li', 'Haifeng Zhang', 'Ying Wen', 'Weinan Zhang', 'Jun Wang', 'Bo XU']","[""Multi-Agent Reinforcement Learning"", ""Offline Reinforcement Learning"", ""Machine Learning""]",This work introduces the Transformer into multi-agent reinforcement learning to promote offline learning and online generalisation on downstream tasks.,,,,
W0MKrbVOxtd,2021,Reject,False,One Vertex Attack on Graph Neural Networks-based Spatiotemporal Forecasting,"[""Fuqiang Liu"", ""Luis Miranda Moreno"", ""Lijun Sun""]","[""adversarial attack"", ""graph neural networks"", ""spatiotemporal forecasting""]",This paper proposes an adversarial attack method that is able to break GNN-based spatiotemporal forecasting models by poisoning only one vertex.,,,,
W1G1JZEIy5_,2021,Accept (Poster),True,MIROSTAT: A NEURAL TEXT DECODING ALGORITHM THAT DIRECTLY CONTROLS PERPLEXITY,"[""Sourya Basu"", ""Govardana Sachitanandam Ramachandran"", ""Nitish Shirish Keskar"", ""Lav R. Varshney""]","[""Neural text decoding"", ""sampling algorithms"", ""cross-entropy"", ""repetitions"", ""incoherence""]",We provide a new text decoding algorithm that directly controls perplexity and hence several important attributes of generated text.,2007.14966,cs.CL,2020-07-29 17:22:26+00:00,2021-01-14 21:36:02+00:00
W1uVrPNO8Bw,2021,Reject,False,Implicit Regularization of SGD via Thermophoresis,"[""Mingwei Wei"", ""David J. Schwab""]","[""SGD"", ""regularization"", ""generalization"", ""statistical mechanics"", ""thermophoresis""]",We generalize the theory of thermophoresis to show that there exists an effective entropic force from SGD.,,,,
W3-hiLnUYl,2022,Reject,False,On the Practicality of Deterministic Epistemic Uncertainty,"['Janis Postels', 'Mattia Segu', 'TAO SUN', 'Luca Sieber', 'Luc Van Gool', 'Fisher Yu', 'Federico Tombari']","[""uncertainty"", ""epistemic uncertainty"", ""uncertainty calibration""]",Investigating the calibration of deterministic epistemic uncertainty.,,,,
W3Wf_wKmqm9,2021,Accept (Poster),False,C-Learning: Horizon-Aware Cumulative Accessibility Estimation,"[""Panteha Naderian"", ""Gabriel Loaiza-Ganem"", ""Harry J. Braviner"", ""Anthony L. Caterini"", ""Jesse C. Cresswell"", ""Tong Li"", ""Animesh Garg""]","[""reinforcement learning"", ""goal reaching"", ""Q-learning""]","We introduce C-learning, a Q-learning inspired method to learn horizon-dependent policies for goal reaching.",2011.12363,cs.LG,2020-11-24 20:34:31+00:00,2021-01-26 03:05:38+00:00
W5PbuwQFzZx,2022,Reject,False,Locality-Based Mini Batching for Graph Neural Networks,"['Johannes Klicpera', 'Chendi Qian', 'Stephan GÃ¼nnemann']","[""GNN"", ""graph neural network"", ""graphs"", ""scalability"", ""batching"", ""local clustering""]","Locality-based mini batching enables large-scale training and inference for graph neural networks by precomputing fixed mini-batches based on node distances, graph partitioning, and local clustering.",,,,
W6BpshgRi0q,2022,Reject,False,Ask2Mask: Guided Data Selection for Masked Speech Modeling,"['Murali Karthick Baskar', 'Andrew Rosenberg', 'Bhuvana Ramabhadran', 'Yu Zhang', 'Pedro Moreno']","[""Masked speech modeling (MSM)"", ""Data selection"", ""Self-supervision"", ""ASR"", ""Speech recognition""]",Data selection Approach for masked speech model to focus on relevant samples to learn meaningful speech representations,,,,
W6lWkLqOss,2022,Reject,False,Class-Weighted Evaluation Metrics for Imbalanced Data Classification,"['Min Du', 'Nesime Tatbul', 'Brian Rivers', 'Akhilesh Kumar Gupta', 'Lucas Hu', 'Wei Wang', 'Ryan Marcus', 'Shengtian Zhou', 'Insup Lee', 'Justin Gottschlich']","[""Imbalanced data classification"", ""Evaluation metrics"", ""Log parsing"", ""Sentiment analysis"", ""URL classification""]","This paper presents a new evaluation framework for imbalanced data classification that can be used to train, evaluate, and rank models in a way that is sensitive to arbitrary skews in class cardinalities and importances.",,,,
W75l6XMzLq,2021,Reject,False,Hindsight Curriculum Generation Based Multi-Goal Experience Replay,"[""Xiaoyun Feng""]","[""reinforcement learning"", ""multi-goal task"", ""experience replay""]","In this paper, we propose a novel multi-goal experience replay method HCG to sample hindsight experiences, and generate a training curriculum to guide the learning.",,,,
W9G_ImpHlQd,2022,Accept (Spotlight),False,How to Robustify Black-Box ML Models? A Zeroth-Order Optimization Perspective,"['Yimeng Zhang', 'Yuguang Yao', 'Jinghan Jia', 'Jinfeng Yi', 'Mingyi Hong', 'Shiyu Chang', 'Sijia Liu']","[""Zeroth-Order Optimization"", ""Black-Box Defense"", ""Gradient-Free"", ""Adversarial Robustness"", ""Certified Defense""]","We propose a general notion of defensive operation that can be applied to black-box models, and design it through the lens of denoised smoothing (DS), a first-order (FO) certified defense technique.",,,,
WAISmwsqDsb,2021,Accept (Poster),False,DINO: A Conditional Energy-Based GAN for Domain Translation,"[""Konstantinos Vougioukas"", ""Stavros Petridis"", ""Maja Pantic""]","[""Generative Modelling"", ""Domain Translation"", ""Conditional GANs"", ""Energy-Based GANs""]",A framework  for domain translation which uses a novel mechanism for conditioning energy-based GANs.,,,,
WAid50QschI,2022,Accept (Oral),False,Sparse Communication via Mixed Distributions,"['AntÃ³nio Farinhas', 'Wilker Aziz', 'Vlad Niculae', 'Andre Martins']",[],,,,,
WC04PD6dFrP,2021,Reject,False,Deep Jump Q-Evaluation for Offline Policy Evaluation in Continuous Action Space,"[""Hengrui Cai"", ""Chengchun Shi"", ""Rui Song"", ""Wenbin Lu""]","[""Continuous action space"", ""Deep learning"", ""Multi-scale change point detection"", ""Off-policy evaluation""]","Develop deep jump Q-evaluation for off-policy evaluation in continuous action domains, by adaptively discretizing the action space.",,,,
WDBo7y8lcJm,2022,Reject,True,Teacher's pet: understanding and mitigating biases in distillation,"['Michal Lukasik', 'Srinadh Bhojanapalli', 'Aditya Krishna Menon', 'Sanjiv Kumar']",[],,2106.10494,cs.LG,2021-06-19 13:06:25+00:00,2021-07-08 14:28:34+00:00
WDVD4lUCTzU,2021,Reject,False,Universal Sentence Representations Learning with Conditional Masked Language Model,"[""Ziyi Yang"", ""Yinfei Yang"", ""Daniel M Cer"", ""Jax Law"", ""Eric Darve""]","[""multilingual representations"", ""sentence embeddings""]",,,,,
WE4qe9xlnQw,2022,Accept (Poster),False,A Program to Build E(N)-Equivariant Steerable CNNs ,"['Gabriele Cesa', 'Leon Lang', 'Maurice Weiler']","[""equivariance"", ""3D"", ""geometric deep learning"", ""isometries"", ""steerable CNN""]",We derive a general method to build G-steerable kernel spaces for equivariant steerable CNNs,,,,
WEHSlH5mOk,2021,Accept (Poster),False,Discrete Graph Structure Learning for Forecasting Multiple Time Series,"[""Chao Shang"", ""Jie Chen"", ""Jinbo Bi""]","[""Time series forecasting"", ""graph neural network"", ""graph structure learning""]",We propose a graph neural network approach that learns a graph structure to enhance the forecasting of multiple multivariate time series.,2101.06861,cs.LG,2021-01-18 03:36:33+00:00,2021-04-21 03:42:14+00:00
WGWzwdjm8mS,2021,Reject,False,Early Stopping by Gradient Disparity,"[""mahsa forouzesh"", ""Patrick Thiran""]","[""Supervised Representation Learning"", ""Deep Neural Networks"", ""Generalization"", ""Early Stopping""]","We propose an early stopping metric that does not require a validation set, which is particularly well suited for settings with limited and/or noisy labels.",2107.06665,cs.LG,2021-07-14 12:59:01+00:00,2021-07-14 12:59:01+00:00
WH6u2SvlLp4,2022,Accept (Poster),False,Learning Prototype-oriented Set Representations for Meta-Learning ,"['Dan dan Guo', 'Long Tian', 'Minghe Zhang', 'Mingyuan Zhou', 'Hongyuan Zha']","[""Summary Networks"", ""Distribution Matching"", ""Optimal Transport"", ""Few-shot Classification"", ""Meta Generative Models""]",A plug-and-play framework for set-structured input tasks,,,,
WHA8009laxu,2022,Accept (Poster),False,Unsupervised Federated Learning is Possible,"['Nan Lu', 'Zhao Wang', 'Xiaoxiao Li', 'Gang Niu', 'Qi Dou', 'Masashi Sugiyama']","[""unsupervised federated learning"", ""unlabeled data"", ""class prior shift""]",Federated learning: no label no cry,,,,
WIJVRV7jnTX,2022,Reject,False,Calibrated ensembles - a simple way to mitigate ID-OOD accuracy tradeoffs,"['Ananya Kumar', 'Aditi Raghunathan', 'Tengyu Ma', 'Percy Liang']","[""distribution shift"", ""calibration"", ""ensembles""]",Robustness interventions (such as removing spurious correlations) improve OOD accuracy at the cost of decreasing ID accuracy - we show that calibrated ensembles are a simple and effective solution to this problem,,,,
WJfIKDt8d2f,2021,Reject,False,Driving through the Lens: Improving Generalization of Learning-based Steering using Simulated Adversarial Examples,"[""Yu Shen"", ""Laura Yu Zheng"", ""Manli Shu"", ""Weizi Li"", ""Tom Goldstein"", ""Ming Lin""]","[""model robustness"", ""data augmentation"", ""adversarial training"", ""image quality"", ""autonomous driving"", ""benchmark""]","Analysis the relationship between image quality factors and ""learn to steer"" performance, and propose a method to improve the robustness on different scenarios, together with a benchmark.",,,,
WKWAkkXGpWN,2022,Reject,False,Efficient Training and Inference of Hypergraph Reasoning Networks,"['Guangxuan Xiao', 'Leslie Pack Kaelbling', 'Jiajun Wu', 'Jiayuan Mao']","[""Relational Rule Induction"", ""Hypergraph Network"", ""Efficient Learning""]",,,,,
WLEx3Jo4QaB,2022,Accept (Poster),True,Graph Condensation for Graph Neural Networks,"['Wei Jin', 'Lingxiao Zhao', 'Shichang Zhang', 'Yozen Liu', 'Jiliang Tang', 'Neil Shah']","[""data-efficient learning"", ""graph generation"", ""graph neural networks""]",We study the problem of graph condensation which targets at condensing a large-real graph into a small-synthetic one while maintaining the performances of GNNs.,2110.07580,cs.LG,2021-10-14 17:42:14+00:00,2021-10-14 17:42:14+00:00
WMUSP41HQWS,2021,Reject,False,DISE: Dynamic Integrator Selection to Minimize Forward Pass Time in Neural ODEs,"[""Soyoung Kang"", ""Ganghyeon Park"", ""Kwang-Sung Jun"", ""Noseong Park""]","[""Neural ODE"", ""DOPRI""]",To make Neural ODEs' forward-pass inference faster,,,,
WN2Sup7qLdw,2022,Reject,False,Multi-Resolution Continuous Normalizing Flows,"['Vikram Voleti', 'Chris Finlay', 'Adam M Oberman', 'Christopher Pal']","[""Normalizing flows"", ""generative models"", ""neural ode"", ""continuous normalizing flows"", ""computer vision""]","We formulate a multi-resolution variant of continuous normalizing flows, and are able to train generative models of images to comparable performance with a fraction of the parameters in significantly less time using only 1 GPU.",,,,
WNTscnQd1s,2022,Reject,False,Sparsistent Model Discovery,"['Georges Tod', 'Gert-Jan Both', 'Remy Kusters']","[""model discovery"", ""sparse regression"", ""sparsistency"", ""physics informed deep learning"", ""partial differential equations""]",Pushing the boundaries of machine discovery of partial differential equations.,,,,
WPI2vbkAl3Q,2022,Accept (Poster),True,Learning Curves for SGD on Structured Features,"['Blake Bordelon', 'Cengiz Pehlevan']","[""Stochastic Gradient Descent"", ""Generalization""]",The average case test risk for stochastic gradient descent on mean square error is computed in terms of feature covariance structure.,2106.02713,stat.ML,2021-06-04 20:48:20+00:00,2022-02-04 19:53:26+00:00
WPO0vDYLXem,2021,Reject,False,Hyperparameter Transfer Across Developer Adjustments,"[""Danny Stoll"", ""J\u00f6rg K.H. Franke"", ""Diane Wagner"", ""Simon Selg"", ""Frank Hutter""]","[""Meta Learning"", ""Hyperparameter Optimization"", ""Transfer Learning""]",A new research framework that introduces automated knowledge transfers across algorithm development steps to speedup hyperparameter optimization.,,,,
WQIdU90Gsu,2022,Reject,False,Compound Multi-branch Feature Fusion for Real Image Restoration,"['Chi-Mao Fan', 'Tsung-Jung Liu', 'Kuan-Hsien Liu']",[],,,,,
WQVouCWioh,2022,Reject,False,Design in the Dark: Learning Deep Generative Models for De Novo Protein Design,"['Lewis Moffat', 'Shaun M. Kandathil', 'David T. Jones']","[""generative models"", ""sequence design"", ""language models"", ""proteins""]",We show how unconditional language models can be used to design proteins by learning a latent understanding of protein structure from synthetic samples. ,,,,
WQc075jmBmf,2022,Accept (Poster),False,CodeTrek: Flexible Modeling of Code using an Extensible Relational Representation,"['Pardis Pashakhanloo', 'Aaditya Naik', 'Yuepeng Wang', 'Hanjun Dai', 'Petros Maniatis', 'Mayur Naik']","[""relational database"", ""code representation"", ""knowledge graph reasoning"", ""program understanding""]",We present a relational database representation and corresponding neural module for source code and show its potential on program understanding tasks,,,,
WRORN3GUCu,2022,Reject,True,VISCOS Flows: Variational Schur Conditional Sampling with Normalizing Flows,"['Vincent Moens', 'Aivar Sootla', 'Haitham Bou Ammar', 'Jun Wang']","[""Normalizing Flows"", ""Conditional Sampling"", ""Implicit Methods""]",,2107.02474,stat.ML,2021-07-06 08:40:03+00:00,2021-10-15 11:59:41+00:00
WTXMNULQ3Uu,2022,Reject,False,Generating Scenes with Latent Object Models,"['Patrick Emami', 'Pan He', 'Sanjay Ranka', 'Anand Rangarajan']","[""deep generative models"", ""slots"", ""scene generation"", ""object-centric"", ""VAEs""]",We introduce a latent variable model and variational inference algorithm for modeling the data-generating process for scenes with a latent scene-slot hierarchy.,,,,
WUNF4WVPvMy,2021,Reject,False,Acceleration in Hyperbolic and Spherical Spaces,"[""David Mart\u00ednez-Rubio""]","[""Riemannian optimization"", ""acceleration"", ""first-order methods""]",We find the first provable accelerated first-order algorithm for g-convex function minimization in manifolds other than the Euclidean space. ,2012.03618,math.OC,2020-12-07 12:09:30+00:00,2021-01-29 12:59:58+00:00
WUTkGqErZ9,2021,Reject,True,"Convolutional Neural Networks are not invariant to translation, but they can learn to be","[""Valerio Biscione"", ""Jeffrey Bowers""]","[""Invariance"", ""Convolutional Networks"", ""Translation"", ""Internal Representations""]","CNNs are not, as commonly assumed, 'architecturally' invariant to translation, but we investigated the conditions in which they can learn to be invariant to translation.",2011.11757,cs.CV,2020-11-06 09:39:27+00:00,2020-11-06 09:39:27+00:00
WVX0NNVBBkV,2022,Accept (Poster),False,Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness?,"['Vikash Sehwag', 'Saeed Mahloujifar', 'Tinashe Handina', 'Sihui Dai', 'Chong Xiang', 'Mung Chiang', 'Prateek Mittal']","[""adversarial robustness"", ""certified adversarial robustness"", ""adversarial attacks"", ""generative models"", ""proxy distribution""]",We leverage proxy distributions to significantly improve the robustness of deep neural network. ,,,,
WW8VEE7gjx,2021,Reject,True,Dimension reduction as an optimization problem over a set of generalized functions,"[""Rustem Takhanov""]","[""Unsupervised dimension reduction"", ""sufficient dimension reduction"", ""alternating scheme"", ""Fourier transform"", ""maximum mean discrepancy"", ""Wasserstein distance"", ""positive definite functions"", ""Bochner\u2019s theorem""]",We reformulate unsupervised dimension reduction problem and sufficient dimension reduction problem in the language of tempered distributions and present a new optimization method.,1903.05083,math.ST,2019-03-12 14:25:18+00:00,2019-03-12 14:25:18+00:00
WXwg_9eRQ0T,2022,Reject,False,MergeBERT: Program Merge Conflict Resolution via Neural Transformers,"['Alexey Svyatkovskiy', 'Todd Mytkowicz', 'Negar Ghorbani', 'Sarah Fakhoury', 'Elizabeth A Dinella', 'Christian Bird', 'Neel Sundaresan', 'Shuvendu Lahiri']","[""Software evolution"", ""program merge"", ""ml4code""]",Program merge conflict resolution model based on BERT finetuned for sequence classification task.,,,,
WXy4C-RjET,2022,Reject,False,Logit Attenuating Weight Normalization,"['Aman Gupta', 'Rohan Ramanath', 'Jun Shi', 'Anika Ramachandran', 'SIROU ZHU', 'Mingzhou Zhou', 'Sathiya Keerthi']","[""deep learning"", ""gradient methods"", ""stochastic optimization"", ""generalization gap"", ""imagenet"", ""adam"", ""large batch training""]",An optimizer for deep learning called Logit Attenuating Weight Normalization (LAWN) for superior generalization performance and scaling to large batches,,,,
WYDzDksK5b,2022,Reject,False,DiBB: Distributing Black-Box Optimization,"['Giuseppe Cuccu', 'Luca Sven Rolshoven', 'Fabien Vorpe', 'Philippe Cudre-Mauroux', 'Tobias Glasmachers']","[""Black Box Optimization"", ""Distributed Computing"", ""Evolutionary Computation""]","DiBB creates partially-separable versions of any BBO algorithm, and provides a distributed implementation for it, allowing scaling *constantly* to arbitrarily high dimensions based on the number of available machines.",,,,
WZ3yjh8coDg,2022,Accept (Poster),False,An Unconstrained Layer-Peeled Perspective on Neural Collapse,"['Wenlong Ji', 'Yiping Lu', 'Yiliang Zhang', 'Zhun Deng', 'Weijie J Su']","[""neural collapse"", ""uncostrained model"", ""implicit regularization""]",We investigate how the gradient flow converges to a neural collapse solution in an unconstrained model.,,,,
WZR7ckBkzPY,2022,Reject,False,Variational Wasserstein gradient flow,"['Jiaojiao Fan', 'Amirhossein Taghvaei', 'Yongxin Chen']","[""Wasserstein gradient flow"", ""JKO"", ""f-divergence""]",,,,,
WZeI0Vro15y,2022,Reject,False,Generative Posterior Networks for Approximately Bayesian Epistemic Uncertainty Estimation,"['Melrose Roderick', 'Felix Berkenkamp', 'Fatemeh Sheikholeslami', 'J Zico Kolter']","[""Uncertainty"", ""Bayesian"", ""Neural Networks"", ""Generative Models""]","We propose a new method, Generative Posterior Networks (GPNs), a generative model that, given a prior distribution over functions, approximates the posterior distribution directly by regularizing the network towards samples from the prior.",,,,
WZnVnlFBKFj,2021,Reject,False,Federated Learning With Quantized Global Model Updates,"[""Mohammad Mohammadi Amiri"", ""Deniz Gunduz"", ""Sanjeev Kulkarni"", ""H. Vincent Poor""]","[""Federated learning"", ""lossy broadcasting""]",We study federated learning where the global model update with significantly less variability/variance compared to the global model itself is quantized and broadcast by the parameter server to the devices for local training.,,,,
WcZUevpX3H3,2022,Reject,False,Personalized Neural Architecture Search for Federated Learning,"['Minh Hoang', 'Carl Kingsford']","[""Personalized Learning"", ""Federated Learning""]",A novel personalized neural architecture search algorithm for Federated Learning scenario with multiple heterogeneous tasks,,,,
WdOCkf4aCM,2021,Reject,False,CDT: Cascading Decision Trees for Explainable Reinforcement Learning,"[""Zihan Ding"", ""Pablo Hernandez-Leal"", ""Gavin Weiguang Ding"", ""Changjian Li"", ""Ruitong Huang""]","[""Explainable Reinforcement Learning"", ""Decision Tree"", ""Matrix Factorization""]",A new method for  explainable reinforcement learning based on differentiable decision trees with representation learning. ,2011.07553,cs.LG,2020-11-15 15:25:56+00:00,2021-03-30 10:40:38+00:00
WesiCoRVQ15,2021,Accept (Poster),True,When Optimizing  $f$-Divergence is Robust with Label Noise,"[""Jiaheng Wei"", ""Yang Liu""]","[""$f-$divergence"", ""robustness"", ""learning with noisy labels""]", We show when maximizing a properly defined $f$-divergence measure with respect to a classifier's predictions and the supervised labels is robust with label noise. ,2011.03687,cs.LG,2020-11-07 04:31:33+00:00,2021-08-18 20:49:13+00:00
WfvgGBcgbE7,2022,Accept (Poster),True,Model Zoo: A Growing Brain That Learns Continually,"['Rahul Ramesh', 'Pratik Chaudhari']","[""Continual Learning"", ""Learning Theory""]","Continual learning methods can benefit by splitting the capacity of the learner and we leverage this in our method Model Zoo, which demonstrates large gains in accuracy on a variety of continual learning benchmarks.",2106.03027,cs.LG,2021-06-06 04:25:09+00:00,2021-12-08 21:48:21+00:00
Wga_hrCa3P3,2021,Accept (Poster),False,Contrastive  Learning  with Adversarial Perturbations for Conditional Text Generation,"[""Seanie Lee"", ""Dong Bok Lee"", ""Sung Ju Hwang""]","[""conditional text generation"", ""contrastive learning""]",We propose a contrastive learning with adversarial perturbation to tackle the exposure bias problem.,2012.07280,cs.CL,2020-12-14 06:20:27+00:00,2021-03-10 13:27:34+00:00
Whq-nTgCbNR,2021,Reject,False,Anomaly detection in dynamical systems from measured time series,"[""Andrei Ivanov"", ""Anna Golovkina""]","[""dynamical systems"", ""polynomial neural networks"", ""anomaly detection""]",Deep polynomial neural networks for abnormalities detection in nonlinear processes represented by measured time series.,,,,
Wi5KUNlqWty,2021,Accept (Poster),False,How to Find Your Friendly Neighborhood: Graph Attention Design with Self-Supervision,"[""Dongkwan Kim"", ""Alice Oh""]","[""Graph Neural Network"", ""Attention Mechanism"", ""Self-supervised Learning""]",We propose a method that self-supervise graph attention through edges and it should be designed according to the average degree and homophily of graphs.,,,,
WiGQBFuVRv,2021,Accept (Spotlight),False,Multivariate Probabilistic Time Series Forecasting via Conditioned Normalizing Flows,"[""Kashif Rasul"", ""Abdul-Saboor Sheikh"", ""Ingmar Schuster"", ""Urs M Bergmann"", ""Roland Vollgraf""]","[""time series"", ""normalizing flows"", ""attention"", ""probabilistic multivariate forecasting""]",SOTA Multivariate probabilistic time series forecasting using RNNs or Attention to model the dynamics and normalizing flows for the emission model.,,,,
Wis-_MNpr4,2021,Reject,True,DarKnight: A Data Privacy Scheme for Training and Inference of Deep Neural Networks,"[""Hanieh Hashemi"", ""Yongqin Wang"", ""Murali Annavaram""]","[""Data Privacy"", ""Information-theoretic Privacy"", ""DNN Privacy"", ""Trusted Execution Environment"", ""Intel SGX""]",,2006.01300,cs.CR,2020-06-01 22:40:57+00:00,2020-10-15 21:01:26+00:00
Wj4ODo0uyCF,2021,Accept (Oral),False,Share or Not? Learning to Schedule Language-Specific Capacity for Multilingual Translation,"[""Biao Zhang"", ""Ankur Bapna"", ""Rico Sennrich"", ""Orhan Firat""]","[""language-specific modeling"", ""conditional computation"", ""multilingual translation"", ""multilingual transformer""]",We investigate and improve parameter-sharing strategies in multilingual Transformers by utilizing conditional computation.,,,,
WkKsWwxnAkt,2021,Reject,False,Subspace Clustering via Robust Self-Supervised Convolutional Neural Network,"[""Dario Sitnik"", ""Ivica Kopriva""]","[""deep subspace clustering"", ""convolutional neural networks"", ""self-supervised learning"", ""correntropy"", ""generalization"", ""robustness""]","This paper proposes a robust formulation of the self-supervised convolutional subspace clustering network, with enhanced generalization capability, by using the correntropy induced metric of the error and early-stopping technique.",,,,
WlT94P_zuHF,2021,Reject,False,Transformer-QL: A Step Towards Making Transformer Network Quadratically Large,"[""Suvadeep Hajra""]","[""deep learning"", ""language model"", ""transformer network"", ""multi-scale transformer network"", ""natural language processing"", ""transformer-xl""]","In this paper, we propose a novel transformer architecture in which the context length (the number of past tokens on which the output states depend) can grow at best quadratically with the memory and computational usage.",,,,
Wm3EA5OlHsG,2022,Accept (Poster),False,Scene Transformer: A unified architecture for predicting future trajectories of multiple agents,"['Jiquan Ngiam', 'Vijay Vasudevan', 'Benjamin Caine', 'Zhengdong Zhang', 'Hao-Tien Lewis Chiang', 'Jeffrey Ling', 'Rebecca Roelofs', 'Alex Bewley', 'Chenxi Liu', 'Ashish Venugopal', 'David J Weiss', 'Ben Sapp', 'Zhifeng Chen', 'Jonathon Shlens']","[""trajectory prediction"", ""motion forecasting"", ""multi-task learning"", ""attention"", ""autonomous vehicles""]",We introduce a scene-centric masked sequence based motion prediction model that unifies a variety of motion prediction tasks from joint motion predictions to conditioned prediction.,,,,
WnOLO1f50MH,2022,Reject,False,Exploiting Redundancy: Separable Group Convolutional Networks on Lie Groups,"['David M Knigge', 'David W. Romero', 'Erik J Bekkers']","[""Group equivariance"", ""separable convolutions"", ""group equivariant neural networks""]",We provide a novel separable parameterisation for Lie group convolutions that reduces redundancy and improves model accuracy as well as computational efficiency.,,,,
WoLQsYU8aZ,2021,Reject,False,PettingZoo: Gym for Multi-Agent Reinforcement Learning,"[""J K Terry"", ""Benjamin Black"", ""Mario Jayakumar"", ""Ananth Hari"", ""Luis Santos"", ""Clemens Dieffendahl"", ""Niall L Williams"", ""Yashas Lokesh"", ""Ryan Sullivan"", ""Caroline Horsch"", ""Praveen Ravi""]","[""Reinforcement Learning"", ""Multi-agent Reinforcement Learning""]",We introduce a large library that's essentially Gym for multi-agent reinforcement learning,,,,
WqXAKcwfZtI,2021,Reject,False,f-Domain-Adversarial Learning: Theory and Algorithms for Unsupervised Domain Adaptation with Neural Networks,"[""David Acuna"", ""Guojun Zhang"", ""Marc T Law"", ""Sanja Fidler""]","[""Domain Adaptation"", ""Adversarial Learning"", ""Transfer Learning"", ""Neural Networks"", ""Deep Learning""]",We propose a novel unsupervised domain adversarial framework that introduces new theory and leads to practical learning algorithms with neural networks.,,,,
WqoBaaPHS-,2022,Accept (Poster),False,Top-label calibration and multiclass-to-binary reductions,"['Chirag Gupta', 'Aaditya Ramdas']","[""calibration"", ""multiclass"", ""uncertainty quantification"", ""distribution-free"", ""histogram binning""]","We propose top-label calibration, a new and arguably natural notion for multiclass calibration, along with 'wrapper' calibration algorithms that reduce multiclass calibration to binary calibration.",,,,
WrNjg9tCLUt,2021,Reject,False,BAFFLE: TOWARDS RESOLVING FEDERATED LEARNINGâS DILEMMA - THWARTING BACKDOOR  AND INFERENCE ATTACKS,"[""Thien Duc Nguyen"", ""Phillip Rieger"", ""Hossein Yalame"", ""Helen M\u00f6llering"", ""Hossein Fereidooni"", ""Samuel Marchal"", ""Markus Miettinen"", ""Azalia Mirhoseini"", ""Ahmad-Reza Sadeghi"", ""Thomas Schneider"", ""Shaza Zeitouni""]","[""federated learning"", ""secure machine learning"", ""backdoor attacks"", ""inference attacks"", ""data privacy""]","We introduce BAFFLE, a novel in-depth defense for federated learning that tackles both backdoor and inference attacks.",,,,
WtPHnvDUk5X,2022,Reject,False,GANet: Glyph-Attention Network for Few-Shot Font Generation,"['Mingtao Guo', 'Wei Xiong', 'Zheng Wang', 'Yong Tang', 'Ting Wu']","[""font generation"", ""GANet"", ""glyph-attention"", ""few-shot"", ""GAN""]",Glyph-Attention Network for Few-shot Font Generation,,,,
WtlM9p1bVAw,2021,Reject,False,Unsupervised Class-Incremental Learning through Confusion,"[""Shivam Khare"", ""Kun Cao"", ""James Matthew Rehg""]","[""Incremental Learning"", ""Unsupervised Learning"", ""Continual Learning"", ""Novelty Detection"", ""Out-of-Distribution Detection""]",This paper introduces a novel OOD detection method that leverages network confusion to learn in an unsupervised incremental setting.,,,,
WuEiafqdy9H,2022,Accept (Poster),False,Model-augmented Prioritized Experience Replay,"['Youngmin Oh', 'Jinwoo Shin', 'Eunho Yang', 'Sung Ju Hwang']","[""RL"", ""Reinforcement Learning"", ""Replay Buffer""]",We propose a novel experience replay which employs additional auxiliary learnable features as well as TD-errors for prioritizing experiences,,,,
WvOGCEAQhxl,2022,Accept (Spotlight),False,Assessing Generalization of SGD via Disagreement,"['Yiding Jiang', 'Vaishnavh Nagarajan', 'Christina Baek', 'J Zico Kolter']","[""Generalization"", ""Deep Learning"", ""Empirical Phenomenon"", ""Accuracy Estimation"", ""Stochastic Gradient Descent""]",We provide a surprisingly simple technique to accurately estimate the test error of deep neural networks using unlabeled data and we prove that this works because SGD ensembles are naturally well-calibrated.,,,,
WwKv20NrsfB,2022,Reject,False,Apollo: An Adaptive Parameter-wised Diagonal Quasi-Newton Method for Nonconvex Stochastic Optimization,['Xuezhe Ma'],"[""Optimization for Neural Networks"", ""Optimization for Representation Learning"", ""Stochastic Optimization"", ""Nonconvex"", ""Quasi-Newton"", ""Optimization for Deep Learning""]",An Adaptive Parameter-wised Diagonal Quasi-Newton Method for Nonconvex Stochastic Optimization,,,,
WweBNiwWkZh,2021,Reject,True,Skinning a Parameterization of Three-Dimensional Space for Neural Network Cloth,"[""Jane Wu"", ""Zhenglin Geng"", ""Hui Zhou"", ""Ronald Fedkiw""]",[],We present a novel learning framework for cloth deformation by embedding virtual cloth into a tetrahedral mesh that parametrizes the volumetric region of air surrounding the underlying body.,2006.04874,cs.CV,2020-06-08 18:53:03+00:00,2020-06-08 18:53:03+00:00
WxBFVNbDUT6,2022,Reject,False,Benchmarking Sample Selection Strategies for Batch Reinforcement Learning,"['Yuwei Fu', 'Di Wu', 'Benoit Boulet']","[""Reinforcement Learning"", ""Experience Replay""]",Benchmarking non-uniform sampling strategies in batch reinforcement learning.,,,,
WxuE_JWxjkW,2022,Accept (Poster),False,Expressivity of Emergent Languages is a Trade-off between Contextual Complexity and Unpredictability,"['Shangmin Guo', 'Yi Ren', 'Kory Wallace Mathewson', 'Simon Kirby', 'Stefano V Albrecht', 'Kenny Smith']","[""Emergent Language"", ""Expressivity""]",We demonstrate that the expressivity of emergent languages is a trade-off between the complexity and unpredictability of the context those languages are used in.,,,,
WznmQa42ZAx,2021,Accept (Spotlight),True,Interpreting Graph Neural Networks for NLP With Differentiable Edge Masking,"[""Michael Sejr Schlichtkrull"", ""Nicola De Cao"", ""Ivan Titov""]","[""Graph neural networks"", ""interpretability"", ""sparse stochastic gates"", ""semantic role labeling"", ""question answering""]","We present a novel post-hoc interpretation method for graph neural networks, and apply it to analyse two models from the NLP literature.",2010.00577,cs.CL,2020-10-01 17:51:19+00:00,2021-04-23 10:17:42+00:00
X0nrKAXu7g-,2022,Accept (Poster),False,HyperDQN: A Randomized Exploration Method for Deep Reinforcement Learning,"['Ziniu Li', 'Yingru Li', 'Yushun Zhang', 'Tong Zhang', 'Zhi-Quan Luo']","[""exploration"", ""reinforcement learning""]",We design a practical randomized exploration method to address the sample efficiency issue in online reinforcement learning.,,,,
X1y1ur-NCh_,2022,Reject,False,Did I do that? Blame as a means to identify controlled effects in reinforcement learning,"['Oriol Corcoll Andreu', 'Youssef Sherif Mansour Mohamed', 'Raul Vicente']","[""reinforcement learning"", ""unsupervised reinforcement learning""]",Unsupervised learning of controlled effects using counterfactual measures of Blame,,,,
X2V7RW3Sul,2022,Reject,False,Improving Hyperparameter Optimization by Planning Ahead,"['Hadi Samer Jomaa', 'Jonas Falkner', 'Lars Schmidt-Thieme']","[""model-based reinforcement learning"", ""hyperparameter optimization"", ""model predictive control"", ""meta-learning"", ""transfer learning""]",,,,,
X3WxnuzAYyE,2022,Reject,False,PKCAM: Previous Knowledge Channel Attention Module,"['Eslam Mohamed BAKR', 'Ahmad A. Al Sallab', 'Mohsen Rashwan']","[""Channel Attention"", ""Attention"", ""Deep Learning"", ""Computer Vision"", ""Neural Networks.""]","We propose a Previous Knowledge Channel Attention Module( PKCAM), that captures channel-wise relations across different layers to model the global context. ",,,,
X4y_10OX-hX,2021,Accept (Poster),False,Large Associative Memory Problem in Neurobiology and Machine Learning,"[""Dmitry Krotov"", ""John J. Hopfield""]","[""associative memory"", ""Hopfield networks"", ""modern Hopfield networks"", ""neuroscience""]",Our paper proposes a microscopic biologically-plausible theory of modern Hopfield networks.,,,,
X5ivSy4AHx,2021,Reject,False,Enhanced First and Zeroth Order Variance Reduced Algorithms for Min-Max Optimization,"[""Tengyu Xu"", ""Zhe Wang"", ""Yingbin Liang"", ""H. Vincent Poor""]","[""minimax optimization"", ""nonconvex"", ""variance reduction""]",This paper develops a new analysis technique for variance reduced nonconvex-strongly-concave minimax optimization algorithms.,,,,
X6D9bAHhBQ1,2022,Accept (Spotlight),False,Planning in Stochastic Environments with a Learned Model,"['Ioannis Antonoglou', 'Julian Schrittwieser', 'Sherjil Ozair', 'Thomas K Hubert', 'David Silver']","[""model-based reinforcement learning"", ""deep reinforcement learning"", ""tree based search"", ""MCTS""]",,,,,
X6YPReSv5CX,2021,Reject,False,Mixture of Step Returns in Bootstrapped DQN,"[""PoHan Chiang"", ""Hsuan-Kung Yang"", ""Zhang-Wei Hong"", ""Chun-Yi Lee""]","[""Reinforcement Learning""]",Utilize multi-step returns into Bootstrapped DQN,,,,
X76iqnUbBjz,2021,Accept (Poster),True,A Unified Approach to Interpreting and Boosting Adversarial Transferability,"[""Xin Wang"", ""Jie Ren"", ""Shuyun Lin"", ""Xiangming Zhu"", ""Yisen Wang"", ""Quanshi Zhang""]","[""Adversarial Learning"", ""Interpretability"", ""Adversarial Transferability""]","We prove the close relationship between the interaction and adversarial transferability, provide a unified explanation for previous transferability-boosting methods, and develop a loss to improve adversarial transferability.",2010.04055,cs.LG,2020-10-08 15:19:22+00:00,2020-10-08 15:19:22+00:00
X8cLTHexYyY,2022,Accept (Spotlight),False,Learning-Augmented $k$-means Clustering,"['Jon Ergun', 'Zhili Feng', 'Sandeep Silwal', 'David Woodruff', 'Samson Zhou']","[""clustering"", ""learning-augmented algorithms""]",We study the $k$-means problem augmented with a learning-based predictor that gives noisy information about true labels.,,,,
X9LHtgR4vq,2021,Reject,False,Bractivate: Dendritic Branching in Medical Image Segmentation Neural Architecture Search,"[""Leila Abdelrahman""]","[""Neural Architecture Search"", ""Segmentation"", ""Computer Vision""]",Bractivate automatically discovers efficient architecture for medical image segmentation through cognitive-inspired dendritic branching.,,,,
XAS3uKeFWj,2021,Accept (Poster),True,Variational State-Space Models for Localisation and Dense 3D Mapping in 6 DoF,"[""Atanas Mirchev"", ""Baris Kayalibay"", ""Patrick van der Smagt"", ""Justin Bayer""]","[""Generative models"", ""Bayesian inference"", ""Variational inference"", ""SLAM"", ""Deep learning""]","We propose a variational state-space model with a latent map for 6-DoF localisation, 3D dense mapping and generative modelling for planning.",2006.10178,stat.ML,2020-06-17 22:06:35+00:00,2021-03-15 17:11:08+00:00
XEW8CQgArno,2022,Accept (Spotlight),False,Training invariances and the low-rank phenomenon: beyond linear networks,"['Thien Le', 'Stefanie Jegelka']","[""deep learning"", ""nonsmooth analysis"", ""Clarke subdifferential"", ""implicit regularization"", ""low rank bias"", ""alignment"", ""training invariance""]","We extend theoretical results regarding the low-rank bias of deep linear neural networks trained with gradient-based algorithm to non-linear architectures, reflecting empirical results in the literature.",2201.11968,cs.LG,2022-01-28 07:31:19+00:00,2022-01-28 07:31:19+00:00
XEw5Onu69uu,2021,Reject,False,Self-Labeling of Fully Mediating Representations by Graph Alignment,"[""Martijn Oldenhof"", ""Adam Arany"", ""Yves Moreau"", ""Jaak Simm""]","[""domain adaptation"", ""self-labeling"", ""chemical graph recognition""]",Fully mediating layers can be exploited in machine learning models to adapt in data efficient way to new domains. Code available on https://github.com/iclr2021-paper1739/workflow-paper1739,2103.14133,cs.LG,2021-03-25 21:01:50+00:00,2021-03-25 21:01:50+00:00
XEyElxd9zji,2021,Reject,False,Learning with Plasticity Rules: Generalization and Robustness,"[""Rares C Cristian"", ""Max Dabagia"", ""Christos Papadimitriou"", ""Santosh Vempala""]","[""meta learning"", ""plasticity"", ""local learning"", ""deep learning"", ""machine learning"", ""neural networks"", ""RNNs"", ""backpropagation"", ""perceptron"", ""evolution"", ""adversarial examples""]","Local plasticity rules, based only on the activations of the transmitting neurons, are used to update the weights of a neural network, leading to better generalization and robustness to adversarial examples.",,,,
XG1Drw7VbLJ,2021,Reject,True,Defining Benchmarks for Continual Few-Shot Learning,"[""Antreas Antoniou"", ""Massimiliano Patacchiola"", ""Mateusz Ochal"", ""Amos Storkey""]","[""few-shot learning"", ""continual learning"", ""benchmark""]",The paper propose a benchmark for bridging the gap between few-shot and continual learning.,2004.11967,cs.CV,2020-04-15 16:41:01+00:00,2020-04-15 16:41:01+00:00
XGzk5OKWFFc,2022,Accept (Poster),True,CDTrans: Cross-domain Transformer for Unsupervised Domain Adaptation,"['Tongkun Xu', 'Weihua Chen', 'Pichao WANG', 'Fan Wang', 'Hao Li', 'Rong Jin']",[],,2109.06165,cs.CV,2021-09-13 17:59:07+00:00,2021-12-14 03:49:14+00:00
XHUxf5aRB3s,2022,Accept (Poster),True,Dealing with Non-Stationarity in MARL via Trust-Region Decomposition,"['Wenhao Li', 'Xiangfeng Wang', 'Bo Jin', 'Junjie Sheng', 'Hongyuan Zha']","[""Nonstationarity"", ""Trust-Region Methods"", ""Multi-Agent Reinforcement Learning""]",,2102.10616,cs.LG,2021-02-21 14:46:50+00:00,2022-02-10 06:13:01+00:00
XI-OJ5yyse,2021,Accept (Poster),True,CopulaGNN: Towards Integrating Representational and Correlational Roles of Graphs in Graph Neural Networks,"[""Jiaqi Ma"", ""Bo Chang"", ""Xuefei Zhang"", ""Qiaozhu Mei""]","[""Graph Neural Network"", ""Gaussian Copula"", ""Gaussian Graphical Model""]","We distinguish the representational and the correlational information encoded by the graphs in node-level prediction tasks, and propose a novel Copula Graph Neural Network to effectively leverage both information.",2010.02089,cs.LG,2020-10-05 15:20:04+00:00,2021-03-18 21:54:58+00:00
XIZaWGCPl0b,2022,Reject,False,Tesseract: Gradient Flip Score to Secure Federated Learning against Model Poisoning Attacks,"['Atul Sharma', 'Wei Chen', 'Joshua Christian Zhao', 'Qiang Qiu', 'Somali Chaterji', 'Saurabh Bagchi']","[""federated learning"", ""aggregation"", ""security"", ""untargeted model poisoning attack""]","How to defend federated learning against local model poisoning attack, the most effective attack known to date, using the pattern of progression of gradients as each client learns.",,,,
XJFGyJEBLuz,2022,Reject,False,Born Again Neural Rankers,"['Zhen Qin', 'Le Yan', 'Yi Tay', 'Honglei Zhuang', 'Xuanhui Wang', 'Michael Bendersky', 'Marc Najork']","[""learning to rank"", ""knowledge distillation"", ""neural networks""]",Born again neural rankers can achieve state-of-the-art ranking performance,,,,
XJiajt89Omg,2022,Accept (Poster),False,Space-Time Graph Neural Networks,"['Samar Hadou', 'Charilaos I Kanatsoulis', 'Alejandro Ribeiro']","[""ST-GNNs"", ""GNNs"", ""stability"", ""graph-time perturbations""]","We introduce space-time graph neural network (ST-GNN) tailored to jointly process the underlying space-time topology of time-varying network data, and we show its stability to perturbations.",,,,
XJk19XzGq2J,2021,Accept (Spotlight),False,The Intrinsic Dimension of Images and Its Impact on Learning,"[""Phil Pope"", ""Chen Zhu"", ""Ahmed Abdelkader"", ""Micah Goldblum"", ""Tom Goldstein""]","[""generalization"", ""dimension"", ""manifold"", ""ImageNet"", ""CIFAR""]","We measure the dimensionality of common used datasets, and experimentally investigate whether the links between dimensionality and learning that have been identified in the manifold learning literature describe the behaviors of deep neural networks.",,,,
XK4GN6UCTfH,2022,Reject,False,MS$^2$-Transformer: An End-to-End Model for MS/MS-assisted Molecule Identification,"['Mengji Zhang', 'Yingce Xia', 'Nian Wu', 'Kun Qian', 'Jianyang Zeng']",[],,,,,
XKgo1UfNRx8,2021,Reject,False,Recycling sub-optimial Hyperparameter Optimization models to generate efficient Ensemble Deep Learning,"[""Pierrick Pochelu"", ""Bruno Conche"", ""Serge G. Petiton""]","[""Deep Learning"", ""hyperparameter optimization"", ""ensemble deep learning"", ""multi-GPU""]",We propose a new workflow that automatically explores neural network designs and efficiently combine them to generate ensemble Deep Learning far more accurate than any other ensemble of any ResNet models from ResNet18 to ResNet152.,,,,
XLfdzwNKzch,2021,Accept (Poster),False,SEDONA: Search for Decoupled Neural Networks toward Greedy Block-wise Learning,"[""Myeongjang Pyeon"", ""Jihwan Moon"", ""Taeyoung Hahn"", ""Gunhee Kim""]","[""AutoML"", ""Neural Architecture Search"", ""Greedy Learning"", ""Deep Learning""]","Our approach is the first attempt to automate decoupling neural networks for greedy block-wise learning and outperforms both end-to-end backprop and state-of-the-art greedy-learning methods on CIFAR-10, Tiny-ImageNet and ImageNet classification.",,,,
XLxhEjKNbXj,2022,Accept (Poster),False,GLASS: GNN with Labeling Tricks for Subgraph Representation Learning,"['Xiyuan Wang', 'Muhan Zhang']",[],,,,,
XMoyS8zm6GA,2021,Reject,False,"Slice, Dice, and Optimize: Measuring the Dimension of Neural Network Class Manifolds","[""Stanislav Fort"", ""Ekin Dogus Cubuk"", ""Surya Ganguli"", ""Samuel Stern Schoenholz""]","[""input space"", ""random hyperplane"", ""optimization"", ""robustness"", ""dimension"", ""codimension"", ""manifold""]","We measure the dimension of class manifolds for deep neural networks by optimizing on randomly chosen subspaces of varying dimension, linking the results to generalization and robustness.",,,,
XOh5x-vxsrV,2022,Accept (Poster),False,Cross-Trajectory Representation Learning for Zero-Shot Generalization in RL,"['Bogdan Mazoure', 'Ahmed M Ahmed', 'R Devon Hjelm', 'Andrey Kolobov', 'Patrick MacAlpine']","[""reinforcement learning"", ""representation learning"", ""self-supervised learning"", ""procgen""]",Cross-trajectory self-supervised learning for better zero-shot generalization in RL,,,,
XOjv2HxIF6i,2021,Accept (Poster),False,Unsupervised Meta-Learning through Latent-Space Interpolation in Generative Models,"[""Siavash Khodadadeh"", ""Sharare Zehtabian"", ""Saeed Vahidian"", ""Weijia Wang"", ""Bill Lin"", ""Ladislau Boloni""]","[""Meta-learning"", ""Unsupervised learning"", ""GANs""]",We use interpolation in generative models latent space to generate tasks for unsupervised meta-learninig.,,,,
XOuAOv_-5Fx,2021,Reject,False,Uncertainty Calibration Error: A New Metric for Multi-Class Classification,"[""Max-Heinrich Laves"", ""Sontje Ihler"", ""Karl-Philipp Kortmann"", ""Tobias Ortmaier""]","[""variational inference"", ""uncertainty"", ""calibration"", ""classification""]",We present an uncertainty calibration error metric based on normalized entropy.,,,,
XPZIaotutsD,2021,Accept (Poster),True,DEBERTA: DECODING-ENHANCED BERT WITH DISENTANGLED ATTENTION,"[""Pengcheng He"", ""Xiaodong Liu"", ""Jianfeng Gao"", ""Weizhu Chen""]","[""Transformer"", ""Attention"", ""Natural Language Processing"", ""Language Model Pre-training"", ""Position Encoding""]",A new model architecture DeBERTa is proposed that improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder.,2006.03654,cs.CL,2020-06-05 19:54:34+00:00,2021-10-06 21:02:00+00:00
XQQA6-So14,2021,Accept (Poster),False,Neural Spatio-Temporal Point Processes,"[""Ricky T. Q. Chen"", ""Brandon Amos"", ""Maximilian Nickel""]","[""point processes"", ""normalizing flows"", ""differential equations""]","We motivate the use of Continuous-time Normalizing Flows for building spatio-temporal point processes, and discuss modeling conditional dependencies with recurrent- or attention-based Neural ODEs.",,,,
XSLF1XFq5h,2021,Accept (Oral),False,Getting a CLUE: A  Method for Explaining Uncertainty Estimates,"[""Javier Antoran"", ""Umang Bhatt"", ""Tameem Adel"", ""Adrian Weller"", ""Jos\u00e9 Miguel Hern\u00e1ndez-Lobato""]","[""interpretability"", ""uncertainty"", ""explainability""]",We introduce a method to help explain uncertainties of any differentiable probabilistic model by perturbing input features.,,,,
XSwpJ2bonX,2022,Reject,False,Neural Circuit Architectural Priors for Embodied Control,"['Nikhil Xie Bhattasali', 'Anthony M. Zador', 'Tatiana A Engel']","[""neuroscience-inspired AI"", ""robotics"", ""motor control""]","NCAP, a set of reusable architectural components and design principles for deriving network architectures for embodied control from biological neural circuits",,,,
XVPqLyNxSyh,2022,Accept (Poster),False,Causal ImageNet: How to discover spurious features in Deep Learning?,"['Sahil Singla', 'Soheil Feizi']","[""interpretability"", ""failure explanation"", ""debugging"", ""robustness""]",A scalable framework for discovering spurious features of deep neural networks,,,,
XWODe7ZLn8f,2022,Accept (Spotlight),False,Contrastive Fine-grained Class Clustering via Generative Adversarial Networks,"['Yunji Kim', 'Jung-Woo Ha']","[""Unsupervised Fine-grained Class Clustering"", ""Disentangled Representation Learning"", ""Generative Adversarial Networks""]",We proposed a method for unsupervised fine-grained class clustering that leverages the information-theoretic regularization term based on contrastive loss. ,,,,
XZDeL25T12l,2021,Reject,False,Can Students Outperform Teachers in Knowledge Distillation based Model Compression?,"[""Xiang Deng"", ""Zhongfei Zhang""]","[""Knowledge Distillation"", ""Deep Learning"", ""Supervised Learning"", ""Model Compression""]",This work is toward understanding why students underperform teachers in knowledge distillation based model compression from a data perspective.,,,,
XZzriKGEj0_,2021,Reject,False,Learning What Not to Model: Gaussian Process Regression with Negative Constraints,"[""Gaurav Shrivastava"", ""Harsh Shrivastava"", ""Abhinav Shrivastava""]","[""Gaussian Process"", ""Gaussian Process Regression""]",,,,,
X_ch3VrNSRg,2022,Accept (Spotlight),False,EE-Net: Exploitation-Exploration Neural Networks in Contextual Bandits,"['Yikun Ban', 'Yuchen Yan', 'Arindam Banerjee', 'Jingrui He']","[""Contextual Bandits"", ""Exploration Strategy"", ""Neural Networks""]",,,,,
X_hByk2-5je,2022,Accept (Spotlight),False,Lossless Compression with Probabilistic Circuits,"['Anji Liu', 'Stephan Mandt', 'Guy Van den Broeck']",[],,2111.11632,cs.LG,2021-11-23 03:30:22+00:00,2021-11-23 03:30:22+00:00
Xa3iM4C1nqd,2021,Reject,False,Transferable Unsupervised Robust Representation Learning,"[""De-An Huang"", ""Zhiding Yu"", ""Anima Anandkumar""]","[""unsupervised representation learning"", ""robustness"", ""transfer learning""]",,,,,
Xa8sKVPnDJq,2022,Reject,False,Composing Features: Compositional Model Augmentation for Steerability of Music Transformers,"['Halley Young', 'Vincent Dumoulin', 'Pablo Samuel Castro', 'Jesse Engel', 'Cheng-Zhi Anna Huang']","[""applications"", ""music"", ""controllable generation"", ""compositionality"", ""transformer"", ""finetuning""]",We propose a method for the highly compositional task of steering a music transformer.,,,,
XavM6v_q59q,2021,Reject,False,GN-Transformer: Fusing AST and Source Code information in Graph Networks,"[""Junyan Cheng"", ""Iordanis Fostiropoulos"", ""Barry Boehm""]",[],,,,,
Xb2YyVApEj6,2022,Reject,False,MaiT: integrating spatial locality into image transformers with attention masks ,"['Ling Li', 'Ali Shafiee', 'Joseph H Hassoun']","[""vision transformer"", ""image classification"", ""deep learning"", ""computer vision""]",We apply attention masks to encode spatial locality into vision transformers and improve top-1 accuracy by up to 1.5%. ,,,,
Xb8xvrtB8Ce,2021,Accept (Poster),True,Bag of Tricks for Adversarial Training,"[""Tianyu Pang"", ""Xiao Yang"", ""Yinpeng Dong"", ""Hang Su"", ""Jun Zhu""]","[""Adversarial Training"", ""Robustness"", ""Adversarial Examples""]",Empirical evaluation of basic training tricks used in adversarial training,2010.00467,cs.LG,2020-10-01 15:03:51+00:00,2021-03-31 09:34:21+00:00
XbJiphOWXiU,2021,Reject,True,Empirically Verifying Hypotheses Using Reinforcement Learning,"[""Kenneth Marino"", ""Rob Fergus"", ""Arthur Szlam"", ""Abhinav Gupta""]",[],,2006.15762,cs.AI,2020-06-29 01:01:10+00:00,2020-06-29 01:01:10+00:00
XbatFr32NRm,2022,Reject,False,"Generalizing MLPs With Dropouts, Batch Normalization, and Skip Connections",['Taewoon Kim'],"[""MLP"", ""batch normalization"", ""dropout"", ""residual connections"", ""Bayesian inference""]","By whitening inputs before every linear layer and adding skip connections, our proposed MLP architecture can result in better performance and capture uncertainty.",,,,
XctLdNfCmP,2022,Accept (Poster),False,Predicting Physics in Mesh-reduced Space with Temporal Attention,"['XU HAN', 'Han Gao', 'Tobias Pfaff', 'Jian-Xun Wang', 'Liping Liu']","[""fluid dynamics"", ""graph neural network"", ""attention neural network""]"," We use a GNN to locally summarize features and create coarsened, compact mesh representation of the system state, onto which we apply a transformer-style temporal attention module for physics prediction.",,,,
XdprrZhBk8,2021,Reject,False,On the Predictability of Pruning Across Scales,"[""Jonathan S Rosenfeld"", ""Jonathan Frankle"", ""Michael Carbin"", ""Nir Shavit""]","[""neural networks"", ""deep learning"", ""generalization error"", ""scaling"", ""scalability"", ""pruning""]","We show pruning generalization error is predictable, and specify the scaling law predicting it across scales, empirically.",,,,
XeqjsCVLk1m,2022,Reject,False,Tell me why!âExplanations support learning relational and causal structure,"['Andrew Kyle Lampinen', 'Nicholas Andrew Roy', 'Ishita Dasgupta', 'Stephanie C.Y. Chan', 'Allison Tam', 'Chen Yan', 'Adam Santoro', 'Neil Charles Rabinowitz', 'Jane X Wang', 'Felix Hill']","[""Explanation"", ""RL"", ""Language"", ""Relations"", ""Causality""]","We show that explanations help agents to understand relational tasks, to generalize appropriately out of distribution, and to meta-learn to identify causal structure.",,,,
Xg47v73CDaj,2022,Reject,False,Non-deep Networks,"['Ankit Goyal', 'Alexey Bochkovskiy', 'Jia Deng', 'Vladlen Koltun']","[""non-deep networks""]",A non-deep neural network that works surprising well.,,,,
Xh5eMZVONGF,2021,Accept (Poster),False,Language-Agnostic Representation Learning of Source Code from Structure and Context,"[""Daniel Z\u00fcgner"", ""Tobias Kirschstein"", ""Michele Catasta"", ""Jure Leskovec"", ""Stephan G\u00fcnnemann""]","[""machine learning for code"", ""code summarization""]",Language-agnostic learning from Structure and Context of programs improves learning.,2103.11318,cs.LG,2021-03-21 06:46:06+00:00,2021-03-21 06:46:06+00:00
XhF2VOMRHS,2022,Accept (Poster),False,A Unified Contrastive Energy-based Model for Understanding the Generative Ability of Adversarial Training,"['Yifei Wang', 'Yisen Wang', 'Jiansheng Yang', 'Zhouchen Lin']","[""Generative Models"", ""Energy-based Models"", ""Sampling"", ""Adversarial Training""]",,,,,
XhMa8XPHxpw,2022,Reject,False,Low-Precision Stochastic Gradient Langevin Dynamics,"['Ruqi Zhang', 'Andrew Gordon Wilson', 'Christopher De Sa']",[],,,,,
XjYgR6gbCEc,2021,Accept (Poster),False,MODALS: Modality-agnostic Automated Data Augmentation in the Latent Space,"[""Tsz-Him Cheung"", ""Dit-Yan Yeung""]","[""deep learning"", ""data augmentation"", ""automated data augmentation"", ""latent space""]",MODALS is an automated data augmentation framework that fine-tunes four universal data transformation operations in the latent space to augment data of different modalities.,,,,
XkI_ggnfLZ4,2021,Reject,False,Uncovering the impact of hyperparameters for global magnitude pruning,"[""Janice Lan"", ""Rudy Chin"", ""Alexei Baevski"", ""Ari S. Morcos""]","[""deep learning"", ""pruning"", ""understanding""]","When pruning, we should decouple the hyperparameters used to find the mask and to evaluate the mask; some hyperparameters, despite leading to better accuracy pre-pruning, lead to bad layerwise pruning ratios, which causes decreased pruned accuracy.",,,,
Xo0lbDt975,2022,Accept (Poster),False,An Agnostic Approach to Federated Learning with Class Imbalance,"['Zebang Shen', 'Juan Cervino', 'Hamed Hassani', 'Alejandro Ribeiro']","[""Federated Learning"", ""Class Imbalance""]",,,,,
XoF2fGAvXO6,2021,Reject,False,Weakly Supervised Neuro-Symbolic Module Networks for Numerical Reasoning,"[""Amrita Saha"", ""Shafiq Joty"", ""Steven Hoi""]","[""neural module networks"", ""machine reading comprehension"", ""numerical reasoning over text""]",A weak supervised neural module network for numerical reasoning based Reading Comprehension which learns to execute a noisy generalized program form of the query over both neural and symbolic reasoning modules with the answer as the sole supervision.,,,,
XpmTU4k-5uf,2022,Reject,False,TIME-LAPSE: Learning to say âI don't knowâ through spatio-temporal uncertainty scoring,"['Nandita Bhaskhar', 'Daniel Rubin', 'Christopher Lee-Messer']","[""out-of-distribution detection"", ""OOD detection"", ""spatio-temporal"", ""latent-space"", ""sequential"", ""outlier"", ""anomaly""]","We propose a spatio-temporal framework, TIME-LAPSE that uses latent space embeddings over time to determine when inputs go out-of-distribution and provide uncertainty estimates.",,,,
XtPeiGx6BwC,2021,Reject,False,Robustness against Relational Adversary,"[""Yizhen Wang"", ""Xiaozhu Meng"", ""Mihai Christodorescu"", ""Somesh Jha"", ""Ke Wang""]","[""Adversarial Machine Learning"", ""Semantics-Preserving Attacks"", ""Logic Relations"", ""Normalization""]",A defense framework for relation-based adversarial attacks.,,,,
XuS18b_H0DW,2022,Reject,False,Tactics on Refining Decision Boundary for Improving Certification-based Robust Training,"['Wang Zhang', 'Lam M. Nguyen', 'Subhro Das', 'Pin-Yu Chen', 'Sijia Liu', 'Alexandre Megretski', 'Luca Daniel', 'Tsui-Wei Weng']","[""adversarial robustness"", ""certifiable training"", ""deep learning""]",,,,,
XvOH0v2hsph,2021,Reject,False,Revisiting the Train Loss: an Efficient Performance Estimator for Neural Architecture Search,"[""Binxin Ru"", ""Clare Lyle"", ""Lisa Schut"", ""Mark van der Wilk"", ""Yarin Gal""]","[""performance estimation"", ""neural architecture search""]",We propose a simple yet reliable method for estimating the generalisation performance of neural architectures; our method utilises early training losses and has theoretical interpretation based on training speed and marginal likelihood.,,,,
Xv_s64FiXTv,2021,Accept (Poster),True,Learning to Represent Action Values as a Hypergraph on the Action Vertices,"[""Arash Tavakoli"", ""Mehdi Fatemi"", ""Petar Kormushev""]","[""reinforcement learning"", ""structural credit assignment"", ""structural inductive bias"", ""multi-dimensional discrete action spaces"", ""learning action representations""]","This paper introduces a class of models, called action hypergraph networks, for action-value estimation by leveraging the combinatorial structure of multi-dimensional discrete action spaces.",2010.14680,cs.LG,2020-10-28 00:19:13+00:00,2021-06-20 15:14:12+00:00
XwATtbX3oCz,2021,Reject,False,Revisiting Point Cloud Classification with a Simple and Effective Baseline,"[""Ankit Goyal"", ""Hei Law"", ""Bowei Liu"", ""Alejandro Newell"", ""Jia Deng""]","[""3D Vision"", ""Point Cloud Processing""]",,2106.05304,cs.CV,2021-06-09 18:01:11+00:00,2021-06-09 18:01:11+00:00
Xx4MNjSmQQ9,2022,Reject,True,Robust Generalization of Quadratic Neural Networks via Function Identification,"['Kan Xu', 'Hamsa Bastani', 'Osbert Bastani']","[""neural network"", ""function identification"", ""robust generalization""]",,2109.10935,cs.LG,2021-09-22 18:02:00+00:00,2022-01-31 22:12:20+00:00
Xxli_LIvYI,2021,Reject,False,When Are Neural Pruning Approximation Bounds Useful?,"[""Mitchell A Gordon""]","[""neural network"", ""pruning"", ""coreset"", ""approximation""]",,,,,
XyVXPuuO_P,2022,Reject,False,Meta-Learning an Inference Algorithm for Probabilistic Programs,"['Gwonsoo Che', 'Hongseok Yang']","[""Probabilistic Programming"", ""Approximate Posterior Inference"", ""Meta Learning""]",,,,,
XzTtHjgPDsT,2022,Accept (Oral),False,Coordination Among Neural Modules Through a Shared Global Workspace,"['Anirudh Goyal', 'Aniket Rajiv Didolkar', 'Alex Lamb', 'Kartikeya Badola', 'Nan Rosemary Ke', 'Nasim Rahaman', 'Jonathan Binas', 'Charles Blundell', 'Michael Curtis Mozer', 'Yoshua Bengio']","[""slot based recurrent architectures"", ""attention"", ""transformers"", ""latent bottleneck.""]",communication among different specialist using a shared workspace allowing higher order interactions ,,,,
Y-Wl1l0Va-,2021,Reject,False,Shortest-Path Constrained Reinforcement Learning for Sparse Reward Tasks,"[""Sungryull Sohn"", ""Sungtae Lee"", ""Jongwook Choi"", ""Harm van Seijen"", ""Honglak Lee"", ""Mehdi Fatemi""]","[""reinforcement learning"", ""exploration"", ""sample efficient reinforcement learning"", ""sparse rewards""]",We propose the k-Shortest-Path (k-SP) constraint: a novel constraint on the trajectory space that improves the sample-efficiency in sparse-reward MDPs.,,,,
Y0MgRifqikY,2021,Reject,False,Visual Explanation using Attention Mechanism in Actor-Critic-based Deep Reinforcement Learning,"[""Hidenori Itaya"", ""Tsubasa Hirakawa"", ""Takayoshi Yamashita"", ""Hironobu Fujiyoshi"", ""Komei Sugiura""]",[],,2103.04067,cs.LG,2021-03-06 08:38:12+00:00,2021-03-06 08:38:12+00:00
Y0cGpgUhSvp,2022,Reject,False,"Prioritized training on points that are learnable, worth learning, and not yet learned","['SÃ¶ren Mindermann', 'Muhammed Razzak', 'Mrinank Sharma', 'Jan M. Brauner', 'Winnie Xu', 'Andreas Kirsch', 'Aidan Gomez', 'Benedikt HÃ¶ltgen', 'Sebastian Farquhar', 'Yarin Gal']","[""Data selection"", ""subset selection"", ""deep learning"", ""active learning""]","We show why prioritizing difficult samples for faster training can fail, and that prioritizing difficult but learnable samples accelerates training.",,,,
Y1O-K5itG09,2022,Reject,False,Deep Ensemble as a Gaussian Process Posterior,"['Zhijie Deng', 'Feng Zhou', 'Jianfei Chen', 'Guoqiang Wu', 'Jun Zhu']","[""Deep ensemble"", ""Bayesian deep learning"", ""Gaussian process"", ""functional variational inference"", ""uncertainty estimation""]","We suggest that deep ensemble defines a Gaussian process (GP) approximate posterior, based on which we develop a principled Bayesian learning rule for deep ensemble.",,,,
Y2eS8eWCsyG,2022,Reject,False,A Broad Dataset is All You Need for One-Shot Object Detection,"['Claudio Michaelis', 'Matthias Bethge', 'Alexander S Ecker']","[""One-Shot Learning"", ""Object Detection"", ""Generalization"", ""Instance Segmentation""]",The key to successful one-shot detection of arbitrary objects is training on a dataset with a sufficiently broad set of categories.,,,,
Y3cm4HJ3Ncs,2022,Reject,False,Learning-to-Count by Learning-to-Rank: Weakly Supervised Object Counting & Localization Using Only Pairwise Image Rankings,"[""Adriano C. D'Alessandro"", 'Ali Mahdavi Amiri', 'Ghassan Hamarneh']","[""Object Counting"", ""Weak Supervision"", ""Ranking""]",Weakly supervised object counting using only pairwise image rankings,,,,
Y3pk2JxYmO,2021,Reject,False,Fast Training of Contrastive Learning with Intermediate Contrastive Loss,"[""Chengyue Gong"", ""Xingchao Liu"", ""qiang liu""]",[],,,,,
Y45i-hDynr,2021,Reject,False,Parameterized Pseudo-Differential Operators for Graph Convolutional Neural Networks,"[""Kevin M. Potter"", ""Steven Richard Sleder"", ""Matthew David Smith"", ""John Tencer""]","[""graph convolutional neural network"", ""superpixel"", ""FAUST"", ""differential operators""]",We introduce a differential operator based graph convolutional layer that outperforms other work on superpixel image classification tasks in speed and accuracy.,,,,
Y4SOA2qsYJS,2021,Reject,False,MCM-aware Twin-least-square GAN for Hyperspectral Anomaly Detection,"[""Jiaping Zhong"", ""Weiying Xie"", ""Jie Lei"", ""Yunsong Li"", ""Zan Li""]","[""Multiscale covariance map (MCM)"", ""least square loss"", ""hyperspectral anomaly detection"", ""generative adversarial network (GAN)""]","A novel multi-scale covariance map (MCM)-aware twin-least-square GAN (MTGAN) is proposed to solve the problem of insufficient prior, gradient vanishing, and instability training in hyperspectral anomaly detection.",,,,
Y4cs1Z3HnqL,2022,Accept (Spotlight),False,Pessimistic Bootstrapping for Uncertainty-Driven Offline Reinforcement Learning,"['Chenjia Bai', 'Lingxiao Wang', 'Zhuoran Yang', 'Zhi-Hong Deng', 'Animesh Garg', 'Peng Liu', 'Zhaoran Wang']","[""Pessimistic Bootstrapping"", ""Bootstrapped Q-functions"", ""Uncertainty Estimation"", ""Offline Reinforcement Learning""]",We propose pessimistic bootstrapping as a purely uncertainty-driven algorithm for offline Reinforcement Learning.,,,,
Y5TgO3J_Glc,2021,Reject,False,Neurosymbolic Deep Generative Models for Sequence Data with Relational Constraints,"[""Halley Young"", ""Maxwell Du"", ""Osbert Bastani""]","[""neurosymbolic"", ""sequence"", ""program synthesis"", ""generative"", ""constraint"", ""music"", ""poetry""]",We use program synthesis to learn and condition on the relational structure of real sequential data.,,,,
Y87Ri-GNHYu,2021,Accept (Poster),True,Ask Your Humans: Using Human Instructions to Improve Generalization in Reinforcement Learning,"[""Valerie Chen"", ""Abhinav Gupta"", ""Kenneth Marino""]",[],,2011.00517,cs.LG,2020-11-01 14:39:46+00:00,2021-09-26 14:53:21+00:00
Y8Ivdg7typR,2022,Reject,False,Wakening Past Concepts without Past Data: Class-incremental Learning from Placebos,"['Yaoyao Liu', 'Bernt Schiele', 'Qianru Sun']","[""incremental learning"", ""continual learning"", ""class-incremental learning""]",We propose to compute the KD loss using placebo data chosen from a free image stream.,,,,
Y8KfxdZl-rI,2022,Reject,False,Weakly Supervised Label Learning Flows,"['You Lu', 'Chidubem Gibson Arachie', 'Bert Huang']","[""Weakly Supervised Learning"", ""Deep Generative Flows"", ""Deep Learning"", ""Deep Generative Models"", ""Machine Learning""]",This paper proposes a new weakly supervised learning framework based on deep generative flows,,,,
Y9FNtYulBE0,2022,Reject,False,CheXT: Knowledge-Guided Cross-Attention Transformer for Abnormality Classification and Localization in Chest X-rays,"['Yan Han', 'Ying Ding', 'Ahmed Tewfik', 'Yifan Peng', 'Zhangyang Wang']",[],,,,,
Y9McSeEaqUh,2021,Accept (Poster),True,Predicting Classification Accuracy When Adding New Unobserved Classes,"[""Yuli Slavutsky"", ""Yuval Benjamini""]","[""multiclass classification"", ""classification"", ""extrapolation"", ""accuracy"", ""ROC""]",A new prediction method of multiclass classification accuracy for an increased number of classes.,2010.15011,cs.LG,2020-10-28 14:37:25+00:00,2021-03-09 14:38:37+00:00
YCXrx6rRCXO,2021,Accept (Poster),True,Faster Binary Embeddings for Preserving Euclidean Distances,"[""Jinjie Zhang"", ""Rayan Saab""]","[""Binary Embeddings"", ""Johnson-Lindenstrauss Transforms"", ""Sigma Delta Quantization""]",We propose a fast binary embedding algorithm to preserve Euclidean distances among well-spread vectors and it achieves optimal bit complexity.,2010.00712,cs.IT,2020-10-01 22:41:41+00:00,2021-03-10 01:30:22+00:00
YD792AFzt4o,2021,Reject,True,Revisiting Explicit Regularization in Neural Networks for Reliable Predictive Probability,"[""Taejong Joo"", ""Uijung Chung""]","[""deep learning"", ""predictive uncertainty"", ""explicit regularization""]",,2006.06399,cs.LG,2020-06-11 13:14:01+00:00,2021-02-06 08:27:27+00:00
YDqIYJBQTQs,2022,Reject,False,Unsupervised Object Learning via Common Fate,"['Matthias Tangemann', 'Steffen Schneider', 'Julius Von KÃ¼gelgen', 'Francesco Locatello', 'Peter Vincent Gehler', 'Thomas Brox', 'Matthias Kuemmerer', 'Matthias Bethge', 'Bernhard SchÃ¶lkopf']","[""object learning"", ""scene modeling"", ""scene generation"", ""causal modeling"", ""causal representation learning"", ""generative modeling"", ""common fate""]","We propose a multi-stage approach for learning object, background and scene models based on unsupervised motion segmentation that allows controlled scene generation beyond the training distribution.",,,,
YDud6vPh2V,2022,Reject,True,Xi-learning: Successor Feature Transfer Learning for General Reward Functions,"['Chris Reinke', 'Xavier Alameda-Pineda']","[""reinforcement learning"", ""transfer learning"", ""meta learning"", ""successor features""]","Transfer Reinforcement Learning method allowing to use Successor Features with any reward function, instead of only linearily decomposable ones.",2110.15701,cs.LG,2021-10-29 12:01:48+00:00,2021-10-29 12:01:48+00:00
YHdeAO61l6T,2021,Accept (Poster),False,Auction Learning as a Two-Player Game,"[""Jad Rahme"", ""Samy Jelassi"", ""S. Matthew Weinberg""]","[""Mechanism Design"", ""Auction Theory"", ""Game Theory"", ""Deep Learning""]",We formulate the auction learning problem as a two player game with a stationary utility functions and explore the advantages of such an approach.,,,,
YJ1WzgMVsMt,2022,Accept (Spotlight),False,Reinforcement Learning with Sparse Rewards using Guidance from Offline Demonstration,"['Desik Rengarajan', 'Gargi Vaidya', 'Akshay Sarvesh', 'Dileep Kalathil', 'Srinivas Shakkottai']","[""Reinforcement Learning"", ""Sparse Rewards"", ""Learning from Demonstrations""]",Reinforcement learning in sparse reward environments  using offline guidance. ,2202.04628,cs.LG,2022-02-09 18:45:40+00:00,2022-02-09 18:45:40+00:00
YJVMboHZCtW,2022,Reject,False,Decision boundary variability and generalization in neural networks,"['Shiye Lei', 'Fengxiang He', 'Yancheng Yuan', 'Dacheng Tao']","[""explainability of deep learning""]",,,,,
YLewtnvKgR7,2021,Accept (Poster),False,Estimating and Evaluating Regression Predictive Uncertainty in Deep Object Detectors,"[""Ali Harakeh"", ""Steven L. Waslander""]","[""Object Detection"", ""Predictive Uncertainty Estimation"", ""Proper Scoring Rules"", ""Variance Networks"", ""Energy Score"", ""Computer Vision""]",,2101.05036,cs.CV,2021-01-13 12:53:54+00:00,2021-03-12 18:16:36+00:00
YLglAn-USkf,2022,Reject,False,Are BERT Families Zero-Shot Learners? A Study on Their Potential and Limitations,"['Yue Wang', 'Lijun Wu', 'xiaobo liang', 'Juntao Li', 'Min Zhang']",[],,,,,
YMsbeG6FqBU,2021,Reject,False,The Advantage Regret-Matching Actor-Critic,"[""Audrunas Gruslys"", ""Marc Lanctot"", ""Remi Munos"", ""Finbarr Timbers"", ""Martin Schmid"", ""Julien Perolet"", ""Dustin Morrill"", ""Vinicius Zambaldi"", ""Jean-Baptiste Lespiau"", ""John Schultz"", ""Mohammad Gheshlaghi Azar"", ""Michael Bowling"", ""Karl Tuyls""]","[""Nash Equilibrium"", ""Games"", ""CFR""]",We introduce ARMAC: generalized Counterfactual Regret Minimization using functional approximations and relying only on outcome sampling.,,,,
YNnpaAKeCfx,2021,Accept (Poster),False,FairBatch: Batch Selection for Model Fairness,"[""Yuji Roh"", ""Kangwook Lee"", ""Steven Euijong Whang"", ""Changho Suh""]","[""model fairness"", ""bilevel optimization"", ""batch selection""]","We address model fairness via the lens of bilevel optimization and propose a batch selection algorithm called FairBatch, which is easy to adopt, has state-of-the-art performance, and is compatible with existing batch selection techniques.",,,,
YPm0fzy_z6R,2021,Reject,False,Signed Graph Diffusion Network,"[""Jinhong Jung"", ""Jaemin Yoo"", ""U Kang""]","[""graph neural network"", ""signed graph analysis"", ""representation learning"", ""graph diffusion"", ""random walk"", ""link sign prediction""]",End-to-end graph neural network model for node representation learning using a novel random walk based feature diffusion in signed graphs.,2012.14191,cs.LG,2020-12-28 11:08:30+00:00,2020-12-28 11:08:30+00:00
YQVjbJPnPc9,2021,Reject,False,Predictive Attention Transformer: Improving Transformer with Attention Map Prediction,"[""Yujing Wang"", ""Yaming Yang"", ""Jiangang Bai"", ""Mingliang Zhang"", ""Jing Bai"", ""Jing Yu"", ""Ce Zhang"", ""Yunhai Tong""]","[""Transformer"", ""Convolution"", ""Attention Map""]","We propose a novel transformer architecture, PA-Transformer, which leverages convolution-based attention prediction and achieves state-of-the-art performances on both natural language processing and image classification. ",,,,
YRDlrT00BP,2022,Reject,False,On Transportation of Mini-batches: A Hierarchical Approach,"['Khai Nguyen', 'Dang Nguyen', 'Nguyen Dinh Quoc', 'Tung Pham', 'Hung Bui', 'Dinh Phung', 'Trung Le', 'Nhat Ho']","[""Deep Generative Models"", ""Deep Domain Adaptation"", ""Color Transfer"", ""Approximate Bayesian Computation"", ""Gradient Flow"", ""Optimal Transport""]","The paper improves deep generative models, deep domain adaptation, color transfer, and approximate Bayesian computation by introducing a novel mini-batch scheme for Optimal Transport.",,,,
YRq0ZUnzKoZ,2022,Accept (Poster),False,A Relational Intervention Approach for Unsupervised Dynamics Generalization in Model-Based Reinforcement Learning,"['Jiaxian Guo', 'Mingming Gong', 'Dacheng Tao']","[""Model-Based Reinforcement Learning"", ""Unsupervised Dynamics Generalization""]",This paper proposes a new model-based RL that could generalize to new environments.,,,,
YTWGvpFOQD-,2021,Accept (Spotlight),False,Differentially Private Learning Needs Better Features (or Much More Data),"[""Florian Tramer"", ""Dan Boneh""]","[""Differential Privacy"", ""Privacy"", ""Deep Learning""]",Linear models with handcrafted features outperform end-to-end CNNs for differentially private learning,,,,
YTtMaJUN_uc,2022,Reject,False,Learning Universal User Representations via Self-Supervised Lifelong Behaviors Modeling,"['Bei Yang', 'Ke Liu', 'Xiaoxiao Xu', 'Renjun Xu', 'Hong Liu', 'huan xu']","[""universal user representation"", ""extremely long sequence modeling"", ""self-supervised learning""]",A self-supervised representation method which can model lifelong behavior to obtain user embedding.,,,,
YTyHkF4P03w,2021,Reject,False,What to Prune and What Not to Prune at Initialization,"[""Maham Haroon""]","[""Network Sparsity"", ""Machine Learning"", ""Initialization Pruning""]",Provides methods to prune weights at initialization,,,,
YUGG2tFuPM,2021,Accept (Poster),True,Deep Partition Aggregation: Provable Defenses against General Poisoning Attacks,"[""Alexander Levine"", ""Soheil Feizi""]","[""bagging"", ""ensemble"", ""robustness"", ""certificate"", ""poisoning"", ""smoothing""]",We propose novel certified defenses against label-flipping and general adversarial poisoning attacks. ,2006.14768,cs.LG,2020-06-26 03:16:31+00:00,2021-03-18 05:50:12+00:00
YVPBh4k78iZ,2022,Accept (Poster),False,Scale Mixtures of Neural Network Gaussian Processes,"['Hyungi Lee', 'Eunggu Yun', 'Hongseok Yang', 'Juho Lee']","[""Neural Network Gaussian Processes"", ""Infinitely-wide Neural Networks"", ""Scale Mixtures of Gaussians"", ""Heavy-tailed Stochastic Processes""]",Infinitely-wide neural networks can be equivalent to scale mixtures of Gaussian processes.,,,,
YVa8X_2I1b,2022,Reject,False,INFERNO: Inferring Object-Centric 3D Scene Representations without Supervision,"['Lluis Castrejon', 'Nicolas Ballas', 'Aaron Courville']","[""object discovery"", ""scene representation"", ""object-centric representations"", ""3D rendering""]","We infer representations for scenes composed by multiple objects that we can re-render, and for each object we disentangle its 3D shape, appearance and pose.",,,,
YWNAX0caEjI,2022,Accept (Oral),False,Neural Structured Prediction for Inductive Node Classification,"['Meng Qu', 'Huiyu Cai', 'Jian Tang']",[],,,,,
YWtLZvLmud7,2021,Accept (Poster),False,BERTology Meets Biology: Interpreting Attention in Protein Language Models,"[""Jesse Vig"", ""Ali Madani"", ""Lav R. Varshney"", ""Caiming Xiong"", ""richard socher"", ""Nazneen Rajani""]","[""interpretability"", ""black box"", ""computational biology"", ""representation learning"", ""attention"", ""transformers"", ""visualization"", ""natural language processing""]","We analyze the internal representations of protein language models, and show that attention targets structural and functional properties of protein sequences.",,,,
YX0lrvdPQc,2022,Accept (Poster),False,A Johnson-Lindenstrauss Framework for Randomly Initialized CNNs,"['Ido Nachum', 'Jan Hazla', 'Michael Gastpar', 'Anatoly Khina']","[""convolutional neural networks"", ""Johnson-Lindenstrauss lemma"", ""initialization"", ""isometry"", ""theory.""]",We study how the geometric representation of a dataset change after the application of each randomly initialized layer of a neural network.,,,,
YYHXJOawkPb,2022,Reject,False,The Evolution of Out-of-Distribution Robustness Throughout Fine-Tuning,"['Anders Johan Andreassen', 'Yasaman Bahri', 'Behnam Neyshabur', 'Rebecca Roelofs']","[""out-of-distribution"", ""generalization"", ""robustness""]","We conduct thorough empirical investigations of the effective robustness under distribution shift of pre-trained, fine-tuned models, studying in particular the effects of pre-training dataset size, diversity, and example difficulty.",,,,
YZ-NHPj6c6O,2021,Reject,False,Quantifying and Learning Disentangled Representations with Limited Supervision,"[""Loek Tonnaer"", ""Luis Armando P\u00e9rez Rey"", ""Vlado Menkovski"", ""Mike Holenderski"", ""Jacobus W. Portegies""]","[""Representation Learning"", ""Disentanglement"", ""Group Theory""]","We propose a metric to quantify linearly symmetry-based disentangled representations, as well as a method to learn such representations with limited supervision.",,,,
YZHES8wIdE,2022,Accept (Spotlight),False,Generative Planning for Temporally Coordinated Exploration in Reinforcement Learning,"['Haichao Zhang', 'Wei Xu', 'Haonan Yu']",[],Temporally coordinated exploration in reinforcement learning using Generative Planning Method.,2201.09765,cs.LG,2022-01-24 15:53:32+00:00,2022-02-03 23:13:38+00:00
YZrQKLHFhv3,2021,Reject,True,"MixSize: Training Convnets With Mixed Image Sizes for Improved Accuracy, Speed and Scale Resiliency","[""Elad Hoffer"", ""Berry Weinstein"", ""Itay Hubara"", ""Tal Ben-Nun"", ""Torsten Hoefler"", ""Daniel Soudry""]",[],,1908.08986,cs.CV,2019-08-12 08:27:49+00:00,2019-08-12 08:27:49+00:00
YbDGyviJkrL,2021,Reject,False,Transformers for Modeling Physical Systems,"[""Nicholas Geneva"", ""Nicholas Zabaras""]","[""Scientific Machine Learning"", ""Deep Learning"", ""Physics"", ""Surrogate Modeling"", ""Koopman"", ""Transformers"", ""Attention""]","Using Koopman embeddings, transformer models can accurately predict physical dynamics.",,,,
Ybx635VOYoM,2022,Reject,False,ContraQA: Question Answering under Contradicting Contexts,"['Liangming Pan', 'Wenhu Chen', 'Min-Yen Kan', 'William Yang Wang']","[""Question Answering"", ""Misinformation Detection"", ""Robustness"", ""Text Generation"", ""Contradicting Contexts""]",We study the risk of misinformation to QA models by investigating the behavior of the QA model under contradicting contexts that are mixed with both real and fake information. ,,,,
YeShU5mLfLt,2022,Accept (Poster),False,On the Convergence of Certified Robust Training with Interval Bound Propagation,"['Yihan Wang', 'Zhouxing Shi', 'Quanquan Gu', 'Cho-Jui Hsieh']","[""Certified robustness"", ""Adversarial robustness"", ""Convergence""]",We present the first theoretical analysis on the convergence of certified robust training with interval bound propagation.,,,,
YedA6OCN6X,2022,Reject,False,Evaluating generative networks using Gaussian mixtures of image features,"['Lorenzo Luzi', 'Carlos Ortiz Marrero', 'Nile N Wynar', 'Richard Baraniuk', 'Michael J. Henry']",[],,,,,
YevsQ05DEN7,2022,Accept (Poster),True,Understanding Dimensional Collapse in Contrastive Self-supervised Learning,"['Li Jing', 'Pascal Vincent', 'Yann LeCun', 'Yuandong Tian']","[""self-supervised learning"", ""contrastive learning"", ""implicit regularization"", ""dimensional collapse""]",We observe and theoretically explain the dimensional collapse in contrastive self-supervised learning. We also propose a novel SSL method that does not rely on a projector.,2110.09348,cs.CV,2021-10-18 14:22:19+00:00,2022-02-02 19:03:47+00:00
YfFWrndRGQx,2022,Reject,False,Multi-Objective Online Learning,"['Jiyan Jiang', 'Wenpeng Zhang', 'Shiji Zhou', 'Lihong Gu', 'Xiaodong Zeng', 'Wenwu Zhu']","[""online algorithm"", ""online learning"", ""multi-objective optimization""]",This paper presents the first systematic study of multi-objective online learning. ,,,,
YgPqNctmyd,2022,Accept (Poster),False,Towards Building A Group-based Unsupervised Representation Disentanglement Framework,"['Tao Yang', 'Xuanchi Ren', 'Yuwang Wang', 'Wenjun Zeng', 'Nanning Zheng']","[""Disentangled representation learning"", ""Group theory"", ""VAE""]","In this paper, built on the group-based definition and inspired by the n-th dihedral group, we first propose a theoretical framework towards achieving unsupervised representation disentanglement.",,,,
YgR1rRWETI,2022,Reject,False,Connectivity Matters: Neural Network Pruning Through the Lens of Effective Sparsity,"['Artem M Vysogorets', 'Julia Kempe']","[""Neural Networks"", ""Pruning"", ""Sparsity""]","We propose effective sparsity, accounting for the connectivity pattern of a network, as the correct measurement framework for performance, reevaluate recent pruning algorithms and propose a competitive method for allocating sparsity across layers.",,,,
YgrdmztE4OY,2021,Reject,False,Federated Mixture of Experts,"[""Matthias Reisser"", ""Christos Louizos"", ""Efstratios Gavves"", ""Max Welling""]","[""Federated Learning"", ""personalized models"", ""non-i.i.d data""]",We propose Federated Mixture of Experts to tackle the non-i.i.d data problem in federated learning.,2107.06724,cs.LG,2021-07-14 14:15:24+00:00,2021-07-14 14:15:24+00:00
YhhEarKSli9,2021,Reject,False,AutoBayes: Automated Bayesian Graph Exploration for Nuisance-Robust Inference,"[""Andac Demir"", ""Toshiaki Koike-Akino"", ""Ye Wang"", ""Deniz Erdogmus""]",[],,,,,
YiBa9HKTyXE,2022,Accept (Poster),True,Permutation-Based SGD: Is Random Optimal?,"['Shashank Rajput', 'Kangwook Lee', 'Dimitris Papailiopoulos']","[""Convex Optimization"", ""Stochastic Optimization"", ""Large Scale Learning""]","We show that the question of whether random permutations are optimal for permutation-based SGD is nuanced, and depends on the family of functions one is trying to optimize.",2102.09718,cs.LG,2021-02-19 03:14:28+00:00,2021-11-25 01:25:18+00:00
YicbFdNTTy,2021,Accept (Oral),True,An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale,"[""Alexey Dosovitskiy"", ""Lucas Beyer"", ""Alexander Kolesnikov"", ""Dirk Weissenborn"", ""Xiaohua Zhai"", ""Thomas Unterthiner"", ""Mostafa Dehghani"", ""Matthias Minderer"", ""Georg Heigold"", ""Sylvain Gelly"", ""Jakob Uszkoreit"", ""Neil Houlsby""]","[""computer vision"", ""image recognition"", ""self-attention"", ""transformer"", ""large-scale training""]",Transformers applied directly to image patches and pre-trained on large datasets work really well on image classification.,2010.11929,cs.CV,2020-10-22 17:55:59+00:00,2021-06-03 13:08:56+00:00
YigKlMJwjye,2022,Accept (Poster),False,Generalized Demographic Parity for Group Fairness,"['Zhimeng Jiang', 'Xiaotian Han', 'Chao Fan', 'Fan Yang', 'Ali Mostafavi', 'Xia Hu']","[""Generalized demographic parity"", ""estimation error analysis""]",This work aims to generalize demographic parity to continuous sensitive attributes while preserving tractable computation.,,,,
Yj4mmVB_l6,2021,Reject,False,Two steps at a time --- taking GAN training in stride with Tseng's method,"[""Axel B\u00f6hm"", ""Michael Sedlmayer"", ""Ern\u00f6 Robert Csetnek"", ""Radu Ioan Bot""]",[],,,,,
YjNv-hzM8BE,2021,Reject,False,VECO: Variable Encoder-decoder Pre-training for Cross-lingual Understanding and Generation,"[""Fuli Luo"", ""Wei Wang"", ""Jiahao Liu"", ""Yijia Liu"", ""Bin Bi"", ""Songfang Huang"", ""Fei Huang"", ""Luo Si""]","[""Natural Language Processing"", ""Representation Learning""]","A cross-lingual pre-training model, that varies in pre-training and fine-tuning, can be applied to both language understanding and generation tasks",,,,
YjXnezbeCwG,2021,Reject,False,Learning to Use Future Information in Simultaneous Translation,"[""Xueqing Wu"", ""Yingce Xia"", ""Lijun Wu"", ""Shufang Xie"", ""Weiqing Liu"", ""Tao Qin"", ""Tie-Yan Liu""]","[""sequence learning"", ""simultaneous machine translation""]","We propose a new method for simultaneous translation, which is guided by a controller (trained via reinforcement learning) that can adaptively leverage future infomation to improve translation quality.",,,,
YmA86Zo-P_t,2021,Accept (Poster),True,What they do when in doubt: a study of inductive biases in seq2seq learners,"[""Eugene Kharitonov"", ""Rahma Chaabouni""]","[""inductive biases"", ""description length"", ""sequence-to-sequence models""]","Standard seq2seq models can infer perfectly different rules when presented with as little as one training example, showing strikingly different inductive biases that can be studied via description length",2006.14953,cs.CL,2020-06-26 12:43:10+00:00,2021-03-29 09:43:36+00:00
YmONQIWli--,2022,Reject,True,Gotta Go Fast When Generating Data with Score-Based Models,"['Alexia Jolicoeur-Martineau', 'Ke Li', 'RÃ©mi PichÃ©-Taillefer', 'Tal Kachman', 'Ioannis Mitliagkas']","[""score-based"", ""generative model"", ""denoising diffusion"", ""SDE"", ""diffusion process""]",Go FASTER and further on diffusion based model,2105.14080,cs.LG,2021-05-28 19:48:51+00:00,2021-05-28 19:48:51+00:00
YmqAnY0CMEy,2021,Accept (Spotlight),False,Mathematical Reasoning via Self-supervised Skip-tree Training,"[""Markus Norman Rabe"", ""Dennis Lee"", ""Kshitij Bansal"", ""Christian Szegedy""]","[""self-supervised learning"", ""mathematics"", ""reasoning"", ""theorem proving"", ""language modeling""]",We demonstrate that self-supervised language modeling applied to mathematical formulas enables logical reasoning.,,,,
Yn4CPz_LRKO,2022,Reject,False,Conditional GANs with Auxiliary Discriminative Classifier,"['Liang Hou', 'Qi Cao', 'Huawei Shen', 'Xueqi Cheng']","[""conditional generative adversarial networks"", ""conditional image generation""]",We propose a novel conditional generative adversarial network with an auxiliary discriminative classifier to achieve faithful conditional generative modeling.,,,,
Yp4sR6rmgFt,2022,Reject,False,Transductive Universal Transport for Zero-Shot Action Recognition,['Pascal Mettes'],"[""zero-shot learning"", ""action recognition"", ""action localization"", ""optimal transport""]",We propose a transductive universal transport to address strong biases in state-of-the-art universal models for zero-shot action recognition.,,,,
YpBHDlalKDG,2022,Reject,False,Complex Locomotion Skill Learning via Differentiable Physics,"['Jiancheng Liu', 'Yu Fang', 'Mingrui Zhang', 'Jiasheng Zhang', 'Yidong Ma', 'Minchen Li', 'Yuanming Hu', 'Chenfanfu Jiang', 'Tiantian Liu']","[""differentiable physics"", ""locomotion skill learning"", ""physical simulation""]",The first differentiable physics based learning framework for complex locomotion tasks using single network,,,,
YpPiNigTzMT,2022,Accept (Poster),False,Universalizing Weak Supervision,"['Changho Shin', 'Winfred Li', 'Harit Vishwakarma', 'Nicholas Carl Roberts', 'Frederic Sala']","[""Weak supervision""]","We extend weak supervision frameworks to new settings â rankings, regression, Riemannian spaces, and more â with a universal algorithm with theoretical guarantees. ",,,,
YpSxqy_RE84,2022,Accept (Poster),True,How Low Can We Go: Trading Memory for Error in Low-Precision Training,"['Chengrun Yang', 'Ziyang Wu', 'Jerry Chee', 'Christopher De Sa', 'Madeleine Udell']","[""low-precision training"", ""meta-learning"", ""Pareto frontier"", ""error-memory tradeoff"", ""active learning"", ""matrix factorization""]","Given a dataset and a memory budget, we use matrix factorization and active learning to efficiently pick the perfect low-precision configuration for a neural network.",2106.09686,cs.LG,2021-06-17 17:38:07+00:00,2021-06-18 04:55:09+00:00
YqHW0o9wXae,2022,Reject,False,Assisted Learning for Organizations with Limited Imbalanced Data,"['Cheng Chen', 'Jiaying Zhou', 'Jie Ding', 'Yi Zhou', 'Bhavya Kailkhura']","[""Assisted learning"", ""Deep learning"", ""Reinforcement learning"", ""Optimization"", ""Heterogeneous learner"", ""Imbalanced data""]",We develop an assisted learning framework for assisting organization-level learners to improve their learning performance with limited and imbalanced data.,,,,
Yr_1QZaRqmv,2022,Reject,False,Decision Tree Algorithms for MDP,"['Elioth Sanabria', 'David Yao', 'Henry Lam']",[],,,,,
Ysuv-WOFeKR,2021,Accept (Oral),False,Parrot: Data-Driven Behavioral Priors for Reinforcement Learning,"[""Avi Singh"", ""Huihan Liu"", ""Gaoyue Zhou"", ""Albert Yu"", ""Nicholas Rhinehart"", ""Sergey Levine""]","[""reinforcement learning"", ""imitation learning""]","We propose a method for pre-training a prior for reinforcement learning using data from a diverse range of tasks, and use this prior to speed up learning of new tasks. ",2011.10024,cs.LG,2020-11-19 18:47:40+00:00,2020-11-19 18:47:40+00:00
YtMG5ex0ou,2021,Accept (Poster),False,Tomographic Auto-Encoder: Unsupervised Bayesian Recovery of Corrupted Data,"[""Francesco Tonolini"", ""Pablo Garcia Moreno"", ""Andreas Damianou"", ""Roderick Murray-Smith""]","[""Missing value imputation"", ""variational inference"", ""variational auto-encoders""]",Recovering accurate posterior distributions for unsupervised data recovery,,,,
YtdASzotUEW,2022,Reject,False,Label Smoothed Embedding Hypothesis for Out-of-Distribution Detection,"['Dara Bahri', 'Heinrich Jiang', 'Yi Tay', 'Donald Metzler']","[""deep k-nn"", ""label smoothing"", ""out-of-distribution detection"", ""robustness""]",We propose an unsupervised method to detect out-of-distribution samples using a $k$-NN density estimate with respect to a classification model's intermediate activations on in-distribution samples.,,,,
YtgKRmhAojv,2021,Reject,True,One Reflection Suffice,"[""Alexander Mathiasen"", ""Frederik Hvilsh\u00f8j""]","[""Orthogonal Weights Householder Reflections Normalizing Flows""]","Instead of using many Householder reflections you can just use one ""auxillary"" reflection. ",2009.14554,cs.LG,2020-09-30 10:52:27+00:00,2020-09-30 10:52:27+00:00
YwpZmcAehZ,2021,Accept (Poster),False,Revisiting Dynamic Convolution via Matrix Decomposition,"[""Yunsheng Li"", ""Yinpeng Chen"", ""Xiyang Dai"", ""mengchen liu"", ""Dongdong Chen"", ""Ye Yu"", ""Lu Yuan"", ""Zicheng Liu"", ""Mei Chen"", ""Nuno Vasconcelos""]","[""supervised representation learning"", ""efficient network"", ""dynamic network"", ""matrix decomposition""]",Efficient network with dynamic matrix decomposition,2103.08756,cs.CV,2021-03-15 23:03:18+00:00,2021-03-15 23:03:18+00:00
YxQiIOLKgEf,2022,Reject,True,Counterfactual Graph Learning for Link Prediction,"['Tong Zhao', 'Gang Liu', 'Daheng Wang', 'Wenhao Yu', 'Meng Jiang']","[""Link Prediction"", ""Graph Representation Learning"", ""Graph Neural Networks.""]",Design a novel method that leverages counterfactual inference to improve link prediction on graphs.,2106.02172,cs.LG,2021-06-03 23:27:00+00:00,2021-06-03 23:27:00+00:00
YxWU4YZ4Cr,2022,Reject,False,Generalization to Out-of-Distribution transformations,"['Shanka Subhra Mondal', 'Zack Dulberg', 'Jonathan Cohen']","[""Out of distribution"", ""generalization"", ""convolution"", ""polar transformation""]",,,,,
Yz-XtK5RBxB,2021,Accept (Poster),False,Deep Repulsive Clustering of Ordered Data Based on Order-Identity Decomposition,"[""Seon-Ho Lee"", ""Chang-Su Kim""]","[""Clustering"", ""order learning"", ""age estimation"", ""aesthetic assessment"", ""historical color image classification""]",A deep clustering algorithm for ordered data is proposed based on the order-identity decomposition.,,,,
YzgAOeA67xX,2021,Reject,False,Stable Weight Decay Regularization,"[""Zeke Xie"", ""Issei Sato"", ""Masashi Sugiyama""]","[""Weight Decay"", ""Regularization"", ""Optimization"", ""Deep Learning""]",The proposed Stable Weight Decay method makes significant improvements over the conventional weight decay implementations in modern deep learning libraries.,,,,
Z0XiFAb_WDr,2022,Reject,False,Communicating Natural Programs to Humans and Machines,"['Sam Acquaviva', 'Yewen Pu', 'Marta Kryven', 'Catherine Wong', 'Theodoros Sechopoulos', 'Gabrielle Ecanow', 'Maxwell Nye', 'Michael Henry Tessler', 'Joshua B. Tenenbaum']","[""program synthesis"", ""communication"", ""cognition""]","We study natural programs - instructions that can be interpreted by humans to produce a verifiable output, as a pathway to building intelligent systems.",,,,
Z1Qlm11uOM,2022,Accept (Poster),False,Learning Audio-Visual Speech Representation by Masked Multimodal Cluster Prediction,"['Bowen Shi', 'Wei-Ning Hsu', 'Kushal Lakhotia', 'Abdelrahman Mohamed']","[""audio-visual speech recognition"", ""lip reading"", ""speech recognition"", ""self-supervised learning""]","A self-supervised learning framework for audio-visual speech data, which uses only 30h of labeled data to match the SOTA lip-reading model trained on 31k hours of data (34.6% vs 33.6% WER), and further outperforms the SOTA with 70x less data (30.6%).",2201.02184,eess.AS,2022-01-05 17:40:45+00:00,2022-01-05 17:40:45+00:00
Z2qyx5vC8Xn,2021,Reject,False,Temporal Difference Uncertainties as a Signal for Exploration,"[""Sebastian Flennerhag"", ""Jane X Wang"", ""Pablo Sprechmann"", ""Francesco Visin"", ""Alexandre Galashov"", ""Steven Kapturowski"", ""Diana L Borsa"", ""Nicolas Heess"", ""Andre Barreto"", ""Razvan Pascanu""]","[""deep reinforcement learning"", ""deep-rl"", ""exploration""]",A method for exploration based on learning from uncertainty over the agent's value-function.,,,,
Z3XVHSbSawb,2021,Reject,False,Daylight: Assessing Generalization Skills of Deep Reinforcement Learning Agents,"[""Ezgi Korkmaz""]","[""deep reinforcement learning"", ""generalization""]",,,,,
Z4R1vxLbRLO,2021,Accept (Poster),True,Extreme Memorization via Scale of Initialization,"[""Harsh Mehta"", ""Ashok Cutkosky"", ""Behnam Neyshabur""]","[""Scale of initialization"", ""Memorization"", ""Overfitting"", ""Generalization"", ""Generalization Measure"", ""Understanding Deep Learning""]","Through studying the effect of scale of initialization on generalization, we come up with an alignment measure that correlations with generalization of deep models.",2008.13363,cs.LG,2020-08-31 04:53:11+00:00,2021-05-01 22:09:15+00:00
Z4YatHL7aq,2021,Reject,False,Semantically-Adaptive Upsampling for Layout-to-Image Translation,"[""Hao Tang"", ""Nicu Sebe""]","[""Feature upsampling"", ""semantically-adaptive"", ""layout-to-image translation""]",A novel feature upsampling method for layout-to-image translation method.,,,,
Z532uNJyG5y,2021,Reject,False,Iterative Graph Self-Distillation,"[""Hanlin Zhang"", ""Shuai Lin"", ""Weiyang Liu"", ""Pan Zhou"", ""Jian Tang"", ""Xiaodan Liang"", ""Eric Xing""]","[""graph-level representation learning"", ""knowledge distillation""]",,,,,
Z7Lk2cQEG8a,2022,Accept (Oral),False,The Hidden Convex Optimization Landscape of Regularized Two-Layer ReLU Networks: an Exact Characterization of Optimal Solutions,"['Yifei Wang', 'Jonathan Lacotte', 'Mert Pilanci']","[""Neural networks"", ""global optimization"", ""convex optimization"", ""convex analysis""]",,,,,
Z7VhFVRVqeU,2022,Reject,False,Neural Bootstrapping Attention for Neural Processes,"['Minsub Lee', 'Junhyun Park', 'Sojin Jang', 'Chanhui Lee', 'Hyungjoo Cho', 'Minsuk Shin', 'Sungbin Lim']","[""Neural Process"", ""Bootstrapping""]","A novel efficient bootstrap method for attentive neural processes that properly models the functional uncertainty, resolve problems of previous neural processes methods, and achieves SOTA performance in sequential decision-making tasks.",,,,
Z8FzvVU6_Kj,2022,Accept (Poster),False,SUMNAS: Supernet with Unbiased Meta-Features for Neural Architecture Search,"['Hyeonmin Ha', 'Ji-Hoon Kim', 'Semin Park', 'Byung-Gon Chun']","[""Neural architecture search""]",We propose a supernet learning strategy that learns unbiased meta-features to tackle multi-model forgetting problem of neural architecture search.,,,,
ZAA0Ol4z2i4,2022,Reject,False,Explaining Off-Policy Actor-Critic From A Bias-Variance Perspective,"['Ting-Han Fan', 'Peter Ramadge']",[],,,,,
ZAfeFYKUek5,2021,Reject,False,Optimization Variance:  Exploring Generalization Properties of DNNs,"[""Xiao Zhang"", ""Dongrui Wu"", ""Haoyi Xiong"", ""Bo Dai""]","[""Double Descent"", ""Neural Networks"", ""Generalization""]",We propose a novel metric to indicate generalization of a DNN without using any validation set.,,,,
ZBESeIUB5k,2022,Accept (Poster),False,Stochastic Training is Not Necessary for Generalization,"['Jonas Geiping', 'Micah Goldblum', 'Phil Pope', 'Michael Moeller', 'Tom Goldstein']","[""Optimization"", ""Generalization"", ""Stochasticity"", ""SGD"", ""full-batch"", ""implicit regularization"", ""implicit bias""]",Models trained with full-batch gradient descent and explicit regularization can match the generalization performance of models trained with stochastic minibatching.,,,,
ZC1s7bdR9bD,2022,Reject,False,Path Integrals for the Attribution of Model Uncertainties,"['Iker Perez Lopez', 'Piotr Skalski', 'Alec Barns-Graham', 'Jason Wong', 'David Sutton']","[""bayesian neural networks"", ""path integrals"", ""uncertainty attribution""]","We present a novel algorithm for uncertainty attribution in Bayesian differentiable models via in-distribution path integrals, which significantly simplifies interpretability over existing alternatives.",,,,
ZD7Ll4pAw7C,2021,Reject,False,Rethinking the Pruning Criteria for Convolutional Neural Network,"[""Zhongzhan Huang"", ""Xinjiang Wang"", ""Ping Luo""]","[""Pruning Criteria"", ""Similarity"", ""Convolution"", ""Weight Distribution""]",,,,,
ZDYhm_o8MX,2022,Reject,False,Neural Manifold Clustering and Embedding,"['ZENGYI LI', 'Yubei Chen', 'Yann LeCun', 'Friedrich Sommer']","[""Self-supervised Learning"", ""Clustering"", ""Subspace Clustering"", ""Manifold Learning"", ""Deep Subspace Clustering""]","We show that to achieve general manifold clustering and embedding with neural networks, one need to combine a constraint implemented by data augmentation with a subspace feature learning method.",,,,
ZDaSIkWT-AP,2022,Accept (Poster),False,Case-based Reasoning for Better Generalization in Text-Adventure Games,"['Mattia Atzeni', 'Shehzaad Zuzar Dhuliawala', 'Keerthiram Murugesan', 'MRINMAYA SACHAN']",[],,,,,
ZDnzZrTqU9N,2021,Accept (Poster),False,Modeling the Second Player in Distributionally Robust Optimization,"[""Paul Michel"", ""Tatsunori Hashimoto"", ""Graham Neubig""]","[""distributionally robust optimization"", ""deep learning"", ""robustness"", ""adversarial learning""]","We use generative neural models to define the uncertainty set in distributionally robust optimization, and show that this helps train more robust classifiers",,,,
ZFIT_sGjPJ,2022,Reject,False,Data-Dependent Randomized Smoothing,"['Motasem Alfarra', 'Adel Bibi', 'Philip Torr', 'Bernard Ghanem']","[""Network Certification"", ""Randomized Smoothing""]",We optimize the parameters of the smoothing distribution for randomized smooth classifiers to maximize the certified radius for each input point.,,,,
ZHADKD4pl5H,2021,Reject,False,Wasserstein diffusion on graphs with missing attributes,"[""Zhixian Chen"", ""Tengfei Ma"", ""Yangqiu Song"", ""Yang Wang""]","[""Wasserstein barycenter"", ""graph learning"", ""diffusion"", ""missing features"", ""matrix completion""]",We propose a new graph representation method based on optimal transport for graphs with missing attributes.,,,,
ZHJlKWN57EQ,2021,Reject,False,Revisiting BFfloat16 Training,"[""Pedram Zamirai"", ""Jian Zhang"", ""Christopher R Aberger"", ""Christopher De Sa""]","[""16-bit training"", ""Low precision training"", ""Deep learning hardware""]",,,,,
ZHkbzSR56jA,2021,Reject,True,BASGD: Buffered Asynchronous SGD for Byzantine Learning,"[""Yi-Rui Yang"", ""Wu-Jun Li""]","[""Distributed optimization"", ""asynchronous Byzantine learning""]","In this paper, we propose a novel method called Buffered Asynchronous Stochastic Gradient Descent (BASGD) for Byzantine learning.",2003.00937,cs.LG,2020-03-02 14:34:28+00:00,2021-07-01 09:06:17+00:00
ZJGnFbd6vW,2021,Reject,False,PCPs: Patient Cardiac Prototypes,"[""Dani Kiyasseh"", ""Tingting Zhu"", ""David A. Clifton""]","[""Contrastive learning"", ""dataset distillation"", ""patient-similarity"", ""physiological signals"", ""healthcare""]",,2011.14227,eess.SP,2020-11-28 22:41:27+00:00,2020-11-28 22:41:27+00:00
ZK6vTvb84s,2021,Accept (Poster),True,A Trainable Optimal Transport Embedding for Feature Aggregation and its Relationship to Attention,"[""Gr\u00e9goire Mialon"", ""Dexiong Chen"", ""Alexandre d'Aspremont"", ""Julien Mairal""]","[""bioinformatics"", ""optimal transport"", ""kernel methods"", ""attention"", ""transformers""]","We propose a new, trainable embedding for large sets of features such as biological sequences, and demonstrate its effectiveness.",2006.12065,cs.LG,2020-06-22 08:35:58+00:00,2021-02-09 21:24:42+00:00
ZKy2X3dgPA,2022,Accept (Poster),False,It Takes Two to Tango: Mixup for Deep Metric Learning,"['Shashanka Venkataramanan', 'Bill Psomas', 'Ewa Kijak', 'laurent amsaleg', 'Konstantinos Karantzalos', 'Yannis Avrithis']",[],"We systematically study different mixup strategies in the context of deep metric learning, and study how to, and the effect of, mixing inputs, features, and output embeddings.",,,,
ZKyd0bkFmom,2021,Reject,True,Parametric Copula-GP model for analyzing multidimensional neuronal and behavioral relationships,"[""Nina Kudryashova"", ""Theoklitos Amvrosiadis"", ""Nathalie Dupuy"", ""Nathalie Rochefort"", ""Arno Onken""]","[""hierarchical vine copula model"", ""copula"", ""gaussian process"", ""mutual information"", ""neuroscience"", ""neuronal activity"", ""calcium imaging"", ""visual cortex""]","Copula-GP provides accurate information estimates (better or similar to MINE and with uncertainty estimates), scales to high dimensions and is invariant to homeomorphic transformations of marginals, making it suitable for application in neuroscience.",2008.01007,stat.ME,2020-08-03 16:44:29+00:00,2020-08-03 16:44:29+00:00
ZN3s7fN-bo,2021,Reject,True,Interactive Visualization for Debugging RL,"[""Shuby Deshpande"", ""Benjamin Eysenbach"", ""Jeff Schneider""]","[""Reinforcement Learning"", ""Interpretability"", ""Visualization""]",,2008.07331,cs.LG,2020-08-14 15:28:18+00:00,2020-08-18 22:27:29+00:00
ZOcX-eybqoL,2022,Accept (Poster),False,Generalisation in Lifelong Reinforcement Learning through Logical Composition ,"['Geraud Nangue Tasse', 'Steven James', 'Benjamin Rosman']","[""Reinforcement Learning"", ""Lifelong learning"", ""Multi task learning"", ""Transfer learning"", ""Logical composition"", ""Deep Reinforcement Learning""]","A framework with theoretical guarantees for an agent to quickly generalize over a task space by autonomously determining whether a new task can be solved zero-shot using existing skills, or whether a task-specific skill should be learned few-shot.",,,,
ZOjKx9dEmLB,2022,Reject,False,NAS-Bench-360: Benchmarking Diverse Tasks for Neural Architecture Search,"['Renbo Tu', 'Mikhail Khodak', 'Nicholas Carl Roberts', 'Ameet Talwalkar']","[""automated machine learning"", ""neural architecture search""]",We provide a benchmark for neural architecture search on a diverse set of understudied tasks.,,,,
ZPa2SyGcbwh,2021,Accept (Spotlight),False,Learning with Feature-Dependent Label Noise: A Progressive Approach,"[""Yikai Zhang"", ""Songzhu Zheng"", ""Pengxiang Wu"", ""Mayank Goswami"", ""Chao Chen""]","[""Noisy Label"", ""Deep Learning"", ""Classification""]",We propose a progressive label correction approach for noisy label learning task.,2103.07756,cs.LG,2021-03-13 17:34:22+00:00,2021-03-27 05:34:18+00:00
ZS-9XoX20AV,2021,Reject,False,GraphSAD: Learning Graph Representations with Structure-Attribute Disentanglement,"[""Minghao Xu"", ""Hang Wang"", ""Bingbing Ni"", ""Wenjun Zhang"", ""Jian Tang""]","[""Graph Representation Learning"", ""Disentangled Representation Learning""]",This work seeks to learn structure-attribute disentangled node/graph representations and measure such disentanglement quantitatively.,,,,
ZSKRQMvttc,2022,Accept (Poster),False,Accelerated Policy Learning with Parallel Differentiable Simulation,"['Jie Xu', 'Miles Macklin', 'Viktor Makoviychuk', 'Yashraj Narang', 'Animesh Garg', 'Fabio Ramos', 'Wojciech Matusik']","[""Robot Control"", ""Policy Learning"", ""Differentiable Simulation"", ""Reinforcement Learning""]","We propose an efficient policy learning method leveraging the recent advance of differentiable simulation, and our method outperforms state-of-the-art algorithms in both sample efficiency and wall clock time on multiple challenging control tasks.",,,,
ZTFeSBIX9C,2021,Accept (Poster),False,Understanding and Improving Lexical Choice in Non-Autoregressive Translation,"[""Liang Ding"", ""Longyue Wang"", ""Xuebo Liu"", ""Derek F. Wong"", ""Dacheng Tao"", ""Zhaopeng Tu""]",[],"We reveal the side effect of knowledge distillation from lexical choice perspective for Non-autoregressvie machine translation, and then propose a simple yet effective approach to improve it.",2012.14583,cs.CL,2020-12-29 03:18:50+00:00,2021-01-27 07:22:16+00:00
ZTsoE8G3GG,2022,Accept (Poster),False,Learning to Extend Molecular Scaffolds with Structural Motifs,"['Krzysztof Maziarz', 'Henry Richard Jackson-Flux', 'Pashmina Cameron', 'Finton Sirockin', 'Nadine Schneider', 'Nikolaus Stiefl', 'Marwin Segler', 'Marc Brockschmidt']","[""molecules"", ""graph neural networks"", ""scaffold"", ""generative model""]",We propose a new fragment-based generative model of molecules that can be constrained to include an arbitrary subgraph (scaffold).,,,,
ZU-zFnTum1N,2022,Accept (Poster),True,Bregman Gradient Policy Optimization,"['Feihu Huang', 'Shangqian Gao', 'Heng Huang']",[],,2106.12112,cs.LG,2021-06-23 01:08:54+00:00,2021-10-05 21:10:42+00:00
ZUW6N_SVKxq,2021,Reject,True,Deep Kernel Processes,"[""Laurence Aitchison"", ""Adam X. Yang"", ""Sebastian W. Ober""]","[""Gaussian process"", ""doubly stochastic variational inference"", ""variational Inference"", ""Bayesian Inference""]","We give a doubly-stochastic variational scheme for deep kernel processes, which are similar to deep Gaussian processes, but operate entirely on Gram matrices, rather than underlying features.",2010.01590,stat.ML,2020-10-04 14:31:18+00:00,2021-05-30 12:23:26+00:00
ZUXZKjfptc9,2022,Reject,False,Bit-aware Randomized Response for Local Differential Privacy in Federated Learning,"['Phung Lai', 'Hai Phan', 'Li Xiong', 'Khang Phuc Tran', 'My Thai', 'Tong Sun', 'Franck Dernoncourt', 'Jiuxiang Gu', 'Nikolaos Barmpalios', 'Rajiv Jain']","[""local differential privacy"", ""federated learning"", ""bit-aware""]","In this paper, we develop BitRand, a novel bit-aware randomized response algorithm, to preserve local differential privacy (LDP) in federated learning (FL).",,,,
ZUinrZwKnHb,2022,Reject,False,Attend to Who You Are: Supervising Self-Attention for Keypoint Detection and Instance-Aware Association,"['Sen Yang', 'Zhicheng Wang', 'Ze Chen', 'Yanjie Li', 'Shoukui Zhang', 'Zhibin Quan', 'Shu-Tao Xia', 'Yiping Bao', 'Erjin Zhou', 'Wankou Yang']","[""human pose estimation"", ""bottom-up"", ""self-attention"", ""transformer"", ""instance segmentation""]",We propose a novel approach of multi-person keypoint detection and instance association using instance masks to supervise self-attention,2111.12892,cs.CV,2021-11-25 03:41:41+00:00,2021-11-25 03:41:41+00:00
ZVBtN6B_6i7,2021,Reject,False,Not All Memories are Created Equal: Learning to Expire,"[""Sainbayar Sukhbaatar"", ""Da JU"", ""Spencer Poff"", ""Stephen Roller"", ""Arthur Szlam"", ""Jason E Weston"", ""Angela Fan""]","[""expire"", ""long attention"", ""memory"", ""transformers""]",Scale attention mechanisms in Transformers by learning what to forget from the past.,,,,
ZVqZIA1GA_,2021,Reject,False,Deformable Capsules for Object Detection,"[""Rodney LaLonde"", ""Naji Khosravan"", ""Ulas Bagci""]","[""Representation Learning"", ""Capsule Networks"", ""Object Detection""]","Introducing deformable capsules, a new capsule detection head structure, and a novel dynamic routing algorithm makes large-scale object detection with capsule neural networks feasible for the first time in the literature.",2104.05031,cs.CV,2021-04-11 15:36:30+00:00,2021-04-11 15:36:30+00:00
ZW0yXJyNmoG,2021,Accept (Poster),False,Taming GANs with Lookahead-Minmax,"[""Tatjana Chavdarova"", ""Matteo Pagliardini"", ""Sebastian U Stich"", ""Fran\u00e7ois Fleuret"", ""Martin Jaggi""]","[""Minmax"", ""Generative Adversarial Networks""]",A novel optimizer for GANs and games in general. ,,,,
ZWykq5n4zx,2022,Reject,False,Boosting the Confidence of Near-Tight Generalization Bounds for Uniformly Stable Randomized Algorithms,"['Xiaotong Yuan', 'Ping Li']","[""Uniform stability"", ""Randomized learning algorithms"", ""Bagging"", ""Generalization bounds"", ""Stochastic gradient methods""]",A confidence-boosting method for deriving near-tight generalization bounds with high probability for uniformly stable randomized learning algorithms.,,,,
Z_3x5eFk1l-,2021,Reject,False,Adversarial Meta-Learning,"[""Chengxiang Yin"", ""Jian Tang"", ""Zhiyuan Xu"", ""Yanzhi Wang""]","[""Meta-learning"", ""Adversarial manner"", ""Adversarial Meta-Learner"", ""Adversarial samples""]",Study the general meta-learning with adversarial samples.,,,,
Z_TwEk_sP34,2021,Reject,False,Does Adversarial Transferability Indicate Knowledge Transferability?,"[""Kaizhao Liang"", ""Jacky Y. Zhang"", ""Oluwasanmi O Koyejo"", ""Bo Li""]","[""adversarial transferability"", ""knowledge transferability""]",We investigate and give an affirmative answer to the question: 'does adversarial transferability indicate knowledge transferability?',,,,
ZaI7Rd11G4S,2022,Reject,False,Embedding Compression with Hashing for Efficient Representation Learning in Graph,"['Chin-Chia Michael Yeh', 'Mengting Gu', 'Yan Zheng', 'Huiyuan Chen', 'Javid Ebrahimi', 'Zhongfang Zhuang', 'Junpeng Wang', 'Liang Wang', 'Wei Zhang']","[""embedding compression"", ""hashing"", ""graph""]",A embedding compression method is developed to represent each node in a graph compactly for graph neural networks like GraphSage.,,,,
ZaVVVlcdaN,2022,Accept (Poster),False,Reducing the Communication Cost of Federated Learning through Multistage Optimization,"['Charlie Hou', 'Kiran Koshy Thekumparampil', 'Giulia Fanti', 'Sewoong Oh']","[""Federated Learning"", ""Optimization"", ""Distributed Optimization""]",,,,,
ZaYZfu8pT_N,2021,Reject,False,Non-iterative Parallel Text Generation via Glancing Transformer,"[""Lihua Qian"", ""Hao Zhou"", ""Yu Bao"", ""Mingxuan Wang"", ""Lin Qiu"", ""Weinan Zhang"", ""Yong Yu"", ""Lei Li""]",[],,,,,
Zae_OHNq-y,2022,Reject,True,Imbalanced Adversarial Training with Reweighting,"['Wentao Wang', 'Han Xu', 'Xiaorui Liu', 'Yaxin Li', 'Bhavani Thuraisingham', 'Jiliang Tang']","[""imbalanced data"", ""robustness"", ""adversarial training""]",This paper investigates adversarial robustness under imbalanced data distribution,2107.13639,cs.LG,2021-07-28 20:51:36+00:00,2021-07-28 20:51:36+00:00
Zbc-ue9p_rE,2021,Accept (Poster),False,Refining Deep Generative Models via Discriminator Gradient Flow,"[""Abdul Fatir Ansari"", ""Ming Liang Ang"", ""Harold Soh""]","[""gradient flows"", ""generative models"", ""GAN"", ""VAE"", ""Normalizing Flow""]",A method of refining samples from deep generative models using the discriminator gradient flow of f-divergences.,2012.00780,cs.LG,2020-12-01 19:10:15+00:00,2021-06-05 04:45:44+00:00
Zc36Mbb8G6,2021,Reject,False,Data Instance Prior for Transfer Learning in GANs,"[""Puneet Mangla"", ""Nupur Kumari"", ""Mayank Singh"", ""Vineeth N. Balasubramanian"", ""Balaji Krishnamurthy""]","[""GAN"", ""transfer learning"", ""fewshot learning"", ""image generation""]",,,,,
ZcKPWuhG6wy,2021,Accept (Poster),False,Tradeoffs in Data Augmentation: An Empirical Study,"[""Raphael Gontijo-Lopes"", ""Sylvia Smullin"", ""Ekin Dogus Cubuk"", ""Ethan Dyer""]","[""Generalization"", ""Interpretability"", ""Understanding Data Augmentation""]",We quantify mechanisms of how data augmentation works with two metrics we introduce: Affinity and Diversity.,,,,
Zca3NK3X8G,2022,Reject,False,WaveCorr: Deep Reinforcement Learning with Permutation Invariant Policy Networks for Portfolio Management,"['Saeed Marzban', 'Erick Delage', 'Jonathan Li']","[""permutation invariance"", ""portfolio management"", ""deep reinforcement learning"", ""policy network""]",This paper develops a new permutation invariance property for deep neural network architectures and designs a new convolutional portfolio policy network architecture that better exploits cross-asset dependencies present in stock prices time series.,,,,
ZeE81SFTsl,2022,Reject,False,DAdaQuant: Doubly-adaptive quantization for communication-efficient Federated Learning,"['Robert HÃ¶nig', 'Yiren Zhao', 'Robert D. Mullins']","[""federated learning"", ""gradient compression"", ""quantization"", ""communication efficiency""]",We develop an algorithm that boosts the performance of quantization-based compression algorithms for Federated Learning.,,,,
Zf4ZdI4OQPV,2022,Accept (Poster),False,Attacking deep networks with surrogate-based adversarial black-box methods is easy,"['Nicholas A. Lord', 'Romain Mueller', 'Luca Bertinetto']","[""adversarial attacks"", ""black-box attacks"", ""network robustness"", ""network analysis""]",We present a simple and extremely effective score- and surrogate-based black-box adversarial attack which uses a specific gradient/Jacobian transfer strategy.,,,,
ZgV2C9NKk6Q,2022,Reject,False,TorchGeo: deep learning with geospatial data,"['Adam J Stewart', 'Caleb Robinson', 'Isaac A Corley', 'Anthony Ortiz', 'Juan M Lavista Ferres', 'Arindam Banerjee']","[""deep learning"", ""remote sensing"", ""geospatial data""]","We introduce TorchGeo, a PyTorch domain library providing datasets, samplers, transforms, and models for geospatial data",,,,
ZglaBL5inu,2021,Reject,False,"Laplacian Eigenspaces, Horocycles and Neuron Models on Hyperbolic Spaces","[""Ming-Xi Wang""]","[""hyperbolic learning"", ""hyperbolic neural network"", ""Poincare embedding""]",A novel spectral learning tool that can be applied to existing theoretical and experimental hyperbolic learning problems.,,,,
ZgrmzzYjMc4,2022,Reject,False,What can multi-cloud configuration learn from AutoML?,"['Malgorzata Lazuka', 'Thomas Parnell', 'Andreea Anghel', 'Haralampos Pozidis']","[""Cloud"", ""AutoML"", ""Multi-armed bandit"", ""Black box optimizers""]",,,,,
Zk3TwMJNj7,2022,Reject,False,Directional Bias Helps Stochastic Gradient Descent to Generalize in Nonparametric Model,"['Yiling Luo', 'Xiaoming Huo', 'Yajun Mei']","[""directional bias"", ""SGD"", ""RKHS"", ""nonparametric regression""]",SGD converges along the direction of the largest eigenvector of the gram matrix in nonparametric regression.,,,,
ZkC8wKoLbQ7,2022,Accept (Spotlight),False,Understanding and Preventing Capacity Loss in Reinforcement Learning,"['Clare Lyle', 'Mark Rowland', 'Will Dabney']","[""Reinforcement learning"", ""representation learning""]",We show that RL agents experience representation collapse in sparse reward environments and propose an auxiliary task that prevents this from happening and outperforms the state of the art on the Atari benchmark.,,,,
ZlIfK1wCubc,2021,Reject,False,Contrasting distinct structured views to learn sentence embeddings,"[""Antoine Simoulin"", ""Benoit Crabb\u00e9""]","[""Sentence"", ""Embeddings"", ""Structure"", ""Contrastive"", ""Multi-views""]",We propose a self-supervised method that builds sentence embeddings from the combination of diverse explicit syntactic structures. ,,,,
ZnUHvSyjstv,2022,Reject,False,On the Capacity and Superposition of Minima in Neural Network Loss Function Landscapes,"['Maximilian Paul Niroomand', 'John William Roger Morgan', 'Conor T Cafolla', 'David John Wales']","[""ensemble learning"", ""interpretability"", ""loss function landscape"", ""theoretical chemistry""]",We provide evidence that different ensemble classifiers truly specialise in different parts of the input data and based on this propose a method to solve certain problems in theoretical molecular sciences.,,,,
ZnUwk6i_iTR,2022,Reject,False,Symmetric Machine Theory of Mind,"['Melanie Sclar', 'Graham Neubig', 'Yonatan Bisk']",[],Framework for analyzing multi-agent theory of mind in settings where all agents have symmetric abilities and roles.,,,,
ZpS34ymonwE,2021,Reject,False,Meta Adversarial Training,"[""Jan Hendrik Metzen"", ""Nicole Finnie"", ""Robin Hutmacher""]","[""robustness"", ""adversarial examples"", ""adversarial training"", ""physical-world adversarial attacks"", ""adversarial patch"", ""universal perturbation""]","We propose Meta Adversarial Training (MAT), which allows efficiently training models with largely increased robustness against universal patch and universal perturbation attacks.",2101.11453,cs.LG,2021-01-27 14:36:23+00:00,2021-06-22 14:07:54+00:00
Zq2G_VTV53T,2022,Accept (Poster),False,FastSHAP: Real-Time Shapley Value Estimation,"['Neil Jethani', 'Mukund Sudarshan', 'Ian Connick Covert', 'Su-In Lee', 'Rajesh Ranganath']","[""interpretability"", ""shapley"", ""amortization"", ""explainability"", ""game theory""]","We introduce FastSHAP, a new method for estimating Shapley values in a single forward pass using an explainer model that is learned via stochastic gradient optimization using a weighted least squares-like objective function.",,,,
ZqB2GD-Ixn,2021,Reject,True,Accounting for Unobserved Confounding in Domain Generalization,"[""Alexis Bellot"", ""Mihaela van der Schaar""]","[""Causality"", ""Robust Optimization"", ""Domain Generalization""]",,2007.10653,stat.ML,2020-07-21 08:18:06+00:00,2021-05-25 09:08:49+00:00
Zr5W2LSRhD,2022,Accept (Poster),False,Constructing Orthogonal Convolutions in an Explicit Manner,"['Tan Yu', 'Jun Li', 'YUNFENG CAI', 'Ping Li']",[],,,,,
ZsZM-4iMQkH,2021,Accept (Poster),True,A unifying view on implicit bias in training linear neural networks,"[""Chulhee Yun"", ""Shankar Krishnan"", ""Hossein Mobahi""]","[""implicit bias"", ""implicit regularization"", ""convergence"", ""gradient flow"", ""gradient descent""]",We propose a unifying framework for analyzing implicit bias of linear networks and show theorems that extend existing results with less convergence assumptions.,2010.02501,cs.LG,2020-10-06 06:08:35+00:00,2021-09-10 05:33:27+00:00
Zu3iPlzCe9J,2021,Reject,False,On the Power of Abstention and Data-Driven Decision Making for Adversarial Robustness,"[""Nina Balcan"", ""Avrim Blum"", ""Dravyansh Sharma"", ""Hongyang Zhang""]","[""Adversarial Machine Learning"", ""Learning Theory""]",We develop algorithms with provable guarantees for defense against adversarial attacks that utilize abstention and also provably learn parameters to optimize over the accuracy vs. abstention trade-off.,,,,
ZumkmSpY9G4,2022,Reject,False,Bypassing Logits Bias in Online Class-Incremental Learning with a Generative Framework,"['Gehui Shen', 'Shibo Jie', 'Ziheng Li', 'Zhi-Hong Deng']","[""continual learning"", ""online class-incremental learning"", ""catastrophic forgetting"", ""deep learning""]",We propose a novel framework from the perspective of generative model to avoid logits bias problem in online class-incremental learning,,,,
ZvvxYyjfvZc,2021,Reject,False,Correcting Momentum in Temporal Difference Learning,"[""Emmanuel Bengio"", ""Joelle Pineau"", ""Doina Precup""]","[""Momentum"", ""Reinforcement Learning"", ""Temporal Difference"", ""Deep Reinforcement Learning""]","We add extra terms to momentum to correct for its staleness, this helps TD learning.",2106.03955,cs.LG,2021-06-07 20:41:15+00:00,2021-06-07 20:41:15+00:00
ZwZ3sc0qad,2021,Reject,True,On Alignment in Deep Linear Neural Networks,"[""Adityanarayanan Radhakrishnan"", ""Eshaan Nichani"", ""Daniel Bernstein"", ""Caroline Uhler""]","[""Alignment"", ""Linear Neural Networks"", ""Implicit Regularization""]","We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.",2003.06340,cs.LG,2020-03-13 15:13:37+00:00,2020-06-17 01:12:33+00:00
ZzwDy_wiWv,2021,Accept (Poster),False,Knowledge distillation via softmax regression representation learning,"[""Jing Yang"", ""Brais Martinez"", ""Adrian Bulat"", ""Georgios Tzimiropoulos""]",[],,,,,
ZzwfldvDLpC,2022,Reject,False,Let Your Heart Speak in its Mother Tongue: Multilingual Captioning of Cardiac Signals,"['Dani Kiyasseh', 'Tingting Zhu', 'David A. Clifton']","[""multilingual representation learning"", ""cardiac signal captioning""]",A multilingual cardiac signal captioning framework that generates clinical reports in multiple languages when presented with cardiac signals,,,,
_0kaDkv3dVf,2021,Accept (Spotlight),False,HW-NAS-Bench: Hardware-Aware Neural Architecture Search Benchmark,"[""Chaojian Li"", ""Zhongzhi Yu"", ""Yonggan Fu"", ""Yongan Zhang"", ""Yang Zhao"", ""Haoran You"", ""Qixuan Yu"", ""Yue Wang"", ""Cong Hao"", ""Yingyan Lin""]","[""Hardware-Aware Neural Architecture Search"", ""AutoML"", ""Benchmark""]",A Hardware-Aware Neural Architecture Search Benchmark,,,,
_2CLeIIYMPd,2022,Reject,False,Discovering Latent Network Topology in Contextualized Representations with Randomized Dynamic Programming,"['Yao Fu', 'Mirella Lapata']","[""latent structures"", ""dynamic programming"", ""approximate inference"", ""randomization"", ""memory efficiency"", ""contextualized representations"", ""network topology"", ""paraphrase generation"", ""bertology""]",We scale up DP-based inference with randomization then use it to discover a latent network within BERT representation space.,,,,
_3bwD_KXl5K,2022,Reject,False,WaveSense: Efficient Temporal Convolutions with Spiking Neural Networks for Keyword Spotting,"['Philipp Weidel', 'Sadique Sheik']","[""spiking"", ""keyword spotting"", ""temporal processing"", ""streaming"", ""audio"", ""neuromorphic"", ""wavenet"", ""wavesense"", ""always-on"", ""low-power"", ""temporal convolution""]",The paper proposes efficient temporal convolutions in spiking neural networks and reports SOTA accuracy on keyword spotting tasks.,,,,
_4D8IVs7yO8,2022,Reject,False,Dense-to-Sparse Gate for Mixture-of-Experts,"['Xiaonan Nie', 'Shijie Cao', 'Xupeng Miao', 'Lingxiao Ma', 'Jilong Xue', 'Youshan Miao', 'Zichao Yang', 'Zhi Yang', 'Bin CUI']","[""Deep Learning"", ""Transformer"", ""Mixture of Experts.""]","Dense-To-Sparse-Gate begins as a dense gate that routes tokens to all experts, then gradually and adaptively becomes sparser while routes to fewer experts. ",,,,
_4GFbtOuWq-,2022,Accept (Poster),True,Capacity of Group-invariant Linear Readouts from Equivariant Representations: How Many Objects can be Linearly Classified Under All Possible Views?,"['Matthew Farrell', 'Blake Bordelon', 'Shubhendu Trivedi', 'Cengiz Pehlevan']","[""representation learning"", ""perceptron capacity"", ""perceptual manifolds"", ""equivariance"", ""cover's theorem"", ""vc dimension""]",We compute the fraction of linearly separable dichotomies of representations formed by group actions and apply these results to intermediate representations of convolutional neural networks.,2110.07472,cs.LG,2021-10-14 15:46:53+00:00,2022-02-05 17:24:58+00:00
_55bCXzj3D9,2022,Reject,False,Exploring and Evaluating Personalized Models for Code Generation,"['Andrei Zlotchevski', 'Dawn Drain', 'Alexey Svyatkovskiy', 'Colin Clement', 'Neel Sundaresan', 'Michele Tufano']","[""code generation"", ""custom models"", ""NLP""]",,,,,
_5js_8uTrx1,2022,Accept (Poster),True,Towards Evaluating the Robustness of Neural Networks Learned by Transduction,"['Jiefeng Chen', 'Xi Wu', 'Yang Guo', 'Yingyu Liang', 'Somesh Jha']","[""adversarial robustness"", ""transductive learning"", ""test-time defense"", ""dynamic defense"", ""attacking model spaces""]",Exploring evaluating the adversarial robustness of transductive-learning based defenses. ,2110.14735,cs.LG,2021-10-27 19:39:50+00:00,2021-10-27 19:39:50+00:00
_67HnXYixmN,2022,Reject,False,Nested Policy Reinforcement Learning for Clinical Decision Support,"['Aishwarya Mandyam', 'Andrew Jones', 'Krzysztof Laudanski', 'Barbara Engelhardt']","[""machine learning for healthcare"", ""reinforcement learning""]","We introduce nested policy fitted Q-iteration (NFQI), an off-policy RL framework that finds optimal policies in environments that a nested structure.",,,,
_77KiX2VIEg,2021,Reject,False,On the Effectiveness of Deep Ensembles for Small Data Tasks,"[""Lorenzo Brigato"", ""Luca Iocchi""]","[""small data"", ""deep learning"", ""ensembles"", ""classification""]",Deep ensembles of relatively small deep networks improve the state of the art of image classification problems in small data regimes,,,,
_7YnfGdDVML,2022,Reject,True,DCoM: A Deep Column Mapper for Semantic Data Type Detection,"['Subhadip Maji', 'Swapna sourav Rout', 'Sudeep Choudhary']","[""Semantic Data Type Detection"", ""Machine Learning"", ""Natural Language Processing"", ""Semantic Column Tagging"", ""Sensitive Data Detection"", ""Column Search""]",This paper introduces a novel NLP-based approach to automatically detect the semantic type data i.e. prediction of column headers given the column values.,2106.12871,cs.LG,2021-06-24 10:12:35+00:00,2021-06-24 10:12:35+00:00
_B8Jd7Nqs7R,2022,Reject,False,Improved Generalization Bound for Deep Neural Networks Using Geometric Functional Analysis,"['Phani raj Chinnalingu', 'Rajarshi Banerjee']","[""Generalization bounds"", ""Geometric functional analysis""]",We provide improved generalization bounds for deep neural networks using sophisticated tools from Geometric functional analysis,,,,
_BNiN4IjC5,2022,Accept (Poster),True,PriorGrad: Improving Conditional Denoising Diffusion Models with Data-Dependent Adaptive Prior,"['Sang-gil Lee', 'Heeseung Kim', 'Chaehun Shin', 'Xu Tan', 'Chang Liu', 'Qi Meng', 'Tao Qin', 'Wei Chen', 'Sungroh Yoon', 'Tie-Yan Liu']","[""diffusion-based model"", ""generative model"", ""speech synthesis""]",We improve the efficiency of diffusion-based conditional generative models for audio by using data-dependent non-standard Gaussian as a prior.,2106.06406,stat.ML,2021-06-11 14:04:03+00:00,2021-06-11 14:04:03+00:00
_CfpJazzXT2,2022,Accept (Oral),False,F8Net: Fixed-Point 8-bit Only Multiplication for Network Quantization,"['Qing Jin', 'Jian Ren', 'Richard Zhuang', 'Sumant Hanumante', 'Zhengang Li', 'Zhiyu Chen', 'Yanzhi Wang', 'Kaiyuan Yang', 'Sergey Tulyakov']","[""Neural Network Quantization"", ""Fixed-Point Arithmetic""]",We propose a method for neural network quantization with only 8-bit fixed-point multiplication.,2202.05239,cs.CV,2022-02-10 18:48:56+00:00,2022-02-10 18:48:56+00:00
_CrmWaJ2uvP,2021,Reject,False,Recurrent Neural Network Architecture based on Dynamic Systems Theory for Data Driven Modelling of Complex Physical Systems,"[""Deniz Neufeld""]","[""dynamic system identification"", ""recurrent networks"", ""explainable AI"", ""time series modelling""]",A new recurrent network structure consisting of basic linear building blocks from dynamic system identification.,,,,
_DqUHcsQfaE,2022,Reject,False,Inference-Time Personalized Federated Learning,"['Ohad Amosy', 'Gal Eyal', 'Gal Chechik']","[""Federated learning"", ""Personalized federated learning"", ""hypernetworks""]",Using hypernetworks to generalize personalized federated learning to a novel client at inference time,,,,
_Ea-ECV6Vkm,2021,Reject,False,Consistent Instance Classification for Unsupervised Representation Learning,"[""Depu Meng"", ""Zigang Geng"", ""Zhirong Wu"", ""Bin Xiao"", ""Houqiang Li"", ""Jingdong Wang""]",[],,,,,
_F9xpOrqyX9,2022,Accept (Poster),False,Spread Spurious Attribute: Improving Worst-group Accuracy with Spurious Attribute Estimation ,"['Junhyun Nam', 'Jaehyung Kim', 'Jaeho Lee', 'Jinwoo Shin']","[""worst-group loss minimization"", ""spurious correlation""]",Using a small amount of attribute annotated samples for training can boost worst-group performance in the presence of spurious correlation.,,,,
_HFPHFbJrP-,2022,Reject,False,Certified Adversarial Robustness Under the Bounded Support Set,"['Yiwen Kou', 'Qinyuan Zheng', 'Yisen Wang']",[],,,,,
_HsKf3YaWpG,2021,Reject,True,Uniform Priors for Data-Efficient Transfer,"[""Samarth Sinha"", ""Karsten Roth"", ""Anirudh Goyal"", ""Marzyeh Ghassemi"", ""Hugo Larochelle"", ""Animesh Garg""]","[""Meta Learning"", ""Deep Metric Learning"", ""Transfer Learning""]","We observe that the uniformity of embeddings is important for better transfer and adaptation, and propose a simple technique to promote uniformity which improve meta learning, deep metric learning, zero-shot domain adaptation and OOD generalization.",2006.16524,cs.LG,2020-06-30 04:39:36+00:00,2020-10-13 12:21:07+00:00
_IM-AfFhna9,2021,Accept (Poster),False,Generalized Variational Continual Learning,"[""Noel Loo"", ""Siddharth Swaroop"", ""Richard E Turner""]",[],We generalize VCL and Online-EWC and combine with task-specific FiLM layers,,,,
_K6rwRjW9WO,2022,Reject,False,RieszNet and ForestRiesz: Automatic Debiased Machine Learning with Neural Nets and Random Forests,"['Victor Quintas-Martinez', 'Victor Chernozhukov', 'Vasilis Syrgkanis', 'Whitney Newey']",[],"We implement an automatic debiasing procedure for causal and policy effects based on automatically learning their corresponding Riesz representation, using Neural Nets and Random Forests.",,,,
_Ko4kT3ckWy,2022,Reject,False,Increase and Conquer: Training Graph Neural Networks on Growing Graphs,"['Juan Cervino', 'Luana Ruiz', 'Alejandro Ribeiro']","[""Machine Learning"", ""Graph Neural Networks""]",The paper describes a way to train GNNs on a sequence of growing graphs. ,,,,
_L6b4Qzn5bp,2021,Reject,False,Beyond COVID-19 Diagnosis: Prognosis with Hierarchical Graph Representation Learning,"[""CHEN LIU"", ""Jinze Cui"", ""Dailin Gan"", ""Guosheng Yin""]","[""COVID-19 Diagnosis"", ""COVID-19 Prognosis"", ""GCN""]",,,,,
_LNdXw0BSx,2022,Reject,False,Towards Coherent and Consistent Use of Entities in Narrative Generation,"['Pinelopi Papalampidi', 'Kris Cao', 'TomÃ¡Å¡ KoÄiskÃ½']","[""language modeling"", ""narrative generation"", ""entity memory"", ""dynamic representations""]",We propose augmenting a pre-trained language model with a dynamic entity memory for increasing long-range entity coherence in narrative generation.,,,,
_MRiKN8-sw,2022,Reject,False,Tabular Data Imputation: Choose KNN over Deep Learning,"['Florian Lalande', 'Kenji Doya']","[""data imputation"", ""knn"", ""deep learning"", ""artificial neural networks"", ""digital sobriety""]",A quantitative proof that artificial neural networks are overestimated for tabular data imputation.,,,,
_MxHo0GHsH6,2021,Reject,False,Once Quantized for All: Progressively Searching for Quantized Compact Models,"[""Mingzhu Shen"", ""Feng Liang"", ""Chuming Li"", ""Chen Lin"", ""Ming Sun"", ""Junjie Yan"", ""Wanli Ouyang""]","[""quantized neural networks"", ""network architecture search"", ""compact models""]",,,,,
_O9YLet0wvN,2021,Reject,False,Closing the Generalization Gap in One-Shot Object Detection,"[""Claudio Michaelis"", ""Matthias Bethge"", ""Alexander S Ecker""]","[""One-Shot Learning"", ""Few-Shot Learning"", ""Object Detection"", ""One-Shot Object Detection"", ""Generalization""]",The generalization gap in one-shot object detection can be closed using datasets with sufficient categories.,,,,
_OGAW_hznmG,2021,Reject,False,Maximum Entropy competes with Maximum Likelihood,"[""Armen Allahverdyan""]","[""maximum entropy"", ""Bayesian statistics""]",The validity domain of the maximum entropy method is studied via tools of the Bayesian decision theory.,,,,
_PHymLIxuI,2022,Accept (Poster),True,CrossFormer: A Versatile Vision Transformer Hinging on Cross-scale Attention,"['Wenxiao Wang', 'Lu Yao', 'Long Chen', 'Binbin Lin', 'Deng Cai', 'Xiaofei He', 'Wei Liu']","[""vision transformers"", ""architecture""]",,2108.00154,cs.CV,2021-07-31 05:52:21+00:00,2021-10-08 06:56:25+00:00
_PlNmPOsUS9,2022,Reject,False,PARL: Enhancing Diversity of Ensemble Networks to Resist Adversarial Attacks via Pairwise Adversarially Robust Loss Function,"['Manaar Alam', 'Shubhajit Datta', 'Debdeep Mukhopadhyay', 'Arijit Mondal', 'Partha Pratim Chakrabarti']","[""Adversarial Attack"", ""Ensemble-based Defence"", ""Model Diversity""]",An ensemble method to enhance robustness against adversarial attacks,,,,
_PzOsP37P4T,2021,Reject,True,Generalized Gumbel-Softmax Gradient Estimator for Generic Discrete Random Variables,"[""Weonyoung Joo"", ""Dongjun Kim"", ""Seungjae Shin"", ""Il-chul Moon""]","[""Deep learning"", ""Deep generative model"", ""Unsupervised learning"", ""Gradient estimator"", ""Reparameterization trick"", ""Discrete distribution"", ""Gumbel-Softmax""]","We present a generalized version of Gumbel-Softmax reparameterization trick, which enables estimating the gradients of discrete random nodes in stochastic computational graphs.",2003.01847,cs.LG,2020-03-04 01:13:15+00:00,2020-06-09 10:38:58+00:00
_QLmakITKg,2022,Accept (Poster),False,Efficient Split-Mix Federated Learning for On-Demand and In-Situ Customization,"['Junyuan Hong', 'Haotao Wang', 'Zhangyang Wang', 'Jiayu Zhou']","[""federated learning""]",,,,,
_QdvdkxOii6,2021,Reject,False,Measuring Progress in Deep Reinforcement Learning Sample Efficiency ,"[""Florian E. Dorner""]","[""Deep Reinforcement Learning"", ""Sample Efficiency""]",We measure progress in deep reinforcement learning sample efficiency using training curves from published papers. ,2102.04881,cs.LG,2021-02-09 15:27:47+00:00,2021-02-09 15:27:47+00:00
_QnwcbR-GG,2021,Reject,False,On the Effectiveness of Weight-Encoded Neural Implicit 3D Shapes   ,"[""Thomas Ryan Davies"", ""Derek Nowrouzezahrai"", ""Alec Jacobson""]",[],Purposefully overfit neural networks are an efficient surface representation for solid 3D shapes.,,,,
_SJ-_yyes8,2022,Accept (Poster),False,Mastering Visual Continuous Control: Improved Data-Augmented Reinforcement Learning,"['Denis Yarats', 'Rob Fergus', 'Alessandro Lazaric', 'Lerrel Pinto']","[""Image-based RL"", ""Data augmentation in RL"", ""Continuous Control""]",We proposed a model-free off-policy algorithm for image-based continuous control that significantly outperforms previous methods both in sample and time complexity.,,,,
_SKUm2AJpvN,2021,Reject,False,Decoupling Representation Learning from Reinforcement Learning,"[""Adam Stooke"", ""Kimin Lee"", ""Pieter Abbeel"", ""Michael Laskin""]","[""reinforcement learning"", ""representation learning"", ""unsupervised learning""]","We introduce a new unsupervised learning task tailored for RL that, for the first time, supports representation learning fully decoupled from policy learning, as demonstrated across a range of visually diverse RL benchmarks.",,,,
_TGlfdZOHY3,2021,Reject,False,"On Episodes, Prototypical Networks, and Few-Shot Learning","[""Steinar Laenen"", ""Luca Bertinetto""]","[""few-shot learning"", ""meta-learning"", ""metric learning"", ""deep learning""]","We analysed the effectiveness of episodic learning in Prototypical Networks and found out that, despite adding complexity and hyper-parameters, it severely affects its performance.",2012.09831,cs.LG,2020-12-17 18:52:47+00:00,2020-12-17 18:52:47+00:00
_TM6rT7tXke,2021,Accept (Poster),False,Return-Based Contrastive Representation Learning for Reinforcement  Learning,"[""Guoqing Liu"", ""Chuheng Zhang"", ""Li Zhao"", ""Tao Qin"", ""Jinhua Zhu"", ""Li Jian"", ""Nenghai Yu"", ""Tie-Yan Liu""]","[""reinforcement learning"", ""auxiliary task"", ""representation learning"", ""contrastive learning""]",We propose a novel contrastive learning based auxiliary task which forces the learnt representations to discriminate state-action pairs with different returns and achieve superior performance on complex tasks in terms of sample effiency.,,,,
_Tf6jEzbH9,2021,Reject,False,Context-Agnostic Learning Using Synthetic Data,"[""Charles Jin"", ""Martin Rinard""]","[""machine learning"", ""synthetic data"", ""few-shot learning"", ""domain adaptation""]",We develop a new setting for learning in which we train image classifiers from scratch using only a single synthetic example per class.,,,,
_Vn-mKDipa1,2022,Reject,True,Hierarchically Regularized Deep Forecasting,"['Biswajit Paria', 'Rajat Sen', 'Amr Ahmed', 'Abhimanyu Das']","[""hierarchical time series"", ""deep learning""]",A end-to-end deep learning approach for hierarchical time series forecasting.,2106.07630,cs.LG,2021-06-14 17:38:16+00:00,2021-10-12 16:01:05+00:00
_WnwtieRHxM,2021,Accept (Spotlight),False,Understanding the role of importance weighting for deep learning,"[""Da Xu"", ""Yuting Ye"", ""Chuanwei Ruan""]","[""Importance Weighting"", ""Deep Learning"", ""Implicit Bias"", ""Gradient Descent"", ""Learning Theory""]",We study the theoretical properties of importance weighting for deep learning.,2103.15209,cs.LG,2021-03-28 19:44:47+00:00,2021-03-28 19:44:47+00:00
_Wzj0J2xs2D,2022,Accept (Poster),False,CURVATURE-GUIDED DYNAMIC SCALE NETWORKS FOR MULTI-VIEW  STEREO,"['Khang Truong Giang', 'Soohwan Song', 'Sungho Jo']","[""multi-view stereo"", ""3D reconstruction"", ""dynamic scale""]",This paper proposes a dynamic scale feature network to address the matching ambiguity problem in Multi-view stereo (MVS) and then designs an efficient MVS network to predict the depth maps.,2112.05999,cs.CV,2021-12-11 14:41:05+00:00,2022-01-29 07:49:53+00:00
_X90SIKbHa,2022,Accept (Poster),False,A Class of Short-term Recurrence Anderson Mixing Methods and Their Applications,"['Fuchao Wei', 'Chenglong Bao', 'Yang Liu']","[""Anderson mixing"", ""sequence acceleration"", ""fixed-point iteration"", ""nonconvex optimization"", ""stochastic optimization""]",We develop a novel class of short-term recurrence Anderson mixing methods and validate its effectiveness in several applications including training neural networks.,,,,
_XNtisL32jv,2022,Accept (Poster),False,Temporal Efficient Training of Spiking Neural Network via Gradient Re-weighting,"['Shikuang Deng', 'Yuhang Li', 'Shanghang Zhang', 'Shi Gu']","[""Spiking Neural Networks"", ""Direct Training"", ""Surrogate Gradient"", ""Generalizability""]","This paper provides a novel temporal efficient training method for SNN, which significantly improves performance by modifying the optimization target.",,,,
_XYzwxPIQu6,2021,Accept (Spotlight),True,Identifying nonlinear dynamical systems with multiple time scales and long-range dependencies,"[""Dominik Schmidt"", ""Georgia Koppe"", ""Zahra Monfared"", ""Max Beutelspacher"", ""Daniel Durstewitz""]","[""nonlinear dynamical systems"", ""recurrent neural networks"", ""attractors"", ""computational neuroscience"", ""vanishing gradient problem"", ""LSTM""]",We introduce a novel regularization for ReLU-based vanilla RNN that mitigates the exploding vs. vanishing gradient problem while retaining a simple mathematical structure that makes the RNN's dynamical systems properties partly analytically tractable,1910.03471,cs.LG,2019-10-08 15:41:50+00:00,2021-03-12 15:33:07+00:00
_X_4Akcd8Re,2021,Accept (Poster),True,Learning Long-term Visual Dynamics with Region Proposal Interaction Networks,"[""Haozhi Qi"", ""Xiaolong Wang"", ""Deepak Pathak"", ""Yi Ma"", ""Jitendra Malik""]","[""dynamics prediction"", ""interaction networks"", ""physical reasoning""]","We propose Region Proposal Interaction Networks for physical interaction prediction, which is applied across both simulation and real world environments for long-range prediction and planning.",2008.02265,cs.CV,2020-08-05 17:48:00+00:00,2021-04-02 20:12:04+00:00
_Xaf6zMDsHL,2022,Reject,False,Momentum Contrastive Autoencoder: Using Contrastive Learning for Latent Space Distribution Matching in WAE,"['Devansh Arpit', 'Aadyot Bhatnagar', 'Huan Wang', 'Caiming Xiong']","[""Wasserstein autoencoder"", ""contrastive learning""]","We show that WAE objective can be achieved by applying contrastive learning objective on the latent space of an auto encoder, and this algorithm achieves faster convergence and more stable optimization compared with existing algorithms for WAE.",,,,
_ZoDJyBBp7z,2022,Reject,True,Feature Flow Regularization: Improving Structured  Sparsity in Deep Neural Networks,"['Yue Wu', 'Yuan Lan', 'Luchan Zhang', 'Yang Xiang']","[""structured pruning""]",We propose a new regularization (FFR) on the trajectory connecting the features of hidden layers to improve the structured sparsity for DNN pruning..,2106.02914,cs.CV,2021-06-05 15:00:50+00:00,2021-10-07 14:22:42+00:00
__ObYt4753c,2022,Reject,False,A Simple Approach to Adversarial Robustness in Few-shot Image Classification ,"['Akshayvarun Subramanya', 'Hamed Pirsiavash']","[""Few-shot learning"", ""Robustness"", ""Image Classification""]",We present a simple transfer-learning based approach to learn robust few-shot classifiers.,,,,
_adSMszz_g9,2021,Reject,False,Memformer: The Memory-Augmented Transformer,"[""Qingyang Wu"", ""Zhenzhong Lan"", ""Jing Gu"", ""Zhou Yu""]","[""transformer"", ""language model"", ""memory networks""]","We propose Memformer, a memory-augmented transformer with a linear time complexity and constant space complexity.",,,,
_b8l7rVPe8z,2021,Reject,True,Relevance Attack on Detectors,"[""Sizhe Chen"", ""Fan He"", ""Xiaolin Huang"", ""Kun Zhang""]","[""adversarial attack"", ""relevance map"", ""object detection"", ""transferability"", ""black-box attack""]","We design a Relevance Attack on Detectors, a high-transferable attack framework with the state-of-the-art performance.",2008.06822,cs.CV,2020-08-16 02:44:25+00:00,2021-08-04 10:08:48+00:00
_bF8aOMNIdu,2021,Reject,False,Robust Temporal Ensembling,"[""Abel Brown"", ""Benedikt Schifferer"", ""Robert DiPietro""]","[""learning with noise"", ""robust task loss"", ""consistency regularization""]","We present robust temporal ensembling (RTE), a state-of-the-art method for learning with noisy labels that combines robust task loss, temporal pseudo-labeling, and a new form of consistency regularization.",2109.14563,cs.CV,2021-09-29 16:59:36+00:00,2021-09-29 16:59:36+00:00
_cadenVdKzF,2021,Reject,False,"Self-supervised Contrastive Zero to Few-shot Learning from Small, Long-tailed Text data","[""Nils Rethmeier"", ""Isabelle Augenstein""]","[""self-supervised pretraining"", ""zero-shot"", ""few-shot"", ""text-to-text"", ""contrastive self-supervised learning"", ""small data"", ""long-tail"", ""multi-label classification"", ""NLP""]","We show the benefits of self-supervised small data pretraining for zero and few-shot learning and that increased self-supervision, rather than data size can boost zero-shot learning without defaulting to pretraining massive external data resources.",,,,
_cz2R6QnpQJ,2022,Reject,False,Noise Reconstruction and Removal Network: A New Way to Denoise FIB-SEM Images,"['Katya Giannios', 'Abhishek Chaurasia', 'Bambi DeLaRosa', 'Guillaume THIBAULT', 'Jessica L. Riesterer', 'Erin S Stempinski', 'Terence P Lo', 'Joe W Gray']","[""Neural Network"", ""CNN"", ""LSTM"", ""Unsupervised learning"", ""Denoising"", ""FIB-SEM""]",A fully unsupervised network for denoising a sequence of scanning electron microscopy images. ,,,,
_dXmN3FV--0,2022,Reject,False,Lottery Ticket Structured Node Pruning for Tabular Datasets,"['Ryan Bluteau', 'Robin Gras', 'Mitchel Paulin', 'Zachary Innes']","[""Lottery Ticket Hypothesis"", ""Tabular"", ""Pruning""]",We prune tabular models to find lottery ticket weights that can generate a pruned network that outperforms the original in terms of training time and inference time while maintaining accuracy.,,,,
_fLxZ6VpXTH,2022,Reject,False,Stabilized Likelihood-based Imitation Learning via Denoising Continuous Normalizing Flow,"['Xin Zhang', 'Yanhua Li', 'Ziming Zhang', 'Christopher Brinton', 'Zhenming Liu', 'Zhi-Li Zhang', 'Hui Lu', 'Zhihong Tian']",[],,,,,
_faKHAwA8O,2022,Reject,False,Representation Consolidation from Multiple Expert Teachers,"['Zhizhong Li', 'Avinash Ravichandran', 'Charless Fowlkes', 'Marzia Polito', 'Rahul Bhotika', 'Stefano Soatto']","[""transfer learning"", ""distillation"", ""pretraining"", ""model merging""]","We propose representation consolidation, which combines multiple models into one without data replay, and maximizes its representation power rather than emulating old modelsâ input-output functionality.",,,,
_gZ8dG4vOr9,2022,Reject,False,Pruning Compact ConvNets For Efficient Inference,"['Sayan Ghosh', 'Karthik Prasad', 'Xiaoliang Dai', 'Peizhao Zhang', 'Bichen Wu', 'Graham Cormode', 'Peter Vajda']","[""pruning"", ""neural networks"", ""computations"", ""latency"", ""imagenet""]",We can compress ConvNets such as FBNetV3 networks optimized by NAS further through pruning to improve on state-of-the-art.,,,,
_gZf4NEuf0H,2022,Reject,False,Towards Understanding the Condensation of Neural Networks at Initial Training,"['Zhiqin Xu', 'Hanxu Zhou', 'Tao Luo', 'Yaoyu Zhang']","[""neural networks"", ""training"", ""condensation dynamics"", ""implicit regularization""]",The regularity of activation functions with small initialization explains the initial condensation of neural networks. ,,,,
_hszZbt46bT,2022,Accept (Poster),False,Anomaly Detection for Tabular Data with Internal Contrastive Learning,"['Tom Shenkar', 'Lior Wolf']","[""Anomaly detection"", ""Tabular data""]", An anomaly detection method based on the ability to predict the masked out part in a vector. ,,,,
_i3ASPp12WS,2021,Accept (Poster),False,Online Adversarial Purification based on Self-supervised Learning,"[""Changhao Shi"", ""Chester Holtz"", ""Gal Mishne""]","[""Adversarial Robustness"", ""Self-Supervised Learning""]",,2101.09387,cs.LG,2021-01-23 00:19:52+00:00,2021-01-23 00:19:52+00:00
_ixHFNR-FZ,2022,Reject,False,Adversarially Robust Models may not Transfer Better: Sufficient Conditions for Domain Transferability from the View of Regularization,"['Xiaojun Xu', 'Jacky Y. Zhang', 'Evelyn Ma', 'Danny Son', 'Oluwasanmi O Koyejo', 'Bo Li']","[""Domain transferability"", ""model regularization""]",,,,,
_j4hwbj6Opj,2022,Reject,False,3D Meta-Registration: Meta-learning 3D Point Cloud Registration Functions,"['Yu Hao', 'Yi Fang']",[],,,,,
_jMtny3sMKU,2022,Accept (Poster),False,Generalizing Few-Shot NAS with Gradient Matching,"['Shoukang Hu', 'Ruochen Wang', 'Lanqing HONG', 'Zhenguo Li', 'Cho-Jui Hsieh', 'Jiashi Feng']",[],,,,,
_kJXRDyaU0X,2022,Reject,False,What Would the Expert $do(\cdot)$?: Causal Imitation Learning,"['Gokul Swamy', 'Sanjiban Choudhury', 'Drew Bagnell', 'Steven Wu']","[""imitation learning"", ""causal inference"", ""reinforcement learning""]",We develop algorithms for imitation learning from data that was corrupted by unobserved confounders.,,,,
_kxlwvhOodK,2021,Accept (Poster),True, Decentralized Attribution of Generative Models,"[""Changhoon Kim"", ""Yi Ren"", ""Yezhou Yang""]","[""GANs"", ""Generative Model"", ""Deepfake"", ""Model Attribution""]",This paper investigates the feasibility of decentralized attribution of generative models.,2010.13974,cs.CV,2020-10-27 01:03:45+00:00,2021-04-28 13:04:51+00:00
_lV1OrJIgiG,2021,Reject,False,Model-based Navigation in Environments with Novel Layouts Using Abstract $2$-D Maps,"[""Linfeng Zhao"", ""Lawson L. S. Wong""]",[],,,,,
_l_QjPGN5ye,2022,Accept (Poster),False,The Boltzmann Policy Distribution: Accounting for Systematic Suboptimality in Human Models,"['Cassidy Laidlaw', 'Anca Dragan']","[""human model"", ""boltzmann rationality"", ""suboptimality"", ""HRI"", ""human-robot collaboration"", ""generative models"", ""reinforcement learning"", ""deep RL""]",We propose modeling human behavior with a Boltzmann distribution over policiesânot trajectoriesâand show it is more accurate and useful.,,,,
_mQp5cr_iNy,2021,Accept (Poster),False,Adversarially Guided Actor-Critic,"[""Yannis Flet-Berliac"", ""Johan Ferret"", ""Olivier Pietquin"", ""Philippe Preux"", ""Matthieu Geist""]",[],This method introduces an adversary to the actor-critic framework that drives the agent to explore more efficiently in hard-exploration tasks.,,,,
_ojjh-QFiFr,2021,Reject,False,"Language-Mediated, Object-Centric Representation Learning","[""Ruocheng Wang"", ""Jiayuan Mao"", ""Samuel Gershman"", ""Jiajun Wu""]","[""Object-Centric Representation Learning"", ""Concept Learning""]","We present a framework for learning disentangled, object-centric scene representations from vision and language.",,,,
_ptUyYP19mP,2021,Reject,False,BeBold: Exploration Beyond the Boundary of Explored Regions,"[""Tianjun Zhang"", ""Huazhe Xu"", ""Xiaolong Wang"", ""Yi Wu"", ""Kurt Keutzer"", ""Joseph E. Gonzalez"", ""Yuandong Tian""]","[""reinforcement learning"", ""exploration""]",,2012.08621,cs.LG,2020-12-15 21:26:54+00:00,2020-12-15 21:26:54+00:00
_qJXkf347k,2021,Reject,False,Reinforcement Learning Based Asymmetrical DNN Modularization for Optimal Loading,"[""Brijraj Singh"", ""Yash Jain"", ""Mayukh Das"", ""Praveen Doreswamy Naidu""]","[""DNN Compression"", ""Loading time""]",This work proposes an application of reinforcement learning for reducing the DNN loading time.,,,,
_qc3iqcq-ps,2022,Reject,True,On the Evolution of Neuron Communities in a Deep Learning Architecture,"['Sakib Mostafa', 'Debajyoti Mondal']","[""explainable ai"", ""deep learning""]",In this paper we have analyzed the activation pattern of deep neural networks and showed that the modularity and entropy of the activation pattern can provide new insights into the deep learning models' performances.,2106.04693,cs.LG,2021-06-08 21:09:55+00:00,2021-10-09 01:00:09+00:00
_qoQkWNEhS,2021,Reject,False,Ricci-GNN: Defending Against Structural Attacks Through a Geometric Approach,"[""Ze Ye"", ""Tengfei Ma"", ""Chien-Chun Ni"", ""Kin Sum Liu"", ""Jie Gao"", ""Chao Chen""]","[""Deep Learning"", ""Graph Convolution"", ""Ricci Flow"", ""Robustness""]",Improve the robustness of graph neural network,,,,
_sCOYXNwaI,2021,Reject,False,Diffeomorphic Template Transformers,"[""Tycho F.A. van der Ouderaa"", ""Ivana Isgum"", ""Wouter B. Veldhuis"", ""Bob D. De Vos"", ""Pim Moeskops""]",[],We propose a special kind of spatial transformer with diffeomorphic transformations and show that it can be particularly useful in certain classification and segmentation tasks.,,,,
_sSHg203jSu,2021,Reject,False,Data-aware Low-Rank Compression for Large NLP Models,"[""Patrick CHen"", ""Hsiang-Fu Yu"", ""Inderjit S Dhillon"", ""Cho-Jui Hsieh""]",[],,,,,
_uCb2ynRu7Y,2022,Accept (Poster),False,Path Integral Sampler: A Stochastic Control Approach For Sampling,"['Qinsheng Zhang', 'Yongxin Chen']","[""Sampling"", ""Path Integral"", ""Stochastic Differential Equation"", ""MCMC""]","We present Path Integral Sampler~(PIS), an efficient algorithm to draw samples from unnormalized probability density functions. ",,,,
_xwr8gOBeV1,2022,Accept (Spotlight),True,Geometric and Physical Quantities improve E(3) Equivariant Message Passing,"['Johannes Brandstetter', 'Rob Hesselink', 'Elise van der Pol', 'Erik J Bekkers', 'Max Welling']","[""equivariant graph neural networks"", ""steerable message passing"", ""non-linear convolutions"", ""molecular modeling"", ""covariant information""]",We generalise equivariant graph networks such that node and edge updates are able to leverage covariant information.,2110.02905,cs.LG,2021-10-06 16:34:26+00:00,2021-12-08 09:03:48+00:00
_xxbJ7oSJXX,2022,Reject,False,Offline Reinforcement Learning with Resource Constrained Online Deployment,"['Jayanth Reddy Regatti', 'Aniket Anand Deshmukh', 'Young Hun Jung', 'Frank Cheng', 'Abhishek Gupta', 'Urun Dogan']","[""Offline Reinforcement Learning"", ""Reinforcement Learning"", ""Transfer Learning"", ""Knowledge Transfer"", ""Resource Constraints""]",We identify an important challenge in offline RL with resource constraints and propose a transfer learning algorithm to improve the performance in the resource constrained setting.,,,,
_ysluXvD1M,2022,Reject,False,Equal Experience in Recommender Systems,"['Jaewoong Cho', 'Moonseok Choi', 'Changho Suh']","[""Fairness"", ""Recommender systems""]",Introducing a new fairness notion and the optimization framework (which respects the notion) in recommender systems. ,,,,
_zHHAZOLTVh,2021,Reject,True,A Maximum Mutual Information Framework for Multi-Agent Reinforcement Learning,"[""Woojun Kim"", ""Whiyoung Jung"", ""Myungsik Cho"", ""Youngchul Sung""]","[""Multi-agent reinforcement learning"", ""coordination"", ""mutual information""]",This paper propose a new framework for multi-agent reinforcement learning named maximum mutual information to enable the multiple agents to learn coordinated behaviors.,2006.02732,cs.MA,2020-06-04 09:43:52+00:00,2020-06-04 09:43:52+00:00
_zx8Oka09eF,2021,Accept (Poster),False,Are wider nets better given the same number of parameters?,"[""Anna Golubeva"", ""Guy Gur-Ari"", ""Behnam Neyshabur""]","[""network width"", ""over-parametrization"", ""understanding deep learning""]",We show that increasing network width leads to better performance even when the number of weights remains fixed.,,,,
a-_HfiIow3m,2021,Reject,False,Multimodal Variational Autoencoders for Semi-Supervised Learning: In Defense of Product-of-Experts,"[""Svetlana Kutuzova"", ""Oswin Krause"", ""Douglas McCloskey"", ""Mads Nielsen"", ""Christian Igel""]","[""variational autoencoder"", ""multimodal data"", ""product-of-experts"", ""semi-supervised learning""]",Product-of-experts based variational autoencoders work well for generative modelling of multiple high-dimensional modalities,2101.07240,cs.LG,2021-01-18 18:47:43+00:00,2021-07-30 11:45:08+00:00
a-xFK8Ymz5J,2021,Accept (Oral),True,DiffWave: A Versatile Diffusion Model for Audio Synthesis,"[""Zhifeng Kong"", ""Wei Ping"", ""Jiaji Huang"", ""Kexin Zhao"", ""Bryan Catanzaro""]","[""diffusion probabilistic models"", ""audio synthesis"", ""speech synthesis"", ""generative models""]","DiffWave is a versatile diffusion probabilistic model for waveform generation, which matches the state-of-the-art neural vocoder in terms of quality and can generate abundant realistic voices in time-domain without any conditional information.",2009.09761,eess.AS,2020-09-21 11:20:38+00:00,2021-03-30 19:48:38+00:00
a0SRWViFYW,2022,Reject,True,Stochastic Projective Splitting: Solving Saddle-Point Problems with Multiple Regularizers,"['Patrick R. Johnstone', 'Jonathan Eckstein', 'Thomas Flynn', 'Shinjae Yoo']","[""convex optimization"", ""min-max games"", ""saddle-point problems"", ""first-order stochastic methods"", ""proximal methods"", ""operator splitting""]",We develop a stochastic splitting method that can easily handle min-max problems with multiple regularizers and constraints,2106.13067,math.OC,2021-06-24 14:48:43+00:00,2021-06-24 14:48:43+00:00
a0yodLze7gs,2021,Reject,False,Disentangling Action Sequences: Discovering Correlated Samples,"[""Jiantao Wu"", ""Chunxiuzi Liu"", ""Lin Wang""]","[""disentanglement"", ""representation learning"", ""unsupervised"", ""inductive bias""]","We analyze the inductive biases on the data with the help of action sequences, and find that the significance of actions is correlated to the latent information.",,,,
a1m8Jba-N6l,2022,Reject,True,$k$-Mixup Regularization for Deep Learning via Optimal Transport,"['Kristjan Greenewald', 'Anming Gu', 'Mikhail Yurochkin', 'Justin Solomon', 'Edward Chien']","[""Neural networks"", ""Classification"", ""Data augmentation"", ""Optimal Transport""]",,2106.02933,cs.LG,2021-06-05 17:08:08+00:00,2021-06-05 17:08:08+00:00
a2gqxKDvYys,2021,Accept (Poster),False,Mind the Gap when Conditioning Amortised Inference in Sequential Latent-Variable Models,"[""Justin Bayer"", ""Maximilian Soelch"", ""Atanas Mirchev"", ""Baris Kayalibay"", ""Patrick van der Smagt""]","[""variational inference"", ""state-space models"", ""amortized inference"", ""recurrent networks""]",We show how a common model assumption in amortised variational inference with sequential LVMS leads to a suboptimality and how to prevent it.,2101.07046,cs.LG,2021-01-18 12:53:39+00:00,2021-03-17 16:52:01+00:00
a2rFihIU7i,2021,Reject,False,Model-based Asynchronous Hyperparameter and Neural Architecture Search,"[""Aaron Klein"", ""Louis Chi-Chun Tiao"", ""Thibaut Lienart"", ""Cedric Archambeau"", ""Matthias Seeger""]","[""Bayesian Optimization"", ""AutoML"", ""Hyperparameter Optimization"", ""Neural Architecture Search""]","We present a new, asynchronous multi-fidelty Bayesian optimization method to efficiently search for hyperparameters and architectures of neural networks.",,,,
a34GrNaYEcS,2022,Accept (Poster),False,Distributionally Robust Models with Parametric Likelihood Ratios,"['Paul Michel', 'Tatsunori Hashimoto', 'Graham Neubig']","[""distributionally robust optimization"", ""fairness"", ""deep learning"", ""robustness"", ""adversarial learning""]",We learn adversarial parametric reweightings of the training data to reliably train more robust models,,,,
a3hQPNqIFk6,2022,Reject,True,Brittle interpretations: The Vulnerability of TCAV and Other Concept-based Explainability Tools to Adversarial Attack,"['Davis Brown', 'Henry Kvinge']","[""interpretability"", ""adversarial attack""]","We identify a novel vulnerability in the deep learning interpretability pipeline, and design attacks that mislead model explanations for two well known interpretability tools.",2110.07120,cs.LG,2021-10-14 02:12:33+00:00,2021-10-14 02:12:33+00:00
a3mRgptHKZd,2022,Reject,False,Faster No-Regret Learning Dynamics for Extensive-Form Correlated Equilibrium,"['Ioannis Anagnostides', 'Gabriele Farina', 'Christian Kroer', 'Tuomas Sandholm']",[],"We present faster uncoupled no-regret learning dynamics that converge to extensive-form correlated equilibrium at a rate of $O(T^{-3/4})$, improving over the prior-best rate of $O(T^{-1/2})$",,,,
a3wKPZpGtCF,2021,Accept (Poster),True,Chaos of Learning Beyond Zero-sum and Coordination via Game Decompositions,"[""Yun Kuen Cheung"", ""Yixin Tao""]","[""Learning in Games"", ""Lyapunov Chaos"", ""Game Decomposition"", ""Multiplicative Weights Update"", ""Follow-the-Regularized-Leader"", ""Volume Analysis"", ""Dynamical Systems""]",We characterize games in which popular learning algorithms exhibit Lyapunov chaos.,2008.00540,cs.GT,2020-08-02 19:02:31+00:00,2020-08-02 19:02:31+00:00
a43otnDilz2,2022,Reject,False,KNIFE: Kernelized-Neural Differential Entropy Estimation,"['Georg Pichler', 'Pierre Colombo', 'Malik Boudiaf', 'GÃ¼nther Koliander', 'Pablo Piantanida']","[""differential entropy estimation"", ""differential entropy"", ""mutual information"", ""kernel estimation""]","We introduce and empirically evaluate KNIFE, a fully parameterized, differentiable kernel-based estimator of differential entropy.",,,,
a4E6SL1rG3F,2021,Reject,False,Optimal allocation of data across training tasks in meta-learning,"[""Georgios Batzolis"", ""Alberto Bernacchia"", ""Da-shan Shiu"", ""Michael Bromberg"", ""Alexandru Cioba""]",[],We study for the first time the problem of optimally allocating labels across tasks during meta-training,,,,
a5KvtsZ14ev,2021,Reject,False,SLAPS: Self-Supervision Improves Structure Learning for Graph Neural Networks,"[""Bahare Fatemi"", ""Seyed Mehran Kazemi"", ""Layla El Asri""]","[""Graph Neural Networks"", ""Graph Representation Learning"", ""Graph Structure Learning"", ""Self-supervision""]",Self-Supervision Improves Structure Learning for Graph Neural Networks.,,,,
a61qArWbjw_,2022,Reject,False,Scalable multimodal variational autoencoders with surrogate joint posterior,"['Masahiro Suzuki', 'Yutaka Matsuo']","[""Deep generative models"", ""multimodal learning""]",We proposed a scalable and high performance multimodal VAE in the framework of approximating inferences from arbitrary subsets of modalities to a surrogate joint posterior.,,,,
a7H7OucbWaU,2022,Accept (Poster),False,Memory Replay with Data Compression for Continual Learning,"['Liyuan Wang', 'Xingxing Zhang', 'Kuo Yang', 'Longhui Yu', 'Chongxuan Li', 'Lanqing HONG', 'Shifeng Zhang', 'Zhenguo Li', 'Yi Zhong', 'Jun Zhu']","[""Continual Learning"", ""Memory Replay"", ""Data Compression""]","We propose memory replay with data compression, which is an important yet neglected baseline and a promising direction for continual learning.",,,,
a7gkBG1m6e,2021,Reject,True,Finding Physical Adversarial Examples for Autonomous Driving with Fast and Differentiable Image Compositing,"[""Jinghan Yang"", ""Adith Boloor"", ""Ayan Chakrabarti"", ""Xuan Zhang"", ""Yevgeniy Vorobeychik""]","[""Adversarial examples"", ""autonomous driving""]","We propose a scalable and efficient approach for finding adversarial physical modifications, using a differentiable approximation for the mapping from environmental modifications to the corresponding video inputs to the controller network.",2010.08844,cs.CV,2020-10-17 18:35:32+00:00,2021-06-11 00:42:30+00:00
a9nIWs-Orh,2021,Reject,True,Deepening Hidden Representations from Pre-trained Language Models,"[""Junjie Yang"", ""hai zhao""]","[""Natural Language Processing"", ""Representation Learning""]",,1911.01940,cs.CL,2019-11-05 16:59:50+00:00,2020-04-29 13:04:59+00:00
aAY23UgDBv0,2021,Reject,True,Variational Dynamic Mixtures,"[""Chen Qiu"", ""Stephan Mandt"", ""Maja Rudolph""]","[""sequential latent variable models""]"," We develop variational dynamic mixtures (VDM): a new variational family to infer sequential latent variables, to better capture multi-modality.",2010.10403,cs.LG,2020-10-20 16:10:07+00:00,2020-12-04 11:18:26+00:00
aBAgwom5pTn,2022,Reject,False,Dynamic and Efficient Gray-Box Hyperparameter Optimization for Deep Learning,"['Martin Wistuba', 'Arlind Kadra', 'Josif Grabocka']","[""hyperparameter optimization""]",Efficient hyperparameter optimization of deep learning methods using dynamic exploration of hyperparameter settings by slowly increasing the budget.,,,,
aBO5SvgSt1,2022,Accept (Poster),False,Mirror Descent Policy Optimization,"['Manan Tomar', 'Lior Shani', 'Yonathan Efroni', 'Mohammad Ghavamzadeh']","[""Reinforcement Learning"", ""Policy Optimization""]","A theory-grounded practical algorithm for policy optimization in RL, which is conceptually simpler and performs better or on par to SOTA.",,,,
aBVxf5NaaRt,2022,Accept (Poster),False,Unrolling PALM for Sparse Semi-Blind Source Separation,"['Mohammad Fahes', 'Christophe Kervazo', 'JÃ©rÃ´me Bobin', 'Florence Tupin']","[""Algorithm Unrolling/Unfolding"", ""Blind Source Separation"", ""Sparse Representations"", ""Multi-Convex Optimization"", ""Hyper-parameter Choice""]",,2112.05694,astro-ph.IM,2021-12-10 17:40:39+00:00,2021-12-10 17:40:39+00:00
aBXzcPPOuX,2022,Accept (Poster),True,"Bundle Networks: Fiber Bundles, Local Trivializations, and a Generative Approach to Exploring Many-to-one Maps","['Nico Courts', 'Henry Kvinge']","[""generative models"", ""applications of topology to deep learning"", ""many-to-one maps"", ""invertible neural nets""]","We draw from the theory of fiber bundles in (differential) topology to create a principled approach to generative models that allow us to learn and sample from the ""fiber"" over a point in a many-to-one map.",2110.06983,cs.LG,2021-10-13 18:54:18+00:00,2022-01-31 20:48:52+00:00
aBsCjcPu_tE,2022,Accept (Poster),True,SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations,"['Chenlin Meng', 'Yutong He', 'Yang Song', 'Jiaming Song', 'Jiajun Wu', 'Jun-Yan Zhu', 'Stefano Ermon']",[],,2108.01073,cs.CV,2021-08-02 17:59:47+00:00,2022-01-05 00:07:35+00:00
aCgLmfhIy_f,2021,Accept (Poster),False,Prototypical Representation Learning for Relation Extraction,"[""Ning Ding"", ""Xiaobin Wang"", ""Yao Fu"", ""Guangwei Xu"", ""Rui Wang"", ""Pengjun Xie"", ""Ying Shen"", ""Fei Huang"", ""Hai-Tao Zheng"", ""Rui Zhang""]","[""NLP"", ""Relation Extraction"", ""Representation Learning""]",,2103.11647,cs.CL,2021-03-22 08:11:43+00:00,2021-03-22 08:11:43+00:00
aD1_5zowqV,2021,Accept (Poster),False,Learning Energy-Based Generative Models via Coarse-to-Fine Expanding and Sampling,"[""Yang Zhao"", ""Jianwen Xie"", ""Ping Li""]","[""Energy-based model"", ""generative model"", ""image translation"", ""Langevin dynamics""]",We propose a coarse-to-fine expanding and sampling strategy for training energy-based models.,,,,
aD7uesX1GF_,2022,Accept (Poster),False,Conditional Object-Centric Learning from Video,"['Thomas Kipf', 'Gamaleldin Fathy Elsayed', 'Aravindh Mahendran', 'Austin Stone', 'Sara Sabour', 'Georg Heigold', 'Rico Jonschkowski', 'Alexey Dosovitskiy', 'Klaus Greff']",[],,,,,
aDjoksTpXOP,2021,Accept (Poster),True,Deep Equals Shallow for ReLU Networks in Kernel Regimes,"[""Alberto Bietti"", ""Francis Bach""]","[""deep learning"", ""kernels"", ""approximation"", ""neural tangent kernels""]",,2009.14397,stat.ML,2020-09-30 02:37:43+00:00,2021-08-26 15:49:40+00:00
aFvG-DNPNB9,2021,Reject,False,Self-Reflective Variational Autoencoder,"[""Ifigeneia Apostolopoulou"", ""Elan Rosenfeld"", ""Artur Dubrawski""]","[""deep generative models"", ""variational inference"", ""approximate inference"", ""variational auto encoder""]",We present the first deep probabilistic model without modeling mismatches between the true and variational posterior yielding computational and predictive benefits.,,,,
aGfU_xziEX8,2021,Accept (Poster),True,Efficient Inference of Flexible Interaction in Spiking-neuron Networks,"[""Feng Zhou"", ""Yixuan Zhang"", ""Jun Zhu""]","[""neural spike train"", ""nonlinear Hawkes process"", ""auxiliary latent variable"", ""conjugacy""]",An efficient conjugate EM algorithm for nonlinear multivariate Hawkes processes based on auxiliary latent variables augmentation. ,2006.12845,stat.ML,2020-06-23 09:10:30+00:00,2021-02-20 14:27:53+00:00
aGmEDl1NWJ-,2021,Reject,False,Luring of transferable adversarial perturbations in the black-box paradigm,"[""R\u00e9mi Bernhard"", ""Pierre-Alain Mo\u00ebllic"", ""Jean-Max Dutertre""]","[""Neural Networks"", ""Adversarial Machine Learning"", ""Security""]",We propose a new approach to improve the robustness of a neural network model against black-box transfer attacks based on a deception method.,,,,
aI8VuzSvCPn,2021,Reject,True,Adversarial Synthetic Datasets for Neural Program Synthesis,"[""Alexander Suh"", ""Yuval Timen""]","[""Program Synthesis"", ""Synthetic Data"", ""Evolutionary Algorithm""]",We propose an adversarial approach to generate synthetic data for program synthesis models.,2003.10485,cs.LG,2020-03-23 18:34:15+00:00,2020-07-25 01:04:06+00:00
aJ9BXxg352,2022,Reject,True,Intriguing Properties of Input-dependent Randomized Smoothing,"['Peter SÃºkenÃ­k', 'Aleksei Kuvshinov', 'Stephan GÃ¼nnemann']","[""randomized smoothing"", ""certifiable robustness"", ""deep learning"", ""machine learning""]","We formally introduce input-dependent randomized smoothing, show that it suffers from the curse of dimensionality, prepare a framework for its practical use and test a concrete design on computer vision datasets.",2110.05365,cs.LG,2021-10-11 15:50:49+00:00,2021-10-11 15:50:49+00:00
aJLjjpi0Vty,2021,Reject,False,Collaborative Filtering with Smooth Reconstruction of the Preference Function,"[""Ali Shirali"", ""Reza Kazemi"", ""Arash Amini""]","[""collaborative filtering"", ""recommender system"", ""sampling theory""]","By putting minimal constraints on the preference function, we reconstruct ratings in two different interpretable ways.",,,,
aJ_GcB4vcT0,2022,Reject,False,Unsupervised Learning of Neurosymbolic Encoders,"['Eric Zhan', 'Jennifer J. Sun', 'Ann Kennedy', 'Yisong Yue', 'Swarat Chaudhuri']","[""unsupervised learning"", ""representation learning"", ""neurosymbolic program synthesis""]",We learn neurosymbolic encoders with symbolic components represented as programs from a domain-specific language.,,,,
aKZeBGUJXlH,2022,Reject,False,Gradient Broadcast Adaptation: Defending against the backdoor attack in pre-trained models,"['Tianyu Chen', 'Haoyi Zhou', 'He Mingrui', 'Jianxin Li']","[""backdoor attacks"", ""deep learning security"", ""pre-trained models""]",We propose a novel adaptation method for pre-trained language models to defend against backdoor attacks.,,,,
aKt7FHPQxVV,2021,Reject,False,Efficient Differentiable Neural Architecture Search with Model Parallelism,"[""Yi-Wei Chen"", ""Qingquan Song"", ""Xia Hu""]","[""Neural Architecture Search"", ""Model Parallel""]","We scale up neural architecture search with consecutive model parallel, running 1.2x faster than using other model parallelism",,,,
aLtty4sUo0o,2021,Reject,False,Quickest change detection for multi-task problems under unknown parameters,"[""Firas Jarboui"", ""Vianney Perchet""]","[""Quickest Change detection"", ""Parametric approach"", ""Multi-task""]",Quickest change detection under unknown pre- and post- change parameters.,,,,
aM7l2S2s5pk,2022,Reject,False,Offline-Online Reinforcement Learning: Extending Batch and Online RL,"['Maryam Hashemzadeh', 'Wesley Chung', 'Martha White']","[""Reinforcement Learning"", ""Batch RL"", ""Online RL"", ""Offline RL""]",We explore a novel setting combining batch and online RL.,,,,
aMaQjwz5IXI,2022,Reject,True,Style Equalization: Unsupervised Learning of Controllable Generative Sequence Models ,"['Jen-Hao Rick Chang', 'Ashish Shrivastava', 'Hema Swetha Koppula', 'Xiaoshuai Zhang', 'Oncel Tuzel']","[""Controllable sequence models"", ""Text to speech"", ""Text to handwriting""]",We propose a controllable generative sequence model that enables us to control content and style separately in text-to-speech and text-to-handwriting models.,2110.02891,cs.LG,2021-10-06 16:17:57+00:00,2021-10-06 16:17:57+00:00
aNCZ8151BjY,2022,Reject,False,Design and Evaluation for Robust Continual Learning,"['Yeu-Shin Fu', 'Josh Milthorpe']","[""Continual Learning"", ""robust experimental protocol"", ""task oracle"", ""task identifier""]",,,,,
aOX3a9q3RVV,2022,Accept (Poster),False,Divisive Feature Normalization Improves Image Recognition Performance in AlexNet,"['Michelle Miller', 'SueYeon Chung', 'Kenneth D. Miller']","[""divisive normalization"", ""AlexNet"", ""ImageNet"", ""CIFAR-100"", ""manifold capacity"", ""sparsity"", ""receptive fields"", ""Batch Normalization"", ""Group Normalization"", ""Layer Normalization""]","DIVISIVE FEATURE NORMALIZATION IMPROVES IMAGE RECOGNITION PERFORMANCE AND IN- CREASES MANIFOLD CAPACITY, SPARSITY, AND LOW-FREQUENCY REPRESENTATION IN DEEP NETS",,,,
aPOpXlnV1T,2022,Accept (Poster),False,On the Pitfalls of Heteroscedastic Uncertainty Estimation with Probabilistic Neural Networks,"['Maximilian Seitzer', 'Arash Tavakoli', 'Dimitrije Antic', 'Georg Martius']","[""Uncertainty Estimation"", ""Probabilistic Neural Networks"", ""Aleatoric Uncertainty"", ""Heteroscedastic Uncertainty"", ""Analysis""]",We analyse problems with the training objective of probabilistic neural networks and propose a fix in the form of a new loss function.,,,,
aRTRjVPkm-,2021,Reject,True,Language Models are Open Knowledge Graphs,"[""Chenguang Wang"", ""Xiao Liu"", ""Dawn Song""]","[""Language Models"", ""Knowledge Graphs"", ""Information Extraction""]","This paper shows how to construct knowledge graphs (KGs) from pre-trained language models (e.g., BERT, GPT-2/3), without human supervision. ",2010.11967,cs.CL,2020-10-22 18:01:56+00:00,2020-10-22 18:01:56+00:00
aTzMi4yV_RO,2022,Accept (Poster),True,Do Not Escape From the Manifold: Discovering the Local Coordinates on the Latent Space of GANs,"['Jaewoong Choi', 'Junho Lee', 'Changyeon Yoon', 'Jung Ho Park', 'Geonho Hwang', 'Myungjoo Kang']","[""generative adversarial network"", ""disentanglement"", ""semantic factorization"", ""latent space control"", ""image manipulation"", ""grassmannian""]",We propose a method for finding local-geometry-aware traversal directions on the intermediate latent space of Generative Adversarial Networks (GANs).,2106.06959,cs.CV,2021-06-13 10:29:42+00:00,2022-02-04 09:58:39+00:00
aUX5Plaq7Oy,2021,Accept (Poster),True,Learning continuous-time PDEs from sparse data with graph neural networks,"[""Valerii Iakovlev"", ""Markus Heinonen"", ""Harri L\u00e4hdesm\u00e4ki""]","[""dynamical systems"", ""partial differential equations"", ""PDEs"", ""graph neural networks"", ""continuous time""]",The paper introduces a method for learning partial differential equations on arbitrary spatial and temporal grids.,2006.08956,cs.LG,2020-06-16 07:15:40+00:00,2021-01-29 16:33:11+00:00
aUoV6qhY_e,2022,Reject,False,"Specialized Transformers: Faster, Smaller and more Accurate NLP Models","['Amrit Nagarajan', 'Sanchari Sen', 'Jacob R. Stevens', 'Anand Raghunathan']",[],,,,,
aWA3-vIQDv,2022,Reject,False,Universality of Deep Neural Network Lottery Tickets: A Renormalization Group Perspective,"['William T Redman', 'Tianlong Chen', 'Akshunna S. Dogra', 'Zhangyang Wang']","[""lottery ticket hypothesis"", ""winning tickets"", ""renormalization group""]",Renormalization group theory is shown to provide theoretically grounded insight into the nature of winning ticket universality.,,,,
aYAA-XHKyk,2022,Accept (Poster),False,Rethinking Class-Prior Estimation for Positive-Unlabeled Learning,"['Yu Yao', 'Tongliang Liu', 'Bo Han', 'Mingming Gong', 'Gang Niu', 'Masashi Sugiyama', 'Dacheng Tao']","[""Positive-Unlabeled Learning"", ""Class-Prior Estimation""]",Class-Prior Estimation for Positive-Unlabeled Learning,,,,
aYJr_Rt30p,2021,Reject,False,Learning Representation in Colour Conversion,"[""Arash Akbarinia"", ""Raquel Gil-Rodriguez"", ""Alban Flachot"", ""Matteo Toscani""]","[""Color representation"", ""VAE"", ""Color space"", ""Unsupervised learning""]",The unsupervised task of colour conversion offers efficient encoding and a method to interpretat colour representation.,,,,
aYSlxlHKEA,2022,Reject,False,Fully Decentralized Model-based Policy Optimization with Networked Agents,"['Yuchen Liu', 'Yali Du', 'Runji Lin', 'Hangrui Bi', 'Mingdong Wu', 'Jun Wang', 'Hao Dong']","[""Reinforcement learning"", ""model-based"", ""multi-agent"", ""deep learning"", ""networked system control.""]",A decentralized multi-agent model-based RL algorithm and a theoretical analysis on its performance.,,,,
aYbCpFNnHdh,2021,Reject,False,Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests,"[""Christopher Beckham"", ""Martin Weiss"", ""Florian Golemo"", ""Sina Honari"", ""Derek Nowrouzezahrai"", ""Christopher Pal""]","[""vqa"", ""clevr"", ""contrastive learning"", ""3d"", ""inverse graphics""]","We propose a version of CLEVR with the problem of performing VQA under mental rotations, as well as methods that perform well on this task via the use and manipulation of 3D feature volumes.",,,,
aYuZO9DIdnn,2021,Accept (Poster),False,The Unreasonable Effectiveness of Patches in Deep Convolutional Kernels Methods,"[""Louis THIRY"", ""Michael Arbel"", ""Eugene Belilovsky"", ""Edouard Oyallon""]","[""convolutional kernel methods"", ""image classification""]",Patch-based representation is a key ingredient for competitive convolutional kernel methods.,2101.07528,cs.CV,2021-01-19 09:30:58+00:00,2021-01-19 09:30:58+00:00
a_nR4BPPJF1,2022,Reject,False,Blessing of Class Diversity in Pre-training,"['Yulai Zhao', 'Jianshu Chen', 'Simon Shaolei Du']","[""representation learning"", ""statistical learning theory""]",This paper presents a new statistical analysis aiming to explain the recent superior achievements of the pre-training techniques in NLP.,,,,
aa0705s2Qc,2021,Reject,False,Measuring Visual Generalization in Continuous Control from Pixels,"[""Jake Grigsby"", ""Yanjun Jane Qi""]","[""Continuous Control"", ""Reinforcement Learning""]",We propose a challenging benchmark that tests agents' visual generalization by adding graphical variety to existing continuous control domains.,,,,
ab7fanwXWu,2022,Reject,False,Accelerating Optimization using Neural Reparametrization,"['Nima Dehmamy', 'Csaba Both', 'Jianzhi Long', 'Rose Yu']","[""optimization"", ""graph neural networks"", ""neural reparameterization"", ""neural tangent kernel""]",We show that some optimization processes can be accelerated by making the parameters the output of a graph neural network with the graph arising from gradients of the loss. ,,,,
ab7lBP7Fb60,2022,Reject,False,Enforcing fairness in private federated learning via the modified method of differential multipliers,"['Borja RodrÃ­guez GÃ¡lvez', 'Filip Granqvist', 'Rogier van Dalen', 'Matt Seigel']","[""Private federated learning"", ""fairness""]","Enforcing fairness on models trained in private federated learning is challenging, as there is no direct access to the data, but in this work we show how this can be done using the modified method of differential multipliers",,,,
ac288vnG_7U,2021,Accept (Poster),False,Learning to Make Decisions via Submodular Regularization,"[""Ayya Alieva"", ""Aiden Aceves"", ""Jialin Song"", ""Stephen Mayo"", ""Yisong Yue"", ""Yuxin Chen""]",[],A data-driven sequential decision making framework based on a novel submodular-regularized loss.,,,,
adjl32ogfqD,2022,Reject,True,Learning Stochastic Shortest Path with Linear Function Approximation,"['Yifei Min', 'Jiafan He', 'Tianhao Wang', 'Quanquan Gu']","[""reinforcement learning"", ""stochastic shortest path""]",,2110.12727,cs.LG,2021-10-25 08:34:00+00:00,2021-10-25 08:34:00+00:00
af1eUDdUVz,2022,Accept (Poster),True,Evading Adversarial Example Detection Defenses with Orthogonal Projected Gradient Descent,"['Oliver Bryniarski', 'Nabeel Hingun', 'Pedro Pachuca', 'Vincent Wang', 'Nicholas Carlini']","[""Adversarial examples"", ""adversarial attacks""]",We break four defenses that detect adversarial examples by introducing an improved attack technique that modifies the gradient before applying PGD.,2106.15023,cs.LG,2021-06-28 23:19:02+00:00,2021-06-28 23:19:02+00:00
afoV8W3-IYp,2022,Accept (Poster),False,RelViT: Concept-guided Vision Transformer for Visual Relational Reasoning,"['Xiaojian Ma', 'Weili Nie', 'Zhiding Yu', 'Huaizu Jiang', 'Chaowei Xiao', 'Yuke Zhu', 'Song-Chun Zhu', 'Anima Anandkumar']","[""visual relational reasoning"", ""representation learning"", ""systematic generalization""]","We propose a novel concept-feature dictionary to enable two new concept-guided auxiliary tasks, which largely improve the model performances on visual relational reasoning, especially for systematic generalization.",,,,
agBJ7SYcUVb,2022,Reject,False,DFSSATTEN:  Dynamic Fine-grained Structured Sparse Attention Mechanism,"['Zhaodong Chen', 'Liu Liu', 'Yuying Quan', 'Zheng Qu', 'Yufei Ding', 'Yuan Xie']",[],"We exploit the 50% fine-grained structured sparsity in A100 GPU to accelerate the attention mechanism, which brings 1.27~1.89x speedup with no accuracy loss.",,,,
agHLCOBM5jP,2021,Accept (Poster),True,Fully Unsupervised Diversity Denoising with Convolutional Variational Autoencoders,"[""Mangal Prakash"", ""Alexander Krull"", ""Florian Jug""]","[""Diversity denoising"", ""Unsupervised denoising"", ""Variational Autoencoders"", ""Noise model""]",DivNoising performs fully unsupervised diversity denoising using fully convolutional variational autoencoders and achieves SOTA results for a number of well known datasets while also enabling VAE-like sampling,2006.06072,cs.CV,2020-06-10 21:28:13+00:00,2021-03-01 12:28:08+00:00
agyFqcmgl6y,2021,Reject,True,Disentangled Generative Causal Representation Learning,"[""Xinwei Shen"", ""Furui Liu"", ""Hanze Dong"", ""Qing LIAN"", ""Zhitang Chen"", ""Tong Zhang""]","[""disentanglement"", ""causality"", ""representation learning"", ""generative model""]",,2010.02637,cs.LG,2020-10-06 11:38:41+00:00,2021-01-21 03:05:47+00:00
ahAUv8TI2Mz,2021,Accept (Poster),False,Adaptive and Generative Zero-Shot Learning,"[""Yu-Ying Chou"", ""Hsuan-Tien Lin"", ""Tyng-Luh Liu""]","[""Generalized zero-shot learning"", ""mixup""]",,,,,
ahi2XSHpAUZ,2022,Accept (Poster),False,WeakM3D: Towards Weakly Supervised Monocular 3D Object Detection,"['Liang Peng', 'Senbo Yan', 'Boxi Wu', 'Zheng Yang', 'Xiaofei He', 'Deng Cai']","[""Computer vision"", ""monocular 3D object detection"", ""weakly supervised""]",This paper explores the weakly supervised monocular 3D detection to dispense with the reliance on 3D box labels.,,,,
aisKPsMM3fg,2022,Accept (Poster),False,Neural Stochastic Dual Dynamic Programming,"['Hanjun Dai', 'Yuan Xue', 'Zia Syed', 'Dale Schuurmans', 'Bo Dai']","[""data-driven algorithm design"", ""learning to optimize"", ""multi-stage stochastic optimization"", ""primal-dual dynamic programming""]",We proposed neural-SDDP pushing the frontier of multi-stage stochastic optimization solver towards practical problem size.,2112.00874,cs.LG,2021-12-01 22:55:23+00:00,2021-12-01 22:55:23+00:00
ajIC9wlTd52,2022,Reject,False,Learning to Generalize Compositionally by Transferring Across Semantic Parsing Tasks,"['Wang Zhu', 'Peter Shaw', 'Tal Linzen', 'Fei Sha']","[""transfer learning"", ""compositional generalization""]",Learning representations that facilitate transfer learning from one compositional task to another,2111.05013,cs.CL,2021-11-09 09:10:21+00:00,2021-11-09 09:10:21+00:00
ajOSNLwqssu,2022,Reject,False,Generating Antimicrobial Peptides from Latent Secondary Structure Space,"['Danqing Wang', 'Zeyu Wen', 'Lei Li', 'Hao Zhou']","[""Antimicrobial Peptides"", ""Drug Discovery"", ""Secondary Structure"", ""VQ-VAE""]",Generating antimicrobial peptides from latent secondary structure space via multi-scale VQ-VAE.,,,,
ajOrOhQOsYx,2021,Accept (Poster),True,A Wigner-Eckart Theorem for Group Equivariant Convolution Kernels,"[""Leon Lang"", ""Maurice Weiler""]","[""Group Equivariant Convolution"", ""Steerable Kernel"", ""Quantum Mechanics"", ""Wigner-Eckart Theorem"", ""Representation Theory"", ""Harmonic Analysis"", ""Peter-Weyl Theorem""]",We parameterize equivariant convolution kernels by proving a generalization of the Wigner-Eckart theorem for spherical tensor operators.,2010.10952,cs.LG,2020-10-21 12:42:23+00:00,2021-01-21 10:00:28+00:00
ajXWF7bVR8d,2022,Accept (Oral),False,Meta-Learning with Fewer Tasks through Task Interpolation,"['Huaxiu Yao', 'Linjun Zhang', 'Chelsea Finn']","[""meta-learning"", ""task interpolation"", ""meta-regularization""]",A new framework to densify the task distribution via task interpolation,,,,
akgiLNAkC7P,2021,Reject,False,Inverse Constrained Reinforcement Learning,"[""Shehryar Malik"", ""Usman Anwar"", ""Alireza Aghasi"", ""Ali Ahmed""]","[""Constrained reinforcement learning"", ""constrain inference"", ""safe reinforcement learning""]","Using reward function and expert demonstrations, learn the constraints present in the environment.",,,,
alaQzRbCY9w,2022,Reject,False,Bolstering Stochastic Gradient Descent with Model Building,"['Ilker Birbil', 'ÃzgÃ¼r Martin', 'GÃ¶nenc Onay', 'Figen Ãztoprak']","[""Stochastic Line Search"", ""Stochastic Model Building"", ""Non-convex Stochastic Optimization"", ""Unconstrained Optimization""]",We propose an alternative approach to stochastic line search by using a new algorithm based on model building.,,,,
amRmtfpYgDt,2021,Reject,False,Regioned Episodic Reinforcement Learning,"[""Jiarui Jin"", ""Cong Chen"", ""Ming Zhou"", ""Weinan Zhang"", ""Rasool Fakoor"", ""David Wipf"", ""Yong Yu"", ""Jun Wang"", ""Alex Smola""]","[""Deep Reinforcement Learning"", ""Episodic Memory"", ""Sample Efficiency""]","In this paper, we introduce Regioned Episodic Reinforcement Learning (RERL) that combines the strengths of episodic and goal-oriented learning to effectively solve tasks with delayed feedbacks and high-dimensional observations.",,,,
anWCFENEc5H,2022,Reject,True,Modeling Adversarial Noise for Adversarial Defense,"['Dawei Zhou', 'Nannan Wang', 'Bo Han', 'Tongliang Liu']",[],,2109.09901,cs.LG,2021-09-21 01:13:26+00:00,2022-02-04 08:13:05+00:00
an_ndI09oVZ,2022,Reject,False,Deep banach space kernels,['Mrityunjay Bhardwaj'],"[""RKBS"", ""RKHS"", ""concatenated kernel learning"", ""representation learning"", ""deep learning"", ""MLMKL"", ""Deep Gaussian Processes"", ""gaussian processes"", ""kernel machines""]",a new class of deep kernel methods which uses kernels from reproducing kernel banach spaces (RKBS).,,,,
anbBFlX1tJ1,2022,Accept (Poster),False,Boosted Curriculum Reinforcement Learning,"['Pascal Klink', ""Carlo D'Eramo"", 'Jan Peters', 'Joni Pajarinen']","[""reinforcement learning"", ""curriculum learning"", ""boosting"", ""residual learning""]","A novel approach for curriculum RL that increases the representativeness of the functional space as new, increasingly complex, tasks from the curriculum are presented to the agent.",,,,
apiI1ySCSSR,2021,Reject,True,Meta-learning Transferable Representations with a Single Target Domain,"[""Hong Liu"", ""Jeff Z. HaoChen"", ""Colin Wei"", ""Tengyu Ma""]","[""transfer learning"", ""fine-tuning"", ""supervised transfer learning""]",We introduce meta representation learning to overcome the limitations of fine-tuning and joint training in a transfer learning setting with a single target domain.,2011.01418,cs.LG,2020-11-03 01:57:37+00:00,2020-11-03 01:57:37+00:00
apv504XsysP,2022,Accept (Spotlight),True,Ab-Initio Potential Energy Surfaces by Pairing GNNs with Neural Wave Functions,"['Nicholas Gao', 'Stephan GÃ¼nnemann']","[""Graph Neural Networks"", ""Computational Physics"", ""Self-Generative Learning"", ""Machine Learning for Science""]","We introduce a PESNet, a new network architecture that solves the SchrÃ¶dinger equation for multiple geometries simultaneously.",2110.05064,cs.LG,2021-10-11 07:58:31+00:00,2021-11-26 08:28:58+00:00
aq6mqSkwApo,2022,Reject,False,Meta-OLE: Meta-learned Orthogonal Low-Rank Embedding,"['Ze Wang', 'Yue Lu', 'Qiang Qiu']",[],,,,,
ar92oEosBIg,2022,Accept (Poster),True,Graph Neural Network Guided Local Search for the Traveling Salesperson Problem,"['Benjamin Hudson', 'Qingbiao Li', 'Matthew Malencia', 'Amanda Prorok']","[""Traveling Salesman Problem"", ""Graph Neural Network"", ""Metaheuristic"", ""Guided Local Search"", ""Hybrid""]","We present a hybrid data-driven approach for solving the TSP based on Graph Neural Networks (GNNs) and Guided Local Search (GLS), which outperforms state-of-the-art learning-based approaches and non-learning GLS algorithms.",2110.05291,cs.LG,2021-10-11 14:06:08+00:00,2021-10-12 09:47:13+00:00
arD29HCZG6O,2021,Reject,False,Linking average- and worst-case perturbation robustness via class selectivity and dimensionality,"[""Matthew L Leavitt"", ""Ari S. Morcos""]","[""robustness"", ""adversarial robustness"", ""corruptions"", ""class selectivity"", ""deep learning""]",We show that robustness to worst-case (i.e. adversarial) and average-case (e.g. naturalistic distortions) perturbations are linked by class selectivity and representational dimensionality,,,,
arNvQ7QRyVb,2021,Reject,False,Sharing Less is More: Lifelong Learning in Deep Networks with Selective Layer Transfer,"[""Seungwon Lee"", ""Sima Behpour"", ""ERIC EATON""]","[""lifelong learning"", ""continual learning"", ""architecture search""]","Starting from the observation that performance of a lifelong learning architecture is significantly improved by transferring at appropriate layers, EM-based algorithm for selective transfer between tasks is proposed and evaluated in this paper.",,,,
asLT0W1w7Li,2021,Reject,False,Efficient Exploration for Model-based Reinforcement Learning with Continuous States and Actions,"[""Ying Fan"", ""Yifei Ming""]","[""Model-based reinforcement learning"", ""posterior sampling"", ""Bayesian reinforcement learning""]",,,,,
ascdLuNQY4J,2021,Reject,False,Searching for Convolutions and a More Ambitious NAS,"[""Nicholas Carl Roberts"", ""Mikhail Khodak"", ""Tri Dao"", ""Liam Li"", ""Nina Balcan"", ""Christopher Re"", ""Ameet Talwalkar""]","[""neural architecture search"", ""automated machine learning"", ""convolutional neural networks""]",A general-purpose search space for neural architecture search that enables discovering operations that beat convolutions on image data.,,,,
auLXcGlEOZ7,2022,Reject,False,On Margin Maximization in Linear and ReLU Networks,"['Gal Vardi', 'Ohad Shamir', 'Nathan Srebro']","[""Implicit bias"", ""Homogeneous neural networks"", ""Exponential loss"", ""Logistic loss"", ""Maximum margin"", ""Linear networks"", ""ReLU networks""]","For several architectures of homogeneous neural networks involving linear and ReLU activations, we study whether gradient flow converges to a global/local optimum of the max margin problem in parameter space.",,,,
auOPcdAcoy,2022,Accept (Poster),False,Hybrid Memoised Wake-Sleep: Approximate Inference at the Discrete-Continuous Interface,"['Tuan Anh Le', 'Katherine M. Collins', 'Luke Hewitt', 'Kevin Ellis', 'Siddharth N', 'Samuel Gershman', 'Joshua B. Tenenbaum']","[""wake-sleep"", ""variational inference"", ""neuro-symbolic generative models""]",,,,,
avBunqDXFS,2021,Reject,False,Memory-Efficient Semi-Supervised Continual Learning: The World is its Own Replay Buffer,"[""James Smith"", ""Jonathan C Balloch"", ""Yen-Chang Hsu"", ""Zsolt Kira""]","[""continual learning"", ""semi-supervised learning""]","We propose the realistic semi-supervised continual learning (SSCL) setting and show that a strategy built on pseudo-labeling, consistency regularization, Out-of-Distribution detection, and knowledge distillation reduces forgetting in this setting.",,,,
avHr-H-1kEa,2021,Reject,False,Temperature check: theory and practice for training models with softmax-cross-entropy losses,"[""Atish Agarwala"", ""Samuel Stern Schoenholz"", ""Jeffrey Pennington"", ""Yann Dauphin""]","[""theory"", ""learning dynamics"", ""temperature"", ""theory of deep learning"", ""generalization""]",We investigate the role of softmax temperature on learning dynamics and provide theoretical and empirical evidence that small inverse-temperature improves learning.,,,,
avgclFZ221l,2022,Accept (Oral),False,Asymmetry Learning for Counterfactually-invariant Classification in OOD Tasks,"['S Chandra Mouli', 'Bruno Ribeiro']","[""out-of-distribution classification"", ""symmetries"", ""counterfactual invariances"", ""geometric deep learning""]",Counterfactual-invariant representations for symmetry transformations,,,,
awMgJJ9H-0q,2021,Reject,False,Generative Learning With Euler Particle Transport,"[""Yuan Gao"", ""Jian Huang"", ""Yuling Jiao"", ""Jin Liu""]","[""Deep density-ratio estimation"", ""forward Euler method"", ""Mckean-Vlasov equation"", ""Monge-Ampere equation"", ""residual map""]",This paper proposes a forward Euler method for particle transport and generative learning.,,,,
awOrpNtsCX,2021,Reject,False,Shape-Tailored Deep Neural Networks Using PDEs for Segmentation,"[""Naeemullah Khan"", ""Angira Sharma"", ""Philip Torr"", ""Ganesh Sundaramoorthi""]","[""robustness"", ""covariance"", ""invariance"", ""convolutional neural nets"", ""PDEs"", ""segmentation""]",Partial differential equations in deep neural networks for better convarince/invariance propertires.,,,,
awnQ2qTLSwn,2021,Reject,False,Learning to Share in Multi-Agent Reinforcement Learning,"[""Yuxuan Yi"", ""Ge Li"", ""Yaowei Wang"", ""Zongqing Lu""]",[],,,,,
axNDkxU9-6z,2021,Reject,False,MDP Playground: Controlling Orthogonal Dimensions of Hardness in Toy Environments,"[""Raghu Rajan"", ""Jessica Lizeth Borja Diaz"", ""Suresh Guttikonda"", ""Fabio Ferreira"", ""Andr\u00e9 Biedenkapp"", ""Frank Hutter""]","[""Reinforcement learning"", ""Benchmarks"", ""Efficiency"", ""Reproducibility"", ""Core issues"", ""Algorithm analysis"", ""Dimensions of hardness"", ""OpenAI Gym""]",Toy benchmarks for Reinforcement Learning (RL) algorithms with controllable dimensions of hardness,,,,
b-7nwWHFtw,2021,Reject,False,Privacy-preserving Learning via Deep Net Pruning,"[""YANGSIBO HUANG"", ""Xiaoxiao Li"", ""Yushan Su"", ""Sachin Ravi"", ""Zhao Song"", ""Sanjeev Arora"", ""Kai Li""]","[""Neural Network Pruning"", ""Differential Privacy""]","This paper shows a novel connection between magnitude-based pruning and adding differentially private noise to intermediate layers, under the over-parameterized regime",,,,
b-VKxdc5cY,2022,Reject,False,Distribution Matching in Deep Generative Models with Kernel Transfer Operators,"['Zhichun Huang', 'Rudrasis Chakraborty', 'Vikas Singh']",[],,2112.00305,cs.LG,2021-12-01 06:54:31+00:00,2021-12-01 06:54:31+00:00
b-ZaBVGx8Q,2022,Reject,False,DP-REC: Private & Communication-Efficient Federated Learning,"['Aleksei Triastcyn', 'Matthias Reisser', 'Christos Louizos']","[""Federated learning"", ""differential privacy"", ""compression"", ""communication efficiency""]",We combine differential privacy with recent advances in compression to jointly tackle communication efficiency and privacy in federated learning,,,,
b-ny3x071E5,2022,Accept (Oral),True,Bootstrapped Meta-Learning,"['Sebastian Flennerhag', 'Yannick Schroecker', 'Tom Zahavy', 'Hado van Hasselt', 'David Silver', 'Satinder Singh']","[""meta-learning"", ""meta-gradients"", ""meta-reinforcement learning""]",We propose an algorithm for meta-learning with gradients that bootstraps the meta-learner from itself or another update rule. ,2109.04504,cs.LG,2021-09-09 18:29:05+00:00,2021-09-09 18:29:05+00:00
b30Yre8MzuN,2022,Reject,False,NeuroSED: Learning Subgraph Similarity via Graph Neural Networks,"['Rishabh Ranjan', 'Siddharth Grover', 'Sourav Medya', 'Venkatesan Chakaravarthy', 'Yogish Sabharwal', 'Sayan Ranu']","[""Subgraph similarity"", ""graph neural networks""]",,2112.13143,cs.LG,2021-12-24 21:46:40+00:00,2021-12-28 16:52:26+00:00
b4Phn_aTm_e,2021,Reject,False,Pseudo Label-Guided Multi Task Learning for Scene Understanding,"[""Sunkyung Kim"", ""Hyesong Choi"", ""Dongbo Min""]","[""Multi-task learning"", ""monocular depth estimation"", ""semantic segmentation"", ""pseudo label"", ""cross-view consistency""]","This paper proposes a novel multi-task learning (MTL) architecture, called Pseudo-MTL, that leverages pseudo labels for joint learning of monocular depth estimation and semantic segmentation tasks.",,,,
b4ach0lGuYO,2021,Reject,False,Iterative Image Inpainting with Structural Similarity Mask for Anomaly Detection,"[""Hitoshi Nakanishi"", ""Masahiro Suzuki"", ""Yutaka Matsuo""]","[""anomaly detection"", ""unsupervised learning"", ""structural similarity"", ""generative adversarial network"", ""deep learning""]",We investigated unsupervised anomaly detection method that utilizes inpainting technique iteratively and purifies anomaly score,,,,
b6BdrqTnFs7,2021,Reject,False,Grounded Compositional Generalization with Environment Interactions,"[""Yuanpeng Li""]","[""compositional generalization"", ""grounding""]",,,,,
b7ZRqEFXdQ,2021,Reject,False,Improving Sequence Generative Adversarial Networks with Feature Statistics Alignment,"[""Yekun Chai"", ""Qiyue Yin"", ""Junge Zhang""]",[],The paper proposes a Feature Statistics Alignment method to improve the training of Gumbel-Softmax-based language GANs.,,,,
b7g3_ZMHnT0,2021,Accept (Poster),True,Learning to Deceive Knowledge Graph Augmented Models via Targeted Perturbation,"[""Mrigank Raman"", ""Aaron Chan"", ""Siddhant Agarwal"", ""PeiFeng Wang"", ""Hansen Wang"", ""Sungchul Kim"", ""Ryan Rossi"", ""Handong Zhao"", ""Nedim Lipka"", ""Xiang Ren""]","[""neural symbolic reasoning"", ""interpretability"", ""model explanation"", ""faithfulness"", ""knowledge graph"", ""commonsense question answering"", ""recommender system""]",KG-augmented models and humans use KG info differently.,2010.12872,cs.CL,2020-10-24 11:04:45+00:00,2021-05-03 18:38:15+00:00
b8mo34uDObn,2022,Reject,False,Ensembles and Cocktails: Robust Finetuning for Natural Language Generation,"['John Hewitt', 'Xiang Lisa Li', 'Sang Michael Xie', 'Benjamin Newman', 'Percy Liang']","[""finetuning"", ""pretrained language models"", ""natural language generation"", ""robustness"", ""prefix-tuning""]","We show that one can achieve the best of new ""lightweight"" finetuning methods' out-of-distribution performance and traditional finetuning's in-distribution performance in a single model.",,,,
b905-XVjbDO,2021,Reject,False,Globally Injective ReLU networks,"[""Michael Puthawala"", ""Konik Kothari"", ""Matti Lassas"", ""Ivan Dokmani\u0107"", ""Maarten V. de Hoop""]","[""Generative models"", ""injectivity of neural networks"", ""universal approximation"", ""inference"", ""compressed sensing with generative priors"", ""well-posedness"", ""random projections""]","We provide a complete characterization of injective deep ReLU networks with implications for compressed sensing, inverse problems, and inference with generative models.",,,,
b9PoimzZFJ,2021,Accept (Spotlight),False,Systematic generalisation with group invariant predictions,"[""Faruk Ahmed"", ""Yoshua Bengio"", ""Harm van Seijen"", ""Aaron Courville""]","[""Systematic generalisation"", ""invariance penalty"", ""semantic anomaly detection""]",Invariance penalties across splits of a biased dataset can improve systematic generalisation,,,,
bB2drc7DPuB,2021,Accept (Poster),True,Global optimality of softmax policy gradient with single hidden layer neural networks in the mean-field regime,"[""Andrea Agazzi"", ""Jianfeng Lu""]","[""policy gradient"", ""entropy regularization"", ""mean-field dynamics"", ""neural networks""]",We prove that softmax policy gradient algorithms with single hidden layer neural networks in the mean-field regime can be expressed as a gradient flow in Wasserstein space and prove that all the fixed points of such dynamics are global optimizers,2010.11858,cs.LG,2020-10-22 16:47:22+00:00,2020-10-22 16:47:22+00:00
bB6YLDJewoK,2022,Reject,False,Simpler Calibration for Survival Analysis,"['Hiroki Yanagisawa', 'Toshiya Iwamori', 'Akira Koseki', 'Michiharu Kudo', 'Mohamed Ghalwash', 'Prithwish Chakraborty']","[""survival analysis"", ""time-to-event analysis"", ""calibration""]",Propose a new regularizer term of loss function for calibration for survival analysis,,,,
bBDlTR5eDIX,2021,Reject,False,Predicting Video with VQVAE,"[""Jacob C Walker"", ""Ali Razavi"", ""Aaron van den Oord""]","[""Generative Models"", ""Video Generation"", ""Video Forecasting"", ""Autoregressive Models"", ""VQVAE"", ""Computer Vision""]",We propose a two-stage model based on VQVAE to forecast video on the Kinetics dataset at a higher resolution than ever before.,,,,
bCrdi4iVvv,2022,Accept (Poster),False,Learning Features with Parameter-Free Layers,"['Dongyoon Han', 'YoungJoon Yoo', 'Beomyoung Kim', 'Byeongho Heo']","[""ImageNet"", ""efficient network architecture"", ""network design"", ""image classification""]",This paper introduces a new design paradigm rethinking a parameter-free operation as the main building block of network architecture.,,,,
bE239PSGIGZ,2022,Reject,False,Synthesising Audio Adversarial Examples for Automatic Speech Recognition,"['Xinghua Qu', 'pengfei wei', 'Mingyong Gao', 'Zhu Sun', 'Yew-Soon Ong', 'Zejun MA']","[""Adversarial Attack"", ""Speech Synthesise"", ""Automatic Speech Recognition""]",A novel audio-independent adversarial attack using speech synthesis based on a conditional variational auto-encoder.,,,,
bERaNdoegnO,2022,Accept (Spotlight),False,Policy improvement by planning with Gumbel,"['Ivo Danihelka', 'Arthur Guez', 'Julian Schrittwieser', 'David Silver']","[""AlphaZero"", ""MuZero"", ""reinforcement learning""]",We redesign AlphaZero to keep improving even when training with a small number of simulations.,,,,
bEoxzW_EXsa,2021,Accept (Poster),True,Wasserstein-2 Generative Networks,"[""Alexander Korotin"", ""Vage Egiazarian"", ""Arip Asadulaev"", ""Alexander Safin"", ""Evgeny Burnaev""]","[""wasserstein-2 distance"", ""optimal transport maps"", ""non-minimax optimization"", ""cycle-consistency regularization"", ""input-convex neural networks""]",We present a new end-to-end algorithm to compute optimal transport maps between continuous distributions without introducing bias or resorting to minimax optimization.,1909.13082,cs.LG,2019-09-28 12:42:12+00:00,2020-12-10 10:53:46+00:00
bFnn6lPn3Sp,2021,Reject,False,A Benchmark for Voice-Face Cross-Modal Matching and  Retrieval,"[""Chuyuan Xiong"", ""Deyuan Zhang"", ""Tao Liu"", ""Xiaoyong Du"", ""Jiankun Tian"", ""Songyan Xue""]","[""Cross-Modal Learning"", ""Voice-Face Matching"", ""Voice-Face Retrieval""]",A baseline framework  are proposed for voice-face cross-modal matching and retrieval tasks.,,,,
bGPNpnZYr1,2021,Reject,False,Least Probable Disagreement Region for Active Learning,"[""Seong Jin Cho"", ""Gwangsu Kim"", ""Chang D. Yoo""]","[""active learning"", ""uncertainty sampling"", ""disagreement region"", ""variation ratio"", ""deep learning"", ""distance"", ""decision boundary""]","This paper defines a sample distance to the decision boundary as the least probable disagreement region (LPDR) containing the sample, and proposes querying unlabeled samples near the decision boundary with lower time complexity in active learning.",,,,
bGZtz5-Cmkz,2021,Reject,False,Learning Collision-free Latent Space for Bayesian Optimization,"[""Fengxue Zhang"", ""Yair Altas"", ""Louise Fan"", ""Kaustubh Vinchure"", ""Brian Nord"", ""Yuxin Chen""]","[""Latent space"", ""Bayesian Optimization"", ""Collision""]",Propose a novel regularizer on neural networks to learn a collision free latent space for Bayesian optimization.,,,,
bG_lJcLwE3p,2021,Reject,True,Deep Single Image Manipulation,"[""Yael Vinker"", ""Eliahu Horwitz"", ""Nir Zabari"", ""Yedid Hoshen""]","[""image translation"", ""single image"", ""conditional generation"", ""image manipulation""]",,2007.01289,cs.CV,2020-07-02 17:55:27+00:00,2020-07-02 17:55:27+00:00
bHqI0DvSIId,2022,Reject,False,Neural Simulated Annealing,"['Alvaro Correia', 'Daniel E. Worrall', 'Roberto Bondesan']","[""Combinatorial Optimization"", ""Reinforcement Learning"", ""Evolution Strategies"", ""Simulated Annealing""]","We extend simulated annealing with learnable (neural) components, producing a new method that is competitive in terms of both speed and quality of the final solution.",,,,
bIQF55zCpWf,2021,Reject,True,Patch-level Neighborhood Interpolation:  A General and Effective Graph-based Regularization Strategy,"[""Ke Sun"", ""Bing Yu"", ""Zhouchen Lin"", ""Zhanxing Zhu""]","[""Deep Learning"", ""Regularization"", ""Graph-based Representation""]",A general and effective graph-based regularization strategy called Patch-level Neighborhood Interpolation is superior in both semi- and supervised settings.,1911.09307,cs.LG,2019-11-21 06:31:59+00:00,2019-11-21 06:31:59+00:00
bIrL42I_NF8,2021,Reject,False,On the Effect of Consensus in Decentralized Deep Learning,"[""Tao Lin"", ""Lingjing Kong"", ""Anastasia Koloskova"", ""Martin Jaggi"", ""Sebastian U Stich""]",[],,,,,
bIwkmDnSeu,2021,Reject,False,Unbiased Learning with State-Conditioned Rewards in Adversarial Imitation Learning,"[""Dong-Sig Han"", ""Hyunseo Kim"", ""Hyundo Lee"", ""Je-Hwan Ryu"", ""Byoung-Tak Zhang""]","[""Adversarial Learning"", ""Imitation Learning"", ""Inverse Reinforcement Learning"", ""Reinforcement Learning"", ""Transfer Learning""]",This work introduces a causal AIRL algorithm for dealing with two distinct issues in adversarial imitation learning.,,,,
bJLHjvYV1Cu,2021,Reject,True,Optimizing Loss Functions Through Multivariate Taylor Polynomial Parameterization,"[""Santiago Gonzalez"", ""Risto Miikkulainen""]","[""taylorglo"", ""loss function"", ""metalearning"", ""evolution"", ""deep networks"", ""evolutionary strategies"", ""taylor polynomials"", ""glo""]","This paper introduces TaylorGLO, a technique that metalearns loss functions that result in higher performance deep networks.",2002.00059,cs.LG,2020-01-31 21:25:37+00:00,2020-10-02 05:29:18+00:00
bJxgv5C3sYc,2021,Accept (Poster),False,Few-Shot Bayesian Optimization with Deep Kernel Surrogates,"[""Martin Wistuba"", ""Josif Grabocka""]","[""bayesian optimization"", ""metalearning"", ""few-shot learning"", ""automl""]",Model-agnostic meta-learning meets Bayesian optimization to speed-up hyperparameter optimization by learning on metadata from different data sets.,2101.07667,cs.LG,2021-01-19 15:00:39+00:00,2021-01-19 15:00:39+00:00
bK-rJMKrOsm,2021,Reject,False,Multi-Head Attention: Collaborate Instead of Concatenate,"[""Jean-Baptiste Cordonnier"", ""Andreas Loukas"", ""Martin Jaggi""]","[""attention"", ""self-attention"", ""bert"", ""multi-head"", ""tensor factorization""]",Multi-head attention learns similar key/query projections which can be shared across heads to decrease number of parameters.,,,,
bM3L3I_853,2021,Accept (Poster),False,AdaFuse: Adaptive Temporal Fusion Network for Efficient Action Recognition,"[""Yue Meng"", ""Rameswar Panda"", ""Chung-Ching Lin"", ""Prasanna Sattigeri"", ""Leonid Karlinsky"", ""Kate Saenko"", ""Aude Oliva"", ""Rogerio Feris""]",[],,2102.05775,cs.CV,2021-02-10 23:31:02+00:00,2021-02-10 23:31:02+00:00
bM45i3LQBdl,2022,Reject,False,Combining Differential Privacy and Byzantine Resilience in Distributed SGD,"['Rachid Guerraoui', 'Nirupam Gupta', 'Rafael Pinot', 'SÃ©bastien Rouault', 'John Stephan']","[""Distributed SGD"", ""Byzantine resilience""]",This paper proposes a formal methodology to ensure Byzantine resilience and differential privacy simultaneously in distributed learning.,,,,
bM4Iqfg8M2k,2021,Accept (Poster),True,Graph Information Bottleneck for Subgraph Recognition,"[""Junchi Yu"", ""Tingyang Xu"", ""Yu Rong"", ""Yatao Bian"", ""Junzhou Huang"", ""Ran He""]",[],,2010.05563,cs.LG,2020-10-12 09:32:20+00:00,2020-10-12 09:32:20+00:00
bM5L3GLi6bG,2022,Reject,False,Open Set Domain Adaptation with Zero-shot Learning on Graph,"['Xinyue Zhang', 'Xu Yang', 'Zhi-yong Liu']","[""open set domain adaptation"", ""zero-shot learning"", ""knowledge graph"", ""graph convolutional network"", ""adversarial learning""]","Our model works to solve the open set domain adpatation with zero-shot learning problem on graph, by aligning the shared classes in different domains while generating classifiers for the unknown classes.",,,,
bMCfFepJXM,2021,Reject,False,BRAC+: Going Deeper with Behavior Regularized Offline Reinforcement Learning,"[""Chi Zhang"", ""Sanmukh Rao Kuppannagari"", ""Viktor Prasanna""]","[""offline reinforcement learning"", ""behavior regularization""]",improving behavior regularized offline reinforcement learning,,,,
bMzj6hXL2VJ,2021,Reject,False,Ordering-Based Causal Discovery with Reinforcement Learning,"[""Xiaoqiang Wang"", ""Yali Du"", ""Shengyu Zhu"", ""Liangjun Ke"", ""Zhitang Chen"", ""Jianye HAO"", ""Jun Wang""]","[""Causal Discovery"", ""Reinforcement Learning"", ""Ordering Search""]",,2105.06631,cs.LG,2021-05-14 03:49:59+00:00,2021-09-15 14:46:28+00:00
bOcUqfdH3S8,2022,Reject,False,Provably Calibrated Regression Under Distribution Drift,"['Shengjia Zhao', 'YUSUKE TASHIRO', 'Danny Tse', 'Stefano Ermon']","[""calibration"", ""online prediction"", ""distribution shift"", ""uncertainty quantification""]",,,,,
bPadTQyLb2_,2022,Reject,True,Efficient representations for privacy-preserving inference,"['Han Xuanyuan', 'Francisco Vargas', 'Stephen Cummins']","[""Deep neural networks"", ""Homomorphic encryption""]",Improving upon low-latency methods for privacy-preserving inference,2110.08321,cs.LG,2021-10-15 19:03:35+00:00,2021-10-15 19:03:35+00:00
bQNosljkHj,2021,Reject,False,On the Geometry of Deep Bayesian Active Learning,"[""Xiaofeng Cao"", ""Ivor Tsang""]","[""Bayesian active learning"", ""geometric interpretation"", ""core-set construction"", ""model uncertainty"", ""ellipsoid.""]",We present geometric Bayesian active learning by disagreements for active deep learning.,,,,
bQf4aGhfmFx,2021,Reject,True,Effective Regularization Through Loss-Function Metalearning,"[""Santiago Gonzalez"", ""Risto Miikkulainen""]","[""regularization"", ""loss"", ""loss function"", ""metalearning"", ""meta-learning"", ""optimization"", ""theory"", ""robustness"", ""adversarial attacks""]",This paper provides a theoretical foundation to explain how and why metalearned loss functions are able to regularize.,2010.00788,cs.LG,2020-10-02 05:22:21+00:00,2021-10-28 04:47:05+00:00
bQtejwuIqB,2021,Reject,False,"With False Friends Like These, Who Can Have Self-Knowledge?","[""Lue Tao"", ""Songcan Chen""]","[""Robustness"", ""Adversarial Risk"", ""Neural Networks"", ""Machine Learning Security""]",Model performance could be hypocritically improved by false friends: we formalize this new realistic risk and analyze its relation with natural risk and adversarial risk.,,,,
bTteFbU99ye,2022,Accept (Poster),False,Evaluating Distributional Distortion in Neural Language Modeling,"['Benjamin LeBrun', 'Alessandro Sordoni', ""Timothy J. O'Donnell""]",[],,,,,
bUAdXW8wN6,2022,Reject,False,Domain Invariant Adversarial Learning,"['Matan Levi', 'Idan Attias', 'Aryeh Kontorovich']","[""adversarial Training"", ""Robustness"", ""Domain-invariant representation"", ""domain adaptation""]",We propose a new adversarial training method that achieves improved robustness and accuracy by learning a feature representation that is both robust and domain-invariant.,,,,
bUKyC0UiZcr,2022,Reject,False,Temporal abstractions-augmented temporally contrastive learning: an alternative to the Laplacian in RL,"['Akram Erraqabi', 'Marlos C. Machado', 'Mingde Zhao', 'Sainbayar Sukhbaatar', 'Ludovic Denoyer', 'Alessandro Lazaric', 'Yoshua Bengio']","[""Representation learning"", ""Laplacian"", ""self-supervised"", ""exploration""]",An alternative to Laplacian-like representations in exploration demanding settings.,,,,
bVT5w39X0a,2022,Reject,False,Bayesian Relational Generative Model for Scalable Multi-modal Learning,"['Ehsan Hajiramezanali', 'Talip Ucar', 'Lindsay Edwards']","[""Multi-modal Learning"", ""Bayesian Learning"", ""Neural Processes"", ""Variational Inference""]",,,,,
bVkRc9NDHcK,2022,Reject,False,Variable Length Variable Quality Audio Steganography,['Seungmo Ku'],"[""computer vision"", ""stegaography"", ""recurrent neural network"", ""loss conditional training"", ""information hiding""]",We propose a steganographic system that can hide variable-length audio signals inside an image and can make inference time quality tradeoffs.,,,,
bVuP3ltATMz,2022,Accept (Oral),False,Large Language Models Can Be Strong Differentially Private Learners,"['Xuechen Li', 'Florian Tramer', 'Percy Liang', 'Tatsunori Hashimoto']","[""language model"", ""differential privacy"", ""language generation"", ""fine-tuning"", ""NLP""]",We show how to build highly performant differentially private NLP models by fine-tuning large pretrained models.,,,,
bVvMOtLMiw,2022,Accept (Poster),False,DIVA: Dataset Derivative of a Learning Task,"['Yonatan Dukler', 'Alessandro Achille', 'Giovanni Paolini', 'Avinash Ravichandran', 'Marzia Polito', 'Stefano Soatto']","[""Leave one out cross validation"", ""AutoML"", ""dataset optimization""]",Presents a method to optimize a dataset based on a notion of a dataset derivative that is computed in closed form using linearization,,,,
bVzUDC_4ls,2021,Reject,True,Exploiting Verified Neural Networks via Floating Point Numerical Error,"[""Kai Jia"", ""Martin Rinard""]",[],We show that floating point error in neural network verifiers and neural network inference implementations can be systematically exploited to invalidate robustness claims.,2003.03021,cs.LG,2020-03-06 03:58:26+00:00,2021-10-01 14:10:25+00:00
bW9SYKHcZiz,2021,Reject,False,Cross-Probe BERT for Efficient and Effective Cross-Modal Search,"[""TAN YU"", ""Hongliang Fei"", ""Ping Li""]",[],,,,,
bWqodw-mFi1,2021,Reject,False,Explicit homography estimation improves contrastive self-supervised learning,"[""David Torpey"", ""Richard Klein""]",[],Explicit homography estimation improves contrastive self-supervised learning,2101.04713,cs.CV,2021-01-12 19:33:37+00:00,2021-01-12 19:33:37+00:00
bXLMnw03KPz,2021,Reject,False,FERMI: Fair Empirical Risk Minimization via Exponential RÃ©nyi Mutual Information,"[""Rakesh Pavan"", ""Andrew Lowy"", ""Sina Baharlouei"", ""Meisam Razaviyayn"", ""Ahmad Beirami""]","[""algorithmic fairness""]","We propose the Fair Empirical Risk Minimization via Exponential RÃ©nyi Mutual Information (FERMI) framework, and showcase its effectiveness theoretically and empirically.",,,,
bYGSzbCM_i,2022,Accept (Poster),False,Online Adversarial Attacks,"['Andjela Mladenovic', 'Joey Bose', 'Hugo berard', 'William L. Hamilton', 'Simon Lacoste-Julien', 'Pascal Vincent', 'Gauthier Gidel']","[""Online Algorithms"", ""Adversarial Attacks""]",We consider a new adversarial attack setting in which the data arrives as a stream and an adversary must pick top-k items to craft blackbox transfer attacks against an unkown target model.,,,,
bYfk8y7BXS,2022,Reject,False,Pessimistic Model Selection for Offline Deep Reinforcement Learning,"['Chao-Han Huck Yang', 'Zhengling Qi', 'Yifan Cui', 'Pin-Yu Chen']","[""reinforcement learning theory"", ""offline deep reinforcement learning"", ""model selection"", ""pessimism"", ""tuning free""]", A pessimistic model selection approach for offline deep reinforcement with a theoretical guarantee is presented.,2111.14346,cs.LG,2021-11-29 06:29:49+00:00,2021-11-29 06:29:49+00:00
bZJbzaj_IlP,2022,Accept (Poster),False,Generalization of Overparametrized Deep Neural Network Under Noisy Observations,"['Namjoon Suh', 'Hyunouk Ko', 'Xiaoming Huo']","[""Overparametrized Deep Neural Network"", ""Neural Tangent Kernel"", ""Minimax"", ""Non-parametric regression""]",Study the generalization of overparametrized deep neural network with relu activation function with noisy dataset.,,,,
b_7OR0Fo_iN,2021,Reject,False,A Unifying Perspective on Neighbor Embeddings along the Attraction-Repulsion Spectrum,"[""Niklas B\u00f6hm"", ""Philipp Berens"", ""Dmitry Kobak""]","[""visualization"", ""t-SNE"", ""UMAP"", ""dimensionality reduction"", ""nonlinear dimensionality reduction""]",,,,,
ba81PoR_k1p,2022,Reject,False,One for Many: an Instagram inspired black-box adversarial attack,"['Alina Elena Baia', 'Alfredo Milani', 'Valentina Poggioni']","[""black-box adversarial attacks"", ""instragram-based image filters"", ""evolutionary algorithm"", ""multi-network attacks""]",,,,,
ba82GniSJdc,2021,Reject,False,Task Calibration for Distributional Uncertainty in Few-Shot Classification,"[""Sungnyun Kim"", ""Se-Young Yun""]","[""few-shot learning"", ""meta-learning"", ""uncertainty estimation""]",,,,,
baUQQPwQiAg,2022,Accept (Poster),False,Robust Unlearnable Examples: Protecting Data Privacy Against Adversarial Learning,"['Shaopeng Fu', 'Fengxiang He', 'Yang Liu', 'Li Shen', 'Dacheng Tao']","[""unlearnable examples"", ""adversarial training"", ""privacy""]",This paper proposes an robust error-minimizing noise that can protect data from being learned under adversarial training.,,,,
bd66LuDPPFh,2021,Reject,False,Towards Understanding Label Smoothing,"[""Yi Xu"", ""Yuanhong Xu"", ""Qi Qian"", ""Li Hao"", ""Rong Jin""]","[""Label Smoothing"", ""Non-convex Optimization"", ""Deep Learning Theory""]", This paper studies the theoretical understanding of the power of label smoothing from the view of optimization and proposes a simple yet effective algorithm TSLA with theoretical guarantee of convergence.,,,,
beUek8ku1Q,2022,Reject,False,k-Median Clustering via Metric Embedding: Towards Better Initialization with Privacy,"['Chenglin Fan', 'Ping Li', 'Xiaoyun Li']",[],,,,,
bfTUfrqL6d,2021,Reject,False,Aspect-based Sentiment Classification via Reinforcement Learning,"[""Lichen Wang"", ""Bo Zong"", ""Yunyu Liu"", ""Can Qin"", ""Wei Cheng"", ""Wenchao Yu"", ""Xuchao Zhang"", ""Haifeng Chen"", ""Yun Fu""]","[""Sentiment classification"", ""reinforcement learning""]",A novel reinforcement learning-based approach for aspect-based sentimental classification.,,,,
bfuGjlCwAq,2022,Accept (Poster),False,Learning Efficient Online 3D Bin Packing on Packing Configuration Trees,"['Hang Zhao', 'Yang Yu', 'Kai Xu']","[""Bin Packing Problem"", ""Online 3D-BPP"", ""Reinforcement Learning""]",We propose to enhance the practical applicability of online 3D-BPP via learning on a hierarchical packing configuration tree which makes the DRL model easy to deal with practical constraints and well-performing even with continuous solution space.,,,,
bgAS1ZvveZ,2022,Reject,False,Faster Reinforcement Learning with Value Target Lower Bounding,"['Le Zhao', 'Wei Xu']","[""reinforcement learning"", ""bellman value target"", ""lower bound"", ""discounted return""]",Speed up RL learning by lower bounding the Bellman value target with empirical episodic return,,,,
bgQek2O63w,2021,Accept (Poster),False,"Self-supervised Adversarial Robustness for the Low-label, High-data Regime","[""Sven Gowal"", ""Po-Sen Huang"", ""Aaron van den Oord"", ""Timothy Mann"", ""Pushmeet Kohli""]","[""self-supervised"", ""adversarial training"", ""robustness""]",This paper builds of Bootstrap Your Own Latents and proposes a self-supervised learning technique that can learn robust representations that are competitive with fully-supervised techniques.,,,,
bglU8l_Pq8Q,2022,Reject,False,In defense of dual-encoders for neural ranking,"['Aditya Krishna Menon', 'Sadeep Jayasumana', 'Seungyeon Kim', 'Ankit Singh Rawat', 'Sashank J. Reddi', 'Sanjiv Kumar']","[""cross-attention"", ""dual encoder"", ""neural ranking"", ""distillation""]","The gap between cross-attention and dual-encoders for neural ranking can be due to overfitting, which can be mitigated with a suitable distillation loss.",,,,
bhCDO_cEGCz,2021,Accept (Poster),False,Grounding Physical Concepts of Objects and Events Through Dynamic Visual Reasoning,"[""Zhenfang Chen"", ""Jiayuan Mao"", ""Jiajun Wu"", ""Kwan-Yee Kenneth Wong"", ""Joshua B. Tenenbaum"", ""Chuang Gan""]","[""Concept Learning"", ""Neuro-Symbolic Learning"", ""Video Reasoning"", ""Visual Reasoning""]",We propose a neural-symbolic framework to learn physical concepts of objects and events via causal reasoning on videos.,2103.16564,cs.CV,2021-03-30 17:59:48+00:00,2021-03-30 17:59:48+00:00
bhKQ7P7gyLA,2021,Reject,True,Manifold Regularization for Locally Stable Deep Neural Networks,"[""Charles Jin"", ""Martin Rinard""]","[""regularization"", ""deep learning"", ""adversarial robustness""]",We derive new manifold regularizers for deep neural networks that are (1) cheap to train with and (2) yield stability against a variety of (unseen) perturbations models.,2003.04286,stat.ML,2020-03-09 17:45:44+00:00,2020-09-22 22:53:45+00:00
bhngY7lHu_,2021,Reject,False,Adaptive N-step Bootstrapping with Off-policy Data,"[""Guan Wang"", ""Dong Yan"", ""Hang Su"", ""Jun Zhu""]","[""reinforcement learning"", ""policy evaluation""]","A new adaptive n-step bootstrapping training method for acceleration, which is based on a detailed analysis of the working mechanism of the n-step returns.",,,,
bi7nTZy4QmH,2021,Reject,False,Learning Contextual Perturbation Budgets for Training Robust Neural Networks,"[""Jing Xu"", ""Zhouxing Shi"", ""Huan Zhang"", ""Jinfeng Yi"", ""Cho-Jui Hsieh"", ""Liwei Wang""]","[""adversarial robustness"", ""certified robustness"", ""certfied robust training""]",We propose a novel algorithm to learn contextual and non-uniform perturbation budgets and train certifiably robust neural networks with learned perturbation budgets.,,,,
bi9j5yi-Vrv,2022,Reject,False,A General Theory of Relativity in Reinforcement Learning,"['Lei Han', 'Cheng Zhou', 'Yizheng Zhang']","[""Reinforcement Learning"", ""General RL Theory"", ""Policy Transfer"", ""Dynamics Modeling""]",A new general RL theory for policy transfer,,,,
biH_IISPxYA,2021,Reject,True,Multi-Level Generative Models for Partial Label Learning with Non-random Label Noise,"[""Yan Yan"", ""Yuhong Guo""]",[],This is the first partial label learning method that handles non-random label noise with a consistent multi-level generative model.,2005.05407,cs.LG,2020-05-11 20:13:19+00:00,2020-05-11 20:13:19+00:00
bidTZROu2y,2022,Reject,False,Physics Informed Machine Learning of SPH: Machine Learning Lagrangian Turbulence,"['Michael J Woodward', 'Yifeng Tian', 'Criston Hyett', 'Chris Fryer', 'Daniel Livescu', 'Misha Stepanov', 'Michael Chertkov']","[""Physics Informed Machine Learning"", ""Smoothed Particle Hydrodynamics"", ""Sensitivity Analysis"", ""Differentiable Programming"", ""Mixed Mode Automatic Differentiation"", ""Deep Learning"", ""Turbulence"", ""Lagrangian Fluid Simulation.""]","Applying a mixed mode approach, we developed a learn-able hierarchy of ""physics-explainable"" Lagrangian fluid simulators and showed that adding physical structure improves interpretability, generalizability, and requires less training data. ",,,,
bilHNPhT6-,2022,Reject,False,On Multi-objective Policy Optimization as a Tool for Reinforcement Learning: Case Studies in Offline RL and Finetuning,"['Abbas Abdolmaleki', 'Sandy Huang', 'Giulia Vezzani', 'Bobak Shahriari', 'Jost Tobias Springenberg', 'Shruti Mishra', 'Dhruva Tirumala', 'Arunkumar Byravan', 'Konstantinos Bousmalis', 'AndrÃ¡s GyÃ¶rgy', 'Csaba Szepesvari', 'raia hadsell', 'Nicolas Heess', 'Martin Riedmiller']","[""offline RL"", ""learning from experts"", ""finetuning"", ""multi-objective RL"", ""deep RL"", ""continuous control""]","We propose that MORL can be used as a tool for tackling fundamental challenges in RL, focusing on offline RL and finetuning as case studies.",,,,
biyvmQe5jM,2022,Reject,False,How to decay your learning rate,['Aitor Lewkowycz'],"[""learning rates"", ""hyperparameter tuning"", ""schedules""]",We study when it is beneficial to decay the learning rate and how to do it.,,,,
bjYunHo6LWR,2022,Reject,False,Classification and Uncertainty Quantification of Corrupted Data using Semi-Supervised Autoencoders,"['Philipp Joppich', 'Sebastian Dorn', 'Oliver De Candido', 'Wolfgang Utschick', 'Jakob KnollmÃ¼ller']",[],"We present a new method to classify/reconstruct corrupted data including uncertainty quantification, where the classifying model is trained on uncorrupted data. ",,,,
bjkX6Kzb5H,2021,Accept (Poster),False,"Cut out the annotator, keep the cutout: better segmentation with weak supervision","[""Sarah Hooper"", ""Michael Wornow"", ""Ying Hang Seah"", ""Peter Kellman"", ""Hui Xue"", ""Frederic Sala"", ""Curtis Langlotz"", ""Christopher Re""]","[""Weak supervision"", ""segmentation"", ""CNN"", ""latent variable"", ""medical imaging""]","In this work, we present a weak supervision approach for segmentation tasks, allowing users to train high-performing segmentation CNNs with very few hand-labeled training points.",,,,
bjy5Zb2fo2,2022,Accept (Poster),False,Scattering Networks on the Sphere for Scalable and Rotationally Equivariant Spherical CNNs,"['Jason McEwen', 'Christopher Wallis', 'Augustine N. Mavor-Parker']",[],Scaling rotationally equivariant spherical CNNs to high-resolution data through spherical scattering networks,,,,
bkincnjT8zx,2021,Reject,True,Neural Dynamical Systems: Balancing Structure and Flexibility in Physical Prediction,"[""Viraj Mehta"", ""Ian Char"", ""Willie Neiswanger"", ""Youngseog Chung"", ""Andrew Oakleigh Nelson"", ""Mark D Boyer"", ""Egemen Kolemen"", ""Jeff Schneider""]","[""nuclear fusion"", ""physics"", ""differential equations"", ""dynamical systems"", ""control"", ""dynamics""]",We use prior knowledge in the form of differential equations to make predictions and do control more sample-efficiently.,2006.12682,cs.LG,2020-06-23 00:50:48+00:00,2021-04-27 16:22:10+00:00
bl9zYxOVwa,2022,Reject,False,Understanding the robustness-accuracy tradeoff by rethinking robust fairness ,"['Zihui Wu', 'Haichang Gao', 'Shudong Zhang', 'Yipeng Gao']","[""Adversarial training"", ""Adversarial robustness""]","We show both the robustness-accuracy tradeoff and robust fairness stem from the increased inter-class similarity caused by AT, and we find smoothing regularizer helps reduce the inter-class similarity, thus mitigate the tradeoff & robust fairness.",,,,
blfSjHeFM_e,2021,Accept (Poster),False,MALI: A memory efficient and reverse accurate integrator for Neural ODEs,"[""Juntang Zhuang"", ""Nicha C Dvornek"", ""sekhar tatikonda"", ""James s Duncan""]","[""neural ode"", ""memory efficient"", ""reverse accuracy"", ""gradient estimation""]",A solver for ODE that guarantees accuracy in reverse-time trajectory  at a constant memory cost,,,,
bmGLlsX_iJl,2022,Reject,False,EMFlow: Data Imputation in Latent Space via EM and Deep Flow Models,"['Qi Ma', 'Sujit K Ghosh']",[],An imputation framework that combines the normalizing flow and online expectation maximization.,,,,
bnY0jm4l59,2021,Accept (Spotlight),False,Memory Optimization for Deep Networks,"[""Aashaka Shah"", ""Chao-Yuan Wu"", ""Jayashree Mohan"", ""Vijay Chidambaram"", ""Philipp Kraehenbuehl""]","[""memory optimized training"", ""memory efficient training"", ""checkpointing"", ""deep network training""]",MONeT reduces the memory footprint of training while minimizing compute overhead by jointly optimizing checkpointing with operator optimizations.,,,,
bnuU0PzXl0-,2021,Reject,False,Evaluating Gender Bias in Natural Language Inference ,"[""Shanya Sharma"", ""Manan Dey"", ""Koustuv Sinha""]","[""Natural Language Inference"", ""Natural Language Understanding"", ""Natural Language Processing"", ""Gender Bias"", ""Societal Bias"", ""Bias"", ""Ethics"", ""Debiasing Techniques"", ""Data Augmentation""]",We propose an evaluation methodology by constructing a challenge task to demonstrate that gender bias is exhibited in state-of-the-art finetuned Transformer-based NLI model outputs and explore an existing debiasing technique for mitigation of bias.,2105.05541,cs.CL,2021-05-12 09:41:51+00:00,2021-05-12 09:41:51+00:00
boJy41J-tnQ,2022,Accept (Poster),False,Subspace Regularizers for Few-Shot Class Incremental Learning,"['Afra Feyza AkyÃ¼rek', 'Ekin AkyÃ¼rek', 'Derry Wijaya', 'Jacob Andreas']","[""few-shot class incremental learning"", ""incremental learning"", ""incremental classification"", ""subspace regularization"", ""manifold regularization"", ""few-shot learning""]",We propose a simple yet highly effective set of subspace-based regularizers to address representation learning for few-shot incremental classification.,,,,
boZj4g3Jocj,2021,Reject,False,Learning to communicate through imagination with model-based deep multi-agent reinforcement learning,"[""Arnu Pretorius"", ""Scott Cameron"", ""Andries Petrus Smit"", ""Elan van Biljon"", ""Lawrence Francis"", ""Femi Azeez"", ""Alexandre Laterre"", ""Karim Beguir""]",[],,,,,
bodgPrarPUJ,2021,Reject,False,Lipschitz-Bounded Equilibrium Networks,"[""Max Revay"", ""Ruigang Wang"", ""Ian Manchester""]","[""Adversarial Robustness"", ""Equilibrium Networks"", ""Neural ODE""]",,,,,
bp-LJ4y_XC,2022,Accept (Poster),False,Sequence Approximation using Feedforward Spiking Neural Network for Spatiotemporal Learning: Theory and Optimization Methods,"['Xueyuan She', 'Saurabh Dash', 'Saibal Mukhopadhyay']","[""spiking neural network"", ""spatiotemporal processing"", ""feedforward network""]",A theoretical approache to study the approximation capability of feedforward spiking neural network and optimization methods for such network.,,,,
bpUHBc9HCU8,2022,Reject,False,A General Unified Graph Neural Network Framework Against Adversarial Attacks,"['Yujie Gu', 'Yangkun Cao', 'Qiang Huang', 'Huiyan Sun']","[""Graph Neural Networks"", ""general unified framework"", ""against adversarial attacks"", ""robust model"", ""graph reconstruction operation""]","We propose a general unified GNN framework to jointly clean the graph and denoise features, and further introduce two operations for the graph and features with some prior knowledge to develop a robust model against  adversarial attacks.",,,,
bq7smM1OJIX,2022,Reject,False,Determining the Ethno-nationality of Writers Using Written English Text,"['Deenuka Niroshini Perera', 'Ruvan Weerasinghe', 'Randhil Pushpananda']","[""Ethno-nationality"", ""Native Language Identification"", ""Natural Language Processing"", ""Machine Learning"", ""Linear SVM"", ""Less-controlled environments"", ""ICE corpus""]",This research focuses on determining a person's country of origin using his/her English text written in less-controlled environments using NLP and Machine Learning techniques.,,,,
bsRjn0RH620,2021,Reject,False, Towards Understanding the Cause of Error in Few-Shot Learning,"[""Liang Song"", ""Jinlu Liu"", ""Yongqiang Qin""]","[""upper bound of error"", ""feature separability"", ""classifier discrepancy"", ""few-shot learning""]",A theoretical analysis about the upper bound of error which is determined by linear separability and classifier discrepancy in few-shot learning.,,,,
bsr02xd-utn,2022,Reject,False,Pairwise Adversarial Training for Unsupervised Class-imbalanced Domain Adaptation,"['Weili Shi', 'Ronghang Zhu', 'Sheng Li']","[""domain adaptation adversarial training imbalanced class distribution""]",we tackle with class-imbalanced domain adaptation by the pairwise adversarial training,,,,
bsycpMi00R1,2022,Accept (Poster),False,Generalized Natural Gradient Flows in Hidden Convex-Concave Games and GANs,"['Andjela Mladenovic', 'Iosif Sakos', 'Gauthier Gidel', 'Georgios Piliouras']",[],,,,,
buSCIu6izBY,2022,Reject,False,Occupy & Specify: Investigations into a Maximum Credit Assignment Occupancy Objective for Data-efficient Reinforcement Learning,['Emmanuel DaucÃ©'],"[""Reinforcement Learning"", ""Intrinsic reward"", ""MaxEnt"", ""Probability matching"", ""Motor control"", ""Variational inference""]","A maxent-regularized actor critic follows a specific state occupancy objective (MaCAO), and provides a greater sampling efficacy than the state of the art.",,,,
butEPeLARP_,2021,Reject,False,Predicting the impact of dataset composition on model performance,"[""Tatsunori Hashimoto""]","[""Experimental design"", ""generalization"", ""data collection""]",,,,,
bwq6O4Cwdl,2022,Accept (Poster),False,How Does SimSiam Avoid Collapse Without Negative Samples? Towards a Unified Understanding of Progress in SSL,"['Chaoning Zhang', 'Kang Zhang', 'Chenshuang Zhang', 'Trung X. Pham', 'Chang D. Yoo', 'In So Kweon']","[""SimSiam"", ""Negative samples"", ""SSL"", ""Collapse"", ""Covariance""]",,,,,
bxiDvWZm6zU,2022,Reject,True,Influence-Based Reinforcement Learning for Intrinsically-Motivated Agents,"['Ammar Fayad', 'Majd Ibrahim']","[""Mutli-Agent Reinforcement Learning"", ""Coordination"", ""Intrinsic Motivation"", ""Coordinated Exploration""]",,2108.12581,cs.LG,2021-08-28 05:36:10+00:00,2021-10-13 01:21:08+00:00
bzVsk7bnGdh,2021,Reject,True,"""Hey, that's not an ODE'"": Faster ODE Adjoints with 12 Lines of Code","[""Patrick Kidger"", ""Ricky T. Q. Chen"", ""Terry Lyons""]","[""neural differential equations"", ""neural ordinary differential equations"", ""adjoint""]","With a small change, we roughly double the speed of training neural ODEs.",2009.09457,cs.LG,2020-09-20 15:42:32+00:00,2021-05-10 12:37:42+00:00
c-4HSDAWua5,2022,Accept (Poster),False,SketchODE: Learning neural sketch representation in continuous time,"['Ayan Das', 'Yongxin Yang', 'Timothy Hospedales', 'Tao Xiang', 'Yi-Zhe Song']","[""Chirography"", ""Sketch"", ""Free-form"", ""Neural ODE""]","Modelling continuous time chirographic structures like handwriting, diagrams, sketches etc with Neural Ordinary Differential Equations.",,,,
c1xAGI3nYST,2021,Reject,False,NCP-VAE: Variational Autoencoders with Noise Contrastive Priors,"[""Jyoti Aneja"", ""Alex Schwing"", ""Jan Kautz"", ""Arash Vahdat""]","[""Variational Autoencoders"", ""Noise Contrastive Estimation"", ""Sampling""]","We address the prior hole problem in VAEs using an energy-based prior, trained with noise contrastive estimation.",,,,
c1zLYtHYyQG,2021,Reject,False,Learning from Demonstrations with Energy based Generative Adversarial Imitation Learning,"[""Kaifeng Zhang""]","[""Learning from Demonstrations"", ""Energy based Models"", ""Inverse Reinforcement Learning"", ""Imitation Learning""]","We present an energy based method for generative adversarial imitation learning, which outperforms SoTA methods with theoretical guarantees.",,,,
c3MWGN_cTf,2021,Reject,False,Policy Optimization in Zero-Sum Markov Games: Fictitious Self-Play Provably Attains Nash Equilibria,"[""Boyi Liu"", ""Zhuoran Yang"", ""Zhaoran Wang""]",[],We propose an FSP-type algorithm and  establish its finite-time convergence guarantee in zero-sum Markov games.,,,,
c4iTLTkpY5,2022,Reject,False,Personalized Heterogeneous Federated Learning with Gradient Similarity,"['Jing Xie', 'Xiang Yin', 'Xiyi Zhang', 'Juan Chen', 'Quan Wen', 'Qiang Yang', 'Xuan Mo']",[],This paper studies the personalized heterogeneous FL with gradient similarity,,,,
c5QbJ1zob73,2021,Reject,True,Understanding Self-supervised Learning with Dual Deep Networks,"[""Yuandong Tian"", ""Lantao Yu"", ""Xinlei Chen"", ""Surya Ganguli""]","[""self-supervised learning"", ""teacher-student setting"", ""theoretical analysis"", ""hierarchical models"", ""representation learning""]",A theoretical framework for self-supervised learning with deep ReLU networks explaining recent success of SimCLR and BYOL.,2010.00578,cs.LG,2020-10-01 17:51:49+00:00,2021-02-15 04:51:42+00:00
c5klJN-Bpq1,2021,Reject,False,Generalizing Tree Models for Improving Prediction Accuracy,"[""Jaemin Yoo"", ""Lee Sael""]",[],,,,,
c60vFLXEwED,2022,Reject,False,PIVQGAN: Posture and Identity Disentangled Image-to-Image Translation via Vector Quantization,"['Bingchen Liu', 'Yizhe Zhu', 'Xiao Yang', 'Ahmed Elgammal']","[""deep learning"", ""generative model"", ""image synthesis"", ""generative adversarial network"", ""self-supervised learning"", ""image-to-image translation""]","Image to image translation model with unsupervised training scheme on unpaired and unlabeled data, with a weak but useful self-learned semantic segmentation capability.",,,,
c77KhoLYSwF,2021,Reject,True,Just How Toxic is Data Poisoning?  A Benchmark for Backdoor and Data Poisoning Attacks,"[""Avi Schwarzschild"", ""Micah Goldblum"", ""Arjun Gupta"", ""John P Dickerson"", ""Tom Goldstein""]","[""Poisoning"", ""backdoor"", ""attack"", ""benchmark""]","A novel benchmark for data poisoning and backdoor attacks offers fair comparison of attacks, filling a major gap in the literature to date.",2006.12557,cs.LG,2020-06-22 18:34:08+00:00,2021-06-17 14:10:57+00:00
c7S4WIlmu5,2022,Reject,False,Contrastive Pre-training for Zero-Shot Information Retrieval,"['Gautier Izacard', 'Mathilde Caron', 'Lucas Hosseini', 'Sebastian Riedel', 'Piotr Bojanowski', 'Armand Joulin', 'Edouard Grave']","[""information retrieval"", ""contrastive pretraining""]",Contrastive pretraining for information retrieval.,,,,
c7rtqjVaWiE,2021,Reject,False,Efficient Sampling for Generative Adversarial Networks with Reparameterized Markov Chains,"[""Yifei Wang"", ""Yisen Wang"", ""Jiansheng Yang"", ""Zhouchen Lin""]","[""Generative Adverarial Networks"", ""Sampling"", ""Markov chain Monte Carlo"", ""Reparameterization""]","We develop a novel sampling method for GANs, called REP-GAN, that enjoys better sample efficiency and sample quality.",2107.00352,stat.ML,2021-07-01 10:34:55+00:00,2021-07-01 10:34:55+00:00
c87d0TS4yX,2022,Accept (Poster),False,Orchestrated Value Mapping for Reinforcement Learning,"['Mehdi Fatemi', 'Arash Tavakoli']","[""Reinforcement Learning"", ""Value Mapping"", ""Reward Decomposition""]",We present a general convergent class of RL algorithms based on combining arbitrary value mappings and reward decomposition. ,,,,
c8AvdRAyVkz,2022,Reject,False,Perturbation Deterioration: The Other Side of Catastrophic Overfitting,"['Zichao Li', 'Liyuan Liu', 'Chengyu Dong', 'Jingbo Shang']",[],"We reveal that the other side of catastrophic overfitting is perturbation underfitting, and propose a novel method to prevent catastrophic overfitting by alleviating perturbation deterioration.",,,,
c8JDlJMBeyh,2022,Reject,False,Towards Generic Interface for Human-Neural Network Knowledge Exchange,"['Yunhao Ge', 'Yao Xiao', 'Zhi Xu', 'Linwei Li', 'Ziyan Wu', 'Laurent Itti']",[],"We propose Human-NN-Interface (HNI), a framework using a structural representation of visual concepts as a âlanguageâ for humans and NN to communicate, interact, and exchange knowledge.",,,,
c8P9NQVtmnO,2021,Accept (Poster),False,Fourier Neural Operator for Parametric Partial Differential Equations,"[""Zongyi Li"", ""Nikola Borislavov Kovachki"", ""Kamyar Azizzadenesheli"", ""Burigede liu"", ""Kaushik Bhattacharya"", ""Andrew Stuart"", ""Anima Anandkumar""]","[""Partial differential equation"", ""Fourier transform"", ""Neural operators""]",A novel neural operator based on Fourier transformation for learning partial differential equations.,,,,
c9-WeM-ceB,2021,Accept (Poster),False,Saliency is a Possible Red Herring When Diagnosing Poor Generalization,"[""Joseph D Viviano"", ""Becks Simpson"", ""Francis Dutil"", ""Yoshua Bengio"", ""Joseph Paul Cohen""]","[""Feature Attribution"", ""Generalization"", ""Saliency""]",We controlled feature construction on images using masks to help models generalize to test distributions with covariate shift and noticed that it didn't affect the saliency maps in the way one would expect even though it improved generalization.,,,,
c9IvZqZ8SNI,2022,Reject,False,Learning Structure from the Ground up---Hierarchical Representation Learning by Chunking,"['Shuchen Wu', 'Noemi Elteto', 'Ishita Dasgupta', 'Eric Schulz']","[""representation learning"", ""interpretability"", ""cognitive science""]",We have proposed the Hierarchical Chunking Model (HCM) as a cognitively-inspired method for learning representations from the ground up.,,,,
cAvgPMAA3hb,2021,Reject,True,GRF: Learning a General Radiance Field for 3D Scene Representation and Rendering,"[""Alex Trevithick"", ""Bo Yang""]","[""3D scene representation"", ""novel view synthesis"", ""neural rendering""]",An implicit neural function to represent and render complex 3D scenes only from 2D views.,2010.04595,cs.CV,2020-10-09 14:21:43+00:00,2021-08-11 07:09:11+00:00
cB_mXKTs9J,2021,Reject,False,What Do Deep Nets Learn? Class-wise Patterns Revealed in the Input Space,"[""Shihao Zhao"", ""Xingjun Ma"", ""Yisen Wang"", ""James Bailey"", ""Bo Li"", ""Yu-Gang Jiang""]","[""deep neural networks"", ""deep learning understanding"", ""backdoor vulnerability"", ""adversarial vulnerability""]",An input space visualization method that reveals what deep nets learn for each class.,2101.06898,cs.CV,2021-01-18 06:38:41+00:00,2021-02-06 05:09:40+00:00
cBu4ElJfneV,2022,Accept (Poster),False,GiraffeDet: A Heavy-Neck Paradigm for Object Detection,"['yiqi jiang', 'Zhiyu Tan', 'Junyan Wang', 'Xiuyu Sun', 'Ming Lin', 'Hao Li']","[""Object Detection"", ""fpn"", ""space-to-depth"", ""representation""]","we propose a novel heavy-neck paradigm(GiraffeDet) for detection task, which allows detectors to process the high-level categorical information and low-level spatial information uniformly, making it more effective in detection tasks.  ",2202.04256,cs.CV,2022-02-09 03:23:49+00:00,2022-02-09 03:23:49+00:00
cD0O_Sc-wNy,2022,Reject,False,Learn the Time to Learn: Replay Scheduling for Continual Learning,"['Marcus Klasson', 'Hedvig Kjellstrom', 'Cheng Zhang']","[""Continual Learning"", ""Replay Memory"", ""Task Incremental Learning""]",,,,,
cFpWC6ZMtmj,2021,Reject,True,Explainability for fair machine learning,"[""Tom Begley"", ""Tobias Schwedes"", ""Christopher Frye"", ""Ilya Feige""]","[""explainability"", ""fairness"", ""Shapley""]",Explainability methods for understanding fairness in machine learning models.,2010.07389,cs.LG,2020-10-14 20:21:01+00:00,2020-10-14 20:21:01+00:00
cGDAkQo1C0p,2022,Accept (Poster),False,Reversible Instance Normalization for Accurate Time-Series Forecasting against Distribution Shift,"['Taesung Kim', 'Jinhee Kim', 'Yunwon Tae', 'Cheonbok Park', 'Jang-Ho Choi', 'Jaegul Choo']","[""Time-series forecasting"", ""Normalization"", ""Distribution shift""]","We propose a simple yet effective normalization method, reversible instance normalization (RevIN), which solves the time-series forecasting task against the distribution shift problem.",,,,
cKTBRHIVjy9,2022,Reject,False,SubMix: Practical Private Prediction for Large-scale Language Models,"['Tony A Ginart', 'Laurens van der Maaten', 'James Zou', 'Chuan Guo']","[""private prediction"", ""language models"", ""user privacy"", ""machine learning""]",,,,,
cKnKJcTPRcV,2021,Reject,False,HyperSAGE: Generalizing Inductive Representation Learning on Hypergraphs,"[""Devanshu Arya"", ""Deepak Gupta"", ""Stevan Rudinac"", ""Marcel Worring""]","[""Hypergraph"", ""Representation Learning"", ""Inductive Learning"", ""Geometric Deep Learning"", ""Aggregation Methods""]",HyperSAGE is a generalized inductive approach for representation learning on hypergraphs that exploits its full expressive power without any loss of information. ,,,,
cL4wkyoxyDJ,2021,Reject,False,Towards Counteracting Adversarial Perturbations to Resist Adversarial Examples,"[""Haimin ZHANG"", ""Min Xu""]","[""adversarial robustness"", ""resisting adversarial examples""]",This paper proposes a method   that uses small first-order perturbations to defend against adversarial attacks.,2103.04565,cs.CV,2021-03-08 06:27:24+00:00,2021-05-10 06:46:56+00:00
cLcLdwOfhoe,2022,Reject,False,FedLite: A Scalable Approach for Federated Learning on Resource-constrained Clients,"['Jianyu Wang', 'Hang Qi', 'Ankit Singh Rawat', 'Sashank J. Reddi', 'Sagar M. Waghmare', 'Felix Yu', 'Gauri Joshi']",[],,,,,
cMBKc-0OTY5,2022,Reject,False,Kalman Filter Is All You Need: Optimization Works When Noise Estimation Fails,"['Ido Greenberg', 'Shie Mannor', 'Netanel Yannay']","[""Kalman Filter"", ""noise estimation"", ""optimization"", ""gradient descent"", ""parameterization""]","Optimization of the KF parameters (instead of determining them by noise estimation) is crucial whenever the KF assumptions are violated, and sometimes removes the need for more complicated models such as neural networks.",,,,
cO1IH43yUF,2021,Accept (Poster),False,Revisiting Few-sample BERT Fine-tuning,"[""Tianyi Zhang"", ""Felix Wu"", ""Arzoo Katiyar"", ""Kilian Q Weinberger"", ""Yoav Artzi""]","[""Fine-tuning"", ""Optimization"", ""BERT""]",,,,,
cOtBRgsf2fO,2022,Accept (Poster),True,Label Leakage and Protection in Two-party Split Learning,"['Oscar Li', 'Jiankai Sun', 'Xin Yang', 'Weihao Gao', 'Hongyi Zhang', 'Junyuan Xie', 'Virginia Smith', 'Chong Wang']","[""Split Learning"", ""label leakage"", ""privacy"", ""privacy protection""]",We identify the label leakage threat in two-party split learning with concrete threat examples and propose random perturbation methods to protect against such threats.,2102.08504,cs.LG,2021-02-17 00:01:49+00:00,2021-10-23 02:56:46+00:00
cP2fJWhYZe0,2021,Reject,True,Overinterpretation reveals image classification model pathologies,"[""Brandon Carter"", ""Siddhartha Jain"", ""Jonas Mueller"", ""David Gifford""]","[""computer vision"", ""benchmarks"", ""datasets"", ""convolutional neural networks"", ""interpretability"", ""robustness"", ""overinterpretation""]",We demonstrate that neural networks trained on CIFAR-10 and ImageNet overinterpret their inputs and rely upon semantically meaningless features present in unmodified input pixels.,2003.08907,cs.LG,2020-03-19 17:12:23+00:00,2021-10-26 17:40:11+00:00
cP5IcoAkfKa,2021,Accept (Poster),False,Large Batch Simulation for Deep Reinforcement Learning,"[""Brennan Shacklett"", ""Erik Wijmans"", ""Aleksei Petrenko"", ""Manolis Savva"", ""Dhruv Batra"", ""Vladlen Koltun"", ""Kayvon Fatahalian""]","[""reinforcement learning"", ""simulation""]",,2103.07013,cs.LG,2021-03-12 00:22:50+00:00,2021-03-12 00:22:50+00:00
cPZOyoDloxl,2021,Accept (Oral),False,SMiRL: Surprise Minimizing Reinforcement Learning in Unstable Environments,"[""Glen Berseth"", ""Daniel Geng"", ""Coline Manon Devin"", ""Nicholas Rhinehart"", ""Chelsea Finn"", ""Dinesh Jayaraman"", ""Sergey Levine""]","[""Reinforcement learning""]",Using Bayesian surprise as an unsupervised intrinsic reward function to learn complex behaviors in unstable environments.,,,,
cQzf26aA3vM,2021,Reject,False,Design-Bench: Benchmarks for Data-Driven Offline Model-Based Optimization,"[""Brandon Trabucco"", ""Aviral Kumar"", ""Xinyang Geng"", ""Sergey Levine""]","[""Model-Based Optimization"", ""Benchmark"", ""Offline""]","Design-Bench, a benchmark suite of offline MBO tasks with a unified evaluation protocol and reference implementations of existing methods.",,,,
cR91FAodFMe,2021,Accept (Poster),True,Learning to Set Waypoints for Audio-Visual Navigation,"[""Changan Chen"", ""Sagnik Majumder"", ""Ziad Al-Halah"", ""Ruohan Gao"", ""Santhosh Kumar Ramakrishnan"", ""Kristen Grauman""]","[""visual navigation"", ""audio visual learning"", ""embodied vision""]",We introduce a hierarchical reinforcement learning approach to audio-visual navigation that learns to dynamically set waypoints in an end-to-end fashion ,2008.09622,cs.CV,2020-08-21 18:00:33+00:00,2021-02-11 18:36:45+00:00
cT0jK5VvFuS,2021,Reject,False,Uncertainty in Neural Processes,"[""Saeid Naderiparizi"", ""Kenny Chiu"", ""Benjamin Bloem-Reddy"", ""Frank Wood""]","[""Neural Processes"", ""Meta-learning"", ""Variational Inference""]",,,,,
cTQnZPLIohy,2021,Reject,False,Lie Algebra Convolutional Neural Networks with Automatic Symmetry Extraction,"[""Nima Dehmamy"", ""Yanchen Liu"", ""Robin Walters"", ""Rose Yu""]","[""equivariance"", ""group convolutional neural network"", ""inductive bias"", ""group equivariant architecture"", ""Lie group"", ""Lie algebra""]",A new approach to group equivariant convolutional architectures capable of learning symmetries during training.  ,,,,
cTbIjyrUVwJ,2021,Accept (Poster),False,Learning Accurate Entropy Model with Global Reference for Image Compression,"[""Yichen Qian"", ""Zhiyu Tan"", ""Xiuyu Sun"", ""Ming Lin"", ""Dongyang Li"", ""Zhenhong Sun"", ""Li Hao"", ""Rong Jin""]","[""Image compression"", ""Entropy Model"", ""Global Reference""]","In this paper, we propose a novel Reference-based Model for image compression to effectively leverage both the local and global context information, which yields an enhanced compression performance.",,,,
cU0a02VF8ZG,2021,Reject,False,Globetrotter: Unsupervised Multilingual Translation from Visual Alignment,"[""Didac Suris Coll-Vinent"", ""Dave Epstein"", ""Carl Vondrick""]","[""cross-modal"", ""multilingual"", ""unsupervised translation"", ""visual similarity""]",We propose a method that leverages cross- modal alignment between language and vision to train a multilingual translation system without any parallel corpora. ,,,,
cU8rknuhxc,2022,Accept (Spotlight),False,Learning more skills through optimistic exploration,"['DJ Strouse', 'Kate Baumli', 'David Warde-Farley', 'Volodymyr Mnih', 'Steven Stenberg Hansen']","[""intrinsic control"", ""skill discovery"", ""unsupervised skill learning"", ""uncertainty estimation"", ""optimistic exploration"", ""variational information maximization""]",Learn more skills by adding an information gain exploration bonus based on discriminator ensemble disagreement.,,,,
cVak2hs06z,2022,Reject,False,Correct-N-Contrast: a Contrastive Approach for Improving Robustness to Spurious Correlations,"['Michael Zhang', 'Nimit Sharad Sohoni', 'Hongyang Zhang', 'Chelsea Finn', 'Christopher Re']","[""spurious correlations"", ""contrastive learning"", ""robustness"", ""group shifts""]","We propose Correct-N-Contrast, a contrastive learning method to substantially improve neural network robustness to spurious correlations.",,,,
cWlMII1LwTZ,2022,Reject,False,Task-aware Privacy Preservation for Multi-dimensional Data,"['Jiangnan Cheng', 'Ao Tang', 'Sandeep P. Chinchali']","[""Privacy"", ""Representation Learning""]",We present a theoretically-grounded algorithm to encode and anonymize salient features of complex data to improve a machine learning task's performance while outperforming standard differential privacy benchmarks. ,,,,
cYek5NoXNiX,2021,Reject,False,On Proximal Policy Optimization's Heavy-Tailed Gradients ,"[""Saurabh Garg"", ""Joshua Zhanson"", ""Emilio Parisotto"", ""Adarsh Prasad"", ""J Zico Kolter"", ""Zachary Chase Lipton"", ""Sivaraman Balakrishnan"", ""Ruslan Salakhutdinov"", ""Pradeep Kumar Ravikumar""]","[""Heavy-tailed Gradients"", ""Proximal Policy Optimization"", ""Robust Estimation"", ""Deep Reinforcement Learning""]",We study the heavy-tailed behavior of gradients in PPO and propose incorporating GMOM (a robust estimator from statistic) as a substitute.,,,,
cYr2OPNyTz7,2021,Reject,True,Improving Self-supervised Pre-training via a Fully-Explored Masked Language Model,"[""Mingzhi Zheng"", ""Dinghan Shen"", ""yelong shen"", ""Weizhu Chen"", ""Lin Xiao""]","[""representation learning"", ""natural language processing""]",A novel masking strategy is proposed to improve the training efficiency of the Masked Language Model (MLM) framework.,2010.06040,cs.CL,2020-10-12 21:28:14+00:00,2020-10-14 04:45:59+00:00
cZAi1yWpiXQ,2022,Accept (Poster),True,Adversarial Robustness Through the Lens of Causality,"['Yonggang Zhang', 'Mingming Gong', 'Tongliang Liu', 'Gang Niu', 'Xinmei Tian', 'Bo Han', 'Bernhard SchÃ¶lkopf', 'Kun Zhang']","[""Adversarial examples"", ""Causality""]",The first attempt towards using causality to understand and mitigate adversarial vulnerability.,2106.06196,cs.LG,2021-06-11 06:55:02+00:00,2021-06-11 06:55:02+00:00
c_E8kFWfhp0,2021,Accept (Poster),False,gradSim: Differentiable simulation for system identification and visuomotor control,"[""J. Krishna Murthy"", ""Miles Macklin"", ""Florian Golemo"", ""Vikram Voleti"", ""Linda Petrini"", ""Martin Weiss"", ""Breandan Considine"", ""J\u00e9r\u00f4me Parent-L\u00e9vesque"", ""Kevin Xie"", ""Kenny Erleben"", ""Liam Paull"", ""Florian Shkurti"", ""Derek Nowrouzezahrai"", ""Sanja Fidler""]","[""Differentiable simulation"", ""System identification"", ""Physical parameter estimation"", ""3D scene understanding"", ""3D vision"", ""Differentiable rendering"", ""Differentiable physics""]",Differentiable models of time-varying dynamics and image formation pipelines result in highly accurate physical parameter estimation from video,,,,
cbdp6RLk2r7,2021,Reject,False,Addressing the Topological Defects of Disentanglement,"[""Diane Bouchacourt"", ""Mark Ibrahim"", ""Stephane Deny""]","[""Disentanglement"", ""Equivariance"", ""Topology"", ""Representation theory"", ""Character theory""]","We use topological arguments to show that disentanglement as commonly defined introduces discontinuities in the encoder, which leads us to propose a new approach to disentanglement through distributed equivariant operators.",,,,
cbtV7xGO9pS,2021,Reject,False,TEAC: Intergrating Trust Region and Max Entropy Actor Critic for Continuous Control,"[""Hongyu Zang"", ""Xin Li"", ""Li Zhang"", ""Peiyao Zhao"", ""Mingzhong Wang""]","[""Reinforcement Learning"", ""Trust region methods"", ""Maximum Entropy Reinforcement Learning"", ""Deep Reinforcement Learning""]",We propose a novel off-policy trust entropy actor critic method  to learn stable and sufficiently explored policies for continuous states and actions.,,,,
ccWaPGl9Hq,2022,Accept (Spotlight),False,Towards Deployment-Efficient Reinforcement Learning: Lower Bound and Optimality,"['Jiawei Huang', 'Jinglin Chen', 'Li Zhao', 'Tao Qin', 'Nan Jiang', 'Tie-Yan Liu']","[""reinforcement learning theory"", ""deployment efficiency"", ""linear MDP""]",We propose a formal theoretical formulation for depolyment-efficient reinforcement learning; establish lower bounds for deployment complexity and study near-optimal deployment-efficient algorithms in linear MDP setting.,,,,
ccwT339SIu,2021,Reject,False,Contrastive Video Textures,"[""Medhini Narasimhan"", ""Shiry Ginosar"", ""Andrew Owens"", ""Alexei A Efros"", ""Trevor Darrell""]","[""Video Textures"", ""Audio Conditioned Video Synthesis"", ""Self-Supervised learning"", ""Contrastive Learning""]","We introduce Contrastive Video Textures, a non-parametric approach for infinite video generation based on learning to resample frames from an input video.",,,,
cdZLe5S0ur,2022,Reject,False,AQUILA: Communication Efficient Federated Learning with Adaptive Quantization of Lazily-Aggregated Gradients,"['Zihao Zhao', 'Yuzhu Mao', 'Muhammad Zeeshan', 'Yang Liu', 'Tian Lan', 'Wenbo Ding']","[""Federated Learning"", ""communication efficiency"", ""adaptive quantization""]",,,,,
cdwobSbmsjA,2022,Reject,False,RAVE: A variational autoencoder for fast and high-quality neural audio synthesis,"['Antoine Caillon', 'Philippe Esling']","[""Variational Autoencoder"", ""generative models"", ""audio"", ""music"", ""deep learning"", ""representation learning"", ""latent space""]",,2111.05011,cs.LG,2021-11-09 09:07:30+00:00,2021-12-15 16:42:14+00:00
ce6CFXBh30h,2021,Accept (Poster),True,Federated Semi-Supervised Learning with Inter-Client Consistency & Disjoint Learning,"[""Wonyong Jeong"", ""Jaehong Yoon"", ""Eunho Yang"", ""Sung Ju Hwang""]","[""Federated Learning""]","We introduce a new practical problem of federated learning with a deficiency of supervision and study two realistic scenarios with a novel method to tackle the problems, including inter-client consistency and disjoint learning.",2006.12097,cs.LG,2020-06-22 09:43:41+00:00,2021-03-29 08:26:03+00:00
cef_G2hkiGc,2021,Reject,False,"More Side Information, Better Pruning: Shared-Label Classification as a Case Study","[""Omer Leibovitch"", ""Nir Ailon""]","[""Pruning"", ""Compression"", ""CNN"", ""LSTM"", ""Image classification""]","The paper presents the practical problem of combining deep network pruning algorithms in scenarios involving additional side information on the data, suggests various solutions and reports empirical findings on their merits.",,,,
cggphp7nPuI,2022,Reject,False,Reasoning-Modulated Representations,"['Petar VeliÄkoviÄ', 'Matko BoÅ¡njak', 'Thomas Kipf', 'Alexander Lerchner', 'raia hadsell', 'Razvan Pascanu', 'Charles Blundell']","[""representation learning"", ""algorithmic reasoning"", ""graph neural networks"", ""relational learning""]","We investigate how the representations captured by neural networks can be modulated by abstract reasoning modules (which respect the dynamics of the underlying task), leading to gains in data efficiency.",,,,
chPj_I5KMHG,2021,Accept (Poster),True,Grounding Language to Autonomously-Acquired Skills via Goal Generation,"[""Ahmed Akakzia"", ""C\u00e9dric Colas"", ""Pierre-Yves Oudeyer"", ""Mohamed CHETOUANI"", ""Olivier Sigaud""]","[""Deep reinforcement learning"", ""intrinsic motivations"", ""symbolic representations"", ""autonomous learning""]",We propose a new RL architecture called Language-Goal-Behavior that proposes to decouple skill learning and language grounding via the introduction of an intermediate semantic goal representation.,2006.07185,cs.AI,2020-06-12 13:46:10+00:00,2021-01-25 15:47:16+00:00
ci7LBzDn2Q,2022,Accept (Poster),False,Deep ReLU Networks Preserve Expected Length,"['Boris Hanin', 'Ryan S Jeong', 'David Rolnick']","[""deep learning theory"", ""random ReLU networks"", ""length distortion"", ""initialization"", ""expressivity""]","This article proves that, both on average and with high probability, randomly initialized ReLU networks with width larger than depth do not distort lengths and volumes. ",,,,
ciSap6Cw5mk,2022,Reject,True,MANDERA: Malicious Node Detection in Federated Learning via Ranking,"['Wanchuang Zhu', 'Benjamin Zi Hao Zhao', 'Simon Luo', 'Ke Deng']","[""Federated Learning"", ""Data poisoning attack"", ""Byzantine attack"", ""Malicious node detection"", ""Ranking""]",The paper derives theoretical guarentees on and experimentally demonstrates effective detection of malicious poisoning nodes in federated learning with unsupervised clustering on the rank domain of gradient updates.,2110.11736,cs.LG,2021-10-22 12:14:16+00:00,2021-10-22 12:14:16+00:00
cjk5mri_aOm,2021,Reject,False,Environment Predictive Coding for Embodied Agents,"[""Santhosh Kumar Ramakrishnan"", ""Tushar Nagarajan"", ""Ziad Al-Halah"", ""Kristen Grauman""]","[""Self-supervised learning"", ""visual navigation""]","We introduce environment predicting coding, a self-supervised approach for learning environment-level representations for embodied agents.",,,,
ckZY7DGa7FQ,2022,Accept (Poster),False,A Fine-Tuning Approach to Belief State Modeling,"['Samuel Sokota', 'Hengyuan Hu', 'David J Wu', 'J Zico Kolter', 'Jakob Nicolaus Foerster', 'Noam Brown']","[""imperfect-information"", ""partial observability"", ""search"", ""decision-time planning""]",A method for improving the accuracy of belief state models and for approximating public belief states at scale.,,,,
clwYez4n8e8,2022,Reject,False,Logarithmic Unbiased Quantization: Practical 4-bit Training in Deep Learning,"['Brian Chmiel', 'Ron Banner', 'Elad Hoffer', 'Hilla Ben Yaacov', 'Daniel Soudry']","[""quantization"", ""efficient training"", ""4 bit training""]",A practical method to train deep neural networks with 4-bit achieving state-of-the-art results,,,,
clyAUUnldg,2021,Reject,False,AdaDGS: An adaptive black-box optimization method with a nonlocal directional Gaussian smoothing gradient,"[""Hoang A Tran"", ""Guannan Zhang""]",[],We developed an adaptive algorithm to avoid fine hyper-parameter tuning of a nonlocal black-box optimization method for high-dimensional problems. ,,,,
cmcwUBKeoUH,2021,Reject,False,Learning Blood Oxygen from Respiration Signals,"[""Hao He"", ""Ying-Cong Chen"", ""Yuan Yuan"", ""Dina Katabi""]","[""healthcare"", ""medical application""]",,,,,
cmt-6KtR4c4,2022,Accept (Spotlight),False,Leveraging Automated Unit Tests for Unsupervised Code Translation,"['Baptiste Roziere', 'Jie Zhang', 'Francois Charton', 'Mark Harman', 'Gabriel Synnaeve', 'Guillaume Lample']","[""unsupervised"", ""translation"", ""code"", ""self-training"", ""pseudo-labelling"", ""unit tests"", ""programming languages"", ""deep learning"", ""transformer""]",We leverage automatically created multilingual unit tests to improve unsupervised machine translation methods for source code and substantially outperform the state-of-the-art on all the language pairs we consider.,,,,
cotg54BSX8,2021,Reject,False,Grey-box Extraction of Natural Language Models,"[""Santiago Zanella-Beguelin"", ""Shruti Tople"", ""Andrew Paverd"", ""Boris K\u00f6pf""]","[""language models"", ""transformer"", ""model extraction"", ""security""]",We demonstrate effective grey-box extraction of classification layers of natural language models with public encoders,,,,
cpDhcsEDC2,2022,Accept (Poster),False,FILIP: Fine-grained Interactive Language-Image Pre-Training,"['Lewei Yao', 'Runhui Huang', 'Lu Hou', 'Guansong Lu', 'Minzhe Niu', 'Hang Xu', 'Xiaodan Liang', 'Zhenguo Li', 'Xin Jiang', 'Chunjing Xu']","[""Visual-language pretraining"", ""Language-Image Pretraining"", ""Multi-modality model""]","We introduce a large-scale Fine-grained Interacitve Language-Image Pretraining (FILIP) to achieve finer-level alignment through a new cross-modal late interaction mechanism, which can boost the performance on more grounded vision and language tasks.",2111.07783,cs.CV,2021-11-09 17:15:38+00:00,2021-11-09 17:15:38+00:00
cpstx0xuvRY,2022,Reject,False,Information-Theoretic Generalization Bounds for Iterative Semi-Supervised Learning,"['Haiyun He', 'Hanshu YAN', 'Vincent Tan']","[""Generalization error"", ""Information theory"", ""Semi-supervised learning""]",We study the behaviour of the generalization error of iterative semi-supervised learning algorithms using information-theoretic principles.,,,,
crAi7c41xTh,2021,Reject,True,Shape Matters: Understanding the Implicit Bias of the Noise Covariance,"[""Jeff Z. HaoChen"", ""Colin Wei"", ""Jason D. Lee"", ""Tengyu Ma""]","[""implicit regularization"", ""implicit bias"", ""algorithmic regularization"", ""over-parameterization"", ""learning theory""]","We theoretically prove that in an over-parameterized setting, SGD with label noise recovers the ground-truth, whereas SGD with spherical Gaussian noise overfits.",2006.08680,cs.LG,2020-06-15 18:31:02+00:00,2020-06-18 03:34:08+00:00
ct8_a9h1M,2021,Accept (Poster),False,Contextual Dropout: An Efficient Sample-Dependent Dropout Module,"[""XINJIE FAN"", ""Shujian Zhang"", ""Korawat Tanwisuth"", ""Xiaoning Qian"", ""Mingyuan Zhou""]","[""Efficient Inference Methods"", ""Probabilistic Methods"", ""Supervised Deep Networks""]","We propose contextual dropout as a scalable sample-dependent dropout method, which makes the dropout probabilities depend on the input covariates of each data sample.",2103.04181,cs.LG,2021-03-06 19:30:32+00:00,2021-03-06 19:30:32+00:00
ctgsGEmWjDY,2021,Reject,False,On The Adversarial Robustness of 3D Point Cloud Classification,"[""Jiachen Sun"", ""Karl Koenig"", ""Yulong Cao"", ""Qi Alfred Chen"", ""Zhuoqing Mao""]","[""Adversarial Machine Learning"", ""Point Cloud Classification"", ""Adversarial Training""]","In this work, we first design adaptive attacks to break the state-of-the-art defenses against adversarial point cloud classification and further improve the adversarial training performance of point cloud classification models by a large margin.",,,,
cu7IUiOhujH,2021,Accept (Poster),False,Supervised Contrastive Learning for Pre-trained Language Model Fine-tuning,"[""Beliz Gunel"", ""Jingfei Du"", ""Alexis Conneau"", ""Veselin Stoyanov""]","[""pre-trained language model fine-tuning"", ""supervised contrastive learning"", ""natural language understanding"", ""few-shot learning"", ""robustness"", ""generalization""]",,,,,
cuDFRRANJ-5,2021,Reject,False,Formalizing Generalization and Robustness of Neural Networks to Weight Perturbations,"[""Yu-Lin Tsai"", ""Chia-Yi Hsu"", ""Chia-Mu Yu"", ""Pin-Yu Chen""]","[""Generalization"", ""Robustness"", ""Neural Network"", ""Weight Perturbation"", ""Rademacher complexity""]","We provide a comprehensive theoretical analysis on the generalization and robustness of neural networks against weight perturbations, and propose a new theory-driven training loss",2103.02200,cs.LG,2021-03-03 06:17:03+00:00,2021-03-03 06:17:03+00:00
cuGIoqAJf6p,2022,Reject,True,"Newer is not always better: Rethinking transferability metrics, their peculiarities, stability and performance","['Shibal Ibrahim', 'Natalia Ponomareva', 'Rahul Mazumder']","[""transferability metrics"", ""fine-tuning"", ""transfer learning"", ""discrepancy measures"", ""domain adaptation""]",Improved transferability estimation for supervised and unsupervised transferability measures for fine-tuning for small samples.,2110.06893,cs.LG,2021-10-13 17:24:12+00:00,2021-10-25 23:28:58+00:00
cuvga_CiVND,2022,Accept (Poster),False,No Parameters Left Behind: Sensitivity Guided Adaptive Learning Rate for Training Large Transformer Models,"['Chen Liang', 'Haoming Jiang', 'Simiao Zuo', 'Pengcheng He', 'Xiaodong Liu', 'Jianfeng Gao', 'Weizhu Chen', 'Tuo Zhao']","[""Training Large Transformer Models"", ""Reducing Model Redundancy"", ""Parameter Sensitivity"", ""Adaptive Learning Rate Method"", ""Model Generalization"", ""Model Pruning""]",We propose a novel adaptive learning rate training strategy for large Transformer models that encourages all parameters to be trained sufficiently.,2202.02664,cs.CL,2022-02-06 00:22:28+00:00,2022-02-06 00:22:28+00:00
cvNYovr16SB,2021,Reject,False,Unsupervised Active Pre-Training for Reinforcement Learning,"[""Hao Liu"", ""Pieter Abbeel""]","[""Reinforcement Learning"", ""Unsupervised Learning"", ""Entropy Maximization"", ""Contrastive Learning"", ""Self-supervised Learning"", ""Exploration""]","We propose APT, a reward-free pre-training approach which is based on maximizing particle-based entropy in contrastive representation space for learning pre-trained models that can be leveraged for solving downstream tasks efficiently",2103.04551,cs.LG,2021-03-08 05:16:49+00:00,2021-10-28 05:56:28+00:00
cw-EmNq5zfD,2022,Accept (Poster),False,Group-based Interleaved Pipeline Parallelism for Large-scale DNN Training,"['PengCheng Yang', 'Xiaoming Zhang', 'Wenpeng Zhang', 'Ming Yang', 'Hong Wei']","[""Model parallelism"", ""Pipeline parallelism"", ""Distributed training""]",,,,,
cxRUccyjw0S,2021,Reject,False,Learning Disentangled Representations for Image Translation,"[""Aviv Gabbay"", ""Yedid Hoshen""]","[""disentanglement"", ""image translation"", ""latent optimization""]",A disentanglement method for high-fidelity image translation,,,,
cy0jU8F60Hy,2021,Reject,False,ACT: Asymptotic Conditional Transport,"[""Huangjie Zheng"", ""Mingyuan Zhou""]","[""Statistical distance"", ""Divergence"", ""Optimal Transport"", ""Implicit Distribution"", ""Deep Generative Models"", ""GANs""]",We propose asymptotic conditional transport as a new probability-distance measure and apply it to improve existing deep generative models.,,,,
czmQDWhGwd9,2022,Reject,False,Representations of Computer Programs in the Human Brain,"['Shashank Srikant', 'Benjamin Lipkin', 'Anna A Ivanova', 'Evelina Fedorenko', ""Una-May O'Reilly""]","[""ML for PL/SE"", ""ML models of code"", ""Code representations"", ""Brain representations"", ""Cognitive neuroscience"", ""Multivoxel pattern analysis"", ""Representation decoding analysis"", ""Representation similarity analysis"", ""fMRI analysis""]",An analysis to determine whether ML models trained on code corpora learn the same information that our brains learn when we comprehend code.,,,,
czv8Ac3Kg7l,2021,Reject,False,Sparse Gaussian Process Variational Autoencoders,"[""Matthew Ashman"", ""Jonathan So"", ""William Tebbutt"", ""Vincent Fortuin"", ""Michael Arthur Leopold Pearce"", ""Richard E Turner""]","[""Gaussian process"", ""variational inference"", ""variational autoencoders"", ""Bayesian inference""]",,,,,
d-XzF81Wg1,2021,Accept (Poster),False,Deconstructing the Regularization of BatchNorm,"[""Yann Dauphin"", ""Ekin Dogus Cubuk""]","[""deep learning"", ""batch normalization"", ""regularization"", ""understanding neural networks""]",We deconstruct the regularization effect of batch normalization and show that preventing explosive growth at the final layer at initialization and during training can recover a large part of BatchNorm's generalization boost.,,,,
d20jtFYzyxe,2022,Reject,False,A Rate-Distortion Approach to Domain Generalization,"['Yihang Chen', 'Grigorios Chrysos', 'Volkan Cevher']",[],,,,,
d2TT6gK9qZn,2022,Accept (Poster),False,Non-Linear Operator Approximations for Initial Value Problems,"['Gaurav Gupta', 'Xiongye Xiao', 'Radu Balan', 'Paul Bogdan']","[""exponential operators"", ""initial value problem"", ""pade approximation"", ""multiwavelets"", ""partial differential equations""]",A PadÃ© approximation based exponential operator module is proposed for working with the Initial Value Problems. The compactness of model yields data-efficiency and better performance which is demonstrated on scarce real-world dataset.,,,,
d2XZsOT-_U_,2022,Reject,False,Match Prediction Using Learned History Embeddings,"['Maxwell Goldstein', 'Leon Bottou', 'Rob Fergus']","[""skill ranking"", ""skill rating"", ""skill""]",A transformer-based skill rating system,,,,
d5IQ3k7ed__,2022,Reject,False,Finding General Equilibria in Many-Agent Economic Simulations using Deep Reinforcement Learning,"['Michael Curry', 'Alexander R Trott', 'Soham Phade', 'Yu Bai', 'Stephan Zheng']","[""reinforcement learning"", ""economics"", ""simulation"", ""multi-agent RL"", ""equilibrium""]",We present empirical techniques for training an economic simulation with a hierarchy of agent types and large numbers of agents.,,,,
d5SCUJ5t1k,2022,Accept (Poster),True,Objects in Semantic Topology,"['Shuo Yang', 'Peize Sun', 'Yi Jiang', 'Xiaobo Xia', 'Ruiheng Zhang', 'Zehuan Yuan', 'Changhu Wang', 'Ping Luo', 'Min Xu']",[],,2110.02687,cs.CV,2021-10-06 12:15:30+00:00,2021-10-06 12:15:30+00:00
d7-GwtDWNNJ,2022,Reject,False,Learning Graph Structure from Convolutional Mixtures,"['Max Wasserman', 'Saurabh Sihag', 'Gonzalo Mateos', 'Alejandro Ribeiro']","[""Graph Neural Network"", ""Graph Signal Processing"", ""Graph Learning"", ""Topology Inference"", ""Algorithm Unrolling""]",,,,,
d71n4ftoCBy,2022,Accept (Poster),False,FedPara: Low-rank Hadamard Product for Communication-Efficient Federated Learning,"['Nam Hyeon-Woo', 'Moon Ye-Bin', 'Tae-Hyun Oh']","[""Federated learning"", ""Parameterization"", ""Communication efficiency""]",New communication-efficient neural network parameterization for federated learning.,,,,
d7KBjmI3GmQ,2021,Accept (Poster),True,Measuring Massive Multitask Language Understanding,"[""Dan Hendrycks"", ""Collin Burns"", ""Steven Basart"", ""Andy Zou"", ""Mantas Mazeika"", ""Dawn Song"", ""Jacob Steinhardt""]","[""multitask"", ""few-shot""]",We test language models on 57 different multiple-choice tasks.,2009.03300,cs.CY,2020-09-07 17:59:25+00:00,2021-01-12 18:57:11+00:00
d8Q1mt2Ghw,2021,Accept (Poster),False,Emergent Road Rules In Multi-Agent Driving Environments,"[""Avik Pal"", ""Jonah Philion"", ""Yuan-Hong Liao"", ""Sanja Fidler""]",[],"In multi-agent driving environments with noisy perception, driving conventions emerge",2011.10753,cs.LG,2020-11-21 09:43:50+00:00,2021-03-17 07:29:41+00:00
d9Emve8gG5E,2021,Reject,True,OFFER PERSONALIZATION USING TEMPORAL CONVOLUTION NETWORK AND OPTIMIZATION,"[""Ankur Verma""]","[""Machine Learning"", ""Deep Learning"", ""Optimization"", ""Time-Series"", ""Offer Personalization""]","Deep Learning and Optimization based approach  to solve the offer optimization problem at the intersection of consumer, item and time in retail setting.",2010.08130,cs.LG,2020-10-14 10:59:34+00:00,2020-10-14 10:59:34+00:00
dDARN-TCiA,2022,Reject,False,Stochastic Reweighted Gradient Descent,"['Ayoub El Hanchi', 'Chris J. Maddison', 'David Alan Stephens']","[""Stochastic gradient descent"", ""Finite-sum optimization"", ""Variance reduction"", ""Importance sampling""]",We introduce the first importance-sampling-based variance reduction algorithm for finite-sum optimization with convergence rate guarantees under standard assumptions.,,,,
dDjSKKA5TP1,2022,Accept (Poster),True,Incremental False Negative Detection for Contrastive Learning,"['Tsai-Shien Chen', 'Wei-Chih Hung', 'Hung-Yu Tseng', 'Shao-Yi Chien', 'Ming-Hsuan Yang']","[""Self-supervised learning"", ""Contrastive learning"", ""Representation learning"", ""Clustering-based learning""]",This paper explores the effect of false negative samples in self-supervised contrastive learning and introduce a framework to incrementally detect and explicitly remove the false negatives.,2106.03719,cs.CV,2021-06-07 15:29:14+00:00,2021-11-24 14:21:02+00:00
dDo8druYppX,2022,Accept (Poster),True,Training Data Generating Networks: Shape Reconstruction via Bi-level Optimization,"['Biao Zhang', 'Peter Wonka']","[""shape reconstruction single image"", ""meta learning"", ""few-shot learning"", ""differentiable optimization"", ""bi-level optimization""]",,2010.08276,cs.CV,2020-10-16 09:52:13+00:00,2020-10-16 09:52:13+00:00
dEOeQgQTyvt,2022,Reject,False,Structured Energy Network as a dynamic loss function. Case study. A case study with multi-label Classification,"['Jay-Yoon Lee', 'Dhruvesh Patel', 'Purujit Goyal', 'Andrew McCallum']","[""Structured Prediction"", ""Energy network"", ""Energy-based models"", ""Loss-function learning"", ""Dynamic loss function""]","We propose to use SPEN, a powerful structured prediction model, from another angle: as a dynamic trainable loss function parameterized by neural network..",,,,
dEelotBE6e2,2022,Reject,False,Defending Against Backdoor Attacks Using Ensembles of Weak Learners ,"['Charles Jin', 'Melinda Sun', 'Martin Rinard']","[""data poisoning""]","We present a defense against data poisoning based on novel theoretical concepts, and obtain state of the art performance against a strong dirty label backdoor adversary.",,,,
dEwfxt14bca,2022,Accept (Spotlight),False,When should agents explore?,"['Miruna Pislar', 'David Szepesvari', 'Georg Ostrovski', 'Diana L Borsa', 'Tom Schaul']","[""exploration"", ""mode-switching"", ""reinforcement learning"", ""Atari""]","A fresh look at the question of *when* to switch into exploration mode, and for how long.",,,,
dFBRrTMjlyL,2021,Reject,True,Bidirectionally Self-Normalizing Neural Networks,"[""Yao Lu"", ""Stephen Gould"", ""Thalaiyasingam Ajanthan""]",[],We theoretically solve the exploding and vanishing gradients problem in neural network training.,2006.12169,cs.LG,2020-06-22 12:07:29+00:00,2021-05-18 08:20:36+00:00
dFbKQaRk15w,2022,Accept (Spotlight),True,Equivariant Subgraph Aggregation Networks,"['Beatrice Bevilacqua', 'Fabrizio Frasca', 'Derek Lim', 'Balasubramaniam Srinivasan', 'Chen Cai', 'Gopinath Balamurugan', 'Michael M. Bronstein', 'Haggai Maron']","[""Graph Neural Networks"", ""Expressive power"", ""Equivariance"", ""Weisfeiler-Leman""]",We present a provably expressive graph learning framework based on representing graphs as multisets of subgraphs and processing them with an equivariant architecture.,2110.02910,cs.LG,2021-10-06 16:45:07+00:00,2021-12-16 19:47:11+00:00
dFwBosAcJkN,2021,Accept (Poster),True,Perceptual Adversarial Robustness: Defense Against Unseen Threat Models,"[""Cassidy Laidlaw"", ""Sahil Singla"", ""Soheil Feizi""]",[],Adversarial training against a perceptually-aligned attack gives high robustness against many diverse adversarial threat models.,2006.12655,cs.LG,2020-06-22 22:40:46+00:00,2021-07-04 19:34:05+00:00
dHJtoaE3yRP,2022,Reject,False,NAFS: A Simple yet Tough-to-Beat Baseline for Graph Representation Learning,"['Wentao Zhang', 'Zeang Sheng', 'Mingyu Yang', 'Yang Li', 'Yu Shen', 'Zhi Yang', 'Zichao Yang', 'Bin CUI']","[""Feature Smoothing"", ""Graph Neural Network"", ""Graph Representation Learning""]",A simple non-parametric method that constructs node representations without parameter learning.,,,,
dHd6pU-8_fF,2022,Reject,False,L-SR1 Adaptive Regularization by Cubics for Deep Learning,"['Aditya Ranganath', 'Mukesh Singhal', 'Roummel Marcia']","[""Non-convex optimization"", ""deep learning"", ""quasi-Newton methods"", ""adaptive cubic regularization""]",,,,,
dIVrWHP9_1i,2022,Reject,False,G-Mixup: Graph Augmentation for Graph Classification,"['Xiaotian Han', 'Zhimeng Jiang', 'Ninghao Liu', 'Xia Hu']","[""graph augmentation"", ""mixup"", ""graph classification"", ""graphon""]","This work develops G-Mixup to augment input graph data for graph classification by interpolating the generators (i.e., graphons) of different classes of graphs.",,,,
dJbf5SqbFrM,2021,Reject,True,Continuous Transfer Learning,"[""Jun Wu"", ""Jingrui He""]",[],Theory and algorithm for transfer learning with a static source domain and a time-evolving target domain,2006.03230,cs.LG,2020-06-05 04:44:58+00:00,2020-06-05 04:44:58+00:00
dKLoUvtnq0C,2022,Reject,False,Semi-supervised learning of partial differential operators and dynamical flows,"['Michael Rotman', 'Amit Dekel', 'Ran Ilan Ber', 'Lior Wolf', 'Yaron Oz']","[""Hypernetworks"", ""Partial Differential Equations"", ""Fluid Dynamics""]",A novel architecture of solving PDEs in a semi-supervised manner.,,,,
dK_t8oN8G4,2022,Reject,False,Neurosymbolic Deep Generative Models for Sequence Data with Relational Constraints,"['Halley Young', 'Maxwell Du', 'Osbert Bastani']","[""synthesis"", ""music"", ""generative"", ""constraints""]",We use program synthesis to learn and condition on the relational structure of real sequential data.,,,,
dKg5D1Z1Lm,2021,Accept (Poster),False,Non-asymptotic Confidence Intervals of Off-policy Evaluation:  Primal and Dual Bounds ,"[""Yihao Feng"", ""Ziyang Tang"", ""na zhang"", ""qiang liu""]","[""Non-asymptotic Confidence Intervals"", ""Off Policy Evaluation"", ""Reinforcement Learnings""]",We propose an approach  to constructing non-asymptotic confidence intervals of off-policy estimation.,,,,
dKwmCtp6YI,2021,Reject,False,Representation and Bias in Multilingual NLP: Insights from Controlled Experiments on Conditional Language Modeling,"[""Ada Wan""]","[""multilinguality"", ""science for NLP"", ""fundamental science in the era of AI/DL"", ""representation learning for language"", ""conditional language modeling"", ""Transformer"", ""Double Descent"", ""non-monotonicity"", ""fairness"", ""meta evaluation"", ""visualization or interpretation of learned representations""]","We study the relationship between language, representation, size, and performance in Transformer conditional language models, and find, among other things, that statistically significant performance disparity can be a byproduct of word segmentation. ",,,,
dLDzuxaN0Hd,2022,Reject,True,Unsupervised Pose-Aware Part Decomposition for 3D Articulated Objects,"['Yuki Kawana', 'YUSUKE Mukuta', 'Tatsuya Harada']","[""unsupervised part decomposition"", ""shape abstraction"", ""3D shape representations"", ""generative models"", ""computer vision""]",This paper proposes a novel 3D generative model for unsupervised part decomposition that learns to decompose artificial articulated object shapes into part shapes and part poses represented as implicit fields and joint parameters.,2110.04411,cs.CV,2021-10-08 23:53:56+00:00,2021-10-08 23:53:56+00:00
dLTXoSIcrik,2022,Reject,False,Avoiding Overfitting to the Importance Weights in Offline Policy Optimization,"['Yao Liu', 'Emma Brunskill']","[""Reinforcement Learning"", ""Batch Reinforcement Learning"", ""Policy Optimization"", ""Overfitting""]","An unique overfitting in offline policy optimization related to importance weights, and its solution with validation on healthcare simulator",,,,
dN_iVr6iNuU,2021,Reject,False,Preventing Value Function Collapse in Ensemble  Q-Learning by Maximizing Representation Diversity,"[""Hassam Sheikh"", ""Ladislau Boloni""]","[""Ensemble Q-Learning"", ""Representation Diversity"", ""Reinforcement Learning""]",A regularization technique to maximize representation diversity in ensemble based Q-learning methods.,,,,
dNigytemkL,2022,Accept (Poster),True,The Role of Permutation Invariance in Linear Mode Connectivity of Neural Networks,"['Rahim Entezari', 'Hanie Sedghi', 'Olga Saukh', 'Behnam Neyshabur']","[""Permutation"", ""Invariance"", ""Mode Connectivity"", ""Energy Barrier"", ""Loss landscape"", ""Deep Learning""]","We conjecture that if the permutation invariance of neural networks is taken into account, SGD solutions will likely have no barrier in the linear interpolation between them.",2110.06296,cs.LG,2021-10-12 19:28:48+00:00,2021-10-12 19:28:48+00:00
dNy_RKzJacY,2021,Accept (Poster),True,Aligning AI With Shared Human Values,"[""Dan Hendrycks"", ""Collin Burns"", ""Steven Basart"", ""Andrew Critch"", ""Jerry Li"", ""Dawn Song"", ""Jacob Steinhardt""]","[""value learning"", ""human preferences"", ""alignment""]",We approach a longstanding problem in machine ethics provide evidence that it is soluble.,2008.02275,cs.CY,2020-08-05 17:59:16+00:00,2021-07-24 04:40:33+00:00
dOcQK-f4byz,2021,Accept (Poster),False,Teaching Temporal Logics to Neural Networks,"[""Christopher Hahn"", ""Frederik Schmitt"", ""Jens U. Kreber"", ""Markus Norman Rabe"", ""Bernd Finkbeiner""]","[""Logic"", ""Verification"", ""Transformer""]","We study two fundamental questions in neuro-symbolic computing: can deep learning tackle challenging problems in logics end-to-end, and can neural networks learn the semantics of logics.",,,,
dOiHyqVaFkg,2021,Reject,False,Unsupervised Progressive Learning and the STAM Architecture,"[""James Smith"", ""Cameron Ethan Taylor"", ""Seth Baer"", ""Constantine Dovrolis""]","[""continual learning"", ""unsupervised learning"", ""representation learning"", ""online learning""]","We pose and solve a new online representation learning problem in which the learner observes a non-stationary and unlabeled data stream, and identifies a growing number of features that persist over time without data storage or replay",,,,
dPyRNUlttBv,2022,Accept (Poster),False,Optimization and Adaptive Generalization of Three layer Neural Networks,"['Khashayar Gatmiry', 'Stefanie Jegelka', 'Jonathan Kelner']","[""deep learning theory"", ""adaptive kernel"", ""robust deep learning"", ""neural tangent kernel"", ""adaptive generalization"", ""non-convex optimization""]",Algorithmically obtaining noise-robust and adaptive generalization bounds for a three layer network model by going beyond the linear approximation of the network,,,,
dQ7Cy_ndl1s,2022,Accept (Poster),False,Controlling the Complexity and Lipschitz Constant improves Polynomial Nets,"['Zhenyu Zhu', 'Fabian Latorre', 'Grigorios Chrysos', 'Volkan Cevher']","[""Polynomial Nets"", ""Rademacher Complexity"", ""Lipschitz constant"", ""Coupled CP decomposition""]","We provide sample complexity results and bounds on the Lipschitz constant of polynomial networks, which we use to construct a regularization scheme that improves the robustness against adversarial noise.",,,,
dS3AxHZkrZT,2022,Reject,False,You May Need both Good-GAN and Bad-GAN for Anomaly Detection,"['Riqiang Gao', 'Zhoubing Xu', 'Guillaume Chabin', 'Awais Mansoor', 'Florin-Cristian Ghesu', 'Bogdan Georgescu', 'Bennett A. Landman', 'Sasa Grbic']","[""Anomaly Detection"", ""GAN"", ""Orthogonal Regularization"", ""Bad-GAN""]",Our proposed method incorporates a Good-GAN and a Bad-GAN in an adversarial manner for end-to-end anomaly detection. ,,,,
dSw0QtRMJkO,2022,Accept (Poster),False,High Probability Bounds for a Class of Nonconvex Algorithms with AdaGrad Stepsize,"['Ali Kavis', 'Kfir Yehuda Levy', 'Volkan Cevher']","[""adaptive methods"", ""nonconvex optimization"", ""stochastic optimization"", ""high probability bounds""]",,,,,
dTqOcTUOQO,2022,Accept (Poster),False,Knowledge Removal in Sampling-based Bayesian Inference,"['Shaopeng Fu', 'Fengxiang He', 'Dacheng Tao']","[""Bayesian inference"", ""Markov chain Monte Carlo"", ""machine unlearning""]",This paper proposes the first machine unlearning algorithm for MCMC.,,,,
dUV91uaXm3,2022,Accept (Spotlight),False,Revisiting Over-smoothing in BERT from the Perspective of Graph,"['Han Shi', 'JIAHUI GAO', 'Hang Xu', 'Xiaodan Liang', 'Zhenguo Li', 'Lingpeng Kong', 'Stephen M. S. Lee', 'James Kwok']","[""BERT"", ""Over-smoothing"", ""Transformer""]","We theoretically analyze the over-smoothing phenomenon of transformer-based models (e.g., BERT) and propose a novel hierarchical fusion strategy to alleviate it.",,,,
dV19Yyi1fS3,2021,Accept (Poster),False,Training with Quantization Noise for Extreme Model Compression,"[""Pierre Stock"", ""Angela Fan"", ""Benjamin Graham"", ""Edouard Grave"", ""R\u00e9mi Gribonval"", ""Herve Jegou"", ""Armand Joulin""]","[""Compression"", ""Efficiency"", ""Product Quantization""]",,,,,
dYUdt59fJ0e,2022,Reject,False,Yformer: U-Net Inspired Transformer Architecture for Far Horizon Time Series Forecasting,"['Kiran Madhusudhanan', 'Johannes Burchert', 'Nghia Duong-Trung', 'Stefan Born', 'Lars Schmidt-Thieme']","[""Time Series Forecasting"", ""U-Net"", ""Transformers""]",Coupling Sparse Transformer Network in a U-Net inspired architecture,,,,
dYeAHXnpWJ4,2021,Accept (Oral),True,Rethinking the Role of Gradient-based Attribution Methods for Model Interpretability,"[""Suraj Srinivas"", ""Francois Fleuret""]","[""Interpretability"", ""saliency maps"", ""score-matching""]","Input-gradients in discriminative neural net models capture information regarding an implicit density model, rather than that of the underlying discriminative model which it is intended to explain.",2006.09128,cs.LG,2020-06-16 13:17:32+00:00,2021-03-03 09:42:58+00:00
dZPgfwaTaXv,2022,Accept (Poster),False,Relational Surrogate Loss Learning,"['Tao Huang', 'Zekang Li', 'Hua Lu', 'Yong Shan', 'Shusheng Yang', 'Yang Feng', 'Fei Wang', 'Shan You', 'Chang Xu']",[],,,,,
d_2lcDh0Y9c,2022,Accept (Poster),False,DriPP: Driven Point Processes to Model Stimuli Induced Patterns in M/EEG Signals,"['CÃ©dric Allain', 'Alexandre Gramfort', 'Thomas Moreau']","[""Electrophysiology"", ""Neuroscience"", ""Temporal point processes"", ""Convolutional Dictionary Learning""]",Model for patterns' activation using temporal point processes to reveal stimulus-induced effects in brain electrophysiology.,,,,
d_Ue2glvcY8,2021,Reject,False,Structure Controllable Text Generation,"[""Liming DENG"", ""Long WANG"", ""Binzhu WANG"", ""Jiang Qian"", ""Bojin Zhuang"", ""Shaojun Wang"", ""Jing Xiao""]","[""Natural language generation"", ""structure representation"", ""structure controlling"", ""conditional language model"", ""structure aware transformer""]","A straightforward, interpretable structure controlling text generation framework is proposed, which is capable of learning and controlling multigranularity sequence structure from character-level to sentence-level structure.",,,,
daLIpc7vQ2q,2021,Reject,False,Improved Contrastive Divergence Training of Energy Based Models,"[""Yilun Du"", ""Shuang Li"", ""Joshua B. Tenenbaum"", ""Igor Mordatch""]","[""Contrastive Divergence"", ""Energy Based Modeling""]",Improvements to contrastive divergence to allow better training of EBMs,,,,
daYoG2O4TtU,2022,Reject,True,Adaptive Speech Duration Modification using a Deep-Generative Framework,"['Ravi Shankar', 'Archana Venkataraman']","[""Prosody"", ""Encoder-Decoder"", ""Attention"", ""Adaptive Duration Modification"", ""Dynamic Time Warping""]",We propose a generative model to locally manipulate speaking rate in a given speech utterance that can be adapted for tasks such as voice/accent conversion and emotion conversion.,2107.04973,eess.AS,2021-07-11 05:53:07+00:00,2021-07-11 05:53:07+00:00
dak8uQE6BOG,2021,Reject,False,MVP: Multivariate polynomials for conditional generation,"[""Grigorios Chrysos"", ""Yannis Panagakis""]","[""conditional image generation"", ""generative models"", ""polynomial neural networks""]",Conditional data generation is framed as a high-order polynomial expansion of the input.,,,,
dcktlmtcM7,2021,Reject,False,Neural Time-Dependent Partial Differential Equation,"[""Yihao Hu"", ""Tong Zhao"", ""Zhiliang Xu"", ""Lizhen Lin""]","[""Numerical analysis"", ""Deep learning"", ""Partial differential equation"", ""Machine learning"", ""Predictive modeling""]",A sequence-to-sequence (Seq2Seq) learning framework to predict nonlinear time-dependent partial differential equations.,,,,
de11dbHzAMF,2021,Accept (Poster),False,Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in NLP Using Fewer Parameters & Less Data,"[""Jonathan Pilault"", ""Amine El hattami"", ""Christopher Pal""]","[""Multi-Task Learning"", ""Adaptive Learning"", ""Transfer Learning"", ""Natural Language Processing"", ""Hypernetwork""]",Can multi-task outperform single task fine-tuning? CA-MTL is a new method that shows that it is possible with task conditioned model adaption via a Hypernetwork and uncertainty sampling.,,,,
defQ1AG6IWn,2021,Reject,False,Neighbor Class Consistency on Unsupervised Domain Adaptation,"[""Chang Liu"", ""Kai Li"", ""Yun Fu""]","[""Unsupervised domain adaptation"", ""Consistency regularization"", ""Neighbor""]",,,,,
demdsohU_e,2022,Reject,False,Neural Capacitance: A New Perspective of Neural Network Selection via Edge Dynamics,"['Chunheng Jiang', 'Tejaswini Pedapati', 'Pin-Yu Chen', 'Yizhou Sun', 'Jianxi Gao']","[""neural network selection"", ""transfer learning"", ""dynamical system"", ""edge dynamics"", ""network science""]", This paper provides a new perspective of neural network selection by studying the edge dynamics during neural network training.,2201.04194,cs.LG,2022-01-11 20:53:15+00:00,2022-01-14 21:18:24+00:00
dg79moSRqIo,2022,Accept (Poster),False,One After Another: Learning Incremental Skills for a Changing World,"['Nur Muhammad Mahi Shafiullah', 'Lerrel Pinto']","[""Skill discovery"", ""Incremental reinforcement learning""]","We discover skills incrementally, without supervision, and it lets us learn skills in both static environments and environments with changing dynamics.",,,,
dgd4EJqsbW5,2021,Accept (Poster),False,Control-Aware Representations for Model-based Reinforcement Learning,"[""Brandon Cui"", ""Yinlam Chow"", ""Mohammad Ghavamzadeh""]",[],,,,,
dgtpE6gKjHn,2021,Accept (Poster),True,FedBE: Making Bayesian Model Ensemble Applicable to Federated Learning,"[""Hong-You Chen"", ""Wei-Lun Chao""]",[],,2009.01974,cs.LG,2020-09-04 01:18:25+00:00,2021-10-10 18:31:55+00:00
dgxFTxuJ50e,2022,Accept (Spotlight),False,Learnability of convolutional neural networks for infinite dimensional input via mixed and anisotropic smoothness,"['Sho Okumoto', 'Taiji Suzuki']",[],,,,,
dhQHk8ShEmF,2021,Reject,False,Informative Outlier Matters: Robustifying Out-of-distribution Detection Using Outlier Mining,"[""Jiefeng Chen"", ""Yixuan Li"", ""Xi Wu"", ""Yingyu Liang"", ""Somesh Jha""]","[""OOD detection"", ""informative outlier mining"", ""robustness""]","We propose a theoretically motivated method, Adversarial Training with informative Outlier Mining (ATOM), which improves the robustness of OOD detection to various types of adversarial OOD inputs and establishes state-of-the-art performance.",,,,
di0r7vfKrq5,2022,Reject,False,Boosting Search Engines with Interactive Agents,"['Leonard Adolphs', 'Benjamin BÃ¶rschinger', 'Christian Buck', 'Michelle Chen Huebscher', 'Massimiliano Ciaramita', 'Lasse Espeholt', 'Thomas Hofmann', 'Yannic Kilcher', 'Sascha Rothe', 'Pier Giuseppe Sessa', 'Lierni Sestorain']","[""query refinement"", ""reinforcement learning"", ""self-supervised learning"", ""question answering"", ""search engines"", ""large language models""]","We train an agent to use a search engine, performing multiple steps of query expansions.",,,,
djZBr4Z7jcz,2022,Reject,False,On the regularization landscape for the linear recommendation models,"['Dong Li', 'Zhenming Liu', 'Ruoming Jin', 'Zhi Liu', 'Jing Gao', 'Bin Ren']","[""recommendation system"", ""regularization"", ""linear model""]",,,,,
djhu4DIZZHR,2022,Reject,False,"NAIL: A Challenging Benchmark for Na\""ive Logical Reasoning","['Xinbo Zhang', 'Changzhi Sun', 'Yue Zhang', 'Lei Li', 'Hao Zhou']","[""Logical Reasoning"", ""Benchmark""]","we focus on a specific category of logical reasoning, named \emph{\mytask}, and propose a new large scale benchmark, named \mydata, targeted for learning and evaluating models' capabilities towards \mytask.",,,,
djwS0m4Ft_A,2021,Accept (Poster),False,Evaluating the Disentanglement of Deep Generative Models through Manifold Topology,"[""Sharon Zhou"", ""Eric Zelikman"", ""Fred Lu"", ""Andrew Y. Ng"", ""Gunnar E. Carlsson"", ""Stefano Ermon""]","[""generative models"", ""evaluation"", ""disentanglement""]",Evaluate disentanglement of generative models by measuring manifold topology using persistent homology,,,,
djwnKXz1B2,2022,Reject,False,EP-GAN: Unsupervised Federated Learning with Expectation-Propagation Prior GAN,"['Xueyang Wu', 'Hengguan Huang', 'Hao Wang', 'Ye Wang', 'Qian Xu']","[""Bayesian Deep learning"", ""Expectation Propagation"", ""Unsupervised Learning"", ""Acoustic Modeling""]","This paper derive an EP prior with closed-form update rules using deep neural networks, allowing  Bayesian GANs to capture latent structure over clients on non-i.i.d. cross-silo data.",,,,
dlEJsyHGeaL,2021,Accept (Poster),False,Graph Edit Networks,"[""Benjamin Paassen"", ""Daniele Grattarola"", ""Daniele Zambon"", ""Cesare Alippi"", ""Barbara Eva Hammer""]","[""graph neural networks"", ""graph edit distance"", ""time series prediction"", ""structured prediction""]",We show that graph neural networks can predict graph edits and are connected to the graph edit distance via graph mappings,,,,
dluhjOg0qKn,2021,Reject,False,Deep Ensembles for Low-Data Transfer Learning,"[""Basil Mustafa"", ""Carlos Riquelme Ruiz"", ""Joan Puigcerver"", ""Andr\u00e9 Susano Pinto"", ""Daniel Keysers"", ""Neil Houlsby""]","[""transfer learning"", ""representation learning"", ""computer vision"", ""ensembles""]","A study of ensembling pre-trained models for downstream computer vision classification tasks with minimal data, and a proposal for an approach that utilises diversity from pre-training to improve accuracy and robustness.",,,,
dmCL033_YwO,2021,Reject,True,DeeperGCN: Training Deeper GCNs with Generalized Aggregation Functions,"[""Guohao Li"", ""Chenxin Xiong"", ""Ali Thabet"", ""Bernard Ghanem""]","[""Graph Neural Networks"", ""Graph Representation Learning""]","This paper proposes DeeperGCN that is capable of successfully and reliably training very deep GCNs. We define differentiable generalized aggregation functions to unify different message aggregation operations (e.g. mean, max and sum).",2006.07739,cs.LG,2020-06-13 23:00:22+00:00,2020-06-13 23:00:22+00:00
dmq_-R2LhQk,2022,Reject,False,The Manifold Hypothesis for Gradient-Based Explanations,"['Sebastian Bordt', 'Uddeshya Upadhyay', 'Zeynep Akata', 'Ulrike von Luxburg']","[""Interpretability"", ""Explainability""]",We explore a simple criterion for gradient-based explanations: That they lie in the tangent space of the data manifold.,,,,
dn4B7Mes2z,2022,Reject,True,The Low-Rank Simplicity Bias in Deep Networks,"['Minyoung Huh', 'Hossein Mobahi', 'Richard Zhang', 'Brian Cheung', 'Pulkit Agrawal', 'Phillip Isola']",[],,2103.10427,cs.LG,2021-03-18 17:58:02+00:00,2021-10-12 00:45:40+00:00
dnKsslWzLNY,2021,Reject,False,On the Universal Approximability and Complexity Bounds of Deep Learning in Hybrid Quantum-Classical Computing,"[""Weiwen Jiang"", ""Yukun Ding"", ""Yiyu Shi""]","[""deep learning"", ""hybrid quantum-classical computing"", ""universal approximability""]",This paper proves the universal approximability of neural networks on a quantum computer for a wide class of functions as well as the associated bounds. ,,,,
doeyA2PBjdy,2021,Reject,False,An empirical study of a pruning mechanism,"[""Minju Jung"", ""Hyounguk Shon"", ""Eojindl Yi"", ""SungHyun Baek"", ""Junmo Kim""]",[],,,,,
dpXL6lz4mOQ,2022,Accept (Poster),False,LEARNING GUARANTEES FOR GRAPH CONVOLUTIONAL NETWORKS ON THE STOCHASTIC BLOCK MODEL,['Wei Lu'],[],,,,,
dpuLRRQ7zC,2021,Reject,True,Enhancing Certified Robustness of Smoothed Classifiers via Weighted Model Ensembling,"[""Chizhou Liu"", ""Yunzhen Feng"", ""Ranran Wang"", ""Bin Dong""]","[""Adversairal Robustness"", ""Randomized Smoothing"", ""Ensembling""]","We employ a Smoothed WEighted ENsembling (SWEEN) scheme to improve the performance of randomized smoothed classifiers, and show its effectiveness both theoretically and empirically.",2005.09363,cs.LG,2020-05-19 11:13:43+00:00,2021-02-23 14:03:58+00:00
dqyK5RKMaW4,2021,Reject,True,LEARNED HARDWARE/SOFTWARE CO-DESIGN OF NEURAL ACCELERATORS,"[""Zhan Shi"", ""Chirag Sakhuja"", ""Milad Hashemi"", ""Kevin Swersky"", ""Calvin Lin""]","[""deep learning accelerator"", ""Bayesian optimization"", ""design space exploration"", ""hardware-software co-design""]",A bilevel Bayesian optimization approach for the hardware/software co-design of neural accelerators.,2010.02075,cs.LG,2020-10-05 15:12:52+00:00,2020-10-05 15:12:52+00:00
ds8yZOUsea,2022,Accept (Poster),False,Hidden Parameter Recurrent State Space Models For Changing Dynamics Scenarios,"['Vaisakh Shaj', 'Dieter BÃ¼chler', 'Rohit Sonker', 'Philipp Becker', 'Gerhard Neumann']","[""State Space Models"", ""Changing Dynamics"", ""Recurrent Neural Networks"", ""Multi Task Learning""]",A new formalism for extending Recurrent State Space Models (RSSMs) to changing dynamics scenarios.,,,,
dtYnHcmQKeM,2022,Reject,False,Physics-Informed Neural Operator for  Learning Partial Differential Equations,"['Zongyi Li', 'Hongkai Zheng', 'Nikola Borislavov Kovachki', 'David Jin', 'Haoxuan Chen', 'Burigede Liu', 'Andrew Stuart', 'Kamyar Azizzadenesheli', 'Anima Anandkumar']","[""Partial Differential Equations"", ""operator learning"", ""physics-informed"", ""PINN"", ""inverse problem"", ""Navier-Stokes Equation""]",We combine operator-learning with physics-informed optimization and are able to solve challenging PDEs and inverse problems with ~1000x speedup over standard solvers.,,,,
dtpgsBPJJW,2022,Reject,False,Riemannian Manifold Embeddings for Straight-Through Estimator,"['Jun Chen', 'Hanwen Chen', 'Jiangning Zhang', 'yuang Liu', 'Tianxin Huang', 'Yong Liu']","[""Neural network quantization"", ""Riemannian manifold"", ""Information geometry"", ""Mirror descent""]",Quantize neural networks in Riemannian manifolds to alleviate the gradient mismatch problem,,,,
dtt435G80Ng,2022,Reject,False,CSQ: Centered Symmetric Quantization for Extremely Low Bit Neural Networks,"['Faaiz Asim', 'Jaewoo Park', 'Azat Azamat', 'Jongeun Lee']","[""deep learning"", ""classification"", ""low precision"", ""uniform symmetric quantization"", ""binary neural network hardware""]",A simple trick for extremely low-bit quantization with an in-depth analysis and an efficient bit-parallel realization method,,,,
dut7suZoRqv,2022,Reject,False,SparRL: Graph Sparsification via Deep Reinforcement Learning,"['Ryan Wickman', 'Xiaofei Zhang', 'Weizi Li']","[""graph sparsification"", ""graph theory"", ""machine learning"", ""reinforcement learning""]",A novel graph sparsification framework based on reinforcement learning that establishes SOTA performance measured over several tasks.,,,,
dvSExzhjG9D,2021,Reject,False,MLR-SNet: Transferable LR Schedules for Heterogeneous Tasks,"[""Jun Shu"", ""Yanwen Zhu"", ""Qian Zhao"", ""Deyu Meng"", ""Zongben Xu""]","[""Meta Learning"", ""Hyperparameters Learning"", ""Generalization on Tasks"", ""Optimization"", ""LR Schedules Learning"", ""DNNs Training""]","We propose a transferable LR schedules, MLR-SNet,  which is plug and play for adapting heterogeneous tasks.",,,,
dvl241Sbrda,2022,Reject,False,Unit Ball Model for Embedding Hierarchical Structures in the Complex Hyperbolic Space,"['Huiru Xiao', 'Caigao JIANG', 'Yangqiu Song', 'james Y zhang', 'Junwu Xiong']","[""Complex hyperbolic embeddings"", ""hierarchical data embeddings"", ""taxonomy embeddings""]",,,,,
dwg5rXg1WS_,2022,Accept (Spotlight),False,ViTGAN: Training GANs with Vision Transformers,"['Kwonjoon Lee', 'Huiwen Chang', 'Lu Jiang', 'Han Zhang', 'Zhuowen Tu', 'Ce Liu']",[],,,,,
dx11_7vm5_r,2021,Accept (Poster),False,Linear Last-iterate Convergence in Constrained Saddle-point Optimization,"[""Chen-Yu Wei"", ""Chung-Wei Lee"", ""Mengxiao Zhang"", ""Haipeng Luo""]","[""Saddle-point Optimization"", ""Optimistic Mirror Decent"", ""Optimistic Gradient Descent Ascent"", ""Optimistic Multiplicative Weights Update"", ""Last-iterate Convergence"", ""Game Theory""]",We prove Optimistic Gradient Descent Ascent (OGDA) and Optimistic Multiplicative Weights Update (OMWU) converge exponentially fast to the Nash equilibrium in the sense of last-iterate in various game settings including matrix games.,,,,
dx4b7lm8jMM,2021,Accept (Poster),True,Seq2Tens: An Efficient Representation of Sequences by Low-Rank Tensor Projections,"[""Csaba Toth"", ""Patric Bonnier"", ""Harald Oberhauser""]","[""time series"", ""sequential data"", ""representation learning"", ""low-rank tensors"", ""classification"", ""generative modelling""]",An Efficient Representation of Sequences by Low-Rank Tensor Projections,2006.07027,cs.LG,2020-06-12 09:24:35+00:00,2021-07-30 10:46:29+00:00
dyaIRud1zXg,2021,Accept (Spotlight),True,Information Laundering for Model Privacy,"[""Xinran Wang"", ""Yu Xiang"", ""Jun Gao"", ""Jie Ding""]","[""Adversarial Attack"", ""Machine Learning"", ""Model privacy"", ""Privacy-utility tradeoff"", ""Security""]","We propose information laundering, a novel framework for enhancing model privacy.",2009.06112,cs.CR,2020-09-13 23:24:08+00:00,2020-09-13 23:24:08+00:00
dyjPVUc2KB,2021,Accept (Poster),False,Adapting to Reward Progressivity via Spectral Reinforcement Learning,"[""Michael Dann"", ""John Thangarajah""]","[""Reinforcement Learning"", ""Deep Reinforcement Learning""]","In this paper, we identify a problem with value-based deep reinforcement learning that has not previously been investigated -- namely, reward progressivity -- and propose an approach that addresses it via magnitudinal decomposition of the reward.",2104.14138,cs.LG,2021-04-29 06:33:21+00:00,2021-04-29 06:33:21+00:00
dzZQEvQ6dRK,2022,Reject,False,Disentangling Properties of Contrastive Methods,"['Jinkun Cao', 'Qing Yang', 'Jialei Huang', 'Yang Gao']","[""self-supervised learning"", ""representation disentanglement""]",This paper reveals the good disentanglement pattern of representation learned by contrastive learning and builds benchmark on both synthetic and real-world datasets.,,,,
dzZaIeG9-fW,2021,Reject,False,Learning to Infer Run-Time Invariants from Source code,"[""Vincent Josua Hellendoorn"", ""Premkumar Devanbu"", ""Alex Polozov"", ""Mark Marron""]","[""Invariants"", ""Software Engineering"", ""Programming Languages""]",A technique for predicting run-time invariants from source code alone,,,,
e-IkMkna5uJ,2022,Reject,True,Spectral Bias in Practice: the Role of Function Frequency in Generalization,"['Sara Fridovich-Keil', 'Raphael Gontijo-Lopes', 'Rebecca Roelofs']","[""spectral bias"", ""generalization"", ""function frequency"", ""image classification""]",,2110.02424,cs.LG,2021-10-06 00:16:10+00:00,2022-02-10 03:26:19+00:00
e-JV6H8lwpl,2022,Reject,False,Subspace State-Space Identification and Model Predictive Control of Nonlinear Dynamical Systems Using Deep Neural Network with Bottleneck,"['Ichiro Maruta', 'Keito Yamada', 'Kenji Fujimoto']","[""System identification"", ""Model predictive control"", ""Subspace state-space system identification""]",We propose a simple nonlinear extension of the subspace identification method and prove its fundamental properties.,,,,
e-ZdxsIwweR,2021,Reject,False,Robust Constrained Reinforcement Learning for Continuous Control with Model Misspecification,"[""Daniel J Mankowitz"", ""Dan Andrei Calian"", ""Rae Jeong"", ""Cosmin Paduraru"", ""Nicolas Heess"", ""Sumanth Dathathri"", ""Martin Riedmiller"", ""Timothy Mann""]","[""reinforcement learning"", ""constraints"", ""robustness""]",This paper presents an approach that is robust with respect to constraint satisfaction in the presence of perturbations to the system dynamics,,,,
e0TRvNWsVIH,2022,Reject,False,Learning Representation for Bayesian Optimization with Collision-free Regularization,"['Fengxue Zhang', 'Brian Nord', 'Yuxin Chen']","[""Latent space"", ""Bayesian Optimization"", ""Collision""]",Propose a novel regularizer on neural networks to learn the learned latent space for Bayesian optimization and address the collision on the latent space.,,,,
e0jtGTfPihs,2022,Accept (Poster),False,"Signing the Supermask: Keep, Hide, Invert","['Nils Koster', 'Oliver Grothe', 'Achim Rettinger']","[""Neural Networks"", ""Supermask"", ""Lottery Ticket Hypothesis"", ""Pruning"", ""Weight Initialization"", ""Interpretation"", ""Subnetworks""]",We train neural networks by weight selection and sign inversion instead of optimizing the values of weights which achieves consistent pruning rates of up to 99% while maintaining competitive performance.,,,,
e0uknAgETh,2022,Reject,True,Adversarial Attacks on Spiking Convolutional Networks for Event-based Vision,"['Julian BÃ¼chel', 'Gregor Lenz', 'Yalun Hu', 'Sadique Sheik', 'Martino Sorbaro']","[""spiking neural networks"", ""neuromorphic engineering"", ""adversarial attacks"", ""dynamic vision sensors""]","We demonstrate the effectiveness of sparse adversarial attacks, as well as adversarial patches, applied to Dynamic-Vision-Sensor data in spiking CNNs and show the functionality of said attacks on neuromorphic hardware.",2110.02929,cs.CV,2021-10-06 17:20:05+00:00,2021-12-20 15:34:41+00:00
e12NDM7wkEY,2021,Accept (Poster),False,Clustering-friendly Representation Learning via Instance Discrimination and Feature Decorrelation,"[""Yaling Tao"", ""Kentaro Takagi"", ""Kouta Nakata""]","[""clustering"", ""representation learning"", ""deep embedding""]","We present a clustering-friendly representation learning method using instance discrimination and feature decorrelation, which achieves accuracy of 81.5% and 95.4% on CIFAR-10 and ImageNet-10, respectively, far above state-of-the-art values.",2106.00131,cs.LG,2021-05-31 22:59:31+00:00,2021-05-31 22:59:31+00:00
e2Lle5cij9D,2022,Accept (Poster),False,Hidden Convexity of Wasserstein GANs: Interpretable Generative Models with Closed-Form Solutions,"['Arda Sahiner', 'Tolga Ergen', 'Batu Ozturkler', 'Burak Bartan', 'John M. Pauly', 'Morteza Mardani', 'Mert Pilanci']","[""Wasserstein GAN"", ""convex-concave game"", ""saddle points"", ""generative models"", ""quadratic"", ""polynomial activation"", ""convex duality""]","We demonstrate that Wasserstein GANs with two-layer discriminators and a variety of generators are equivalent to convex optimization problems or convex-concave games, allowing for global optimization in polynomial time and improved interpretability.",,,,
e3KNSdWFOfT,2021,Reject,False,Solving Min-Max Optimization with Hidden Structure via Gradient Descent Ascent,"[""Emmanouil-Vasileios Vlatakis-Gkaragkounis"", ""Lampros Flokas"", ""Georgios Piliouras""]","[""Min-max optimization"", ""Lyapunov functions"", ""Stability Analysis"", ""Generative Adversarial Networks"", ""Non-convex optimization""]",We prove non-local asymptotic convergence guarantees in a class of non-convex non-concave zero-sum.,,,,
e3bhF_p0T7c,2021,Reject,False,Analysis of Alignment Phenomenon in Simple Teacher-student Networks with Finite Width,"[""Hanlin Zhu"", ""Chengyang Ying"", ""Song Zuo""]","[""alignment"", ""finite width network"", ""teacher student model"", ""angular distance function""]","We prove the uniqueness of local minima in a simple student-teacher framework, and conjecture the same conclusion for more general settings. ",,,,
e42KbIw6Wb,2022,Accept (Poster),False,Pix2seq: A Language Modeling Framework for Object Detection,"['Ting Chen', 'Saurabh Saxena', 'Lala Li', 'David J. Fleet', 'Geoffrey Hinton']","[""language modeling"", ""object detection""]",We demonstrated that object detection can be tackled by simply training a language model conditioned on pixel inputs.,,,,
e60-SyRXtRt,2021,Reject,False,GANMEX: Class-Targeted One-vs-One Attributions using GAN-based Model Explainability,"[""Sheng-Min Shih"", ""Pin-Ju Tien"", ""Zohar Karnin""]","[""Deep Neural Networks"", ""Attribution Methods"", ""Generative Adversarial Networks"", ""Interpretability"", ""Explainability""]","We developed GANMEX, a novel approach using GAN for generating class-targeted attribution method baselines and achieving one-vs-one explanations for DNNs.",,,,
e6MWIbNeW1,2022,Reject,False,Trading Quality for Efficiency of Graph Partitioning: An Inductive Method across Graphs,"['Meng QIN', 'Chaorui Zhang', 'Bo Bai', 'Gong Zhang', 'Dit-Yan Yeung']","[""Graph Partitioning"", ""Community Detection"", ""Inductive Graph Embedding""]",We try to achieve a better trade-off between quality and efficiency of the NP-hard graph partitioning task via a novel inductive node-level dual GNN across graphs.,,,,
e6hMkY6MFcU,2021,Reject,False,WordsWorth Scores for Attacking CNNs and LSTMs for Text Classification,"[""Nimrah Shakeel""]",[],An efficient method for computing word importance scores for CNNs and LSTMs,,,,
e8JI3SBZKa4,2022,Reject,False,Online approximate factorization of a kernel matrix by a Hebbian neural network,"['Kyle Luther', 'Sebastian Seung']","[""online kernel methods"", ""hebbian learning"", ""similarity matching""]","An online algorithm for factorizing a kernel matrix, implemented by a neural network with Hebbian and anti-Hebbian plasticity",,,,
e8W-hsu_q5,2021,Accept (Poster),False,Group Equivariant Conditional Neural Processes,"[""Makoto Kawano"", ""Wataru Kumagai"", ""Akiyoshi Sannai"", ""Yusuke Iwasawa"", ""Yutaka Matsuo""]","[""Neural Processes"", ""Conditional Neural Processes"", ""Stochastic Processes"", ""Regression"", ""Group Equivariance"", ""Symmetry""]","A model for regression that learns conditional distributions of a stochastic process, by incorporating group equivariance into Conditional Neural Processes.",2102.08759,cs.LG,2021-02-17 13:50:07+00:00,2021-02-17 13:50:07+00:00
e95i1IHcWj,2022,Accept (Poster),False,Equivariant and Stable Positional Encoding for More Powerful Graph Neural Networks,"['Haorui Wang', 'Haoteng Yin', 'Muhan Zhang', 'Pan Li']","[""Graph Neural Network"", ""Spectral Graph Theory"", ""System Stability""]",,,,,
eBCmOocUejf,2022,Accept (Poster),False,On Robust Prefix-Tuning for Text Classification,"['Zonghan Yang', 'Yang Liu']","[""prefix-tuning"", ""pretrained language models"", ""text classification"", ""robustness in NLP"", ""optimal control""]",We propose a robust prefix-tuning framework that improves robustness of prefix-tuning against different types of attacks while preserving its efficiency and modularity with interpretation from the perspective of optimal control.,,,,
eBHq5irt-tk,2021,Reject,False,Rethinking Parameter Counting: Effective Dimensionality Revisited,"[""Gregory Benton"", ""Wesley Maddox"", ""Andrew Gordon Wilson""]","[""effective dimension"", ""hessian"", ""generalization"", ""double descent""]","We show how effective dimensionality can shed light on a number of phenomena in modern deep learning including double descent, width-depth trade-offs, and subspace inference, while providing a straightforward and compelling generalization metric.",,,,
eBS-3YiaIL-,2022,Accept (Spotlight),False,Analyzing and Improving the Optimization Landscape of Noise-Contrastive Estimation,"['Bingbin Liu', 'Elan Rosenfeld', 'Pradeep Kumar Ravikumar', 'Andrej Risteski']","[""noise contrastive estimation"", ""contrastive learning"", ""unsupervised learning"", ""theory""]","This work theoretically explains the difficulty of optimizing the NCE loss when the noise distribution is poor, and provides a provably efficient solution consisting of normalized gradient descent (NGD) combined with the proposed \emph{eNCE} loss.",,,,
eCPCn25gat,2022,Reject,False,Pretraining for Language Conditioned Imitation with Transformers,"['Aaron L Putterman', 'Kevin Lu', 'Igor Mordatch', 'Pieter Abbeel']",[],,,,,
eDjxhFbaWX,2022,Reject,False,HODA: Protecting DNNs Against Model Extraction Attacks via Hardness of Samples,"['AmirMahdi Sadeghzadeh', 'Faezeh Dehghan', 'Amir Sobhanian', 'Rasool Jalili']","[""Trustworthy Machine Learning"", ""Model Extraction Attacks"", ""Hardness of Samples""]",We propose Hardness-Oriented Detection Approach (HODA) to detect the sample sequences of model extraction attacks.,,,,
eELR-4Dk4U8,2022,Reject,False,Model-based Reinforcement Learning with a Hamiltonian Canonical ODE Network,"['Yao Feng', 'Yuhong Jiang', 'Hang Su', 'Dong Yan', 'Jun Zhu']","[""Reinforcement learning"", ""Hamiltonian canonical equation"", ""ODE"", ""World model"", ""Sample efficiency""]",We introduce Hamiltonian canonical ordinary differential equations into the model-based reinforcement learning to increase the sample efficiency and to guarantee physical plausibility.,,,,
eEeyRrKVfbL,2021,Reject,False,Balancing training time vs. performance with Bayesian Early Pruning,"[""Mohit Rajpal"", ""Yehong Zhang"", ""Bryan Kian Hsiang Low""]","[""Efficient Training"", ""Multi-Output Gaussian Process"", ""Gaussian Process"", ""Bayesian"", ""Single-shot network pruning"", ""Dynamic Sparse Reparameterization"", ""Lottery Ticket Hypothesis""]",Our work improves the training efficiency of deep neural networks while minimizing degradation in performance through optimizing the tradeoff between training time and performance by pruning ineffectual network elements during the training process.,,,,
eEn8KTtJOx,2021,Accept (Poster),False,WaNet - Imperceptible Warping-based Backdoor Attack,"[""Tuan Anh Nguyen"", ""Anh Tuan Tran""]","[""backdoor attack"", ""image warping"", ""wanet""]","We propose an imperceptible backdoor attack based on image-warping, which can surpass both human and machine inspections.",,,,
eGd34W56KIT,2022,Reject,False,SPARK: co-exploring model SPArsity and low-RanKness for compact neural networks,"['Wanzhao Yang', 'Miao Yin', 'Yang Sui', 'Bo Yuan']","[""model compression"", ""low-rankness"", ""sparsity"", ""tensor""]",We propose a unified DNN compression framework SPARK that can simultaneously capture model sparsity and low-rankness and achieves better performance than uncompressed model with reduced storage and computational costs.,,,,
eHG7asK_v-k,2021,Reject,False,Multi-Agent Trust Region Learning,"[""Ying Wen"", ""Hui Chen"", ""Yaodong Yang"", ""Zheng Tian"", ""Minne Li"", ""Xu Chen"", ""Jun Wang""]","[""multi-agent learning"", ""reinforcement learning"", ""empirical game-theoretic analysis""]",A Multi-Agent Trust Region Learning (MATRL)  algorithm that augments the single-agent trust region policy optimization with a weak stable fixed point approximated by the policy-space meta-game.,2106.06828,cs.MA,2021-06-12 18:21:26+00:00,2021-06-12 18:21:26+00:00
eHg0cXYigrT,2021,Reject,False,Conditional Generative Modeling for De Novo Hierarchical Multi-Label Functional Protein Design,"[""Tim Kucera"", ""Karsten Michael Borgwardt"", ""Matteo Togninalli"", ""Laetitia Papaxanthos""]","[""protein design"", ""conditional generative adversarial networks"", ""gene ontology"", ""hierarchical multi-label"", ""GO"", ""GAN""]",We develop a conditional Generative Adversarial Network for sequence-based protein design with hierarchical multi-label gene ontology annotations.,,,,
eIHYL6fpbkA,2021,Accept (Poster),False,Removing Undesirable Feature Contributions Using Out-of-Distribution Data,"[""Saehyung Lee"", ""Changhwa Park"", ""Hyungyu Lee"", ""Jihun Yi"", ""Jonghyun Lee"", ""Sungroh Yoon""]","[""adversarial training"", ""adversarial robustness"", ""generalization"", ""out-of-distribution""]","We propose a simple method, Out-of-distribution data Augmented Training (OAT), to leverage OOD data for adversarial and standard learning.",2101.06639,cs.LG,2021-01-17 10:26:34+00:00,2021-03-03 05:40:51+00:00
eIPsmKwTrIe,2021,Reject,False,Using Deep Reinforcement Learning to Train and Evaluate Instructional Sequencing Policies for an Intelligent Tutoring System,"[""Jithendaraa Subramanian"", ""David Mostow""]","[""Deep Reinforcement Learning"", ""Intelligent Tutoring Systems"", ""Adaptive policy"", ""Instructional Sequencing""]",A Deep Reinforcement Learning framework that can be used by Intelligent Tutoring System to learn an instructional policy that maximizes student learning gains.,,,,
eIvzaLx6nKW,2022,Reject,False,Multi-Domain Self-Supervised Learning,"['Neha Mukund Kalibhat', 'Yogesh Balaji', 'C. Bayan Bruss', 'Soheil Feizi']","[""self-supervised learning"", ""contrastive learning"", ""multi-domain data"", ""unsupervised learning""]",We present a novel approach to learn self-supervised representations on multi-domain data in an efficient and generalizable manner.,,,,
eJIJF3-LoZO,2021,Accept (Poster),False,Concept Learners for Few-Shot Learning,"[""Kaidi Cao"", ""Maria Brbic"", ""Jure Leskovec""]","[""few-shot learning"", ""meta learning""]",COMET learns generalizable representations along human-understandable concept dimensions.,,,,
eJyt4hJzOLk,2022,Reject,False,Discrepancy-Optimal Meta-Learning for Domain Generalization,['Chen Jia'],"[""Domain generalization Meta-learning Transfer learning Generalization Bound""]",This paper tackles the problem of domain generalization via discrepancy-optimal meta-learning from both theoretical and empirical perspectives.,,,,
eLfqMl3z3lq,2021,Accept (Poster),False,Adversarial score matching and improved sampling for image generation,"[""Alexia Jolicoeur-Martineau"", ""R\u00e9mi Pich\u00e9-Taillefer"", ""Ioannis Mitliagkas"", ""Remi Tachet des Combes""]","[""adversarial"", ""score matching"", ""Langevin dynamics"", ""GAN"", ""generative model""]",Combining GANs with score matching and using Consistent Sampling (as an alternative to Langevin dynamics) for improved generative modeling,,,,
eMP1j9efXtX,2021,Accept (Spotlight),False,DeepAveragers: Offline Reinforcement Learning By Solving Derived Non-Parametric MDPs,"[""Aayam Kumar Shrestha"", ""Stefan Lee"", ""Prasad Tadepalli"", ""Alan Fern""]","[""Offline Reinforcement Learning"", ""Planning""]",The paper introduces and investigates an offline RL approach based on optimally solving a finite-state MDP that is derived from the experience dataset using any latent state representation. ,,,,
eMudnJsb1T5,2022,Accept (Spotlight),True,Sampling with Mirrored Stein Operators,"['Jiaxin Shi', 'Chang Liu', 'Lester Mackey']","[""Stein's method"", ""Sampling"", ""Mirror descent"", ""Natural gradient descent"", ""Probabilistic inference"", ""Bayesian inference"", ""Post-selection inference"", ""Stein operators""]",We introduce multi-particle generalization of mirror descent for sampling in constrained domains and non-Euclidean geometries.,2106.12506,stat.ML,2021-06-23 16:23:34+00:00,2021-06-23 16:23:34+00:00
eNSpdJeR_J,2021,Reject,False,Deep Learning with Data Privacy via Residual Perturbation,"[""Wenqi Tao"", ""Huaming Ling"", ""Zuoqiang Shi"", ""Bao Wang""]","[""Data Privacy"", ""Residual Perturbation"", ""Deep Learning""]",We propose a stochastic differential equation principled residual perturbation for privacy-preserving DL.,,,,
eNdiU_DbM9,2021,Accept (Spotlight),False,Uncertainty Sets for Image Classifiers using Conformal Prediction,"[""Anastasios Nikolas Angelopoulos"", ""Stephen Bates"", ""Michael Jordan"", ""Jitendra Malik""]","[""classification"", ""predictive uncertainty"", ""conformal inference"", ""computer vision"", ""imagenet""]","We quantify uncertainty for image classifiers using prediction sets, with detailed experiments on Imagenet Val and V2.",,,,
eOdSD0B5TE,2022,Reject,False,On the Implicit Biases of Architecture & Gradient Descent,"['Jeremy Bernstein', 'Yisong Yue']","[""generalisation"", ""function space"", ""PAC-Bayes"", ""NNGP"", ""orthants"", ""margin""]",New technical tools suggest a nuanced portrait of generalisation that involves both the implicit biases of architecture and gradient descent.,,,,
ePI0bPbrih,2022,Reject,True,Boundary Graph Neural Networks for 3D Simulations,"['Andreas Mayr', 'Sebastian Lehner', 'Arno Mayrhofer', 'Christoph Kloss', 'Sepp Hochreiter', 'Johannes Brandstetter']","[""Simulation"", ""Graph Neural Network"", ""Boundary Conditions"", ""Granular Flow"", ""Physics Application""]",Boundary Graph Neural Networks are able to model 3D simulations within complex geometries over hundreds of thousands of timesteps.,2106.11299,cs.LG,2021-06-21 17:56:07+00:00,2021-10-13 09:22:04+00:00
ePh9bvqIgKL,2021,Reject,True,Discovering Parametric Activation Functions,"[""Garrett Bingham"", ""Risto Miikkulainen""]","[""activation function"", ""parametric"", ""evolution""]","Evolutionary search discovers the general form of novel activation functions, and gradient descent fine-tunes the shape for different parts of the network and over the learning process.",2006.03179,cs.LG,2020-06-05 00:25:33+00:00,2021-01-30 02:17:20+00:00
eQe8DEWNN2W,2021,Accept (Poster),True,Calibration of Neural Networks using Splines,"[""Kartik Gupta"", ""Amir Rahimi"", ""Thalaiyasingam Ajanthan"", ""Thomas Mensink"", ""Cristian Sminchisescu"", ""Richard Hartley""]","[""neural network calibration"", ""uncertainty"", ""calibration measure""]",We introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov statistical test and obtain a recalibration function by approximating the empirical cumulative distribution using a differentiable function via splines.,2006.12800,cs.LG,2020-06-23 07:18:05+00:00,2020-06-23 07:18:05+00:00
eSHBmLnD1s8,2022,Reject,False,Task Conditioned Stochastic Subsampling,"['Andreis Bruno', 'Seanie Lee', 'A. Tuan Nguyen', 'Juho Lee', 'Eunho Yang', 'Sung Ju Hwang']",[],We present a two-stage stochastic subsampling model for feature selection.,,,,
eU776ZYxEpz,2021,Accept (Poster),False,Learning to live with Dale's principle: ANNs with separate excitatory and inhibitory units,"[""Jonathan Cornford"", ""Damjan Kalajdzievski"", ""Marco Leite"", ""Am\u00e9lie Lamarquette"", ""Dimitri Michael Kullmann"", ""Blake Aaron Richards""]",[],,,,,
eV5d4I3eso,2022,Reject,False,Geometric Random Walk Graph Neural Networks via Implicit Layers,"['Giannis Nikolentzos', 'Michalis Vazirgiannis']",[],,,,,
eVzy-BWKY6Z,2022,Reject,False,Edge Rewiring Goes Neural: Boosting Network Resilience via Policy Gradient,"['Shanchao Yang', 'MA KAILI', 'Baoxiang Wang', 'Hongyuan Zha']","[""network resilience"", ""neural combinatorial optimization"", ""graph neural networks"", ""reinforcement learning""]",We present a reinforcement learning-based solver for boosting the resilience of a graph network which protects the system from natural disasters or targeted attacks.,,,,
eW5R4Cek6y6,2022,Accept (Spotlight),False,On Predicting Generalization using GANs,"['Yi Zhang', 'Arushi Gupta', 'Nikunj Saunshi', 'Sanjeev Arora']","[""generalization"", ""generative adversarial network""]",,,,,
eYciPrLuUhG,2022,Accept (Poster),True,Efficient Neural Causal Discovery without Acyclicity Constraints,"['Phillip Lippe', 'Taco Cohen', 'Efstratios Gavves']","[""Causal discovery"", ""structure learning""]","We present ENCO, an efficient structure learning method that leverages observational and interventional data and scales to graphs with a thousand variables.",2107.10483,cs.LG,2021-07-22 07:01:41+00:00,2021-10-07 06:59:22+00:00
eYgI3cTPTq9,2021,Reject,False,How to Avoid Being Eaten by a Grue: Structured Exploration Strategies for Textual Worlds,"[""Prithviraj Ammanabrolu"", ""Ethan Tien"", ""Matthew Hausknecht"", ""Mark Riedl""]","[""text-based games"", ""reinforcement learning"", ""exploration"", ""intrinsic motivation"", ""knowledge graphs"", ""question answering"", ""natural language processing""]","We present Q*BERT, an agent that systematically explores via an intrinsic motivation to learn a knowledge graph of the world.",,,,
eYyvftCgtD,2022,Reject,False,GroupBERT: Enhanced Transformer Architecture with Efficient Grouped Structures,"['Ivan Chelombiev', 'Daniel Justus', 'Douglas Orr', 'Anastasia S. D. Dietrich', 'Frithjof Gressmann', 'Alexandros Koliousis', 'Carlo Luschi']","[""Transformer"", ""BERT"", ""self-supervision"", ""compute efficiency"", ""sparsity"", ""convolution"", ""natural language processing""]","We present GroupBERT, proving more than 2x efficiency improvement over BERT, in terms of FLOPs and time-to-train",,,,
eZ-xMLuKPc,2022,Reject,False,Surgical Prediction with Interpretable Latent Representation,"['Bing Xue', 'York Jiao', 'Thomas Kannampallil', 'Joanna Abraham', 'Christopher Ryan King', 'Bradley A Fritz', 'Michael Avidan', 'Chenyang Lu']","[""machine learning"", ""healthcare applications"", ""latent encoding"", ""surgical predictions""]",Application of a tailored VAE model to surgical datasets that achieves high-performance prediction and clinically meaningful phenotyping effects. ,,,,
eZllW0F5aM_,2021,Reject,False,"Don't stack layers in graph neural networks, wire them randomly","[""Diego Valsesia"", ""Giulia Fracastoro"", ""Enrico Magli""]","[""Graph neural networks"", ""random architectures""]","Randomly wired architectures boost the performance of graph neural networks, providing a more effective way of increasing the number of layers with respect to Resnets.",2103.15565,cs.LG,2021-03-29 12:34:36+00:00,2021-03-29 12:34:36+00:00
e_D6AmszH4P,2022,Reject,False,ViViT: Curvature access through the generalized Gauss-Newton's low-rank structure,"['Felix Dangel', 'Lukas Tatzel', 'Philipp Hennig']","[""generalized Gauss-Newton"", ""curvature"", ""second-order methods"", ""Hessian spectrum in deep learning"", ""automatic differentiation""]",We present a curvature model that scales well and provides access to the mini-batch noise; we then characterize this noise and showcase its usefulness to improve optimizer stability.,,,,
e_FK_rDajEv,2022,Reject,False,Learning Neural Causal Models with Active Interventions,"['Nino Scherrer', 'Olexa Bilaniuk', 'Yashas Annadani', 'Anirudh Goyal', 'Patrick Schwab', 'Bernhard SchÃ¶lkopf', 'Michael Curtis Mozer', 'Yoshua Bengio', 'Stefan Bauer', 'Nan Rosemary Ke']","[""neural causal discovery"", ""causal structure learning"", ""active learning"", ""experimental design""]",We propose an active intervention-targeting mechanism which enables quick identification of the underlying causal structure in differentiable causal discovery.,,,,
ebS5NUfoMKL,2021,Accept (Poster),False,Boost then Convolve: Gradient Boosting Meets Graph Neural Networks,"[""Sergei Ivanov"", ""Liudmila Prokhorenkova""]","[""GNN"", ""GBDT"", ""graphs"", ""tabular data"", ""heterogeneous data""]",A novel strong architecture that combines advantages of GBDT and GNN for node-level prediction problems on graphs with tabular data.,2101.08543,cs.LG,2021-01-21 10:46:41+00:00,2021-03-31 12:13:30+00:00
ecH2FKaARUp,2022,Accept (Poster),False,An Information Fusion Approach to Learning with Instance-Dependent Label Noise,"['Zhimeng Jiang', 'Kaixiong Zhou', 'Zirui Liu', 'Li Li', 'Rui Chen', 'Soo-Hyun Choi', 'Xia Hu']","[""Instance-dependent label noise"", ""posterior transition matrix"", ""statiscally consistent classifier""]",This work is the first time to realize and bridge the gap between clean and noisy empirical distribution mismatch.,,,,
edJ_HipawCa,2021,Accept (Poster),False,Impact of Representation Learning in Linear Bandits,"[""Jiaqi Yang"", ""Wei Hu"", ""Jason D. Lee"", ""Simon Shaolei Du""]","[""linear bandits"", ""representation learning"", ""multi-task learning""]",We show representation learning provably improves multi-task linear bandits.,,,,
edN_G_4njyi,2022,Reject,True,On the Impact of Client Sampling on Federated Learning Convergence,"['Yann Fraboni', 'Richard Vidal', 'Laetitia Kameni', 'Marco Lorenzi']","[""Federated learning"", ""client sampling"", ""bias"", ""convergence rate"", ""distributed optimization"", ""data heterogeneity""]",,2107.12211,cs.LG,2021-07-26 13:36:06+00:00,2021-12-22 09:02:13+00:00
edONMAnhLu-,2022,Accept (Poster),False,Surrogate Gap Minimization Improves Sharpness-Aware Training,"['Juntang Zhuang', 'Boqing Gong', 'Liangzhe Yuan', 'Yin Cui', 'Hartwig Adam', 'Nicha C Dvornek', 'sekhar tatikonda', 'James s Duncan', 'Ting Liu']","[""generalization"", ""sharpness-aware minimization"", ""surrogate gap"", ""deep learning""]","We propose GSAM which seeks a region with both small loss and low sharpness, and improves generalization over SAM with negligible computation overhead.",,,,
edku48LG0pT,2021,Reject,False,A Neural Network MCMC sampler that maximizes Proposal Entropy,"[""ZENGYI LI"", ""Yubei Chen"", ""Friedrich Sommer""]","[""MCMC"", ""Adaptive MCMC"", ""Neural MCMC"", ""Normalizing Flow"", ""Entropy based speed Measure"", ""HMC"", ""Energy-based Model"", ""Sampling""]",Neural network MCMC sampler that tractably maximize proposal entropy objective,,,,
ee6W5UgQLa,2021,Accept (Poster),False,"MultiModalQA: complex question answering over text, tables and images","[""Alon Talmor"", ""Ori Yoran"", ""Amnon Catav"", ""Dan Lahav"", ""Yizhong Wang"", ""Akari Asai"", ""Gabriel Ilharco"", ""Hannaneh Hajishirzi"", ""Jonathan Berant""]","[""NLP"", ""Question Answering"", ""Dataset"", ""Multi-Modal"", ""Multi-Hop""]","MultiModalQA: A question answering dataset that requires multi-modal multi-hop reasoning over wikipedia text, tables and images, accompanied by a new multi-hop model for tackling the task.",2104.06039,cs.CL,2021-04-13 09:14:28+00:00,2021-04-13 09:14:28+00:00
ef0nInZHKIC,2022,Accept (Poster),False,Symbolic Learning to Optimize: Towards Interpretability and Scalability,"['Wenqing Zheng', 'Tianlong Chen', 'Ting-Kuei Hu', 'Zhangyang Wang']","[""Symbolic Regression"", ""Learning To Optimize"", ""Interpretability""]",Learning to distill learned optimization rule into symbolic math equations that bears better interpretability and scales better.,,,,
ehJqJQk9cw,2021,Accept (Poster),False,Personalized Federated Learning with First Order Model Optimization,"[""Michael Zhang"", ""Karan Sapra"", ""Sanja Fidler"", ""Serena Yeung"", ""Jose M. Alvarez""]","[""Federated learning"", ""personalized learning""]","We propose a new federated learning framework that efficiently computes a personalized weighted combination of available models for each client, outperforming existing work for personalized federated learning.",2012.08565,cs.LG,2020-12-15 19:30:29+00:00,2021-03-26 23:13:26+00:00
ei3SY1_zYsE,2022,Accept (Poster),False,Fortuitous Forgetting in Connectionist Networks,"['Hattie Zhou', 'Ankit Vani', 'Hugo Larochelle', 'Aaron Courville']","[""Neural Networks"", ""Generalization"", ""Iterative Training"", ""Compositionality"", ""Iterated Learning""]","We introduce ""forget-and-relearn"" as a training paradigm where forgetting removes undesirable information and relearning bolsters useful features towards better generalization and compositionality.",2202.00155,cs.LG,2022-02-01 00:15:58+00:00,2022-02-01 00:15:58+00:00
eiwpbi3iwr,2022,Reject,False,Neuronal Learning Analysis using Cycle-Consistent Adversarial Networks,"['Bryan M. Li', 'Theoklitos Amvrosiadis', 'Nathalie L. Rochefort', 'Arno Onken']","[""neuronal learning"", ""unsupervised learning"", ""calcium imaging"", ""generative adversarial networks"", ""cycle-consistent adversarial networks"", ""explainable AI""]",Learn the unknown mapping between pre-learning and post-learning neuronal activities recorded in vivo using cycle-consistent adversarial networks.,,,,
ek9a0qIafW,2022,Accept (Poster),True,Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners,"['Ningyu Zhang', 'Luoqiu Li', 'Xiang Chen', 'Shumin Deng', 'Zhen Bi', 'Chuanqi Tan', 'Fei Huang', 'Huajun Chen']","[""prompt-tuning"", ""pre-trained language model"", ""few-shot learning""]",A differentiable prompt learning method for few-shot NLP with optimized prompt templates as well as labels. ,2108.13161,cs.CL,2021-08-30 12:29:25+00:00,2022-02-11 14:23:52+00:00
enhd0P_ERBO,2021,Reject,False,Learning a Transferable Scheduling Policy for Various Vehicle Routing Problems based on Graph-centric Representation Learning,"[""Inwook Kim"", ""Jinkyoo Park""]","[""Vehicle Routing Problem"", ""Multiple Traveling Salesmen Problem"", ""Capacitated Vehicle Routing Problem"", ""Reinforcement Learning"", ""Graph Neural Network""]","This study proposes the graph-centric, RL-based transferable scheduler for various vehicle routing problems using graph-centric state presentation (GRLTS) that can solve any types of vehicle routing problems such as mCVRP, mTSP, CVRP, and TSP.",,,,
enoVQWLsfyL,2021,Accept (Poster),True,Viewmaker Networks: Learning Views for Unsupervised Representation Learning,"[""Alex Tamkin"", ""Mike Wu"", ""Noah Goodman""]","[""unsupervised learning"", ""self-supervised"", ""representation learning"", ""contrastive learning"", ""views"", ""data augmentation""]","We present a new generative model that produces views for self-supervised learning, matching or outperforming hand-crafted views on image, speech, and wearable sensor datasets",2010.07432,cs.LG,2020-10-14 23:03:31+00:00,2021-03-29 06:49:09+00:00
eo1barn2Xmd,2022,Reject,False,"SLIM-QN: A Stochastic, Light, Momentumized Quasi-Newton Optimizer for Deep Neural Networks","['Yue Niu', 'Zalan Fabian', 'Sunwoo Lee', 'Mahdi Soltanolkotabi', 'Salman Avestimehr']","[""Second-Order Methods"", ""Stochastic Optimization"", ""Deep Neural Networks""]",A stochastic light quasi-Newton optimizer for large-scale deep neural networks.,,,,
eo6U4CAwVmg,2021,Accept (Poster),False,Training GANs with Stronger Augmentations via Contrastive Discriminator,"[""Jongheon Jeong"", ""Jinwoo Shin""]","[""generative adversarial networks"", ""contrastive learning"", ""data augmentation"", ""visual representation learning"", ""unsupervised learning""]","We propose a novel discriminator of GAN showing that contrastive representation learning, e.g., SimCLR, and GAN can benefit each other when they are jointly trained. ",2103.09742,cs.LG,2021-03-17 16:04:54+00:00,2021-03-17 16:04:54+00:00
eoQBpdMy81m,2021,Reject,False,Federated Averaging as Expectation Maximization,"[""Christos Louizos"", ""Matthias Reisser"", ""Joseph Soriaga"", ""Max Welling""]","[""federated"", ""learning"", ""sparsity"", ""expectation"", ""maximization"", ""efficient"", ""FedAvg"", ""FedSparse"", ""EM""]","We provide a view of federated averaging through Expectation-Maximization and propose FedSparse, an extension that learns sparse models in the federated setting.",,,,
eom0IUrF__F,2021,Accept (Poster),True,CoCo: Controllable Counterfactuals for Evaluating Dialogue State Trackers,"[""SHIYANG LI"", ""Semih Yavuz"", ""Kazuma Hashimoto"", ""Jia Li"", ""Tong Niu"", ""Nazneen Rajani"", ""Xifeng Yan"", ""Yingbo Zhou"", ""Caiming Xiong""]","[""task-oriented dialogue"", ""dialogue state tracking"", ""robustness"", ""dst"", ""evaluation""]",CoCo is a principled method to more flexibly evaluate the robustness of the DST component of TOD systems.,2010.12850,cs.CL,2020-10-24 09:39:35+00:00,2021-03-26 06:35:21+00:00
ep81NLpHeos,2021,Reject,False,Momentum Contrastive Autoencoder,"[""Devansh Arpit"", ""Aadyot Bhatnagar"", ""Huan Wang"", ""Caiming Xiong""]","[""generative model"", ""contrastive learning"", ""autoencoder"", ""Wasserstein autoencoder""]",We propose a simple autoencoder based generative model that overcomes many of the optimization challenges of existing generative models by combining contrastive learning with Wasserstein autoencoder.,,,,
eqBwg3AcIAK,2021,Accept (Poster),False,Off-Dynamics Reinforcement Learning: Training for Transfer with Domain Classifiers,"[""Benjamin Eysenbach"", ""Shreyas Chaudhari"", ""Swapnil Asawa"", ""Sergey Levine"", ""Ruslan Salakhutdinov""]","[""reinforcement learning"", ""transfer learning"", ""domain adaptation""]","We propose a method for addressing domain adaptation in RL by using a (learned) modified reward, and prove that our method recovers a near-optimal policy for the target domain.",,,,
eqRTPB134q0,2022,Reject,False,Invariance in Policy Optimisation and Partial Identifiability in Reward Learning,"['Joar Max Viktor Skalse', 'Matthew Farrugia-Roberts', 'Stuart Russell', 'Adam Gleave']",[],"Theoretical analysis of partial identifiability of core reward learning methods including IRL and preference comparisons, with links to lattice structure of invariances of core RL objects.",,,,
eqaxDZg4MHw,2022,Reject,False,Understanding the Generalization Gap in Visual Reinforcement Learning,"['Anurag Ajay', 'Ge Yang', 'Ofir Nachum', 'Pulkit Agrawal']","[""Visual Reinforcement Learning"", ""Transfer in Reinforcement Learning"", ""Generalization in Reinforcement Learning""]",Analyzing and understanding the generalization gap in visual reinforcement learning,,,,
euDnVs0Ynts,2021,Accept (Poster),False,Robust Learning of Fixed-Structure Bayesian Networks in Nearly-Linear Time,"[""Yu Cheng"", ""Honghao Lin""]","[""Bayesian networks"", ""robust statistics"", ""learning theory""]",We give the first nearly-linear time algorithm for the robust learning of fixed-structure Bayesian networks.,2105.05555,cs.LG,2021-05-12 10:11:32+00:00,2021-05-12 10:11:32+00:00
exa2mDqPb5E,2021,Reject,False,CIGMO: Learning categorical invariant deep generative models from grouped data,"[""Haruo Hosoya""]","[""variational autoencoders"", ""disentangling"", ""mixture"", ""clustering""]","A novel VAE-based deep general model that can discover category, shape, and view factors of general object images is presented.",,,,
ey1XXNzcIZS,2021,Reject,False,Exploring Routing Strategies for Multilingual Mixture-of-Experts Models,"[""Sneha Kudugunta"", ""Yanping Huang"", ""Ankur Bapna"", ""Maxim Krikun"", ""Dmitry Lepikhin"", ""Thang Luong"", ""Orhan Firat""]","[""Mixture-of-Experts"", ""Neural Machine Translation"", ""Multilingual"", ""Multi-Task Learning"", ""Conditional Computation"", ""Natural Language Processing""]",,,,,
eyDDGPt5R1S,2021,Reject,False,Learning Deep Latent Variable Models via Amortized Langevin Dynamics,"[""Shohei Taniguchi"", ""Yusuke Iwasawa"", ""Yutaka Matsuo""]","[""Langevin dynamics"", ""amortized inference"", ""deep generative model""]",Amortization method for Langevin dynamics and its application to deep latent variable models,,,,
eyXknI5scWu,2021,Reject,True,Investigating and Simplifying Masking-based Saliency Methods for Model Interpretability,"[""Jason Phang"", ""Jungkyu Park"", ""Krzysztof J. Geras""]","[""saliency maps"", ""interpretability"", ""explainable AI"", ""image recognition"", ""image masking"", ""adversarial training""]","In a large evaluation study, we show that a simple formulation of masking-based saliency map generation outperforms many recently proposed improvements, and that comparable results can be obtained by training on as few as 10 examples per class.",2010.09750,cs.CV,2020-10-19 18:00:36+00:00,2020-10-19 18:00:36+00:00
eypsJ0rvAqo,2022,Reject,True,1-bit LAMB: Communication Efficient Large-Scale Large-Batch Training with LAMB's Convergence Speed,"['Conglong Li', 'Ammar Ahmad Awan', 'Hanlin Tang', 'Samyam Rajbhandari', 'Yuxiong He']","[""optimization"", ""communication compression"", ""natural language processing"", ""language model pre-training""]",1-bit LAMB provides communication efficient large-batch pre-training with LAMB's convergence speed,2104.06069,cs.LG,2021-04-13 10:07:49+00:00,2021-10-06 03:48:58+00:00
ezbMFmQY7L,2022,Reject,False,C5T5: Controllable Generation of Organic Molecules with Transformers,"['Daniel Rothchild', 'Alex Tamkin', 'Julie Yu', 'Ujval Misra', 'Joseph E. Gonzalez']","[""molecular modeling"", ""sequence modeling"", ""conditional sequence modeling"", ""drug discovery""]",,,,,
f-KGT01Qze0,2022,Reject,False,Robustmix: Improving Robustness by Regularizing the Frequency Bias of Deep Nets,"['Jonas NgnawÃ©', 'MARIANNE NJIFON', 'Jonathan Heek', 'Yann Dauphin']","[""robustness"", ""imagenet-c"", ""mixup""]",,,,,
f0sNwNeqqxx,2021,Reject,False,Practical Locally Private Federated Learning with Communication Efficiency,"[""Yan Feng"", ""Tao Xiong"", ""Ruofan Wu"", ""Yuan Qi""]",[],,,,,
f2OYVDyfIB,2022,Accept (Poster),True,Scale Efficiently: Insights from Pretraining and Finetuning Transformers,"['Yi Tay', 'Mostafa Dehghani', 'Jinfeng Rao', 'William Fedus', 'Samira Abnar', 'Hyung Won Chung', 'Sharan Narang', 'Dani Yogatama', 'Ashish Vaswani', 'Donald Metzler']","[""transformers"", ""attention"", ""deep learning""]",Scaling laws for upstream and downstream tasks ,2109.10686,cs.CL,2021-09-22 12:29:15+00:00,2022-01-30 16:42:46+00:00
f2lrIbGx3x7,2022,Accept (Poster),False,Bayesian Framework for Gradient Leakage,"['Mislav Balunovic', 'Dimitar Iliev Dimitrov', 'Robin Staab', 'Martin Vechev']","[""federated learning"", ""privacy"", ""gradient leakage""]","We propose a theoretical framework for analysis of the Bayes optimal adversary for gradient leakage, and perform evaluation of existing defenses.",,,,
f3QTgKQW0TD,2022,Reject,False,"Manifold Distance Judge, an Adversarial Samples Defense Strategy Based on Service Orchestration","['Mengxin Zhang', 'Xiaofeng QIU']","[""service orchestration"", ""manifold distance detection"", ""adversarial example"", ""neural network.""]","We demonstrated an orchestrated defense strategy, named Manifold Distance Judge (MDJ), which selects the best image processing to combine with a manifold distance detector to defense adversarial samples",,,,
f3qFAV_MH-C,2022,Reject,False,Transfer and Marginalize: Explaining Away Label Noise with Privileged Information,"['Mark Collier', 'Rodolphe Jenatton', 'Effrosyni Kokiopoulou', 'Jesse Berent']",[],"Leveraging privileged information to explain away label noise with a simple, efficient, novel method: TRAM.",,,,
f4c4JtbHJ7B,2022,Reject,False,"Pixab-CAM: Attend Pixel, not Channel","['Jaeeun Jang', 'Seokjun Kim', 'Hyeoncheol Kim']","[""Explainable AI"", ""Interpretable ML"", ""Visual explanation of CNN"", ""Class activation maps"", ""Computer Vision""]",A new method that breaks the frame of the existing class activation mapping (CAM) based approach,,,,
f6CQliwyra,2022,Reject,False,A Free Lunch from the Noise: Provable and Practical Exploration for Representation Learning,"['Tongzheng Ren', 'Tianjun Zhang', 'Csaba Szepesvari', 'Bo Dai']","[""representation learning"", ""reinforcement learning""]","We utilize the structure of noise to propose a provable and practical exploration algorithm for representation learning in reinforcement learning, which has superior performance over the existing state-of-the-art algorithms on several benchmarks.",,,,
f7cWROZYSU,2022,Reject,False,Detecting Worst-case Corruptions via Loss Landscape Curvature in Deep Reinforcement Learning,"['Ezgi Korkmaz', 'Jonah Brown-Cohen']",[],,,,,
f9AIc3mEprf,2022,Reject,False,What classifiers know what they don't know?,"['Mohamed Ishmael Belghazi', 'David Lopez-Paz']","[""Uncertainty quantification"", ""neural networks"", ""benchmark""]","The entropy of ERM deep image classifiers is a very hard baseline to beat in realistic, large-scale uncertainty estimation",,,,
f9D-5WNG4Nv,2022,Accept (Poster),True,Online Coreset Selection for Rehearsal-based Continual Learning,"['Jaehong Yoon', 'Divyam Madaan', 'Eunho Yang', 'Sung Ju Hwang']","[""Continual Learning""]","We propose Online Coreset Selection (OCS), a simple yet effective method that selects the most representative and informative coreset at each iteration and trains them in an online manner.",2106.01085,cs.LG,2021-06-02 11:39:25+00:00,2021-06-02 11:39:25+00:00
f9JwVXMJ1Up,2022,Reject,False,The Needle in the haystack: Out-distribution aware Self-training in an Open-World Setting,"['Maximilian Augustin', 'Matthias Hein']",[],,,,,
f9MHpAGUyMn,2022,Accept (Poster),False,Dynamic Token Normalization improves Vision Transformers,"['Wenqi Shao', 'Yixiao Ge', 'Zhaoyang Zhang', 'XUYUAN XU', 'Xiaogang Wang', 'Ying Shan', 'Ping Luo']","[""classification"", ""Normalization"", ""transformer""]",The proposed DTN is a simple yet effective normalizer for vision transformers.,2112.02624,cs.CV,2021-12-05 17:04:59+00:00,2021-12-05 17:04:59+00:00
fAbkE6ant2,2021,Accept (Poster),False,Revisiting Locally Supervised Learning: an Alternative to End-to-end Training,"[""Yulin Wang"", ""Zanlin Ni"", ""Shiji Song"", ""Le Yang"", ""Gao Huang""]","[""Locally supervised training"", ""Deep learning""]","We provide a deep understanding of locally supervised learning, and make it perform on par with end-to-end training, while with significantly reduced GPUs memory footprint. Code is available at: https://github.com/blackfeather-wang/InfoPro-Pytorch.",2101.10832,cs.CV,2021-01-26 15:02:18+00:00,2021-01-26 15:02:18+00:00
fCG75wd39ze,2022,Accept (Poster),False,LORD: Lower-Dimensional Embedding of Log-Signature in Neural Rough Differential Equations,"['JAEHOON LEE', 'Jinsung Jeon', 'Sheo yon Jhin', 'Jihyeon Hyeong', 'Jayoung Kim', 'Minju Jo', 'Kook Seungji', 'Noseong Park']",[],We reduce the complexity of processing higher depth log-signatures in NRDE.,,,,
fCSq8yrDkc,2022,Accept (Poster),True,A fast and accurate splitting method for optimal transport: analysis and implementation,"['Vien V. Mai', 'Jacob LindbÃ¤ck', 'Mikael Johansson']","[""Optimal transport"", ""Operator splitting"", ""Douglas-Rachford"", ""ADMM"", ""GPUs""]",We develop a fast and reliable method for solving large-scale optimal transport (OT) problems at an unprecedented combination of speed and accuracy.,2110.11738,math.OC,2021-10-22 12:16:08+00:00,2021-10-22 12:16:08+00:00
fESskTMMSv,2021,Reject,False,Practical Marginalized Importance Sampling with the Successor Representation,"[""Scott Fujimoto"", ""David Meger"", ""Doina Precup""]","[""marginalized importance sampling"", ""off-policy evaluation"", ""deep reinforcement learning"", ""successor representation""]",We develop an approach for MIS that can be computed from the successor representation and scales to high-dimensional systems.,2106.06854,cs.LG,2021-06-12 20:21:38+00:00,2021-06-12 20:21:38+00:00
fEcbkaHqlur,2022,Reject,False,Beyond Target Networks: Improving Deep $Q$-learning with Functional Regularization,"['Alexandre PichÃ©', 'Joseph Marino', 'Gian Maria Marconi', 'Christopher Pal', 'Mohammad Emtiyaz Khan']","[""Q learning"", ""regularization"", ""deep Q learning""]",We propose a functionally regularize alternative to the squared Bellman error.,,,,
fExcSKdDo_,2022,Accept (Poster),False,Learning to Dequantise with Truncated Flows,"['Shawn Tan', 'Chin-Wei Huang', 'Alessandro Sordoni', 'Aaron Courville']","[""variational inference"", ""variational bayes"", ""dequantisation"", ""normalizing flows""]",Learning a variational dequantisation scheme with truncated/bounded-support distributions,,,,
fGEoHDk0C,2022,Reject,False,A framework of deep neural networks via the solution operator of partial differential equations,"['Wenqi Tao', 'Zuoqiang Shi']","[""deep neural networks"", ""partial differential equations"", ""solution operator""]",We derive a general form of PDEs for the design of ResNet-like DNN and design a training method for DNN.,,,,
fGF8qAqpXXG,2021,Accept (Poster),False,Vector-output ReLU Neural Network Problems are Copositive Programs: Convex Analysis of Two Layer Networks and Polynomial-time Algorithms,"[""Arda Sahiner"", ""Tolga Ergen"", ""John M. Pauly"", ""Mert Pilanci""]","[""neural networks"", ""theory"", ""convex optimization"", ""copositive programming"", ""convex duality"", ""nonnegative PCA"", ""semi-nonnegative matrix factorization"", ""computational complexity"", ""global optima"", ""semi-infinite duality"", ""convolutional neural networks""]","We demonstrate that two-layer vector-output ReLU networks can be expressed as copositive programs, and introduce algorithms for provably finding their global optima, which are polynomial in the number of samples for a fixed data rank.",,,,
fGiKxvF-eub,2021,Reject,False,Oblivious Sketching-based Central Path Method for Solving Linear Programming Problems,"[""Zhao Song"", ""Zheng Yu""]","[""optimization"", ""sketching"", ""linear programming"", ""central path method"", ""running time complexity""]","We propose a sketching-based central path method for solving linear programs, which has the same running time as the state of art algorithms and enjoys the advantages of being ""oblivious"" and ""feasible"".",,,,
fHPdmN3I0tY,2022,Reject,False,Decoupled Kernel Neural Processes: Neural Network-Parameterized Stochastic Processes using Explicit Data-driven Kernel,"['Daehoon Gwak', 'Gyubok Lee', 'Jaehoon Lee', 'Jaesik Choi', 'Jaegul Choo', 'Edward Choi']",[],,,,,
fHeK814NOMO,2022,Reject,False,Trainable Learning Rate,"['George Retsinas', 'Giorgos Sfikas', 'Panagiotis Filntisis', 'Petros Maragos']","[""Gradient Descent"", ""Adaptive Step Size"", ""Adaptive Learning Rate""]","An extension of classic Gradient Descent, where instead of using a schedule for learning rate we propose treating it as a model parameter and learning it from the data.",,,,
fILj7WpI-g,2022,Accept (Spotlight),False,Perceiver IO: A General Architecture for Structured Inputs & Outputs,"['Andrew Jaegle', 'Sebastian Borgeaud', 'Jean-Baptiste Alayrac', 'Carl Doersch', 'Catalin Ionescu', 'David Ding', 'Skanda Koppula', 'Daniel Zoran', 'Andrew Brock', 'Evan Shelhamer', 'Olivier J Henaff', 'Matthew Botvinick', 'Andrew Zisserman', 'Oriol Vinyals', 'Joao Carreira']","[""Perceiver"", ""BERT"", ""natural language processing"", ""optical flow"", ""computer vision"", ""multimodal"", ""GLUE"", ""ImageNet"", ""StarCraft""]","We propose Perceiver IO, a general-purpose architecture that handles data from arbitrary settings while scaling linearly with the size of inputs and outputs.",,,,
fJIrkNKGBNI,2022,Reject,False,Effective Polynomial Filter Adaptation for Graph Neural Networks,"['Vijay Lingam', 'Chanakya Ajit Ekbote', 'Manan Sharma', 'Rahul Ragesh', 'Arun Iyer', 'SUNDARARAJAN SELLAMANICKAM']","[""Graph Neural Networks"", ""Graph Filters""]","This work proposes an effective polynomial filter design, combining multiple polynomials, for Graph Neural Networks",,,,
fKv__asZk47,2022,Reject,False,Learning Similarity Metrics for Volumetric Simulations with Multiscale CNNs,"['Georg Kohl', 'Liwei Chen', 'Nils Thuerey']","[""metric learning"", ""PDEs"", ""numerical simulation"", ""physical modeling""]",We propose a learned metric for 3D data from numerical simulations that is motivated by an entropy-based similarity model.,,,,
fM8VzFD_2-,2022,Reject,False,Discovering the neural correlate informed nosological relation among multiple neuropsychiatric disorders through dual utilisation of diagnostic information,"['Wenjun Bai', 'Tomoki Tokuda', 'Okito Yamashita', 'Junichiro Yoshimoto']","[""computational psychiatric"", ""variational auto-encoder"", ""fMRI analysis""]",We are seeking to reveal the complex nosological relation among diverse neuropsychiatric disorders with the help of diagnostic information. ,,,,
fMHwogGqTYs,2021,Reject,False,Identifying Coarse-grained Independent Causal Mechanisms with Self-supervision,"[""Xiaoyang Wang"", ""Klara Nahrstedt"", ""Oluwasanmi O Koyejo""]","[""Causal Mechanisms"", ""Identifiability"", ""Disentangled Representations""]",We propose a self-supervised method to learn the independent causal mechanisms and prove the identifiability.,,,,
fOsN52jn25l,2022,Accept (Poster),False,Dual Lottery Ticket Hypothesis,"['Yue Bai', 'Huan Wang', 'ZHIQIANG TAO', 'Kunpeng Li', 'Yun Fu']","[""Dual Lottery Ticket Hypothesis"", ""Sparse Network Training""]",We articulate a Dual Lottery Ticket Hypothesis (DLTH) with a proposed training strategy Random Sparse Network to validate DLTH.,,,,
fPhKeld3Okz,2022,Accept (Poster),True,Gradient Step Denoiser for convergent Plug-and-Play,"['Samuel Hurault', 'Arthur Leclaire', 'Nicolas Papadakis']","[""Plug-and-Play"", ""Inverse Problem"", ""Image Restoration"", ""Denoising""]",We propose a performant Plug-and-Play image restoration algorithm that theoretically converges with an exact gradient step deep denoiser.,2110.03220,cs.CV,2021-10-07 07:11:48+00:00,2021-10-07 07:11:48+00:00
fQTlgI2qZqE,2022,Accept (Poster),False,Fast Generic Interaction Detection for Model Interpretability and Compression,"['Tianjian Zhang', 'Feng Yin', 'Zhi-Quan Luo']",[],,,,,
fR-EnKWL_Zb,2022,Accept (Poster),False,Quadtree Attention for Vision Transformers,"['Shitao Tang', 'Jiahui Zhang', 'Siyu Zhu', 'Ping Tan']","[""Vision Transformer"", ""Efficient Transformer"", ""Feature matching"", ""Stereo"", ""image classification"", ""detection"", ""3D Vision""]",Reduce the computation of transformer by coarse-to-fine attention computation for feature matching/stereo/classification/detection tasks.,2201.02767,cs.CV,2022-01-08 05:45:32+00:00,2022-01-08 05:45:32+00:00
fRb9LBWUo56,2022,Reject,False,On the benefits of deep RL in accelerated MRI sampling,"['Thomas Sanchez', 'Igor Krawczuk', 'Volkan Cevher']","[""MRI reconstruction"", ""MRI sampling"", ""reinforcement learning"", ""accelerated MRI"", ""replication""]","Current deep RL methods applied to accelerated MRI sampling do not bring as much benefits as expected, and can be matched by a simple non-adaptive baseline.",,,,
fRnRsdc_nR7,2022,Reject,False,Towards fast and effective single-step adversarial training,"['Pau de Jorge', 'Adel Bibi', 'Riccardo Volpi', 'Amartya Sanyal', 'Philip Torr', 'GrÃ©gory Rogez', 'Puneet K. Dokania']","[""single-step adversarial training"", ""catastrophic overfitting"", ""FGSM"", ""efficient adversarial training"", ""fast adversarial training""]",We introduce a novel single-step attack for adversarial training that can prevent catastrophic overfitting while obtaining a 3x speed-up.,,,,
fSTD6NFIW_b,2021,Accept (Poster),True,Understanding the failure modes of out-of-distribution generalization,"[""Vaishnavh Nagarajan"", ""Anders Andreassen"", ""Behnam Neyshabur""]","[""out-of-distribution generalization"", ""spurious correlations"", ""empirical risk minimization"", ""theoretical study""]","In this theoretical study, we explain why machine learning models rely on spuriously correlated features in the dataset and fail at out-of-distribution generalization.",2010.15775,cs.LG,2020-10-29 17:19:03+00:00,2021-04-29 04:08:02+00:00
fSeD40P0XTI,2022,Reject,False,ACCTS: an Adaptive Model Training Policy for Continuous Classification of Time Series,"['Chenxi Sun', 'Moxian Song', 'Derun Cai', 'Shenda Hong', 'Hongyan Li']","[""Continuous classification of time series"", ""Deep learning"", ""Model training""]",,,,,
fStMpzKkjMT,2021,Reject,False,Why Does Decentralized Training Outperform Synchronous Training In The Large Batch Setting?,"[""Wei Zhang"", ""Mingrui Liu"", ""Yu Feng"", ""Brian Kingsbury"", ""Yuhai Tu""]","[""Decentralized"", ""Distributed Deep Learning"", ""Large Batch""]",The inherent system noise in decentralized distributed training can improve generalization in large batch setting compared to the synchronous training.,,,,
fStt6fyzrK,2022,Reject,False,Model-Based Robust Adaptive Semantic Segmentation,"['Jun Wang', 'Yiannis Kantaros']","[""Semantic Segmentation"", ""Robustness"", ""Natural Variation""]","We propose a new method to enhance robustness of deep learning-based segmentation methods against natural variations, such as changes in the lighting conditions.",,,,
fTYeefgXReA,2022,Reject,False,Equivariant Heterogeneous Graph Networks,"['Daniel Levy', 'Siamak Ravanbakhsh']","[""Heterogeneous Graphs"", ""Graph Neural Networks"", ""GNN"", ""Equivariance""]",We design maximally expressive linear neural network layers for heterogeneous graph learning,,,,
fTeb_adw5y4,2021,Reject,False,Improving Calibration through the Relationship with Adversarial Robustness,"[""Yao Qin"", ""Xuezhi Wang"", ""Alex Beutel"", ""Ed Chi""]","[""Calibration"", ""Uncertainty Estimates"", ""Adversarial Robustness""]",,,,,
fUhxuop_Q1r,2022,Reject,False,Disentangling Generalization in Reinforcement Learning,"['Alex Lewandowski', 'Dale Schuurmans', 'Jun Luo']","[""Reinforcement learning"", ""generalization""]","We propose a protocol for rigorously evaluating generalization in reinforcement learning across states, observations and actions.",,,,
fV2ScEA03Hg,2021,Reject,False,AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data,"[""Koichi Kuriyama""]","[""Automatic Data Cleansing"", ""Incorrect Labels"", ""Multiple Objects""]",AutoCleansing can capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. ,,,,
fV4vvs1J5iM,2021,Reject,False,A Reduction Approach to Constrained Reinforcement Learning,"[""Tianchi Cai"", ""Wenjie Shi"", ""Lihong Gu"", ""Xiaodong Zeng"", ""Jinjie Gu""]",[],,,,,
fVu3o-YUGQK,2022,Accept (Poster),True,Efficient Self-supervised Vision Transformers for Representation Learning,"['Chunyuan Li', 'Jianwei Yang', 'Pengchuan Zhang', 'Mei Gao', 'Bin Xiao', 'Xiyang Dai', 'Lu Yuan', 'Jianfeng Gao']","[""self-supervised learning"", ""vision transformers"", ""non-contrastive region-matching task""]","Achieving SoTA ImageNet linear probe task with 10 times higher throughput, using the synergy of a multi-stage Transformer architecture and a non-contrastive region-matching pre-training task. ",2106.09785,cs.CV,2021-06-17 19:57:33+00:00,2021-06-17 19:57:33+00:00
fWK3qhAtbbk,2022,Reject,False,A Study of Aggregation of Long Time-series Input for LSTM Neural Networks,"['Nitzan Farhi', 'Yuval Shavitt']","[""LSTM"", ""Data Aggregation"", ""Time Series""]",,,,,
fXHl76nO2AZ,2022,Accept (Poster),False,Gradient Importance Learning for Incomplete Observations,"['Qitong Gao', 'Dong Wang', 'Joshua David Amason', 'Siyang Yuan', 'Chenyang Tao', 'Ricardo Henao', 'Majda Hadziahmetovic', 'Lawrence Carin', 'Miroslav Pajic']","[""Missing Data"", ""Reinforcement Learning"", ""Representation Learning""]",,,,,
fYor2QIp_3,2022,Reject,False,An Effective GCN-based Hierarchical Multi-label classification for Protein Function Prediction,"['Kyudam Choi', 'Yurim Lee', 'Cheongwon Kim']","[""Bioinformatics"", ""Protein function prediction"", ""Machine Learning""]",We introduce a novel protein function model combined pre-trained language model and an efficient GCN-based model.,,,,
f_GA2IU9-K-,2021,Reject,False,Non-decreasing Quantile Function Network with Efficient Exploration for Distributional Reinforcement Learning,"[""Fan Zhou"", ""Zhoufan Zhu"", ""Qi Kuang"", ""Liwen Zhang""]","[""Non-decreasing Quantile Function"", ""Distributional Reinforcement Learning"", ""Distributional Prediction Error"", ""Exploration""]",This paper introduces a general framework to obtain non-decreasing quantile estimate for Distributional Reinforcement Learning and proposes an efficient exploration method for quantile value based DRL algorithms,2105.06696,cs.LG,2021-05-14 08:12:51+00:00,2021-05-14 08:12:51+00:00
faMcf0MDk0f,2022,Reject,False,BoolNet: Streamlining Binary Neural Networks Using Binary Feature Maps,"['Nianhui Guo', 'Joseph Bethge', 'Haojin Yang', 'Kai Zhong', 'Xuefei Ning', 'Christoph Meinel', 'Yu Wang']","[""Binary Neural Networks"", ""Hardware-Friendly Neural Architecture Design""]",This is the first paper that investigates the challenge of balancing accuracy and hardware-friendlyness in a binary neural network design.,,,,
famc03Gg231,2022,Reject,False,Physical Gradients for Deep Learning,"['Philipp Holl', 'Nils Thuerey', 'Vladlen Koltun']","[""deep learning"", ""simulation"", ""optimization"", ""inverse problems"", ""physics""]","We present a new training technique for neural networks that interact with physical simulations, outperforming state-of-the-art techniques by orders of magnitude.",,,,
fdZvTFn8Yq,2021,Reject,False,Probabilistic Meta-Learning for Bayesian Optimization,"[""Felix Berkenkamp"", ""Anna Eivazi"", ""Lukas Grossberger"", ""Kathrin Skubch"", ""Jonathan Spitz"", ""Christian Daniel"", ""Stefan Falkner""]","[""meta-learning"", ""bayesian optimization"", ""probabilistic modelling""]",We develop a probabilistic meta-learning model to speed up Bayesian optimization,,,,
ffS_Y258dZs,2022,Reject,False,Meta-Referential Games to Learn Compositional Learning Behaviours,"['Kevin Yandoka Denamganai', 'Sondess Missaoui', 'James Alfred Walker']","[""language emergence"", ""language grounding"", ""compositionality"", ""systematicity"", ""few-shot learning""]","Presentation of a novel benchmark to study artificial agents' abilities to learn compositional learning behaviours, along with results of state-of-the-art RL algorithms against it.",,,,
fgX9O5q0BT,2021,Reject,False,On Noise Injection in Generative Adversarial Networks,"[""Ruili Feng"", ""Deli Zhao"", ""Zheng-Jun Zha""]","[""Generative Adversarial Networks"", ""StyleGAN"", ""learning theory""]",,,,,
fgcIb5gd99r,2022,Reject,False,Multi-scale fusion self attention mechanism,"['Qibin Li', 'Nianmin Yao', 'Jian Zhao', 'Yanan Zhang']","[""Attention"", ""multi-scale"", ""phrase information"", ""sparsity scheme""]",A new attention mechanism that can better extract phrase level information ------ multi-scale attention mechanism,,,,
fgd7we_uZa6,2021,Accept (Poster),True,How Much Over-parameterization Is Sufficient to Learn Deep ReLU Networks?,"[""Zixiang Chen"", ""Yuan Cao"", ""Difan Zou"", ""Quanquan Gu""]","[""deep ReLU networks"", ""neural tangent kernel"", ""(stochastic) gradient descent"", ""generalization error"", ""classification""]",We establish learning guarantees for deep ReLU networks with width polylogarithmic in sample size and the inverse of the target error.,1911.12360,cs.LG,2019-11-27 18:59:50+00:00,2020-10-05 17:41:21+00:00
fgpXAu8puGj,2021,Reject,False,NAHAS: Neural Architecture and Hardware Accelerator Search,"[""Yanqi Zhou"", ""Xuanyi Dong"", ""Daiyi Peng"", ""Ethan Zhu"", ""Amir Yazdanbakhsh"", ""Berkin Akin"", ""Mingxing Tan"", ""James Laudon""]","[""neural architecture search"", ""systems"", ""hardware""]","We propose NAHAS, a latency-driven software/hardware co-optimizer that jointly optimize the design of neural architectures and a mobile edge processor.",,,,
fhcMwjavKEZ,2021,Reject,True,A Simple and General Graph Neural Network with Stochastic Message Passing,"[""Ziwei Zhang"", ""Chenhao Niu"", ""Peng Cui"", ""Bo Zhang"", ""Wei Cui"", ""Wenwu Zhu""]","[""Graph Neural Network"", ""Node Proximity"", ""Permutation-equivariant""]",A simple GNN that maintains both proximity-awareness and permutation-equivariance properties using Stochastic Message Passing,2009.02562,cs.LG,2020-09-05 16:46:56+00:00,2020-09-05 16:46:56+00:00
figzpGMrdD,2022,Accept (Poster),False,Pretrained Language Model in Continual Learning: A Comparative Study,"['Tongtong Wu', 'Massimo Caccia', 'Zhuang Li', 'Yuan-Fang Li', 'Guilin Qi', 'Gholamreza Haffari']","[""Continual Learning"", ""Pre-trained Language Model""]","In this paper, we thoroughly compare the continual learning performance over the combination of 5 PLMs and 4 veins of CL methods on 3 benchmarks in 2 typical incremental settings. ",,,,
fkhl7lb3aw,2021,Reject,False,ROGA: Random Over-sampling Based on Genetic Algorithm,"[""ZONGDA HAN"", ""XIUQUAN QIAO"", ""SHUBO ZHAN""]","[""class imbalance"", ""over-sampling"", ""genetic algorithm""]",,,,,
fkjO_FKVzw,2022,Reject,False,Coarformer: Transformer for large graph via graph coarsening,"['Weirui Kuang', 'Zhen WANG', 'Yaliang Li', 'Zhewei Wei', 'Bolin Ding']","[""Graph Neural Networks"", ""Transformer"", ""Graph Coarsening""]","We present Coarformer, a two-view architecture that captures fine-grained local information using a GNN-based module on the original graph and coarse yet long-range information using a Transformer-based module on the coarse graph.",,,,
fm58XfadSTF,2021,Reject,False,Learning a Max-Margin Classifier for Cross-Domain Sentiment Analysis,"[""Mohammad Rostami"", ""Aram Galstyan""]","[""natural language processing"", ""sentiment analysis"", ""cross-domain data representation"", ""distribution alignment""]",This paper intorduces a new method for mitigating domain shift problem in cross-domain sentiment classification by inducing large margins between classes in a source domain.,,,,
fmOOI2a3tQP,2021,Accept (Poster),True,Learning Robust State Abstractions for Hidden-Parameter Block MDPs,"[""Amy Zhang"", ""Shagun Sodhani"", ""Khimya Khetarpal"", ""Joelle Pineau""]","[""multi-task reinforcement learning"", ""bisimulation"", ""hidden-parameter mdp"", ""block mdp""]",We propose a new framework for tackling environments with different dynamics in rich observation settings and learning abstractions with this framework for improved generalization performance.,2007.07206,cs.LG,2020-07-14 17:25:27+00:00,2021-02-12 04:40:14+00:00
fmtSg8591Q,2021,Accept (Poster),True,Efficient Reinforcement Learning in Factored MDPs with Application to Constrained RL,"[""Xiaoyu Chen"", ""Jiachen Hu"", ""Lihong Li"", ""Liwei Wang""]","[""reinforcement learning"", ""factored MDP"", ""constrained RL"", ""learning theory""]","We propose an efficient algorithm with near-optimal regret guarantee for factored MDP, and apply the algorithm to a new formulation of constrained RL.",2008.13319,cs.LG,2020-08-31 02:20:41+00:00,2021-03-10 01:58:03+00:00
foNTMJHXHXC,2021,Reject,False,Out-of-Distribution Generalization via Risk Extrapolation (REx),"[""David Krueger"", ""Ethan Caballero"", ""Joern-Henrik Jacobsen"", ""Amy Zhang"", ""Jonathan Binas"", ""R\u00e9mi LE PRIOL"", ""Dinghuai Zhang"", ""Aaron Courville""]","[""out of distribution"", ""domain generalization"", ""invariant risk minimization"", ""robust optimization"", ""invariant causal prediction"", ""spurious features"", ""generalization""]",Risk extrapolation is a simple robust optimization approache for Out-of-Distribution (OOD) generalization and invariant prediction.,,,,
fpJX0O5bWKJ,2021,Reject,False,Estimating Example Difficulty using Variance of Gradients,"[""Chirag Agarwal"", ""Sara Hooker""]","[""interpretability"", ""human in the loop learning"", ""atypical examples""]",The Variance of Gradients (VoG) metric can be used to identify atypical examples from a distribution,,,,
fpU10jwpPvw,2022,Reject,False,Folded Hamiltonian Monte Carlo for Bayesian Generative Adversarial Networks,"['Narges Pourshahrokhi', 'Samaneh Kouchaki', 'Yunpeng Li', 'Payam M. Barnaghi']",[],,,,,
fuYtttFI-By,2022,Reject,False,Programmable 3D snapshot microscopy with Fourier convolutional networks,"['Diptodip Deb', 'Zhenfei Jiao', 'Alex Bo-Yuan Chen', 'Misha Ahrens', 'Kaspar Podgorski', 'Srinivas C Turaga']","[""computational microscopy"", ""computational photography"", ""computer vision"", ""deep learning""]","We introduce a neural network architecture using efficiently implemented global kernels for 3D snapshot microscope optimization, volume reconstruction, and lensless computational photograph reconstruction.",,,,
fuaHYhuYIDm,2022,Reject,False,MAGNEx: A Model Agnostic Global Neural Explainer,"['Nikolaos Manginas', 'Prodromos Malakasiotis', 'Eirini Spyropoulou', 'Ion Androutsopoulos', 'Georgios Paliouras']","[""Explainability"", ""Neural Explainer"", ""Faithfullness"", ""Global"", ""Post-hoc""]","A global post-hoc method for black-box model explainability, utilizing neural-based explainers. ",,,,
fvLLcIYmXb,2022,Accept (Poster),True,AS-MLP: An Axial Shifted MLP Architecture for Vision,"['Dongze Lian', 'Zehao Yu', 'Xing Sun', 'Shenghua Gao']","[""Architecture Design"", ""MLP"", ""Classification"", ""Detection"", ""Segmentation""]","We design the first MLP-based architecture for downstream tasks. It achieves competitive performance compared to the transformer-based architecture, which establishes a new strong baseline of MLP-based architecture. ",2107.08391,cs.CV,2021-07-18 08:56:34+00:00,2021-07-18 08:56:34+00:00
fw-BHZ1KjxJ,2021,Accept (Poster),True,SOLAR: Sparse Orthogonal Learned and Random Embeddings,"[""Tharun Medini"", ""Beidi Chen"", ""Anshumali Shrivastava""]","[""Sparse Embedding"", ""Inverted Index"", ""Learning to Hash"", ""Embedding Models""]",We propose a distributed training scheme to learn high dimensional sparse embeddings that are much better than dense embeddings on both precision and speed.,2008.13225,cs.LG,2020-08-30 17:35:35+00:00,2020-08-30 17:35:35+00:00
fw1-fHJpPK,2021,Reject,True,Decentralized Knowledge Graph Representation Learning,"[""Lingbing Guo"", ""Weiqing Wang"", ""Zequn Sun"", ""Chenghao Liu"", ""Wei Hu""]","[""Representation Learning"", ""Knowledge Graph"", ""Entity Alignment"", ""Knowledge Graph Completion"", ""Knowledge Graph Embedding""]",An inductive KG representation learning approach that only levearges structure information.,2010.08114,cs.LG,2020-10-16 02:31:22+00:00,2020-10-16 02:31:22+00:00
fwJWhOxuzV9,2022,Reject,False,Semi-supervised Offline Reinforcement Learning with Pre-trained Decision Transformers,"['Catherine Cang', 'Kourosh Hakhamaneshi', 'Ryan Rudes', 'Igor Mordatch', 'Aravind Rajeswaran', 'Pieter Abbeel', 'Michael Laskin']","[""Multi-task RL"", ""Decision Transformer"", ""self-supervised RL"", ""Pretraining""]","We introduce Pre-trained Decision Transformers, a simple and flexible architecture that can be pre-trained on unlabeled environment interactions and can quickly adapt to several downstream tasks with just a small reward-annotated fine-tuning dataset.",,,,
fwsdscicqUm,2022,Reject,True,Improving Fairness via Federated Learning,"['Yuchen Zeng', 'Hongxu Chen', 'Kangwook Lee']",[],,2110.15545,cs.LG,2021-10-29 05:25:44+00:00,2022-02-09 17:41:07+00:00
fwzUgo0FM9v,2022,Accept (Poster),False,Robbing the Fed:  Directly Obtaining Private Data in Federated Learning with Modified Models,"['Liam H Fowl', 'Jonas Geiping', 'Wojciech Czaja', 'Micah Goldblum', 'Tom Goldstein']","[""Privacy"", ""Federated Learning"", ""Gradient Inversion""]",,,,,
fyLvrx9M9YP,2022,Reject,False,Towards Unsupervised Content Disentanglement in Sentence Representations via Syntactic Roles,"['Ghazi Felhi', 'Joseph Le Roux', 'DjamÃ© Seddah']","[""NLP"", ""disentanglement"", ""unsupervised learning"", ""controllable generation.""]",We develop a procedure that exhibits disentanglement of content in sentence representations along syntactic roles.,,,,
fy_XRVHqly,2022,Accept (Poster),False,Structure-Aware Transformer Policy for Inhomogeneous Multi-Task Reinforcement Learning,"['Sunghoon Hong', 'Deunsol Yoon', 'Kee-Eung Kim']","[""Multitask Reinforcement Learning"", ""Modular Reinforcement Learning"", ""Transfer Learning"", ""Transformer"", ""Structural Embedding""]",We present a modular Multi-task Reinforcement Learning method for inhomogeneous control tasks incorporating structural embedding of morphology.,,,,
fycxGdpCCmW,2021,Reject,True,Hybrid Discriminative-Generative Training via Contrastive Learning,"[""Hao Liu"", ""Pieter Abbeel""]","[""Hybrid Models"", ""Contrastive Learning"", ""Energy-Based Models"", ""Discriminative-Generative Models""]","We propose a hybrid discriminative-generative model based on contrastive loss and energy-based models, which significantly improves state-of-the-art energy-based models and contrastive learning methods in multiple tasks.",2007.09070,cs.LG,2020-07-17 15:50:34+00:00,2020-08-10 07:34:31+00:00
fylclEqgvgd,2021,Accept (Poster),False,Transformer protein language models are unsupervised structure learners,"[""Roshan Rao"", ""Joshua Meier"", ""Tom Sercu"", ""Sergey Ovchinnikov"", ""Alexander Rives""]","[""proteins"", ""language modeling"", ""structure prediction"", ""unsupervised learning"", ""explainable""]",Transformer attention maps directly represent protein contacts with state-of-the-art unsupervised precision.,,,,
g-wu9TMPODo,2021,Accept (Spotlight),False,How Benign is Benign Overfitting ?,"[""Amartya Sanyal"", ""Puneet K. Dokania"", ""Varun Kanade"", ""Philip Torr""]","[""benign overfitting"", ""adversarial robustness"", ""memorization"", ""generalization""]",Interpolating label noise hurts adversarial robustness,,,,
g0a-XYjpQ7r,2021,Reject,True,Adaptive Personalized Federated Learning,"[""yuyang deng"", ""Mohammad Mahdi Kamani"", ""Mehrdad Mahdavi""]","[""Federated learning"", ""Personalization"", ""Optimization""]",In this paper we propose a provable efficient personalized federated learning algorithm.,2003.13461,cs.LG,2020-03-30 13:19:37+00:00,2020-11-06 04:07:31+00:00
g11CZSghXyY,2021,Accept (Poster),False,Combining Ensembles and Data Augmentation Can Harm Your Calibration,"[""Yeming Wen"", ""Ghassen Jerfel"", ""Rafael Muller"", ""Michael W Dusenberry"", ""Jasper Snoek"", ""Balaji Lakshminarayanan"", ""Dustin Tran""]","[""Ensembles"", ""Uncertainty estimates"", ""Calibration""]","We found that combining ensembles and data augmentation worsens calibration than applying them individually, and we proposed a simple fix to it.",,,,
g1KmTQhOhag,2021,Reject,False,Memory Representation in Transformer,"[""Mikhail Burtsev"", ""Yurii Kuratov"", ""Anton Peganov"", ""Grigory V. Sapunov""]","[""transformer"", ""memory augmented networks""]",Transformer can be trained to use memory for solving natural language processing tasks.,,,,
g1SzIRLQXMM,2022,Accept (Spotlight),False,Wiring Up Vision: Minimizing Supervised Synaptic Updates Needed to Produce a Primate Ventral Stream,"['Franziska Geiger', 'Martin Schrimpf', 'Tiago Marques', 'James J. DiCarlo']","[""computational neuroscience"", ""primate visual ventral stream"", ""convolutional neural networks"", ""biologically plausible learning""]",We develop biologically-motivated initialization and training procedures to train models with 200x fewer synaptic updates (epochs x labeled images x weights) while maintaining 80% of brain predictivity on a set of neural and behavioral benchmarks.,,,,
g21u6nlbPzn,2021,Accept (Poster),False,VA-RED$^2$: Video Adaptive Redundancy Reduction,"[""Bowen Pan"", ""Rameswar Panda"", ""Camilo Luciano Fosco"", ""Chung-Ching Lin"", ""Alex J Andonian"", ""Yue Meng"", ""Kate Saenko"", ""Aude Oliva"", ""Rogerio Feris""]",[],,,,,
g2LCQwG7Of,2022,Accept (Poster),False,End-to-End Learning of Probabilistic Hierarchies on Graphs,"['Daniel ZÃ¼gner', 'Bertrand Charpentier', 'Morgane Ayle', 'Sascha Geringer', 'Stephan GÃ¼nnemann']","[""hierarchical clustering"", ""graphs"", ""networks"", ""graph mining"", ""network mining"", ""graph custering""]",End-to-end gradient-based hierarchical clustering on graphs by exploiting Markov chain theory leads to state-of-the-art results.,,,,
g4E6SAAvACo,2021,Reject,False,Neural Architecture Search without Training,"[""Joseph Mellor"", ""Jack Turner"", ""Amos Storkey"", ""Elliot J. Crowley""]","[""NAS"", ""efficiency"", ""search"", ""fast"", ""cheap"", ""convnets""]",We can cheaply estimate how good an architecture will be without training it to save time and compute in NAS.,,,,
g4nVdxU9RK,2022,Reject,False,Rewardless Open-Ended Learning (ROEL),"['Alexander Quessy', 'Thomas Stuart Richardson']","[""unsupervised reinforcement learning"", ""open-ended learning"", ""skill discovery""]","We present ROEL, an unsupervised open-ended reinforcement learning algorithm that aims to automatically generate increasingly complex & useful skills",,,,
g4szfsQUdy3,2021,Reject,False,Implicit Regularization Effects of Unbiased Random Label Noises with SGD,"[""Haoyi Xiong"", ""Xuhong Li"", ""Boyang Yu"", ""Dejing Dou"", ""Dongrui Wu"", ""Zhanxing Zhu""]",[],The random label noises perform as an implicit regularizer of SGD and help the learning procedure select a stable solution.,,,,
g5odb-gVVZY,2022,Reject,False,Multilevel physics informed neural networks (MPINNs),"['Elisa Riccietti', 'Valentin Mercier', 'Serge Gratton', 'Pierre Boudier']",[],,,,,
g5tANwND04i,2022,Accept (Poster),False,On the Convergence of mSGD and AdaGrad for Stochastic Optimization,"['ruinan Jin', 'Yu Xing', 'Xingkang He']","[""stochastic gradient descent"", ""adaptive gradient algorithm"", ""asymptotic convergence""]",A theoretical paper focusing on the investigation for the convergence of mSGD and AdaGrad optimization algorithms.,2201.11204,cs.LG,2022-01-26 22:02:21+00:00,2022-01-26 22:02:21+00:00
g5ynW-jMq4M,2022,Accept (Spotlight),True,Properties from mechanisms: an equivariance perspective on identifiable representation learning,"['Kartik Ahuja', 'Jason Hartford', 'Yoshua Bengio']","[""representation learning"", ""equivariance"", ""independent component analysis"", ""ICA"", ""autoencoders""]",Representation learning is identifiable up to any equivariances of the (known) mechanisms that govern an environment's evolution.,2110.15796,cs.LG,2021-10-29 14:04:08+00:00,2021-10-29 14:04:08+00:00
g6OrH2oT5so,2021,Reject,False,Bridging the Imitation Gap by Adaptive Insubordination,"[""Luca Weihs"", ""Unnat Jain"", ""Jordi Salvador"", ""Svetlana Lazebnik"", ""Aniruddha Kembhavi"", ""Alex Schwing""]","[""Privileged Experts"", ""Imitation Learning"", ""Reinforcement Learning"", ""Actor-Critic"", ""Behavior Cloning"", ""MiniGrid"", ""Knowledge Distillation""]","Imitation learning can fail when the expert uses privileged information, we address this by combining imitation and reward-based reinforcement learning losses using dynamic weights.",,,,
g6UqpVislvH,2022,Reject,False,Generalized Fourier Features for Coordinate-Based Learning of Functions on Manifolds,"['Carlos Esteves', 'Tianjian Lu', 'Mohammed Suhail', 'Yi-fan Chen\u200e', 'Ameesh Makadia']","[""positional encoding"", ""fourier features"", ""coordinate-based mlp""]",We generalize the positional encoding method using Fourier features for coordinate-based learning of functions on non-Euclidean manifolds.,,,,
g75kUi1jAc_,2021,Reject,True,WAFFLe: Weight Anonymized Factorization for Federated Learning,"[""Weituo Hao"", ""Nikhil Mehta"", ""Kevin J Liang"", ""Pengyu Cheng"", ""Mostafa El-Khamy"", ""Lawrence Carin""]","[""Federated Learning"", ""Fairness"", ""Privacy""]","We propose WAFFLe, combining IBP with a shared dictionary of weight factors to model statistical heterogeneity, leading to a fairer FL method with better data security.",2008.05687,cs.LG,2020-08-13 04:26:31+00:00,2020-08-13 04:26:31+00:00
g8NJR6fCCl8,2022,Accept (Spotlight),True,NODE-GAM: Neural Generalized Additive Model for Interpretable Deep Learning,"['Chun-Hao Chang', 'Rich Caruana', 'Anna Goldenberg']","[""Generalized Additive Model"", ""Deep Learning Architecture"", ""Interpretability""]","We develop a deep-learning version of Generalized Additive Model (GAM) and GA2M that is accurate, scalable and interpretable.",2106.01613,cs.LG,2021-06-03 06:20:18+00:00,2021-12-14 20:23:47+00:00
gBpYGXH9J7F,2021,Reject,False,Online Learning under Adversarial Corruptions,"[""Pranjal Awasthi"", ""Sreenivas Gollapudi"", ""Kostas Kollias"", ""Apaar Sadhwani""]","[""Online Learning"", ""Learning Theory"", ""Bandits"", ""Robustness"", ""Adversarial Corruptions""]",We initiate a theoretical study and design near-optimal algorithms for online learning in stochastic environments with adversarially corrupted rewards.,,,,
gCmCiclZV6Q,2022,Reject,True,Inferring Offensiveness In Images From Natural Language Supervision,"['Patrick Schramowski', 'Kristian Kersting']",[],,2110.04222,cs.CV,2021-10-08 16:19:21+00:00,2021-10-08 16:19:21+00:00
gD0KBsQcGKg,2022,Reject,False,Distribution-Driven Disjoint Prediction Intervals for Deep Learning,"['Jaehak Cho', 'Jae Myung Kim', 'Sungyeob Han', 'Jungwoo Lee']","[""Uncertainty"", ""Prediction Interval"", ""Regression Uncertainty""]",We propose a novel distribution-driven method that generates a union of disjoint PIs.,,,,
gDHCPUvKRP,2021,Reject,False,Sparse Linear Networks with a Fixed Butterfly Structure: Theory and Practice,"[""Nir Ailon"", ""Omer Leibovitch"", ""Vineet Sreedharan Nair""]","[""Butterfly Network"", ""Matrix approximation"", ""Encoder-Decoder Network"", ""Optimization Landscape""]",Replacing a dense linear layer in any neural network with an architecture based on butterfly network.,,,,
gEZrGCozdqR,2022,Accept (Oral),False,Finetuned Language Models are Zero-Shot Learners,"['Jason Wei', 'Maarten Bosma', 'Vincent Zhao', 'Kelvin Guu', 'Adams Wei Yu', 'Brian Lester', 'Nan Du', 'Andrew M. Dai', 'Quoc V Le']","[""natural language processing"", ""zero-shot learning"", ""language models""]","""Instruction tuning"", which finetunes language models on a collection of tasks described via instructions, substantially boosts zero-shot performance on unseen tasks.",,,,
gEynpztqZug,2022,Reject,False,Mako: Semi-supervised continual learning with minimal labeled data via data programming,"['Pengyuan Lu', 'Seungwon Lee', 'Amanda Watson', 'David Kent', 'Insup Lee', 'ERIC EATON', 'James Weimer']","[""lifelong machine learning"", ""data programming"", ""semi-supervised learning""]","A tool mounted on top of supervised lifelong machine learning frameworks and enables semi-supervised learning, achieving very close performance to fully labeled data with only partially labeled is given.",,,,
gFDFKC4gHL4,2022,Accept (Poster),False,How Did the Model Change? Efficiently Assessing Machine Learning API Shifts ,"['Lingjiao Chen', 'Matei Zaharia', 'James Zou']","[""ML API performance shifts"", ""ML as a service"", ""ML monitoring"", ""ML performance evaluation""]",We systematically study real world ML APIs' performance shifts due to API updates/retraining and propose a framework to efficiently estimate those shifts.  ,,,,
gGDlZrfFq9d,2021,Reject,False,Learning Robust Models using the Principle of Independent Causal Mechanisms,"[""Jens M\u00fcller"", ""Robert Schmier"", ""Lynton Ardizzone"", ""Carsten Rother"", ""Ullrich Koethe""]","[""Causal Discovery"", ""Principle of Independent Causal Mechanisms"", ""Normalizing Flows"", ""Domain Generalization""]",A causal perspective on domain generalization turns distribution shift into an opportunity.,,,,
gHsr-v8Tz6l,2021,Reject,False,Variational Invariant Learning for Bayesian Domain Generalization,"[""Zehao Xiao"", ""Jiayi Shen"", ""Xiantong Zhen"", ""Ling Shao"", ""Cees G. M. Snoek""]","[""domain generalization"", ""variational invariant learning"", ""Bayesian inference""]","We propose variational invariant learning, a probabilistic inference framework that jointly models domain invariance and uncertainty for Bayesian domain generalization",2105.04030,cs.LG,2021-05-09 21:33:27+00:00,2021-07-14 23:45:59+00:00
gI7KCy4UDN9,2022,Reject,False,Post-Training Quantization Is All You Need to Perform Cross-Platform Learned Image Compression,"['Dailan He', 'Ziming Yang', 'Yan Wang', 'Yuan Chen', 'Qi Zhang', 'Hongwei Qin']",[],"We propose to solve cross-platform inconsistency issue of learned image compression by adopting integer-arithmetic-only post-training quantization, which makes the further development and practice of learned image compression more promising.",,,,
gI7feJ9yXPz,2022,Accept (Poster),False,High Probability Generalization Bounds for Minimax Problems with Fast Rates,"['Shaojie Li', 'Yong Liu']",[],,,,,
gICys3ITSmj,2022,Accept (Poster),False,Contrastive Learning is Just Meta-Learning,"['Renkun Ni', 'Manli Shu', 'Hossein Souri', 'Micah Goldblum', 'Tom Goldstein']","[""meta-learning"", ""contrastive learning"", ""self-supervised learning""]","We discuss the close relationship between contrastive learning and meta-learning, and we propose a meta-learning framework for self-supervised learning (SSL) along with meta-specific methods to improve contrastive learning performance for SSL.",,,,
gIHd-5X324,2021,Accept (Poster),False,Rethinking Soft Labels for Knowledge Distillation: A BiasâVariance Tradeoff Perspective,"[""Helong Zhou"", ""Liangchen Song"", ""Jiajie Chen"", ""Ye Zhou"", ""Guoli Wang"", ""Junsong Yuan"", ""Qian Zhang""]","[""Knowledge distillation"", ""soft labels"", ""teacher-student model""]","For knowledge distillation, we analyze the regularization effect introduced by soft labels from a bias-variance perspective and propose weighted soft labels to handle the tradeoff.",2102.00650,cs.LG,2021-02-01 05:53:04+00:00,2021-02-01 05:53:04+00:00
gJLEXy3ySpu,2022,Accept (Poster),True,Almost Tight L0-norm Certified Robustness of Top-k Predictions against Adversarial Perturbations,"['Jinyuan Jia', 'Binghui Wang', 'Xiaoyu Cao', 'Hongbin Liu', 'Neil Zhenqiang Gong']",[],"In this work, we derive the certified robustness against $\ell_0$-norm adversarial perturbation for top-$k$ prediction.",2011.07633,cs.CR,2020-11-15 21:34:44+00:00,2020-11-15 21:34:44+00:00
gJYlaqL8i8,2021,Accept (Poster),True,Learning to Sample with Local and Global Contexts  in Experience Replay Buffer,"[""Youngmin Oh"", ""Kimin Lee"", ""Jinwoo Shin"", ""Eunho Yang"", ""Sung Ju Hwang""]","[""reinforcement learning"", ""experience replay buffer"", ""off-policy RL""]",We propose a learning-based neural replay which calculates the relative importance to sample experience for off-policy RL.,2007.07358,cs.LG,2020-07-14 21:12:56+00:00,2021-04-07 15:10:58+00:00
gJcEM8sxHK,2022,Accept (Poster),False,Mapping Language Models to Grounded Conceptual Spaces,"['Roma Patel', 'Ellie Pavlick']",[],Mapping text-only pre-trained language models to grounded conceptual worlds.,,,,
gKLAAfiytI,2022,Accept (Poster),False,Equivariant Self-Supervised Learning: Encouraging Equivariance in Representations,"['Rumen Dangovski', 'Li Jing', 'Charlotte Loh', 'Seungwook Han', 'Akash Srivastava', 'Brian Cheung', 'Pulkit Agrawal', 'Marin Soljacic']","[""self-supervised learning"", ""contrastive learning"", ""photonics science""]",Imposing invariance to certain transformations (e.g. random resized cropping) and sensitivity to other transformations (e.g. four-fold rotations) learns better features.,,,,
gKWxifgJVP,2022,Reject,False,Fact-driven Logical Reasoning,"['Siru Ouyang', 'Zhuosheng Zhang', 'hai zhao']","[""logical reasoning"", ""machine reading comprehension"", ""language understanding""]",,,,,
gKprVaCyQmA,2022,Reject,False,There are free lunches,"['Zhuoran Xu', 'hao liu', 'bo dong']","[""No-Free-Lunch Theorems""]",,,,,
gLWj29369lW,2021,Accept (Poster),False,Interpreting Knowledge Graph Relation Representation from Word Embeddings,"[""Carl Allen"", ""Ivana Balazevic"", ""Timothy Hospedales""]","[""knowledge graphs"", ""word embedding"", ""representation learning""]",Interpreting the structure of knowledge graph relation representation using insight from word embeddings.,,,,
gLqnSGXVJ6l,2022,Reject,False,Neural Combinatorial Optimization with Reinforcement Learning : Solving theVehicle Routing Problem with Time Windows,"['Abdelhakim Abdellaoui', 'Issmail El Hallaoui', 'Loubna Benabbou']","[""rienforcement learning"", ""neural combinatorial optimization"", ""vehicle routing problem with time windows"", ""attention model""]",,,,,
gLtMe3vpfZa,2022,Reject,False,Accelerating Stochastic Simulation with Interactive Neural Processes,"['Dongxia Wu', 'Matteo Chinazzi', 'Alessandro Vespignani', 'Yian Ma', 'Rose Yu']","[""neural processes"", ""bayesian active learning"", ""stochastic process"", ""deep sequence model"", ""epidemic modeling""]",Bayesian active learning framework to speed up stochastic simulation of infectious diseases,,,,
gMRZ4wLqlkJ,2021,Reject,False,Few-Round Learning for Federated Learning,"[""Younghyun Park"", ""Dong-Jun Han"", ""Do-Yeon Kim"", ""Jun Seo"", ""Jaekyun Moon""]","[""Federated Learning""]",We propose a few-round learning approach for federated learning which enables to obtain a high-accuracy global model within only a few communication rounds between the server and the clients.,,,,
gNp54NxHUPJ,2022,Accept (Poster),False,Fast Regression for Structured Inputs,"['Raphael A Meyer', 'Cameron N Musco', 'Christopher P Musco', 'David Woodruff', 'Samson Zhou']","[""regression"", ""sublinear time algorithm"", ""structured input""]",,,,,
gPvB4pdu_Z,2022,Accept (Spotlight),False,Compositional Training for End-to-End Deep AUC Maximization,"['Zhuoning Yuan', 'Zhishuai Guo', 'Nitesh Chawla', 'Tianbao Yang']","[""Compositional Training"", ""Imbalanced Losses"", ""AUC optimization"", ""Deep Learning""]",We propose a novel end-to-end training framework with a provable stochastic algorithm for deep AUC maximization. ,,,,
gRCCdgpVZf,2022,Accept (Poster),False,Provable Adaptation across Multiway Domains via Representation Learning,"['Zhili Feng', 'Shaobo Han', 'Simon Shaolei Du']","[""Representation learning"", ""tensor"", ""statistical learning theory""]",,,,,
gRr_gt5bker,2021,Reject,False,Multi-Agent Imitation Learning with Copulas,"[""Hongwei Wang"", ""Lantao Yu"", ""Zhangjie Cao"", ""Stefano Ermon""]","[""multi-agent imitation learning"", ""dependence modeling"", ""copula""]","In this paper, we propose a new multi-agent imitation learning algorithm by using copula to explicitly model the rich dependency structure in multi-agent systems.",2107.04750,cs.LG,2021-07-10 03:49:41+00:00,2021-07-10 03:49:41+00:00
gSJTgko59MC,2021,Reject,True,Predicting the Outputs of Finite Networks Trained with Noisy Gradients,"[""Gadi Naveh"", ""Oded Ben-David"", ""Haim Sompolinsky"", ""Zohar Ringel""]","[""Gaussian process"", ""deep learning theory"", ""finite DNNs"", ""statistical mechanics""]",,2004.01190,stat.ML,2020-04-02 18:00:01+00:00,2021-09-30 07:19:27+00:00
gSdSJoenupI,2022,Accept (Poster),False,PolyLoss: A Polynomial Expansion Perspective of Classification Loss Functions,"['Zhaoqi Leng', 'Mingxing Tan', 'Chenxi Liu', 'Ekin Dogus Cubuk', 'Jay Shi', 'Shuyang Cheng', 'Dragomir Anguelov']","[""classification"", ""computer vision"", ""loss""]","In the PolyLoss framework, we propose a simple and effective Poly-1 formulation which outperforms the cross-entropy loss and focal loss on various of tasks.",,,,
gULyf2IVll0,2022,Reject,False,Empirical Study of the Decision Region and Robustness in Deep Neural Networks,"['Seongjin Park', 'Haedong Jeong', 'Giyoung Jeon', 'Jaesik Choi']","[""Decision Region"", ""Adversarial Robustness"", ""Deep Neural Networks""]",Empirical study to analyze the relationship between the decision regions and robustness under adversarial attack in Deep Neural Networks.,,,,
gV3wdEOGy_V,2021,Accept (Poster),False,MiCE: Mixture of Contrastive Experts for Unsupervised Image Clustering,"[""Tsung Wei Tsai"", ""Chongxuan Li"", ""Jun Zhu""]","[""unsupervised learning"", ""clustering"", ""self supervised learning"", ""mixture of experts""]",A principled probabilistic clustering method that exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model in a unified framework.,2105.01899,cs.LG,2021-05-05 07:17:57+00:00,2021-05-05 07:17:57+00:00
gVRhIEajG1k,2022,Accept (Poster),False,Rethinking Adversarial Transferability from a Data Distribution Perspective,"['Yao Zhu', 'Jiacheng Sun', 'Zhenguo Li']","[""Adversarial Attack"", ""Adversarial Transferability"", ""Black-box Attack""]","In this paper, we rethink adversarial transferability from a data distribution perspective and further enhance transferability by score matching based optimization. ",,,,
gW8n0uD6rl,2021,Reject,True,Amortized Causal Discovery: Learning to Infer Causal Graphs from Time-Series Data,"[""Sindy L\u00f6we"", ""David Madras"", ""Richard Zemel"", ""Max Welling""]",[],"We propose Amortized Causal Discovery, a framework for inferring causal relations from time series data across samples with different underlying causal graphs.",2006.10833,cs.LG,2020-06-18 19:59:12+00:00,2020-12-16 16:13:35+00:00
gWGexz8hFH,2022,Reject,False,Distributed Skellam Mechanism: a Novel Approach to Federated Learning with Differential Privacy,"['Ergute Bao', 'Yizheng Zhu', 'Xiaokui Xiao', 'Yin Yang', 'Beng Chin Ooi', 'Benjamin Hong Meng Tan', 'Khin Mi Mi Aung']","[""Differential Privacy"", ""Federated Learning"", ""Skellam Distribution"", ""Renyi Divergence""]","We propose a novel distributed Skellam mechanism (DSM) for enforcing differential privacy on models built through an MPC-based federated learning process, which demonstrates consistent and significant model utility advantages over existing methods.",,,,
gX9Ub6AwAd,2022,Reject,False,ANOMALY DETECTION WITH FRAME-GROUP ATTENTION IN SURVEILLANCE VIDEOS,"['Jinsheng Xiao', 'Haowen Guo', 'Yuanxu Wu', 'Yunhua Chen', 'Honggang Xie']","[""Anomaly detection"", ""attention mechanism"", ""frame-group"", ""spatial-temporal feature""]",The paper proposes an end-to-end abnormal behavior detection network to detect strenuous movements in slow moving crowds.,,,,
gYbimGJAENn,2021,Reject,False,Powers of layers for image-to-image translation,"[""Hugo Touvron"", ""Matthijs Douze"", ""Matthieu Cord"", ""Herve Jegou""]",[],,,,,
gZ2qq0oPvJR,2021,Reject,True,Towards Finding Longer Proofs,"[""Zsolt Zombori"", ""Adri\u00e1n Csisz\u00e1rik"", ""Henryk Michalewski"", ""Cezary Kaliszyk"", ""Josef Urban""]","[""automated reasoning"", ""reinforcement learning"", ""reasoning by analogy""]",FLoP is a theorem prover that uses RL based guidance to implement a simple form of analogical reasoning to overcome fundamental limitations of search based approaches.,1905.13100,cs.LO,2019-05-30 15:23:26+00:00,2021-06-29 14:15:58+00:00
gZ9hCDWe6ke,2021,Accept (Oral),True,Deformable DETR: Deformable Transformers for End-to-End Object Detection,"[""Xizhou Zhu"", ""Weijie Su"", ""Lewei Lu"", ""Bin Li"", ""Xiaogang Wang"", ""Jifeng Dai""]","[""Efficient Attention Mechanism"", ""Deformation Modeling"", ""Multi-scale Representation"", ""End-to-End Object Detection""]",Deformable DETR is an efficient and fast-converging end-to-end object detector. It mitigates the high complexity and slow convergence issues of DETR via a novel sampling-based efficient attention mechanism. ,2010.04159,cs.CV,2020-10-08 17:59:21+00:00,2021-03-18 03:14:26+00:00
gaYko_Y2_l,2022,Reject,False,Weakly Supervised Graph Clustering,"['Tian Bian', 'Tingyang Xu', 'Yu Rong', 'Wenbing Huang', 'Xi Xiao', 'Peilin Zhao', 'Junzhou Huang', 'Hong Cheng']",[],,,,,
gbe1zHyA73,2022,Accept (Poster),False,Constrained Physical-Statistics Models for Dynamical System Identification and Prediction,"['JÃ©rÃ©mie DONA', 'Marie DÃ©chelle', 'patrick gallinari', 'Marina Levy']","[""Deep Learning"", ""Hybrid Models"", ""Differential Equations""]",We propose to incorporate constraints in the learning of hybrid physical and data driven dynamical models.,,,,
gc8zLQWf2k,2022,Reject,True,Towards the Memorization Effect of Neural Networks in Adversarial Training,"['Han Xu', 'Xiaorui Liu', 'Wentao Wang', 'Wenbiao Ding', 'Zhongqin Wu', 'Zitao Liu', 'Anil Jain', 'Jiliang Tang']","[""Adversarial training"", ""Robustness"", ""Overfitting"", ""Neural networks""]",This paper uncovers several key findings about adversarial robustness generalization problems. ,2106.04794,cs.LG,2021-06-09 03:47:32+00:00,2021-06-09 03:47:32+00:00
gccdzDu5Ur,2022,Reject,False,Combining Diverse Feature Priors,"['Saachi Jain', 'Dimitris Tsipras', 'Aleksander Madry']","[""robustness"", ""spurious correlations"", ""feature priors""]",We explore how a diverse set of feature priors can be leveraged to improve model generalization.,,,,
gciJWCp3z1s,2022,Reject,True,On the Convergence of Projected Alternating Maximization for Equitable and Optimal Transport,"['Minhui Huang', 'Shiqian Ma', 'Lifeng Lai']","[""Equitable and Optimal Transport"", ""Fairness"", ""Saddle Point Problem"", ""Projected Alternating Maximization"", ""Block Coordinate Descent"", ""Acceleration"", ""Rounding""]",Convergence rate analysis for Equitable and Optimal Transport with Entropy regularization.,2109.15030,math.OC,2021-09-29 04:32:06+00:00,2021-10-01 01:00:36+00:00
gdWQMQVJST,2022,Reject,False,Neural Tangent Kernel Empowered Federated Learning,"['Kai Yue', 'Richeng Jin', 'Ryan Pilgrim', 'Chau-Wai Wong', 'Dror Baron', 'Huaiyu Dai']","[""Federated Learning"", ""Neural Tangent Kernel""]",,,,,
gdegUuC_fxR,2022,Reject,True,Hessian-Free High-Resolution Nesterov Acceleration for Sampling,"['Ruilin Li', 'Hongyuan Zha', 'Molei Tao']","[""Markov Chain Monte Carlo"", ""Nesterov Accelerated Gradient"", ""accelerated sampling""]","Like the finite stepsize difference between NAG for optimization and its continuous time limit, sampler based on kinetic Langevin can also be further accelerated.",2006.09230,cs.LG,2020-06-16 15:07:37+00:00,2021-04-26 20:15:51+00:00
gdtGg1hCK2,2021,Reject,True,On Low Rank Directed Acyclic Graphs and Causal Structure Learning,"[""Zhuangyan Fang"", ""Shengyu Zhu"", ""Jiji Zhang"", ""Yue Liu"", ""Zhitang Chen"", ""Yangbo He""]","[""causal discovery"", ""structure learning"", ""low rank graphs"", ""directed acyclic graphs""]",We study the potential of exploiting a low rank assumption on directed acyclic graphs to help learning large and dense causal structures.,2006.05691,cs.LG,2020-06-10 07:11:12+00:00,2020-06-10 07:11:12+00:00
gex-2G2bLdh,2022,Reject,False,Hinge Policy Optimization: Rethinking Policy Improvement and Reinterpreting PPO,"['Hsuan-Yu Yao', 'Ping-Chun Hsieh', 'Kuo-Hao Ho', 'Kai-Chun Hu', 'Liang Chun Ouyang', 'I-Chen Wu']","[""Reinforcement learning"", ""policy optimization"", ""hinge loss"", ""policy improvement"", ""PPO-clip""]","This paper proposes to rethink policy optimization and reinterpret the theory of PPO-clip through the lens of Hinge Policy Optimization (HPO), which casts policy improvement as a large-margin binary classification problem.",,,,
gf9buGzMCa,2022,Reject,False,Expressiveness of Neural Networks Having Width Equal or Below the Input Dimension,"['Hans-Peter Beise', 'Steve Dias Da Cruz']","[""Neural network approximation"", ""expressiveness of width bounded neural networks"", ""maximum principle""]",We prove some theoretical results for neural network functions having width equal or below the input dimension.,,,,
gfUPGPMxB7E,2022,Reject,False,Data Sharing without Rewards in Multi-Task Offline Reinforcement Learning,"['Tianhe Yu', 'Aviral Kumar', 'Yevgen Chebotar', 'Chelsea Finn', 'Sergey Levine', 'Karol Hausman']","[""offline reinforcement learning"", ""multi-task reinforcement learning""]",,,,,
gfwON7rAm4,2022,Accept (Poster),True,Global Convergence of Multi-Agent Policy Gradient in Markov Potential Games,"['Stefanos Leonardos', 'Will Overman', 'Ioannis Panageas', 'Georgios Piliouras']","[""Multi-agent Reinforcement Learning"", ""Markov Potential Games"", ""Policy Gradient""]",Convergence of policy gradient in a class of MDPs called Markov Potential Games in which cooperation is desired.,2106.01969,cs.LG,2021-06-03 16:17:46+00:00,2021-09-28 22:11:43+00:00
gfwfOskyzSx,2021,Reject,False,Redefining The Self-Normalization Property,"[""Zhaodong Chen"", ""Zhao WeiQin"", ""Lei Deng"", ""Guoqi Li"", ""Yuan Xie""]","[""Self-normalizing Neural Network"", ""Activation Function""]",We redefine the self-normalization property based on the statistical analysis of both forward and backward passes in deep neural networks and propose two novel activation functions that achieve competitive results on multiple benchmarks.,,,,
ggNgn8Fhr5Q,2021,Reject,False,Frequency Decomposition in Neural Processes,"[""Jens Petersen"", ""Paul F Jaeger"", ""Gregor Koehler"", ""David Zimmerer"", ""Fabian Isensee"", ""Klaus Maier-Hein""]",[],"We show that deterministic Neural Processes decompose signals into different frequency components, a behaviour that can be controlled to turn them into programmable band-pass or band-stop filters.",,,,
gggnCQBT_iE,2022,Reject,False,Connecting Data to Mechanisms with Meta Structual Causal Model,['Gong Heyang'],"[""meta-SCM"", ""cyclic causal models"", ""sufficient activated mechanisms""]",A meta-SCM framework for cyclic causal modeling and the sufficient activated mechanisms assumption.,,,,
ghKbryXRRAB,2021,Reject,False,Tracking the progress of Language Models by extracting their underlying Knowledge Graphs,"[""Carlos Aspillaga"", ""Marcelo Mendoza"", ""Alvaro Soto""]","[""Language Models"", ""NLP"", ""Knowledge Graphs"", ""Probe tasks"", ""Word2Vec"", ""GloVe"", ""ELMo"", ""BERT"", ""RoBERTa"", ""XLNet"", ""ALBERT"", ""T5"", ""GPT2""]",Knowledge Graph Extraction from models' embeddings,2105.13471,cs.AI,2021-05-27 22:19:19+00:00,2021-06-02 13:29:09+00:00
ghTlLwlBS-,2022,Reject,True,Feudal Reinforcement Learning by Reading Manuals,"['Kai Wang', 'Zhonghao Wang', 'Mo Yu', 'Humphrey Shi']","[""feudal reinforcement learning"", ""textual instruction following"", ""reading to act"", ""text games"", ""multi-hop reasoning""]","We propose a feudal reinforcement learning framework for the task of instruction following, which addresses the mismatch between high-level language descriptions and low-level perceptions.",2110.06477,cs.AI,2021-10-13 03:50:15+00:00,2021-10-13 03:50:15+00:00
ghjxvfgv9ht,2021,Reject,False,Self-Pretraining for Small Datasets by Exploiting Patch Information,"[""Zhang Chunyang""]","[""Learning with Small Datasets"", ""Self-Pretraining""]",Pretraining the model using patch information in the small dataset itself,,,,
gi4956J8g5,2022,Reject,False,Second-Order Unsupervised Feature Selection via Knowledge Contrastive Distillation,"['Han Yue', 'Jundong Li', 'Hongfu Liu']","[""Machine Learning"", ""Unsupervised Feature Selection"", ""Knowledge Distillation""]",,,,,
giBFoa-uS12,2022,Accept (Poster),False,Iterated Reasoning with Mutual Information in Cooperative and Byzantine Decentralized Teaming,"['Sachin G Konan', 'Esmaeil Seraj', 'Matthew Gombolay']","[""Multi-agent Reinforcement Learning"", ""Cooperation and Coordination"", ""Policy Gradient Optimization"", ""Mutual Information"", ""Iterated Reasoning""]",We propose a MARL framework with iterated and hierarchical rationalizability through mutual information for decision-making in fully-decentralized cooperative and Byzantine scenarios.,,,,
giit4HdDNa,2021,Accept (Poster),True,Go with the flow: Adaptive control for Neural ODEs,"[""Mathieu Chalvidal"", ""Matthew Ricci"", ""Rufin VanRullen"", ""Thomas Serre""]","[""Neural ODEs"", ""Optimal Control Theory"", ""Hypernetworks"", ""Normalizing flows""]",This paper presents a new method to enhance Neural ODEs representation power by dynamically controlling their weight parametrization.,2006.09545,cs.LG,2020-06-16 22:21:15+00:00,2021-04-15 10:03:12+00:00
gijKplIZ2Y-,2022,Reject,False,Mistill: Distilling Distributed Network Protocols from Examples,"['Patrick KrÃ¤mer', 'Johannes Zerwas', 'Andreas Blenk']","[""communication networks"", ""distributed protocols""]",,,,,
givsRXsOt9r,2022,Accept (Poster),False,Spherical Message Passing for 3D Molecular Graphs,"['Yi Liu', 'Limei Wang', 'Meng Liu', 'Yuchao Lin', 'Xuan Zhang', 'Bora Oztekin', 'Shuiwang Ji']",[],,,,,
gjNcH0hj0LM,2022,Accept (Poster),False,Coherence-based Label Propagation over Time Series for Accelerated Active Learning,"['Yooju Shin', 'Susik Yoon', 'Sundong Kim', 'Hwanjun Song', 'Jae-Gil Lee', 'Byung Suk Lee']","[""active learning"", ""time series"", ""pseudo labeling""]","We present a novel label propagation framework for time-series active learning, TCLP, that fully takes advantage of the temporal coherence inherent in time-series data.",,,,
gkOYZpeGEK,2021,Reject,False,Uniform Manifold Approximation with Two-phase Optimization,"[""Hyung-Kwon Ko"", ""Jaemin Jo"", ""Yung-Kyun Noh"", ""Jinwook Seo""]","[""Dimensionality Reduction"", ""Manifold Learning"", ""Visualization"", ""Topological Data Analysis"", ""UMAP""]","The proposal of a dimensionality reduction algorithm called Uniform Manifold Approximation with Two-phase Optimization (UMATO), which preserves the global as well as the local structures of high-dimensional data.",,,,
gl3D-xY7wLq,2021,Accept (Poster),False,Noise or Signal: The Role of Image Backgrounds in Object Recognition,"[""Kai Yuanqing Xiao"", ""Logan Engstrom"", ""Andrew Ilyas"", ""Aleksander Madry""]","[""Backgrounds"", ""Model Biases"", ""Robustness"", ""Computer Vision""]",We develop and use a toolkit to investigate modelsâ use of (and reliance on) image backgrounds.,,,,
gmxgG6_BL_N,2022,Reject,False,Variational Component Decoder for Source Extraction from Nonlinear Mixture,"['Shujie Zhang', 'Tianyue Zheng', 'Zhe Chen', 'Jun Luo', 'Sinno Pan']","[""Source Extraction"", ""Variational Inference"", ""Disentanglement""]","We propose a novel approach for high fidelity source extraction from nonlinear mixture, combining sequence-to-sequence translation with varitational inference.",,,,
gp5Uzbl-9C-,2021,Reject,False,Systematic Evaluation of Causal Discovery in Visual Model Based Reinforcement Learning,"[""Nan Rosemary Ke"", ""Aniket Rajiv Didolkar"", ""Sarthak Mittal"", ""Anirudh Goyal"", ""Guillaume Lajoie"", ""Stefan Bauer"", ""Danilo Jimenez Rezende"", ""Michael Curtis Mozer"", ""Yoshua Bengio"", ""Christopher Pal""]","[""causal induction"", ""model based RL""]",We systematically evaluate aspects of causal induction for visual model based RL.,,,,
gpp7cf0xdfN,2022,Accept (Poster),False,Reverse Engineering of Imperceptible Adversarial Image Perturbations,"['Yifan Gong', 'Yuguang Yao', 'Yize Li', 'Yimeng Zhang', 'Xiaoming Liu', 'Xue Lin', 'Sijia Liu']","[""Reverse Engineering of Deceptions"", ""adversarial examples"", ""denoising"", ""neural networks"", ""interpretability""]",Reverse engineer adversarial image perturbations with a denoiser-based framework.,,,,
gtvM-nBZEbc,2022,Reject,False,"Learning Visual-Linguistic Adequacy, Fidelity, and Fluency for Novel Object Captioning","['Cheng-Fu Yang', 'Yao-Hung Hubert Tsai', 'Wan-Cyuan Fan', 'Yu-Chiang Frank Wang', 'Louis-Philippe Morency', 'Ruslan Salakhutdinov']","[""Semi-supervised Image Captioning"", ""Novel Object Captioning""]",,,,,
gtwVBChN8td,2021,Reject,False,Deep Reinforcement Learning With Adaptive Combined Critics,"[""Huihui Zhang"", ""Wu Huang""]","[""overestimation"", ""continuous control"", ""deep reinforcement learning"", ""policy improvement""]",We propose a novel algorithm to tackle overestimation existing in deep reinforcement learning with  continuous control to avoild other problems and ensure policy improvement.,,,,
guEuB3FPcd,2021,Reject,True,AlgebraNets,"[""Jordan Hoffmann"", ""Simon Schmitt"", ""Simon Osindero"", ""Karen Simonyan"", ""Erich Elsen""]","[""Sparsity"", ""Pruning"", ""Efficiency"", ""Mathematics""]",We investigate a wide range of alternatives to real-valued weights in neural networks and find promising alternatives. ,2006.07360,cs.LG,2020-06-12 17:51:20+00:00,2020-06-16 16:10:13+00:00
guetrIHLFGI,2021,Accept (Poster),True,The Deep Bootstrap Framework: Good Online Learners are Good Offline Generalizers,"[""Preetum Nakkiran"", ""Behnam Neyshabur"", ""Hanie Sedghi""]","[""generalization"", ""optimization"", ""online learning"", ""understanding deep learning"", ""empirical investigation""]",We show empirical evidence that the performance gap between offline generalization and online optimization is small and propose an alternative framework for studying generalization.,2010.08127,cs.LG,2020-10-16 03:07:49+00:00,2021-02-19 03:24:24+00:00
gvxJzw8kW4b,2021,Accept (Oral),False,Co-Mixup: Saliency Guided Joint Mixup with Supermodular Diversity,"[""JangHyun Kim"", ""Wonho Choo"", ""Hosan Jeong"", ""Hyun Oh Song""]","[""Data Augmentation"", ""Deep Learning"", ""Supervised Learning"", ""Discrete Optimization""]",We propose a new perspective on joint mixup augmentation and formulate the optimal construction of a batch of mixup data.,,,,
gwFTuzxJW0,2021,Accept (Poster),False,Stochastic Security: Adversarial Defense Using Long-Run Dynamics of Energy-Based Models,"[""Mitch Hill"", ""Jonathan Craig Mitchell"", ""Song-Chun Zhu""]","[""adversarial defense"", ""adversarial robustness"", ""energy-based model"", ""Markov chain Monte Carlo"", ""Langevin sampling"", ""adversarial attack""]",Our defensive transformation using long-run MCMC sampling with a convergent EBM is the first method to successfully defend naturally-trained classifiers against adversarial attacks.,,,,
gwnoVHIES05,2021,Accept (Poster),False,Creative Sketch Generation,"[""Songwei Ge"", ""Vedanuj Goswami"", ""Larry Zitnick"", ""Devi Parikh""]","[""creativity"", ""sketches"", ""part-based"", ""GAN"", ""dataset"", ""generative art""]",We introduce two creative sketch datasets and DoodlerGAN -- a part-based GAN model that generates creative sketches.,,,,
gxRcqTbJpVW,2022,Reject,False,Structured Pruning Meets Orthogonality,"['Huan Wang', 'Yun Fu']","[""network pruning"", ""structured pruning"", ""dynamical isometry"", ""model compression""]","We propose a filter pruning method that drives the unimportant weights towards zero while maintaining dynamical isometry, which is easily scalable to ImageNet.",,,,
gxk4-rVATDA,2022,Reject,False,Bit-wise Training of Neural Network Weights,['Cristian Ivan'],"[""quantization"", ""pruning"", ""bit-wise training"", ""resnet"", ""lenet""]","We present an algorithm which allows training of a neural network's weights in a bit-wise fashion and show that 10% of the most significant bits contribute to the classification accuracy, while the rest can be random or used to store arbitrary codes.",,,,
gzeruP-0J29,2022,Reject,False,Revisiting and Advancing Fast Adversarial Training Through the lens of Bi-Level Optimization,"['Yihua Zhang', 'Guanhua Zhang', 'Prashant Khanduri', 'Mingyi Hong', 'Shiyu Chang', 'Sijia Liu']","[""fast adversarial training"", ""bi-level optimization"", ""adversarial robustness"", ""adversarial defense""]","In this paper, we introduce a novel bi-level optimization (BLO)-based fast adversarial training framework, termed FAST-BAT.",2112.12376,cs.LG,2021-12-23 06:25:36+00:00,2022-02-03 15:24:46+00:00
h-z_zqT2yJU,2022,Reject,False,Reducing the Teacher-Student Gap via Adaptive Temperatures,['Jia Guo'],"[""Soft Labels"", ""Knowledge distillation""]",The proposed method adapts temperatures during distillation to reduce the sharpness gap between the teacher and the student based on a sharpness metric.,,,,
h0OYV0We3oh,2022,Accept (Poster),True,Illiterate DALL$\cdot$E Learns to Compose,"['Gautam Singh', 'Fei Deng', 'Sungjin Ahn']","[""Zero-Shot Image Generation"", ""Compositional Representation"", ""Object-Centric Representation"", ""Out-of-Distribution Generalization"", ""Image Transformers""]",To learn compositional slot-based representation of an image and perform slot composition for zero-shot novel image generation.,2110.11405,cs.CV,2021-10-17 16:40:47+00:00,2021-10-27 18:46:24+00:00
h0de3QWtGG,2021,Accept (Poster),False,"Learning ""What-if"" Explanations for Sequential Decision-Making","[""Ioana Bica"", ""Daniel Jarrett"", ""Alihan H\u00fcy\u00fck"", ""Mihaela van der Schaar""]","[""counterfactuals"", ""explaining decision-making"", ""preference learning""]","We propose explaining sequential decision-making by integrating counterfactual reasoning into batch inverse reinforcement learning and recovering the preferences of experts over ""what-if"" outcomes.",,,,
h2EbJ4_wMVq,2021,Accept (Poster),False,CaPC Learning: Confidential and Private Collaborative Learning,"[""Christopher A. Choquette-Choo"", ""Natalie Dullerud"", ""Adam Dziedzic"", ""Yunxiang Zhang"", ""Somesh Jha"", ""Nicolas Papernot"", ""Xiao Wang""]","[""machine learning"", ""deep learning"", ""privacy"", ""confidentiality"", ""security"", ""homomorphic encryption"", ""mpc"", ""differential privacy""]",A method that enables parties to improve their own local heterogeneous machine learning models in a collaborative setting where both confidentiality and privacy need to be preserved to prevent both explicit and implicit sharing of private data.,2102.05188,cs.LG,2021-02-09 23:50:24+00:00,2021-03-19 19:31:05+00:00
h4EOymDV3vV,2022,Reject,False,Diffusion-Based Representation Learning,"['Korbinian Abstreiter', 'Stefan Bauer', 'Bernhard SchÃ¶lkopf', 'Arash Mehrjou']",[],Introducing a framework for representation learning in diffusion models,,,,
h8q8iZi-ks,2021,Reject,False,Conditional Networks,"[""Anthony Ortiz"", ""Kris Sankaran"", ""Olac Fuentes"", ""Christopher Kiekintveld"", ""Pascal Vincent"", ""Yoshua Bengio"", ""Doina Precup""]","[""Conditional Computation"", ""Generalization""]",We propose a framework for improving out of distribution (OOD) generalization by leveraging auxiliary data via conditional normalization.,,,,
h9XgC7JzyHZ,2021,Reject,False,Efficient estimates of optimal transport via low-dimensional embeddings,"[""Patric Fulop"", ""Vincent Danos""]","[""optimal transport"", ""sinkhorn divergences"", ""robustness"", ""neural networks"", ""lipschitz"", ""spectral norm""]",Approximating optimal transport distances using a low-dimensional space constructed through a general projection map that is 1-Lipschitz. ,,,,
hBxSksqPuOg,2021,Reject,False,Random Network Distillation as a Diversity Metric for Both Image and Text Generation,"[""Liam H Fowl"", ""Micah Goldblum"", ""Arjun Gupta"", ""Amr Sharaf"", ""Tom Goldstein""]","[""GAN"", ""NLP"", ""ImageNet"", ""generative"", ""diversity"", ""VAE"", ""CelebA"", ""language model""]","We present a novel, dataset agnostic framework for comparing diversity of generated data. ",,,,
hC474P6AqN-,2022,Reject,False,Unifying Categorical Models by Explicit Disentanglement of the Labels' Generative Factors,"['Luca Pinchetti', 'Lei Sha', 'Thomas Lukasiewicz']","[""Disentanglement"", ""explainability"", ""latent representation""]",,,,,
hE3JWimujG,2021,Reject,False,Cortico-cerebellar networks as decoupled neural interfaces,"[""Joseph Pemberton"", ""Ellen Boven"", ""Richard Apps"", ""Rui Ponte Costa""]","[""systems neuroscience"", ""cerebellum"", ""neocortex"", ""decoupled neural interfaces"", ""deep learning"", ""decorrelation"", ""inverse models"", ""forward models""]",We propose that cerebellar-cortical networks facilitate learning across the brain by solving the locking problems inherent to credit assignment.,2110.11501,q-bio.NC,2021-10-21 22:02:38+00:00,2021-10-28 12:57:34+00:00
hEiwVblq4P,2022,Reject,False,Proper Straight-Through Estimator: Breaking symmetry promotes convergence to true minimum,"['Shinya Gongyo', 'Kohta Ishikawa']","[""quantization"", ""binary network"", ""low bit network"", ""Straight through estimator"", ""STE""]",We discuss breaking symmetry embedded in the network by Straight through estimators enhances the possibility of convergence to the true minimum.,,,,
hGXij5rfiHw,2022,Accept (Poster),False,Discovering Invariant Rationales for Graph Neural Networks,"['Yingxin Wu', 'Xiang Wang', 'An Zhang', 'Xiangnan He', 'Tat-Seng Chua']","[""Interpretability"", ""Graph Neural Networks"", ""Causal Discovery"", ""Invariant Learning""]","We propose a novel invariant learning algorithm, Discovering Invariant Rationale (DIR), for intrinsically interpretable models.",,,,
hJk11f5yfy,2022,Reject,False,Encoding Hierarchical Information in Neural Networks Helps in Subpopulation Shift,"['Amitangshu Mukherjee', 'Isha Garg', 'Kaushik Roy']","[""Subpopulation shift"", ""Hierarchical"", ""Hierarchical Networks"", ""Conditional Training"", ""Domain Adaptation""]",The impact of subpopulation shift can be mitigated by encoding information about the hierarchical nature of classes via labels.,2112.10844,cs.CV,2021-12-20 20:26:26+00:00,2021-12-20 20:26:26+00:00
hJmtwocEqzc,2021,Accept (Poster),False,LowKey: Leveraging Adversarial Attacks to Protect Social Media Users from Facial Recognition,"[""Valeriia Cherepanova"", ""Micah Goldblum"", ""Harrison Foley"", ""Shiyuan Duan"", ""John P Dickerson"", ""Gavin Taylor"", ""Tom Goldstein""]","[""facial recognition"", ""adversarial attacks""]","We leverage adversarial attacks in our tool, LowKey, which protects social media users from invasive mass surveillance systems.",,,,
hKps4HGGGx,2021,Reject,False,Improving robustness of softmax corss-entropy loss via inference information,"[""Bingbing Song"", ""Wei He"", ""Renyang Liu"", ""Shui Yu"", ""Ruxin Wang"", ""Mingming Gong"", ""Tongliang Liu"", ""Wei Zhou""]","[""Adversarial defense"", ""Loss function"", ""Neural networks robustness""]","This paper design a novel loss function to improve robustness via inference information, and achieve better performance of robustness than state-of-the-art methods.",,,,
hLElJeJKxzY,2021,Reject,False,Deep Q Learning from Dynamic Demonstration with Behavioral Cloning,"[""Xiaoshuang Li"", ""Junchen Jin"", ""Xiao Wang"", ""Fei-Yue Wang""]",[],,,,,
hOaYDFpQk3g,2022,Reject,False,Taking ROCKET on an efficiency mission: A distributed solution for fast and accurate multivariate time series classification,"['Leonardos Pantiskas', 'Kees Verstoep', 'Mark Hoogendoorn', 'Henri Bal']","[""distribution"", ""time series"", ""classification"", ""multivariate"", ""wavelet"", ""scattering"", ""feature selection"", ""scaling""]","LightWaveS: A distributed solution for accurate multivariate time series classification, which is fast both during training and inference",,,,
hPWj1qduVw8,2021,Accept (Poster),False,Learning Reasoning Paths over Semantic Graphs for Video-grounded Dialogues,"[""Hung Le"", ""Nancy F. Chen"", ""Steven Hoi""]","[""video-grounded dialogues"", ""reasoning paths"", ""semantic graphs""]","We introduce PDC, a novel approach to learn reasoning paths over semantic graphs which are built upon dialogue context at each turn, for video-grounded dialogues. ",,,,
hRVZd5g-z7,2022,Reject,False,A Joint Subspace View to Convolutional Neural Networks,"['Ze Wang', 'Xiuyuan Cheng', 'Guillermo Sapiro', 'Qiang Qiu']",[],,,,,
hR_SMu8cxCV,2022,Accept (Spotlight),True,Scaling Laws for Neural Machine Translation,"['Behrooz Ghorbani', 'Orhan Firat', 'Markus Freitag', 'Ankur Bapna', 'Maxim Krikun', 'Xavier Garcia', 'Ciprian Chelba', 'Colin Cherry']","[""Scaling Laws"", ""Neural Machine Translation"", ""NMT"", ""Model Scaling""]",We provide (model) scaling laws for neural machine translation.,2109.07740,cs.LG,2021-09-16 06:15:20+00:00,2021-09-16 06:15:20+00:00
hSjxQ3B7GWq,2021,Accept (Poster),False,Sample-Efficient Automated Deep Reinforcement Learning,"[""J\u00f6rg K.H. Franke"", ""Gregor Koehler"", ""Andr\u00e9 Biedenkapp"", ""Frank Hutter""]","[""AutoRL"", ""Deep Reinforcement Learning"", ""Hyperparameter Optimization"", ""Neuroevolution""]",SEARL trains a population of off-policy RL agents while simultaneously optimizing the hyperparameters and the neural architecture sample-efficiently.,,,,
hSktDu-h94,2022,Accept (Poster),False,Automatic Loss Function Search for Predict-Then-Optimize Problems with Strong Ranking Property,"['Boshi Wang', 'Jialin Yi', 'Hang Dong', 'Bo Qiao', 'Chuan Luo', 'Qingwei Lin']",[],,,,,
hTUPgfEobsm,2021,Reject,False,ADIS-GAN: Affine Disentangled GAN,"[""Letao Liu"", ""Martin Saerbeck"", ""Justin Dauwels""]","[""Deep Learning"", ""Disentangled Representation"", ""Generative Adversarial Network"", ""Computer Vision""]",A Generative Adversarial Network that can explicitly disentangle affine transformations in a self-supervised and rigorous manner.  ,,,,
hUAmiQCeUGm,2021,Reject,False,Improving Tail Label Prediction for Extreme Multi-label Learning,"[""Tong Wei"", ""Wei-Wei Tu"", ""Yu-Feng Li""]","[""classification"", ""multi-label learning"", ""extreme multi-label classification"", ""tail label""]","We provide theoretical and experimental evidence for the inferior performance of many XML methods on tail labels, and two new modules are proposed to alleviate this problem.",,,,
hUr6K4D9f7P,2022,Reject,False,Adversarial Weight Perturbation Improves Generalization in Graph Neural Networks,"['Yihan Wu', 'Aleksandar Bojchevski', 'Heng Huang']","[""Graph neural networks"", ""Adversarial weight perturbation""]",,,,,
hW2kwAcXq5w,2022,Reject,False,Discriminator-Weighted Offline Imitation Learning from Suboptimal Demonstrations,"['Haoran Xu', 'Xianyuan Zhan', 'Honglei Yin', 'Huiling Qin']","[""imitation learning"", ""offline imitation learning""]",We propose a new imitation learning algorithm that can learn from suboptimal demonstrations without environment interactions or expert annotations.,,,,
hWr3e3r-oH5,2021,Accept (Poster),False,Cross-Attentional Audio-Visual Fusion for Weakly-Supervised Action Localization,"[""Jun-Tae Lee"", ""Mihir Jain"", ""Hyoungwoo Park"", ""Sungrack Yun""]","[""Audio-Visual"", ""Multimodal Attention"", ""Action localization"", ""Event localization"", ""Weak-supervision""]","An audio-visual fusion technique, called ""multi-stage cross-attention"", is developed to exploit the multi-modal representation in weakly-supervised action or event localization in untrimmed videos.",,,,
hb1sDDSLbV,2021,Accept (Poster),True,Learning explanations that are hard to vary,"[""Giambattista Parascandolo"", ""Alexander Neitz"", ""ANTONIO ORVIETO"", ""Luigi Gresele"", ""Bernhard Sch\u00f6lkopf""]","[""invariances"", ""consistency"", ""gradient alignment""]",,2009.00329,cs.LG,2020-09-01 10:17:48+00:00,2020-10-24 11:32:18+00:00
hbGV3vzMPzG,2022,Reject,False,On the Impact of Hard Adversarial Instances on Overfitting in Adversarial Training,"['Chen Liu', 'Zhichao Huang', 'Mathieu Salzmann', 'Tong Zhang', 'Sabine SÃ¼sstrunk']",[],Study adversarial overfitting from the perspective of training instances,2112.07324,cs.LG,2021-12-14 12:19:24+00:00,2021-12-14 12:19:24+00:00
hbzCPZEIUU,2021,Reject,False,Connecting Sphere Manifolds Hierarchically for Regularization,"[""Damien Scieur"", ""Youngsung Kim""]","[""Hierarchy"", ""Manifold"", ""Classification""]","Assuming we know a hierarchical structure over classes, we regularize the neural network by forcing the classifier of each class to belong to a sphere manifold, whose center is the classifier of its super-class.",2106.13549,cs.CV,2021-06-25 10:51:36+00:00,2021-06-25 10:51:36+00:00
hcCao_UYd6O,2021,Reject,False,Adversarial Feature Desensitization,"[""Pouya Bashivan"", ""Mojtaba Faramarzi"", ""Touraj Laleh"", ""Blake Aaron Richards"", ""Irina Rish""]","[""adversarial robustness"", ""adversarial learning"", ""convolutional neural networks""]",We propose a new way for learning adversarially robust features via an adversarial game between an embedding and discriminator function.,,,,
hcMvApxGSzZ,2022,Accept (Poster),False,"Fixed Neural Network Steganography: Train the images, not the network","['Varsha Kishore', 'Xiangyu Chen', 'Yan Wang', 'Boyi Li', 'Kilian Q Weinberger']",[],A novel method for steganography based on adversarial perturbations.,,,,
hcQHRHKfN_,2022,Accept (Poster),False,Continuously Discovering Novel Strategies via Reward-Switching Policy Optimization,"['Zihan Zhou', 'Wei Fu', 'Bingliang Zhang', 'Yi Wu']","[""diverse behavior"", ""deep reinforcement learning"", ""multi-agent reinforcement learning""]","We propose Reward-Switching Policy Optimization (RSPO), a paradigm to discover diverse strategies in complex RL environments by iteratively finding novel policies that are both locally optimal and sufficiently different from existing ones.",,,,
hcoswsDHNAW,2022,Accept (Poster),False,Fast AdvProp,"['Jieru Mei', 'Yucheng Han', 'Yutong Bai', 'Yixiao Zhang', 'Yingwei Li', 'Xianhang Li', 'Alan Yuille', 'Cihang Xie']","[""Adversarial examples"", ""efficient training"", ""generalization""]",,,,,
hdSn_X7Hfvz,2022,Reject,False,Deep Probability Estimation,"['Weicheng Zhu', 'Matan Leibovich', 'Sheng Liu', 'Sreyas Mohan', 'Aakash Kaku', 'Boyang Yu', 'Laure Zanna', 'Narges Razavian', 'Carlos Fernandez-Granda']","[""Probability estimation"", ""calibration"", ""uncertainty"", ""weather forecasting"", ""medical prognosis"", ""car crash"", ""benchmark datasets"", ""deep learning"", ""high dimensional data""]",We introduce new synthetic and real-world benchmark datasets for the task of probability estimation. We also propose a novel probability-estimation method which outperforms existing approaches on the above datasets.,,,,
heFdS9_tkzc,2021,Reject,True,Distantly Supervised Relation Extraction in Federated Settings,"[""Dianbo Sui"", ""Yubo Chen"", ""Kang Liu"", ""Jun Zhao""]","[""Distant Supervision"", ""Relation Extraction"", ""Federated Learning""]",We propose a federated denoising framework to suppress distantly supervised label noise in federated settings.,2008.05049,cs.CL,2020-08-12 00:58:39+00:00,2020-08-12 00:58:39+00:00
hecuSLbL_vC,2021,Reject,True,Generalisation Guarantees For Continual Learning With Orthogonal Gradient Descent,"[""Mehdi Abbana Bennani"", ""Thang Doan"", ""Masashi Sugiyama""]","[""Continual Learning"", ""Neural Tangent Kernel"", ""Optimisation""]","An NTK framework for Continual Learning, with robustness and generalisation guarantees for Orthogonal Gradient Descent.",2006.11942,stat.ML,2020-06-21 23:49:57+00:00,2020-12-04 09:23:18+00:00
heqv8eIweMY,2021,Reject,False,Non-Local Graph Neural Networks,"[""Meng Liu"", ""Zhengyang Wang"", ""Shuiwang Ji""]","[""Graph Neural Networks"", ""Non-Local Aggregation"", ""Attention"", ""Disassortative Graph""]",A simple yet effective non-local aggregator for capturing long-range information on disassortative graphs.,,,,
hfU7Ka5cfrC,2022,Accept (Spotlight),False,Scalable One-Pass Optimisation of High-Dimensional Weight-Update Hyperparameters by Implicit Differentiation,"['Ross M Clarke', 'Elre Talea Oldewage', 'JosÃ© Miguel HernÃ¡ndez-Lobato']","[""Hyperparameter Optimisation""]","We develop a gradient-based hyperparameter optimisation algorithm, applicable to a wide range of continuous hyperparameters, and scaling to large numbers of hyperparameters, without dramatically increasing training time from the non-HPO baseline.",,,,
hgKtwSb4S2,2022,Accept (Poster),False,A generalization of the randomized singular value decomposition,"['Nicolas Boulle', 'Alex Townsend']","[""Low rank approximation"", ""Randomized SVD"", ""Hilbert--Schmidt operators"", ""Gaussian processes""]",The randomized SVD is generalized to multivariate Gaussian input vectors and Hilbert-Schmidt operators.,,,,
hiq1rHO8pNT,2021,Accept (Poster),True,HyperGrid Transformers: Towards A Single Model for Multiple Tasks,"[""Yi Tay"", ""Zhe Zhao"", ""Dara Bahri"", ""Donald Metzler"", ""Da-Cheng Juan""]","[""Transformers"", ""Multi-Task Learning""]",State-of-the-art multi-task NLU performance with only a single model,2007.05891,cs.CL,2020-07-12 02:49:16+00:00,2020-07-12 02:49:16+00:00
hjd-kcpDpf2,2022,Accept (Poster),False,Maximizing Ensemble Diversity in Deep Reinforcement Learning,"['Hassam Sheikh', 'Mariano Phielipp', 'Ladislau Boloni']","[""Ensemble Based Reinforcement Learning"", ""Ensemble Diversity""]",Maximizing diversity in neural network improves performance ensemble based reinforcement learning,,,,
hjlXybdILM3,2022,Reject,False,When less is more: Simplifying inputs aids neural network understanding,"['Robin Tibor Schirrmeister', 'Rosanne Liu', 'Sara Hooker', 'Tonio Ball']","[""interpretability"", ""compression"", ""network training""]",Simplifying inputs to contain less bits can help understand deep neural network behavior.,2201.05610,cs.LG,2022-01-14 18:58:36+00:00,2022-02-01 13:15:00+00:00
hk3Cxc2laT-,2022,Reject,False,Clustered Task-Aware Meta-Learning by Learning from Learning Paths,"['Danni Peng', 'Sinno Pan']",[],,,,,
hkMoYYEkBoI,2021,Accept (Poster),True,Computational Separation Between Convolutional and Fully-Connected Networks,"[""eran malach"", ""Shai Shalev-Shwartz""]","[""Neural Networks"", ""Deep Learning"", ""Convolutional Networks"", ""Fully-Connected Networks"", ""Gradient Descent""]","We show a computational separation between convolutional and fully-connected networks, proving that the former can leverage strong local structure in the data.",2010.01369,cs.LG,2020-10-03 14:24:59+00:00,2020-10-03 14:24:59+00:00
hl9ePdHO4_s,2022,Accept (Poster),False,Adaptive Filters for Low-Latency and Memory-Efficient Graph Neural Networks,"['Shyam A. Tailor', 'Felix Opolka', 'Pietro Lio', 'Nicholas Donald Lane']","[""graph neural networks"", ""efficiency"", ""latency reduction"", ""memory reduction"", ""architecture design"", ""benchmarking"", ""hardware-aware""]","We find that using a simple adaptive filtering approach for GNNs improves performance over SOTA, while reducing model memory consumption and latency.",,,,
hm2tNDdgaFK,2022,Accept (Poster),True,Learning 3D Representations of Molecular Chirality with Invariance to Bond Rotations,"['Keir Adams', 'Lagnajit Pattanaik', 'Connor W. Coley']","[""geometric deep learning"", ""equivariance"", ""molecules""]",We propose a method of processing the 3D torsion angles of a molecular conformer to learn tetrahedral chirality while integrating a novel invariance to rotations about internal molecular bonds directly into the model architecture.,2110.04383,cs.LG,2021-10-08 21:25:47+00:00,2021-10-08 21:25:47+00:00
hniLRD_XCA,2022,Accept (Poster),False,DeSKO: Stability-Assured Robust Control with a Deep Stochastic Koopman Operator,"['Minghao Han', 'Jacob Euler-Rolle', 'Robert K. Katzschmann']","[""Koopman Operator"", ""Robust Control"", ""Robotics"", ""Model Predictive Control"", ""Soft Robotics""]",A robust learning control framework with guarantee stability based on deep stochastic Koopman operator models,,,,
hpBTIv2uy_E,2022,Accept (Poster),False,You are AllSet: A Multiset Function Framework for Hypergraph Neural Networks,"['Eli Chien', 'Chao Pan', 'Jianhao Peng', 'Olgica Milenkovic']","[""Hypergraph neural networks"", ""multiset functions"", ""deep sets"", ""set transformer""]",We propose a multiset function framework for hypergraph neural networks.,,,,
hpH98mK5Puk,2021,Accept (Poster),True,InfoBERT: Improving Robustness of Language Models from An Information Theoretic Perspective,"[""Boxin Wang"", ""Shuohang Wang"", ""Yu Cheng"", ""Zhe Gan"", ""Ruoxi Jia"", ""Bo Li"", ""Jingjing Liu""]","[""adversarial robustness"", ""information theory"", ""BERT"", ""adversarial training"", ""NLI"", ""QA""]","We propose a novel learning framework, InfoBERT, for robust fine-tuning of pre-trained language models from an information-theoretic perspective, and achieve state-of-the-art robust accuracy over several adversarial datasets on NLI and QA tasks.",2010.02329,cs.CL,2020-10-05 20:49:26+00:00,2021-03-22 11:44:30+00:00
hq7vLjZTJPk,2022,Reject,False,A Communication-Efficient Distributed Gradient Clipping Algorithm for Training Deep Neural Networks,"['Chunyang Liao', 'Zhenxun Zhuang', 'Mingrui Liu']","[""Distributed Training"", ""Federated Learning"", ""Gradient Clipping"", ""Communication-Efficient"", ""Optimization""]","This paper develops a communication-efficient distributed gradient clipping algorithm, which provably enjoys linear speedup for deep learning applications.",,,,
hqkN6lE1fFQ,2022,Reject,False,Kernel Deformed Exponential Families for Sparse Continuous Attention,"['Alexander Moreno', 'Supriya Nagesh', 'Zhenke Wu', 'Walter Dempsey', 'James Matthew Rehg']","[""kernel methods"", ""attention mechanism"", ""theory"", ""exponential families"", ""deformed exponential families""]",We introduce a new flexible non-parametric density class for use as a continuous attention mechanism and show novel theoretical existence and approximation results for this class.,,,,
hqkhcFHOeKD,2022,Accept (Poster),False,Learning Towards The Largest Margins,"['Xiong Zhou', 'Xianming Liu', 'Deming Zhai', 'Junjun Jiang', 'Xin Gao', 'Xiangyang Ji']","[""loss function design"", ""margin-based loss"", ""classification""]",,,,,
hr-3PMvDpil,2021,Accept (Poster),False,Efficient Certified Defenses Against Patch Attacks on Image Classifiers,"[""Jan Hendrik Metzen"", ""Maksym Yatsura""]","[""robustness"", ""certified defense"", ""adversarial patch"", ""aversarial examples""]",We propose a method for certifying robustness against adversarial patches that combines high certified accuracy with efficient inference while maintaining strong performance on clean data.,2102.04154,cs.LG,2021-02-08 12:11:41+00:00,2021-02-08 12:11:41+00:00
hsFN92eQEla,2021,Accept (Poster),True,EVALUATION OF NEURAL ARCHITECTURES TRAINED WITH SQUARE LOSS VS CROSS-ENTROPY IN CLASSIFICATION TASKS,"[""Like Hui"", ""Mikhail Belkin""]","[""large scale learning"", ""square loss vs cross-entropy"", ""classification"", ""experimental evaluation""]",An experimental evaluation of neural architectures in classification tasks shows that training with square loss produces better results than the cross-entropy in the majority of NLP and ASR experiments.,2006.07322,cs.LG,2020-06-12 17:00:49+00:00,2021-10-23 00:36:12+00:00
ht61oVsaya,2022,Reject,False,DESTA: A Framework for Safe Reinforcement Learning with Markov Games of Intervention,"['David Henry Mguni', 'Joel Jennings', 'Taher Jafferjee', 'Aivar Sootla', 'Changmin Yu', 'Usman Islam', 'Ziyan Wang', 'Yaodong Yang', 'Jun Wang']","[""Safe reinforcement learning"", ""safety"", ""Markov games"", ""stochastic games""]",,,,,
htWIlvDcY8,2022,Accept (Poster),False,"FALCON: Fast Visual Concept Learning by Integrating Images, Linguistic descriptions, and Conceptual Relations","['Lingjie Mei', 'Jiayuan Mao', 'Ziqi Wang', 'Chuang Gan', 'Joshua B. Tenenbaum']","[""Neuro-Symbolic Reasoning"", ""Concept Learning"", ""Meta-Learning""]",,,,,
hu2aMLzOxC,2021,Reject,False,Asymmetric self-play for automatic goal discovery in robotic manipulation,"[""OpenAI OpenAI"", ""Matthias Plappert"", ""Raul Sampedro"", ""Tao Xu"", ""Ilge Akkaya"", ""Vineet Kosaraju"", ""Peter Welinder"", ""Ruben D'Sa"", ""Arthur Petron"", ""Henrique Ponde de Oliveira Pinto"", ""Alex Paino"", ""Hyeonwoo Noh"", ""Lilian Weng"", ""Qiming Yuan"", ""Casey Chu"", ""Wojciech Zaremba""]","[""self-play"", ""asymmetric self-play"", ""automatic curriculum"", ""automatic goal generation"", ""robotic learning"", ""robotic manipulation"", ""reinforcement learning""]","We use asymmetric self-play to train a goal-conditioned policy for complex object manipulation tasks, and the learned policy can zero-shot generalize to many manually designed holdout tasks.",,,,
huXTh4GF2YD,2022,Reject,False,Distance-Based Background Class Regularization for Open-Set Recognition,"['Wonwoo Cho', 'Jaegul Choo']",[],,,,,
hvdKKV2yt7T,2021,Accept (Spotlight),False,Dataset Inference: Ownership Resolution in Machine Learning,"[""Pratyush Maini"", ""Mohammad Yaghini"", ""Nicolas Papernot""]","[""model ownership"", ""model extraction"", ""MLaaS""]",We introduce 'Dataset Inference' as a new method towards resolving model ownership.,,,,
hx0D7wn6qIy,2021,Reject,False,Semi-supervised learning by selective training with pseudo labels via confidence estimation,"[""Masato Ishii""]","[""semi-supervised learning"", ""confidence estimation""]",,2103.08193,cs.LG,2021-03-15 08:00:33+00:00,2021-03-15 08:00:33+00:00
hx1IXFHAw7R,2021,Accept (Poster),False,Provable Rich Observation Reinforcement Learning with Combinatorial Latent States,"[""Dipendra Misra"", ""Qinghua Liu"", ""Chi Jin"", ""John Langford""]","[""Reinforcement learning theory"", ""Rich observation"", ""Noise-contrastive learning"", ""State abstraction"", ""Factored MDP""]",We introduce a problem setup and a provable reinforcement learning algorithm for rich-observation problems with latent combinatorially large state space.,,,,
hxitw01k_Ql,2022,Reject,False,How memory architecture affects learning in a simple POMDP: the two-hypothesis testing problem,"['Mario Geiger', 'Christophe Eloy', 'Matthieu Wyart']","[""POMDP"", ""memory architecture"", ""optimization"", ""reinforcement learning""]",,,,,
hypDstHla7,2021,Reject,False,Neuron Activation Analysis for Multi-Joint Robot Reinforcement Learning,"[""Benedikt Feldotto"", ""Heiko Lengenfelder"", ""Alois Knoll""]","[""Reinforcement Learning"", ""Machine Learning"", ""Robot Motion Learning"", ""DQN"", ""Robot Manipulator"", ""Target Reaching"", ""Network Pruning""]","We analyze the neuron activation in neural networks trained for robot target reaching with Reinforcement Learning, prune the network and highlight correlations between networks trained for robots with different joint count.",,,,
hyuacPZQFb0,2022,Reject,False,A Systematic Evaluation of Domain Adaptation Algorithms On Time Series Data,"['Mohamed Ragab', 'Emadeldeen Eldele', 'Wee Ling Tan', 'Chuan-Sheng Foo', 'Zhenghua Chen', 'Min Wu', 'Chee Kwoh', 'Xiaoli Li']","[""domain adaptation"", ""time series data"", ""benchmarking""]","We systematically and fairly evaluate domain adaptation algorithms on time series data and find that algorithms developed for images perform well, and model selection is important.",,,,
hzkhOUll63,2021,Reject,False,Stability analysis of SGD through the normalized loss function,"[""Alexandre Lemire Paquin"", ""Brahim Chaib-draa"", ""Philippe Gigu\u00e8re""]","[""stability"", ""neural networks"", ""generalization bounds"", ""normalized loss""]",,,,,
hzmQ4wOnSb,2022,Accept (Poster),True,GNN is a Counter? Revisiting GNN for Question Answering,"['Kuan Wang', 'Yuyu Zhang', 'Diyi Yang', 'Le Song', 'Tao Qin']","[""GNN"", ""Question Answering"", ""QA"", ""Reasoning"", ""ML""]",Counting is essential for reasoning and our simplistic graph neural counter is efficient and effective for QA tasks.,2110.03192,cs.AI,2021-10-07 05:44:52+00:00,2021-10-07 05:44:52+00:00
i--G7mhB19P,2022,Reject,False,Depth Without the Magic: Inductive Bias of Natural Gradient Descent,"['Anna Kerekes', 'Anna MÃ©szÃ¡ros', 'Ferenc HuszÃ¡r']",[],,2111.11542,stat.ML,2021-11-22 21:20:10+00:00,2021-11-22 21:20:10+00:00
i1ogYhs0ByT,2022,Reject,False,Transformer with a Mixture of Gaussian Keys,"['Tam Minh Nguyen', 'Tan Minh Nguyen', 'Dung Duy Le', 'Nguyen Duy Khuong', 'Viet Anh TRAN', 'Richard Baraniuk', 'Nhat Ho', 'Stanley Osher']","[""transformer"", ""gaussian mixture model"", ""attention heads"", ""attention keys""]","We propose Transformer with a Mixture of Gaussian Keys (Transformer-MGK), a novel transformer architecture that replaces redundant heads in transformers with a mixture of keys at each head.",,,,
i2baoZMYZ3,2022,Reject,False,Continuous Control with Action Quantization from Demonstrations,"['Robert Dadashi', 'Leonard Hussenot', 'Damien Vincent', 'Sertan Girgin', 'Anton Raichuk', 'Matthieu Geist', 'Olivier Pietquin']","[""Deep Reinforcement Learning"", ""Action Discretization"", ""Learning from Demonstrations""]",,,,,
i3RI65sR7N,2022,Accept (Poster),False,Hierarchical Variational Memory for Few-shot Learning Across Domains,"['Yingjun Du', 'Xiantong Zhen', 'Ling Shao', 'Cees G. M. Snoek']","[""Meta-learning"", ""Variational hierarchical memory"", ""Variational hierarchical prototype"", ""Cross-domain few-shot learning""]",We propose a hierarchical memory that stores features at different semantic levels for the cross-domain few-shot learning.,2112.08181,cs.LG,2021-12-15 15:01:29+00:00,2021-12-15 15:01:29+00:00
i3Ui1Csrqpm,2021,Reject,True,"Optimizing Transformers with Approximate Computing for Faster, Smaller and more Accurate NLP Models","[""Amrit Nagarajan"", ""Sanchari Sen"", ""Jacob R. Stevens"", ""Anand Raghunathan""]","[""BERT"", ""Transformer"", ""NLP"", ""Efficient"", ""Faster"", ""Smaller"", ""Accurate""]","We develop a framework to create smaller, faster and more accurate NLP Models",2010.03688,cs.CL,2020-10-07 23:29:34+00:00,2020-10-07 23:29:34+00:00
i3abvoMoeCZ,2022,Reject,False,Exploring Covariate and Concept Shift for Detection and Confidence Calibration of Out-of-Distribution Data,"['Junjiao Tian', 'Yen-Chang Hsu', 'Yilin Shen', 'Hongxia Jin', 'Zsolt Kira']","[""out-of-distribution detection"", ""calibration"", ""distribution shift""]","We propose to analyze out-of-distribution detection and model calibration from the perspective of distribution shift, specifically covariate shift and concept shift.",,,,
i4qKmHdq6y8,2022,Reject,False,Learning to Abstain in the Presence of Uninformative Data,"['Yikai Zhang', 'Songzhu Zheng', 'Pengxiang Wu', 'Yuriy Nevmyvaka', 'Chao Chen']","[""Selective learning"", ""Uninformative data"", ""PAC Learning"", ""Sample Complexity""]",We study a natural noisy generative process which models the problem where a significant proportion of data are purely random. ,,,,
i7FNvHnPvPc,2022,Reject,False,Boosting the Transferability of Adversarial Attacks with Reverse Adversarial Perturbation,"['Zeyu Qin', 'Yanbo Fan', 'Yi Liu', 'Yong Zhang', 'Jue Wang', 'Baoyuan Wu']","[""Adversarial Examples"", ""Black-Box Attacks"", ""Adversarial Transferability""]",,,,,
i7O3VGpb7qZ,2022,Reject,False,Code Editing from Few Exemplars by Adaptive Multi-Extent Composition,"['Peizhao Li', 'Xuchao Zhang', 'Ziyu Yao', 'Wei Cheng', 'Haifeng Chen', 'Hongfu Liu']","[""code editing"", ""few-shot learning"", ""compositional generalization""]",This paper proposes a learning method to edit a code snippet following the editorial style from few examples.,,,,
i7aDkDEXJQU,2021,Reject,False,Demystifying Learning of Unsupervised Neural Machine Translation,"[""Guanlin Li"", ""lemao liu"", ""Taro Watanabe"", ""Conghui Zhu"", ""Tiejun Zhao""]","[""Unsupervised Neural Machine Translation"", ""Marginal Likelihood Maximization"", ""Mutual Information""]",Try to demystify why dae+bt training can lead to successfully trained UNMT model with decent performance.,,,,
i7aMbliTkHs,2021,Reject,False,TAM: Temporal Adaptive Module for Video Recognition,"[""Zhaoyang Liu"", ""Limin Wang"", ""Wayne Wu"", ""Chen Qian"", ""Tong Lu""]","[""Action Recognition"", ""Temporal Adaptive Module"", ""Temporal Adaptive Network""]","As the video data has extremely complex dynamics along its temporal dimension, we thus propose a temporal adaptive module decoupled by a location sensitive map and a location invariant weight to capture the temporal clues in a dynamic scheme.",,,,
i7h4M45tU8,2022,Reject,False,Neural Temporal Logic Programming,"['Karan Samel', 'Zelin Zhao', 'Binghong Chen', 'Shuang Li', 'Dharmashankar Subramanian', 'Irfan Essa', 'Le Song']","[""logic programming"", ""time series"", ""neuro-symbolic"", ""video"", ""healthcare""]",We propose a framework to learn temporal logic rules over noisy time series data.,2202.05403,cs.LG,2022-02-11 01:29:02+00:00,2022-02-11 01:29:02+00:00
i80OPhOCVH2,2021,Accept (Poster),True,On the Bottleneck of Graph Neural Networks and its Practical Implications,"[""Uri Alon"", ""Eran Yahav""]","[""graphs"", ""GNNs"", ""limitations"", ""understanding"", ""bottleneck"", ""over-squashing""]","A novel observation on GNN limitations: in long-range problems, a computational bottleneck causes over-squashing of information.",2006.05205,cs.LG,2020-06-09 12:04:50+00:00,2021-03-09 11:53:06+00:00
i8d2kdxii1L,2022,Reject,False,$p$-Laplacian Based Graph Neural Networks,"['Guoji Fu', 'Peilin Zhao', 'Yatao Bian']","[""Graph neural networks"", ""$p$-Laplacian"", ""semi-supervised learning"", ""node prediction""]",We propose a novel $p$-Laplacian based message passing scheme and GNN architecture to address the problem of generalizing GNNs to heterophilic graphs and graphs with noisy edges.,,,,
iAX0l6Cz8ub,2021,Accept (Oral),False,Geometry-aware Instance-reweighted Adversarial Training,"[""Jingfeng Zhang"", ""Jianing Zhu"", ""Gang Niu"", ""Bo Han"", ""Masashi Sugiyama"", ""Mohan Kankanhalli""]","[""Adversarial robustness""]","This paper has proposed a novel adversarial training method, i.e., geometry-aware instance-reweighted adversarial training (GAIRAT), which sheds new lights on improving the adversarial training.",,,,
iAmZUo0DxC0,2021,Accept (Spotlight),False,Unlearnable Examples: Making Personal Data Unexploitable,"[""Hanxun Huang"", ""Xingjun Ma"", ""Sarah Monazam Erfani"", ""James Bailey"", ""Yisen Wang""]","[""Unlearnable Examples"", ""Data Protection"", ""Adversarial Machine Learning""]",We present a type of error-minimizing noise that can make training examples unlearnable to deep learning.,2101.04898,cs.LG,2021-01-13 06:15:56+00:00,2021-02-24 22:53:31+00:00
iC4UHbQ01Mp,2022,Accept (Oral),False,Poisoning and Backdooring Contrastive Learning,"['Nicholas Carlini', 'Andreas Terzis']","[""Contrastive Learning"", ""Poisoning attack"", ""Backdoor attack"", ""CLIP""]","We argue poisoning and backdooring attacks are a serious threat to multimodal contrastive classifiers, because they are explicitly designed to be trained on uncurated datasets from the Internet.",,,,
iEcqwosBEgx,2021,Reject,True,Novel Policy Seeking with Constrained Optimization,"[""Hao Sun"", ""Zhenghao Peng"", ""Bo Dai"", ""Jian Guo"", ""Dahua Lin"", ""Bolei Zhou""]","[""Novel Policy Seeking"", ""Reinforcement Learning"", ""Constrained Optimization""]",We address the problem of seeking novel policies in reinforcement learning tasks with constrained optimization to generate well-performed diverse policies.,2005.10696,cs.LG,2020-05-21 14:39:14+00:00,2021-07-05 07:18:38+00:00
iEvAf8i6JjO,2022,Accept (Spotlight),False,TRGP: Trust Region Gradient Projection for Continual Learning,"['Sen Lin', 'Li Yang', 'Deliang Fan', 'Junshan Zhang']","[""trust region"", ""gradient projection"", ""scaled weight projection"", ""continual learning"", ""forward knowledge transfer"", ""task correlation""]","We propose a novel continual learning approach to facilitate the forward knowledge transfer, based on an efficient characterization of task correlation using a novel notion of 'trust region'.",2202.02931,cs.LG,2022-02-07 04:21:54+00:00,2022-02-07 04:21:54+00:00
iEx3PiooLy,2022,Accept (Poster),False,VAT-Mart: Learning Visual Action Trajectory Proposals for Manipulating 3D ARTiculated Objects,"['Ruihai Wu', 'Yan Zhao', 'Kaichun Mo', 'Zizheng Guo', 'Yian Wang', 'Tianhao Wu', 'Qingnan Fan', 'Xuelin Chen', 'Leonidas Guibas', 'Hao Dong']","[""Visual Representation Learning for Robotics"", ""Robotic Affordance and Trajectories"", ""3D Shape Understanding""]",We propose a novel interaction-for-perception framework to learn visual actionable representations (i.e. affordance and action trajectory proposals) for robotic manipulation.,,,,
iFf26yMjRdN,2022,Reject,False,Federated Learning with Partial Model Personalization,"['Krishna Pillutla', 'Kshitiz Malik', 'Abdelrahman Mohamed', 'Michael Rabbat', 'Maziar Sanjabi', 'Lin Xiao']","[""personalization"", ""federated learning"", ""partial personalization"", ""adapter modules"", ""nonconvex minimization""]",We personalize a part of the model for federated learning and find that it gives most of the benefits of full personalization and that an alternating optimization algorithm works the best.,,,,
iG_Cg6ONjX,2021,Reject,False,A General Computational Framework to Measure the Expressiveness of Complex Networks using a Tight Upper Bound of Linear Regions,"[""Yutong Xie"", ""Gaoxiang Chen"", ""Quanzheng Li""]",[],,2012.04428,cs.LG,2020-12-08 14:01:20+00:00,2020-12-08 14:01:20+00:00
iGffRQ9jQpQ,2022,Reject,False,Enhancing semi-supervised learning via self-interested coalitional learning,"['Huiling Qin', 'Xianyuan Zhan', 'Yuanxun li', 'Haoran Xu', 'yu zheng']","[""self-interested coalitional learning"", ""semi-supervised learning"", ""soft labeling"", ""loss reweighting""]",Enhancing semi-supervised learning via self-interested coalitional learning,,,,
iKQAk8a2kM0,2021,Accept (Poster),False,Targeted Attack against Deep Neural Networks via Flipping Limited Weight Bits,"[""Jiawang Bai"", ""Baoyuan Wu"", ""Yong Zhang"", ""Yiming Li"", ""Zhifeng Li"", ""Shu-Tao Xia""]","[""targeted attack"", ""bit-flip"", ""weight attack""]",We propose a targeted attack method against the deployed DNN via flipping a few binary weight bits.,2102.10496,cs.LG,2021-02-21 03:13:27+00:00,2021-02-21 03:13:27+00:00
iKXWZru0DS,2021,Reject,False,Attention-driven Robotic Manipulation,"[""Stephen James"", ""Andrew Davison""]","[""Robotics"", ""Robot Manipulation"", ""Reinforcement Learning""]",Attention-driven Robotic Manipulation (ARM) algorithm that succeeds on complex sparsely-rewarded tasks where other methods catastrophically fail,,,,
iLHOIDsPv1P,2022,Accept (Spotlight),False,PAC-Bayes Information Bottleneck,"['Zifeng Wang', 'Shao-Lun Huang', 'Ercan Engin Kuruoglu', 'Jimeng Sun', 'Xi Chen', 'Yefeng Zheng']","[""information bottleneck"", ""representation learning"", ""generalization""]",We propose a novel PAC-Bayes bound guided information bottleneck for understanding and enhancing deep representation learning.,,,,
iMH1e5k7n3L,2022,Accept (Spotlight),True,Spike-inspired rank coding for fast and accurate recurrent neural networks,"['Alan Jeffares', 'Qinghai Guo', 'Pontus Stenetorp', 'Timoleon Moraitis']",[],"Learning to infer fast in LSTMs inspired by SNNs, and applied in speech recognition",2110.02865,cs.NE,2021-10-06 15:51:38+00:00,2022-01-31 12:25:13+00:00
iMKvxHlrZb3,2021,Reject,False,Scalable Graph Neural Networks for Heterogeneous Graphs,"[""Lingfan Yu"", ""Jiajun Shen"", ""Jinyang Li"", ""Adam Lerer""]","[""Graph Neural Networks"", ""Large Graphs"", ""Heterogeneous Graphs""]",,2011.09679,cs.LG,2020-11-19 06:03:35+00:00,2020-11-19 06:03:35+00:00
iMSjopcOn0p,2022,Accept (Spotlight),False,MT3: Multi-Task Multitrack Music Transcription,"['Joshua P Gardner', 'Ian Simon', 'Ethan Manilow', 'Curtis Hawthorne', 'Jesse Engel']","[""music transcription"", ""transformer"", ""multi-task learning"", ""low resource learning"", ""music understanding"", ""music information retrieval""]","Unified framework for music transcription, jointly training a single model on six multi-instrument datasets and establishing a new SOTA for low-resource music transcription.",,,,
iMqTLyfwnOO,2022,Accept (Poster),True,Augmented Sliced Wasserstein Distances,"['Xiongjie Chen', 'Yongxin Yang', 'Yunpeng Li']",[],,2006.08812,cs.LG,2020-06-15 23:00:08+00:00,2021-10-11 21:00:54+00:00
iOnhIy-a-0n,2021,Accept (Poster),False,Accelerating Convergence of Replica Exchange Stochastic Gradient MCMC via Variance Reduction,"[""Wei Deng"", ""Qi Feng"", ""Georgios P. Karagiannis"", ""Guang Lin"", ""Faming Liang""]","[""variance reduction"", ""replica exchange"", ""parallel tempering"", ""stochastic gradient Langevin dynamics"", ""uncertainty quantification"", ""change of measure"", ""generalized Girsanov theorem"", ""Dirichlet form"", ""Markov jump process""]",We propose a variance-reduced replica-exchange stochastic gradient Langevin dynamics to reduce the variance of the energy estimators to accelerate the convergence.,,,,
iPHLcmtietq,2022,Accept (Poster),True,Phase Collapse in Neural Networks,"['Florentin Guth', 'John Zarka', 'StÃ©phane Mallat']","[""phase collapse"", ""neural collapse"", ""concentration"", ""classification"", ""imagenet"", ""deep networks"", ""complex networks"", ""sparsity in deep networks""]",The classification accuracy of CNNs mostly relies on the mechanism of phase collapses to eliminate spatial variability and linearly separate class means.,2110.05283,cs.LG,2021-10-11 13:58:01+00:00,2021-10-11 13:58:01+00:00
iQQK02mxVIT,2021,Accept (Poster),True,Why resampling outperforms reweighting for correcting sampling bias with stochastic gradients,"[""Jing An"", ""Lexing Ying"", ""Yuhua Zhu""]","[""biased sampling"", ""reweighting"", ""resampling"", ""stability"", ""stochastic asymptotics""]",We explain why resampling outperforms reweighting for correcting sampling bias when stochastic gradient algorithms are used.,2009.13447,cs.LG,2020-09-28 16:12:38+00:00,2021-08-27 16:28:01+00:00
iQxS0S9ir1a,2021,Reject,False,Distributional Generalization: A New Kind of Generalization,"[""Preetum Nakkiran"", ""Yamini Bansal""]","[""understanding deep learning"", ""generalization"", ""interpolating methods"", ""empirical investigation""]","We introduce a new notion of generalization (""Distributional Generalization""), to characterize empirical observations of interpolating classifiers.",,,,
iRCUlgmdfHJ,2022,Accept (Oral),False,DISCOVERING AND EXPLAINING THE REPRESENTATION BOTTLENECK OF DNNS,"['Huiqi Deng', 'Qihan Ren', 'Hao Zhang', 'Quanshi Zhang']","[""representation bottleneck"", ""representation ability"", ""interaction"", ""explanation""]",,2111.06236,cs.LG,2021-11-11 14:35:20+00:00,2022-01-30 08:17:49+00:00
iTeUSEw5rl2,2021,Reject,False,Online Continual Learning  Under  Domain Shift,"[""Quang Pham"", ""Chenghao Liu"", ""Steven HOI""]","[""Continual Learning"", ""Domain Generalization""]",,,,,
iUTHidd-ylL,2021,Reject,False,Matrix Data Deep Decoder - Geometric Learning for Structured Data Completion,"[""Maria Schmidt"", ""Alexander Bronstein""]","[""Deep learning"", ""Non-Euclidean data completion"", ""Sparse matrices"", ""Recommender systems"", ""Recommendation systems"", ""Sparse representations""]",Non-Euclidean Data Matrix Completion with end-to-end fully convolutional graph neural network based on Deep Image Prior Generalization  ,,,,
iUuzzTMUw9K,2022,Accept (Poster),True,StyleNeRF: A Style-based 3D Aware Generator for High-resolution Image Synthesis,"['Jiatao Gu', 'Lingjie Liu', 'Peng Wang', 'Christian Theobalt']","[""Neural Radiance Field"", ""StyleGAN"", ""high resolution image generation""]","We present StyleNeRF, a 3D-aware generative model that can synthesize high-resolution images with high multi-view consistency.",2110.08985,cs.CV,2021-10-18 02:37:01+00:00,2021-10-18 02:37:01+00:00
iVaPuvROtMm,2021,Reject,False,Learning Stochastic Behaviour from Aggregate Data,"[""Shaojun Ma"", ""Shu Liu"", ""Hongyuan Zha"", ""Hao-Min Zhou""]","[""Fokker Planck Equation"", ""weak form"", ""Wasserstein GAN""]",Develop a weak form of Fokker Planck Equation and WGAN model to recover hidden dynamics of aggregate data.,,,,
iWLByfvUhN,2021,Accept (Poster),False,Decoupling Global and Local Representations via Invertible Generative Flows,"[""Xuezhe Ma"", ""Xiang Kong"", ""Shanghang Zhang"", ""Eduard H Hovy""]","[""Generative Models"", ""Generative Flow"", ""Normalizing Flow"", ""Image Generation"", ""Representation Learning""]",Generative Flow for Decoupled Representation Learning,,,,
iaO86DUuKi,2021,Accept (Poster),True,Conservative Safety Critics for Exploration,"[""Homanga Bharadhwaj"", ""Aviral Kumar"", ""Nicholas Rhinehart"", ""Sergey Levine"", ""Florian Shkurti"", ""Animesh Garg""]","[""Safe exploration"", ""Reinforcement Learning""]",Safe exploration in reinforcement learning can be achieved by constraining policy learning with conservative safety estimates of the environment.,2010.14497,cs.LG,2020-10-27 17:54:25+00:00,2021-04-26 17:38:23+00:00
iaqgio-pOv,2022,Reject,False,Analogies and Feature Attributions for Model Agnostic Explanation of Similarity Learners,"['Karthikeyan Natesan Ramamurthy', 'Amit Dhurandhar', 'Dennis Wei', 'Zaid Bin Tariq']",[],Model agnostic local explanations for black-box similarity models using feature attributions as well as identifying diverse analogous pairs of examples.,,,,
iaxWbVx-CG_,2022,Reject,False,Hierarchical Cross Contrastive Learning of Visual Representations,"['Hesen Chen', 'Ming Lin', 'Xiuyu Sun', 'Rong Jin']","[""Self-supervised Learning"", ""Unsupervised Learning"", ""Computer Vision""]",We propose a hierarchical cross contrastive learning to further distill the information from the projection head and outperform most previous methods in various benchmark datasets.,,,,
ibNr25jJrf,2022,Reject,False,Direct Evolutionary Optimization of Variational Autoencoders With Binary Latents,"['Enrico Guiraud', 'Jakob Drefs', 'Filippos S Panagiotou', 'Jorg Lucke']","[""variational optimization"", ""variational autoencoders"", ""denoising"", ""inpainting"", ""evolutionary algorithms""]",,,,,
ibqTBNfJmi,2022,Accept (Poster),True,Frequency-aware SGD for Efficient Embedding Learning with Provable Benefits,"['Yan Li', 'Dhruv Choudhary', 'Xiaohan Wei', 'Baichuan Yuan', 'Bhargav Bhushanam', 'Tuo Zhao', 'Guanghui Lan']",[],,2110.04844,cs.LG,2021-10-10 16:17:43+00:00,2021-11-23 18:32:10+00:00
ibrUkC-pbis,2022,Accept (Poster),False,Neural Models for Output-Space Invariance in Combinatorial Problems,"['Yatin Nandwani', 'Vidit Jain', 'Mausam .', 'Parag Singla']","[""neural reasoning"", ""output space invariance""]","We design GNN based neural models to achieve output space invariance in combinatorial problems, e.g. solving 16 x 16 sudoku after training on 9 x 9 sudoku",,,,
ieNJYujcGDO,2022,Accept (Spotlight),False,Towards Understanding the Data Dependency of Mixup-style Training,"['Muthu Chidambaram', 'Xiang Wang', 'Yuzheng Hu', 'Chenwei Wu', 'Rong Ge']","[""mixup"", ""deep learning"", ""semi-supervised learning"", ""empirical risk minimization"", ""generalization"", ""margin"", ""counterexample""]","A theoretical analysis of data conditions under which mixup can perform worse, better, and identically when compared to empirical risk minimization.",,,,
iedYJm92o0a,2022,Reject,False,Show Your Work: Scratchpads for Intermediate Computation with Language Models,"['Maxwell Nye', 'Anders Johan Andreassen', 'Guy Gur-Ari', 'Henryk Michalewski', 'Jacob Austin', 'David Bieber', 'David Dohan', 'Aitor Lewkowycz', 'Maarten Bosma', 'David Luan', 'Charles Sutton', 'Augustus Odena']","[""program synthesis"", ""transformers"", ""language models"", ""pre-training"", ""program induction""]",We train very large pre-trained language models to execute algorithms and Python programs by predicting the intermediate states line-by-line.,2112.00114,cs.LG,2021-11-30 21:32:46+00:00,2021-11-30 21:32:46+00:00
igkmo23BgzB,2021,Reject,False,End-to-end Quantized Training via Log-Barrier Extensions,"[""Juncheng B Li"", ""Shuhui Qu"", ""Xinjian Li"", ""Emma Strubell"", ""Florian Metze""]","[""Quantization"", ""Constrained Optimization"", ""Mu-law"", ""8-bit training""]",fully 8-bit quantized training using log-barrier constrain and MU8(8-bit) encoding,,,,
iim-R8xu0TG,2022,Reject,False,FitVid: High-Capacity Pixel-Level Video Prediction,"['Mohammad Babaeizadeh', 'Mohammad Taghi Saffar', 'Suraj Nair', 'Sergey Levine', 'Chelsea Finn', 'Dumitru Erhan']","[""video prediction"", ""self supervised learning"", ""unsupervised learning"", ""robotics""]",A video prediction model which fits the current video prediction benchmarks so well that it begins to suffer from overfitting.,,,,
ijJZbomCJIm,2021,Accept (Poster),True,Adversarially-Trained Deep Nets Transfer Better: Illustration on Image Classification,"[""Francisco Utrera"", ""Evan Kravitz"", ""N. Benjamin Erichson"", ""Rajiv Khanna"", ""Michael W. Mahoney""]","[""transfer learning"", ""adversarial training"", ""influence functions"", ""limited data""]","We demonstrate that adversarially-trained models transfer better to new domains than naturally-trained models, especially when only limited training data is available in the target domain. ",2007.05869,cs.LG,2020-07-11 22:48:42+00:00,2021-04-24 03:21:05+00:00
ijVgDcvLmZ,2021,Reject,False,FSV: Learning to Factorize Soft Value Function for Cooperative Multi-Agent Reinforcement Learning,"[""Yueheng Li"", ""Tianhao Zhang"", ""Chen Wang"", ""Jinan Sun"", ""Shikun Zhang"", ""Guangming Xie""]","[""cooperative MARL"", ""value function factorization"", ""stochastic policy"", ""continuous tasks""]","We propose a novel stochastic-based policy solution in CTDE for cooperative MARL by factorizing the soft value function, which significantly outperforms existing factorization MARL methods in discrete and continuous tasks.",,,,
ijygjHyhcFp,2022,Reject,True,Anarchic Federated Learning,"['Haibo Yang', 'Xin Zhang', 'Prashant Khanduri', 'Jia Liu']",[],,2108.09875,cs.LG,2021-08-23 00:38:37+00:00,2021-08-23 00:38:37+00:00
iktA2PtTRsK,2021,Reject,True,Watching the World Go By: Representation Learning from Unlabeled Videos,"[""Daniel Gordon"", ""Kiana Ehsani"", ""Dieter Fox"", ""Ali Farhadi""]","[""Representation Learning"", ""Unsupervised Learning"", ""Video Analytics""]","Using unlabeled videos, we improve over recent unsupervised single image techniques, as well as over fully supervised ImageNet pretraining, across a variety of temporal and non-temporal tasks.",2003.07990,cs.CV,2020-03-18 00:07:21+00:00,2020-05-07 17:23:14+00:00
imnG4Ap9dAd,2021,Reject,False,News-Driven Stock Prediction Using Noisy Equity State Representation,"[""Xiao Liu"", ""Heyan Huang"", ""Yue Zhang""]","[""news-driven stock prediction"", ""equity state representation"", ""recurrent state transition""]","We investigate explicit modeling of equity state representations in news-driven stock prediction by using an LSTM state to model the fundamentals, adding news impact and noise impact by using attention and noise sampling, respectively.",,,,
in1ynkrXyMH,2022,Reject,False,Introspective Learning : A Two-Stage approach for Inference in Neural Networks,"['Mohit Prabhushankar', 'Ghassan AlRegib']","[""Reasoning"", ""Knowledge Representation"", ""Robustness"", ""Recognition""]",The paper proposes a framework that implicitly introspects against all possible decisions to create robust and calibrated decisions.,,,,
in2qzBZ-Vwr,2021,Reject,False,Cooperating RPN's Improve Few-Shot Object Detection,"[""Weilin Zhang"", ""Yu-Xiong Wang"", ""David Forsyth""]","[""Few-shot learning"", ""Object detection""]",We identify the proposal neglect effect in few-shot detection and propose cooperating RPN's that yield significant performance improvements over state of the art in the very few-shot setting.,,,,
inA3szzFE5,2022,Reject,False,Spatial Frequency Sensitivity Regularization for Robustness,"['Kiran Chari', 'Chuan-Sheng Foo', 'See-Kiong Ng']",[],The paper studies and modifies the frequency characteristics of DNNs. ,,,,
inBTt_wSv0,2021,Reject,False,Exploring Transferability of Perturbations in Deep Reinforcement Learning,"[""Ezgi Korkmaz""]","[""transferability"", ""deep reinforcement learning"", ""generalization"", ""adversarial""]",,,,,
inSTvgLk2YP,2022,Reject,False,MeshInversion: 3D textured mesh reconstruction with generative prior,"['Junzhe Zhang', 'Daxuan Ren', 'Zhongang Cai', 'Chai Kiat Yeo', 'Bo Dai', 'Chen Change Loy']","[""Single-view 3D object reconstruction"", ""GAN inversion""]",We propose an alternative 3D reconstruction framework that exploits the rich prior knowledge in a pre-trained GAN.,,,,
io-EI8C0q6A,2021,Reject,True,Unsupervised Cross-lingual Representation Learning for Speech Recognition,"[""Alexis Conneau"", ""Alexei Baevski"", ""Ronan Collobert"", ""Abdelrahman Mohamed"", ""Michael Auli""]","[""Deep learning"", ""speech processing"", ""multilingual modeling"", ""cross-lingual""]",Multilingual pre-training on speech data improves speech recognition,2006.13979,cs.CL,2020-06-24 18:25:05+00:00,2020-12-15 23:19:19+00:00
ioXEbG_Sf-a,2021,Reject,True,Experience Replay with Likelihood-free Importance Weights,"[""Samarth Sinha"", ""Jiaming Song"", ""Animesh Garg"", ""Stefano Ermon""]","[""Experience Replay"", ""Off-Policy Optimization"", ""Deep Reinforcement Learning""]","A simple approach that improves deep actor-critic methods (SAC, TD3, DrQ) by appropriately reweighting the experience replay buffer",2006.13169,cs.AI,2020-06-23 17:17:44+00:00,2020-06-23 17:17:44+00:00
iox4AjpZ15,2021,Reject,True,Invertible Manifold Learning for Dimension Reduction,"[""Siyuan Li"", ""Haitao Lin"", ""Zelin Zang"", ""Lirong Wu"", ""Jun Xia"", ""Stan Z. Li""]","[""Manifold Learning"", ""Inverse Model"", ""Representation Learing""]","We propose a novel invertible dimension reduction process for manifold learning with a neural network implementation, and explore the inherent difficulty of manifold learning in real-world secnarios by the way.",2010.04012,cs.LG,2020-10-07 14:22:51+00:00,2021-06-30 15:32:57+00:00
ipUPfYxWZvM,2021,Accept (Poster),False,IOT: Instance-wise Layer Reordering for Transformer Structures,"[""Jinhua Zhu"", ""Lijun Wu"", ""Yingce Xia"", ""Shufang Xie"", ""Tao Qin"", ""Wengang Zhou"", ""Houqiang Li"", ""Tie-Yan Liu""]","[""Layer order"", ""Transformers"", ""Instance-wise Learning""]",,2103.03457,cs.CL,2021-03-05 03:44:42+00:00,2021-03-05 03:44:42+00:00
iqmOTi9J7E8,2021,Reject,False,Private Split Inference of Deep Networks,"[""Mohammad Samragh"", ""Hossein Hosseini"", ""Kambiz Azarian"", ""Joseph Soriaga""]","[""ML privacy"", ""split inference""]","We propose a split learning framework for private inference of neural networks, in which the edge device removes the content of the activations that is not relevant to the main task.  ",,,,
irARV_2VFs4,2022,Accept (Poster),False,Focus on the Common Good: Group Distributional Robustness Follows,"['Vihari Piratla', 'Praneeth Netrapalli', 'Sunita Sarawagi']","[""sub-population shift"", ""robust optimization"", ""domain generalization""]","We propose a new and simple algorithm for the sub-population shift problem that enables learning of shared features and performed consistently well over several standard, and real-world, benchmarks of the problem.",,,,
iulEMLYh1uR,2022,Accept (Poster),False,The Efficiency Misnomer,"['Mostafa Dehghani', 'Yi Tay', 'Anurag Arnab', 'Lucas Beyer', 'Ashish Vaswani']","[""Efficiency in Machine Learning"", ""FLOPs"", ""Number of Parameters"", ""Throughput""]",,,,,
ivQruZvXxtz,2022,Accept (Poster),False,Sequential Reptile: Inter-Task Gradient Alignment for Multilingual Learning,"['Seanie Lee', 'Hae Beom Lee', 'Juho Lee', 'Sung Ju Hwang']","[""multilingual language model"", ""gradient alignment""]",We propose a simple yet effective gradient alignment method for finetuning multilingual pretrained language models.,,,,
iw-ms2znSS2,2022,Reject,False,The Remarkable Effectiveness of Combining Policy and Value Networks in A*-based Deep RL for AI Planning,"['Dieqiao Feng', 'Carla P Gomes', 'Bart Selman']",[],The Remarkable Effectiveness of Combining Policy and Value Networks in A*-based Deep RL for AI Planning,,,,
ixpSxO9flk3,2021,Accept (Poster),False,No MCMC for me: Amortized sampling for fast and stable training of energy-based models,"[""Will Sussman Grathwohl"", ""Jacob Jin Kelly"", ""Milad Hashemi"", ""Mohammad Norouzi"", ""Kevin Swersky"", ""David Duvenaud""]","[""Generative Models"", ""EBM"", ""Energy-Based Models"", ""Energy Based Models"", ""semi-supervised learning"", ""JEM""]",We present a new generator-based approach for training EBMs and demonstrate that it trains models which obtain high likelihood and overcomes stability issues common in EBM training.,,,,
iy3xVojOhV,2021,Reject,False,GraphCGAN: Convolutional Graph Neural Network with Generative Adversarial Networks,"[""Sheng Zhang"", ""Rui Song"", ""Wenbin Lu""]",[],,,,,
izj68lUcBpt,2022,Accept (Poster),False,TAda! Temporally-Adaptive Convolutions for Video Understanding,"['Ziyuan Huang', 'Shiwei Zhang', 'Liang Pan', 'Zhiwu Qing', 'Mingqian Tang', 'Ziwei Liu', 'Marcelo H Ang Jr']","[""Video understanding"", ""Action classification"", ""Dynamic networks""]",A stand-alone temporal modelling module or a plug-in enhancement of the 1D/2D/3D convolutions used in video models for better and more efficient temporal modelling.,,,,
izvwgBic9q,2022,Accept (Poster),False,Unsupervised Learning of Full-Waveform Inversion: Connecting CNN and Partial Differential Equation in a Loop,"['Peng Jin', 'Xitong Zhang', 'Yinpeng Chen', 'Sharon X Huang', 'Zicheng Liu', 'Youzuo Lin']","[""Unsupervised Learning"", ""Full-Waveform Inversion"", ""Partial Differential Equation"", ""Physics-Informed Machine Learning""]",We develop an unsupervised method to solve seismic full-waveform inversion in geophysics by integrating CNN and the governing partial differential equation. ,,,,
j-63FSNcO5a,2022,Accept (Poster),True,Learning Disentangled Representation by Exploiting Pretrained Generative Models:  A Contrastive Learning View,"['Xuanchi Ren', 'Tao Yang', 'Yuwang Wang', 'Wenjun Zeng']","[""Latent space discovery"", ""Disentangled representation learning"", ""Generative models"", ""Contrastive learning""]",DisCo is a new contrastive learning framework to leverage pretrained generative models to jointly learn disentangled representation and discover disentangled directions in the latent space.,2102.10543,cs.CV,2021-02-21 08:01:20+00:00,2021-02-21 08:01:20+00:00
j0p8ASp9Br,2021,Reject,True,Real-time Uncertainty Decomposition for Online Learning Control,"[""Jonas Umlauft"", ""Armin Lederer"", ""Thomas Beckers"", ""Sandra Hirche""]","[""uncertainty decomposition"", ""epistemic uncertainty"", ""online learning"", ""real-time control""]",The paper proposes a real-time capable epistemic uncertainty estimation with sample-free inference which allows online learning control applications for which we demonstrate the benefits of aleatoric/epistemic uncertainty decomposition.,2010.02613,cs.LG,2020-10-06 10:46:27+00:00,2020-11-24 18:12:06+00:00
j0uePNuoBho,2021,Reject,False,Learned Threshold Pruning,"[""Kambiz Azarian"", ""Yash Sanjay Bhalgat"", ""Jinwon Lee"", ""Tijmen Blankevoort""]","[""Efficiency"", ""Model Compression"", ""Unstructured Pruning"", ""Differentiable Pruning""]","We propose Learned Threshold Pruning (LTP) method for unstructured pruning of deep networks, where the per-layer pruning thresholds are learned via gradient descent leading to state-of-the-art compression of various modern architectures.",,,,
j0yLJ-MsgJ,2021,Reject,False,Class Imbalance in Few-Shot Learning,"[""Mateusz Ochal"", ""Massimiliano Patacchiola"", ""Jose Vazquez"", ""Amos Storkey"", ""Sen Wang""]","[""few-shot learning"", ""class imbalance""]",We extensively compare over 10 few-shot learning methods in the class imbalance problem.,,,,
j1RMMKeP2gR,2021,Accept (Poster),False,Acting in Delayed Environments with Non-Stationary Markov Policies,"[""Esther Derman"", ""Gal Dalal"", ""Shie Mannor""]","[""reinforcement learning"", ""delay""]","In this paper, we derive theoretical results on execution-delay MDPs, and devise a DQN-based algorithm to empirically tackle this setup.",2101.11992,cs.LG,2021-01-28 13:35:37+00:00,2021-03-18 08:40:13+00:00
j30wC0JM39Q,2022,Reject,False,Why do embedding spaces look as they do?,"['Xingzhi Guo', 'Baojian Zhou', 'Haochen Chen', 'Sergiy Verstyuk', 'Steven Skiena']",[],,,,,
j39sWOYhfEg,2021,Reject,True,The shape and simplicity biases of adversarially robust ImageNet-trained CNNs,"[""Peijie Chen"", ""Chirag Agarwal"", ""Anh Nguyen""]","[""shape bias"", ""texture bias"", ""interpretability"", ""smoothness"", ""visualization""]",adversarial training makes networks more robust by smoothing out kernels and reducing the space of active inputs of each neuron,2006.09373,cs.CV,2020-06-16 16:38:16+00:00,2021-09-20 13:36:39+00:00
j3krplz_4w6,2022,Accept (Poster),False,Fooling Explanations in Text Classifiers,"['Adam Ivankay', 'Ivan Girardi', 'Chiara Marchiori', 'Pascal Frossard']","[""robustness"", ""explainability"", ""text classification"", ""natural language processing""]",Our work shows that explanation methods in text classifiers are susceptible to imperceptible perturbations that alter the explanation outcomes without changing the predictions of the classifiers.,,,,
j5d9qacxdZa,2021,Reject,False,Energy-Based Models for Continual Learning,"[""Shuang Li"", ""Yilun Du"", ""Gido Martijn van de Ven"", ""Antonio Torralba"", ""Igor Mordatch""]","[""Continual learning"", ""Energy-based model""]",We show Energy-Based Models are a class of models naturally inclined towards the continual learning regime.,,,,
j6rILItz4yr,2021,Reject,False,ALFA: Adversarial Feature Augmentation for Enhanced Image Recognition,"[""Tianlong Chen"", ""Yu Cheng"", ""Zhe Gan"", ""Yu Hu"", ""Zhangyang Wang"", ""Jingjing Liu""]","[""Adversarial Training"", ""Image Recognition"", ""Generalization""]",Utilizing clean and adversarial augmented features to improve the generalization of image recognition,,,,
j7qEcn647RY,2021,Reject,False,LINGUINE: LearnIng to pruNe on subGraph convolUtIon NEtworks,"[""Yihan He"", ""Wei Cao"", ""Shun Zheng"", ""Zhifeng Gao"", ""Jiang Bian""]","[""Graph Neural Networks"", ""Meta-Learning"", ""Pruning""]",,,,,
j8J97VgdmsT,2022,Reject,True,FLAME-in-NeRF: Neural control of Radiance Fields for Free View Face Animation,"['ShahRukh Athar', 'Zhixin Shu', 'Dimitris Samaras']","[""Neural Rendering"", ""Facial Reanimation"", ""3D Scene Priors""]",,2108.04913,cs.CV,2021-08-10 20:41:15+00:00,2021-08-10 20:41:15+00:00
j97zf-nLhC,2022,Reject,False,Zero-Shot Coordination via Semantic Relationships Between Actions and Observations,"['Mingwei Ma', 'Jizhou Liu', 'Samuel Sokota', 'Max Kleiman-Weiner', 'Jakob Nicolaus Foerster']","[""multi-agent communication"", ""multi-agent reinforcement learning"", ""attention mechanism"", ""zero-shot coordination""]",We investigate how attention can be use to coordinate in settings that contain shared features across actions and observations.,,,,
j9Rv7qdXjd,2021,Accept (Poster),True,Interpretable Neural Architecture Search via Bayesian Optimisation with Weisfeiler-Lehman Kernels,"[""Binxin Ru"", ""Xingchen Wan"", ""Xiaowen Dong"", ""Michael Osborne""]",[],"We propose a NAS method that is sample-efficient, highly performant and interpretable.",2006.07556,cs.LG,2020-06-13 04:10:34+00:00,2021-02-19 05:36:54+00:00
jAJrc-kzVd0,2021,Reject,False,Revisiting Prioritized Experience Replay: A Value Perspective,"[""Ang A. Li"", ""Zongqing Lu"", ""Chenglin Miao""]",[],,2102.03261,cs.LG,2021-02-05 16:09:07+00:00,2021-02-05 16:09:07+00:00
jC9G3ns6jH,2021,Reject,True,Quantifying Statistical Significance of Neural Network Representation-Driven Hypotheses by Selective Inference,"[""Vo Nguyen Le Duy"", ""Shogo Iwazaki"", ""Ichiro Takeuchi""]","[""Deep Neural Network Representation"", ""Reliability"", ""Selective Inference"", ""Statistical Hypothesis Testing"", ""p-value""]",We propose a novel method to quantify the reliability of neural network representation-driven hypotheses in statistical hypothesis testing framework by Selective Inference.,2010.01823,stat.ML,2020-10-05 07:16:40+00:00,2020-10-05 07:16:40+00:00
jDIWFyftpQh,2021,Reject,True,Discriminative Cross-Modal Data Augmentation for Medical Imaging Applications,"[""Yue Yang"", ""Pengtao Xie""]","[""Deep learning"", ""Medical imaging"", ""Cross-Modal Learning""]",,2010.03468,eess.IV,2020-10-07 15:07:00+00:00,2020-10-07 15:07:00+00:00
jDdzh5ul-d,2021,Accept (Poster),False,Achieving Linear Speedup with Partial Worker Participation in Non-IID Federated Learning,"[""Haibo Yang"", ""Minghong Fang"", ""Jia Liu""]","[""Federated Learning"", ""Linear Speedup"", ""Partial Worker Participation""]",,2101.11203,cs.LG,2021-01-27 04:38:27+00:00,2021-05-04 03:30:18+00:00
jEYKjPE1xYN,2021,Accept (Poster),False,Symmetry-Aware Actor-Critic for 3D Molecular Design,"[""Gregor N. C. Simm"", ""Robert Pinsler"", ""G\u00e1bor Cs\u00e1nyi"", ""Jos\u00e9 Miguel Hern\u00e1ndez-Lobato""]","[""deep reinforcement learning"", ""molecular design"", ""covariant neural networks""]",Covariant actor-critic based on spherical harmonics that exploits symmetries to design molecules in 3D,2011.12747,stat.ML,2020-11-25 14:04:33+00:00,2020-11-25 14:04:33+00:00
jE_ipyh20rb,2022,Reject,False,FedProf: Selective Federated Learning with Representation Profiling,"['Wentai Wu', 'Ligang He', 'Weiwei Lin', 'carsten maple', 'Rui Mao']","[""federated learning"", ""neural network"", ""representation learning"", ""distributed computing""]",A selective FL training algorithm based on distributional representation profiling and matching.,,,,
jFfRcKVut98,2022,Reject,True,Learning Equivariances and Partial Equivariances From Data,"['David W. Romero', 'Suhas Lohit']","[""group equivariance"", ""learning equivariances from data"", ""partial equivariance"", ""group convolutional networks.""]",We introduce Partial Group equivariant Convolutional Neural Networks: a family of equivariant networks able to learn equivariances and partial equivariances from data at every layer end-to-end.,2110.10211,cs.CV,2021-10-19 19:17:32+00:00,2021-10-19 19:17:32+00:00
jGeOQt3oUl1,2021,Reject,True,Representational aspects of depth and conditioning in normalizing flows,"[""Frederic Koehler"", ""Viraj Mehta"", ""Andrej Risteski""]","[""normalizing flows"", ""representational power"", ""conditioning"", ""depth"", ""theory""]",Provable tradeoffs between conditioning/depth and representational power for normalizing flows. ,2010.01155,cs.LG,2020-10-02 18:15:45+00:00,2021-06-25 23:48:35+00:00
jGmNTfiXwGb,2022,Reject,False,"Learning Predictive, Online Approximations of Explanatory, Offline Algorithms","['Mattson Thieme', 'Ammar Gilani', 'Han Liu']","[""multi-task learning"", ""machine learning"", ""online algorithms"", ""offline algorithms""]","We introduce a novel, multi-task learning methodology to approximate the behavior of arbitrary offline algorithms in online settings.",,,,
jH7wTMOYvbw,2021,Reject,False,Recursive Neighborhood Pooling for Graph Representation Learning,"[""Behrooz Tahmasebi"", ""Stefanie Jegelka""]",[],,,,,
jHefDGsorp5,2021,Accept (Poster),False,Molecule Optimization by Explainable Evolution,"[""Binghong Chen"", ""Tianzhe Wang"", ""Chengtao Li"", ""Hanjun Dai"", ""Le Song""]","[""Molecule Design"", ""Explainable Model"", ""Evolutionary Algorithm"", ""Reinforcement Learning"", ""Graph Generative Model""]",We propose a novel EM-like evolution-by-explanation algorithm alternating between an explainable graph model and a conditional generative model for molecule optimization.,,,,
jHykXSIk3ch,2021,Reject,False,A spherical analysis of Adam with Batch Normalization,"[""Simon Roburin"", ""Yann Dubois de Mont-Marin"", ""Andrei Bursuc"", ""Renaud Marlet"", ""Patrick Perez"", ""Mathieu Aubry""]","[""Deep Learning"", ""Machine Learning"", ""Adam"", ""Batch Normalization""]",Analysis of the interaction between BN and Adam during the training process.,,,,
jJJWwrMrEsx,2022,Reject,False,"Truth Table Deep Convolutional Neural Network, A New SAT-Encodable Architecture - Application To Complete Robustness","['Adrien Benamira', 'Thomas Peyrin', 'Bryan Hooi']","[""AI Safety"", ""SAT-encodable Neural Network"", ""Formal Verification"", ""Complete Verification Robustness"", ""Interpretability"", ""Logic Rules"", ""XAI""]",We introduce a new family of real-weighted SAT-encodable models and we apply it to complete robustness verification.,,,,
jJOjjiZHy3h,2022,Accept (Poster),False,Defending Against Image Corruptions Through Adversarial Augmentations,"['Dan Andrei Calian', 'Florian Stimberg', 'Olivia Wiles', 'Sylvestre-Alvise Rebuffi', 'AndrÃ¡s GyÃ¶rgy', 'Timothy A Mann', 'Sven Gowal']","[""robustness"", ""adversarial training"", ""image corruptions""]","Our theoretically-supported method finds adversarial examples by optimizing over the weights of pre-trained autoencoders, and yields classifiers with improved robustness to image corruptions.",,,,
jJWK09skiNl,2022,Reject,False,Zero-shot detection of daily objects in YCB video dataset,['Wanqing Xia'],"[""zero-shot learning"", ""object detection"", ""multi-label learning"", ""attribute vector""]",A zer-shot detection algorithm that based on YOLOv5 and tested on YCB Video dataset,,,,
jJis-v9Pzhj,2022,Reject,False,Positive-Unlabeled Learning with Uncertainty-aware Pseudo-label Selection,"['Emilio Dorigatti', 'Jann Goschenhofer', 'Benjamin Schubert', 'Mina Rezaei', 'Bernd Bischl']","[""positive-unlabeled learning"", ""semi-supervised learning"", ""pseudo-labeling"", ""deep ensembles"", ""uncertainty quantification""]",Selecting pseudo-labels based on epistemic uncertainty provides better performance and increased robustness in positive-unlabeled learning.,2201.13192,stat.ML,2022-01-31 12:55:47+00:00,2022-01-31 12:55:47+00:00
jKzjSZYsrGP,2022,Reject,False,SCformer: Segment Correlation Transformer for Long Sequence Time Series Forecasting,"['Dazhao Du', 'Bing Su', 'Zhewei Wei']","[""Transformer"", ""time series forecasting"", ""sparse attention""]",We propose an efficient Transformer-based model with SCAttention mechanism for long sequence time series forecasting,,,,
jLoC4ez43PZ,2021,Accept (Poster),True,GraphCodeBERT: Pre-training Code Representations with Data Flow,"[""Daya Guo"", ""Shuo Ren"", ""Shuai Lu"", ""Zhangyin Feng"", ""Duyu Tang"", ""Shujie LIU"", ""Long Zhou"", ""Nan Duan"", ""Alexey Svyatkovskiy"", ""Shengyu Fu"", ""Michele Tufano"", ""Shao Kun Deng"", ""Colin Clement"", ""Dawn Drain"", ""Neel Sundaresan"", ""Jian Yin"", ""Daxin Jiang"", ""Ming Zhou""]","[""Pre-training"", ""BERT"", ""Code Representations"", ""Code Structure"", ""Data Flow""]",,2009.08366,cs.SE,2020-09-17 15:25:56+00:00,2021-09-13 05:48:51+00:00
jM76BCb6F9m,2021,Accept (Poster),False,LEAF: A Learnable Frontend for Audio Classification,"[""Neil Zeghidour"", ""Olivier Teboul"", ""F\u00e9lix de Chaumont Quitry"", ""Marco Tagliasacchi""]","[""audio understanding"", ""frontend"", ""learnable"", ""mel-filterbanks"", ""time-frequency representations"", ""sound classification""]",We propose a lightweight learnable frontend of audio that can replace fixed features over a wide range of audio classification tasks.,2101.08596,cs.SD,2021-01-21 13:25:58+00:00,2021-01-21 13:25:58+00:00
jMPcEkJpdD,2021,Accept (Poster),False,Self-Supervised Learning of Compressed Video Representations,"[""Youngjae Yu"", ""Sangho Lee"", ""Gunhee Kim"", ""Yale Song""]","[""Compressed videos"", ""self-supervised learning""]",We propose a self-supervised approach to learning compressed video representations.,,,,
jMc7DlflrMC,2021,Reject,False,Density Constrained Reinforcement Learning,"[""Zengyi Qin"", ""Yuxiao Chen"", ""Chuchu Fan""]","[""Constrained Reinforcement Learning"", ""Density"", ""Safe AI""]","We present a pioneering study of imposing constraints directly on the state density function in constrained RL for safety-critical and resource-limited tasks, with theoretical guarantees of optimality and extensive empirical experiments.",2106.12764,cs.LG,2021-06-24 04:22:03+00:00,2021-06-24 04:22:03+00:00
jN5y-zb5Q7m,2021,Accept (Poster),True,Uncertainty Estimation in Autoregressive Structured Prediction,"[""Andrey Malinin"", ""Mark Gales""]","[""ensembles"", ""structures prediction"", ""uncertainty estimation"", ""knowledge uncertainty"", ""autoregressive models"", ""information theory"", ""machine translation"", ""speech recognition.""]",A Deep Investigation of Ensemble-based Uncertainty Estimation for Autoregressive ASR and NMT models.,2002.07650,stat.ML,2020-02-18 15:40:13+00:00,2021-02-11 09:42:35+00:00
jN8TTVCgOqf,2021,Reject,False,Local Clustering Graph Neural Networks,"[""Jiezhong Qiu"", ""Yukuo Cen"", ""Qibin Chen"", ""Chang Zhou"", ""Jingren Zhou"", ""Hongxia Yang"", ""Jie Tang""]","[""Graph Neural Networks"", ""Local Clustering"", ""Random Walk on Graphs"", ""Open Graph Benchmark""]",A local clustering based graph neural networks learning paradigm.,,,,
jNB6vfl_680,2022,Reject,False,Global Magnitude Pruning With Minimum Threshold Is All We Need,"['Manas Gupta', 'Vishandi Rudy Keneta', 'Abhishek Vaidyanathan', 'Ritwik Kanodia', 'Efe Camci', 'Chuan-Sheng Foo', 'Jie Lin']","[""Pruning"", ""Model Compression"", ""One-shot"", ""Global Magnitude Pruning""]",Global magnitude pruning along with minimum threshold is a very simple pruning technique and at the same time sufficient to obtain SOTA pruning performance.,,,,
jNTeYscgSw8,2021,Reject,False,Demystifying Loss Functions for Classification,"[""Simon Kornblith"", ""Honglak Lee"", ""Ting Chen"", ""Mohammad Norouzi""]","[""softmax"", ""classification"", ""representational similarity"", ""transfer learning"", ""label smoothing"", ""dropout""]",,,,,
jNhWDHdjVi4,2021,Reject,False,Learning Consistent Deep Generative Models from Sparse Data via Prediction Constraints,"[""Gabriel Hope"", ""Madina Abdrakhmanova"", ""Xiaoyin Chen"", ""Michael C Hughes"", ""Erik B Sudderth""]","[""Semisupervised learning"", ""deep generative models"", ""variational autoencoders""]",We develop a new framework for learning variational autoencoders and other deep generative models that balances generative and discriminative goals.,,,,
jNsynsmDkl,2022,Reject,False,Contrastively Enforcing Distinctiveness  for Multi-Label Classification,"['Son Duy Dao', 'He Zhao', 'Dinh Phung', 'Jianfei Cai']","[""Multi-label Classification"", ""Contrastive learning""]",,,,,
jOQbDGngsg8,2021,Reject,False,Secure Network Release with Link Privacy,"[""Carl Yang"", ""Haonan Wang"", ""Ke ZHANG"", ""Lichao Sun""]","[""generative model"", ""graph neural network"", ""data release""]",We study secure network release by learning to generate globally useful graphs with individual link privacy.,,,,
jP1vTH3inC,2021,Accept (Poster),False,Discovering Non-monotonic Autoregressive Orderings with Variational Inference,"[""Xuanlin Li"", ""Brandon Trabucco"", ""Dong Huk Park"", ""Michael Luo"", ""Sheng Shen"", ""Trevor Darrell"", ""Yang Gao""]","[""variational inference"", ""unsupervised learning"", ""computer vision"", ""natural language processing"", ""optimization"", ""reinforcement learning""]",The paper proposes an unsupervised learner that discovers non-monotonic autoregressive orders for sequence generation through fully-parallelizable end-to-end training without domain-specific prior.,2110.15797,cs.CL,2021-10-27 16:08:09+00:00,2021-10-27 16:08:09+00:00
jPSYH47QSZL,2021,Reject,False,Pre-Training by Completing Point Clouds,"[""Hanchen Wang"", ""Qi Liu"", ""Xiangyu Yue"", ""Joan Lasenby"", ""Matt Kusner""]","[""self-supervised learning"", ""pre-training"", ""point clouds""]",We present a self-supervised pre-training technique that learns to complete occluded point clouds.,,,,
jQ0XleVhYuT,2021,Reject,False,Double Generative Adversarial Networks for Conditional Independence Testing,"[""Chengchun Shi"", ""Tianlin Xu"", ""Wicher Pieter Bergsma"", ""Lexin Li""]","[""conditional independence testing"", ""generative adversarial networks"", ""high dimensionality"", ""statistical inference""]",We introduce a double generative adversarial networks for conditional independence testing. ,,,,
jQSBcVURlpW,2021,Reject,False,Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning,"[""Chi Zhang"", ""Sirui Xie"", ""Baoxiong Jia"", ""Yixin Zhu"", ""Ying Nian Wu"", ""Song-Chun Zhu""]",[],,,,,
jQUf0TmN-oT,2021,Reject,False,SACoD: Sensor Algorithm Co-Design Towards Efficient CNN-powered Intelligent PhlatCam,"[""Yonggan Fu"", ""Yang Zhang"", ""Yue Wang"", ""Zhihan Lu"", ""Vivek Boominathan"", ""Ashok Veeraraghavan"", ""Yingyan Lin""]","[""Sensor Network Co-design"", ""neural architecture search""]","We propose SACoD, a Sensor Algorithm Co-Design framework to develop more efficient CNN-powered PhlatCam.",,,,
jT1EwXu-4hj,2022,Accept (Poster),False,From Intervention to Domain Transportation: A Novel Perspective to Optimize Recommendation,"['Da Xu', 'Yuting Ye', 'Chuanwei Ruan', 'Evren Korpeoglu', 'Sushant Kumar', 'Kannan Achan']","[""Information retrieval"", ""Learning theory"", ""Causal inference"", ""Missing data"", ""Overlapping"", ""Reweighting"", ""Optimal transport""]",We propose and study a novel domain-transportation view for optimizing recommendation for information retrieval systems.,,,,
jT5vnpqlrSN,2022,Reject,True,GIR Framework: Learning Graph Positional Embeddings with Anchor Indication and Path Encoding,"['Yuheng Lu', 'Jinpeng Chen', 'Chuxiong Sun', 'Jie Hu']","[""Graph neural networks"", ""Anchor based GNN"", ""Node representation learning""]",,2105.03821,cs.LG,2021-05-09 03:25:58+00:00,2021-06-12 14:53:25+00:00
jWXBUsWP7N,2021,Reject,False,A Distributional Perspective on Actor-Critic Framework,"[""Daniel Wontae Nam"", ""Younghoon Kim"", ""Chan Youn Park""]","[""Value distribution learning"", ""reinforcement learning"", ""deep learning"", ""distributional reinforcement learning"", ""distributional actor-critic""]","This paper proposes value distribution learning in actor-critic framework for more stable theoretical guarantee, computational efficiency, and accurate distribution learning.",,,,
jWaLuyg6OEw,2022,Reject,False,First-Order Optimization Inspired from Finite-Time Convergent Flows,"['Siqi Zhang', 'Mouhacine Benosman', 'Orlando Romero', 'Anoop Cherian']","[""Dynamical systems"", ""continuous-time optimization flows"", ""first-order optimization"", ""DNN applications""]",,,,,
jWkw45-9AbL,2021,Accept (Oral),False,A Distributional Approach to Controlled Text Generation,"[""Muhammad Khalifa"", ""Hady Elsahar"", ""Marc Dymetman""]","[""Controlled NLG"", ""Pretrained Language Models"", ""Bias in Language Models"", ""Energy-Based Models"", ""Information Geometry"", ""Exponential Families""]","We propose a novel approach to Controlled NLG, relying on Constraints over Distributions, Information Geometry, and Sampling from Energy-Based Models.",2012.11635,cs.CL,2020-12-21 19:02:41+00:00,2021-05-06 10:18:59+00:00
jXKKDEi5vJt,2022,Accept (Spotlight),True,Byzantine-Robust Learning on Heterogeneous Datasets via Bucketing,"['Sai Praneeth Karimireddy', 'Lie He', 'Martin Jaggi']","[""Federated learning"", ""Distributed learning"", ""Byzantine robust optimization"", ""Heterogeneity (Non-IID)""]",Byzantine-robust distributed learning with heterogeneous data distribution,2006.09365,cs.LG,2020-06-16 17:58:53+00:00,2021-10-13 20:23:07+00:00
jXe91kq3jAq,2021,Accept (Poster),False,Latent Skill Planning for Exploration and Transfer,"[""Kevin Xie"", ""Homanga Bharadhwaj"", ""Danijar Hafner"", ""Animesh Garg"", ""Florian Shkurti""]","[""Model-Based Reinforcement Learning"", ""World Models"", ""Skill Discovery"", ""Mutual Information"", ""Planning"", ""Model Predictive Control"", ""Partial Amortization""]",Partially amortized planning through hierarchy helps learn skills for complex control tasks,2011.13897,cs.LG,2020-11-27 18:40:03+00:00,2021-05-02 15:53:04+00:00
jYVY_piet7m,2021,Reject,False,Hybrid-Regressive Neural Machine Translation,"[""Qiang Wang"", ""Heng Yu"", ""Shaohui Kuang"", ""Weihua Luo""]","[""neural machine translation"", ""non-autoregressive translation""]","Conventional non-autoregressive translation with multiple iterations cannot accelerate decoding when using a small batch size (especially on CPU), and we propose Hybrid-Regressive Translation (HRT) to overcome this issue.",,,,
jYkO_0z2TAr,2021,Reject,False,Zero-Shot Learning with Common Sense Knowledge Graphs,"[""Nihal Nayak"", ""Stephen Bach""]","[""Zero-Shot Learning"", ""Common Sense Knowledge Graphs"", ""Graph Neural Networks""]","Our paper introduces ZSL-KG, a general-purpose zero-shot learning framework with a novel transformer graph convolutional network (TrGCN) to learn class representation from common sense knowledge graphs.",,,,
jZQOWas0Lo3,2022,Reject,False,Cycle monotonicity of adversarial attacks for optimal domain adaptation,"['Arip Asadulaev', 'Vitaly Shutov', 'Alexander Korotin', 'Alexander Panfilov', 'Andrey Filchenkov']","[""Optimal Transport"", ""Domain Adaptation"", ""Adversarial Attacks""]",Connection of optimal transport and adversarial attacks for semi-supervised domain adaptation,,,,
jaLDP8Hp_gc,2022,Accept (Poster),True,Visual Correspondence Hallucination,"['Hugo Germain', 'Vincent Lepetit', 'Guillaume Bourmaud']","[""visual correspondence hallucination"", ""camera pose estimation""]",We learn to hallucinate visual correspondences.,2106.09711,cs.CV,2021-06-17 17:58:35+00:00,2022-02-02 15:13:36+00:00
jbrgwbv8nD,2022,Accept (Poster),False,Constraining Linear-chain CRFs to Regular Languages,"['Sean Papay', 'Roman Klinger', 'Sebastian Pado']","[""constrained training"", ""probabilistic graphical models"", ""CRF"", ""semantic role labeling"", ""sequence labeling""]","CRFs can be efficiently constrained to arbitrary regular languages, enforcing nonlocal constraints on their outputs.",,,,
jcN7a3yZeQc,2021,Reject,True,Decorrelated Double Q-learning,"[""GANG CHEN""]","[""q-learning"", ""control variates"", ""reinforcement learning""]",This paper proposes a decorrelated Double Q-learning for continuous task control,2006.06956,cs.LG,2020-06-12 05:59:05+00:00,2020-06-12 05:59:05+00:00
jcpcUjw7Kzz,2021,Reject,False,Discrete Predictive Representation for Long-horizon Planning,"[""Thanard Kurutach"", ""Julia Peng"", ""Yang Gao"", ""Stuart Russell"", ""Pieter Abbeel""]","[""Discrete Representation"", ""Learning and Planning"", ""Model-based RL"", ""Hierarchical RL""]","We propose Discrete Object-factorized Representation Planning (DORP), which learns temporally-abstracted discrete representations from exploratory video data for long-horizon planning and control.",,,,
jeLW-Fh9bV,2022,Accept (Poster),False,Skill-based Meta-Reinforcement Learning,"['Taewook Nam', 'Shao-Hua Sun', 'Karl Pertsch', 'Sung Ju Hwang', 'Joseph J Lim']","[""meta-RL"", ""meta-reinforcement learning"", ""skill-based meta-reinforcement learning"", ""meta-learning"", ""skill-based RL""]",,,,,
jfPU-u_52Tx,2021,Reject,True,Federated Generalized Bayesian Learning via  Distributed Stein Variational Gradient Descent,"[""Rahif Kassab"", ""Osvaldo Simeone""]","[""Federated Learning"", ""Distributed Variational Inference""]",This paper introduces a non-parametric generalized Bayesian federated learning framework based on SVGD that allows a flexible trade-off between per-iteration communication load and number of communication rounds.,2009.06419,cs.LG,2020-09-11 17:33:22+00:00,2021-03-30 13:14:24+00:00
jgAl403zfau,2022,Reject,True,HALP: Hardware-Aware Latency Pruning,"['Maying Shen', 'Hongxu Yin', 'Pavlo Molchanov', 'Lei Mao', 'Jianna Liu', 'Jose M. Alvarez']","[""Efficient deep learning"", ""deep neural network pruning"", ""latency reduction"", ""hardware-aware pruning""]","We propose HALP, Hardware-Aware Latency Pruning. HALP formulates the pruning as global resource allocation problem to fully exploits the hardware latency traits to yield direct inference speedups.",2110.10811,cs.CV,2021-10-20 22:34:51+00:00,2021-10-20 22:34:51+00:00
jh-rTtvkGeM,2021,Accept (Poster),False,Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability,"[""Jeremy Cohen"", ""Simran Kaur"", ""Yuanzhi Li"", ""J Zico Kolter"", ""Ameet Talwalkar""]","[""optimization"", ""trajectory"", ""stability"", ""sharpness"", ""implicit bias"", ""implicit regularization"", ""L-smoothness"", ""deep learning theory"", ""science of deep learning""]",We trained neural networks using full-batch gradient descent -- you won't believe what happens next!,,,,
jjKzfD9vP9,2021,Reject,False,Saliency Grafting: Innocuous Attribution-Guided Mixup with Calibrated Label Mixing,"[""Joonhyung Park"", ""June Yong Yang"", ""Jinwoo Shin"", ""Sung Ju Hwang"", ""Eunho Yang""]","[""Deep learning"", ""Data augmentation"", ""Input attribution""]",,,,,
jk1094_ZiN,2021,Reject,False,Synthetic Petri Dish: A Novel Surrogate Model for Rapid Architecture Search,"[""Aditya Rawal"", ""Joel Lehman"", ""Felipe Petroski Such"", ""Jeff Clune"", ""Kenneth Stanley""]","[""Neural Architecture Search"", ""AutoML"", ""Meta-learning""]","In order to speed-up NAS, this paper learns synthetic data to quickly train and evaluate miniaturized version of the full architectures. ",,,,
jlVNBPEDynH,2021,Reject,False,Neuro-algorithmic Policies for Discrete Planning,"[""Marin Vlastelica Pogan\u010di\u0107"", ""Michal Rolinek"", ""Georg Martius""]","[""planning"", ""reinforcement learning"", ""combinatorial optimization"", ""control"", ""imitation learning""]",We introduce neuro-algorithmic policies embedding shortest path solvers for discrete planning. ,,,,
jn1WDxmDe5P,2021,Reject,False,Meta-k: Towards Unsupervised Prediction of Number of Clusters,"[""Azade Farshad"", ""Samin Hamidi"", ""Nassir Navab""]","[""Clustering"", ""Self-supervised learning"", ""Meta-learning""]",Our work is an attempt to self-supervised prediction of number of clusters in a given data using policy gradient optimization.,,,,
jnMjOctlfbZ,2021,Reject,False,ATOM3D: Tasks On Molecules in Three Dimensions,"[""Raphael John Lamarre Townshend"", ""Martin Vogele"", ""Patricia Suriana"", ""Alex Derry"", ""Alex Powers"", ""Yianni Laloudakis"", ""Sidhika Balachandar"", ""Brandon M Anderson"", ""Stephan Eismann"", ""Risi Kondor"", ""Russ Altman"", ""Ron O. Dror""]","[""machine learning"", ""structural biology"", ""biomolecules""]",ATOM3D is a collection of benchmark datasets for learning algorithms that work with 3D biomolecular structure.,,,,
jnRqf0CzBK,2021,Reject,True,Hierarchical Probabilistic Model for Blind Source Separation via Legendre Transformation,"[""Simon Luo"", ""Lamiae Azizi"", ""Mahito Sugiyama""]","[""blind source separation"", ""log-linear model"", ""energy-based model"", ""information geometry""]",A novel formulation of blind source separation using a hierarchical energy-based model.,1909.11294,stat.ML,2019-09-25 05:22:45+00:00,2021-06-11 01:46:56+00:00
jpDaS6jQvcr,2021,Reject,False,Unsupervised Anomaly Detection by Robust Collaborative Autoencoders,"[""Boyang Liu"", ""Ding Wang"", ""Kaixiang Lin"", ""Pang-Ning Tan"", ""Jiayu Zhou""]","[""Anomaly Detection"", ""Robustness""]",Unsupervised anomaly detection algorithm which can handle training data corruptions.,,,,
jphnJNOwe36,2021,Accept (Poster),False,Overparameterisation and worst-case generalisation: friend or foe?,"[""Aditya Krishna Menon"", ""Ankit Singh Rawat"", ""Sanjiv Kumar""]","[""overparameterisation"", ""worst-case generalisation""]",Overparameterised models' worst-subgroup performance can be improved via post-hoc processing.,,,,
jpm1AfJucwt,2021,Reject,False,Revisiting Loss Modelling for Unstructured Pruning,"[""C\u00e9sar Laurent"", ""Camille Ballas"", ""Thomas George"", ""Pascal Vincent"", ""Nicolas Ballas""]","[""Deep Learning"", ""Network Pruning"", ""Unstructured Pruning""]",Studies the assumptions behind the loss models used in unstructured pruning.,,,,
jrA5GAccy_,2021,Accept (Poster),True,Empirical or Invariant Risk Minimization? A Sample Complexity Perspective,"[""Kartik Ahuja"", ""Jun Wang"", ""Amit Dhurandhar"", ""Karthikeyan Shanmugam"", ""Kush R. Varshney""]","[""invariant risk minimization"", ""IRM""]","In this work, we provide a sample complexity comparison of the recent invariant risk minimization (IRM) framework with the classic empirical risk minimization (ERM) to answer when is IRM better than ERM in terms of out-of-distribution generalization?",2010.16412,cs.LG,2020-10-30 17:55:30+00:00,2020-10-30 17:55:30+00:00
js62_xuLDDv,2022,Accept (Poster),False,Is Fairness Only Metric Deep? Evaluating and Addressing Subgroup Gaps in Deep Metric Learning,"['Natalie Dullerud', 'Karsten Roth', 'Kimia Hamidieh', 'Nicolas Papernot', 'Marzyeh Ghassemi']","[""deep metric learning"", ""fairness"", ""representation learning""]",We provide a benchmark for fairness in the scope of deep metric learning; investigate fairness impacts of learned representations on downstream classification; and provide a novel method for reducing subgroup gaps in deep metric learning methods.,,,,
jsM6yvqiT0W,2021,Reject,False,Improved Uncertainty Post-Calibration via Rank Preserving Transforms,"[""Yu Bai"", ""Tengyu Ma"", ""Huan Wang"", ""Caiming Xiong""]","[""uncertainty quantification"", ""calibration"", ""temperature scaling""]","Post-calibration with a high-capacity calibrator can improve over simple calibrators such as temperature scaling, if we make it guaranteed to maintain the accuracy.",,,,
jwgZh4Y4U7,2021,Reject,False,Temporal and Object Quantification Nets,"[""Jiayuan Mao"", ""Zhezheng Luo"", ""Chuang Gan"", ""Joshua B. Tenenbaum"", ""Jiajun Wu"", ""Leslie Pack Kaelbling"", ""Tomer Ullman""]","[""Temporal Modeling"", ""Object-Centric Representations""]",We present a framework for learning generalizable representations for complex activities by quantifying over both entities and time.,,,,
jxTRL-VOoQo,2022,Reject,False,Evaluating Deep Graph Neural Networks,"['Wentao Zhang', 'Zeang Sheng', 'Jiang Yuezihan', 'Yikuan Xia', 'Jun Gao', 'Zhi Yang', 'Bin CUI']","[""Deep"", ""Graph Neural Networks""]",A systematic experimental evaluation on the fundamental limitations of current GNN architecture designs.,,,,
jxdXSW9Doc,2021,Accept (Poster),False,Effective Distributed Learning with Random Features: Improved Bounds and Algorithms,"[""Yong Liu"", ""Jiankun Liu"", ""Shuqiang Wang""]","[""Risk bound"", ""statistical learning theory"", ""kernel methods""]",This papaer focuses on the studies of  the statistical properties of distributed KRR together with random features,,,,
jyDpkM9lntb,2021,Reject,True,Multi-Task Multicriteria Hyperparameter Optimization,"[""Kirill Akhmetzyanov"", ""Alexander Yuzhakov""]","[""hyperparameter optimization"", ""machine learning"", ""neural network""]",Pareto-based hyperparametric optimization method on several tasls with criteria significance coefficients,2002.06372,cs.LG,2020-02-15 12:47:53+00:00,2020-02-15 12:47:53+00:00
jz7tDvX6XYR,2021,Reject,False,Speeding up Deep Learning Training by Sharing Weights and Then Unsharing,"[""Shuo Yang"", ""Le Hou"", ""Xiaodan Song"", ""qiang liu"", ""Denny Zhou""]","[""fast training"", ""BERT"", ""transformer"", ""weight sharing"", ""deep learning""]",Speeding up deep learning training by sharing weights and then unsharing,,,,
jznizqvr15J,2021,Accept (Poster),False,In-N-Out: Pre-Training and Self-Training using Auxiliary Information for Out-of-Distribution Robustness,"[""Sang Michael Xie"", ""Ananya Kumar"", ""Robbie Jones"", ""Fereshte Khani"", ""Tengyu Ma"", ""Percy Liang""]","[""pre-training"", ""self-training theory"", ""robustness"", ""out-of-distribution"", ""unlabeled data"", ""auxiliary information"", ""multi-task learning theory"", ""distribution shift""]","Using auxiliary information as inputs hurts OOD, but using auxiliary information by pretraining and self-training improves in-distribution and OOD accuracies on real-world datasets, with theoretical guarantees in a linear multi-task setting.",2012.04550,cs.LG,2020-12-08 16:43:07+00:00,2021-04-07 16:47:17+00:00
k-sNDIPY-1T,2022,Reject,False,Modelling neuronal behaviour with time series regression: Recurrent Neural Networks on synthetic C. elegans data,"['GonÃ§alo Leote Cardoso Mestre', 'Ruxandra Barbulescu', 'Arlindo L. Oliveira', 'L. Miguel Silveira']","[""Data-driven models"", ""RNNs"", ""LSTMs"", ""GRUs"", ""C. Elegans"", ""Time series regression"", ""black-box""]",,,,,
k2Hm5Szfl5Z,2021,Reject,False,A new framework for tensor PCA based on trace invariants,"[""Mohamed Ouerfelli"", ""mohamed Tamaazousti"", ""Vincent Rivasseau""]","[""Tensor"", ""Principal Component Analysis"", ""Tensor decomposition"", ""trace invariant""]",,,,,
k2Om84I9JuX,2021,Reject,False,Descending through a Crowded Valley â Benchmarking Deep Learning Optimizers,"[""Robin Marc Schmidt"", ""Frank Schneider"", ""Philipp Hennig""]","[""Deep learning"", ""optimizers"", ""benchmark""]",A large-scale deep learning optimizer benchmark with open-sourced results for more meaningful optimizer comparisons.,,,,
k32ZY1CmE0,2022,Reject,False,How to train RNNs on chaotic data?,"['Zahra Monfared', 'Jonas Magdy Mikhaeil', 'Daniel Durstewitz']","[""dynamical systems"", ""back-propagation through time"", ""chaos"", ""recurrent neural networks"", ""LSTM"", ""Lyapunov spectrum"", ""time series""]",A mathematical framework that links RNN dynamics to the behavior of the loss gradients and offers a simple solution for training RNNs on chaotic data.,,,,
k6F-4Bw7LpV,2022,Reject,False,Distributional Generalization: Structure Beyond Test Error,"['Preetum Nakkiran', 'Yamini Bansal']","[""generalization"", ""empirical phenomena"", ""overparameterization""]","We study generalization beyond single-dimensional metrics, with new empirical behaviors and formal conjectures.",,,,
k7-s5HSSPE5,2022,Accept (Poster),False,Learning Invariant Representations on Multilingual Language Models for Unsupervised Cross-Lingual Transfer,"['Ruicheng Xian', 'Heng Ji', 'Han Zhao']","[""cross-lingual transfer"", ""unsupervised cross-lingual learning"", ""multilingual neural language model"", ""domain adaptation""]","We propose an importance-weighted domain adaptation method for unsupervised cross-lingual learning that is effective at correcting class prior shifts, a distributional property that negatively affects transfer performance.",,,,
k7efTb0un9z,2022,Accept (Poster),False,Learning to Schedule Learning rate with Graph Neural Networks,"['Yuanhao Xiong', 'Li-Cheng Lan', 'Xiangning Chen', 'Ruochen Wang', 'Cho-Jui Hsieh']","[""learning rate scheduling"", ""graph neural networks""]","We propose a novel Graph-Network-based Scheduler (GNS), which is both informative to to encode rich information and generalizable to different architectures.",,,,
k9EHBqXDEOX,2021,Reject,False,Asynchronous Advantage Actor Critic: Non-asymptotic Analysis and Linear Speedup,"[""Han Shen"", ""Kaiqing Zhang"", ""Mingyi Hong"", ""Tianyi Chen""]",[],,2012.15511,cs.LG,2020-12-31 09:07:09+00:00,2020-12-31 09:07:09+00:00
k9GoaycDeio,2021,Reject,False,Improving Local Effectiveness for Global Robustness Training,"[""JINGYUE LU"", ""M. Pawan Kumar""]",[],,2110.14030,cs.LG,2021-10-26 21:12:28+00:00,2021-10-26 21:12:28+00:00
k9bx1EfHI_-,2022,Accept (Poster),False,Self-Supervised Graph Neural Networks for Improved Electroencephalographic Seizure Analysis,"['Siyi Tang', 'Jared Dunnmon', 'Khaled Kamal Saab', 'Xuan Zhang', 'Qianying Huang', 'Florian Dubost', 'Daniel Rubin', 'Christopher Lee-Messer']","[""Graph neural network"", ""Self-supervision"", ""Interpretability"", ""Visualization"", ""Neuroscience"", ""Electroencephalography"", ""Seizure"", ""Epilepsy"", ""Time Series""]",Self-supervised graph neural networks for seizure detection and classification from EEG.,,,,
kAa9eDS0RdO,2022,Accept (Poster),False,Attention-based Interpretability with Concept Transformers,"['Mattia Rigotti', 'Christoph Miksovic', 'Ioana Giurgiu', 'Thomas Gschwind', 'Paolo Scotton']","[""attention"", ""transformer"", ""concepts"", ""interpretability""]",We the Concept Transformer an architecture that generalization attention from low-level input features to high-level concepts as a mechanism to ensure the interpretability of attention scores within a given application domain.,,,,
kB8DkEKSDH,2021,Reject,False,Hellinger Distance Constrained Regression,"[""Egor Rotinov""]","[""offline"", ""Reinforcement Learning"", ""off-policy"", ""control""]",This paper presents an offline reinforcement learning method based on the Hellinger distance constraint.,,,,
kBVJ2NtiY-,2021,Accept (Poster),False,Learning What To Do by Simulating the Past,"[""David Lindner"", ""Rohin Shah"", ""Pieter Abbeel"", ""Anca Dragan""]","[""imitation learning"", ""reward learning"", ""reinforcement learning""]",Imitating policies given just a single state sampled from a rollout from an expert.,2104.03946,cs.LG,2021-04-08 17:43:29+00:00,2021-05-03 10:51:40+00:00
kDF4Owotj5j,2022,Reject,False,Thinking Deeper With Recurrent Networks: Logical Extrapolation Without Overthinking,"['Arpit Bansal', 'Avi Schwarzschild', 'Eitan Borgnia', 'Zeyad Emam', 'Furong Huang', 'Micah Goldblum', 'Tom Goldstein']","[""Deep learning"", ""recurrent networks"", ""thinking"", ""extrapolation"", ""generalization""]",We propose new techniques for training recurrent networks to perform logical extrapolation without overthinking.,,,,
kDnal_bbb-E,2021,Accept (Poster),False,DialoGraph: Incorporating Interpretable Strategy-Graph Networks into Negotiation Dialogues,"[""Rishabh Joshi"", ""Vidhisha Balachandran"", ""Shikhar Vashishth"", ""Alan Black"", ""Yulia Tsvetkov""]","[""negotiation"", ""dialogue"", ""graph neural networks"", ""interpretability"", ""structure""]","We propose DialoGraph, a negotiation dialogue system that leverages Graph Attention Networks to model complex negotiation strategies while providing interpretability for the model via intermediate structures.",2106.00920,cs.CL,2021-06-02 03:34:36+00:00,2021-06-02 03:34:36+00:00
kE3vd639uRW,2021,Accept (Poster),False,LiftPool: Bidirectional ConvNet Pooling,"[""Jiaojiao Zhao"", ""Cees G. M. Snoek""]","[""bidirectional"", ""pooling""]",,,,,
kEnBH98BGs5,2021,Accept (Poster),False,Estimating informativeness of samples with Smooth Unique Information,"[""Hrayr Harutyunyan"", ""Alessandro Achille"", ""Giovanni Paolini"", ""Orchid Majumder"", ""Avinash Ravichandran"", ""Rahul Bhotika"", ""Stefano Soatto""]","[""sample information"", ""information theory"", ""stability theory"", ""ntk"", ""dataset summarization""]","We define, both in weight-space and function-space, a notion of unique information that an individual sample provides to the training of a deep network and show how to compute it efficiently for large networks using a linearization of the model.",2101.06640,cs.LG,2021-01-17 10:29:29+00:00,2021-03-28 08:24:40+00:00
kEvhVb452CC,2022,Reject,False,Transformed CNNs: recasting pre-trained convolutional layers with self-attention,"[""StÃ©phane d'Ascoli"", 'Levent Sagun', 'Giulio Biroli', 'Ari S. Morcos']","[""convolutional networks"", ""transformers"", ""hybrid"", ""fine-tuning""]",We reparametrize pre-trained convolutional layers as self-attention layers to improve their robustness.,,,,
kF9DZQQrU0w,2022,Accept (Poster),True,Information Bottleneck: Exact Analysis of (Quantized) Neural Networks,"['Stephan Sloth Lorenzen', 'Christian Igel', 'Mads Nielsen']","[""information bottleneck"", ""quantization"", ""neural network""]","We investigate the information bottleneck in quantized neural networks, allowing us to compute the exact mutual information and provide an analysis free from estimation artifacts.",2106.12912,cs.LG,2021-06-24 11:13:08+00:00,2021-06-24 11:13:08+00:00
kG0AtPi6JI1,2022,Accept (Poster),False,Visual Representation Learning over Latent Domains,"['Lucas Deecke', 'Timothy Hospedales', 'Hakan Bilen']","[""transfer learning"", ""latent domains"", ""computer vision""]","A new setting for learning over data with multiple latent domains is introduced, alongside new methods for it.",,,,
kGvXK_1qzyy,2021,Reject,False,Drift Detection in Episodic Data: Detect When Your Agent Starts Faltering,"[""Ido Greenberg"", ""Shie Mannor""]","[""Reinforcement learning reliability"", ""Reinforcement learning stability"", ""Drift detection"", ""Degradation test"", ""Bootstrapping""]","Optimal test for change detection in non-i.i.d settings, with applications to identifying deterioration in agent performance in episodic RL.",,,,
kHNKTO2sYH,2022,Reject,False,Repairing Systematic Outliers by Learning Clean Subspaces in VAEs,"['Simao Eduardo', 'Kai Xu', 'Alfredo Nazabal', 'Charles Sutton']","[""variational autoencoder"", ""deep generative models"", ""outlier detection"", ""data repair""]","To repair outliers resulting from systematic errors, we propose a semi-supervised VAE that learns separate representations for inliers and systematic errors.",,,,
kHSu4ebxFXY,2021,Accept (Spotlight),False,MARS: Markov Molecular Sampling for Multi-objective Drug Discovery,"[""Yutong Xie"", ""Chence Shi"", ""Hao Zhou"", ""Yuwei Yang"", ""Weinan Zhang"", ""Yong Yu"", ""Lei Li""]","[""drug discovery"", ""molecular graph generation"", ""MCMC sampling""]","In this paper, we propose a self-adaptive MCMC sampling method (MARS) to generate molecules targeting multiple objectives for drug discovery for multi-objective drug discovery.",2103.10432,q-bio.BM,2021-03-18 10:04:15+00:00,2021-03-18 10:04:15+00:00
kHkWgqOysk_,2022,Reject,False,On Pseudo-Labeling for Class-Mismatch Semi-Supervised Learning,"['Lu Han', 'Han-Jia Ye', 'De-Chuan Zhan']",[],,,,,
kJVVgJ-yCq,2021,Reject,False,Learning without Forgetting: Task Aware Multitask Learning for Multi-Modality Tasks,"[""Sathish Reddy Indurthi"", ""Mohd Abbas Zaidi"", ""Nikhil Kumar Lakumarapu"", ""Beomseok Lee"", ""HyoJung Han"", ""Sangha Kim"", ""Inchul Hwang""]","[""Deep Learning"", ""Joint Learning"", ""Meta Learning"", ""Multi-task Learning""]",Avoiding the issue of forgetfulness in the current multitask learning strategies by incorporating a task aware framework into the training.,,,,
kK3DlGuusi,2022,Reject,False,Quantized sparse PCA for neural network weight compression,"['Andrey Kuzmin', 'Mart Van Baalen', 'Markus Nagel', 'Arash Behboodi']","[""Model Compression"", ""neural network quantization"", ""sparse principal component analysis"", ""vector quantization""]",A neural network weight compression method based on sparse quantized PCA.,,,,
kKwFlM32HV5,2021,Reject,False,Natural World Distribution via Adaptive Confusion Energy Regularization,"[""Yen-Chi Hsu"", ""Cheng-Yao Hong"", ""Wan-Cyuan Fan"", ""Ding-Jie Chen"", ""Ming-Sui Lee"", ""davi geiger"", ""Tyng-Luh Liu""]","[""Fine-Grained Visual Classification"", ""long-tailed distribution"", ""confusion energy""]",We propose a novel confusion term which can adaptively addresses the fine-grained and long-tailed distribution simultaneously.,,,,
kLbhLJ8OT12,2021,Accept (Poster),True,Modelling Hierarchical Structure between Dialogue Policy and Natural Language Generator with Option Framework for Task-oriented Dialogue System,"[""Jianhong Wang"", ""Yuan Zhang"", ""Tae-Kyun Kim"", ""Yunjie Gu""]","[""Task-oriented Dialogue System"", ""Natural Language Processing"", ""Hierarchical Reinforcement Learning"", ""Policy Optimization""]",We propose a novel algorithm called HDNO for policy optimization for task-oriented dialogue system so that the performance on the comprehensibility of generated responses is improved compared with other RL-based algorithms.,2006.06814,cs.CL,2020-06-11 20:55:28+00:00,2021-02-19 17:26:40+00:00
kNKFOXleuC,2022,Accept (Poster),False,Confidence Adaptive Anytime Pixel-Level Recognition,"['Zhuang Liu', 'Hung-Ju Wang', 'Zhiqiu Xu', 'Trevor Darrell', 'Evan Shelhamer']","[""Efficient Inference"", ""Anytime Inference"", ""Semantic Segmentation"", ""Dense Prediction"", ""Computer Vision""]","First single-model anytime approach for pixel-level visual recognition; our model with redesigned exits and confidence adaptivity enables anytime inference, achieves the same level of final accuracy, and significantly reduces total computation. ",,,,
kO-wQWwqnO,2022,Reject,False,L2BGAN: An image enhancement model for image quality improvement and image analysis tasks without paired supervision,"['Jhilik Bhattacharya', 'Gianni Ramponi', 'Leonardo Gregorat', 'Shatrughan Modi']",[],Image Enhancement without paired supervision,,,,
kOA6rtPxyL,2021,Reject,False,A Lazy Approach to Long-Horizon Gradient-Based Meta-Learning,"[""Muhammad Abdullah Jamal"", ""Liqiang Wang"", ""Boqing Gong""]","[""meta-learning"", ""learning to learn""]",,,,,
kOtkgUGAVTX,2022,Reject,False,CIC: Contrastive Intrinsic Control for Unsupervised Skill Discovery,"['Michael Laskin', 'Hao Liu', 'Xue Bin Peng', 'Denis Yarats', 'Aravind Rajeswaran', 'Pieter Abbeel']","[""unsupervised learning"", ""reinforcement learning"", ""exploration""]",We introduce Contrastive Intrinsic Control (CIC) - a new unsupervised skill discovery algorithm that achieves leading performance on the Unsupervised Reinforcement Learning Benchmark,2202.00161,cs.LG,2022-02-01 00:36:29+00:00,2022-02-01 00:36:29+00:00
kOu3-S3wJ7,2022,Accept (Poster),True,Filling the G_ap_s: Multivariate Time Series Imputation by Graph Neural Networks,"['Andrea Cini', 'Ivan Marisca', 'Cesare Alippi']","[""graph neural networks"", ""missing data"", ""time series analysis"", ""time series imputation""]",We propose a graph neural network architecture for multivariate time series imputation and achieve state-of-the-art results on several benchmarks.,2108.00298,cs.LG,2021-07-31 17:47:10+00:00,2022-02-10 17:11:40+00:00
kPheYCFm0Od,2021,Reject,False,Variational Multi-Task Learning,"[""Jiayi Shen"", ""Xiantong Zhen"", ""Marcel Worring"", ""Ling Shao""]","[""multi-task learning"", ""variational Bayesian inference"", ""Gumbel-softmax priors""]","We develop variational multi-task learning, a general probabilistic inference framework for exploring task relatedness for both representations and classifiers.",,,,
kQ2SOflIOVC,2022,Accept (Poster),False,Towards Better Understanding and Better Generalization of Low-shot Classification in Histology Images with Contrastive Learning,"['Jiawei Yang', 'Hanbo Chen', 'Jiangpeng Yan', 'Xiaoyu Chen', 'Jianhua Yao']","[""Few shot learning"", ""Histology Image"", ""Knowledge Transferring""]",,,,,
kQMXLDF_z20,2022,Reject,False,Tackling Oversmoothing of GNNs with Contrastive Learning,"['Lecheng Zheng', 'Dongqi Fu', 'Jingrui He']","[""graph mining"", ""oversmoothing"", ""contrastive learning""]",,,,,
kR1hC6j48Tp,2022,Accept (Poster),False,GATSBI: Generative Adversarial Training for Simulation-Based Inference,"['Poornima Ramesh', 'Jan-Matthis Lueckmann', 'Jan Boelts', 'Ãlvaro Tejero-Cantero', 'David S. Greenberg', 'Pedro J. Goncalves', 'Jakob H. Macke']","[""Machine Learning"", ""simulation-based inference"", ""generative adversarial networks"", ""approximate bayesian computation"", ""data-driven modelling"", ""GANs"", ""SBI"", ""likelihood-free inference"", ""implicit models""]",Using generative adversarial networks for simulation-based inference,,,,
kSqyNY_QrD9,2022,Reject,False,Learning to Solve Multi-Robot Task Allocation with a Covariant-Attention based Neural Architecture,"['Steve Paul', 'Payam Ghassemi', 'Souma Chowdhury']","[""MRTA"", ""Reinforcement learning"", ""graph learning""]","A graph learning based method for multi-agent task allocation problems, which learns local structural information and  generalize to larger sized problem, without the need to retrain.",,,,
kSwqMH0zn1F,2022,Accept (Poster),False,PipeGCN: Efficient Full-Graph Training of Graph Convolutional Networks with Pipelined Feature Communication,"['Cheng Wan', 'Youjie Li', 'Cameron R. Wolfe', 'Anastasios Kyrillidis', 'Nam Sung Kim', 'Yingyan Lin']","[""Graph Neural Networks"", ""Graph Convolutional Networks"", ""Distributed Training"", ""Asynchronous Training"", ""Full-Graph Training"", ""Large-Graph Training"", ""Stale Features""]",,,,,
kUGYDTJUcuc,2022,Reject,False,Unifying Top-down and Bottom-up for Recurrent Visual Attention,['GANG CHEN'],"[""visual attention model"", ""reinforcement learning""]",Unify the bottom-up and top-down attention model for visual recognition,,,,
kUtux8k0G6y,2022,Reject,False,Avoiding Robust Misclassifications for Improved Robustness without Accuracy Loss,"['Yannick Merkli', 'Pavol Bielik', 'PETAR TSANKOV', 'Martin Vechev']",[],,,,,
kVZ6WBYazFq,2021,Reject,False,Constraint-Driven Explanations of Black-Box ML Models,"[""Aditya Aniruddha Shrotri"", ""Nina Narodytska"", ""Alexey Ignatiev"", ""Joao Marques-Silva"", ""Kuldeep S. Meel"", ""Moshe Vardi""]","[""Explainability"", ""constraints"", ""uniform sampling""]",Trustworthy and reliable explainations on user-defined constrained subspaces.,,,,
kWSeGEeHvF8,2021,Accept (Poster),False,Benchmarks for Deep Off-Policy Evaluation,"[""Justin Fu"", ""Mohammad Norouzi"", ""Ofir Nachum"", ""George Tucker"", ""ziyu wang"", ""Alexander Novikov"", ""Mengjiao Yang"", ""Michael R Zhang"", ""Yutian Chen"", ""Aviral Kumar"", ""Cosmin Paduraru"", ""Sergey Levine"", ""Thomas Paine""]","[""reinforcement learning"", ""off-policy evaluation"", ""benchmarks""]",A benchmark proposal for off-policy evaluation and policy selection.,,,,
kW_zpEmMLdP,2021,Accept (Poster),True,Learning Neural Event Functions for Ordinary Differential Equations,"[""Ricky T. Q. Chen"", ""Brandon Amos"", ""Maximilian Nickel""]","[""differential equations"", ""implicit differentiation"", ""point processes""]","We discuss how event handling in ODE solvers can be differentiated through, allowing us to extend Neural ODEs to cases of implicitly defined termination times and enabling learning of discrete events and discontinuous dynamics.",2011.03902,cs.LG,2020-11-08 04:33:54+00:00,2021-10-27 17:16:56+00:00
kWuBTQmkO8_,2022,Reject,False,MixRL: Data Mixing Augmentation for Regression using Reinforcement Learning,"['Seong-Hyeon Hwang', 'Steven Euijong Whang']","[""data augmentation"", ""regression"", ""mixup"", ""reinforcement learning""]",We propose a data augmentation framework for regression that learns for each example how many nearest neighbors it should be mixed with for the best model performance using reinforcement learning.,,,,
kXwdjtmMbUr,2021,Reject,False,Practical Evaluation of Out-of-Distribution Detection Methods for Image Classification,"[""Engkarat Techapanurak"", ""Takayuki Okatani""]","[""out-of-distribution"", ""novel class detection"", ""domain shift"", ""concept drift""]",This paper provides a practical evaluation of OOD detection methods that is missing in previous studies and will serve as a practitioners' guide.,2101.02447,cs.CV,2021-01-07 09:28:45+00:00,2021-01-07 09:28:45+00:00
kZ0UYdhqkNY,2022,Accept (Spotlight),False,Variational methods for simulation-based inference,"['Manuel GlÃ¶ckler', 'Michael Deistler', 'Jakob H. Macke']","[""likelihood-free inference"", ""simulation-based inference"", ""variational inference"", ""neural density estimation""]",We combine likelihood-estimation with variational inference to achieve a scalable approach for simulation-based inference.,,,,
kamUXjlAZuw,2022,Reject,False,On Learning with Fairness Trade-Offs,['Francois Buet-Golfouse'],"[""fairness"", ""statistical learning"", ""PAC"", ""social welfare""]",,,,,
kavTY__jxp,2022,Accept (Poster),False,Spatial Graph Attention and Curiosity-driven Policy for Antiviral Drug Discovery,"['Yulun Wu', 'Nicholas Choma', 'Andrew Deru Chen', 'Mikaela Cashman', 'Erica Teixeira Prates', 'Veronica G Melesse Vergara', 'Manesh B Shah', 'Austin Clyde', 'Thomas Brettin', 'Wibe Albert de Jong', 'Neeraj Kumar', 'Martha S Head', 'Rick L. Stevens', 'Peter Nugent', 'Daniel A Jacobson', 'James B Brown']","[""reinforcement learning"", ""graph neural network"", ""molecule generation"", ""drug discovery"", ""curiosity-driven policy""]",We developed a reinforcement learning framework that advances in exploiting spatial and attributional molecular information as well as exploring novel and synthesizable chemical structures for the purpose of antiviral drug discovery.,,,,
kcadk-DShNO,2022,Reject,False,Why be adversarial? Let's cooperate!: Cooperative Dataset Alignment via JSD Upper Bound,"['Wonwoong Cho', 'Ziyu Gong', 'David I. Inouye']",[],We propose non-adversarial unsupervised dataset alignment with invertible flows by proving JSD upper bound.,,,,
kcqSDWySoy,2021,Reject,False,Sobolev Training for the Neural Network Solutions of PDEs,"[""Hwijae Son"", ""Jin Woo Jang"", ""Woo Jin Han"", ""Hyung Ju Hwang""]","[""Sobolev Training"", ""Partial Differential Equations"", ""Neural Networks"", ""Convergence""]",We propose a class of novel loss functions for efficient training when solving PDEs using neural networks.,2101.08932,math.NA,2021-01-22 03:35:42+00:00,2021-01-22 03:35:42+00:00
kcrIligNnl,2022,Reject,False,Direct Molecular Conformation Generation,"['Jinhua Zhu', 'Yingce Xia', 'Chang Liu', 'Lijun Wu', 'Shufang Xie', 'Wengang Zhou', 'Tao Qin', 'Houqiang Li', 'Tie-Yan Liu']","[""Molecular Conformation Generation""]","We propose a method for molecular conformation generation, that directly outputs the coordinates of atoms instead of generating the interatomic distances first.",,,,
kcwyXtt7yDJ,2022,Accept (Poster),False,Graph-Relational Domain Adaptation,"['Zihao Xu', 'Hao He', 'Guang-He Lee', 'Bernie Wang', 'Hao Wang']","[""Graphs"", ""Network Topology"", ""Transfer Learning"", ""Domain Adaptation"", ""Adversarial Learning""]",,,,,
kdm4Lm9rgB,2021,Reject,False,Monotonic Robust Policy Optimization with Model Discrepancy,"[""Yuankun Jiang"", ""Chenglin Li"", ""Junni Zou"", ""Wenrui Dai"", ""Hongkai Xiong""]","[""Reinforcement Learning"", ""generalization""]",,,,,
keQjAwuC7j-,2022,Reject,False,"Two Birds, One Stone:  Achieving both Differential Privacy and Certified Robustness for Pre-trained Classifiers via Input Perturbation","['Pengfei Tang', 'Wenjie Wang', 'Xiaolan Gu', 'Jian Lou', 'Li Xiong', 'Ming Li']","[""Differential Privacy"", ""Certified Robustness"", ""Pre-trained Classifiers"", ""Input Perturbation""]","Our work stands as the first attempt to achieve both DP and certified robustness via input perturbation, and it perfectly works for the vastly exist, yet under-studied, pre-trained model setting.",,,,
keeCvPPd3vL,2022,Reject,False,Improved Image Generation via Sparsity,"['Roy Ganz', 'Michael Elad']","[""Sparse Modeling"", ""Image Generation""]",A sparse-modeling interpretation of image synthesis networks is shown to improve the performance of image generators and solution of inverse problems.,,,,
kezNJydWvE,2022,Accept (Poster),True,Clean Images are Hard to Reblur: Exploiting the Ill-Posed Inverse Task for Dynamic Scene Deblurring,"['Seungjun Nah', 'Sanghyun Son', 'Jaerin Lee', 'Kyoung Mu Lee']","[""Deblur"", ""Reblur"", ""Loss"", ""Test-time adaptation"", ""Self-supervised""]","Reblurring, the inverse task of deblurring, is used for supervised/self-supervised learning of deblurring and improves the image sharpness.",2104.12665,eess.IV,2021-04-26 15:49:21+00:00,2021-04-26 15:49:21+00:00
kiNEOCSEzt,2022,Reject,False,Estimating and Penalizing Induced Preference Shifts in Recommender Systems,"['Micah Carroll', 'Dylan Hadfield-Menell', 'Stuart Russell', 'Anca Dragan']","[""recommender systems"", ""preference shift"", ""preference estimation"", ""preference tampering""]",,,,,
kic8cng35wX,2021,Reject,False,Weak NAS Predictor Is All You Need,"[""Junru Wu"", ""Xiyang Dai"", ""Dongdong Chen"", ""Yinpeng Chen"", ""Mengchen Liu"", ""Ye Yu"", ""Zhangyang Wang"", ""Zicheng Liu"", ""Mei Chen"", ""Lu Yuan""]","[""performance predictor"", ""neural architecture search""]","We present a novel method to estimate weak predictors progressively in predictor-based neural architecture search. By coarse-to-fine iteration, the ranking of sampling space is refined gradually which helps find the optimal architectures eventually.",2102.10490,cs.LG,2021-02-21 01:58:43+00:00,2021-11-03 08:51:36+00:00
kj0_45Y4r9i,2022,Accept (Poster),True,Discriminative Similarity for Data Clustering,"['Yingzhen Yang', 'Ping Li']","[""Discriminative Similarity"", ""Rademacher Complexity"", ""Generalization Bound"", ""Data Clustering""]","We present a novel discriminative similarity for data clustering, and the discriminative similarity is induced by generalization error bound for unsupervised classifier ",2109.08675,cs.LG,2021-09-17 17:56:55+00:00,2021-09-17 17:56:55+00:00
kj8TBnJ0SXh,2022,Reject,False,FaceDet3D: Facial Expressions with 3D Geometric Detail Hallucination,"['ShahRukh Athar', 'Albert Pumarola', 'Francesc Moreno-noguer', 'Dimitris Samaras']",[],,,,,
kl8flCo98nm,2022,Reject,False,LEARNING DISTRIBUTIONS GENERATED  BY SINGLE-LAYER RELU  NETWORKS  IN  THE PRESENCE  OF ARBITRARY OUTLIERS,"['Saikiran Bulusu', 'Geethu Joseph', 'M. Cenk Gursoy', 'Pramod Varshney']","[""Learning distribution"", ""ReLU"", ""Truncated Gaussian"", ""Unsupervised learning""]",We are learning the parameters of the single-layer ReLU neural network assuming the bias vector is non-negative.,,,,
kmBFHJ5pr0o,2021,Reject,False,Distributed Adversarial Training to Robustify Deep Neural Networks at Scale,"[""Gaoyuan Zhang"", ""Songtao Lu"", ""Sijia Liu"", ""Xiangyi Chen"", ""Pin-Yu Chen"", ""Lee Martie"", ""Lior Horesh"", ""Mingyi Hong""]","[""Adversarial robustness"", ""min-max"", ""distributed learning""]","A principled distributed large-batch adversarial training framework which supports one-shot and iterative attack generation, gradient quantization, and training over lare-batch labeled and unlabeled data.",,,,
kmG8vRXTFv,2021,Accept (Oral),False,Augmenting Physical Models with Deep Networks for Complex Dynamics Forecasting,"[""Yuan Yin"", ""Vincent LE GUEN"", ""J\u00e9r\u00e9mie DONA"", ""Emmanuel de Bezenac"", ""Ibrahim Ayed"", ""Nicolas THOME"", ""patrick gallinari""]","[""spatio-temporal forecasting"", ""deep learning"", ""physics"", ""differential equations"", ""hybrid systems""]","We propose a new principled framework for combining physical models with deep data-driven networks, for which we provide theoretical decomposition guarantees.",,,,
kmqjgSNXby,2021,Accept (Poster),False,Autoregressive Dynamics Models for Offline Policy Evaluation and Optimization,"[""Michael R Zhang"", ""Thomas Paine"", ""Ofir Nachum"", ""Cosmin Paduraru"", ""George Tucker"", ""ziyu wang"", ""Mohammad Norouzi""]","[""Off-policy policy evaluation"", ""autoregressive models"", ""offline reinforcement learning"", ""policy optimization""]",We demonstrate autoregressive dynamics models outperform standard feedforward models and other baselines in offline policy evaluation and optimization.,,,,
kq4SNxgQI4v,2021,Reject,False,Efficient Neural Machine Translation with Prior Word Alignment,"[""Jeonghyeok Park"", ""hai zhao""]","[""Word Alignment"", ""Neural Machine Translation""]",,,,,
kqDCPX7eWS,2021,Reject,False,Local SGD Meets Asynchrony,"[""Bapi Chatterjee"", ""Vyacheslav Kungurtsev"", ""Dan Alistarh""]","[""SGD"", ""Data-parallel"", ""Asynchronous"", ""Optimization"", ""Non-convex"", ""Deep Neural Network""]",A new variant of decentralized distributed SGD to train deep neural netowrks ,,,,
krI-ahhgN2,2022,Reject,False,Self-Contrastive Learning,"['Sangmin Bae', 'Sungnyun Kim', 'Jongwoo Ko', 'Gihun Lee', 'SeungJong Noh', 'Se-Young Yun']","[""contrastive learning"", ""representation learning"", ""image classification"", ""mutual information""]","This paper proposes a novel contrastive framework, called Self-Contrastive (SelfCon) Learning, that self-contrasts within multiple outputs from the different levels of a multi-exit network.",,,,
kroqZZb-6s,2022,Reject,False,Cluster-based Feature Importance Learning for Electronic Health Record Time-series,"['Henrique Aguiar', 'Mauro Santos', 'Peter Watkinson', 'Tingting Zhu']","[""Clustering"", ""Electronic Health Records""]",A Feature-Time Interpretable model for Phenotyping Clusters in Electronic Health Records Time-series data,,,,
krz7T0xU9Z_,2021,Accept (Poster),False,The inductive bias of ReLU networks on orthogonally separable data,"[""Mary Phuong"", ""Christoph H Lampert""]","[""inductive bias"", ""implicit bias"", ""gradient descent"", ""ReLU networks"", ""max-margin"", ""extremal sector""]",We characterise the function learnt by two-layer ReLU nets trained on orthogonally separable data.,,,,
ks5nebunVn_,2021,Accept (Spotlight),False,Towards Robustness Against Natural Language Word Substitutions,"[""Xinshuai Dong"", ""Anh Tuan Luu"", ""Rongrong Ji"", ""Hong Liu""]","[""Natural Language Processing"", ""Adversarial Defense""]",Capture adversarial word substitutions in the vector space using convex hull towards robustness.,2107.13541,cs.CL,2021-07-28 17:55:08+00:00,2021-07-28 17:55:08+00:00
ks_uMcTPyW4,2022,Reject,False,Reinforcement Learning with Efficient Active Feature Acquisition,"['Haiyan Yin', 'Yingzhen Li', 'Sinno Pan', 'Cheng Zhang', 'Sebastian Tschiatschek']","[""Representation Learning"", ""Reinforcement Learning"", ""Active Learning""]",A novel active learning method for sequential decision making.,,,,
ku4sJKvnbwV,2021,Reject,False,Model-Based Reinforcement Learning via Latent-Space Collocation,"[""Oleh Rybkin"", ""Chuning Zhu"", ""Anusha Nagabandi"", ""Kostas Daniilidis"", ""Igor Mordatch"", ""Sergey Levine""]","[""visual model-based reinforcement learning"", ""visual planning"", ""long-horizon planning"", ""collocation""]",We propose a visual model-based reinforcement agent that uses collocation in the latent space to plan and outperforms prior shooting-based planning methods. ,2106.13229,cs.LG,2021-06-24 17:59:18+00:00,2021-08-07 23:57:31+00:00
kuqBCnJuD4Z,2021,Reject,False,FedMes: Speeding Up Federated Learning with Multiple Edge Servers,"[""Dong-Jun Han"", ""Minseok Choi"", ""Jungwuk Park"", ""Jaekyun Moon""]","[""Federated Learning"", ""Edge Servers"", ""Wireless Edge Networks""]",We propose a scheme to speed up federated learning in an increasingly practical setup with multiple edge servers having their own local coverages.,,,,
kvhzKz-_DMF,2021,Accept (Poster),False,Variational Information Bottleneck for Effective Low-Resource Fine-Tuning,"[""Rabeeh Karimi mahabadi"", ""Yonatan Belinkov"", ""James Henderson""]","[""Transfer learning"", ""NLP"", ""large-scale pre-trained language models"", ""over-fitting"", ""robust"", ""biases"", ""variational information bottleneck""]",We propose to use Variational Information Bottleneck  to suppress irrelevant features for an effective fine-tuning of large-scale language models in low-resource scenarios. ,,,,
kxARp2zoqAk,2022,Reject,False,Information-Aware Time Series Meta-Contrastive Learning,"['Dongsheng Luo', 'Wei Cheng', 'Yingheng Wang', 'Dongkuan Xu', 'Jingchao Ni', 'Wenchao Yu', 'Xuchao Zhang', 'Yanchi Liu', 'Haifeng Chen', 'Xiang Zhang']","[""Information-Aware Time Series Meta-Contrastive Learning""]","Guilded by information theory, we employ meta-learning mechanism to propose an information-aware time series contrastive learning approach that adaptively generates suitable task-specific augmentations for contrastive representation learning.",,,,
kyaIeYj4zZ,2021,Accept (Poster),False,GraPPa: Grammar-Augmented Pre-Training for Table Semantic Parsing,"[""Tao Yu"", ""Chien-Sheng Wu"", ""Xi Victoria Lin"", ""bailin wang"", ""Yi Chern Tan"", ""Xinyi Yang"", ""Dragomir Radev"", ""richard socher"", ""Caiming Xiong""]","[""text-to-sql"", ""semantic parsing"", ""pre-training"", ""nlp""]",Language model pre-training for table semantic parsing.,,,,
kz6rsFehYjd,2022,Reject,False,Towards General Robustness to Bad Training Data,"['Tianhao Wang', 'Yi Zeng', 'Ming Jin', 'Ruoxi Jia']","[""General Robustness"", ""Data Valuation"", ""Data Utility Learning""]","We formulate the problem of good/bad data selection as utility optimization, propose a theoretical framework for analyzing data selection heuristics, and develop an algorithmic framework to detect a variety of and even unknown data issues. ",,,,
l-LGlk4Yl6G,2021,Accept (Poster),False,Mixed-Features Vectors and Subspace Splitting,"[""Alejandro Pimentel-Alarc\u00f3n"", ""Daniel L. Pimentel-Alarc\u00f3n""]",[],,,,,
l-PrrQrK0QR,2021,Accept (Poster),False,Dataset Meta-Learning from Kernel Ridge-Regression,"[""Timothy Nguyen"", ""Zhourong Chen"", ""Jaehoon Lee""]","[""dataset distillation"", ""dataset compression"", ""meta-learning"", ""kernel-ridge regression"", ""neural kernels"", ""infinite-width networks"", ""dataset corruption""]","We introduce a meta-learning approach to distilling datasets, achieving state of the art performance for kernel-ridge regression and neural networks.",,,,
l0V53bErniB,2021,Accept (Poster),False,Combining Physics and Machine Learning for Network Flow Estimation,"[""Arlei Lopes da Silva"", ""Furkan Kocayusufoglu"", ""Saber Jafarpour"", ""Francesco Bullo"", ""Ananthram Swami"", ""Ambuj Singh""]","[""graphs"", ""networks"", ""bilevel optimization"", ""metalearning"", ""flow graphs""]",Paper solves missing flow estimation problem using bilevel optimization and deep learning.,,,,
l0mSUROpwY,2021,Accept (Poster),False,Intrinsic-Extrinsic Convolution and Pooling for Learning on 3D Protein Structures,"[""Pedro Hermosilla"", ""Marco Sch\u00e4fer"", ""Matej Lang"", ""Gloria Fackelmann"", ""Pere-Pau V\u00e1zquez"", ""Barbora Kozlikova"", ""Michael Krone"", ""Tobias Ritschel"", ""Timo Ropinski""]","[""classification"", ""bioinformatics""]",We present a new neural network architecture to process 3D protein structures.,,,,
l35SB-_raSQ,2021,Accept (Poster),False,A Hypergradient Approach to Robust Regression without Correspondence,"[""Yujia Xie"", ""Yixiu Mao"", ""Simiao Zuo"", ""Hongteng Xu"", ""Xiaojing Ye"", ""Tuo Zhao"", ""Hongyuan Zha""]","[""Regression without correspondence"", ""differentiable programming"", ""first-order optimization"", ""Sinkhorn algorithm""]",We propose a differentiable programming framework for the regression without correspondence problem.,2012.00123,cs.LG,2020-11-30 21:47:38+00:00,2021-02-11 16:47:12+00:00
l3SDgUh7qZO,2022,Accept (Spotlight),True,SphereFace2: Binary Classification is All You Need for Deep Face Recognition,"['Yandong Wen', 'Weiyang Liu', 'Adrian Weller', 'Bhiksha Raj', 'Rita Singh']",[],A novel deep face recognition framework,2108.01513,cs.CV,2021-08-03 13:58:45+00:00,2021-08-03 13:58:45+00:00
l3YcqzaPlx0,2021,Reject,False,Neighbor2Seq: Deep Learning on Massive Graphs by Transforming Neighbors to Sequences,"[""Meng Liu"", ""Shuiwang Ji""]","[""Graph representation learning"", ""large-scale"", ""sequence""]",Transforming hierarchical neighborhoods to ordered sequences and enabling general deep learning methods on massive-scale graphs.,,,,
l3gNU1KStIC,2021,Reject,True,Stochastic Inverse Reinforcement Learning ,"[""Ce Ju""]","[""Inverse Reinforcement Learning"", ""Stochastic Methods"", ""MCEM""]",We generalize the IRL problem to a well-posed expectation optimization problem stochastic inverse reinforcement learning (SIRL) problem to recover the probability distribution for reward functions. ,1905.08513,cs.LG,2019-05-21 09:29:18+00:00,2020-09-11 03:42:17+00:00
l431c_2eGO2,2022,Reject,False,Mix-MaxEnt: Creating High Entropy Barriers To Improve Accuracy and Uncertainty Estimates of Deterministic Neural Networks,"['Francesco Pinto', 'Harry Yang', 'Ser-Nam Lim', 'Philip Torr', 'Puneet K. Dokania']","[""regularizer"", ""maximum entropy"", ""uncertainty estimation"", ""data-shift robustness"", ""calibration"", ""out-of-distribution detection""]",,,,,
l4IHywGq6a,2022,Accept (Oral),False,Data-Efficient Graph Grammar Learning for Molecular Generation,"['Minghao Guo', 'Veronika Thost', 'Beichen Li', 'Payel Das', 'Jie Chen', 'Wojciech Matusik']","[""molecular generation"", ""graph grammar"", ""data efficient generative model""]",,,,,
l5aSHXi8jG5,2022,Accept (Poster),False,Demystifying Limited Adversarial Transferability in Automatic Speech Recognition Systems,"['Hadi Abdullah', 'Aditya Karlekar', 'Vincent Bindschaedler', 'Patrick Traynor']","[""optimization attacks"", ""transferability"", ""adversarial machine learning""]",Uncover factors that limit transferability of the popular optimization attacks in the automatic speech recognition systems.,,,,
l8It-0lE5e7,2022,Accept (Poster),False,Implicit Bias of Adversarial Training for Deep Neural Networks,"['Bochen Lv', 'Zhanxing Zhu']","[""adversarial training"", ""adversarial examples""]",We provide theoretical understandings of the implicit bias imposed by adversarial training for homogeneous deep neural networks without explicit regularization.,,,,
l9tb1bKyfMn,2022,Reject,False,LMSA: Low-relation Mutil-head Self-Attention Mechanism in Visual Transformer,"['JingJie Wang', 'Xiang Wei', 'Xiaoyu Liu']",[],,,,,
lD8qAOTu5FJ,2022,Reject,False,Addressing the Stability-Plasticity Dilemma via Knowledge-Aware Continual Learning,"['Ghada Sokar', 'Decebal Constantin Mocanu', 'Mykola Pechenizkiy']","[""Continual learning"", ""Class incremental learning"", ""Stability-plasticity dilemma"", ""Sparse neural networks"", ""Knowledge-Awareness""]",,,,,
lDjgALS4qs8,2021,Reject,False,To Understand Representation of Layer-aware Sequence Encoders as Multi-order-graph,"[""Sufeng Duan"", ""hai zhao"", ""Rui Wang""]","[""multigraph"", ""Transformer"", ""natural language process""]",This paper proposes a unified explanation of representation for layer-aware neural sequence encoders.,2101.06397,cs.CL,2021-01-16 08:12:03+00:00,2021-01-16 08:12:03+00:00
lE1AB4stmX,2021,Reject,True,A Transformer-based Framework for Multivariate Time Series Representation Learning,"[""George Zerveas"", ""Srideepika Jayaraman"", ""Dhaval Patel"", ""Anuradha Bhamidipaty"", ""Carsten Eickhoff""]","[""transformer"", ""multivariate time series"", ""unsupervised representation learning"", ""deep learning""]", We propose a transformer-based framework for unsupervised representation learning of multivariate time series,2010.02803,cs.LG,2020-10-06 15:14:46+00:00,2020-12-08 21:57:10+00:00
lEB5Dnz_MmH,2022,Reject,False,A Collaborative Attention Adaptive Network for Financial Market Forecasting,"['Qiuyue Zhang', 'Yunfeng Zhang', 'Fangxun Bao', 'Caiming Zhang', 'Peide Liu', 'Xunxiang Yao']","[""Financial market forecasting"", ""Deep fusion"", ""Collaborative attention""]","We propose a collaborative attention adaptive Transformer approach to financial market forecasting, including parallel extraction of texts and price features, deep fusion and a joint feature processing module, that can deeply fuse tweets and  prices.",,,,
lEZIPgMIB1,2021,Reject,False,Parametric UMAP: learning embeddings with deep neural networks for representation and semi-supervised learning,"[""Tim Sainburg"", ""Leland McInnes"", ""Timothy Q Gentner""]","[""unsupervised learning"", ""representation learning"", ""dimensionality reduction"", ""UMAP"", ""semi-supervised learning""]",We propose a parametric variant of UMAP and applications in representation and semi-supervised learning.,,,,
lEoFUoMH2Uu,2022,Reject,False,Foreground-attention in neural decoding: Guiding Loop-Enc-Dec to reconstruct visual stimulus images from fMRI,"['Kai Chen', 'Yongqiang Ma', 'Mingyang Sheng', 'Nanning Zheng']","[""neural decoding"", ""visual stimulus image reconstruction"", ""visual attention"", ""encoder-decoder"", ""fMRI""]","We propose a visual attention guidance method to reconstruct visual stimulus images from fMRI, which decodes visual attention (Foreground-attention) from fMRI and guides Loop-Enc-Dec to reconstruct visual stimulus images by F-attention.",,,,
lH2ukHnGDdq,2021,Reject,False,Data augmentation for deep learning based accelerated MRI reconstruction,"[""Zalan Fabian"", ""Reinhard Heckel"", ""Mahdi Soltanolkotabi""]","[""fast MRI"", ""deep learning for inverse problems"", ""data augmentation"", ""unrolled networks"", ""learning with limited data""]",We develop physics inspired data augmentation to reduce the required training data for deep learning based accelerated MRI reconstruction.,,,,
lJgbDxGhJ4r,2021,Reject,False,OpenCoS: Contrastive Semi-supervised Learning for Handling Open-set Unlabeled Data,"[""Jongjin Park"", ""Sukmin Yun"", ""Jongheon Jeong"", ""Jinwoo Shin""]","[""semi-supervised learning"", ""realistic semi-supervised learning"", ""class-distribution mismatch"", ""unsupervised learning""]","We utilize unsupervised representations to handle realistic semi-supervised learning, where the class distributions of labeled and unlabeled datasets do not match.",2107.08943,cs.CV,2021-06-29 06:10:05+00:00,2021-06-29 06:10:05+00:00
lJuOUWlAC8i,2021,Reject,False,Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning,"[""Jun Yan"", ""Mrigank Raman"", ""Tianyu Zhang"", ""Ryan Rossi"", ""Handong Zhao"", ""Sungchul Kim"", ""Nedim Lipka"", ""Xiang Ren""]",[],,,,,
lKcq2fe-HB,2022,Reject,False,Metrics Matter: A Closer Look on Self-Paced Reinforcement Learning,"['Pascal Klink', 'Haoyi Yang', 'Jan Peters', 'Joni Pajarinen']","[""Curriculum Learning"", ""Reinforcement Learning"", ""Self-Paced Learning""]","We investigate Self-Paced Reinforcement Learning (SPRL) (a Curriculum Reinforcement Learning (CRL) algorithm), showing that its theoretical definition can be unsuited for CRL and taking a look at a potential solution for this problem.",,,,
lKrchawH4sB,2022,Reject,False,Heterologous  Normalization,"['Chunjie Luo', 'Jianfeng Zhan', 'Lei Wang', 'Wanling Gao']",[],,,,,
lL3lnMbR4WU,2022,Accept (Poster),True,Open-vocabulary Object Detection via Vision and Language Knowledge Distillation,"['Xiuye Gu', 'Tsung-Yi Lin', 'Weicheng Kuo', 'Yin Cui']","[""Open-vocabulary recognition"", ""Object detection"", ""Knowledge distillation""]","We propose using knowledge distillation to train an object detector that can detect objects with arbitrary text inputs, outperforming its supervised counterparts on rare categories.",2104.13921,cs.CV,2021-04-28 17:58:57+00:00,2021-10-13 03:48:03+00:00
lNreaMZf9X,2022,Reject,False,Learning Dynamics Models for Model Predictive Agents,"['Michael Lutter', 'Leonard Hasenclever', 'Arunkumar Byravan', 'Gabriel Dulac-Arnold', 'Piotr Trochim', 'Nicolas Heess', 'Josh Merel', 'Yuval Tassa']","[""Model Learning"", ""Model Based Reinforcement Learning"", ""Control""]",In-depth evaluation of the model learning design space for model predictive control.,,,,
lNrtNGkr-vw,2021,Reject,False,Linear Representation Meta-Reinforcement Learning for Instant Adaptation,"[""Matt Peng"", ""Banghua Zhu"", ""Jiantao Jiao""]","[""meta reinforcement learning"", ""out-of-distribution"", ""reinforcement learning""]",Our paper proposes a meta-reinforcement learning algorithm that generalizes well to highly extrapolated test tasks with an adaptation process that showcases a significantly reduced run-time.,2101.04750,cs.LG,2021-01-12 20:56:34+00:00,2021-01-12 20:56:34+00:00
lP11WtZwquE,2022,Reject,False,Language Model Pre-training on True Negatives,"['Zhuosheng Zhang', 'hai zhao', 'Masao Utiyama', 'Eiichiro Sumita']","[""Pre-trained Language Models"", ""Masked Language Modeling"", ""False Negatives"", ""Natural Language Understanding""]",We present a principled semantic correction approach to counteract false negative predictions and encourage pre-training language models on true negatives.,,,,
lQI_mZjvBxj,2022,Accept (Poster),True,Towards Model Agnostic Federated Learning Using Knowledge Distillation,"['Andrei Afonin', 'Sai Praneeth Karimireddy']","[""Federated Learning"", ""Knowledge Distillation"", ""Model Agnostic Communication"", ""Kernel Regression""]","We develop a rich yet tractable framework for analyzing distillation based federated learning algorithms, using which we draw some surprising insights.",2110.15210,cs.LG,2021-10-28 15:27:51+00:00,2021-10-28 15:27:51+00:00
lQdXeXDoWtI,2021,Accept (Poster),True,In Search of Lost Domain Generalization,"[""Ishaan Gulrajani"", ""David Lopez-Paz""]","[""domain generalization"", ""reproducible research""]",Our ERM baseline achieves state-of-the-art performance across many domain generalization benchmarks,2007.01434,cs.LG,2020-07-02 23:08:07+00:00,2020-07-02 23:08:07+00:00
lSijhyKKsct,2021,Reject,False,Reinforcement Learning with Latent Flow,"[""Wenling Shang"", ""Xiaofei Wang"", ""Aravind Rajeswaran"", ""Aravind Srinivas"", ""Yang Gao"", ""Pieter Abbeel"", ""Michael Laskin""]","[""reinforcement learning"", ""deep learning"", ""machine learning"", ""deep reinforcement learning""]",We investigate explicit encoding of temporal information in Deep Reinforcement Learning through latent vector differences and show SOTA results on the DeepMind control suite benchmark.,,,,
lTqGXfn9Tv,2022,Accept (Poster),False,Phenomenology of Double Descent in Finite-Width Neural Networks,"['Sidak Pal Singh', 'Aurelien Lucchi', 'Thomas Hofmann', 'Bernhard SchÃ¶lkopf']","[""double descent"", ""generalization"", ""neural networks"", ""hessian"", ""flatness""]",We provide a theoretical analysis of double descent that applies for finite-width neural networks and delivers insights into the properties of neural networks (and its Hessian spectrum) near the interpolation threshold.,,,,
lU5Rs_wCweN,2021,Accept (Poster),True,Taking Notes on the Fly Helps Language Pre-Training,"[""Qiyu Wu"", ""Chen Xing"", ""Yatao Li"", ""Guolin Ke"", ""Di He"", ""Tie-Yan Liu""]","[""Natural Language Processing"", ""Pre-training""]",We improve the efficiency of language pre-training methods through providing better data utilization.,2008.01466,cs.CL,2020-08-04 11:25:09+00:00,2021-03-14 15:37:11+00:00
lVgB2FUbzuQ,2021,Accept (Spotlight),False,Predicting Infectiousness for Proactive Contact Tracing,"[""Yoshua Bengio"", ""Prateek Gupta"", ""Tegan Maharaj"", ""Nasim Rahaman"", ""Martin Weiss"", ""Tristan Deleu"", ""Eilif Benjamin Muller"", ""Meng Qu"", ""victor schmidt"", ""Pierre-luc St-charles"", ""hannah alsdurf"", ""Olexa Bilaniuk"", ""david buckeridge"", ""gaetan caron"", ""pierre luc carrier"", ""Joumana Ghosn"", ""satya ortiz gagne"", ""Christopher Pal"", ""Irina Rish"", ""Bernhard Sch\u00f6lkopf"", ""abhinav sharma"", ""Jian Tang"", ""andrew williams""]","[""covid-19"", ""contact tracing"", ""distributed inference"", ""set transformer"", ""deepset"", ""epidemiology"", ""applications"", ""domain randomization"", ""retraining"", ""simulation""]","Proposes a framework called Proactive Contact Tracing which uses distributed inference of expected Covid-19 infectiousness to provide individualized, private recommendations.",,,,
lWaz5a9lcFU,2021,Accept (Poster),False,EEC: Learning to Encode and Regenerate Images for Continual Learning,"[""Ali Ayub"", ""Alan Wagner""]","[""Continual Learning"", ""Catastrophic Forgetting"", ""Cognitively-inspired Learning""]",We train autoencoders with Neural Style Transfer to replay old tasks data for continual learning. The encoded features are converted into centroids and covariances to keep memory footprint from growing while keeping classifier performance stable.,,,,
lXW6Sk1075v,2021,Reject,False,FORK: A FORward-looKing Actor for Model-Free Reinforcement Learning,"[""Honghao Wei"", ""Lei Ying""]","[""Reinforcement Learning"", ""Actor Critic"", ""Policy Gradient"", ""Model Free""]","A new type of actor named forward-looking actor or FORK for short, for Actor-Critic reinforcement learning algorithms. ",,,,
lXoWPoi_40,2021,Reject,True,Wide-minima Density Hypothesis and the Explore-Exploit Learning Rate Schedule,"[""Nikhil Iyer"", ""V Thejas"", ""Nipun Kwatra"", ""Ramachandran Ramjee"", ""Muthian Sivathanu""]","[""deep learning"", ""learning rate"", ""generalization""]","We present a hypothesis on the density of wide and narrow minima in deep learning landscapes, which also motivates a principled explore-exploit learning rate schedule.",2003.03977,cs.LG,2020-03-09 09:01:53+00:00,2021-06-01 05:48:04+00:00
lY0-7bj0Vfz,2022,Accept (Poster),False,Prototype memory and attention mechanisms for few shot image generation,"['Tianqin Li', 'Zijie Li', 'Andrew Luo', 'Harold Rockwell', 'Amir Barati Farimani', 'Tai Sing Lee']","[""neuroscience"", ""deep learning""]",computational role for âprototype concept neuronsâ in top-down synthesis path,,,,
l_amHf1oaK,2022,Accept (Poster),False,Complete Verification via Multi-Neuron Relaxation Guided Branch-and-Bound,"['Claudio Ferrari', 'Mark Niklas Mueller', 'Nikola JovanoviÄ', 'Martin Vechev']","[""Certified Robustness"", ""Branch-and-Bound"", ""Convex Relaxation""]",We obtain a state-of-the-art GPU-based neural network verifier by leveraging tight multi-neuron constraints in a Branch-and-Bound setting.,,,,
lbHDMllIYI1,2021,Reject,False,Sparse matrix products for neural network compression,"[""Luc Giffon"", ""hachem kadri"", ""Stephane Ayache"", ""Ronan Sicre"", ""thierry artieres""]","[""Compression"", ""sparsity""]",The paper explores high rate neural networks compression with factorisation of weight matrices as product of sparse matrices. ,,,,
lbauk6wK2-y,2022,Accept (Poster),False,Object Pursuit: Building a Space of Objects via Discriminative Weight Generation,"['Chuanyu Pan', 'Yanchao Yang', 'Kaichun Mo', 'Yueqi Duan', 'Leonidas Guibas']","[""object-centric"", ""continual learning"", ""representation learning"", ""hypernetwork""]",We propose a novel framework named object pursuit that can continuously learn object-centric representations using training data collected from interactions with individual objects.,2112.07954,cs.CV,2021-12-15 08:25:30+00:00,2021-12-18 03:33:34+00:00
lbc44k2jgnX,2021,Reject,False,Random Coordinate Langevin Monte Carlo,"[""Zhiyan Ding"", ""Qin Li"", ""Jianfeng Lu"", ""Stephen Wright""]","[""Random coordinate descent"", ""Langevin dynamics"", ""Monte Carlo sampling""]",We propose and investigate a coordinate based sampling method: Random Coordinate Langevin Monte Carlo (RC-LMC).,,,,
lcNa5mQ-CSb,2021,Reject,False,Score-based Causal Discovery from Heterogeneous Data,"[""Chenwei Ding"", ""Biwei Huang"", ""Mingming Gong"", ""Kun Zhang"", ""Tongliang Liu"", ""Dacheng Tao""]","[""causal discovery"", ""heterogeneous data"", ""structure learning""]",The paper proposes a novel score-based approach for discovering the structure of a causal graph in the presence of heterogeneous data,,,,
ldkunzUzRWj,2022,Reject,False,A Simple and Debiased Sampling Method for Personalized Ranking,"['Lu Yu', 'Shichao Pei', 'Chuxu Zhang', 'Xiangliang Zhang']","[""personalized ranking"", ""class-imbalance"", ""negative sampling"", ""deep learning""]",,,,,
ldxlzGYWDmW,2021,Accept (Poster),False,Effective Abstract Reasoning with Dual-Contrast Network,"[""Tao Zhuo"", ""Mohan Kankanhalli""]","[""abstract reasoning"", ""raven's progressive matrices"", ""deep learning""]",We propose a simple yet effective Dual-Contrast Network (DCNet) to solve Raven's progressive matrices without using auxiliary annotations and assumptions.,,,,
le9LIliDOG,2021,Reject,False,Efficient Long-Range Convolutions for Point Clouds,"[""Yifan Peng"", ""Lin Lin"", ""Lexing Ying"", ""Leonardo Zepeda-Nunez""]","[""global convolution"", ""point cloud"", ""graph-cnn"", ""NUFFT""]",,,,,
lf0W6tcWmh-,2022,Reject,False,Towards understanding how momentum improves generalization in deep learning,"['Samy Jelassi', 'Yuanzhi Li']","[""Deep learning theory"", ""non-convex optimization""]",,,,,
lf7st0bJIA5,2021,Accept (Poster),False,Unsupervised Discovery of 3D Physical Objects from Video,"[""Yilun Du"", ""Kevin A. Smith"", ""Tomer Ullman"", ""Joshua B. Tenenbaum"", ""Jiajun Wu""]","[""unsupervised object discovery"", ""surprisal"", ""scene decomposition"", ""physical scene understanding""]",We propose an unsupervised framework for discovery 3D physical objects and show that these 3D objects to be used for tasks mimicking early infant cognition.,,,,
lfJpQn3xPV-,2021,Reject,False,Online Learning of Graph Neural Networks: When Can Data Be Permanently Deleted,"[""Lukas Paul Achatius Galke"", ""Benedikt Franke"", ""Tobias Zielke"", ""Ansgar Scherp""]","[""graph neural networks"", ""online learning""]","In online learning setups, GNNs need only very few past time steps to maintain a high accuracy.",,,,
lgNx56yZh8a,2021,Accept (Poster),True,Bayesian Few-Shot Classification with One-vs-Each PÃ³lya-Gamma Augmented Gaussian Processes,"[""Jake Snell"", ""Richard Zemel""]","[""few-shot learning"", ""gaussian processes"", ""bayesian deep learning"", ""uncertainty estimation""]","We propose a Gaussian process approach to few-shot classification based on the one-vs-each softmax approximation and PÃ³lya-Gamma augmentation, and demonstrate competitive few-shot accuracy and strong uncertainty quantification.",2007.10417,cs.LG,2020-07-20 19:10:41+00:00,2021-01-21 19:54:57+00:00
lgOylcEZQgr,2022,Reject,False,Online Unsupervised Learning of Visual Representations and Categories,"['Mengye Ren', 'Tyler R. Scott', 'Michael Louis Iuzzolino', 'Michael Curtis Mozer', 'Richard Zemel']","[""Unsupervised learning"", ""self-supervised learning"", ""few-shot learning"", ""visual representation learning"", ""visual category learning""]",,,,,
liV-Re74fK,2022,Reject,False,Density Estimation for Conservative Q-Learning,"['Paul Daoudi', 'Merwan Barlier', 'Ludovic Dos Santos', 'Aladin Virmaux']","[""Offline Reinforcement Learning"", ""Batch Reinforcement Learning""]","In this work, we aim to improve Batch Reinforcement Learning by considering relevant neighbourhoods induced by the dataset density.",,,,
ljCoTzUsdS,2022,Reject,True,Distinguishing rule- and exemplar-based generalization in learning systems,"['Ishita Dasgupta', 'Erin Grant', 'Thomas L. Griffiths']","[""inductive bias"", ""combinatorial generalization"", ""cognitive psychology"", ""robustness to spurious correlation""]","We distinguish exemplar- from rule-based reasoning in learning systems, controlling for biases at the level of specific features, with implications for systematicity in combinatorial domains and sensitivity to spurious correlations.",2110.04328,cs.LG,2021-10-08 18:37:59+00:00,2021-10-08 18:37:59+00:00
ljxWpdBl4V,2022,Accept (Poster),False,Closed-form Sample Probing for Learning Generative Models in Zero-shot Learning,"['Samet Cetin', 'Orhun BuÄra Baran', 'Ramazan Gokberk Cinbis']","[""zero-shot learning"", ""generative zero-shot learning"", ""generative models""]",We show how to train a conditional generative model in a way that directly maximizes the value of its samples for zero-shot model training purposes.,,,,
lkQ7meEa-qv,2022,Reject,False,Learning Neural Acoustic Fields,"['Andrew Luo', 'Yilun Du', 'Michael J. Tarr', 'Joshua B. Tenenbaum', 'Antonio Torralba', 'Chuang Gan']","[""Audio-Visual Learning"", ""Acoustic""]","We propose neural acoustic fields, a continuous representation of the acoustics of a scene",,,,
lmTWnm3coJJ,2021,Accept (Poster),False,Robust Curriculum Learning: from clean label detection to noisy label self-correction,"[""Tianyi Zhou"", ""Shengjie Wang"", ""Jeff Bilmes""]","[""curriculum learning"", ""noisy label"", ""robust learning"", ""training dynamics"", ""neural networks""]","RoCL improves noisy label learning by periodical transitions from supervised learning of clean labeled data to self-supervision of wrongly-labeled data, where the data are selected according to training dynamics.",,,,
lnEaqbTJIRz,2022,Accept (Spotlight),True,The Inductive Bias of In-Context Learning: Rethinking Pretraining Example Design,"['Yoav Levine', 'Noam Wies', 'Daniel Jannai', 'Dan Navon', 'Yedid Hoshen', 'Amnon Shashua']","[""Language Modeling"", ""Pretraining"", ""Self-attention"", ""Transformers"", ""Expressivity"", ""Separation Rank"", ""Sentence Embeddings""]","We prove that pertained LMs model stronger dependencies between sentences that were shown in same training example, thus indicating benefits of better informed ""pretraining example design""",2110.04541,cs.CL,2021-10-09 11:05:16+00:00,2021-10-25 15:51:31+00:00
lo7GKwmakFZ,2021,Reject,False,Average Reward Reinforcement Learning with Monotonic Policy Improvement,"[""Yiming Zhang"", ""Keith W. Ross""]","[""Reinforcement Learning"", ""Deep Reinforcement Learning"", ""Average Reward"", ""Policy Optimization"", ""Model Free RL""]",Theoretically extend trust-region based methods to the average reward setting and empirically demonstrate their efficacy on continuing control tasks.,,,,
loe6h28yoq,2021,Reject,False,Certified Robustness of Nearest Neighbors against Data Poisoning Attacks,"[""Jinyuan Jia"", ""Xiaoyu Cao"", ""Neil Zhenqiang Gong""]",[],,2012.03765,cs.CR,2020-12-07 15:04:48+00:00,2021-02-04 02:20:42+00:00
lpkGn3k2YdD,2022,Accept (Spotlight),False,Learning Long-Term Reward Redistribution via Randomized Return Decomposition,"['Zhizhou Ren', 'Ruihan Guo', 'Yuan Zhou', 'Jian Peng']","[""Reinforcement Learning"", ""Long-Term Credit Assignment"", ""Reward Redistribution"", ""Return Decomposition""]","We propose randomized return decomposition, a novel reward redistribution algorithm, which establishes a surrogate optimization problem to scale up learning in long-horizon tasks.",2111.13485,cs.LG,2021-11-26 13:23:36+00:00,2021-11-26 13:23:36+00:00
lqU2cs3Zca,2021,Accept (Poster),True,"Signatory: differentiable computations of the signature and logsignature transforms, on both CPU and GPU","[""Patrick Kidger"", ""Terry Lyons""]","[""signature"", ""logsignature"", ""gpu"", ""library"", ""open source""]","Differentiable, GPU-capable implementations of the (log)signature transform via novel algorithms.",2001.00706,cs.LG,2020-01-03 03:15:58+00:00,2021-02-05 19:28:30+00:00
lrocYB-0ST2,2022,Accept (Poster),True,Approximation and Learning with Deep Convolutional Models: a Kernel Perspective,['Alberto Bietti'],"[""kernel methods"", ""deep learning theory"", ""convolution"", ""approximation"", ""generalization""]","We study the inductive bias of multi-layer convolutional models through a kernel lens, showing generalization benefits of various architectural choices such as locality, depth, and pooling layers.",2102.10032,stat.ML,2021-02-19 17:03:42+00:00,2021-06-07 23:20:41+00:00
ls8D_-g8-ne,2021,Reject,False,AdaLead: A simple and robust adaptive greedy search algorithm for sequence design,"[""Sam Sinai"", ""Richard Wang"", ""Alexander Whatley"", ""Stewart Slocum"", ""Elina Locane"", ""Eric Kelsic""]","[""Black-box Optimization"", ""Model-guided sequence design"", ""Computational biology""]",A strong and simple benchmark for sequence design and a platform to compare sequence design algorithms on biologically motivated problems.,,,,
lsQCDXjOl3k,2022,Reject,False,Unconditional Diffusion Guidance,"['Jonathan Ho', 'Tim Salimans']","[""diffusion"", ""score"", ""guidance"", ""generative""]",Classifier guidance without a classifier,,,,
ltM1RMZntpu,2022,Accept (Oral),False,Weighted Training for Cross-Task Learning,"['Shuxiao Chen', 'Koby Crammer', 'Hangfeng He', 'Dan Roth', 'Weijie J Su']","[""Cross-task learning"", ""Natural language processing"", ""Representation learning""]",We introduce a weighted training algorithm for cross-task learning based on minimizing a representation-based task distance between the source and target tasks.,,,,
luGQiBeRMxd,2021,Reject,False,CorrAttack: Black-box Adversarial Attack with Structured Search,"[""Zhichao Huang"", ""Yaowei Huang"", ""Tong Zhang""]","[""adversarial examples"", ""black-box attack"", ""bandits""]",,,,,
luO6l9cP6b6,2022,Reject,False,Identifying the Limits of Cross-Domain Knowledge Transfer for Pretrained Models,"['Zhengxuan Wu', 'Nelson F. Liu', 'Christopher Potts']","[""transfer learning"", ""pretrained language model""]",We explore how much transfer occurs when models are denied any information about word identity via random scrambling.,,,,
lu_DAxnWsh,2022,Reject,False,Guiding Transformers to Process in Steps,"['Simas Sakenis', 'Stuart Shieber']",[],,,,,
lvM693mon8q,2022,Reject,False,Compressed-VFL: Communication-Efficient Learning with Vertically Partitioned Data,"['Timothy Castiglia', 'Anirban Das', 'Shiqiang Wang', 'Stacy Patterson']","[""Federated Learning"", ""Optimization"", ""Split Learning"", ""Cross-Silo Learning"", ""Compression"", ""Quantization"", ""Sparsification""]",We propose Compressed Vertical Federated Learning (C-VFL) where a server and multiple parties collaboratively train a model over vertically-partitioned data utilizing several local iterations and sharing compressed intermediate results periodically. ,,,,
lvRTC669EY_,2021,Accept (Poster),False,Discovering Diverse Multi-Agent Strategic Behavior via Reward Randomization,"[""Zhenggang Tang"", ""Chao Yu"", ""Boyuan Chen"", ""Huazhe Xu"", ""Xiaolong Wang"", ""Fei Fang"", ""Simon Shaolei Du"", ""Yu Wang"", ""Yi Wu""]","[""strategic behavior"", ""multi-agent reinforcement learning"", ""reward randomization"", ""diverse strategies""]","We propose an MARL algorithm, RPG, which discovers diverse non-trivial strategic behavior in several challenging multi-agent games.",,,,
lvXLfNeCQdK,2021,Reject,False,Loss Landscape Matters: Training Certifiably Robust Models with Favorable Loss Landscape,"[""Sungyoon Lee"", ""Woojin Lee"", ""Jinseong Park"", ""Jaewook Lee""]","[""Adversarial Examples"", ""Certifiable Robustness"", ""Certifiable Training"", ""Loss Landscape"", ""Deep Learning"", ""Security""]",We identify smoothness of the loss landscape as an important factor in building certifiably robust model and propose a method that achieves performance comparable to state-of-the-art certifiable training methods under a wide range of perturbations.,,,,
lxHgXYN4bwl,2021,Accept (Spotlight),False,Expressive Power of Invariant and Equivariant Graph Neural Networks,"[""Waiss Azizian"", ""marc lelarge""]","[""Graph Neural Network"", ""Universality"", ""Approximation""]",,,,,
lyLVzukXi08,2022,Accept (Poster),False,Neural Variational Dropout Processes,"['Insu Jeon', 'Youngjin Park', 'Gunhee Kim']","[""Meta Learning"", ""Few-shot Learning"", ""Bayesian Neural Networks"", ""Variatinoal Dropout""]",This paper presents a new model-based Bayesian meta-learning approach called NVDPs that combines a novel conditional dropout posterior with a new variational prior for the data-efficient learning and adaptation of deep neural networks.,,,,
lycl1GD7fVP,2022,Reject,False,Neural tangent kernel eigenvalues accurately predict generalization,"['James B Simon', 'Madeline Dickens', 'Michael Deweese']","[""deep learning"", ""generalization"", ""neural tangent kernel"", ""kernel regression"", ""inductive bias""]",We derive a predictive theory of generalization for wide neural networks and empirically confirm its accuracy.,,,,
lyzRAErG6Kv,2022,Reject,False,Self-Supervised Structured Representations for Deep Reinforcement Learning,"['Hyesong Choi', 'Hunsang Lee', 'Wonil Song', 'Sangryul Jeon', 'Kwanghoon Sohn', 'Dongbo Min']","[""Reinforcement Learning"", ""Representation Learning"", ""Optical Flow Estimation"", ""Structured representation"", ""Self-supervised Learning""]",We propose a novel approach that learns self-supervised structured representations for effectively encoding spatial structures in an unsupervised manner.,,,,
lzupY5zjaU9,2022,Accept (Poster),False,Distribution Compression in Near-Linear Time,"['Abhishek Shetty', 'Raaz Dwivedi', 'Lester Mackey']","[""Distribution compression"", ""linear time"", ""thinning"", ""i.i.d. sampling"", ""Markov chain Monte Carlo"", ""maximum mean discrepancy"", ""reproducing kernel Hilbert space""]",We introduce a simple algorithm for compressing an $n$-point summary of a probability distribution into a $\sqrt{n}$-point summary of comparable quality in $O(n \log^2 n)$ time.,,,,
m08OHhXxl-5,2021,Reject,True,Privacy Preserving Recalibration under Domain Shift,"[""Rachel Luo"", ""Shengjia Zhao"", ""Jiaming Song"", ""Jonathan Kuck"", ""Stefano Ermon"", ""Silvio Savarese""]","[""uncertainty calibration"", ""differential privacy""]","We introduce a framework that provides abstractions for performing recalibration under differential privacy constraints, design a novel recalibration algorithm that works well in this setting, and extensively validate our method experimentally. ",2008.09643,cs.LG,2020-08-21 18:43:37+00:00,2020-08-21 18:43:37+00:00
m0ECRXO6QlP,2021,Reject,False,Supervision Accelerates Pre-training in Contrastive Semi-Supervised Learning of Visual Representations,"[""Mido Assran"", ""Nicolas Ballas"", ""Lluis Castrejon"", ""Michael Rabbat""]","[""semi-supervised learning"", ""contrastive learning"", ""self-supervised learning"", ""deep learning"", ""representation learning"", ""metric learning"", ""visual representations""]",A few labeled samples can accelerate contrastive pre-training.,,,,
m1CD7tPubNy,2021,Accept (Spotlight),True,Mind the Pad -- CNNs Can Develop Blind Spots,"[""Bilal Alsallakh"", ""Narine Kokhlikyan"", ""Vivek Miglani"", ""Jun Yuan"", ""Orion Reblitz-Richardson""]","[""CNN"", ""convolution"", ""spatial bias"", ""blind spots"", ""foveation"", ""padding"", ""exposition"", ""debugging"", ""visualization""]","The padding mechanism in CNNs can induce harmful spatial bias in the learned weights and in the feature maps, which can be mitigated with careful architectural choices.",2010.02178,cs.CV,2020-10-05 17:24:48+00:00,2020-10-05 17:24:48+00:00
m22XrToDacC,2022,Reject,False,Distributionally Robust Recourse Action,"['Duy Nguyen', 'Ngoc Bui', 'Viet Anh Nguyen']","[""Algorithmic recourse"", ""Robust optimization""]",We propose the framework of Distributionally Robust Recourse Action (DiRRAc) for designing a recourse action that is robust to mixture shifts of the model parameters.,,,,
m2ZxDprKYlO,2021,Reject,False,Meta-Learning with Implicit Processes,"[""YIZHOU CHEN"", ""DONG LI"", ""NA LI"", ""TONG LIANG"", ""SHIZHUO ZHANG"", ""Bryan Kian Hsiang Low""]",[],,,,,
m4BAEB_Imy,2022,Reject,False,iPrune: A Magnitude Based Unstructured Pruning Method for Efficient Binary Networks in Hardware,"['Adithya Venkateswaran', 'Jean-Pierre David']",[],,,,,
m4PC1eUknQG,2021,Reject,False,L2E: Learning to Exploit Your Opponent,"[""Zhe Wu"", ""Kai Li"", ""Hang Xu"", ""Meng Zhang"", ""Haobo Fu"", ""Bo An"", ""Junliang Xing""]",[],,,,,
m4UCf24r0Y,2021,Accept (Poster),False,Knowledge Distillation as Semiparametric Inference,"[""Tri Dao"", ""Govinda M Kamath"", ""Vasilis Syrgkanis"", ""Lester Mackey""]","[""knowledge distillation"", ""semiparametric inference"", ""generalization bounds"", ""model compression"", ""cross-fitting"", ""orthogonal machine learning"", ""loss correction""]","By framing distillation as semiparametric inference, we derive new guarantees for standard distillation and develop two enhancementsâcross-fitting and loss correctionâto mitigate the impact of teacher overfitting and underfitting.",2104.09732,stat.ML,2021-04-20 03:00:45+00:00,2021-04-20 03:00:45+00:00
m4baHw5LZ7M,2021,Reject,False,Deep Learning Solution of the Eigenvalue Problem for Differential Operators,"[""Ido Ben-Shaul"", ""Leah Bar"", ""Nir Sochen""]","[""Eigenvalue problem"", ""Unsupervised learning"", ""Laplacian operator""]",We propose an unsupervised neural network-based solver for the eigenvalue problem of differential operators demonstrated on  one and two dimensional Laplacian.,,,,
m5EBN92vjN,2022,Reject,False,AASEG: ATTENTION AWARE NETWORK FOR REAL TIME SEMANTIC SEGMENTATION,['Abhinav Sagar'],[],,,,,
m5Qsh0kBQG,2021,Accept (Oral),False,Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients,"[""Brenden K Petersen"", ""Mikel Landajuela Larma"", ""Terrell N. Mundhenk"", ""Claudio Prata Santiago"", ""Soo Kyung Kim"", ""Joanne Taery Kim""]","[""symbolic regression"", ""reinforcement learning"", ""automated machine learning""]","A deep learning approach to symbolic regression, in which an autoregressive RNN emits a distribution over expressions that is optimized using a risk-seeking policy gradient.",,,,
m716e-0clj,2022,Reject,False,Communicate Then Adapt: An Effective Decentralized Adaptive Method for Deep Training,"['Bicheng Ying', 'Kun Yuan', 'Yiming Chen', 'Hanbin Hu', 'Yingya Zhang', 'Pan Pan', 'Wotao Yin']",[],,,,,
m7zsaLt1Sab,2022,Reject,False,Finding One Missing Puzzle of Contextual Word Embedding: Representing Contexts as Manifold,"['Hailin Hu', 'Rong Yao', 'Cheng LI']","[""Contextual Word Embedding"", ""Category Theory"", ""Manifold""]",A theory-grounded analysis to tackle how contexts are represented by contextual word embedding,,,,
m8bypnj7Yl5,2022,Accept (Poster),False,Neural Solvers for Fast and Accurate Numerical Optimal Control,"['Federico Berto', 'Stefano Massaroli', 'Michael Poli', 'Jinkyoo Park']","[""Deep Learning"", ""Numerical Methods"", ""Optimal Control""]",We propose a hypersolvers approach for numerical optimal control which shows consistent Pareto improvements in solution accuracy and control performance.,,,,
m8uJvVgwRci,2022,Accept (Poster),True,Creating Training Sets via Weak Indirect Supervision,"['Jieyu Zhang', 'Bohan Wang', 'Xiangchen Song', 'Yujing Wang', 'Yaming Yang', 'Jing Bai', 'Alexander Ratner']","[""weak supervision"", ""data programming"", ""training label synthesis""]","In this work, we present a new weak supervision paradigm which automatically creates training sets for training a machine learning model given unlabeled dataset and indirect supervision sources.",2110.03484,cs.LG,2021-10-07 14:09:35+00:00,2022-01-29 17:55:17+00:00
mCLVeEpplNE,2021,Accept (Poster),False,NBDT: Neural-Backed Decision Tree,"[""Alvin Wan"", ""Lisa Dunlap"", ""Daniel Ho"", ""Jihan Yin"", ""Scott Lee"", ""Suzanne Petryk"", ""Sarah Adel Bargal"", ""Joseph E. Gonzalez""]","[""explainability"", ""computer vision"", ""interpretability""]","Neural-Backed Decision Trees improve interpretability and accuracy: (1) out-generalize, improve, and match or outperform baseline neural networks; (2) show visual evidence of generalization, reveal ambiguous ImageNet labels, and improve human trust.",,,,
mCtadqIxOJ,2021,Accept (Poster),False,Representing Partial Programs with Blended Abstract Semantics,"[""Maxwell Nye"", ""Yewen Pu"", ""Matthew Bowers"", ""Jacob Andreas"", ""Joshua B. Tenenbaum"", ""Armando Solar-Lezama""]","[""program synthesis"", ""representation learning"", ""abstract interpretation"", ""modular neural networks""]","We use a combination of concrete execution and learned neural semantics to represent partial programs, resulting in more accurate program synthesis.",2012.12964,cs.PL,2020-12-23 20:40:18+00:00,2021-04-19 18:44:59+00:00
mDAZVlBeXWx,2021,Reject,False,Towards Robust and Efficient Contrastive Textual Representation Learning,"[""Liqun Chen"", ""Yizhe Zhang"", ""Dianqi Li"", ""Chenyang Tao"", ""Dong Wang"", ""Lawrence Carin""]",[],,,,,
mEdwVCRJuX4,2021,Accept (Poster),True,Heteroskedastic and Imbalanced Deep Learning with Adaptive Regularization,"[""Kaidi Cao"", ""Yining Chen"", ""Junwei Lu"", ""Nikos Arechiga"", ""Adrien Gaidon"", ""Tengyu Ma""]","[""deep learning"", ""noise robust learning"", ""imbalanced learning""]",We propose a data-dependent regularization technique for learning heteroskedastic and imbalanced datasets.,2006.15766,cs.LG,2020-06-29 01:09:50+00:00,2021-03-18 07:49:18+00:00
mF122BuAnnW,2022,Reject,False,Localized Randomized Smoothing for Collective Robustness Certification,"['Jan Schuchardt', 'Tom WollschlÃ¤ger', 'Aleksandar Bojchevski', 'Stephan GÃ¼nnemann']","[""Adversarial robustness"", ""Robustness certification"", ""Robust machine learning"", ""Randomized smoothing"", ""Verification""]",,,,,
mF5tmqUfdsw,2022,Reject,False,Zeroth-Order Actor-Critic,"['Yuheng Lei', 'Jianyu Chen', 'Shengbo Eben Li', 'Sifa Zheng']","[""reinforcement learning"", ""zeroth-order optimization"", ""actor-critic""]","We propose Zeroth-Order Actor-Critic algorithm (ZOAC) that unifies timestep-wise parameter space perturbation, first-order policy evaluation and zeroth-order improvement into an on-policy actor-critic architecture.",2201.12518,cs.LG,2022-01-29 07:09:03+00:00,2022-01-29 07:09:03+00:00
mFpP0THYeaX,2022,Reject,True,Gradual Domain Adaptation in the Wild: When Intermediate Distributions are Absent,"['Samira Abnar', 'Rianne van den Berg', 'Golnaz Ghiasi', 'Mostafa Dehghani', 'Nal Kalchbrenner', 'Hanie Sedghi']","[""gradual domain adaptation"", ""self-training"", ""gradual distribution shift"", ""curriculum learning""]",We address the problem of gradually shifting a model towards the target distribution when we do not have access to the intermediate distributions.,2106.06080,cs.LG,2021-06-10 22:47:06+00:00,2021-07-13 09:13:55+00:00
mHu2vIds_-b,2022,Accept (Spotlight),False,Boosting Randomized Smoothing with Variance Reduced Classifiers,"['MiklÃ³s Z. HorvÃ¡th', 'Mark Niklas Mueller', 'Marc Fischer', 'Martin Vechev']","[""adversarial robustness"", ""certified robustness"", ""randomized smoothing""]","We show -- theoretically and empirically -- that ensembles reduce variance under randomized smoothing, yielding higher certified accuracy, leading to a new state-of-the-art on CIFAR-10 and ImageNet.",,,,
mKDtUtxIGJ,2022,Accept (Poster),False,Deep Point Cloud Reconstruction,"['Jaesung Choe', 'ByeongIn Joung', 'Francois Rameau', 'Jaesik Park', 'In So Kweon']","[""Computer Vision"", ""3D Geometry"", ""Deep Learning based Point Cloud Understanding"", ""Point Cloud Denoising"", ""Point Cloud Upsampling""]",We propose deep learning-based point cloud reconstruction algorithm,,,,
mKsMcL8FfsV,2022,Reject,False,Learning Rich Nearest Neighbor Representations from Self-supervised Ensembles,"['Bram Wallace', 'Devansh Arpit', 'Huan Wang', 'Caiming Xiong']","[""k-NN"", ""ensemble"", ""self-supervised learning""]",We propose a method to extract better k-NN representations from an ensemble of self-supervised models.,,,,
mL07kYPn3E,2022,Reject,False,Few-shot Learning with Big Prototypes,"['Ning Ding', 'Yulin Chen', 'Xiaobin Wang', 'Hai-Tao Zheng', 'Zhiyuan Liu', 'Pengjun Xie']","[""Prototype"", ""Few-shot Learning"", ""Meta-learning""]",,,,,
mLcmdlEUxy-,2021,Accept (Spotlight),True,Recurrent Independent Mechanisms,"[""Anirudh Goyal"", ""Alex Lamb"", ""Jordan Hoffmann"", ""Shagun Sodhani"", ""Sergey Levine"", ""Yoshua Bengio"", ""Bernhard Sch\u00f6lkopf""]","[""modular representations"", ""better generalization"", ""learning mechanisms""]","Learning recurrent mechanisms which operate independently, and sparingly interact  can lead to better generalization to out of distribution samples.",1909.10893,cs.LG,2019-09-24 13:28:00+00:00,2020-11-17 05:23:43+00:00
mLeIhe67Li6,2021,Reject,False,Learning One-hidden-layer Neural Networks on Gaussian Mixture Models with Guaranteed Generalizability,"[""Hongkang Li"", ""Shuai Zhang"", ""Meng Wang""]","[""neural networks"", ""generalization"", ""Gaussian mixture model"", ""sample complexity"", ""learning algorithm""]",This paper provides the first theoretical analysis of the impact of the distribution of the input data on the learning performance from the perspective of sample complexity and convergence rate.,,,,
mLtPtH2SIHX,2021,Reject,False,Bypassing the Random Input Mixing in Mixup,"[""Hongyu Guo""]","[""Deep Learning"", ""Data Augmentation"", ""Mixup""]",We report a finding that one can bypass the random input mixing in Mixup to conduct effective model regularization. ,,,,
mMiKHj7Pobj,2022,Reject,False,Revealing the Incentive to Cause Distributional Shift,"['David Krueger', 'Tegan Maharaj', 'Jan Leike']","[""alignment"", ""incentives"", ""unit testing"", ""distributional shift"", ""content recommendation"", ""myopic reinforcement learning""]","We define auto-induced distributional shift (ADS) as shift caused by an algorithm, and design a unit test for checking which learning algorithms reveal incentives for ADS; this may help identify undesirable forms of ADS e.g. in content recommendation",,,,
mNLLDtkAy4X,2022,Reject,False,Escaping Stochastic Traps with Aleatoric Mapping Agents,"['Augustine N. Mavor-Parker', 'Kimberly A Young', 'Caswell Barry', 'Lewis Griffin']","[""Curiosity"", ""Neuroscience"", ""Acetylcholine"", ""Uncertainty"", ""Reinforcement learning"", ""Intrinsic Rewards""]",Avoiding distractions within curiosity driven learning using neuroscience inspired uncertainty computations.,,,,
mNtmhaDkAr,2021,Accept (Poster),False,Predicting Inductive Biases of Pre-Trained Models,"[""Charles Lovering"", ""Rohan Jha"", ""Tal Linzen"", ""Ellie Pavlick""]","[""information-theoretical probing"", ""probing"", ""challenge sets"", ""natural language processing""]","We find that feature extractability, measured by probing classifiers, can be viewed as an inductive bias: the more extractable a feature is after pre-training, the less statistical evidence needed during fine-tuning for the model to use the feature.",,,,
mOO-LfEVZK,2021,Reject,False,Manifold-aware Training: Increase Adversarial Robustness with Feature Clustering,"[""Ting-An Yen"", ""Chun-Shien Lu"", ""Pau-Choo Chung""]","[""Adversarial Attacks"", ""Adversarial Defense"", ""Robustness"", ""Convolutional Neural Network"", ""Feature Compactness""]","A training process called Manifold-Aware Training (MAT), which forces CNNs to learn compact features to increase their robustness and exhibit significantly higher performance than state-of-the-art robustness.",,,,
mPmCP2CXc7p,2021,Reject,False,Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition,"[""Randy Ardywibowo"", ""Shahin Boluki"", ""Zhangyang Wang"", ""Bobak J Mortazavi"", ""Shuai Huang"", ""Xiaoning Qian""]","[""dynamic feature selection"", ""human activity recognition"", ""sparse monitoring""]",We propose a task-driven dynamic feature selection method to perform human activity recognition efficiently.,,,,
mQDpmgFKu1P,2022,Reject,False,Language Modeling using LMUs: 10x Better Data Efficiency or Improved Scaling Compared to Transformers,"['Narsimha Reddy Chilkuri', 'Eric Hunsberger', 'Aaron Russell Voelker', 'Gurshaant Singh Malik', 'Chris Eliasmith']","[""Recurrent Neural Network"", ""Legendre Memory Unit"", ""Natural Language Processing""]",Study the scaling properties of language models employing the Linear Time-Invariant component of the Legendre Memory Unit.,,,,
mQPBmvyAuk,2021,Accept (Poster),True,BREEDS: Benchmarks for Subpopulation Shift,"[""Shibani Santurkar"", ""Dimitris Tsipras"", ""Aleksander Madry""]","[""benchmarks"", ""distribution shift"", ""hierarchy"", ""robustness""]",We develop a methodology for constructing large-scale subpopulation shift benchmarks and use them to assess model robustness as well as the effectiveness existing robustness interventions.,2008.04859,cs.CV,2020-08-11 17:04:47+00:00,2020-08-11 17:04:47+00:00
mQxt8l7JL04,2022,Accept (Poster),False,Regularized Autoencoders for Isometric Representation Learning,"['Yonghyeon LEE', 'Sangwoong Yoon', 'MinJun Son', 'Frank C. Park']","[""Autoencoders"", ""Manifold Learning"", ""Regularization"", ""Geometry"", ""Distortion""]",Regularized Autoencoders that simultaneously learn data manifold and a set of latent space coordinates that preserves the geometry of the learned manifold.,,,,
mRF387I4Wl,2022,Reject,False,FlowX: Towards Explainable Graph Neural Networks via Message Flows,"['Shurui Gui', 'Hao Yuan', 'Jie Wang', 'Qicheng Lao', 'Kang Li', 'Shuiwang Ji']","[""Deep learning"", ""Graph Neural Networks"", ""Explainability""]",,,,,
mRNkPVHyIVX,2021,Reject,False,Exploiting Safe Spots in Neural Networks for Preemptive Robustness and Out-of-Distribution Detection,"[""Seungyong Moon"", ""Gaon An"", ""Hyun Oh Song""]","[""adversarial defense"", ""out-of-distribution detection""]","We define a new problem on adversarial robustness of neural networks, named preemptive robustness, and develop a novel algorithm to improve the robustness. ",,,,
mRc_t2b3l1-,2022,Reject,False,"Rethinking the limiting dynamics of SGD: modified loss, phase space oscillations, and anomalous diffusion","['Daniel Kunin', 'Javier Sagastuy-Brena', 'Lauren Gillespie', 'Eshed Margalit', 'Hidenori Tanaka', 'Surya Ganguli', 'Daniel LK Yamins']","[""learning dynamics"", ""loss landscape"", ""stochastic differential equation"", ""modified equation analysis"", ""hessian"", ""geometry"", ""physics"", ""fokker-plank"", ""modified loss"", ""probability currents"", ""diffusion""]","We identify empirical phenomena (constant instantaneous speed, anomalous diffusion, isotropic parameter exploration) present in the limiting dynamics of deep neural networks and derive a mechanistic origin through the lens of statistical physics",,,,
mSAKhLYLSsl,2021,Accept (Oral),True,Dataset Condensation with Gradient Matching,"[""Bo Zhao"", ""Konda Reddy Mopuri"", ""Hakan Bilen""]","[""dataset condensation"", ""data-efficient learning"", ""image generation""]",This paper proposes a training set synthesis technique that learns to produce a small set of informative samples for training deep neural networks from scratch in a small fraction of computational cost while achieving as close results as possible.,2006.05929,cs.CV,2020-06-10 16:30:52+00:00,2021-03-08 13:31:22+00:00
mTcO4-QCOB,2022,Reject,False,Analyzing the Effects of Classifier Lipschitzness on Explainers,"['Zulqarnain Khan', 'Aria Masoomi', 'Davin Hill', 'Jennifer Dy']","[""Explainers"", ""Explanation"", ""Robustness"", ""Astuteness"", ""Lipschitz"", ""Blackbox"", ""Classifiers""]", locally smooth prediction functions lend themselves to locally robust explanations.,,,,
mWnfMrd9JLr,2021,Reject,False,On the Latent Space of Flow-based Models,"[""Mingtian Zhang"", ""Yitong Sun"", ""Steven McDonagh"", ""Chen Zhang""]","[""flow-based mode"", ""generative model"", ""intrinsic dimension"", ""manifold learning""]",A flow based model for data supported on a manifold.,,,,
mYNfmvt8oSv,2021,Reject,True,D2RL: Deep Dense Architectures in Reinforcement Learning,"[""Samarth Sinha"", ""Homanga Bharadhwaj"", ""Aravind Srinivas"", ""Animesh Garg""]","[""Deep Reinforcement learning"", ""Policy architectures""]",Introducing dense architectures in the policy and value function in deep reinforcement learning can significantly improve performance in state and image-based RL.,2010.09163,cs.LG,2020-10-19 01:27:07+00:00,2020-11-27 20:22:38+00:00
mZLhA0xFGmR,2021,Reject,False,Deep Gated Canonical Correlation Analysis,"[""Ofir Lindenbaum"", ""Moshe Salhov"", ""Amir Averbuch"", ""Yuval Kluger""]",[],,,,,
mZsZy481_F,2022,Reject,False,FROB: Few-shot ROBust Model for Classification with Out-of-Distribution Detection,"['Nikolaos Dionelis', 'Mehrdad Yaghoobi', 'Sotirios A. Tsaftaris']","[""Classification and Out-of-Distribution Detection"", ""Confidence Prediction"", ""Few-Shot Out-of-Distribution Detection"", ""Outlier Exposure"", ""Robustness""]","We propose the Few-shot ROBust (FROB) model for few-shot Out-of-Distribution (OoD) detection and classification using both discriminative and generative models, to improve robustness and reliable confidence prediction for few-shot OoD detection.",2111.15487,cs.LG,2021-11-30 15:20:44+00:00,2022-02-02 15:33:44+00:00
mb2L9vL-MjI,2021,Reject,True,The Quenching-Activation Behavior of the Gradient Descent Dynamics for Two-layer Neural Network Models,"[""Chao Ma"", ""Lei Wu"", ""Weinan E""]","[""Gradient descent"", ""neural networks"", ""implicit regularization"", ""quenching-activation""]",The gradient descent dynamics  for two-layer neural networks exhibits a quenching-activation behavior. ,2006.14450,cs.LG,2020-06-25 14:41:53+00:00,2020-06-25 14:41:53+00:00
mdUYT5QV0O,2022,Accept (Poster),False,Training Structured Neural Networks Through Manifold Identification and Variance Reduction,"['Zih-Syuan Huang', 'Ching-pei Lee']","[""Structured neural networks"", ""variance reduction"", ""manifold identification"", ""proximal methods""]",We propose a variance-reduction method for training structured deep learning models that can provably identify the optimal structure.,2112.02612,cs.LG,2021-12-05 16:23:53+00:00,2021-12-05 16:23:53+00:00
me5hEszKra4,2021,Reject,False,ResPerfNet: Deep Residual Learning for Regressional Performance Modeling of Deep Neural Networks,"[""Chuan-Chi Wang"", ""Ying-Chiao Liao"", ""Chia-Heng Tu"", ""Ming-Chang Kao"", ""Wen-Yew Liang"", ""Shih-Hao Hung""]",[],,2012.01671,cs.LG,2020-12-03 03:02:42+00:00,2020-12-03 03:02:42+00:00
meG3o0ttiAD,2021,Reject,False,Toward Trainability of Quantum Neural Networks,"[""Kaining Zhang"", ""Min-Hsiu Hsieh"", ""Liu Liu"", ""Dacheng Tao""]","[""Near-term Quantum Algorithm"", ""Quantum Neural Network"", ""Trainability"", ""Hierarchical Structure""]",We analyze the trainability of quantum neural networks with special structures with proven bounds and numerical simulations.,2011.06258,quant-ph,2020-11-12 08:32:04+00:00,2020-12-05 04:06:40+00:00
metRpM4Zrcb,2022,Accept (Spotlight),False,Continual Learning with Filter Atom Swapping,"['Zichen Miao', 'Ze Wang', 'Wei Chen', 'Qiang Qiu']","[""continual learning""]",,,,,
mewtfP6YZ7,2021,Reject,False,On Trade-offs of Image Prediction in Visual Model-Based Reinforcement Learning,"[""Mohammad Babaeizadeh"", ""Mohammad Taghi Saffar"", ""Danijar Hafner"", ""Dumitru Erhan"", ""Harini Kannan"", ""Chelsea Finn"", ""Sergey Levine""]","[""world models"", ""model based reinforcement learning"", ""latent planning"", ""model-based reinforcement learning"", ""model predictive control"", ""video prediction""]",Predicting pixels in addition to rewards lead to higher performance while a more accurate world model may fail to perform well due to failed exploration,,,,
mfJepDyIUcQ,2021,Reject,True,Safety Verification of Model Based Reinforcement Learning Controllers,"[""akshita gupta"", ""Inseok Hwang""]","[""Reachable set"", ""state constraints"", ""safety verification"", ""model-based reinforcement learning""]",Safety verification and determination of safe initial states for model-based reinforcement learning controllers.,2010.10740,cs.LG,2020-10-21 03:35:28+00:00,2020-10-21 03:35:28+00:00
mfwdY3U_9ea,2022,Accept (Poster),False,Igeood: An Information Geometry Approach to Out-of-Distribution Detection,"['Eduardo Dadalto Camara Gomes', 'Florence Alberge', 'Pierre Duhamel', 'Pablo Piantanida']","[""out-of-distribution detection"", ""anomaly detection"", ""deep learning""]",We propose a flexible and effective out-of-distribution detection method by building on the Fisher-Rao distance between probability distributions.,,,,
mgVbI13p96,2021,Reject,False,Multi-modal Self-Supervision from Generalized Data Transformations,"[""Mandela Patrick"", ""Yuki Asano"", ""Polina Kuznetsova"", ""Ruth Fong"", ""Joao F. Henriques"", ""Geoffrey Zweig"", ""Andrea Vedaldi""]","[""video representation learning"", ""multi-modal learning"", ""self-supervised learning"", ""audio-visual learning"", ""noise-contrastive learning""]","A systematic framework to express invariance and distinctiveness induced by transformations in multi-modal representation learning, achieving state-of-the-art results on several audio and video benchmarks",,,,
mhEd8uOyNTI,2021,Reject,False,Representational correlates of hierarchical phrase structure in deep language models,"[""Matteo Alleman"", ""Jonathan Mamou"", ""Miguel A Del Rio"", ""Hanlin Tang"", ""Yoon Kim"", ""SueYeon Chung""]","[""bertology"", ""interpretability"", ""computational neuroscience"", ""population coding""]",We use methods from computational neuroscience to analyze representational correlates of syntax in BERT-models and find that these models gradually build up sensitivities to hierarchical phrase structure along its layers.,2104.07578,cs.CL,2021-04-15 16:30:31+00:00,2021-04-15 16:30:31+00:00
mhYUBYNoGz,2022,Accept (Poster),True,"Machine Learning For Elliptic PDEs: Fast Rate Generalization Bound, Neural Scaling Law and Minimax Optimality","['Yiping Lu', 'Haoxuan Chen', 'Jianfeng Lu', 'Lexing Ying', 'Jose Blanchet']","[""Numerical PDE"", ""non-parametric statistics"", ""computational physics""]",We provided min-max optimal convergence bound for machine learning based PDE solvers and numerically verified the scaling law.,2110.06897,math.NA,2021-10-13 17:26:31+00:00,2021-11-13 02:25:51+00:00
mhv2gWm3sf,2022,Reject,False,$f$-Divergence Thermodynamic Variational Objective: a Deformed Geometry Perspective,"['Jun Li', 'Ping Li']",[],,,,,
miA4AkGK00R,2022,Reject,True,EF21 with Bells & Whistles: Practical Algorithmic Extensions of Modern Error Feedback,"['Ilyas Fatkhullin', 'Igor Sokolov', 'Eduard Gorbunov', 'Zhize Li', 'Peter RichtÃ¡rik']","[""EF21"", ""error feedback"", ""bidirectional compression"", ""regularization"", ""variance reduction"", ""heavy ball momentum"", ""stochastic approximation""]",,2110.03294,cs.LG,2021-10-07 09:29:14+00:00,2021-10-07 09:29:14+00:00
mj7WsaHYxj,2021,Reject,True,FLAG: Adversarial Data Augmentation for Graph Neural Networks,"[""Kezhi Kong"", ""Guohao Li"", ""Mucong Ding"", ""Zuxuan Wu"", ""Chen Zhu"", ""Bernard Ghanem"", ""Gavin Taylor"", ""Tom Goldstein""]","[""Graph Neural Networks"", ""Data Augmentation"", ""Adversarial Training""]",We show that adversarial data augmentation generalizes Graph Neural Networks on large-scale datasets.,2010.09891,cs.LG,2020-10-19 21:51:47+00:00,2021-11-05 03:41:34+00:00
mk0HzdqY7i1,2022,Accept (Poster),False,Whatâs Wrong with Deep Learning in Tree Search for Combinatorial Optimization,"['Maximilian BÃ¶ther', 'Otto KiÃig', 'Martin Taraz', 'Sarel Cohen', 'Karen Seidel', 'Tobias Friedrich']","[""deep learning"", ""combinatorial optimization"", ""maximum independent set""]","Using our open-source Maximum Independent Set benchmarking suite, we show that in tree search for combinatorial optimization, the GNN can be replaced by random values without performance decrease.",,,,
mk8AzPcd3x,2022,Reject,False,BCDR: Betweenness Centrality-based Distance Resampling for Graph Shortest Distance Embedding,"['Haoyu Wang', 'Chun Yuan']","[""graph representation learning"", ""graph shortest path distance"", ""shortest distance query"", ""graph embedding"", ""random walk""]",We propose a novel graph shortest distance embedding method using betweenness centrality-based random walk plus distance resampling strategy with a strong theoretical background and much more satisfactory empirical performance than existing methods.,,,,
ml1LSu49FLZ,2021,Reject,False,Topic-aware Contextualized Transformers,"[""Ruiying Lu"", ""Bo Chen"", ""Dan dan Guo"", ""Dongsheng Wang"", ""Mingyuan Zhou""]",[],,,,,
mmUA7_O9mjY,2022,Accept (Spotlight),False,Contact Points Discovery for Soft-Body Manipulations with Differentiable Physics,"['Sizhe Li', 'Zhiao Huang', 'Tao Du', 'Hao Su', 'Joshua B. Tenenbaum', 'Chuang Gan']","[""differentiable physics"", ""soft body manipulation""]",We propose a contact pose discovery method that guides the stand-alone differentiable physics solver to complete various soft-body manipulation tasks.,,,,
mniwiEAuzL,2022,Reject,False,Sample-efficient actor-critic algorithms with an etiquette for zero-sum Markov games,"['Ahmet Alacaoglu', 'Luca Viano', 'Niao He', 'Volkan Cevher']","[""zero sum Markov-games"", ""policy gradient"", ""actor-critic"", ""temporal difference""]",We improve the sample complexity of actor-critic algorithms for solving zero-sum Markov games.,,,,
mnj-9lYJgu,2021,Reject,True,DEEP ADAPTIVE SEMANTIC LOGIC (DASL): COMPILING DECLARATIVE KNOWLEDGE INTO DEEP NEURAL NETWORKS,"[""Karan Sikka"", ""Andrew Silberfarb"", ""John Byrnes"", ""Indranil Sur"", ""Ed Chow"", ""Ajay Divakaran"", ""Richard Rohwer""]","[""deep neural networks"", ""first order logic"", ""neuro-symbolic computing"", ""knowledge"", ""commonsense""]",DASL- a novel neuro-symbolic framework capturing full first order logic to improve learning with knowledge,2003.07344,cs.CV,2020-03-16 17:37:25+00:00,2020-03-16 17:37:25+00:00
mo3Uqtnvz_,2021,Reject,False,Multi-scale Network Architecture Search for Object Detection,"[""Yuxin Yue"", ""Quanquan Li"", ""Yujie Wang""]","[""Object Detection"", ""Neural Architecture Search""]",We design multi-scale detection networks by NAS.,,,,
moHCzz6D5H3,2022,Accept (Poster),False,"Peek-a-Boo: What (More) is Disguised in a Randomly Weighted Neural Network, and How to Find It Efficiently","['Xiaohan Chen', 'Jason Zhang', 'Zhangyang Wang']","[""Sparse Neural Network"", ""Lottery Ticket Hypothesis"", ""Efficient Machine Leanring""]",,,,,
morSrUyWG26,2022,Reject,False,AutoOED: Automated Optimal Experimental Design Platform with Data- and Time-Efficient Multi-Objective Optimization,"['Yunsheng Tian', 'Mina Konakovic Lukovic', 'Michael Foshey', 'Timothy Erps', 'Beichen Li', 'Wojciech Matusik']","[""optimal experiment design"", ""bayesian optimization"", ""multi-objective optimization"", ""software platform""]",AutoOED: an Automated Optimal Experimental Design platform powered by machine learning to accelerate discovering solutions with optimal objective trade-offs.,,,,
mqIeP6qPvta,2022,Reject,False,FoveaTer: Foveated Transformer for Image Classification,"['Aditya Jonnalagadda', 'William Yang Wang', 'B.S. Manjunath', 'Miguel Eckstein']",[],,,,,
ms7xJWbf8Ku,2022,Reject,True,Efficient Packing: Towards 2x NLP Speed-Up without Loss of Accuracy for BERT,"['Matej Kosec', 'Sheng Fu', 'Mario Michael Krell']","[""deep learning"", ""BERT"", ""IPU"", ""GPU"", ""hardware-acceleration"", ""padding"", ""Wikipedia"", ""NLP""]",We eliminate padding overhead in BERT with our proposed packing algorithms that combine sequences to achieve 2x speed-up on the IPU.,2107.02027,cs.CL,2021-06-29 04:37:23+00:00,2021-06-29 04:37:23+00:00
msRBojTz-Nh,2022,Accept (Poster),False,Learned Simulators for Turbulence,"['Kim Stachenfeld', 'Drummond Buschman Fielding', 'Dmitrii Kochkov', 'Miles Cranmer', 'Tobias Pfaff', 'Jonathan Godwin', 'Can Cui', 'Shirley Ho', 'Peter Battaglia', 'Alvaro Sanchez-Gonzalez']","[""learned simulation"", ""turbulence""]",Learned simulators that outperform baselines in capturing turbulent dynamics at low resolution across multiple challenging turbulence domains.,,,,
muppfCkU9H1,2021,Reject,False,Multi-hop Attention Graph Neural Network,"[""Guangtao Wang"", ""Zhitao Ying"", ""Jing Huang"", ""Jure Leskovec""]",[],,,,,
muu0gF6BW-,2021,Reject,True,Cubic Spline Smoothing Compensation for Irregularly Sampled Sequences,"[""Jing Shi"", ""Jing Bi"", ""Yingru Liu"", ""Chenliang Xu""]","[""Neural Ordinary Differential Equations"", ""Cubic Spline Interpolation"", ""Irregular Time Series""]",A cubic spline smoothing compensation to the ODE-RNN for irregular sampled sequence interpolation.,2010.01381,cs.LG,2020-10-03 16:15:22+00:00,2020-10-03 16:15:22+00:00
mwdfai8NBrJ,2022,Accept (Poster),True,Policy Smoothing for Provably Robust Reinforcement Learning,"['Aounon Kumar', 'Alexander Levine', 'Soheil Feizi']","[""Reinforcement Learning"", ""Provable Adversarial Robustness"", ""Randomized Smoothing""]",A provable adversarial robustness technique for reinforcement learning.,2106.11420,cs.LG,2021-06-21 21:42:08+00:00,2021-10-11 20:28:59+00:00
mxIEptSTK6Z,2021,Reject,False,Continual learning with neural activation importance,"[""Sohee Kim"", ""Seungkyu Lee""]",[],,,,,
mxfRhLgLg_,2021,Reject,False,Deep Ecological Inference,"[""Nic Fishman"", ""Colin McAuliffe""]","[""ecological inference"", ""representation learning"", ""multi-task learning"", ""bayesian deep learning""]","We extend ecological inference with an efficient loss function, and build models to infer probabilities of vote choice for candidates in the Maryland 2018 midterm elections.",,,,
mz7Bkl2Pz6,2022,Reject,False,Global Convergence and Stability of Stochastic Gradient Descent,"['Vivak Patel', 'Bowen Tian', 'Shushu Zhang']","[""Stochastic Gradient Descent"", ""Nonconvexity"", ""Noise Model"", ""Global Convergence"", ""Stability""]",We analyze the global behavior of SGD under assumptions that are realistic to machine learning problems.,,,,
mzfqkPOhVI4,2021,Reject,False,Adaptive Spatial-Temporal Inception Graph Convolutional Networks for Multi-step Spatial-Temporal Network Data Forecasting,"[""Xing Wang"", ""Lin Zhu"", ""Juan Zhao"", ""Zhou Xu"", ""Zhao Li"", ""Junlan Feng"", ""Chao Deng""]",[],,,,,
n0OeTdNRG0Q,2022,Accept (Poster),False,Efficient Sharpness-aware Minimization for Improved Training of Neural Networks,"['Jiawei Du', 'Hanshu Yan', 'Jiashi Feng', 'Joey Tianyi Zhou', 'Liangli Zhen', 'Rick Siow Mong Goh', 'Vincent Tan']","[""Efficient learning"", ""gengeralization"", ""training algorithm""]",An efficient sharpness aware minimizer that improves the generalization ,,,,
n1BMcctC12,2022,Reject,False,Randomized Primal-Dual Coordinate Method for Large-scale Linearly Constrained Nonsmooth Nonconvex Optimization,"['Lei Zhao', 'Daoli Zhu', 'Xiao Li']","[""primal-dual methods"", ""constrained nonconvex nonsmooth optimization"", ""coordinate descent methods"", ""global convergence"", ""iteration complexity""]",We design an efficient primal-dual coordinate method called N-RPDC for large-scale linearly constrained nonsmooth nonconvex optimization and provide thorough convergence analysis for this method.,,,,
n1HD8M6WGn,2021,Accept (Poster),False,Understanding and Improving Encoder Layer Fusion in Sequence-to-Sequence Learning,"[""Xuebo Liu"", ""Longyue Wang"", ""Derek F. Wong"", ""Liang Ding"", ""Lidia S. Chao"", ""Zhaopeng Tu""]","[""Encoder layer fusion"", ""Transformer"", ""Sequence-to-sequence learning"", ""Machine translation"", ""Summarization"", ""Grammatical error correction""]",,2012.14768,cs.CL,2020-12-29 14:26:59+00:00,2021-03-18 11:46:55+00:00
n1wPkibo2R,2021,Reject,False,An Efficient Protocol for Distributed Column Subset Selection in the Entrywise $\ell_p$ Norm,"[""Shuli Jiang"", ""Dongyu Li"", ""Irene Mengze Li"", ""Arvind V. Mahankali"", ""David Woodruff""]","[""Column Subset Selection"", ""Distributed Learning""]",,,,,
n4IMHNb8_f,2021,Reject,False,Differentiable Spatial Planning using Transformers,"[""Devendra Singh Chaplot"", ""Deepak Pathak"", ""Jitendra Malik""]","[""Planning"", ""Spatial planning"", ""Path planning"", ""Navigation"", ""Manipulation"", ""Robotics""]",A differentiable spatial planning model designed for long-distance spatial reasoning using Transformers which allows end-to-end mapping and planning without access to ground-truth maps.,,,,
n54Drs00M1,2022,Reject,False,Learning affective meanings that derives the social behavior using Bidirectional Encoder Representations from Transformers,"['Moeen Mostafavi', 'Michael D. Porter', 'Dawn T Robinson']","[""Affect Control Theory"", ""Bidirectional Encoder Representations from Transformers"", ""affective lexicon"", ""formal theory""]",BERT and domain knowledge are used to get  state of the art in extending affective meanings of words.,,,,
n5ej38Vfuup,2021,Reject,False,Deep Quotient Manifold Modeling,"[""Jiseob Kim"", ""Seungjae Jung"", ""Hyundo Lee"", ""Byoung-Tak Zhang""]","[""deep generative models"", ""manifold learning""]","We propose quotient manifold modeling, a new generative modeling scheme that considers generic manifold structure, thereby allowing generalizations over untrained manifolds.",,,,
n5go16HF_B,2021,Reject,False,"Adversarial Data Generation of Multi-category Marked Temporal Point Processes with Sparse, Incomplete, and Small Training Samples","[""Shashika Ranga Muramudalige"", ""Anura Jayasumana"", ""Haonan Wang""]","[""Marked temporal point process"", ""Stochastic process"", ""Adversarial autoencoder"", ""Incomplete data generation""]","A novel technique to generate multi-category Marked Temporal Point Processes (MTTPs) using sparse, incomplete, and small training data",,,,
n5yBuzpqqw,2021,Reject,False,Error Controlled Actor-Critic Method to Reinforcement Learning,"[""Xingen Gao"", ""Fei Chao"", ""Changle Zhou"", ""Zhen Ge"", ""Chih-Min Lin"", ""Longzhi Yang"", ""Xiang Chang"", ""Changjing Shang""]","[""reinforcement learning"", ""actor-critic"", ""function approximation"", ""approximation error"", ""KL divergence""]",We propose a new actor-critic algorithm called Error Controlled Actor-critic which ensures confining the approximation error in value function.,,,,
n6Bc3YElODq,2022,Reject,True,Model-Based Opponent Modeling,"['XiaoPeng Yu', 'Jiechuan Jiang', 'Haobin Jiang', 'Zongqing Lu']","[""multi-agent reinforcement learning"", ""opponent modeling""]",,2108.01843,cs.LG,2021-08-04 04:42:43+00:00,2021-08-04 04:42:43+00:00
n6jl7fLxrP,2021,Accept (Poster),True,Adaptive Universal Generalized PageRank Graph Neural Network,"[""Eli Chien"", ""Jianhao Peng"", ""Pan Li"", ""Olgica Milenkovic""]","[""Graph Neural Networks"", ""Generalized PageRank"", ""Heterophily"", ""Homophily"", ""Over-smoothing""]",We combine generalized PageRank with GNNs to adapt universal node label patterns and the over-smoothing problem.,2006.07988,cs.LG,2020-06-14 19:27:39+00:00,2021-10-26 20:07:59+00:00
n7wIfYPdVet,2021,Accept (Poster),True,Auxiliary Learning by Implicit Differentiation,"[""Aviv Navon"", ""Idan Achituve"", ""Haggai Maron"", ""Gal Chechik"", ""Ethan Fetaya""]","[""Auxiliary Learning"", ""Multi-task Learning""]",Learn to combine auxiliary tasks in a nonlinear fashion and to design them automatically.,2007.02693,cs.CV,2020-06-22 19:35:07+00:00,2021-05-11 06:52:59+00:00
nBU_u6DLvoK,2022,Accept (Poster),False,UniFormer: Unified Transformer for Efficient Spatial-Temporal Representation Learning,"['Kunchang Li', 'Yali Wang', 'Gao Peng', 'Guanglu Song', 'Yu Liu', 'Hongsheng Li', 'Yu Qiao']","[""Spatial-Temporal Representation Learning"", ""3D Convolution"", ""Transformer""]","We introduce a novel Unified transFormer (UniFormer) which seamlessly integrates merits of 3D convolution and spatial-temporal self-attention in a concise transformer format, and achieves new state-of-the-art performances on Something-Something.",,,,
nCY83KxoehA,2021,Reject,True,Automated Concatenation of Embeddings for Structured Prediction,"[""Xinyu Wang"", ""Yong Jiang"", ""Nguyen Bach"", ""Tao Wang"", ""Zhongqiang Huang"", ""Fei Huang"", ""Kewei Tu""]",[],"We propose ACE, which automatically searches the best word embedding concatenation as word representation. ACE achieved state-of-the-art results on 6 structured prediction tasks over 19 out of 21 datasets.",2010.05006,cs.CL,2020-10-10 14:03:20+00:00,2021-06-01 13:23:25+00:00
nCw4talHmo5,2022,Reject,True,ParaDiS: Parallelly Distributable Slimmable Neural Networks,"['Alexey Ozerov', 'Anne Lambert', 'Suresh Kirthi Kumaraswamy']","[""convolutional neural networks"", ""efficient inference"", ""distributed inference"", ""parallel distribution"", ""slimmable neural networks"", ""flexible neural networks""]",We introduce parallely distributable slimmable (ParaDiS) neural networks that are splittable in parallel between various device configurations with minimal communication load.,2110.02724,cs.LG,2021-10-06 13:17:08+00:00,2021-11-29 09:50:25+00:00
nD9Pf-PjTbT,2022,Reject,False,Convergence of Generalized Belief Propagation Algorithm on Graphs with Motifs,"['Yitao Chen', 'Deepanshu Vasal']","[""Belief Propagation"", ""Bethe energy function""]",,,,,
nEMiSX_ipXr,2021,Reject,False,Proper Measure for Adversarial Robustness,"[""Hyeongji Kim"", ""Ketil Malde""]","[""adversarial examples"", ""adversarial robustness"", ""adversarial accuracy"", ""nearest neighbor classifiers""]",This paper introduces a new measure for the robustness of classifiers and suggests one possible factor for the tradeoff between test accuracy and adversarial robustness.,,,,
nEfdkfAyRT8,2022,Reject,True,Escaping Saddle Points in Nonconvex Minimax Optimization via Cubic-Regularized Gradient Descent-Ascent,"['Ziyi Chen', 'Qunwei Li', 'Yi Zhou']","[""Minimax optimization"", ""Gradient descent-ascent"", ""saddle point"", ""cubic regularization"", ""Lojasiewicz gradient geometry""]",This paper proposes the first GDA-type algorithm to avoid saddle point of the envolope function in minimax optimization and obtains faster global convergence than Cubic-GDA in the full spectrum of a gradient dominant-type nonconvex geometry.,2110.07098,math.OC,2021-10-14 00:36:44+00:00,2022-01-31 19:03:44+00:00
nG4Djb4h8Re,2021,Reject,False,MetaPhys: Few-Shot Adaptation for Non-Contact Physiological Measurement,"[""Xin Liu"", ""Ziheng Jiang"", ""Joshua Wolff Fromm"", ""Xuhai Xu"", ""Shwetak Patel"", ""Daniel McDuff""]","[""Healthcare"", ""Meta Learning"", ""Computer Vision""]",MetaPhys: A novel meta-learning approach for learning personalized cardiovascular signals from 18-seconds of video data.,,,,
nHpzE7DqAnG,2022,Accept (Spotlight),True,Convergent Boosted Smoothing for Modeling GraphData with Tabular Node Features,"['Jiuhai Chen', 'Jonas Mueller', 'Vassilis N. Ioannidis', 'Soji Adeshina', 'Yangkun Wang', 'Tom Goldstein', 'David Wipf']","[""Graph Neural Network"", ""Boosting"", ""Node classification"", ""Tabular Data""]",We develop a convergent method for combining boosting and graph propagation layers. ,2110.13413,cs.LG,2021-10-26 04:53:12+00:00,2021-10-26 04:53:12+00:00
nIAxjsniDzg,2021,Accept (Oral),False,What Matters for On-Policy Deep Actor-Critic Methods? A Large-Scale Study,"[""Marcin Andrychowicz"", ""Anton Raichuk"", ""Piotr Sta\u0144czyk"", ""Manu Orsini"", ""Sertan Girgin"", ""Rapha\u00ebl Marinier"", ""Leonard Hussenot"", ""Matthieu Geist"", ""Olivier Pietquin"", ""Marcin Michalski"", ""Sylvain Gelly"", ""Olivier Bachem""]","[""Reinforcement learning"", ""continuous control""]",We conduct a large-scale empirical study that provides insights and practical recommendations for the training of on-policy deep actor-critic RL agents.,,,,
nIqapkAyZ9_,2021,Reject,False,SVMax: A Feature Embedding Regularizer,"[""Ahmed Taha"", ""Alex Hanson"", ""Abhinav Shrivastava"", ""Larry S. Davis""]","[""metric learning"", ""model collapse"", ""feature embedding"", ""neural network regularizer""]","We propose singular value maximization (SVMax) as a feature embedding regularizer. SVMax promotes a uniform embedding, mitigates model collapse, and enables large learning rates.",,,,
nK7eZEURiJ4,2022,Reject,False,"Towards Understanding Distributional Reinforcement Learning: Regularization, Optimization, Acceleration and Sinkhorn Algorithm","['Ke Sun', 'Yingnan Zhao', 'Yi Liu', 'Enze Shi', 'Yafei Wang', 'Aref Sadeghi', 'Xiaodong Yan', 'Bei Jiang', 'Linglong Kong']","[""distributional reinforcement learning""]","We study the theoretical advantage of distributional reinforcement learning from perspectives of regularization, generalization and acceleration, and further propose Sinkhorn distributioanal RL algorithm.",,,,
nKWjE4QF1hB,2022,Accept (Poster),False,AlphaZero-based Proof Cost Network to Aid Game Solving,"['Ti-Rong Wu', 'Chung-Chin Shih', 'Ting Han Wei', 'Meng-Yu Tsai', 'Wei-Yuan Hsu', 'I-Chen Wu']","[""Monte-Carlo Tree Search"", ""Solving Games"", ""AlphaZero"", ""Deep Reinforcement Learning""]","This paper proposes a novel approach to solving problems by modifying the training target of the AlphaZero algorithm, such that it prioritizes solving the game quickly, rather than winning.",,,,
nKZvpGRdJlG,2022,Reject,False,Mind Your Solver! On Adversarial Attack and Defense for Combinatorial Optimization,"['Han Lu', 'Zenan Li', 'Runzhong Wang', 'Qibing Ren', 'Junchi Yan', 'Zhigang Hua', 'Gan Liu', 'JUN ZHOU', 'Xiaokang Yang']","[""Adversarial Attack"", ""Combinatorial Optimization"", ""Reinforcement Learning""]",A general framework for adversarial attack and defense for combinatorial solvers.,,,,
nL2lDlsrZU,2022,Reject,False,SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training,"['Gowthami Somepalli', 'Avi Schwarzschild', 'Micah Goldblum', 'C. Bayan Bruss', 'Tom Goldstein']","[""Transformer"", ""Tabular"", ""Attention"", ""Contrastive Pre-Training""]","A deep learning framework with attention between data points, contrastive pre-training, and a novel augmentation scheme to improve performance on tabular datasets.",,,,
nLYMajjctMh,2021,Reject,False,Federated Learning of a Mixture of Global and Local Models,"[""Filip Hanzely"", ""Peter Richtarik""]","[""optimization"", ""federated learning"", ""personalization"", ""local SGD""]","We propose a new optimization formulation for training federated learning models, which enables the local algorithms to outperform their non-local counterparts in the heterogeneous data regime. ",,,,
nLb60uXd6Np,2022,Reject,True,Geometric Algebra Attention Networks for Small Point Clouds,['Matthew Spellings'],"[""deep learning"", ""geometric algebra"", ""equivariance"", ""geometric deep learning"", ""rotation equivariance"", ""permutation equivariance"", ""chemistry"", ""physics"", ""biology"", ""attention"", ""point cloud""]","We use geometric algebra and attention to build deep learning architectures with rotation and permutation equivariance suitable for many applications in physics, chemistry, and biology.",2110.02393,cs.LG,2021-10-05 22:52:12+00:00,2021-10-05 22:52:12+00:00
nO5caZwFwYu,2022,Accept (Poster),True,Efficient Active Search for Combinatorial Optimization Problems,"['AndrÃ© Hottung', 'Yeong-Dae Kwon', 'Kevin Tierney']","[""heuristic search"", ""combinatorial optimization"", ""learning to optimize"", ""reinforcement learning"", ""traveling salesperson problem"", ""vehicle routing problem"", ""job shop scheduling problem""]",We propose active search approaches for combinatorial optimization problems that search for solutions by adjusting a subset of (model) parameters to a single instance at test time.,2106.05126,cs.LG,2021-06-09 15:08:03+00:00,2021-06-09 15:08:03+00:00
nPVlVsBTiJ,2021,Reject,True,Adversarial Boot Camp: label free certified robustness in one epoch,"[""Ryan Campbell"", ""Chris Finlay"", ""Adam M Oberman""]","[""machine"", ""learning"", ""adversarial"", ""robustness"", ""neural"", ""networks"", ""image"", ""classification"", ""computer"", ""vision""]",Deriving a regularized loss function that leads to certifiably robust computer vision models.,2010.02508,cs.LG,2020-10-05 13:47:45+00:00,2020-10-05 13:47:45+00:00
nQxCYIFk7Rz,2021,Reject,True,Multiple Descent: Design Your Own Generalization Curve,"[""Lin Chen"", ""Yifei Min"", ""Mikhail Belkin"", ""amin karbasi""]","[""multiple descent"", ""interpolation"", ""overparametrization""]","We show that the generalization curve can have an arbitrary number of peaks, and moreover, locations of those peaks can be explicitly controlled. ",2008.01036,cs.LG,2020-08-03 17:22:21+00:00,2021-11-08 18:58:11+00:00
nRCS3BfynGQ,2022,Reject,False,Symmetry-driven graph neural networks,"['Francesco Farina', 'Emma Slade']",[],,,,,
nRJ08rN_b17,2021,Reject,True,Vision at A Glance: Interplay between Fine and Coarse Information Processing Pathways,"[""Zilong Ji"", ""Xiaolong Zou"", ""Tiejun Huang"", ""Si Wu""]","[""Fast pathway"", ""Slow pathway"", ""Interplay"", ""Robustness"", ""Visual backward masking"", ""Biological visual systems"", ""Biological inspried model""]",We build a network model to elucidate the compuational properties asscociated with the interplay between fast and slow biological visual pathways.,2009.05101,cs.CV,2020-08-23 06:46:26+00:00,2020-08-23 06:46:26+00:00
nRj0NcmSuxb,2022,Accept (Poster),False,FairCal: Fairness Calibration for Face Verification,"['Tiago Salvador', 'Stephanie Cairns', 'Vikram Voleti', 'Noah Marshall', 'Adam M Oberman']","[""face verification"", ""bias"", ""fairness"", ""clustering"", ""calibration""]","We calibrate face verification models for fairness, without use of the sensitive attribute, without the need for retraining. This leads to SOTA accuracy, fairness calibration, and equal FPRs across subgroups.",,,,
nT0GS37Clr,2022,Reject,False,FSL: Federated Supermask Learning,"['Hamid Mozaffari', 'Virat Shejwalkar', 'Amir Houmansadr']","[""Collaborative learning"", ""robustness"", ""poisoning attacks"", ""communication efficiency""]",,,,,
nVZtXBI6LNn,2021,Accept (Poster),False,Fast and Complete: Enabling Complete Neural Network Verification with Rapid and Massively Parallel Incomplete Verifiers,"[""Kaidi Xu"", ""Huan Zhang"", ""Shiqi Wang"", ""Yihan Wang"", ""Suman Jana"", ""Xue Lin"", ""Cho-Jui Hsieh""]","[""neural network verification"", ""branch and bound""]",We use fast bound propagation methods on GPUs for complete neural network verification and achieve large speedup compared to SOTA.,2011.13824,cs.AI,2020-11-27 16:42:12+00:00,2021-03-16 16:35:00+00:00
nWlk4jwupZ,2022,Reject,False,ScheduleNet: Learn to solve multi-agent scheduling problems with reinforcement learning,"['Junyoung Park', 'Sanzhar Bakhtiyarov', 'Jinkyoo Park']","[""scheduling problems"", ""combinatorial optimization"", ""reinforcement learning"", ""graph"", ""graph neural network""]",,,,,
nWprF5r2spe,2022,Reject,False,ON THE GENERALIZATION OF WASSERSTEIN ROBUST FEDERATED LEARNING,"['Long Tan Le', 'Josh Nguyen', 'Canh T. Dinh', 'Nguyen Hoang Tran']","[""Federated Learning"", ""Robust Optimization"", ""Adversarial Training""]",,,,,
nXSDybDWV3,2021,Reject,False,Einstein VI:   General and Integrated Stein Variational Inference in NumPyro,"[""Ahmad Salim Al-Sibahi"", ""Ola R\u00f8nning"", ""Christophe Ley"", ""Thomas Wim Hamelryck""]","[""Stein variational inference"", ""variational inference"", ""probabilistic programming"", ""Pyro"", ""deep probabilistic programming"", ""deep learning""]","We present EinStein Variational Inference, a technique for inference that integrates all the latest developments within Stein VI into NumPyro, adds optimizable parameter transforms and supports ELBO optimization.",,,,
nZOUYEN6Wvy,2022,Accept (Poster),False,Granger causal inference on DAGs identifies genomic loci regulating transcription,"['Alexander P Wu', 'Rohit Singh', 'Bonnie Berger']","[""Granger causality"", ""causal inference"", ""graph neural networks"", ""gene regulation"", ""single-cell genomics"", ""chromatin accessibility"", ""directed acyclic graphs"", ""single-cell multimodal""]","We show how to extend Granger causality to DAG-structured dynamical systems using graph neural networks, applying it to infer noncoding regions involved in gene regulation.",,,,
nZeVKeeFYf9,2022,Accept (Poster),False,LoRA: Low-Rank Adaptation of Large Language Models,"['Edward J Hu', 'yelong shen', 'Phillip Wallis', 'Zeyuan Allen-Zhu', 'Yuanzhi Li', 'Shean Wang', 'Lu Wang', 'Weizhu Chen']","[""Transfer learning"", ""Adaptation"", ""Transformer"", ""Fine-tuning"", ""Low-rank"", ""RoBERTa"", ""DeBERTa"", ""GPT-2"", ""GPT-3""]","Finetuning updates have a low ""intrinsic rank"" which allows us to train only the rank decomposition matrices of certain weights, yielding better performance and practical benefits.",,,,
naSAkn2Xo46,2021,Reject,False,Factored Action Spaces in Deep Reinforcement Learning,"[""Thomas PIERROT"", ""Valentin Mac\u00e9"", ""Jean-Baptiste Sevestre"", ""Louis Monier"", ""Alexandre Laterre"", ""Nicolas Perrin"", ""Karim Beguir"", ""Olivier Sigaud""]","[""Deep Reinforcement Learning"", ""Large action spaces"", ""Parameterized action spaces"", ""Multi-Agent"", ""Continuous Control""]",We propose a theoretical study as well as practical tips and applications of action spaces factorization in deep Reinforcement Learning.,,,,
naoQDOYsHnS,2022,Reject,False,Learning Pseudometric-based Action Representations for Offline Reinforcement Learning,"['Pengjie Gu', 'Mengchen Zhao', 'Chen Chen', 'Dong Li', 'Jianye Hao', 'Bo An']","[""offline reinforcement learning\uff0crepresentation learning\uff0c metric learning""]",,,,,
nbC8iTTXIrk,2022,Accept (Poster),False,Optimization inspired Multi-Branch Equilibrium Models,"['Mingjie Li', 'Yisen Wang', 'Xingyu Xie', 'Zhouchen Lin']",[],A Multi-Branch DEQ model and its training strategy proposed by minimizing an objective function designed as our purpose.,,,,
nc0ETaieux,2022,Accept (Poster),False,Minimax Optimality (Probably) Doesn't Imply Distribution Learning for GANs,"['Sitan Chen', 'Jerry Li', 'Yuanzhi Li', 'Raghu Meka']","[""theory of GANs"", ""distribution learning"", ""pseudorandom generators"", ""cryptography""]","Under the standard crypto assumption that local pseudorandom generators exist, we show that even a global optimizer for the population WGAN objective need not be close to the true distribution.",2201.07206,cs.LG,2022-01-18 18:59:21+00:00,2022-01-18 18:59:21+00:00
neqU3HWDgE,2022,Accept (Poster),False,Unsupervised Disentanglement with Tensor Product Representations on the Torus,"['Michael Rotman', 'Amit Dekel', 'Shir Gur', 'Yaron Oz', 'Lior Wolf']","[""Variational Auto-Encoder"", ""Disentanglement Learning""]",Decomposition of a latent space on a torus leads to a disentangled representation,,,,
nf3A0WZsXS5,2022,Accept (Poster),True,Surreal-GAN:Semi-Supervised Representation Learning via GAN for uncovering heterogeneous disease-related imaging patterns,"['Zhijian Yang', 'Junhao Wen', 'Christos Davatzikos']","[""Representation Learning"", ""Disease-related imaging patterns"", ""Alzheimer's disease"", ""MRI"", ""GAN""]","We proposed a novel method, Surreal-GAN, to derive low dimensional representation of disease-related patterns from neuroimaging data.",2006.15255,q-bio.QM,2020-06-27 02:06:21+00:00,2020-06-27 02:06:21+00:00
ng0IIc1mbTu,2021,Reject,False,ARELU: ATTENTION-BASED RECTIFIED LINEAR UNIT,"[""Chen Dengsheng"", ""Jun Li"", ""Kai Xu""]","[""activation function"", ""attention mechanism"", ""rectified linear unit""]",We propose a new perspective of learnable activation function through formulating them with element-wise attention mechanism.,,,,
ngjR4Gw9oAp,2022,Reject,False,Soft Actor-Critic with Inhibitory Networks for Faster Retraining,"['Jaime S. Ide', 'Daria Micovic', 'Adrian P Pope', 'Michael John Guarino', 'Kevin Alcedo', 'David Rosenbluth']","[""soft actor-critic"", ""SAC"", ""maximum entropy RL"", ""inhibitory response"", ""cognitive control""]",We apply inhibitory control ideas from neuroscience to soft actor-critic methods to speed-up retraining of RL agents,,,,
nhIsVl2UoMt,2021,Reject,True,Additive Poisson Process: Learning Intensity of Higher-Order Interaction in Stochastic Processes,"[""Simon Luo"", ""Feng Zhou"", ""Lamiae Azizi"", ""Mahito Sugiyama""]","[""Poisson Process"", ""Log-Linear Model"", ""Energy-Based Model"", ""Generalized Additive Models"", ""Information Geometry""]",Efficient estimation of high dimensional intensity function using information geometric projections.,2006.08982,stat.ML,2020-06-16 08:25:36+00:00,2020-06-16 08:25:36+00:00
nhN-fqxmNGx,2022,Accept (Poster),False,A Comparison of Variable Selection Methods for Blockwise Diagonal Designs,"['Tracy Ke', 'Longlin Wang']","[""Lasso"", ""Hamming error"", ""phase diagram"", ""rare and weak signals"", ""elastic net"", ""SCAD"", ""thresholded Lasso"", ""forward selection"", ""forward backward selection""]",A theoretical comparison of the Hamming errors for 6 different variable selection methods,,,,
nhnJ3oo6AB,2022,Accept (Spotlight),True,Learning Vision-Guided Quadrupedal Locomotion End-to-End with Cross-Modal Transformers,"['Ruihan Yang', 'Minghao Zhang', 'Nicklas Hansen', 'Huazhe Xu', 'Xiaolong Wang']","[""Reinforcement Learning"", ""Robotics"", ""Locomotion Control"", ""Multi-Modal Transformer""]","We introduce a novel end-to-end Reinforcement Learning approach called LocoTransformer, leveraging both visual inputs and proprioceptive states, for locomotion control in both simulation and with real robots.",2107.03996,cs.LG,2021-07-08 17:41:55+00:00,2021-10-20 17:48:42+00:00
niZImJIrqVt,2022,Reject,True,Mean-Variance Efficient Reinforcement Learning by Expected Quadratic Utility Maximization,"['Masahiro Kato', 'Kei Nakagawa', 'Kenshi Abe', 'Tetsuro Morimura']","[""Reinforcement learning"", ""Mean-variance tradeoff""]",Learning a policy achieving a Pareto efficiency in the sense of the mean variance trade-off by maximizing the expected quadratic utility function.,2010.01404,cs.LG,2020-10-03 18:17:34+00:00,2021-09-05 10:28:58+00:00
ni_nys-C9D6,2021,Reject,False,Differentiate Everything with a Reversible Domain-Specific Language,"[""JinGuo Liu"", ""Taine Zhao""]","[""Reversible computing"", ""automatic differentiation"", ""Julia""]",Design a reversible eDSL in Julia with native high performance AD support.,,,,
nioAdKCEdXB,2022,Accept (Poster),False,Likelihood Training of SchrÃ¶dinger Bridge using Forward-Backward SDEs Theory,"['Tianrong Chen', 'Guan-Horng Liu', 'Evangelos Theodorou']","[""Schr\u00f6dinger Bridge"", ""score-based generative model"", ""optimal transport"", ""forward-backward stochastic differential equations"", ""stochastic optimal control""]","We present a new computational framework, grounded on Forward-Backward SDEs theory, for the log-likelihood training of SchrÃ¶dinger Bridge and provide theoretical connections to score-baesd generative models.",,,,
nkIDwI6oO4_,2021,Accept (Poster),False,Learning A Minimax Optimizer: A Pilot Study,"[""Jiayi Shen"", ""Xiaohan Chen"", ""Howard Heaton"", ""Tianlong Chen"", ""Jialin Liu"", ""Wotao Yin"", ""Zhangyang Wang""]","[""Learning to Optimize"", ""Minimax Optimization""]","This paper introduces the learning to optimize (L2O) methodology, called Twin L2O, for minimax optimization consisting of two LSTMs.",,,,
nkaba3ND7B5,2022,Accept (Poster),False,Autonomous Reinforcement Learning: Formalism and Benchmarking,"['Archit Sharma', 'Kelvin Xu', 'Nikhil Sardana', 'Abhishek Gupta', 'Karol Hausman', 'Sergey Levine', 'Chelsea Finn']","[""reinforcement learning"", ""autonomous"", ""reset-free reinforcement learning"", ""continual reinforcement learning""]",,,,,
nkap3LV7t7O,2021,Reject,True,Simple and Effective VAE Training with Calibrated Decoders,"[""Oleh Rybkin"", ""Kostas Daniilidis"", ""Sergey Levine""]","[""variational autoencoders"", ""\u03b2-VAE"", ""representation learning""]",We analyze calibrated decoders for VAE training and provide recommendations for simple and effective training without heuristic hyperparameters. ,2006.13202,cs.LG,2020-06-23 17:57:47+00:00,2021-07-12 04:06:41+00:00
nlWgE3A-iS,2021,Reject,False,ReaPER: Improving Sample Efficiency in Model-Based Latent Imagination,"[""Martin A Bertran"", ""Guillermo Sapiro"", ""mariano phielipp""]","[""model-based reinforcement learning"", ""visual control"", ""sample efficiency""]","We introduce ReaPER, an algorithm that addresses the sample efficiency challenge in model-based DRL, we illustrate the power of the proposed solution on the DeepMind Control benchmark.",,,,
nnU3IUMJmN,2022,Accept (Poster),False,Capturing Structural Locality in Non-parametric Language Models,"['Frank F. Xu', 'Junxian He', 'Graham Neubig', 'Vincent Josua Hellendoorn']",[]," We propose, study the effect of, and incorporate structural locality in non-parametric language models.",,,,
noaG7SrPVK0,2022,Accept (Poster),False,Counterfactual Plans under Distributional Ambiguity,"['Ngoc Bui', 'Duy Nguyen', 'Viet Anh Nguyen']","[""Counterfactual explanations"", ""Robust optimization""]","This study the counterfactual plans under model uncertainty, in which the distribution of the model parameters is partially prescribed using only the first- and second-moment information.",2201.12487,cs.LG,2022-01-29 03:41:47+00:00,2022-01-29 03:41:47+00:00
npOuXc85I5k,2021,Reject,False,Pareto Adversarial Robustness: Balancing Spatial Robustness and Sensitivity-based Robustness,"[""Ke Sun"", ""Mingjie Li"", ""Zhouchen Lin""]",[],,2111.01996,cs.LG,2021-11-03 03:28:30+00:00,2021-11-03 03:28:30+00:00
npkSFg-ktnW,2021,Reject,False,Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration,"[""Yunhao Ge"", ""Gan Xin"", ""Zhi Xu"", ""Yao Xiao"", ""Yunkui Pang"", ""Yining HE"", ""Laurent Itti""]","[""Generative autoencoder"", ""disentangled representation learning"", ""attribute controllable synthesis""]",Disentanglement and ExplorationAutoencoder (DEAE) using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  ,,,,
nrGGfMbY_qK,2022,Accept (Poster),True,Online Continual Learning on Class Incremental Blurry Task Configuration with Anytime Inference,"['Hyunseo Koh', 'Dahyun Kim', 'Jung-Woo Ha', 'Jonghyun Choi']","[""online"", ""continual learning"", ""task-free continual learning"", ""any-time inference""]","a novel continual learning set-up that is online and task-free, has new class distributions and focuses on any-time inference",2110.10031,cs.LG,2021-10-19 14:59:48+00:00,2021-10-19 14:59:48+00:00
nsZGadY22N4,2021,Reject,True,Weighted Bellman Backups for Improved Signal-to-Noise in Q-Updates,"[""Kimin Lee"", ""Michael Laskin"", ""Aravind Srinivas"", ""Pieter Abbeel""]","[""Deep reinforcement learning"", ""ensemble learning"", ""Q-learning""]","We propose ensemble-based weighted Bellman backups for preventing error propagation in Q-learning, and introduce a simple unified ensemble method that handles various issues in off-policy RL algorithms.",2007.04938,cs.LG,2020-07-09 17:08:44+00:00,2021-06-11 21:00:13+00:00
nsjkNB2oKsQ,2022,Reject,True,Off-Policy Reinforcement Learning with Delayed Rewards,"['Beining Han', 'Zhizhou Ren', 'Zuofan Wu', 'Yuan Zhou', 'Jian Peng']","[""Delayed Rewards"", ""Off-Policy Reinforcement Learning""]",We put forward a SOTA off-policy RL algorithm that can handle non-Markovian rewards with theoretical support.,2106.11854,cs.LG,2021-06-22 15:19:48+00:00,2021-06-22 15:19:48+00:00
nuWpS9FNSKn,2022,Reject,False,One Objective for All Models --- Self-supervised Learning for Topic Models,"['Zeping Luo', 'Cindy Weng', 'Shiyou Wu', 'Mo Zhou', 'Rong Ge']","[""self-supervised learning"", ""topic models""]",We study the self-supervised learning in the topic models setup and show that it can provide useful information about the topic posterior for general topic models.,,,,
nuwy7R_kemM,2021,Reject,False,Wat zei je? Detecting Out-of-Distribution Translations with Variational Transformers,"[""Tim Z. Xiao"", ""Aidan Gomez"", ""Yarin Gal""]","[""Bayesian Deep Learning"", ""Uncertainty"", ""NMT"", ""Transformer""]",A new measure for estimating uncertainty in NMT.,,,,
nwKXyFvaUm,2022,Accept (Poster),False,Diverse Client Selection for Federated Learning via Submodular Maximization,"['Ravikumar Balakrishnan', 'Tian Li', 'Tianyi Zhou', 'Nageen Himayat', 'Virginia Smith', 'Jeff Bilmes']","[""federated learning"", ""submodularity"", ""diversity""]",The paper addresses a key challenge of selecting the most representative clients iteratively for federated learning through formulating it as a submodular optimization problem and developing efficient algorithms.,,,,
nxJ8ugF24q2,2021,Reject,False,Learning Disconnected Manifolds: Avoiding The No Gan's Land by Latent Rejection,"[""Thibaut Issenhuth"", ""Ugo Tanielian"", ""David Picard"", ""Jeremie Mary""]",[],,,,,
nxcABL7jbQh,2022,Accept (Poster),False,Zero Pixel Directional Boundary by Vector Transform,"['Edoardo Mello Rella', 'Ajad Chhatkuli', 'Yun Liu', 'Ender Konukoglu', 'Luc Van Gool']",[],,,,,
nzKv5vxZfge,2021,Reject,False,Causal Screening to Interpret Graph Neural Networks,"[""Xiang Wang"", ""Yingxin Wu"", ""An Zhang"", ""Xiangnan He"", ""Tat-seng Chua""]","[""Feature Attribution"", ""Graph Neural Networks"", ""Explainable Methods"", ""Causal Effect""]","We explore the causal interpretability of graph neural networks, and propose a new method, Causal Screening, to identify the most inï¬uential edges and generate post-hoc explanations for model predictions.",,,,
nzLFm097HI,2021,Reject,False,How to Design Sample and Computationally Efficient VQA Models,"[""Karan Samel"", ""Zelin Zhao"", ""Kuan Wang"", ""Robin Luo"", ""Binghong Chen"", ""Le Song""]","[""vqa"", ""visual question answering"", ""neural modules"", ""probabilistic logic""]","An exploration of which individual components of VQA methods are most efficient, and show that the combination of all these components provides the most efficient model.",,,,
nzpLWnVAyah,2021,Accept (Poster),False,"On the Stability of Fine-tuning BERT: Misconceptions, Explanations, and Strong Baselines","[""Marius Mosbach"", ""Maksym Andriushchenko"", ""Dietrich Klakow""]","[""fine-tuning stability"", ""transfer learning"", ""pretrained language model"", ""BERT""]",We provide an analysis of the fine-tuning instability of BERT-based models and present a simple method to fix it.,,,,
nzvbBD_3J-g,2022,Accept (Poster),False,On Incorporating Inductive Biases into VAEs,"['Ning Miao', 'Emile Mathieu', 'Siddharth N', 'Yee Whye Teh', 'Tom Rainforth']","[""VAEs"", ""Variational autoencoders"", ""Variational auto-encoders"", ""Representation learning"", ""Inductive biases""]",A flexible and effective framework for adding inductive biases to VAEs that corrects the pathologies of previous approaches and leads to improved representations and generative models.,,,,
o-1v9hdSult,2022,Accept (Poster),True,Bridging the Gap: Providing Post-Hoc Symbolic Explanations for Sequential Decision-Making Problems with Inscrutable Representations,"['Sarath Sreedharan', 'Utkarsh Soni', 'Mudit Verma', 'Siddharth Srivastava', 'Subbarao Kambhampati']","[""Explanations"", ""XAI"", ""Post-hoc explanations""]",,2002.01080,cs.AI,2020-02-04 01:37:56+00:00,2021-10-06 00:17:50+00:00
o0ehFykKVtr,2022,Accept (Poster),False,Transferable Visual Control Policies Through Robot-Awareness,"['Edward S. Hu', 'Kun Huang', 'Oleh Rybkin', 'Dinesh Jayaraman']","[""visual foresight"", ""dynamics models"", ""visuomotor control"", ""video prediction"", ""planning"", ""transfer""]",We closely integrate readily available knowledge about the robot and world into a learned model to facilitate transfer.,,,,
o1O5nc48rn,2021,Reject,False,Optimal Transport Graph Neural Networks,"[""Gary B\u00e9cigneul"", ""Octavian-Eugen Ganea"", ""Benson Chen"", ""Regina Barzilay"", ""Tommi S. Jaakkola""]","[""graph neural networks"", ""optimal transport"", ""molecular representations"", ""molecular property prediction""]",We compute graph representations based on abstract prototypes  that leverage optimal transport and graph neural networks.,,,,
o20_NVA92tK,2021,Reject,True,A Critical Analysis of Distribution Shift,"[""Dan Hendrycks"", ""Steven Basart"", ""Norman Mu"", ""Saurav Kadavath"", ""Frank Wang"", ""Evan Dorundo"", ""Rahul Desai"", ""Tyler Zhu"", ""Samyak Parajuli"", ""Mike Guo"", ""Dawn Song"", ""Jacob Steinhardt"", ""Justin Gilmer""]","[""distribution shift"", ""ood""]","We assess which techniques can help with robustness to distribution shift, and we find that none consistently help.",2006.16241,cs.CV,2020-06-29 17:59:10+00:00,2021-07-24 04:28:58+00:00
o21sjfFaU1,2021,Reject,False,Learning Robust Models by Countering Spurious Correlations,"[""Haohan Wang"", ""Zeyi Huang"", ""Eric Xing""]","[""robustness"", ""domain adaptation"", ""spurious correlation"", ""dataset bias""]","We offer a formal generalization error bound of the problem of learning when there are spurious correlated features, with the knowledge of these features. Our bound also leads to discussion of the methods for this problem. ",,,,
o29tNZZqGcN,2021,Reject,False,Bridging Graph Network to Lifelong Learning with Feature Interaction,"[""Chen Wang"", ""Yuheng Qiu"", ""Sebastian Scherer""]","[""Graph Neural Network"", ""Continual Learning""]",We propose a graph topology  to overcome the difficulty of directly applying continual learning techniques to graph networks.,,,,
o2N6AYOp31,2021,Reject,False,Augmentation-Interpolative AutoEncoders for Unsupervised Few-Shot Image Generation,"[""Davis Wertheimer"", ""Omid Poursaeed"", ""Bharath Hariharan""]","[""Interpolation"", ""autoencoder"", ""reconstruction"", ""few-shot learning"", ""few-shot image generation"", ""generalization"", ""augmentation""]",A reconstruction-based method with strong generalization capability for synthesizing images beyond the training domain,2011.13026,cs.CV,2020-11-25 21:18:55+00:00,2020-11-25 21:18:55+00:00
o2ko2D_uvXJ,2021,Reject,False,Group-Connected Multilayer Perceptron Networks,"[""Mohammad Kachuee"", ""Sajad Darabi"", ""Shayan Fazeli"", ""Majid Sarrafzadeh""]",[],,,,,
o3iritJHLfO,2021,Accept (Poster),False,Bidirectional Variational Inference for Non-Autoregressive Text-to-Speech,"[""Yoonhyung Lee"", ""Joongbo Shin"", ""Kyomin Jung""]","[""text-to-speech"", ""speech synthesis"", ""non-autoregressive"", ""VAE""]","In this paper, a novel non-autoregressive text-to-speech model based on bidirectional-inference variational autoencoder called BVAE-TTS is proposed.",,,,
o6dG7nVYDS,2022,Reject,False,Finding lost DG: Explaining domain generalization via model complexity,"['Da Li', 'Henry Gouk', 'Timothy Hospedales']","[""domain generalisation"", ""rademacher complexity""]","We derive generalisation bounds for the Domain Generalisation problem setting, and then provide experimental evidence that existing DG approaches work because they implicitly control model capacity.",2202.00563,stat.ML,2022-02-01 17:08:29+00:00,2022-02-01 17:08:29+00:00
o6ndFLB1DST,2021,Reject,False,Semi-supervised counterfactual explanations,"[""SURYA SHRAVAN KUMAR SAJJA"", ""Sumanta Mukherjee"", ""Satyam Dwivedi"", ""Vikas C. Raykar""]","[""Semi-supervised feature representation"", ""counterfactual explanations""]",Semi supervised feature representation to achieve more interpretable counterfactual explanations,,,,
o7YTArVXdEW,2021,Reject,False,AC-VAE: Learning Semantic Representation with VAE for Adaptive Clustering,"[""Xingyu Xie"", ""Minjuan Zhu"", ""Yan Wang"", ""Lei Zhang""]","[""Unsupervised Representation Learning"", ""Neighbor Clustering"", ""Variational Autoencoder"", ""Unsupervised Classification""]",This paper proposes a VAE based network and a z-score based clustering method to achieve adaptive neighbor clustering for supporting unsupervised classification.,,,,
o81ZyBCojoA,2021,Accept (Poster),False,On Fast Adversarial Robustness Adaptation in Model-Agnostic Meta-Learning,"[""Ren Wang"", ""Kaidi Xu"", ""Sijia Liu"", ""Pin-Yu Chen"", ""Tsui-Wei Weng"", ""Chuang Gan"", ""Meng Wang""]",[],,2102.10454,cs.LG,2021-02-20 22:03:04+00:00,2021-02-20 22:03:04+00:00
o86_622j0sb,2022,Reject,False,Imperceptible Black-box Attack via Refining in Salient Region,"['Zeyu Dai', 'Shengcai Liu', 'Ke Tang', 'Qing Li']",[],,,,,
o8iGesI9HN-,2022,Reject,False,Optimized Separable Convolution: Yet Another Efficient Convolution Operator,"['Tao Wei', 'Yonghong Tian', 'Yaowei Wang', 'Yun Liang', 'Chang Wen Chen']","[""Separable Convolution"", ""Volumetric Receptive Field"", ""Optimized""]",,,,,
o966_Is_nPA,2021,Accept (Poster),False,Neural Pruning via Growing Regularization,"[""Huan Wang"", ""Can Qin"", ""Yulun Zhang"", ""Yun Fu""]","[""model compression"", ""deep neural network pruning"", ""Hessian matrix"", ""regularization""]",We propose two new deep network pruning algorithms based a growing regularization paradigm.,2012.09243,cs.CV,2020-12-16 20:16:28+00:00,2021-04-05 19:37:45+00:00
o9DnX55PEAo,2022,Reject,False,Cross-Architecture Distillation Using Bidirectional CMOW Embeddings,"['Lukas Paul Achatius Galke', 'Isabelle Cuber', 'Christoph Meyer', 'Henrik Ferdinand NÃ¶lscher', 'Angelina Sonderecker', 'Ansgar Scherp']","[""natural language processing"", ""word embedding"", ""knowledge distillation"", ""model compression"", ""efficient methods"", ""transfer learning""]",Large pretrained language models can be effectively distilled into more efficient matrix embedding models.,,,,
oAy7yPmdNz,2022,Accept (Poster),False,CoordX: Accelerating Implicit Neural Representation with a Split MLP Architecture,"['Ruofan Liang', 'Hongyi Sun', 'Nandita Vijaykumar']",[],,,,,
oBmpWzJTCa4,2021,Reject,False,Meta-Active Learning in Probabilistically-Safe Optimization,"[""Mariah L Schrum"", ""Mark Connolly"", ""Eric Cole"", ""Mihir Ghetiya"", ""Robert Gross"", ""Matthew C. Gombolay""]","[""meta-learning"", ""active-learning"", ""safe learning""]","We present a probabilistically-safe, meta-active learning approach to efficiently learn system dynamics and optimal system configurations based on an LSTM encoding of sample history.",,,,
oC12z8lkbrU,2022,Reject,False,"Generate, Annotate, and Learn: Generative Models Advance Self-Training and Knowledge Distillation","['Xuanli He', 'Islam Nassar', 'Jamie Ryan Kiros', 'Gholamreza Haffari', 'Mohammad Norouzi']","[""deep generative models"", ""semi-supervised learning"", ""knowledge distillation"", ""large language models""]","We propose a framework, so-called, GAL to advance self-training, knowledge distillation and few-shot learning on NLP and tabular datasets.",,,,
oDFvtxzPOx,2022,Accept (Spotlight),False,Self-Supervision Enhanced Feature Selection with Correlated Gates,"['Changhee Lee', 'Fergus Imrie', 'Mihaela van der Schaar']","[""Feature Selection"", ""Feature Importance"", ""Self-Supervised Learning""]",We propose a novel DL-based feature selection method using self-supervised learning and multivariate Bernoulli distribution to address common challenges in feature selection: a scarcity of labeled samples and significant correlations among features.,,,,
oFp8Mx_V5FL,2021,Accept (Poster),False,Overfitting for Fun and Profit: Instance-Adaptive Data Compression,"[""Ties van Rozendaal"", ""Iris AM Huijben"", ""Taco Cohen""]","[""Neural data compression"", ""Learned compression"", ""Generative modeling"", ""Overfitting"", ""Finetuning"", ""Instance learning"", ""Instance adaptation"", ""Variational autoencoders"", ""Rate-distortion optimization"", ""Model compression"", ""Weight quantization""]","We show that we can finetune an entire data compression model on a single instance, and improve the rate-distortion performance,Â taking into account the additional costs for sending theÂ model updates.",,,,
oGq4d9TbyIA,2021,Reject,False,Uniform-Precision Neural Network Quantization via Neural Channel Expansion,"[""Seongmin Park"", ""Beomseok Kwon"", ""Kyuyoung Sim"", ""Jieun Lim"", ""Tae-Ho Kim"", ""Jungwook Choi""]","[""deep neural network"", ""quantization"", ""neural architecture search"", ""image classification"", ""reduced precision"", ""inference""]","a new NAS-based quantization algorithm called neural channel expansion (NCE), which is equipped with a simple yet innovative channel expansion mechanism to balance the number of channels across the layers under uniform-precision quantization.",,,,
oGzm2X0aek,2021,Reject,False,Offline Adaptive Policy Leaning in Real-World Sequential Recommendation Systems,"[""Xiong-Hui Chen"", ""Yang Yu"", ""Qingyang Li"", ""Zhiwei Tony Qin"", ""Wenjie Shang"", ""Yiping Meng"", ""Jieping Ye""]","[""Reinforcement learning"", ""Recommendation system""]",we propose a new paradigm to learn an RL policy from offline data in the real-world sequential recommendation system,,,,
oJGDYQFKL3i,2022,Accept (Poster),False,OBJECT DYNAMICS DISTILLATION FOR SCENE DECOMPOSITION AND REPRESENTATION,"['Qu Tang', 'Xiangyu Zhu', 'Zhen Lei', 'Zhaoxiang Zhang']",[],,,,,
oKWmzgO7bfl,2021,Reject,False,Detection Booster Training: A detection booster training method for improving the accuracy of classifiers.,"[""Ali Ghobadzadeh"", ""Deepak Sridhar"", ""Juwei Lu"", ""Wei Li""]","[""Representation Learning"", ""Deep Learning Theory"", ""Face Recognition"", ""Image Classification"", ""Parametric Estimation Theory""]",We introduce a new detection booster training method using estimation theory (statistical inference) to improve classification accuracies while implicitly achieving robustness.,,,,
oLYTo-pL0Be,2022,Reject,False,Towards Scheduling Federated Deep Learning using Meta-Gradients for Inter-Hospital Learning,"['Rasheed El-Bouri', 'Tingting Zhu', 'David A. Clifton']","[""federated learning"", ""hospital""]",A federated learning approach to learn effectively from multiple noisy hospital datasets,,,,
oLltLS5F9R,2021,Reject,True,Learning Graph Normalization for Graph Neural Networks,"[""Yihao Chen"", ""Xin Tang"", ""Xianbiao Qi"", ""Chun-Guang Li"", ""Rong Xiao""]","[""Graph Neural Network"", ""Normalization"", ""Graph Normalization""]",We propose two graph-aware normalization methods for training GNNs and also propose to learn graph normalization which optimizes a weighted combination of multiple normalization methods. ,2009.11746,cs.LG,2020-09-24 15:16:43+00:00,2020-09-24 15:16:43+00:00
oMI9PjOb9Jl,2022,Accept (Poster),False,DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR,"['Shilong Liu', 'Feng Li', 'Hao Zhang', 'Xiao Yang', 'Xianbiao Qi', 'Hang Su', 'Jun Zhu', 'Lei Zhang']","[""Object detection"", ""Transformer""]",We present in this paper a novel query formulation using dynamic anchor boxes for DETR and offer a deeper understanding of the role of queries in DETR. ,,,,
oOuPVoT1kA5,2022,Reject,False,FEVERLESS: Fast and Secure Vertical Federated Learning based on XGBoost for Decentralized Labels,"['Rui Wang', 'OÄuzhan Ersoy', 'Hangyu Zhu', 'Yaochu Jin', 'Kaitai Liang']",[],,,,,
oQyb8NrFzu,2021,Reject,False,Revisiting the Stability of Stochastic Gradient Descent: A Tightness Analysis,"[""Yikai Zhang"", ""Samuel Bald"", ""wenjia Zhang"", ""Vamsi Pritham Pingali"", ""Chao Chen"", ""Mayank Goswami""]","[""SGD"", ""Stability"", ""Generalization"", ""Deep Learning""]","This paper tightens the algorithmic stability bounds on SGD and, noting the inapplicability of said bounds to the setting of deep learning, provides an empirically-supported hypothesis to explain deep learning generalization.",,,,
oSP1hwZB24,2022,Reject,False,Dynamic Parameterized Network for CTR Prediction,"['Jian Zhu', 'Congcong Liu', 'Pei Wang', 'Xiwei Zhao', 'Guangpeng Chen', 'Jin Jun Sheng', 'Changping Peng', 'Zhangang Lin', 'Jingping Shao']","[""Recommendation System"", ""Feature modeling"", ""User Behavior modeling"", ""Dynamic Network""]",,,,,
oSrM_jG_Ng,2021,Reject,False,The Benefit of Distraction: Denoising Remote Vitals Measurements Using Inverse Attention,"[""Ewa Magdalena Nowara"", ""Daniel McDuff"", ""Ashok Veeraraghavan""]","[""convolutional attention networks"", ""denoising"", ""computer vision"", ""camera-based physiology""]",Regions ignored by the attention networks can provide powerful noise estimates and denoise signals of interest.,,,,
oTQNAU_g_AZ,2022,Reject,False,DAIR: Disentangled Attention Intrinsic Regularization for Safe and Efficient Bimanual Manipulation,"['Minghao Zhang', 'Pingcheng Jian', 'Yi Wu', 'Huazhe Xu', 'Xiaolong Wang']","[""Reinforcement Learning"", ""Safe Robotics"", ""Bimanual Manipulation"", ""Attention Mechanism""]",We propose a novel Disentangled Attention Intrinsic Regularization which helps two robots to collaborate efficiently and safely for diverse manipulation tasks.,,,,
oU3aTsmeRQV,2022,Accept (Poster),False,Self-ensemble Adversarial Training for Improved Robustness,"['Hongjun Wang', 'Yisen Wang']","[""Adversarial Example"", ""Adversarial Training""]",This paper proposes an efficient self-ensemble method for adversarial trained classifiers and significantly improve their adversarial robustness,,,,
oVE1z8NlNe,2022,Accept (Poster),False,Divergence-aware Federated Self-Supervised Learning,"['Weiming Zhuang', 'Yonggang Wen', 'Shuai Zhang']","[""Federated Learning"", ""Self-supervised Learning"", ""Unsupervised representation learning""]","We propose a new approach, FedEMA, to address the non-IID data challenge in federated self-supervised learning (FedSSL), inspired by deep insights uncovered from in-depth empirical studies using a newly introduced FedSSL framework.",,,,
oVfIKuhqfC,2022,Reject,False,Non-Denoising Forward-Time Diffusions,['Stefano Peluchetti'],"[""deep learning"", ""diffusion"", ""SDE"", ""generative modelling"", ""DDPM""]",We introduce methodological advances for diffusion-based generative modeling.,,,,
oVz-YWdiMjt,2021,Reject,False,Single Layers of Attention Suffice to Predict Protein Contacts,"[""Nick Bhattacharya"", ""Neil Thomas"", ""Roshan Rao"", ""Justas Daupras"", ""Peter K Koo"", ""David Baker"", ""Yun S. Song"", ""Sergey Ovchinnikov""]","[""Protein Structure"", ""Proteins"", ""Contact Prediction"", ""Representation Learning"", ""Language Modeling"", ""Attention"", ""Transformer"", ""BERT"", ""Markov Random Fields"", ""Potts Models"", ""Self-supervised learning""]",We show a single layer of attention can achieve competitive results on protein contact prediction and provide a link between attention and Potts models to explore why.,,,,
oWZsQ8o5EA,2022,Accept (Poster),True,On the Generalization of Models Trained with SGD: Information-Theoretic Bounds and Implications,"['Ziqiao Wang', 'Yongyi Mao']","[""deep learning"", ""generalization"", ""information theory"", ""learning bound"", ""regularization""]",We derived new information-theoretic generalization bounds for SGD and we also proposed a new regularization scheme.,2110.03128,cs.LG,2021-10-07 00:53:33+00:00,2021-10-07 00:53:33+00:00
oXQxan1BWgU,2021,Reject,False,Model agnostic meta-learning on trees,"[""Jezabel Garcia"", ""Federica Freddi"", ""Jamie McGowan"", ""Tim Nieradzik"", ""Da-shan Shiu"", ""Ye Tian"", ""Alberto Bernacchia""]","[""Meta-learning"", ""hierarchical data"", ""clustering""]",We propose a modification of MAML to learn a hierarchical distribution of tasks,,,,
oY7La6DBTLx,2021,Reject,False,One-class Classification Robust to Geometric Transformation,"[""Hyunjun Ju"", ""Dongha Lee"", ""SeongKu Kang"", ""Hwanjo Yu""]","[""one-class classification"", ""image classification"", ""object classification"", ""self-supervised learning"", ""geometric robustness""]","This paper proposes a one-class classification method robust to geometric transformations, which effectively addresses the challenge that in-class images cannot be correctly distinguished from out-of-class images when they have various viewpoints. ",,,,
oZIvHV04XgC,2021,Accept (Poster),False,Wandering within a world: Online contextualized few-shot learning,"[""Mengye Ren"", ""Michael Louis Iuzzolino"", ""Michael Curtis Mozer"", ""Richard Zemel""]","[""Few-shot learning"", ""continual learning"", ""lifelong learning""]",We propose a new continual few-shot learning paradigm and a new model.,,,,
oZe7Zdia1H5,2022,Reject,False,Lottery Tickets can have Structural Sparsity,"['Tianlong Chen', 'Xuxi Chen', 'Xiaolong Ma', 'Yanzhi Wang', 'Zhangyang Wang']","[""Lottery Ticket Hypothesis"", ""Structural Winning Tickets""]",This paper for the first time demonstrates the general existence of structural winning tickets.,2202.04736,cs.LG,2022-02-09 21:33:51+00:00,2022-02-09 21:33:51+00:00
o_HsiMPYh_x,2022,Accept (Poster),False,Leveraging unlabeled data to predict out-of-distribution performance,"['Saurabh Garg', 'Sivaraman Balakrishnan', 'Zachary Chase Lipton', 'Behnam Neyshabur', 'Hanie Sedghi']","[""Distribution Shift"", ""OOD error prediction"", ""Deep Learning""]",,,,,
o_V-MjyyGV_,2021,Accept (Spotlight),False,Self-Supervised Policy Adaptation during Deployment,"[""Nicklas Hansen"", ""Rishabh Jangir"", ""Yu Sun"", ""Guillem Aleny\u00e0"", ""Pieter Abbeel"", ""Alexei A Efros"", ""Lerrel Pinto"", ""Xiaolong Wang""]","[""reinforcement learning"", ""robotics"", ""self-supervised learning"", ""generalization"", ""sim2real""]","Generalization across enviroments is known to be hard. We propose a self-supervised method for policy adaptation during deployment that assumes no prior knowledge of the test environment, yet still obtains significant improvements.",,,,
oaKw-GmBZZ,2022,Reject,False,Learning Time-dependent PDE Solver using Message Passing Graph Neural Networks,"['Pourya Pilva', 'Ahmad Zareei']","[""graph neural networks"", ""partial differential equations"", ""time-dependent PDE"", ""message passing graph neural networks""]",Solving Time-dependent PDEs using (Recurrent) Message Passing Graph Neural Networks,,,,
oapKSVM2bcj,2022,Accept (Oral),False,Einops: Clear and Reliable Tensor Manipulations with Einstein-like Notation,['Alex Rogozhnikov'],"[""tensor manipulations"", ""tensor transformation"", ""einops"", ""einstein notation"", ""einsum""]",We propose a notation for clear and reliable tensor manipulations; we implented notation in Python package to handle multiple frameworks,,,,
obi9EkyVeED,2022,Reject,False,FedDrop: Trajectory-weighted Dropout for Efficient Federated Learning,"['Dongping Liao', 'Xitong Gao', 'Yiren Zhao', 'Hao Dai', 'Li Li', 'Kafeng Wang', 'Kejiang Ye', 'Yang Wang', 'Cheng-zhong Xu']","[""federated learning"", ""efficient training"", ""dropout"", ""stochastic model"", ""channel selection""]","FedDrop adjusts channel dropout probabilities to concentrate the clients' training effort on neurons that they specialize well, while sparsifying models for improved communication/compute trade-offs.",,,,
oeHTRAehiFF,2021,Reject,False,ChemistryQA: A Complex Question Answering Dataset from Chemistry,"[""Zhuoyu Wei"", ""Wei Ji"", ""Xiubo Geng"", ""Yining Chen"", ""Baihua Chen"", ""Tao Qin"", ""Daxin Jiang""]",[],,,,,
oev4KdikGjy,2021,Reject,False,FMix: Enhancing Mixed Sample Data Augmentation,"[""Ethan Harris"", ""Antonia Marcu"", ""Matthew Painter"", ""Mahesan Niranjan"", ""Adam Prugel-Bennett"", ""Jonathon Hare""]",[],,,,,
ofLwshMBL_H,2022,Reject,False,Continual Learning Using Task Conditional Neural Networks,"['Honglin Li', 'Frieder Ganz', 'David J. Sharp', 'Payam M. Barnaghi']","[""catastrophic forgetting"", ""continual learning""]",A dynamic approach for continual learning,,,,
oh4TirnfSem,2022,Accept (Poster),False,PF-GNN: Differentiable particle filtering based approximation of universal graph representations,"['Mohammed Haroon Dupty', 'Yanfei Dong', 'Wee Sun Lee']","[""Graph Neural Networks"", ""Graph representation learning"", ""Expressive GNN""]",Increasing the expressive power of Graph Neural Networks by using techniques from exact isomorphism solvers with a particle filtering approach.,,,,
oh71uL93yay,2021,Reject,True,Unifying Graph Convolutional Neural Networks and Label Propagation,"[""Hongwei Wang"", ""Jure Leskovec""]","[""graph convolutional neural networks"", ""label propagation"", ""semi-supervised node classification""]","This paper studies theoretical relationships between Graph Convolutional Neural Networks (GCN) and Label Propagation Algorithm (LPA), then proposes an end-to-end model that unifies GCN and LPA for semi-supervised node classification.",2002.06755,cs.LG,2020-02-17 03:23:13+00:00,2020-02-17 03:23:13+00:00
ohdw3t-8VCY,2021,Reject,False,CTRLsum: Towards Generic Controllable Text Summarization,"[""Junxian He"", ""Wojciech Maciej Kryscinski"", ""Bryan McCann"", ""Nazneen Rajani"", ""Caiming Xiong""]","[""controllable text summarization""]","We present CTRLsum, a generic framework for controllable summarization that is able to achieve a broad scope of summary manipulation",,,,
ohz3OEhVcs,2021,Reject,False,Graph Autoencoders with Deconvolutional Networks,"[""Jia Li"", ""Jianwei Yu"", ""Da-Cheng Juan"", ""HAN Zhichao"", ""Arjun Gopalan"", ""Hong Cheng"", ""Andrew Tomkins""]","[""graph autoencoders"", ""graph deconvolutional networks""]",,,,,
oiZJwC_fyS,2022,Accept (Poster),False,Neural Network Approximation based on Hausdorff distance of Zonotopes,"['Panagiotis Misiakos', 'Georgios Smyrnis', 'George Retsinas', 'Petros Maragos']","[""Tropical Geometry"", ""Zonotopes"", ""Hausdorff Approximation"", ""Neural Network Compression""]",,,,,
oj2yn1Q4Ett,2022,Accept (Poster),False,Decentralized Learning for Overparameterized Problems: A Multi-Agent Kernel Approximation Approach,"['Prashant Khanduri', 'Haibo Yang', 'Mingyi Hong', 'Jia Liu', 'Hoi To Wai', 'Sijia Liu']","[""distributed optimization"", ""over-parameterized optimization"", ""kernel learning""]",Decentralized optimization for overparameterized kernel learning,,,,
oj3bHNSq_2w,2021,Reject,True,Sample weighting as an explanation for mode collapse in generative adversarial networks,"[""Aksel Wilhelm Wold Eide"", ""Eilif Solberg"", ""Ingebj\u00f8rg K\u00e5sen""]","[""GAN"", ""generative adversarial networks"", ""generative model"", ""image synthesis"", ""sample weighting"", ""importance weighting"", ""cost function"", ""loss"", ""mode collapse"", ""mode dropping"", ""coverage"", ""divergence"", ""FID"", ""training dynamics"", ""NS-GAN"", ""MM-GAN"", ""non-saturating"", ""minimax""]","NS-GAN sample weighting causes mode collapse: MM-GAN has much better training dynamics, but requires a gradient rescaling to avoid saturation.",2010.02035,cs.LG,2020-10-05 14:13:45+00:00,2020-10-05 14:13:45+00:00
ok4MWWSeOJ1,2021,Reject,True,Unifying Regularisation Methods for Continual Learning,"[""Frederik Benzing""]","[""Continual Learning"", ""Regularisation"", ""Fisher Information""]",,2006.06357,cs.LG,2020-06-11 12:20:38+00:00,2021-02-03 20:53:03+00:00
okT7QRhSYBw,2021,Reject,False,Anti-Distillation: Improving Reproducibility of Deep Networks,"[""Gil I Shamir"", ""Lorenzo Coviello""]","[""Deep networks"", ""ensembles"", ""reproducibility""]","A novel approach, Anti-Distillation, is proposed to address irreproducibility in deep networks, where ensemble models are used to generate predictions.",,,,
okmZ6-zU6Lz,2022,Reject,False,Quantifying the Controllability of Coarsely Characterized Networked Dynamical Systems,"['Nafiseh Ghoroghchian', 'Rajasekhar Anguluri', 'Gautam Dasarathy', 'Stark Draper']",[],We introduced a learning-based framework that exploits the power of community-based representation learning to infer average controllability of fine graphs from coarse summary data.,,,,
olQbo52II9,2022,Reject,False,Learning to Solve Combinatorial Problems via Efficient Exploration,"['Thomas D Barrett', 'Christopher William Falke Parsonson', 'Alexandre Laterre']","[""reinforcement learning"", ""combinatorial optimisation"", ""graph neural network"", ""maximum cut""]",Achieving SOTA performance and massive scalability on the Maximum-Cut problem by combining a single GNN pass with fast exploration at test time directed by a recurrent unit.,,,,
ol_xwLR2uWD,2021,Reject,False,Reviving Autoencoder Pretraining,"[""You Xie"", ""Nils Thuerey""]","[""unsupervised pretraining"", ""greedy layer-wise pretraining"", ""transfer learning"", ""orthogonality""]",We re-visit unsupervised autoencoder pretraining and propose a variant that relies on a full reverse pass trained in conjunction with a given training task.,,,,
om1guSP_ray,2021,Reject,False,Graph Pooling by Edge Cut,"[""Alexis Galland"", ""marc lelarge""]","[""graph"", ""deep"", ""learning"", ""pooling""]",A pooling layer for graph neural networks based on edge cuts.,,,,
on54StZqGQ_,2022,Reject,False,Degradation Attacks on Certifiably Robust Neural Networks,"['Klas Leino', 'Chi Zhang', 'Ravi Mangal', 'Matt Fredrikson', 'Bryan Parno', 'Corina Pasareanu']","[""adversarial examples"", ""certified defenses"", ""degradation attacks""]","Certifiably robust neural networks are too conservative, making them vulnerable to degradation attacks",,,,
onwTC5W0XJ,2022,Reject,False,Causally Focused Convolutional Networks Through Minimal Human Guidance,"['Rimmon Saloman Bhosale', 'Mrinal Das']","[""Causal Features"", ""Convolutional Networks"", ""Interpretability"", ""Minimal Guidance"", ""Computer Vision"", ""Deep Learning""]",,,,,
onxoVA9FxMw,2021,Accept (Poster),False,On Position Embeddings in BERT,"[""Benyou Wang"", ""Lifeng Shang"", ""Christina Lioma"", ""Xin Jiang"", ""Hao Yang"", ""Qun Liu"", ""Jakob Grue Simonsen""]","[""Position Embedding"", ""BERT"", ""pretrained language model.""]","This paper amis to understand and evaluate position embeddings, especially in pretrain language models",,,,
opHLcXxYTC_,2021,Accept (Spotlight),False,Influence Estimation for Generative Adversarial Networks,"[""Naoyuki Terashita"", ""Hiroki Ohashi"", ""Yuichi Nonaka"", ""Takashi Kanemaru""]","[""influence"", ""generative adversarial networks"", ""data cleansing""]","We propose an influence estimation method which predicts how GAN's output changes if an training instance is abesent, and propose to evaluate harmfulness of the instance by estimating how its absence improves GAN evaluation metric.",2101.08367,stat.ML,2021-01-20 23:55:54+00:00,2021-11-15 08:08:58+00:00
ot9bYHvuULl,2021,Reject,True,Augmented Sliced Wasserstein Distances,"[""Xiongjie Chen"", ""Yongxin Yang"", ""Yunpeng Li""]",[],,2006.08812,cs.LG,2020-06-15 23:00:08+00:00,2021-10-11 21:00:54+00:00
otuxSY_QDZ9,2021,Reject,True,Multilayer Dense Connections for Hierarchical Concept Classification,"[""Toufiq Parag"", ""Hongcheng Wang""]","[""Deep Learning: Applications"", ""Methodology"", ""and Theory"", ""Recognition: Detection"", ""Categorization"", ""Retrieval and Matching"", ""Scene Understanding"", ""Visual Reasoning""]",,2003.09015,cs.CV,2020-03-19 20:56:09+00:00,2021-02-22 19:20:39+00:00
ovRQmeVFbrC,2022,Reject,False,PARS: PSEUDO-LABEL AWARE ROBUST SAMPLE SELECTION FOR LEARNING WITH NOISY LABELS,"['Arushi Goel', 'Yunlong Jiao', 'Jordan Massiah']","[""learning with label noise""]",We propose a novel pseudo-label aware robust sample selection method for learning with noisy labels that outperforms state-of-the-art especially in presence of high label noise.,2201.10836,cs.CV,2022-01-26 09:31:55+00:00,2022-01-26 09:31:55+00:00
oweBPxtma_i,2021,Reject,False,A self-explanatory method for the black box problem on discrimination part of CNN,"[""Jinwei Zhao"", ""Qizhou Wang"", ""Wanli Qiu"", ""Guo Xie"", ""Wei Wang"", ""Xinhong Hei"", ""Deyu Meng""]","[""Convolution neural network"", ""Interpretability performance"", ""Markov random field""]","For finding the inherent causality implied in the discrimination part of CNN without largely reducing its generalization performance, a self-explanatory method is proposed.",,,,
ox8wgFpoyHc,2021,Reject,False,Targeted VAE: Structured Inference and Targeted Learning for Causal Parameter Estimation,"[""Matthew James Vowels"", ""Necati Cihan Camgoz"", ""Richard Bowden""]","[""causal inference"", ""variational inference"", ""disentanglement"", ""variational autoencoder""]",TVAE combines targeted learning theory with amortized variational inference to learn structured latent encodings to yield treatment effect estimation.,,,,
oxC2IBx8OuZ,2022,Reject,False,Towards Federated Learning on Time-Evolving Heterogeneous Data,"['Yongxin Guo', 'Tao Lin', 'Xiaoying Tang']","[""Federated Learning"", ""Continual Learning"", ""Convergence Analysis""]",We propose CFL framework to capture complex time-evolving scenarios in FL.,2112.13246,cs.LG,2021-12-25 14:58:52+00:00,2021-12-25 14:58:52+00:00
oxRaiMDSzwr,2021,Reject,False,NETWORK ROBUSTNESS TO PCA PERTURBATIONS,"[""Anan Kabaha"", ""Dana Drachsler Cohen""]","[""neural network robustness"", ""adversarial examples""]",A framework to detect robust and weak features of DNNs and to use them to define robustness neighborhoods and adversarial examples.,,,,
oxnp2q-PGL4,2021,Accept (Poster),True,Lossless Compression of Structured Convolutional Models via Lifting,"[""Gustav Sourek"", ""Filip Zelezny"", ""Ondrej Kuzelka""]","[""weight sharing"", ""graph neural networks"", ""lifted inference"", ""relational learning"", ""dynamic computation graphs"", ""convolutional models""]","Speeding up weight-sharing dynamic neural computation graphs, such as GNNs, with lifted inference.",2007.06567,cs.LG,2020-07-13 08:02:27+00:00,2021-01-18 12:49:03+00:00
oxwsctgY5da,2022,Reject,False,A Branch and Bound Framework for Stronger Adversarial Attacks of ReLU Networks,"['Huan Zhang', 'Shiqi Wang', 'Kaidi Xu', 'Yihan Wang', 'Suman Jana', 'Cho-Jui Hsieh', 'J Zico Kolter']","[""adversarial attack"", ""branch and bound"", ""adversarial robustness"", ""deep neural network""]",We propose a branch-and-bound based adversarial attack and aim to solve hard instance where none of existing adversarial attacks can succeed.,,,,
oxxUMeFwEHd,2022,Accept (Poster),False,Topological Graph Neural Networks,"['Max Horn', 'Edward De Brouwer', 'Michael Moor', 'Yves Moreau', 'Bastian Rieck', 'Karsten Borgwardt']","[""topology"", ""persistent homology"", ""gnn"", ""graph neural networks"", ""graph classification"", ""node classification"", ""filtrations"", ""topological data analysis"", ""tda""]",We describe a new layer for graph neural networks that incorporates multi-scale (ranging from local to global) topological information.,,,,
oyZxhRI2RiE,2021,Accept (Poster),False,SCoRe: Pre-Training for Context Representation in Conversational Semantic Parsing,"[""Tao Yu"", ""Rui Zhang"", ""Alex Polozov"", ""Christopher Meek"", ""Ahmed Hassan Awadallah""]",[],,,,,
p-BhZSz59o4,2022,Accept (Oral),False,BEiT: BERT Pre-Training of Image Transformers,"['Hangbo Bao', 'Li Dong', 'Songhao Piao', 'Furu Wei']","[""self-supervised learning"", ""pre-training"", ""vision Transformer""]",We propose a masked image modeling task to pretrain vision Transformers.,,,,
p-NZIuwqhI4,2021,Accept (Spotlight),False,On the Theory of Implicit Deep Learning: Global Convergence with Implicit Layers,"[""Kenji Kawaguchi""]","[""Implicit Deep Learning"", ""Deep Equilibrium Models"", ""Gradient Descent"", ""Learning Theory"", ""Non-Convex Optimization""]",We analyze gradient dynamics of a simple deep equilibrium model and mathematically prove its theoretical properties. ,2102.07346,cs.LG,2021-02-15 05:08:11+00:00,2021-02-18 18:39:14+00:00
p0rCmDEN_-,2022,Accept (Poster),False,Visual hyperacuity with moving sensor and recurrent neural computations,"['Alexander Rivkind', 'Or Ram', 'Eldad Assa', 'Michael Kreiserman', 'Ehud Ahissar']","[""visual system"", ""convolutional neural networks"", ""recurrent neural networks"", ""active vision"", ""active sensing"", ""ocular drift""]",We show how recurrent connectivity in early vision together with eye motion helps to cope with limited sensor's spatial resolution.,,,,
p3DKPQ7uaAi,2022,Accept (Poster),False,Temporal Alignment Prediction for Supervised Representation Learning and Few-Shot Sequence Classification,"['Bing Su', 'Ji-Rong Wen']","[""Temporal Alignment"", ""Supervised Representation Learning"", ""Few-shot Action Recognition"", ""Alignment Prediction"", ""Sequence Classification""]",We propose a learnable sequence distance by predicting the temporal alignment and show its application in supervised representation learning for sequence data and few-shot action recognition.,,,,
p3_z68kKrus,2021,Reject,True,"For interpolating kernel machines, minimizing the norm of the ERM solution minimizes stability","[""Akshay Rangamani"", ""Lorenzo Rosasco"", ""Tomaso Poggio""]","[""Stability"", ""Linear Regression"", ""Kernel Regression"", ""Cross Validation Leave One Out Stability"", ""Minimum norm solutions"", ""Interpolation"", ""Double Descent""]",,2006.15522,stat.ML,2020-06-28 05:54:03+00:00,2020-10-11 22:58:31+00:00
p4H9QlbJvx,2022,Reject,False,Rethinking Again the Value of Network Pruning -- A Dynamical Isometry Perspective,"['Huan Wang', 'Can Qin', 'Yue Bai', 'Yun Fu']","[""neural network pruning"", ""dynamical isometry"", ""model compression"", ""filter pruning""]",We show inheriting weights in filter pruning is valuable and examine the impact of finetuning LR on the final performance via dynamical isometry.,,,,
p5uylG94S68,2021,Accept (Poster),False,Model-based micro-data reinforcement learning: what are the crucial model properties and which model to choose?,"[""Bal\u00e1zs K\u00e9gl"", ""Gabriel Hurtado"", ""Albert Thomas""]","[""model-based reinforcement learning"", ""generative models"", ""mixture density nets"", ""dynamic systems"", ""heteroscedasticity""]",Crucial model properties for model-based reinforcement learning: multi-modal posterior predictives and heteroscedasticity.,,,,
p65lWYKpqKz,2021,Reject,True,Physics-aware Spatiotemporal Modules with Auxiliary Tasks for Meta-Learning,"[""Sungyong Seo"", ""Chuizheng Meng"", ""Sirisha Rambhatla"", ""Yan Liu""]","[""physics-aware learning"", ""spatiotemporal graph signals"", ""few shot learning""]",We propose physics-aware modules designed for meta-learning to tackle the few sample challenges in spatiotemporal physical observations in the real-world.,2006.08831,cs.LG,2020-06-15 23:51:40+00:00,2021-06-07 22:03:35+00:00
p7LSrQ3AADp,2022,Reject,False,Beyond Faithfulness: A Framework to Characterize and Compare Saliency Methods,"['Angie Boggust', 'Harini Suresh', 'Hendrik Strobelt', 'John Guttag', 'Arvind Satyanarayan']","[""saliency methods"", ""interpretability"", ""faithfulness"", ""explainability"", ""attribution"", ""feature importance""]","A framework to describe, compare, and select saliency methods, with nine dimensions corresponding to meaningful attributes about what the method represents and how it is computed.",,,,
p7OewL0RRIH,2021,Reject,False,Sself: Robust Federated Learning against Stragglers and Adversaries,"[""Jungwuk Park"", ""Dong-Jun Han"", ""Minseok Choi"", ""Jaekyun Moon""]","[""Federated Learning""]","We propose Sself, a semi-synchronous entropy and loss based filtering for federated learning, to tackle both stragglers and adversaries simultaneously.",,,,
p84tly8c4zf,2021,Reject,False,WeMix: How to Better Utilize Data Augmentation,"[""Yi Xu"", ""Asaf Noy"", ""Ming Lin"", ""Qi Qian"", ""Li Hao"", ""Rong Jin""]","[""Data Augmentation"", ""Data Bias"", ""Non-convex Optimization"", ""Deep Learning Theory""]",This paper theoretically and empirically studies how to better utilize data augmentation by correcting data bias.,,,,
p8agn6bmTbr,2021,Accept (Poster),False,Usable Information and Evolution of Optimal Representations During Training,"[""Michael Kleinman"", ""Alessandro Achille"", ""Daksh Idnani"", ""Jonathan Kao""]","[""Usable Information"", ""Representation Learning"", ""Learning Dynamics"", ""Initialization"", ""SGD""]",,,,,
p98WJxUC3Ca,2022,Accept (Poster),False,Discrepancy-Based Active Learning for Domain Adaptation,"['Antoine De mathelin', 'FranÃ§ois Deheeger', 'Mathilde MOUGEOT', 'Nicolas Vayatis']","[""active learning"", ""domain adaptation"", ""discrepancy"", ""kmedoids"", ""single batch"", ""covariate shift""]",This paper presents an active learning for domain adaptation method based on a localized discrepancy between source and target distributions.,,,,
pAJ3svHLDV,2021,Reject,False,R-MONet: Region-Based Unsupervised Scene Decomposition and Representation via Consistency of Object Representations,"[""Shengxin Qian""]","[""unsupervised representation learning"", ""unsupervised scene representation"", ""unsupervised scene decomposition"", ""generative models""]",We propose an unsupervised generative framework which can have better scene decomposition capability by ensuring the consistency between two kinds of object geometric representations (i.e. bounding boxes and foreground segmentation masks),,,,
pAbm1qfheGk,2021,Accept (Poster),False,Learning Neural Generative Dynamics for Molecular Conformation Generation,"[""Minkai Xu"", ""Shitong Luo"", ""Yoshua Bengio"", ""Jian Peng"", ""Jian Tang""]","[""Molecular conformation generation"", ""deep generative models"", ""continuous normalizing flow"", ""energy-based models""]",A novel probabilistic framework to generate valid and diverse molecular conformations. Reaching state-of-the-art results on conformation generation and inter-atomic distance modeling.,2102.10240,cs.LG,2021-02-20 03:17:58+00:00,2021-03-31 03:20:36+00:00
pAj7zLJK05U,2021,Reject,False,AttackDist: Characterizing Zero-day Adversarial Samples by Counter Attack,"[""Simin Chen"", ""Zihe Song"", ""Lei Ma"", ""Cong Liu"", ""Wei Yang""]",[],,,,,
pAq1h9sQhqd,2021,Reject,False,Stochastic Canonical Correlation Analysis: A Riemannian Approach,"[""Zihang Meng"", ""Rudrasis Chakraborty"", ""Vikas Singh""]","[""CCA"", ""streaming"", ""differential geometry"", ""DeepCCA"", ""fairness""]",We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task.,2106.07479,cs.LG,2021-06-08 23:38:29+00:00,2021-06-08 23:38:29+00:00
pBDwTjmdDo,2021,Reject,False,Dynamic Graph Representation Learning with Fourier Temporal State Embedding,"[""Yihan He"", ""Wei Cao"", ""Shun Zheng"", ""Zhifeng Gao"", ""Jiang Bian""]","[""Graph Neural Networks"", ""Dynamic Graph"", ""Signal Processing""]",,,,,
pBqLS-7KYAF,2021,Accept (Spotlight),True,Sparse Quantized Spectral Clustering,"[""Zhenyu Liao"", ""Romain Couillet"", ""Michael W. Mahoney""]","[""Eigenspectrum"", ""high-dimensional statistic"", ""random matrix theory"", ""spectral clustering""]",,2010.01376,stat.ML,2020-10-03 15:58:07+00:00,2020-10-03 15:58:07+00:00
pC00NfsvnSK,2022,Reject,False,Improving zero-shot generalization in offline reinforcement learning using generalized similarity functions,"['Bogdan Mazoure', 'Ilya Kostrikov', 'Ofir Nachum', 'Jonathan Tompson']","[""reinforcement learning"", ""representation learning"", ""self-supervised learning"", ""offline RL"", ""generalized value function"", ""generalization""]",Contrastive representation learning based on generalized value functions for better generalization in offline RL,2111.14629,cs.LG,2021-11-29 15:42:54+00:00,2021-11-29 15:42:54+00:00
pD9x3TmLONE,2021,Reject,False,XMixup: Efficient Transfer Learning with Auxiliary Samples by Cross-Domain Mixup,"[""Xingjian Li"", ""Haoyi Xiong"", ""Haozhe An"", ""Cheng-zhong Xu"", ""Dejing Dou""]","[""transfer learning"", ""deep learning""]",This paper presents an effective and efficient deep transfer learning algorithm. ,,,,
pETy-HVvGtt,2022,Accept (Poster),True,Disentanglement Analysis with Partial Information Decomposition,"['Seiya Tokui', 'Issei Sato']","[""disentangled representations"", ""variational autoencoders"", ""deep generative models""]",We establish a framework to analyze information sharing in a multivariate representation with Partial Information Decomposition and propose a new disentanglement metric.,2108.13753,stat.ML,2021-08-31 11:09:40+00:00,2022-02-10 01:43:08+00:00
pFyXqxChZc,2022,Accept (Spotlight),True,IntSGD: Adaptive Floatless Compression of Stochastic Gradients,"['Konstantin Mishchenko', 'Bokun Wang', 'Dmitry Kovalev', 'Peter RichtÃ¡rik']","[""optimization"", ""distributed optimization"", ""compression"", ""theory"", ""parallel training"", ""switchML""]",We propose the provably convergent and computationally cheap IntSGD algorithm for efficient distributed machine learning.,2102.08374,cs.LG,2021-02-16 18:58:57+00:00,2021-02-16 18:58:57+00:00
pGIHq1m7PU,2021,Accept (Poster),False,Explainable Subgraph Reasoning for Forecasting on Temporal Knowledge Graphs,"[""Zhen Han"", ""Peng Chen"", ""Yunpu Ma"", ""Volker Tresp""]","[""Temporal knowledge graph"", ""future link prediction"", ""graph neural network"", ""subgraph reasoning.""]",We propose an explainable attention-based reasoning model for predicting future links on temporal knowledge graphs.,2012.15537,cs.LG,2020-12-31 10:41:01+00:00,2021-04-01 13:17:47+00:00
pHXfe1cOmA,2021,Accept (Poster),False,HyperDynamics: Meta-Learning Object and Agent Dynamics with Hypernetworks,"[""Zhou Xian"", ""Shamit Lal"", ""Hsiao-Yu Tung"", ""Emmanouil Antonios Platanios"", ""Katerina Fragkiadaki""]",[],,2103.09439,cs.RO,2021-03-17 04:48:43+00:00,2021-03-17 04:48:43+00:00
pHgB1ASMgMW,2021,Reject,False,Rethinking Uncertainty in Deep Learning: Whether and How it Improves Robustness,"[""Yilun Jin"", ""Lixin Fan"", ""Kam Woh Ng"", ""Ce Ju"", ""Qiang Yang""]","[""Adversarial Robustness"", ""Uncertainty Promotion"", ""Adversarial Training""]","We show that uncertainty promotion regularizers complement adversarial training consistently, while uncertainty promotion alone does not provide consistent robustness. ",2011.13538,cs.LG,2020-11-27 03:22:50+00:00,2020-11-27 03:22:50+00:00
pHkBwAaZ3UK,2021,Reject,False,Learning Discrete Adaptive Receptive Fields for Graph Convolutional Networks,"[""Xiaojun Ma"", ""Ziyao Li"", ""Lingjun Xu"", ""Guojie Song"", ""Yi Li"", ""Chuan Shi""]","[""Graph Neural Networks"", ""Reinforcement Learning"", ""Attention Mechanism"", ""Adaptive Receptive Fields""]","We propose GRARF, an RL-based approach of deriving adaptive receptive fields in GCNs.",,,,
pHsHaXAv8m-,2021,Reject,False,Towards Principled Representation Learning for Entity Alignment,"[""Lingbing Guo"", ""Zequn Sun"", ""Mingyang Chen"", ""Wei Hu"", ""Huajun Chen""]","[""Representation Learning"", ""Knowledge Graph"", ""Entity Alignment"", ""Knowledge Graph Embedding""]",A principled approach to learn principled representations for entity alignment.,,,,
pIjvdJ_QUYv,2022,Reject,False,Practical and Private Heterogeneous Federated Learning,"['Hanxiao Chen', 'Meng Hao', 'Hongwei Li', 'Guangxiao Niu', 'Guowen Xu', 'Huawei Wang', 'Yuan Zhang', 'Tianwei Zhang']",[],,,,,
pLNLdHrZmcX,2022,Reject,False,SANE: Specialization-Aware Neural Network Ensemble,"['Ziyue Li', 'Kan Ren', 'XINYANG JIANG', 'Mingzhe Han', 'Haipeng Zhang', 'Dongsheng Li']",[],We propose an end-to-end ensemble learning method to simultaneously achieve specialized base model learning and adaptive ensemble of base models.,,,,
pMQwKL1yctf,2022,Accept (Oral),False,Language modeling via stochastic processes,"['Rose E Wang', 'Esin Durmus', 'Noah Goodman', 'Tatsunori Hashimoto']","[""contrastive learning"", ""language modelling"", ""stochastic processes""]",We introduce a language model that implicitly plans via a latent stochastic process.,,,,
pN1JOdrSY9,2022,Accept (Poster),False,Contrastive Clustering to Mine Pseudo Parallel Data for Unsupervised Translation,"['Xuan-Phi Nguyen', 'Hongyu Gong', 'Yun Tang', 'Changhan Wang', 'Philipp Koehn', 'Shafiq Joty']","[""machine translation"", ""unsupervised machine translation"", ""pseudo-parallel data"", ""contrastive clustering"", ""pretraining""]",We propose a fine-tuning loss that enables pre-trained model's ability to mine pseudo-parallel data for fully unsupervised machine translation.,,,,
pOHW7EwFbo9,2021,Reject,False,Explicit Pareto Front Optimization for Constrained Reinforcement Learning,"[""Sandy Huang"", ""Abbas Abdolmaleki"", ""Philemon Brakel"", ""Steven Bohez"", ""Nicolas Heess"", ""Martin Riedmiller"", ""raia hadsell""]","[""constrained reinforcement learning"", ""multi-objective reinforcement learning"", ""continuous control"", ""deep reinforcement learning""]","We introduce a novel framework for constrained RL, by leveraging the ability of multi-objective RL algorithms to find Pareto-optimal solutions.",,,,
pQ-AoEbNYQK,2021,Reject,False,DiffAutoML: Differentiable Joint Optimization for Efficient End-to-End Automated Machine Learning,"[""Kaichen Zhou"", ""Lanqing HONG"", ""Fengwei Zhou"", ""Binxin Ru"", ""Zhenguo Li"", ""Trigoni Niki"", ""Jiashi Feng""]","[""Differentiable"", ""Automated machine learning"", ""Neural Architecture Search"", ""Data Augment"", ""Hyperparameter Optimization""]",,,,,
pQ02Y-onvZA,2022,Reject,False,$\sbf{\delta^2}$-exploration for Reinforcement Learning,"['Rong Zhu', 'Mattia Rigotti']","[""Reinforcement learning"", ""exploration"", ""Q-learning"", ""DQN""]","We propose and evaluate $\delta^2$-exploration, an efficient and competitive exploration strategy for Reinforcement Learning based on Sample Average Uncertainty, an uncertainty measure in the bandits literature.",,,,
pQq3oLH9UmL,2021,Reject,False,Achieving Explainability in a Visual Hard Attention Model through Content Prediction,"[""Samrudhdhi Bharatkumar Rangrej"", ""James J. Clark""]","[""visual hard attention"", ""glimpses"", ""explainability"", ""bayesian optimal experiment design"", ""variational autoencoder""]",The hard attention model learns explainable attention policy by predicting the content of the glimpses and using it to find an optimal location to attend.,,,,
pRGF3Jtaie,2021,Reject,False,ALT-MAS: A Data-Efficient Framework for Active Testing of Machine Learning Algorithms,"[""Huong Ha"", ""Sunil Gupta"", ""Santu Rana"", ""Svetha Venkatesh""]","[""active learning"", ""bayesian learning"", ""machine learning testing"", ""information theory""]",We propose a novel framework for active testing of machine learning models.,2104.04999,cs.LG,2021-04-11 12:14:04+00:00,2021-04-11 12:14:04+00:00
pTZ6EgZtzDU,2021,Reject,False,Meta-Reinforcement Learning With Informed Policy Regularization,"[""Pierre-Alexandre Kamienny"", ""Matteo Pirotta"", ""Alessandro Lazaric"", ""Thibault Lavril"", ""Nicolas Usunier"", ""Ludovic Denoyer""]","[""meta-reinforcement learning"", ""reinforcement learning"", ""multi-task"", ""non-stationary"", ""task representations"", ""regularization""]",Generalize to unseen environments by leveraging privileged information to learn task embeddings.,,,,
pULTvw9X313,2021,Reject,False,MeshMVS: Multi-view Stereo Guided Mesh Reconstruction,"[""Rakesh Shrestha"", ""Zhiwen Fan"", ""Siyu Zhu"", ""Zuozhuo Dai"", ""Qingkun Su"", ""Ping Tan""]","[""Mesh Reconstruction"", ""Multi-view Stereo"", ""Deep Learning""]","We propose multi-view stereo guided mesh reconstruction method which incorporates geometry information from depth images, along with the rendered depth images to refine the mesh in a coarse-to-fine manner.",,,,
pVU7Gp7Nq4k,2022,Reject,True,Representation mitosis in wide neural networks,"['Diego Doimo', 'Aldo Glielmo', 'Sebastian Goldt', 'Alessandro Laio']",[],"We describe a mechanism for benign overfitting of deep neural networks that we call ""representation mitosis"".",2106.03485,stat.ML,2021-06-07 10:18:54+00:00,2021-10-07 19:01:35+00:00
pVwU-8cdjQQ,2021,Reject,False,Unsupervised Video Decomposition using Spatio-temporal Iterative Inference,"[""Polina Zablotskaia"", ""Edoardo Alberto Dominici"", ""Leonid Sigal"", ""Andreas Lehrmann""]","[""Unsupervised Learning"", ""Representation Learning"", ""Scene Decomposition"", ""Computer Vision""]",,,,,
pW--cu2FCHY,2021,Reject,False,An Attention Free Transformer,"[""Shuangfei Zhai"", ""Walter Talbott"", ""Nitish Srivastava"", ""Chen Huang"", ""Hanlin Goh"", ""Joshua M. Susskind""]","[""Transformers"", ""attention"", ""efficient""]",We propose an efficient Transformer that eliminates attention.,,,,
pW2Q2xLwIMD,2021,Accept (Poster),False,"Few-Shot Learning via Learning the Representation, Provably","[""Simon Shaolei Du"", ""Wei Hu"", ""Sham M. Kakade"", ""Jason D. Lee"", ""Qi Lei""]","[""representation learning"", ""statistical learning theory""]",We study when and how much representation learning can help few-shot learning by drastically reducing sample complexity on the target task.,,,,
pWBNOgdeURp,2022,Accept (Poster),False,An Operator Theoretic View On Pruning Deep Neural Networks,"['William T Redman', 'MARIA FONOBEROVA', 'Ryan Mohr', 'Yannis Kevrekidis', 'Igor Mezic']","[""deep neural network pruning"", ""Koopman operator theory""]",Koopman operator theoretic methods are extended to deep neural network pruning and are shown to provide new insight into existing work.,,,,
pWipslK5xVf,2021,Reject,False,Wasserstein Distributional Normalization : Nonparametric Stochastic Modeling for Handling Noisy Labels,"[""Sung Woo Park"", ""Junseok Kwon""]","[""Wasserstein distributional normalization"", ""Noisy labels"", ""Classification""]",We propose a novel Wasserstein distributional normalization (WDN) algorithm to handle noisy labels for accurate classification. ,,,,
pXi-zY262sE,2021,Reject,True,Ruminating Word Representations with Random Noise Masking,"[""Hwiyeol Jo"", ""Byoung-Tak Zhang""]","[""representation learning for natural language processing"", ""pretrained word embeddings"", ""iterative training method"", ""model regularization""]",An iterative method to be applied on pretrained word embeddings to find better word representations.,1911.03459,cs.LG,2019-11-08 05:23:43+00:00,2019-11-08 05:23:43+00:00
pXmtZdDW16,2021,Reject,False,Embedding a random graph via GNN: mean-field inference theory and RL applications to NP-Hard multi-robot/machine scheduling,"[""HYUNWOOK KANG"", ""SEUNGWOO SCHIN"", ""James Morrison"", ""Jinkyoo Park""]","[""Graph neural network"", ""graph embedding"", ""multi-robot/machine scheduling"", ""Reinforcement learning"", ""Mean-field inference""]","A GNN-based random graph embedding theory is developed, motivated by the problem of learning multi-robot/machine scheduling. Towards scalable multi-robot Q-learning, an approximate algorithm with a provable performance guarantee was developed.",,,,
paE8yL0aKHo,2021,Reject,False,CAT-SAC: Soft Actor-Critic with Curiosity-Aware Entropy Temperature,"[""Junfan Lin"", ""Changxin Huang"", ""Xiaodan Liang"", ""Liang Lin""]",[],,,,,
paUVOwaXTAR,2021,Reject,False,Compositional Models: Multi-Task Learning and Knowledge Transfer with Modular Networks,"[""Andrey Zhmoginov"", ""Dina Bashkirova"", ""Mark Sandler""]","[""modular networks"", ""transfer learning"", ""domain adaptation"", ""self-organization""]",An approach to building modular networks using soft mixture of block templates.,2107.10963,cs.LG,2021-07-23 00:05:55+00:00,2021-07-23 00:05:55+00:00
padYzanQNbg,2021,Reject,False,Neural SDEs Made Easy: SDEs are Infinite-Dimensional GANs,"[""Patrick Kidger"", ""James Foster"", ""Xuechen Li"", ""Harald Oberhauser"", ""Terry Lyons""]","[""neural differential equation"", ""neural ODE"", ""SDE"", ""GAN""]","We show that the mathematics of SDEs corresponds to the machine learning of GANs, and use this to train neural SDEs as continuous-time generative time series models.",,,,
pavee2r1N01,2021,Reject,False,Provable Robustness by Geometric Regularization of ReLU Networks,"[""Chester Holtz"", ""Changhao Shi"", ""Gal Mishne""]","[""deep learning"", ""adversarial attack"", ""robust certification""]",We propose a novel geometric regularization term which provably improves the robustness of neural networks. ,,,,
pbUcKxmiM54,2021,Reject,False,Simple deductive reasoning tests and numerical data sets for exposing limitation of today's deep neural networks,"[""Kalidas Yeturu"", ""Manish Kumar Srivastava""]","[""inductive reasoning"", ""deductive reasoning"", ""neural network"", ""memory"", ""feature engineering""]",Ten simple tests and data sets on which today's deep neural networks fail and call for algorithms for learning deductive reasoning,,,,
pbXQtKXwLS,2021,Reject,False,Guiding Neural Network Initialization via Marginal Likelihood Maximization,"[""Anthony Tai"", ""Chunfeng Huang""]","[""Neural networks"", ""Gaussian processes"", ""model initialization"", ""marginal likelihood""]",We propose using Gaussian process marginal likelihood maximization to recommend hyperparameter values for initialization of the corresponding neural network.,,,,
pbduKpYzn9j,2022,Reject,False,A Comprehensive Overhaul of Distilling Unconditional GANs,"['Guodong Xu', 'Yuenan Hou', 'Ziwei Liu', 'Chen Change Loy']",[],,,,,
pbkSuhxdnZ,2021,Reject,False,TwinDNN: A Tale of Two Deep Neural Networks,"[""Hyunmin Jeong"", ""Deming Chen""]","[""Hardware Accelerator"", ""High-Level-Synthesis"", ""Machine Learning"", ""Neural Network Quantization""]","This study presents a way to accelerate neural network inferences by using an extremely low bit-width network, while maintaining the accuracy of the original network by using relatively high precision network concurrently. ",,,,
pdsec2YIOCx,2021,Reject,False,Untangle: Critiquing Disentangled Recommendations,"[""Preksha Nema"", ""Alexandros Karatzoglou"", ""Filip Radlinski""]","[""Disentangling"", ""Recommender Systems"", ""VAE"", ""Critiquing"", ""Explainability""]",,,,,
per0G3dnkYh,2022,Reject,False,Marginal Tail-Adaptive Normalizing Flows,"['Mike Laszkiewicz', 'Johannes Lederer', 'Asja Fischer']","[""Normalizing Flows"", ""Heavy-Tailed Data"", ""Generative Models""]","We develop novel theoretical results about the tail behavior of the distributions learned by affine triangular flows, which motivate marginal tail-adaptive flows. ",,,,
pfNyExj7z2,2022,Accept (Poster),True,Vector-quantized Image Modeling with Improved VQGAN,"['Jiahui Yu', 'Xin Li', 'Jing Yu Koh', 'Han Zhang', 'Ruoming Pang', 'James Qin', 'Alexander Ku', 'Yuanzhong Xu', 'Jason Baldridge', 'Yonghui Wu']","[""VQGAN"", ""Vision Transformers"", ""Vector-quantized Image Modeling""]",We propose the ViT-VQGAN and further explore a Vector-quantized Image Modeling (VIM) approach on both generative and discriminative tasks on images.,2110.04627,cs.CV,2021-10-09 18:36:00+00:00,2021-10-09 18:36:00+00:00
pg9c6etTWXR,2021,Reject,True,Learnable Uncertainty under Laplace Approximations,"[""Agustinus Kristiadi"", ""Matthias Hein"", ""Philipp Hennig""]","[""Bayesian deep learning"", ""Laplace approximations"", ""uncertainty quantification""]","A new form of hidden units for Bayesian deep learning that only affects uncertainty, not the prediction, and which can be trained post-hoc at low cost.",2010.02720,cs.LG,2020-10-06 13:43:33+00:00,2021-06-07 15:06:19+00:00
pgKE5Q-CF2,2022,Reject,False,Neuron-Enhanced Autoencoder based Collaborative filtering: Theory and Practice,"['Jicong Fan', 'Rui Chen', 'Chris Ding']",[],,,,,
pgir5f7ekAL,2022,Accept (Poster),False,Generative Principal Component Analysis,"['Zhaoqiang Liu', 'Jiulong Liu', 'Subhroshekhar Ghosh', 'Jun Han', 'Jonathan Scarlett']","[""Principal component analysis"", ""generative models"", ""sparse principal component analysis"", ""projected power methods"", ""optimal statistical rates""]","We study the problem of principal component analysis with generative modeling assumptions, and provide a corresponding efficient algorithm with provable guarantees.",,,,
pgkwZxLW8b,2022,Reject,False,Efficient Image Representation Learning with Federated Sampled Softmax,"['Sagar M. Waghmare', 'Hang Qi', 'Huizhong Chen', 'Mikhail Sirotenko', 'Tomer Meron']","[""Federated learning"", ""sampled softmax""]",We propose an algorithm for using sampled softmax in federated setting.,,,,
piLPYqxtWuA,2021,Accept (Poster),True,FastSpeech 2: Fast and High-Quality End-to-End Text to Speech,"[""Yi Ren"", ""Chenxu Hu"", ""Xu Tan"", ""Tao Qin"", ""Sheng Zhao"", ""Zhou Zhao"", ""Tie-Yan Liu""]","[""text to speech"", ""speech synthesis"", ""non-autoregressive generation"", ""one-to-many mapping"", ""end-to-end""]",We propose a non-autoregressive TTS model named FastSpeech 2 to better solve the one-to-many mapping problem in TTS and surpass autoregressive models in voice quality.,2006.04558,eess.AS,2020-06-08 13:05:40+00:00,2021-03-04 05:52:28+00:00
piek7LGx7j,2021,Reject,False,Improving the Reconstruction of Disentangled Representation Learners via Multi-Stage Modelling,"[""Akash Srivastava"", ""Yamini Bansal"", ""Yukun Ding"", ""Cole Lincoln Hurwitz"", ""Kai Xu"", ""Bernhard Egger"", ""Prasanna Sattigeri"", ""Joshua B. Tenenbaum"", ""Dan Gutfreund""]","[""disentanglement"", ""disentangled representation learning"", ""vae"", ""generative model""]",,,,,
pjqqxepwoMy,2022,Accept (Poster),False,Variational oracle guiding for reinforcement learning,"['Dongqi Han', 'Tadashi Kozuno', 'Xufang Luo', 'Zhao-Yun Chen', 'Kenji Doya', 'Yuqing Yang', 'Dongsheng Li']","[""variational Bayes"", ""oracle guiding"", ""reinforcement learning"", ""decision making"", ""probabilistic modeling"", ""game"", ""Mahjong""]",We propose a variational Bayes framework leveraging oracle (hindsight) information available in training to improve deep reinforcement learning.,,,,
pmj131uIL9H,2021,Accept (Poster),False,NeMo: Neural Mesh Models of Contrastive Features for Robust 3D Pose Estimation,"[""Angtian Wang"", ""Adam Kortylewski"", ""Alan Yuille""]","[""Pose Estimation"", ""Robust Deep Learning"", ""Contrastive Learning"", ""Render-and-Compare""]","We introduce NeMo, a rendering-based approach to 3D pose estimation that models objects in terms of neural feature activations, instead of image intensities.",2101.12378,cs.CV,2021-01-29 03:23:12+00:00,2021-02-04 05:01:51+00:00
po-DLlBuAuz,2021,Accept (Poster),False,Batch Reinforcement Learning Through Continuation Method,"[""Yijie Guo"", ""Shengyu Feng"", ""Nicolas Le Roux"", ""Ed Chi"", ""Honglak Lee"", ""Minmin Chen""]","[""batch reinforcement learning"", ""continuation method"", ""relaxed regularization""]",,,,,
poH5qibNFZ,2021,Reject,False,Neighbourhood Distillation: On the benefits of non end-to-end distillation,"[""La\u00ebtitia Shao"", ""Elad Eban"", ""Yair Movshovitz-Attias""]","[""distillation"", ""deep learning""]",A paper that shows the benefits of non end-to-end training for knowledge distillation,,,,
pqZV_srUVmK,2021,Accept (Poster),True,Single-Timescale Actor-Critic Provably Finds Globally Optimal Policy,"[""Zuyue Fu"", ""Zhuoran Yang"", ""Zhaoran Wang""]",[],,2008.00483,cs.LG,2020-08-02 14:01:49+00:00,2021-06-13 05:25:16+00:00
psNSQsmd4JI,2022,Reject,False,Containerized Distributed Value-Based Multi-Agent Reinforcement Learning,"['Siyang Wu', 'Tonghan Wang', 'Chenghao Li', 'Chongjie Zhang']","[""Multi-agent reinforcement learning"", ""Distributed reinforcement learning""]",,,,,
psQ6wcNXjS1,2022,Reject,False,"EBM Life Cycle: MCMC Strategies for Synthesis, Defense, and Density Modeling","['Mitch Hill', 'Jonathan Craig Mitchell', 'Chu Chen', 'Yuan Du', 'Mubarak Shah', 'Song-Chun Zhu']","[""energy-based model"", ""MCMC sampling"", ""Langevin sampling"", ""generative modeling"", ""unsupervised learning"", ""image synthesis"", ""adversarial defense"", ""density estimation""]","Our works explores new MCMC initialization methods for the EBM learning process to obtain shortrun models for image synthesis, midrun models for adversarial defense, and longrun models for density modeling.",,,,
psh0oeMSBiF,2022,Accept (Poster),False,COPA: Certifying Robust Policies for Offline Reinforcement Learning against Poisoning Attacks,"['Fan Wu', 'Linyi Li', 'Huan Zhang', 'Bhavya Kailkhura', 'Krishnaram Kenthapadi', 'Ding Zhao', 'Bo Li']","[""certified robustness"", ""poisoning attacks"", ""reinforcement learning""]",We propose the first framework for certifiying robustness of offline reinforcement learning against poisoning attacks.,,,,
ptZfV8tJbpe,2022,Reject,False,Modeling label correlations implicitly through latent label encodings for multi-label text classification,"['Zhizhong Zeng', 'Yufen Liu', 'Wenpeng Gao', 'Baihong Li', 'Ting Zhang', 'Xinguo Yu', 'Zongkai Yang']","[""multi-label text classification"", ""multi-label classification"", ""label correlation"", ""label embedding""]","It is the first method to model label-correlations implicitly for multi-label text classification to our knowledge, it has outperformed the state-of-the-art results on two widelly used datasets by a large margin.",,,,
ptbb7olhGHd,2021,Reject,False,On the Robustness of Sentiment Analysis for Stock Price Forecasting,"[""Gabriel Deza"", ""Colin Rowat"", ""Nicolas Papernot""]","[""adversarial machine learning"", ""adversarial examples"", ""stock price forecasting"", ""finance""]","Replicate industry standard sentiment analysis of Twitter data for stock price forecasting, and demonstrate its vulnerability to adversarial manipulations of the model's inputs.",,,,
ptxGmKMLH_,2022,Reject,True,A Closer Look at Prototype Classifier for Few-shot Image Classification,"['Mingcheng Hou', 'Issei Sato']","[""few-shot"", ""meta-learning"", ""prototypical network"", ""fine-tuning"", ""prototypical clasifier""]","In this paper, we analyze how a prototypical classifier works equally well without fine-tuning and meta-learning.",2110.05076,cs.CV,2021-10-11 08:28:43+00:00,2021-11-02 02:33:17+00:00
punMXQEsPr0,2021,Reject,False,BROS: A Pre-trained Language Model for Understanding Texts in Document,"[""Teakgyu Hong"", ""DongHyun Kim"", ""Mingi Ji"", ""Wonseok Hwang"", ""Daehyun Nam"", ""Sungrae Park""]","[""Pre-trained model"", ""language model"", ""Document understanding"", ""Document intelligence"", ""OCR""]",We propose a pre-trained language model for understanding texts in document and it shows the state-of-the-art performances on four benchmark tasks.,,,,
pwwVuSICBgt,2021,Reject,False,Enabling Binary Neural Network Training on the Edge,"[""Erwei Wang"", ""James J. Davis"", ""Daniele Moro"", ""Piotr Zielinski"", ""Claudionor Coelho"", ""Satrajit Chatterjee"", ""Peter Y. K. Cheung"", ""George Anthony Constantinides""]","[""Binary neural network"", ""edge computing"", ""neural network training""]","In this paper, we introduce a low-cost binary neural network training strategy exhibiting sizable memory footprint reductions and energy savings vs Courbariaux & Bengio's standard approach.",,,,
px0-N3_KjA,2021,Reject,False,D4RL: Datasets for Deep Data-Driven Reinforcement Learning,"[""Justin Fu"", ""Aviral Kumar"", ""Ofir Nachum"", ""George Tucker"", ""Sergey Levine""]","[""reinforcement learning"", ""deep learning"", ""benchmarks""]",A benchmark proposal for offline reinforcement learning.,,,,
pz1euXohm4H,2022,Accept (Poster),False,Target-Side Data Augmentation for Sequence Generation,"['Shufang Xie', 'Ang Lv', 'Yingce Xia', 'Lijun Wu', 'Tao Qin', 'Rui Yan', 'Tie-Yan Liu']","[""Sequence Gerneration"", ""Data Augmentation""]",We study the data augmentation for target-side conditional input of autoregressive sequence generation and propose a new method to build soft synthetic data.,,,,
pzgENfIRBil,2022,Reject,False,Self-consistent Gradient-like Eigen Decomposition in Solving SchrÃ¶dinger Equations,"['Xihan Li', 'Xiang Chen', 'Rasul Tutunov', 'Haitham Bou Ammar', 'Lei Wang', 'Jun Wang']","[""Schr\u00f6dinger Equation"", ""Hartree-Fock"", ""Self-consistent"", ""Eigen-decomposition"", ""online learning"", ""stochastic k-PCA"", ""Oja's Algorithm"", ""EigenGame""]","We developed SCGLED, an efficient framework to solve approximated SchrÃ¶dinger equations with gradient-like eigen decomposition in streaming $k$-PCA",,,,
pzpytjk3Xb2,2021,Accept (Poster),False,Policy-Driven Attack: Learning to Query for Hard-label Black-box Adversarial Examples,"[""Ziang Yan"", ""Yiwen Guo"", ""Jian Liang"", ""Changshui Zhang""]","[""hard-label attack"", ""black-box attack"", ""adversarial attack"", ""reinforcement learning""]",A novel hard-label black-box adversarial attack that introduces a reinforcement learning based formulation with a pre-trained policy network,,,,
q-cnWaaoUTH,2021,Accept (Poster),False,Conformation-Guided Molecular Representation with Hamiltonian Neural Networks,"[""Ziyao Li"", ""Shuwen Yang"", ""Guojie Song"", ""Lingsheng Cai""]","[""Molecular Representation"", ""Neural Physics Engines"", ""Molecular Dynamics"", ""Graph Neural Networks""]","We propose a molecular representation algorithm, which preserves molecular conformations with a neural physics engine and generates fingerprints with an MPNN.",2105.03688,cs.LG,2021-05-08 12:48:08+00:00,2021-05-08 12:48:08+00:00
q-qxdClTs0d,2021,Reject,False,Out-of-distribution Prediction with Invariant Risk Minimization: The Limitation and An Effective Fix,"[""Ruocheng Guo"", ""Pengchuan Zhang"", ""Hao Liu"", ""Emre Kiciman""]","[""Invariant Risk Minimization"", ""Causal Machine Learning"", ""Out-of-distribution Prediction""]",We find a limitation of Invariant Risk Minimization under a specific type of strong spuriousness and propose an effective fix for Out-of-distribution Prediction.,2101.07732,cs.LG,2021-01-16 01:35:06+00:00,2021-02-22 19:42:32+00:00
q1QmAqT_4Zh,2022,Reject,True,Koopman Q-learning: Offline Reinforcement Learning via Symmetries of Dynamics,"['Matthias Weissenbacher', 'Samarth Sinha', 'Animesh Garg', 'Yoshinobu Kawahara']","[""offline reinforcement learning"", ""representation learning"", ""Koopman theory"", ""symmetries of representations"", ""data augmentation""]",We propose a novel data augmentation framework for offline reinforcement learning based on Koopman theory which reflects the system's dynamic and is thus to be interpreted as an exploration of the environments phase space.,2111.01365,cs.LG,2021-11-02 04:32:18+00:00,2021-11-02 04:32:18+00:00
q23I9kJE3gA,2022,Reject,False,Conditional set generation using Seq2seq models,"['Aman Madaan', 'Dheeraj Rajagopal', 'Antoine Bosselut', 'Yiming Yang']","[""natural language processing"", ""nlp"", ""language generation""]","We propose a method for generating sets using sequence generation models by converting a set to a sequence in informative orders, and jointly modeling cardinality.",,,,
q2DCMRTvdZ-,2022,Reject,False,Picking up the pieces: separately evaluating supernet training and architecture selection,"['Gabriel Meyer-Lee', 'Nick Cheney']","[""neural architecture search"", ""automl"", ""deep learning theory""]",A 2-stage framework for evaluating differentiable supernet NAS methods with evaluation statistics for each search stage.,,,,
q2ZaVU6bEsT,2022,Reject,False,CONTEXT AUGMENTATION AND FEATURE REFINEMENT NETWORK FOR TINY OBJECT DETECTION,"['Jinsheng Xiao', 'Tao Zhao', 'Yuntao Yao', 'Qiuze Yu', 'Yunhua Chen']","[""Tiny Object Detection"", ""context augmentation"", ""feature refinement"", ""Data Enhancement""]",A new feature pyramid network is proposed to combine context augmentation and feature refinement for tiny object detection.,,,,
q3KSThy2GwB,2021,Accept (Spotlight),True,Practical Real Time Recurrent Learning with a Sparse Approximation,"[""Jacob Menick"", ""Erich Elsen"", ""Utku Evci"", ""Simon Osindero"", ""Karen Simonyan"", ""Alex Graves""]","[""recurrent neural networks"", ""backpropagation"", ""biologically plausible"", ""forward mode"", ""real time recurrent learning"", ""rtrl"", ""bptt""]","We show how to make RTRL efficient with sparse RNNs, a sparse approximation, or both.",2006.07232,cs.LG,2020-06-12 14:38:15+00:00,2020-06-12 14:38:15+00:00
q4HaTeMO--y,2022,Accept (Poster),False,Declarative nets that are equilibrium models,"['Russell Tsuchida', 'Suk Yee Yong', 'Mohammad Ali Armin', 'Lars Petersson', 'Cheng Soon Ong']","[""deep equilibrium models"", ""deep declarative networks"", ""implicit layers"", ""kernel methods"", ""generalised linear models""]",Choosing a kernelised generalised linear model as the inner problem of a DDN yields a DEQ with specific fixed weights.,,,,
q4tZR1Y-UIs,2022,Accept (Poster),False,It Takes Four to Tango: Multiagent Self Play for Automatic Curriculum Generation,"['Yuqing Du', 'Pieter Abbeel', 'Aditya Grover']","[""curriculum generation"", ""unsupervised reinforcement learning"", ""goal conditioned reinforcement learning"", ""multi agent""]",,,,,
q79uMSC6ZBT,2022,Accept (Poster),False,Learning to Complete Code with Sketches,"['Daya Guo', 'Alexey Svyatkovskiy', 'Jian Yin', 'Nan Duan', 'Marc Brockschmidt', 'Miltiadis Allamanis']","[""sketch"", ""generative model"", ""ml4code""]","Autocomplete code sketches, placing holes where ambiguity prevents us predicting terminal tokens.",,,,
q7n2RngwOM,2022,Accept (Poster),False,$\beta$-Intact-VAE: Identifying and Estimating Causal Effects under Limited Overlap,"['Pengzhou Abel Wu', 'Kenji Fukumizu']","[""VAE"", ""variational autoencoder"", ""balanced representation Learning"", ""treatment effects"", ""causal inference"", ""identifiability"", ""identification"", ""CATE"", ""ATE"", ""weak overlap"", ""limited overlap"", ""Prognostic Model"", ""Prognostic score""]","See all these naturally in one: limited overlap, prognostic score, identifiable VAE, balanced representation Learning, CATE error bounds.",,,,
q8qLAbQBupm,2021,Accept (Poster),False,Neural Mechanics: Symmetry and Broken Conservation Laws in Deep Learning Dynamics,"[""Daniel Kunin"", ""Javier Sagastuy-Brena"", ""Surya Ganguli"", ""Daniel LK Yamins"", ""Hidenori Tanaka""]","[""learning dynamics"", ""symmetry"", ""loss landscape"", ""stochastic differential equation"", ""modified equation analysis"", ""conservation law"", ""hessian"", ""geometry"", ""physics"", ""gradient flow""]","By exploiting architectural symmetry, our work demonstrates that we can analytically describe the learning dynamics of various parameter combinations at finite learning rates and batch sizes for state of the art architectures trained on any dataset.",,,,
q9zIvzRaU94,2022,Reject,False,Causal discovery from conditionally stationary time-series ,"['Carles Balsells Rodas', 'Ruibo Tu', 'Hedvig Kjellstrom']","[""causal discovery"", ""temporal inference"", ""graph neural network"", ""time series"", ""non-stationary"", ""probabilistic modelling""]",,,,,
qCBmozgVr9r,2022,Reject,True,Few-Shot Attribute Learning,"['Mengye Ren', 'Eleni Triantafillou', 'Kuan-Chieh Wang', 'James Lucas', 'Jake Snell', 'Xaq Pitkow', 'Andreas S. Tolias', 'Richard Zemel']","[""Few-shot learning"", ""transfer learning"", ""attribute learning""]",,2012.05895,cs.LG,2020-12-10 18:58:02+00:00,2021-10-11 21:17:34+00:00
qClL9hRDSMZ,2021,Reject,False,Implicit bias of gradient descent for mean squared error regression with wide neural networks,"[""Hui Jin"", ""Guido Montufar""]","[""Implicit bias"", ""overparametrized neural network"", ""cubic spline interpolation"", ""spatially adaptive smoothing spline"", ""effective capacity""]",,,,,
qDx6DXD3Fzt,2022,Reject,True,Provably Robust Detection of Out-of-distribution Data (almost) for free,"['Alexander Meinke', 'Julian Bitterwolf', 'Matthias Hein']","[""out-of-distribution detection"", ""adversarial noise"", ""provable robustness"", ""guarantees""]",We combine a classifier and a provably robust OOD detector in order to obtain provable robustness around OOD data and asymptotic guarantees without sacrificing performance.,2106.04260,cs.LG,2021-06-08 11:40:49+00:00,2021-06-08 11:40:49+00:00
qEGBB9YB31,2022,Reject,True,Where do Models go Wrong? Parameter-Space Saliency Maps for Explainability,"['Roman Levin', 'Manli Shu', 'Eitan Borgnia', 'Furong Huang', 'Micah Goldblum', 'Tom Goldstein']","[""explainability"", ""interpretability"", ""saliency maps"", ""parameter saliency""]",We develop a method to identify salient network parameters (rather than input features) which are responsible for erroneous decisions.,2108.01335,cs.CV,2021-08-03 07:32:34+00:00,2021-08-03 07:32:34+00:00
qESp3gXBm2g,2022,Reject,False,TRAKR â A reservoir-based tool for fast and accurate classification of neural time-series patterns,"['Muhammad Furqan Afzal', 'Christian D Marton', 'Erin L. Rich', 'Kanaka Rajan']","[""neuroscience"", ""recurrent neural networks"", ""reservoir networks"", ""time series classification"", ""neural data"", ""electrophysiological recordings""]",We introduce a reservoir-based tool for fast and accurate classification of time-series patterns,,,,
qFQTP00Q0kp,2021,Reject,False,Self-Supervised Time Series Representation Learning by Inter-Intra Relational Reasoning,"[""Haoyi Fan"", ""Fengbin Zhang"", ""Yue Gao""]","[""self-supervised learning"", ""time series"", ""deep learning"", ""relational reasoning""]",A general self-supervised time series representation learning framework by exploring the inter-sample relation and intra-temporal relation of time series to learn the underlying structure feature on the unlabeled time series.,2011.13548,cs.LG,2020-11-27 04:04:17+00:00,2020-11-27 04:04:17+00:00
qG4ZVCCyCB0,2021,Reject,False,How Important is the Train-Validation Split in Meta-Learning?,"[""Yu Bai"", ""Minshuo Chen"", ""Pan Zhou"", ""Tuo Zhao"", ""Jason D. Lee"", ""Sham M. Kakade"", ""Huan Wang"", ""Caiming Xiong""]","[""Learning theory"", ""meta-learning""]","The per-task train-validation split in meta-learning is not always necessary or optimal, especially when the data is realizable by the model.",,,,
qHXkE-8c1sQ,2021,Reject,False,Information distance for neural network functions,"[""Xiao Zhang"", ""Dejing Dou"", ""Ji Wu""]",[],An approximated information distance for measuring the distance (or similarity) between neural network functions.,,,,
qHsuiKXkUb,2022,Reject,False,High Precision Score-based Diffusion Models,"['Dongjun Kim', 'Seungjae Shin', 'Kyungwoo Song', 'Wanmo Kang', 'Il-chul Moon']","[""Diffusion Model"", ""Score-based Model""]","We improve the diffusion models capable of estimating the unbounded data score, and provide practical training method for the stable diffusion training.",,,,
qI4542Y2s1D,2022,Accept (Poster),False,FILM: Following Instructions in Language with Modular Methods,"['So Yeon Min', 'Devendra Singh Chaplot', 'Pradeep Kumar Ravikumar', 'Yonatan Bisk', 'Ruslan Salakhutdinov']","[""Instruction Following"", ""Visual Language Navigation"", ""Embodied Instruction Following"", ""VLN"", ""ALFRED""]",We propose a modular method for embodied instruction following; our method achieves SOTA on the ALFRED benchmark by a large margin while using less data by eschewing both expert trajectories and low-level instructions.,,,,
qLqeb9AjD2o,2022,Reject,False,Confidence-aware Training of Smoothed Classifiers for Certified Robustness,"['Jongheon Jeong', 'Seojin Kim', 'Jinwoo Shin']","[""randomized smoothing"", ""adversarial robustness"", ""certified defense"", ""adversarial defense"", ""robust training"", ""confidence calibration""]","We propose a novel training objective for randomized smoothing with state-of-the-art results in certified robustness, leveraging the relationship between confidence and robustness of smoothed classifiers.",,,,
qNcedShvOs4,2022,Reject,False,EinSteinVI: General and Integrated Stein Variational Inference,"['Ola RÃ¸nning', 'Ahmad Salim Al-Sibahi', 'Christophe Ley', 'Thomas Hamelryck']","[""Stein variational inference"", ""variational inference"", ""probabilistic programming"", ""Pyro"", ""deep probabilistic programming"", ""deep learning""]","We present EinStein Variational Inference, a technique for inference that integrates all the latest developments within Stein VI into NumPyro and supports ELBO optimization.",,,,
qO-PN1zjmi_,2022,Reject,False,Novelty detection using ensembles with regularized disagreement,"['Alexandru Tifrea', 'Eric Petru Stavarache', 'Fanny Yang']","[""out-of-distribution detection"", ""novelty detection"", ""ensembles"", ""ensemble diversity"", ""outlier detection"", ""regularization""]",,,,,
qOCdZn3lQIJ,2021,Reject,False,Compressing gradients in distributed SGD by exploiting their temporal correlation,"[""Tharindu Adikari"", ""Stark Draper""]","[""distributed optimization"", ""gradient compression"", ""error-feedback""]",A novel compression scheme that exploits temporal correlation of gradients for the purpose of gradient compression.,,,,
qPQRIj_Y_EW,2022,Reject,False,Learning to Solve an Order Fulfillment Problem in Milliseconds with Edge-Feature-Embedded Graph Attention,"['Jingwei Yang', 'Qingchun Hou', 'Xiaoqing Wang', 'Yang Wei', 'Yuming Deng', 'Hongyang Jia', 'Ning Zhang']","[""Combinatorial Optimization"", ""Machine Learning"", ""Modern Supply Chain Management""]",Propose and apply a graph-based machine learning method to solve a size-variant combinatorial optimization problem in modern supply chain management.,,,,
qPzR-M6HY8x,2022,Reject,True,Approximating Instance-Dependent Noise via Instance-Confidence Embedding,"['Yivan Zhang', 'Masashi Sugiyama']","[""instance-dependent noise"", ""label noise"", ""classification"", ""robustness"", ""weakly supervised learning""]",We investigate the instance-dependent noise (IDN) model and propose an efficient approximation of IDN to capture the instance-specific label corruption.,2103.13569,cs.LG,2021-03-25 02:33:30+00:00,2021-03-25 02:33:30+00:00
qQuzhbU3Gto,2022,Reject,False,An Interpretable Graph Generative Model with Heterophily,"['Sudhanshu Chanpuriya', 'Ryan Rossi', 'Anup Rao', 'Tung Mai', 'Nedim Lipka', 'Zhao Song', 'Cameron N Musco']","[""graph"", ""network"", ""generative"", ""heterophily"", ""community detection"", ""link prediction"", ""interpretability""]",We introduce an interpretable graph generative model which is highly expressive in representing both heterophily and overlapping communities.,,,,
qRDQi3ocgR3,2022,Accept (Poster),True,Which Shortcut Cues Will DNNs Choose? A Study from the Parameter-Space Perspective,"['Luca Scimeca', 'Seong Joon Oh', 'Sanghyuk Chun', 'Michael Poli', 'Sangdoo Yun']","[""shortcut learning"", ""shortcut bias"", ""loss geometry"", ""simplicity bias"", ""flat minima"", ""generalization"", ""wisconsin card sorting test""]","When given equally likely shortcuts in data, which shortcut cue will a DNN choose, and why?",2110.03095,cs.LG,2021-10-06 22:51:26+00:00,2022-02-10 16:27:51+00:00
qRdED5QjM9e,2021,Reject,False,Distributionally Robust Learning for Unsupervised Domain Adaptation,"[""Haoxuan Wang"", ""Anqi Liu"", ""Zhiding Yu"", ""Yisong Yue"", ""Anima Anandkumar""]","[""Distributionally Robust Learning"", ""Domain Adaptation"", ""Self-training"", ""Density Ratio Estimation""]",We propose a distributionally robust method for unsupervised domain adaptation that gives conservative uncertainties and SOTA accuracy.,,,,
qSTEPv2uLR8,2022,Reject,False,Physics Informed Convex Artificial Neural Networks (PICANNs) for Optimal Transport based Density Estimation,"['Amanpreet Singh', 'Martin Bauer', 'Sarang Joshi']","[""Optimal Mass Transport"", ""Density Estimation"", ""Physics Informed Neural Networks"", ""Input Convex Neural Networks"", ""Monge Ampere Equation""]","In this paper, building on recent developments of input convex neural networks and physics informed neural networks for solving PDE's, we propose a new Deep Learning approach to solve the continuous OMT problem. ",,,,
qSV5CuSaK_a,2022,Accept (Poster),False,Few-Shot Backdoor Attacks on Visual Object Tracking,"['Yiming Li', 'Haoxiang Zhong', 'Xingjun Ma', 'Yong Jiang', 'Shu-Tao Xia']","[""Backdoor Attack"", ""Visual Object Tracking"", ""AI Security"", ""Deep Learning""]","We propose a simple yet effective backdoor attack against visual object tracking, which is effective in both digital and physical-world scenarios even if the trigger only appears in a few frames and resistant to potential defenses.",2201.13178,cs.CV,2022-01-31 12:38:58+00:00,2022-01-31 12:38:58+00:00
qSeqhriWKsn,2021,Reject,False,Adaptive Single-Pass Stochastic Gradient Descent in Input Sparsity Time,"[""Sepideh Mahabadi"", ""David Woodruff"", ""Samson Zhou""]","[""stochastic gradient descent"", ""streaming algorithm"", ""stochastic optimization""]",We introduce a space and time efficient variance reduction method for stochastic gradient descent that can even be implemented in the distributed/streaming models. ,,,,
qTBC7E4c454,2022,Reject,False,Recursive Construction of Stable Assemblies of Recurrent Neural Networks,"['Leo Kozachkov', 'Michaela M Ennis', 'Jean-Jacques Slotine']","[""stability"", ""deep learning"", ""RNN"", ""combinations"", ""modularity"", ""sparsity"", ""negative feedback"", ""sequence learning"", ""contraction analysis""]","Provably stable RNNs perform near-SOTA on benchmark sequential image tasks with few trainable parameters, by leveraging combination properties and sparsity. ",,,,
qTHBE7E9iej,2022,Accept (Spotlight),False,Learning transferable motor skills with hierarchical latent mixture policies,"['Dushyant Rao', 'Fereshteh Sadeghi', 'Leonard Hasenclever', 'Markus Wulfmeier', 'Martina Zambelli', 'Giulia Vezzani', 'Dhruva Tirumala', 'Yusuf Aytar', 'Josh Merel', 'Nicolas Heess', 'raia hadsell']","[""Robotics"", ""Reinforcement Learning"", ""Hierarchical"", ""Latent Variable Models"", ""Skills"", ""Transfer""]","An approach to learn reusable and transferable skills from data via a hierarchical latent mixture policy, which can significantly improve sample efficiency and asymptotic performance on downstream RL tasks",2112.05062,cs.LG,2021-12-09 17:37:14+00:00,2021-12-09 17:37:14+00:00
qTTccuW4dja,2022,Reject,True,AriEL: volume coding for sentence generation comparisons,"['Luca Celotti', 'Simon Brodeur', 'Jean Rouat']",[],Volume codes reveal latent space can be used more effectively,2003.13600,cs.CL,2020-03-30 16:30:47+00:00,2020-04-21 14:06:11+00:00
qU-eouoIyAy,2021,Reject,False,Hyperrealistic neural decoding: Reconstruction of face stimuli from fMRI measurements via the GAN latent space,"[""Thirza Dado"", ""Ya\u011fmur G\u00fc\u00e7l\u00fct\u00fcrk"", ""Luca Ambrogioni"", ""Gabrielle Ras"", ""Sander E. Bosch"", ""Marcel van Gerven"", ""Umut G\u00fc\u00e7l\u00fc""]","[""Deep learning"", ""Face perception"", ""fMRI"", ""Generative Adversarial Networks"", ""Neural decoding""]","A very powerful yet simple framework for HYperrealistic reconstruction of PERception (HYPER), which elegantly integrates GANs in neural decoding, leading to ground-breaking stimulus reconstructions.",,,,
qVyeW-grC2k,2021,Accept (Poster),True,Long Range Arena : A Benchmark for Efficient Transformers ,"[""Yi Tay"", ""Mostafa Dehghani"", ""Samira Abnar"", ""Yikang Shen"", ""Dara Bahri"", ""Philip Pham"", ""Jinfeng Rao"", ""Liu Yang"", ""Sebastian Ruder"", ""Donald Metzler""]","[""Transformers"", ""Attention"", ""Deep Learning""]",Better benchmarking for Xformers,2011.04006,cs.LG,2020-11-08 15:53:56+00:00,2020-11-08 15:53:56+00:00
qWhajfmKEUt,2022,Reject,False,Delving into Feature Space: Improving Adversarial Robustness by Feature Spectral Regularization,"['Zhen Cheng', 'Fei Zhu', 'Xu-yao Zhang', 'Cheng-lin Liu']","[""adversarial example"", ""adversarial robustness"", ""spectral signature""]","We find that the dominance of the top eigenvalues in feature space is harmful to adversarial robustness, and then propose a method to alleviate such phenomenon in the distribution of eigenvalues.",,,,
qXa0nhTRZGV,2022,Reject,False,Understanding Sharpness-Aware Minimization,"['Maksym Andriushchenko', 'Nicolas Flammarion']","[""Sharpness-aware minimization"", ""implicit bias"", ""noisy labels"", ""adversarial training""]","We discuss and study multiple aspects of SAM: its implicit bias, convergence, effect on noisy labels and on robust overfitting",,,,
qY79G8jGsep,2022,Accept (Poster),False,DISSECT: Disentangled Simultaneous Explanations via Concept Traversals,"['Asma Ghandeharioun', 'Been Kim', 'Chun-Liang Li', 'Brendan Jou', 'Brian Eoff', 'Rosalind Picard']","[""Explainability"", ""Interpretability"", ""Counterfactual generation"", ""Generative Adversarial Network"", ""Variational Autoencoder""]","We propose a novel counterfactual explainability method that simultaneously satisfies several desirable qualities where other methods fail by training a generator, a discriminator, and a concept disentangler using the classifierâs signal.",,,,
qYZD-AO1Vn,2021,Accept (Poster),False,Differentiable Trust Region Layers for Deep Reinforcement Learning,"[""Fabian Otto"", ""Philipp Becker"", ""Vien Anh Ngo"", ""Hanna Carolin Maria Ziesche"", ""Gerhard Neumann""]","[""reinforcement learning"", ""trust region"", ""policy gradient"", ""projection"", ""Wasserstein distance"", ""Kullback-Leibler divergence"", ""Frobenius norm""]",,,,,
qYda4oLEc1,2021,Accept (Spotlight),True,The Traveling Observer Model: Multi-task Learning Through Spatial Variable Embeddings,"[""Elliot Meyerson"", ""Risto Miikkulainen""]","[""Multi-task"", ""Many-task"", ""Multi-domain"", ""Cross-domain"", ""Variable Embeddings"", ""Task Embeddings"", ""Tabular"", ""Analogies""]","Learn a single model across ""unrelated"" tasks by embedding their input and output variables in a shared space.",2010.02354,cs.NE,2020-10-05 21:51:37+00:00,2021-03-22 23:11:12+00:00
qZNw8Ao_BIC,2022,Reject,False,Understanding and Improving Robustness of Vision Transformers through Patch-based Negative Augmentation,"['Yao Qin', 'Chiyuan Zhang', 'Ting Chen', 'Balaji Lakshminarayanan', 'Alex Beutel', 'Xuezhi Wang']","[""Vision Transformer"", ""robustness under distributional shift"", ""data augmentation""]",,,,,
qZzy5urZw9,2021,Accept (Poster),False,Robust Overfitting may be mitigated by properly learned smoothening,"[""Tianlong Chen"", ""Zhenyu Zhang"", ""Sijia Liu"", ""Shiyu Chang"", ""Zhangyang Wang""]","[""Robust Overfitting"", ""Adversarial Training"", ""Adversarial Robustness""]","Mitigate robust overfitting by properly learned smoothening, establishing the new state-of-the-art bar in adversarial training",,,,
q_Q9MMGwSQu,2021,Reject,False,A Simple and Effective  Baseline for Out-of-Distribution Detection using Abstention,"[""Sunil Thulasidasan"", ""Sushil Thapa"", ""Sayera Dhaubhadel"", ""Gopinath Chennupati"", ""Tanmoy Bhattacharya"", ""Jeff Bilmes""]","[""deep learning"", ""out-of-distribution detection""]","Deep neural networks augmented with an extra abstention class and trained on in and out-of-distribution data  show strong out-of-detection performance, often exceeding existing state-of-the-art.",2105.07107,cs.LG,2021-05-15 00:46:11+00:00,2021-05-15 00:46:11+00:00
q_S44KLQ_Aa,2021,Accept (Poster),True,Neurally Augmented ALISTA,"[""Freya Behrens"", ""Jonathan Sauder"", ""Peter Jung""]","[""compressed sensing"", ""sparse reconstruction"", ""unrolled algorithms"", ""learned ISTA""]","We introduce Neurally Augmented ALISTA, extending ALISTA to compute adaptive parameters to achieve improved recovery of individual sparse target vectors.",2010.01930,cs.LG,2020-10-05 11:39:49+00:00,2020-10-05 11:39:49+00:00
q_kZm9eHIeD,2021,Reject,False,Entropic Risk-Sensitive Reinforcement Learning: A Meta Regret Framework with Function Approximation,"[""Yingjie Fei"", ""Zhuoran Yang"", ""Zhaoran Wang""]",[],,,,,
qaQ8kUBYhEK,2022,Reject,False,Spectral Multiplicity Entails Sample-wise Multiple Descent,"['Lin Chen', 'Song Mei']",[],,,,,
qaxhBG1UUaS,2022,Accept (Poster),False,Offline Reinforcement Learning for Large Scale Language Action Spaces,"['Youngsoo Jang', 'Jongmin Lee', 'Kee-Eung Kim']","[""task-oriented dialogue"", ""pre-trained language model"", ""offline reinforcement learning""]",,,,,
qbH974jKUVy,2021,Accept (Poster),False,The role of Disentanglement in Generalisation,"[""Milton Llera Montero"", ""Casimir JH Ludwig"", ""Rui Ponte Costa"", ""Gaurav Malhotra"", ""Jeffrey Bowers""]","[""disentanglement"", ""compositionality"", ""compositional generalization"", ""generalisation"", ""generative models"", ""variational autoencoders""]",Disentangled models do not achieve compositional generalization when tested systematically.,,,,
qbRv1k2AcH,2021,Reject,False,Learning to Reason in Large Theories without Imitation,"[""Kshitij Bansal"", ""Christian Szegedy"", ""Markus Norman Rabe"", ""Sarah M. Loos"", ""Viktor Toman""]","[""reinforcement learning"", ""thoerem proving"", ""exploration"", ""mathematics""]",Demonstrate that it is possible to learn a premise selection model for theorem proving in the absence of human proofs.,,,,
qcKh_Msv1GP,2021,Reject,False,Motif-Driven Contrastive Learning of Graph Representations,"[""Shichang Zhang"", ""Ziniu Hu"", ""Arjun Subramonian"", ""Yizhou Sun""]","[""graph neural network"", ""self-supervised learning"", ""contrastive learning"", ""graph motif learning""]",Learn graph motifs and use motifs to benefit contrastive learning of whole graph representations,,,,
qda7-sVg84,2021,Accept (Spotlight),False,Contrastive Behavioral Similarity Embeddings for Generalization in Reinforcement Learning,"[""Rishabh Agarwal"", ""Marlos C. Machado"", ""Pablo Samuel Castro"", ""Marc G Bellemare""]","[""Reinforcement"", ""Generalization"", ""Contrastive learning"", ""Bisimulation"", ""Representation Learning""]",A contrastive representation learning method which encodes behavioural similarity in RL for improving generalization.,,,,
qf6Nmm-_6Z,2021,Reject,False,VECoDeR - Variational Embeddings for Community Detection and Node Representation,"[""Rayyan Ahmad Khan"", ""Muhammad Umer Anwaar"", ""Omran Kaddah"", ""Martin Kleinsteuber""]","[""Generative Models"", ""Node representation"", ""VECoDeR"", ""Graph Neural Networks"", ""Variational Embeddings""]",A variational approach to jointly learn node and community embeddings for community detection and node representation.   ,,,,
qfGcsAGhFbc,2022,Reject,False,Rethinking Client Reweighting for Selfish Federated Learning,"['Ruichen Luo', 'Shoubo Hu', 'Lequan Yu']","[""Federated Learning"", ""Sample Reweighting"", ""Variance Reduction"", ""Medical Image""]",This work studys a novel setting in FL to consider biased objectives and internal/external partitions and we also propose a novel algorithm for solving it via gradients variance reduction. ,,,,
qfLJBJf_DnH,2022,Reject,False,Brain insights improve RNNs' accuracy and robustness for hierarchical control of continually learned autonomous motor motifs,"['Laureline Logiaco', 'G Sean Escola']","[""neuroscience"", ""dynamical systems"", ""thalamocortical architecture"", ""motor preparation"", ""continual learning"", ""hierarchical continuous motor control"", ""out-of-distribution generalization"", ""robustness""]",Motor preparation in nonlinear RNNs supports robust chaining of accurate continuous motor motifs in never-experienced orders.,,,,
qfaNCudAnji,2022,Reject,False,Deep Q-Network with Proximal Iteration,"['Kavosh Asadi', 'Rasool Fakoor', 'Omer Gottesman', 'Michael Littman', 'Alex Smola']","[""reinforcement learning"", ""deep learning""]",We combine Proximal Iteration with DQN and show significant improvements on the Atari benchmark. ,,,,
qhAeZjs7dCL,2022,Accept (Poster),True,Generative Models as a Data Source for Multiview Representation Learning,"['Ali Jahanian', 'Xavier Puig', 'Yonglong Tian', 'Phillip Isola']","[""Generative models"", ""GANs"", ""Contrastive Learning"", ""Representation Learning""]",State of the art visual representations are learned by aligning multiple âviewsâ of the training data; we show how GANs can be used to generate synthetic multiview data that yields effective visual representations.,2106.05258,cs.CV,2021-06-09 17:54:55+00:00,2021-06-09 17:54:55+00:00
qhC8mr2LEKq,2022,Accept (Poster),False,CrossBeam: Learning to Search in Bottom-Up Program Synthesis,"['Kensen Shi', 'Hanjun Dai', 'Kevin Ellis', 'Charles Sutton']","[""Program Synthesis"", ""Bottom-Up Search""]","We propose training a neural model to learn a hands-on search policy for bottom-up program synthesis, in an effort to tame the search space blowup.",,,,
qhkFX-HLuHV,2022,Accept (Poster),False,Can an Image Classifier Suffice For Action Recognition?,"['Quanfu Fan', 'Chun-Fu Chen', 'Rameswar Panda']","[""action recognition"", ""image classifier"", ""super image"", ""vision transformer""]",We propose the idea of super images to re-purpose an image classifer for action recognition.,,,,
qiAxL3Xqx1o,2021,Reject,False,GG-GAN: A Geometric Graph Generative Adversarial Network,"[""Igor Krawczuk"", ""Pedro Abranches"", ""Andreas Loukas"", ""Volkan Cevher""]","[""GAN"", ""generative adversarial network"", ""WGAN"", ""GNN"", ""graph neural network"", ""generative model"", ""graph""]"," We present the first fully equivariant pure GAN framework for graph generation, based on a geometric perspective on graphs and scalable for inference of thousands of nodes on commonly available hardware.",,,,
qiMXBIf4NfB,2022,Accept (Poster),False,How unlabeled data improve generalization in self-training? A one-hidden-layer theoretical analysis,"['Shuai Zhang', 'Meng Wang', 'Sijia Liu', 'Pin-Yu Chen', 'Jinjun Xiong']","[""Self-training"", ""Semi-supervised learning"", ""Convergence analysis"", ""Generalization analysis""]",Theoretical characterization of unlabeled data in improving generalization and convergence rate via iterative self-training algorithm ,2201.08514,cs.LG,2022-01-21 02:16:52+00:00,2022-01-25 01:03:55+00:00
qiukmqxQF6,2022,Reject,False,LatTe Flows: Latent Temporal Flows for Multivariate Sequence Analysis ,"['Magda Amiridi', 'Gregory Darnell', 'Sean Jewell']","[""time-series analysis"", ""multivariate time series forecasting"", ""latent space"", ""autoregressive models""]",,,,,
qiydAcw6Re,2021,Reject,False,Geometry of Program Synthesis,"[""James Clift"", ""Daniel Murfet"", ""James Wallbridge""]","[""Program Synthesis"", ""Singular Learning Theory"", ""Bayesian Inference"", ""MCMC""]",A new perspective on program synthesis using the geometry of singular learning theory.,,,,
qj1IZ-6TInc,2022,Accept (Oral),False,Real-Time Neural Voice Camouflage,"['Mia Chiquier', 'Chengzhi Mao', 'Carl Vondrick']","[""automatic speech recognition"", ""predictive models"", ""privacy""]","We introduce predictive attacks, which achieve real-time performance in breaking automatic speech recognition models by forecasting the attack vector that will be the most effective in the future. ",2112.07076,cs.SD,2021-12-14 00:27:44+00:00,2021-12-14 00:27:44+00:00
qjN4h_wwUO,2022,Accept (Poster),False,GradMax: Growing Neural Networks using Gradient Information,"['Utku Evci', 'Bart van Merrienboer', 'Thomas Unterthiner', 'Fabian Pedregosa', 'Max Vladymyrov']","[""efficient training"", ""efficient"", ""computer vision"", ""architecture search""]","We present a method that adds new neurons during training without impacting what is already learned, while improving the training dynamics.",,,,
qk0FE399OJ,2021,Reject,False,Improving Random-Sampling Neural Architecture Search by Evolving the Proxy Search Space,"[""Yuhong Li"", ""Cong Hao"", ""Xiaofan Zhang"", ""Jinjun Xiong"", ""Wen-mei Hwu"", ""Deming Chen""]","[""Neural Architecture Search"", ""AutoML"", ""Computer Vision""]",A state-of-the-art Random sampling Neural Architecture Search method.,,,,
qkLMTphG5-h,2021,Accept (Poster),False,Repurposing Pretrained Models for Robust Out-of-domain Few-Shot Learning,"[""Namyeong Kwon"", ""Hwidong Na"", ""Gabriel Huang"", ""Simon Lacoste-Julien""]","[""Meta-learning"", ""Few-shot learning"", ""Out-of-domain"", ""Uncertainty"", ""Ensemble"", ""Adversarial training"", ""Stepsize optimization""]",We propose an alternative meta-testing procedure and combine MAML gradient steps with adversarial training and uncertainty-based stepsize adaptation.,2103.09027,cs.LG,2021-03-16 12:53:09+00:00,2021-03-16 12:53:09+00:00
qnQN4yr6FJz,2022,Accept (Oral),False,Variational Inference for Discriminative Learning with Generative Modeling of Feature Incompletion,"['Kohei Miyaguchi', 'Takayuki Katsuki', 'Akira Koseki', 'Toshiya Iwamori']","[""Black-box variational inference"", ""missing values"", ""evidence upper bound""]",A new variational approximation and algorithm are proposed for discriminative inference with missing features.,,,,
qn_gk5j3PJ,2021,Reject,True,PIVEN: A Deep Neural Network for Prediction Intervals with Specific Value Prediction,"[""Eli Simhayev"", ""Gilad Katz"", ""Lior Rokach""]","[""Prediction Intervals"", ""Uncertainty Estimation"", ""Regression""]",A network architecture that provides both the value prediction and predictive interval (PI) on regression tasks.,2006.05139,cs.LG,2020-06-09 09:29:58+00:00,2021-06-20 13:23:00+00:00
qoTcTS9-IZ-,2021,Reject,False,Dynamically Stable Infinite-Width Limits of Neural Classifiers,"[""Eugene Golikov""]","[""neural tangent kernel"", ""mean field limit""]","A framework that unifies both mean-field and NTK limits, and suggests other important limit models that have not been studied previously.",,,,
qpcG27kYK6z,2022,Reject,False,Concentric Spherical GNN for 3D Representation Learning,"['James S Fox', 'Bo Zhao', 'Beatriz Gonzalez Del Rio', 'Siva Rajamanickam', 'Rampi Ramprasad', 'Le Song']","[""spherical cnn"", ""CNN"", ""point cloud"", ""graph convolution"", ""rotation"", ""equivariance"", ""3D"", ""molecular"", ""volumetric""]","We propose a concentric spherical convolutional approach learning rotationally equivariant representations of 3D point cloud data, with application to computer vision and molecular modeling.",,,,
qpsl2dR9twy,2021,Accept (Poster),False,Communication in Multi-Agent Reinforcement Learning: Intention Sharing,"[""Woojun Kim"", ""Jongeui Park"", ""Youngchul Sung""]","[""Multi-agent reinforcement learning"", ""communication"", ""intention"", ""attention""]",This paper propose a new communication scheme named intention sharing to enhance the coordination among agents.,,,,
qqdXHUGec9h,2022,Accept (Poster),False,Exploiting Class Activation Value for Partial-Label Learning,"['Fei Zhang', 'Lei Feng', 'Bo Han', 'Tongliang Liu', 'Gang Niu', 'Tao Qin', 'Masashi Sugiyama']","[""Partial-label Learning"", ""Class Activation Map""]",Class activation value is better for partial-label learning than the basic outputs of the classifier itself.,,,,
qrdbsZEZPZ,2022,Reject,False,Certified Robustness for Free in Differentially Private Federated Learning,"['Chulin Xie', 'Yunhui Long', 'Pin-Yu Chen', 'Krishnaram Kenthapadi', 'Bo Li']","[""Certified Robustness"", ""Differential Privacy"", ""Federated Learning""]",We derive certified robustness in differentially private federated learning for free against poisoning attacks. ,,,,
qrwe7XHTmYb,2021,Accept (Poster),True,GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding,"[""Dmitry Lepikhin"", ""HyoukJoong Lee"", ""Yuanzhong Xu"", ""Dehao Chen"", ""Orhan Firat"", ""Yanping Huang"", ""Maxim Krikun"", ""Noam Shazeer"", ""Zhifeng Chen""]",[],,2006.16668,cs.CL,2020-06-30 10:42:02+00:00,2020-06-30 10:42:02+00:00
qsZoGvFiJn1,2022,Accept (Poster),False,Hindsight is 20/20: Leveraging Past Traversals to Aid 3D Perception,"['Yurong You', 'Katie Z Luo', 'Xiangyu Chen', 'Junan Chen', 'Wei-Lun Chao', 'Wen Sun', 'Bharath Hariharan', 'Mark Campbell', 'Kilian Q Weinberger']","[""3D object detection"", ""perception with historical context""]",,,,,
qvUJV2-t_c,2022,Reject,False,Using a one dimensional parabolic model of the full-batch loss to estimate learning rates during training,"['Maximus Mutschler', 'Kevin Alexander Laube', 'Andreas Zell']","[""Empirics based Optimization"", ""Optimization"", ""Line Search"", ""SGD"", ""Deep Learning""]",Using a one dimensional parabolic model of the full-batch loss to estimate learning rates during training.,,,,
qw674L9PfQE,2022,Reject,False,CLOOB: Modern Hopfield Networks with InfoLOOB Outperform CLIP,"['Andreas FÃ¼rst', 'Elisabeth Rumetshofer', 'Viet Thuong Tran', 'Hubert Ramsauer', 'Fei Tang', 'Johannes Lehner', 'D P Kreil', 'Michael K Kopp', 'GÃ¼nter Klambauer', 'Angela Bitto-Nemling', 'Sepp Hochreiter']","[""Deep learning"", ""Associative memory"", ""Hopfield networks"", ""Contrastive learning"", ""Multimodal learning""]",,,,,
qwBK94cP1y,2022,Accept (Spotlight),False,Optimal Transport for Causal Discovery,"['Ruibo Tu', 'Kun Zhang', 'Hedvig Kjellstrom', 'Cheng Zhang']","[""causal discovery"", ""optimal transport"", ""functional causal model""]",,,,,
qwULHx9zld,2022,Accept (Poster),True,Random matrices in service of ML footprint: ternary random features with no performance loss,"['Hafiz Tiomoko Ali', 'Zhenyu Liao', 'Romain Couillet']","[""Computationally efficient methods"", ""kernel methods"", ""random features"", ""random matrix theory""]",A novel computational and storage efficient random features technique with no performance loss,2110.01899,stat.ML,2021-10-05 09:33:49+00:00,2021-10-05 09:33:49+00:00
qyTBxTztIpQ,2022,Accept (Poster),False,CrowdPlay: Crowdsourcing human demonstration data for offline learning in Atari games,"['Matthias Gerstgrasser', 'Rakshit Trivedi', 'David C. Parkes']",[],"We provide a crowdsourcing pipeline for arbitrary RL environments, a first dataset on Atari games, and benchmark results.",,,,
qynB_fAt5TQ,2022,Reject,True,Centroid Approximation for Bootstrap,"['Mao Ye', 'qiang liu']","[""bootstrap"", ""centroid approximation"", ""uncertainty""]",We propose a centroid approximation for bootstrap that improves the quality of bootstrap when the number of bootstrap particles is small.,2110.08720,cs.LG,2021-10-17 04:31:57+00:00,2021-10-17 04:31:57+00:00
qynwf18DgXM,2022,Reject,False,Manifold Micro-Surgery with Linearly Nearly Euclidean Metrics,"['Jun Chen', 'Tianxin Huang', 'Wenzhou Chen', 'Yong Liu']","[""Geometry"", ""Ricci flow"", ""Neural network"", ""Metric learning"", ""Information geometry""]",Optimize a linearly nearly Euclidean manifold with the Ricci flow,,,,
qyzTEWWM0Pp,2022,Reject,False,Multiresolution Equivariant Graph Variational Autoencoder,"['Truong Son Hy', 'Risi Kondor']","[""group equivariant model"", ""graph neural network"", ""hierarchical generative model"", ""variational autoencoder"", ""graph generation"", ""link prediction"", ""unsupervised representation learning""]",Multiresolution Equivariant Graph Variational Autoencoders (MGVAE) is the first hierarchical generative model to learn and generate graphs in a multiresolution and equivariant manner.,,,,
qzBUIzq5XR2,2021,Accept (Poster),False,Learning Task-General Representations with Generative Neuro-Symbolic Modeling,"[""Reuben Feinman"", ""Brenden M. Lake""]","[""few-shot concept learning"", ""neuro-symbolic models"", ""probabilistic programs"", ""generative models""]",few-shot concept learning with generative neuro-symbolic models,,,,
r-gPPHEjpmw,2021,Accept (Poster),False,Hierarchical Reinforcement Learning by Discovering Intrinsic Options,"[""Jesse Zhang"", ""Haonan Yu"", ""Wei Xu""]","[""hierarchical reinforcement learning"", ""reinforcement learning"", ""options"", ""unsupervised skill discovery"", ""exploration""]",Hierarchical RL that discovers short-horizon task-agnostic options to perform well on sparse reward manipulation and navigation tasks.,2101.06521,cs.LG,2021-01-16 20:54:31+00:00,2021-03-11 00:31:24+00:00
r10FA8Kxg,2017,Accept (Poster),False,Do Deep Convolutional Nets Really Need to be Deep and Convolutional?,"[""Gregor Urban"", ""Krzysztof J. Geras"", ""Samira Ebrahimi Kahou"", ""Ozlem Aslan"", ""Shengjie Wang"", ""Abdelrahman Mohamed"", ""Matthai Philipose"", ""Matt Richardson"", ""Rich Caruana""]","[""Deep learning"", ""Transfer Learning""]","This paper provides the first empirical demonstration that deep convolutional models really need to be both deep and convolutional, even when trained with model distillation and heavy hyperparameter optimization.",,,,
r111KtCp-,2018,Reject,False,Taking Apart Autoencoders: How do They Encode Geometric Shapes ?,"[""Alasdair Newson"", ""Andres Almansa"", ""Yann Gousseau"", ""Said Ladjal""]","[""autoencoders"", ""CNN"", ""image synthesis"", ""latent space""]",We study the functioning of autoencoders in a simple setting and advise new strategies for their regularisation in order to obtain bettre generalisation with latent interpolation in mind for image sythesis. ,,,,
r11Q2SlRW,2018,Accept (Poster),False,Auto-Conditioned Recurrent Networks for Extended Complex Human Motion Synthesis,"[""Yi Zhou"", ""Zimo Li"", ""Shuangjiu Xiao"", ""Chong He"", ""Zeng Huang"", ""Hao Li""]","[""motion synthesis"", ""motion prediction"", ""human pose"", ""human motion"", ""recurrent networks"", ""lstm""]",Synthesize complex and extended human motions using an auto-conditioned LSTM network,,,,
r14Aas09Y7,2019,Reject,False,COCO-GAN: Conditional Coordinate Generative Adversarial Network,"[""Chieh Hubert Lin"", ""Chia-Che Chang"", ""Yu-Sheng Chen"", ""Da-Cheng Juan"", ""Wei Wei"", ""Hwann-Tzong Chen""]",[],,,,,
r14EOsCqKX,2019,Accept (Poster),False,"A Closer Look at Deep Learning Heuristics: Learning rate restarts, Warmup and Distillation","[""Akhilesh Gotmare"", ""Nitish Shirish Keskar"", ""Caiming Xiong"", ""Richard Socher""]","[""deep learning heuristics"", ""learning rate restarts"", ""learning rate warmup"", ""knowledge distillation"", ""mode connectivity"", ""SVCCA""]","We use empirical tools of mode connectivity and SVCCA to investigate neural network training heuristics of learning rate restarts, warmup and knowledge distillation.",,,,
r154_g-Rb,2018,Reject,False,Composable Planning with Attributes,"[""Amy Zhang"", ""Adam Lerer"", ""Sainbayar Sukhbaatar"", ""Rob Fergus"", ""Arthur Szlam""]","[""Planning"", ""Compositionality"", ""Attributes"", ""Reinforcement learning""]","Compositional attribute-based planning that generalizes to long test tasks, despite being trained on short & simple tasks.",,,,
r15kjpHa-,2018,Reject,False,Reward Design in Cooperative Multi-agent Reinforcement Learning for Packet Routing,"[""Hangyu Mao"", ""Zhibo Gong"", ""Zhen Xiao""]","[""Reward Design"", ""Cooperative Multi-agent Reinforcement Learning"", ""Packet Routing""]","We study reward design problem in cooperative MARL based on packet routing environments. The experimental results remind us to be careful to design the rewards, as they are really important to guide the agent behavior.",2003.03433,cs.AI,2020-03-05 02:27:46+00:00,2020-03-05 02:27:46+00:00
r16Vyf-0-,2018,Reject,False,Image Transformer,"[""Ashish Vaswani"", ""Niki Parmar"", ""Jakob Uszkoreit"", ""Noam Shazeer"", ""Lukasz Kaiser""]","[""image generation"", ""super-resolution"", ""self-attention"", ""transformer""]",,,,,
r17Q6WWA-,2018,Reject,False,Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection,"[""Ludovic Trottier"", ""Philippe Gigu\u00e8re"", ""Brahim Chaib-draa""]","[""multi-task learning"", ""soft parameter sharing"", ""facial landmark detection""]",We propose a novel approach for connecting task-specific networks in a multi-task learning setting based on recent residual network advances.,,,,
r17RD2oxe,2017,Reject,False,Deep Neural Networks and the Tree of Life,"[""Yan Wang"", ""Kun He"", ""John E. Hopcroft"", ""Yu Sun""]","[""Deep learning"", ""Computer vision"", ""Applications""]",Provideing a potential solution to the important problem of constructing a biology evolutionary tree; Giving insight into the representations produced by deep neural networks,,,,
r17lFgZ0Z,2018,Reject,False,Relevance of Unsupervised Metrics in Task-Oriented Dialogue for Evaluating Natural Language Generation,"[""Shikhar Sharma"", ""Layla El Asri"", ""Hannes Schulz"", ""Jeremie Zumer""]","[""task-oriented dialog"", ""goal-oriented dialog"", ""nlg evaluation"", ""natural language generation"", ""automated metrics for nlg""]",,,,,
r1AMITFaW,2018,Reject,False,Dependent Bidirectional RNN with Extended-long Short-term Memory,"[""Yuanhang Su"", ""Yuzhong Huang"", ""C.-C. Jay Kuo""]","[""RNN"", ""memory"", ""LSTM"", ""GRU"", ""BRNN"", ""encoder-decoder"", ""Natural language processing""]",A recurrent neural network cell with extended-long short-term memory and a multi-task RNN model for sequence-in-sequence-out problems,,,,
r1Aab85gg,2017,Accept (Poster),False,"Offline bilingual word vectors, orthogonal transformations and the inverted softmax","[""Samuel L. Smith"", ""David H. P. Turban"", ""Steven Hamblin"", ""Nils Y. Hammerla""]","[""Natural language processing"", ""Transfer Learning"", ""Applications""]","We show that a linear transformation between word vector spaces should be orthogonal and can be obtained analytically using the SVD,  and introduce the inverted softmax for information retrieval.",,,,
r1AoGNlC-,2018,Reject,False,Code Synthesis with Priority Queue Training,"[""Daniel A. Abolafia"", ""Quoc V. Le"", ""Mohammad Norouzi""]","[""code synthesis"", ""program synthesis"", ""genetic algorithm"", ""reinforcement learning"", ""policy gradient"", ""reinforce"", ""priority queue"", ""topk buffer"", ""bf"", ""code golf"", ""rnn""]",We use a simple search algorithm involving an RNN and priority queue to find solutions to coding tasks.,,,,
r1BJLw9ex,2017,Reject,False,Adjusting for Dropout Variance in Batch Normalization and Weight Initialization,"[""Dan Hendrycks"", ""Kevin Gimpel""]",[],Batch Norm Incorrectly Estimates Variance When Dropout Is On,,,,
r1BRfhiab,2018,Reject,False,The Principle of Logit Separation,"[""Gil Keren"", ""Sivan Sabato"", ""Bj\u00f6rn Schuller""]",[],,,,,
r1Bjj8qge,2017,Reject,False,Encoding and Decoding Representations with Sum- and Max-Product Networks,"[""Antonio Vergari"", ""Robert Peharz"", ""Nicola Di Mauro"", ""Floriana Esposito""]",[],"Sum-Product Networks can be effectively employed for unsupervised representation learning, when turned into Max-Product Networks, they can also be used as encoder-decoders",,,,
r1CE9GWR-,2018,Reject,False,Understanding GANs: the LQG Setting,"[""Soheil Feizi"", ""Changho Suh"", ""Fei Xia"", ""David Tse""]","[""Generative Adversarial Networks"", ""Wasserstein"", ""Generalization"", ""PCA""]",,,,,
r1Chut9xl,2017,Reject,False,Inference and Introspection in Deep Generative Models of Sparse Data,"[""Rahul G. Krishnan"", ""Matthew Hoffman""]","[""Unsupervised Learning"", ""Deep learning""]","We study two techniques to improve learning in deep generative models on sparse, high-dimensional text data. We also propose an algorithmic tool to visualize and introspect arbitrarily deep learned models.Â ",,,,
r1DPFCyA-,2018,Reject,False,Discriminative k-shot learning using probabilistic models,"[""Matthias Bauer"", ""Mateo Rojas-Carulla"", ""Jakub Bart\u0142omiej \u015awi\u0105tkowski"", ""Bernhard Sch\u00f6lkopf"", ""Richard E. Turner""]","[""discriminative k-shot learning"", ""probabilistic inference""]",This paper introduces a probabilistic framework for k-shot image classification that achieves state-of-the-art results,,,,
r1Ddp1-Rb,2018,Accept (Poster),True,mixup: Beyond Empirical Risk Minimization,"[""Hongyi Zhang"", ""Moustapha Cisse"", ""Yann N. Dauphin"", ""David Lopez-Paz""]","[""empirical risk minimization"", ""vicinal risk minimization"", ""generalization"", ""data augmentation"", ""image classification"", ""generative adversarial networks"", ""adversarial examples"", ""random labels""]",Training on convex combinations between random training examples and their labels improves generalization in deep neural networks,1710.09412,cs.LG,2017-10-25 18:30:49+00:00,2018-04-27 21:39:25+00:00
r1Dx7fbCW,2018,Accept (Poster),False,Generalizing Across Domains via Cross-Gradient Training,"[""Shiv Shankar*"", ""Vihari Piratla*"", ""Soumen Chakrabarti"", ""Siddhartha Chaudhuri"", ""Preethi Jyothi"", ""Sunita Sarawagi""]","[""domain generalization"", ""domain adaptation"", ""adversarial learning"", ""adversarial examples""]",Domain guided augmentation of data provides a robust and stable method of domain generalization,,,,
r1E0OsA9tX,2019,Reject,False,Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks,"[""Han Zhao"", ""Yao-Hung Hubert Tsai"", ""Ruslan Salakhutdinov"", ""Geoff Gordon""]","[""Empirical Bayes"", ""Bayesian Deep Learning""]",,,,,
r1G4z8cge,2017,Accept (Poster),False,Mollifying Networks,"[""Caglar Gulcehre"", ""Marcin Moczulski"", ""Francesco Visin"", ""Yoshua Bengio""]","[""Deep learning"", ""Optimization""]","We are proposing a new continuation method for neural networks, that starts from optimizing a convex objective function and gradually during the training the function evolves into more non-convex function.",,,,
r1GAsjC5Fm,2019,Accept (Poster),False,Self-Monitoring Navigation Agent via Auxiliary Progress Estimation,"[""Chih-Yao Ma"", ""Jiasen Lu"", ""Zuxuan Wu"", ""Ghassan AlRegib"", ""Zsolt Kira"", ""Richard Socher"", ""Caiming Xiong""]","[""visual grounding"", ""textual grounding"", ""instruction-following"", ""navigation agent""]",We propose a self-monitoring agent for the Vision-and-Language Navigation task.,,,,
r1GB5jA5tm,2019,Reject,False,Adversarial Sampling for Active Learning,"[""Christoph Mayer"", ""Radu Timofte""]","[""active learning"", ""adversarial training"", ""GAN""]",ASAL is a pool based active learning method that generates high entropy samples and retrieves matching samples from the pool in sub-linear time.,,,,
r1GKzP5xx,2017,Invite to Workshop Track,False,Recurrent Normalization Propagation,"[""C\u00e9sar Laurent"", ""Nicolas Ballas"", ""Pascal Vincent""]","[""Deep learning"", ""Optimization""]",Extension of Normalization Propagation to the LSTM.,,,,
r1GbfhRqF7,2019,Accept (Poster),False,Kernel Change-point Detection with Auxiliary Deep Generative Models,"[""Wei-Cheng Chang"", ""Chun-Liang Li"", ""Yiming Yang"", ""Barnab\u00e1s P\u00f3czos""]","[""deep kernel learning"", ""generative models"", ""kernel two-sample test"", ""time series change-point detection""]","In this paper, we propose KL-CPD, a novel kernel learning framework for time series CPD that optimizes a lower bound of test power via an auxiliary generative model as a surrogate to the abnormal distribution. ",,,,
r1GgDj0cKX,2019,Reject,False,PRUNING IN TRAINING: LEARNING AND RANKING SPARSE CONNECTIONS IN DEEP CONVOLUTIONAL NETWORKS,"[""Yanwei Fu"", ""Shun Zhang"", ""Donghao Li"", ""Xinwei Sun"", ""Xiangyang Xue"", ""Yuan Yao""]","[""Split LBI"", ""sparse penalty"", ""network pruning"", ""feature selection""]",we propose an algorithm of learning to prune network by enforcing structure sparsity penalties,,,,
r1GkMhAqYm,2019,Reject,False,CoDraw: Collaborative Drawing as a Testbed for Grounded Goal-driven Communication,"[""Nikita Kitaev"", ""Jin-Hwa Kim"", ""Xinlei Chen"", ""Marcus Rohrbach"", ""Yuandong Tian"", ""Dhruv Batra"", ""Devi Parikh""]","[""CoDraw"", ""collaborative drawing"", ""grounded language""]","We introduce a dataset, models, and training + evaluation protocols for a collaborative drawing task that allows studying goal-driven and perceptually + actionably grounded language generation and understanding. ",,,,
r1Gsk3R9Fm,2019,Reject,False,Shallow Learning For Deep Networks,"[""Eugene Belilovsky"", ""Michael Eickenberg"", ""Edouard Oyallon""]","[""CNN"", ""greedy learning""]","We build CNNs layer by layer without end to end training and show for the first time that this kind of approach can scale to Imagenet, while having multiple favorable  properties.",,,,
r1HNP0eCW,2018,Reject,False,Estimation of cross-lingual news similarities using text-mining methods,"[""Zhouhao Wang"", ""Enda Liu"", ""Hiroki Sakaji"", ""Tomoki Ito"", ""Kiyoshi Izumi"", ""Kota Tsubouchi"", ""Tatsuo Yamashita""]",[],,,,,
r1HhRfWRZ,2018,Accept (Poster),False,Learning Awareness Models,"[""Brandon Amos"", ""Laurent Dinh"", ""Serkan Cabi"", ""Thomas Roth\u00f6rl"", ""Sergio G\u00f3mez Colmenarejo"", ""Alistair Muldal"", ""Tom Erez"", ""Yuval Tassa"", ""Nando de Freitas"", ""Misha Denil""]","[""Awareness"", ""Prediction"", ""Seq2seq"", ""Robots""]",We train predictive models on proprioceptive information and show they represent properties of external objects.,,,,
r1IRctqxg,2017,Reject,False,Sample Importance in Training Deep Neural Networks,"[""Tianxiang Gao"", ""Vladimir Jojic""]","[""Deep learning"", ""Supervised Learning""]",,,,,
r1ISxGZRb,2018,Reject,False,Generation and Consolidation of Recollections for Efficient Deep Lifelong Learning,"[""Matt Riemer"", ""Michele Franceschini"", ""and Tim Klinger""]",[],,,,,
r1Kr3TyAb,2018,Reject,False,ANALYSIS ON GRADIENT PROPAGATION IN BATCH NORMALIZED RESIDUAL NETWORKS,"[""Abhishek Panigrahi"", ""Yueru Chen"", ""C.-C. Jay Kuo""]","[""Batch normalization"", ""gradient backpropagation"", ""Residual network"", ""wide residual network""]","Batch normalisation maintains gradient variance throughout training, thus stabilizing optimization.",,,,
r1LXit5ee,2017,Accept (Poster),False,Episodic Exploration for Deep Deterministic Policies for StarCraft Micromanagement,"[""Nicolas Usunier"", ""Gabriel Synnaeve"", ""Zeming Lin"", ""Soumith Chintala""]","[""Deep learning"", ""Reinforcement Learning"", ""Games""]","We propose a new reinforcement learning algorithm based on zero order optimization, that we evaluate on StarCraft micromanagement scenarios.",,,,
r1MSBjA9Ym,2019,Reject,False,Collapse of deep and narrow neural nets,"[""Lu Lu"", ""Yanhui Su"", ""George Em Karniadakis""]","[""neural networks"", ""deep and narrow"", ""ReLU"", ""collapse""]",Deep and narrow neural networks will converge to erroneous mean or median states of the target function depending on the loss with high probability.,,,,
r1MxciCcKm,2019,Reject,False,Connecting the Dots Between MLE and RL for Sequence Generation,"[""Bowen Tan*"", ""Zhiting Hu*"", ""Zichao Yang"", ""Ruslan Salakhutdinov"", ""Eric P. Xing""]","[""sequence generation"", ""maximum likelihood learning"", ""reinforcement learning"", ""policy optimization"", ""text generation"", ""reward augmented maximum likelihood"", ""exposure bias""]","A unified perspective of various learning algorithms for sequence generation, such as MLE, RL, RAML, data noising, etc.",,,,
r1My6sR9tX,2019,Accept (Poster),False,Unsupervised Learning via Meta-Learning,"[""Kyle Hsu"", ""Sergey Levine"", ""Chelsea Finn""]","[""unsupervised learning"", ""meta-learning""]","An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.",,,,
r1NDBsAqY7,2019,Reject,False,Unsupervised Word Discovery with Segmental Neural Language Models,"[""Kazuya Kawakami"", ""Chris Dyer"", ""Phil Blunsom""]",[],A LSTM language model that discovers words from unsegmented sequences of characters.,,,,
r1NJqsRctX,2019,Accept (Poster),False,Auxiliary Variational MCMC,"[""Raza Habib"", ""David Barber""]","[""MCMC"", ""Variational Inference""]",,,,,
r1NYjfbR-,2018,Accept (Poster),False,Generative networks as inverse problems with Scattering transforms,"[""Tom\u00e1s Angles"", ""St\u00e9phane Mallat""]","[""Unsupervised Learning"", ""Inverse Problems"", ""Convolutional Networks"", ""Generative Models"", ""Scattering Transform""]",We introduce generative networks that do not require to be learned with a discriminator or an encoder; they are obtained by inverting a special embedding operator defined by a wavelet Scattering transform.,1805.06621,cs.LG,2018-05-17 07:12:18+00:00,2018-05-17 07:12:18+00:00
r1Nb5i05tX,2019,Reject,False,The effectiveness of layer-by-layer training using the information bottleneck principle,"[""Adar Elad"", ""Doron Haviv"", ""Yochai Blau"", ""Tomer Michaeli""]",[],,,,,
r1Oen--RW,2018,Reject,False,The (Un)reliability of saliency methods,"[""Pieter-Jan Kindermans"", ""Sara Hooker"", ""Julius Adebayo"", ""Kristof T. Sch\u00fctt"", ""Maximilian Alber"", ""Sven D\u00e4hne"", ""Dumitru Erhan"", ""Been Kim""]","[""Deep learning interpretability"", ""understanding""]",Attribution can sometimes be misleading,,,,
r1PRvK9el,2017,Reject,False,Implicit ReasoNet: Modeling Large-Scale Structured Relationships with Shared Memory,"[""Yelong Shen*"", ""Po-Sen Huang*"", ""Ming-Wei Chang"", ""Jianfeng Gao""]","[""Deep learning"", ""Reinforcement Learning""]",,,,,
r1QZ3zbAZ,2018,Reject,False,Adversarial Examples for Natural Language Classification Problems,"[""Volodymyr Kuleshov"", ""Shantanu Thakoor"", ""Tingfung Lau"", ""Stefano Ermon""]",[],,,,,
r1R5Z19le,2017,Invite to Workshop Track,False,Semi-supervised deep learning by metric embedding,"[""Elad Hoffer"", ""Nir Ailon""]","[""Deep learning"", ""Semi-Supervised Learning""]",,,,,
r1RF3ExCb,2018,Reject,False,Transformation Autoregressive Networks,"[""Junier Oliva"", ""Avinava Dubey"", ""Barnab\u00e1s P\u00f3czos"", ""Eric P. Xing"", ""Jeff Schneider""]","[""density estimation"", ""autoregressive models"", ""RNNs""]",,,,,
r1RQdCg0W,2018,Reject,False,"MACH: Embarrassingly parallel $K$-class classification in $O(d\log{K})$ memory and $O(K\log{K} + d\log{K})$ time, instead of $O(Kd)$","[""Qixuan Huang"", ""Anshumali Shrivastava"", ""Yiqiu Wang""]","[""Extreme Classification"", ""Large-scale learning"", ""hashing"", ""GPU"", ""High Performance Computing""]","How to Training 100,000 classes on a single GPU",,,,
r1S083cgx,2017,Reject,False,Sequence generation with a physiologically plausible model of handwriting and Recurrent Mixture Density Networks,"[""Daniel Berio"", ""Memo Akten"", ""Frederic Fol Leymarie"", ""Mick Grierson"", ""R\u00e9jean Plamondon""]","[""Deep learning"", ""Supervised Learning"", ""Applications""]",To explore the feasibility and potential benefits of using a physiological plausible model of handwriting as a feature representation for sequence generation with recurrent mixture density networks,,,,
r1SnX5xCb,2018,Accept (Poster),False,Deep Sensing: Active Sensing using Multi-directional Recurrent Neural Networks,"[""Jinsung Yoon"", ""William R. Zame"", ""Mihaela van der Schaar""]","[""Active Sensing"", ""Timely Prediction"", ""Irregular Sampling"", ""Missing Data""]",,,,,
r1SuFjkRW,2018,Reject,False,Discrete Sequential Prediction of Continuous Actions for Deep RL,"[""Luke Metz"", ""Julian Ibarz"", ""Navdeep Jaitly"", ""James Davidson""]","[""Reinforcement learning"", ""continuous control"", ""deep learning""]",A method to do Q-learning on continuous action spaces by predicting a sequence of discretized 1-D actions.,,,,
r1TA9ZbA-,2018,Reject,False,Learning to search with MCTSnets,"[""Arthur Guez"", ""Theophane Weber"", ""Ioannis Antonoglou"", ""Karen Simonyan"", ""Oriol Vinyals"", ""Daan Wierstra"", ""Remi Munos"", ""David Silver""]","[""Monte-Carlo Tree Search"", ""search"", ""planning""]",,,,,
r1Ue8Hcxg,2017,Accept (Oral),False,Neural Architecture Search with Reinforcement Learning,"[""Barret Zoph"", ""Quoc Le""]",[],,,,,
r1Usiwcex,2017,Reject,False,Counterpoint by Convolution,"[""Cheng-Zhi Anna Huang"", ""Tim Cooijmans"", ""Adam Roberts"", ""Aaron Courville"", ""Douglas Eck""]","[""Deep learning"", ""Applications"", ""Unsupervised Learning""]","NADE generative model of music, with new insights on sampling",,,,
r1V0m3C5YQ,2019,Reject,False,Coupled Recurrent Models for Polyphonic Music Composition,"[""John Thickstun"", ""Zaid Harchaoui"", ""Dean P. Foster"", ""Sham M. Kakade""]","[""music composition"", ""music generation"", ""polyphonic music modeling""]","New recurrent generative models for composition of rhythmically complex, polyphonic music.",,,,
r1VGvBcxl,2017,Accept (Poster),False,Reinforcement Learning through Asynchronous Advantage Actor-Critic on a GPU,"[""Mohammad Babaeizadeh"", ""Iuri Frosio"", ""Stephen Tyree"", ""Jason Clemons"", ""Jan Kautz""]","[""Reinforcement Learning""]",Implementation and analysis of the computational aspect of a GPU version of the Asynchronous Advantage Actor-Critic (A3C) algorithm,,,,
r1VPNiA5Fm,2019,Reject,False,The Universal Approximation Power of Finite-Width Deep ReLU Networks,"[""Dmytro Perekrestenko"", ""Philipp Grohs"", ""Dennis Elbr\u00e4chter"", ""Helmut B\u00f6lcskei""]","[""rate-distortion optimality"", ""ReLU"", ""deep learning"", ""approximation theory"", ""Weierstrass function""]",,,,,
r1VVsebAZ,2018,Accept (Poster),False,Synthesizing realistic neural population activity patterns using Generative Adversarial Networks,"[""Manuel Molano-Mazon"", ""Arno Onken"", ""Eugenio Piasini*"", ""Stefano Panzeri*""]","[""GANs"", ""Wasserstein-GANs"", ""convolutional networks"", ""neuroscience"", ""spike train patterns"", ""spike train analysis""]",Using Wasserstein-GANs to generate realistic neural activity and to detect the most relevant features present in neural population patterns.,,,,
r1VdcHcxx,2017,Accept (Poster),False,Recurrent Batch Normalization,"[""Tim Cooijmans"", ""Nicolas Ballas"", ""C\u00e9sar Laurent"", ""\u00c7a\u011flar G\u00fcl\u00e7ehre"", ""Aaron Courville""]","[""Deep learning"", ""Optimization""]",Make batch normalization work in recurrent neural networks,,,,
r1Vx_oA5YQ,2019,Reject,False,Integrated Steganography and Steganalysis with Generative Adversarial Networks,"[""Chong Yu""]","[""Steganography"", ""Steganography"", ""Security"", ""Generative Adversarial Networks""]",,,,,
r1WUqIceg,2017,Reject,False,Improving Stochastic Gradient Descent with Feedback,"[""Jayanth Koushik"", ""Hiroaki Hayashi""]","[""Deep learning"", ""Optimization""]",We improve stochastic gradient descent by incorporating feedback from the objective function,,,,
r1X3g2_xl,2017,Accept (Poster),False,Adversarial Training Methods for Semi-Supervised Text Classification,"[""Takeru Miyato"", ""Andrew M. Dai"", ""Ian Goodfellow""]","[""Natural language processing"", ""Deep learning"", ""Semi-Supervised Learning""]",,,,,
r1YNw6sxg,2017,Accept (Poster),False,Learning Visual Servoing with Deep Features and Fitted Q-Iteration,"[""Alex X. Lee"", ""Sergey Levine"", ""Pieter Abbeel""]","[""Computer vision"", ""Deep learning"", ""Reinforcement Learning""]","We use deep semantic features, learned predictive dynamics, and reinforcement learning to efficiently learn a visual servoing policy that is robust to visual variations.",,,,
r1YUtYx0-,2018,Invite to Workshop Track,False,Ensemble Robustness and Generalization of Stochastic Deep Learning Algorithms,"[""Tom Zahavy"", ""Bingyi Kang"", ""Alex Sivak"", ""Jiashi Feng"", ""Huan Xu"", ""Shie Mannor""]","[""Robustness"", ""Generalization"", ""Deep Learning"", ""Adversarial Learning""]","Explaining the generalization of stochastic deep learning algorithms, theoretically and empirically, via ensemble robustness",,,,
r1ZdKJ-0W,2018,Accept (Poster),False,Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking,"[""Aleksandar Bojchevski"", ""Stephan G\u00fcnnemann""]","[""node embeddings"", ""graphs"", ""unsupervised learning"", ""inductive learning"", ""uncertainty"", ""deep learning""]", We embed nodes in a graph as Gaussian distributions allowing us to capture uncertainty about their representation.,,,,
r1Zi2Mb0-,2018,Reject,False,EXPLORING NEURAL ARCHITECTURE SEARCH FOR LANGUAGE TASKS,"[""Minh-Thang Luong"", ""David Dohan"", ""Adams Wei Yu"", ""Quoc V. Le"", ""Barret Zoph"", ""Vijay Vasudevan""]","[""Neural architecture search"", ""language tasks"", ""neural machine translation"", ""reading comprehension"", ""SQuAD""]","We explore neural architecture search for language tasks. Recurrent cell search is challenging for NMT, but attention mechanism search works. The result of attention search on translation is transferable to reading comprehension.",,,,
r1aGWUqgg,2017,Reject,False,Unsupervised Learning of State Representations for Multiple Tasks,"[""Antonin Raffin"", ""Sebastian H\u00f6fer"", ""Rico Jonschkowski"", ""Oliver Brock"", ""Freek Stulp""]","[""Reinforcement Learning"", ""Unsupervised Learning""]",Learning method for automatic detection of multiple reinforcement tasks and extraction of state representations from raw observations,,,,
r1aPbsFle,2017,Accept (Poster),False,Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling,"[""Hakan Inan"", ""Khashayar Khosravi"", ""Richard Socher""]","[""Natural language processing"", ""Deep learning""]",,,,,
r1ayG7WRZ,2018,Reject,False,Don't encrypt the data; just approximate the model \ Towards Secure Transaction and Fair Pricing of Training Data,"[""Xinlei Xu""]","[""Applications"", ""Security in Machine Learning"", ""Fairness and Security"", ""Model Compression""]","Facing complex, black-box models, encrypting the data is not as usable as approximating the model and using it to price a potential transaction.",,,,
r1br_2Kge,2017,Invite to Workshop Track,False,Short and Deep: Sketching and Neural Networks,"[""Amit Daniely"", ""Nevena Lazic"", ""Yoram Singer"", ""Kunal Talwar""]","[""Theory""]","For sparse boolean inputs, Neural Networks operating on very short sketches can provably and empirically represent a large class of functions.",,,,
r1cLblgCZ,2018,Reject,False,Recurrent Auto-Encoder Model for Multidimensional Time Series Representation,"[""Timothy Wong"", ""Zhiyuan Luo""]","[""recurrent autoencoder"", ""seq2seq"", ""rnn"", ""multidimensional time series"", ""clustering"", ""sensor"", ""signal analysis"", ""industrial application""]",Using recurrent auto-encoder model to extract multidimensional time series features,,,,
r1d-lFmO-cM,2021,Reject,True,Pointwise Binary Classification with Pairwise Confidence Comparisons,"[""Lei Feng"", ""Senlin Shu"", ""Nan Lu"", ""Bo Han"", ""Miao Xu"", ""Gang Niu"", ""Bo An"", ""Masashi Sugiyama""]","[""Binary classification"", ""pairwise comparisons"", ""unbiased risk estimator""]",We can successfully learn a binary classifier from only pairwise comparison data.,2010.01875,cs.LG,2020-10-05 09:23:58+00:00,2021-06-19 15:08:45+00:00
r1dHXnH6-,2018,Accept (Poster),False,Natural Language Inference over Interaction Space,"[""Yichen Gong"", ""Heng Luo"", ""Jian Zhang""]","[""natural language inference"", ""attention"", ""SoTA"", ""natural language understanding""]",show multi-channel attention weight contains semantic feature to solve natural language inference task.,,,,
r1drp-WCZ,2018,Reject,False,State Space LSTM Models with Particle MCMC Inference,"[""Xun Zheng"", ""Manzil Zaheer"", ""Amr Ahmed"", ""Yuan Wang"", ""Eric P. Xing"", ""Alex Smola""]","[""recurrent neural networks"", ""state space models"", ""sequential Monte Carlo""]","We present State Space LSTM models, a combination of state space models and LSTMs, and propose an inference algorithm based on sequential Monte Carlo. ",,,,
r1e0G04Kvr,2020,Reject,False,Deep Graph Translation,"[""Xiaojie Guo"", ""Lingfei Wu"", ""Liang Zhao""]","[""Graph translation"", ""graph generation"", ""deep neural network""]",a novel Graph-Translation-Generative-Adversarial-Networks (GT-GAN) that transforms the input graphs into their target output graphs,,,,
r1e13s05YX,2019,Accept (Poster),False,Neural network gradient-based learning of black-box function interfaces,"[""Alon Jacovi"", ""Guy Hadash"", ""Einat Kermany"", ""Boaz Carmeli"", ""Ofer Lavi"", ""George Kour"", ""Jonathan Berant""]","[""neural networks"", ""black box functions"", ""gradient descent""]",Training DNNs to interface w\ black box functions w\o intermediate labels by using an estimator sub-network that can be replaced with the black box after training,,,,
r1e30AEKPr,2020,Reject,False,A Group-Theoretic Framework for Knowledge Graph Embedding,"[""Tong Yang"", ""Long Sha"", ""Pengyu Hong""]","[""group theory"", ""knowledge graph embedding"", ""representation learning""]",A group-theoretic framework for knowledge graph embedding learning,,,,
r1e4MkSFDr,2020,Reject,False,Continuous Convolutional Neural Network forNonuniform Time Series,"[""Hui Shi"", ""Yang Zhang"", ""Hao Wu"", ""Shiyu Chang"", ""Kaizhi Qian"", ""Mark Hasegawa-Johnson"", ""Jishen Zhao""]",[],,,,,
r1e74a4twH,2020,Reject,False,CZ-GEM:  A  FRAMEWORK  FOR DISENTANGLED REPRESENTATION LEARNING,"[""Akash Srivastava"", ""Yamini Bansal"", ""Yukun Ding"", ""Bernhard Egger"", ""Prasanna Sattigeri"", ""Josh Tenenbaum"", ""David D. Cox"", ""Dan Gutfreund""]","[""disentangled representation learning"", ""gan"", ""generative model"", ""simulator""]",Hierarchical generative model (hybrid of VAE and GAN) that learns a disentangled representation of data without compromising the generative quality.,,,,
r1e7M6VYwH,2020,Reject,False,RotationOut as a Regularization Method for Neural Network,"[""Kai Hu"", ""Barnabas Poczos""]","[""Neural Network"", ""Regularization""]",We propose a regularization method for neural network and a noise analysis method,1911.07427,cs.LG,2019-11-18 04:45:47+00:00,2019-11-18 04:45:47+00:00
r1e7NgrYvH,2020,Reject,False,DO-AutoEncoder: Learning and Intervening Bivariate Causal Mechanisms in Images,"[""Tianshuo Cong"", ""Dan Peng"", ""Furui Liu"", ""Zhitang Chen""]","[""Causality discovery"", ""AutoEncoder"", ""Deep representation learning"", ""Do-calculus""]",We propose a new framework  for deep representation learning that fully capture bivariate causal relationship in the images.,,,,
r1e8WTEYPB,2020,Reject,False,Sparse and Structured Visual Attention,"[""Pedro Henrique Martins"", ""Vlad Niculae"", ""Zita Marinho"", ""Andr\u00e9 F.T. Martins""]","[""Sparsity"", ""attention"", ""structured attention"", ""total variation"", ""fused lasso"", ""image captioning""]","We propose a new sparse and structured attention mechanism, TVmax, which promotes sparsity and encourages the weight of related adjacent locations to be the same.",,,,
r1e8qpVKPS,2020,Reject,False,Role of two learning rates in convergence of model-agnostic meta-learning,"[""Shiro Takagi"", ""Yoshihiro Nagano"", ""Yuki Yoshida"", ""Masato Okada""]","[""meta-learning"", ""convergence""]",We analyzed the role of two learning rates in model-agnostic meta-learning in convergence.,,,,
r1e9GCNKvH,2020,Accept (Poster),False,One-Shot Pruning of Recurrent Neural Networks by Jacobian Spectrum Evaluation,"[""Shunshi Zhang"", ""Bradly C. Stadie""]","[""Pruning"", ""RNNs"", ""Sparsity""]",New Objective for One-Shot Pruning Recurrent Neural Networks,,,,
r1eBeyHFDH,2020,Accept (Talk),False,A Theory of Usable Information under Computational Constraints,"[""Yilun Xu"", ""Shengjia Zhao"", ""Jiaming Song"", ""Russell Stewart"", ""Stefano Ermon""]",[],,2002.10689,cs.LG,2020-02-25 06:09:30+00:00,2020-02-25 06:09:30+00:00
r1eCukHYDH,2020,Reject,False,Manifold Learning and Alignment with Generative Adversarial Networks,"[""Jiseob Kim"", ""Seungjae Jung"", ""Hyundo Lee"", ""Byoung-Tak Zhang""]","[""Generative Adversarial Networks"", ""Manifold Learning"", ""Manifold Alignment""]","We present a generative adversarial network that performs both multi-manifold learning and manifold alignment, utilizing the abstraction ability of encoder architecture. ",,,,
r1eCy0NtDH,2020,Reject,True,Mean-field Behaviour of Neural Tangent Kernel for Deep Neural Networks,"[""Soufiane Hayou"", ""Arnaud Doucet"", ""Judith Rousseau""]",[],Impact of the Initialization and the Activation function on the Neural Tangent Kernel ,1905.13654,stat.ML,2019-05-31 14:53:59+00:00,2021-05-23 17:14:22+00:00
r1eEG20qKQ,2019,Accept (Poster),False,Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions,"[""Matthew Mackay"", ""Paul Vicol"", ""Jonathan Lorraine"", ""David Duvenaud"", ""Roger Grosse""]","[""hyperparameter optimization"", ""game theory"", ""optimization""]","We use a hypernetwork to predict optimal weights given hyperparameters, and jointly train everything together.",,,,
r1eIiCNYwS,2020,Accept (Poster),False,Transformer-XH: Multi-Evidence Reasoning with eXtra Hop Attention,"[""Chen Zhao"", ""Chenyan Xiong"", ""Corby Rosset"", ""Xia Song"", ""Paul Bennett"", ""Saurabh Tiwary""]","[""Transformer-XH"", ""multi-hop QA"", ""fact verification"", ""extra hop attention"", ""structured modeling""]","We present Transformer-XH, which upgrades Transformer with eXtra Hop attentions to intrinsically model structured texts in a data driven way. ",,,,
r1eJssCqY7,2019,Reject,False,TabNN: A Universal Neural Network Solution for Tabular Data,"[""Guolin Ke"", ""Jia Zhang"", ""Zhenhui Xu"", ""Jiang Bian"", ""Tie-Yan Liu""]","[""neural network"", ""machine learning"", ""tabular data""]",We propose a universal neural network solution to derive effective NN architectures for tabular data automatically.,,,,
r1eO_oCqtQ,2019,Reject,False,Gaussian-gated LSTM: Improved convergence by reducing state updates,"[""Matthew Thornton"", ""Jithendar Anumula"", ""Shih-Chii Liu""]","[""time gate"", ""faster convergence"", ""trainability"", ""rnn"", ""computational budget""]",Gaussian-gated LSTM is a novel time-gated LSTM RNN network that enables faster and better training on long sequence data.,1901.07334,cs.LG,2019-01-22 14:36:11+00:00,2019-01-22 14:36:11+00:00
r1eOnh4YPB,2020,Reject,True,How Does Learning Rate Decay Help Modern Neural Networks?,"[""Kaichao You"", ""Mingsheng Long"", ""Jianmin Wang"", ""Michael I. Jordan""]","[""Learning rate decay"", ""Optimization"", ""Explainability"", ""Deep learning"", ""Transfer learning""]",We provide another novel explanation of learning rate decay: an initially large learning rate suppresses the network from memorizing noisy data while decaying the learning rate improves the learning of complex patterns.,1908.01878,cs.LG,2019-08-05 21:56:41+00:00,2019-09-26 06:53:59+00:00
r1eQeCEYwB,2020,Reject,False,GRAPH ANALYSIS AND GRAPH POOLING IN THE SPATIAL DOMAIN,"[""Mostafa Rahmani"", ""Ping Li""]","[""Graph Neural Network"", ""Graph Classification"", ""Graph Pooling"", ""Graph Embedding""]",Addressing a serious shortcoming of the GNNs by making them aware of the role of the nodes in the structure of the graph and proposing a novel graph pooling method. ,,,,
r1eU1gHFvH,2020,Reject,False,Under what circumstances do local codes emerge in feed-forward neural networks,"[""Ella M. Gale"", ""Nicolas Martin""]","[""localist coding"", ""emergence"", ""contructionist science"", ""neural networks"", ""feed-forward"", ""learning representation"", ""distributed coding"", ""generalisation"", ""memorisation"", ""biological plausibility"", ""deep-NNs"", ""training conditions""]","Localist codes emerge in response to learning a rule and generalising in 3- and 4-layer NNs under some situations, including noise, but are inhibited by softmax, large datasets and early stopping.",,,,
r1eUukrtwH,2020,Reject,False,The Variational InfoMax AutoEncoder,"[""Vinenzo Crescimanna"", ""Bruce Graham""]","[""autoencoder"", ""information theory"", ""infomax"", ""vae""]","We propose a VIMAE, a variational autoencoder learning both a good generative model and disentangled representations",,,,
r1eVMnA9K7,2019,Accept (Poster),False,Unsupervised Control Through Non-Parametric Discriminative Rewards,"[""David Warde-Farley"", ""Tom Van de Wiele"", ""Tejas Kulkarni"", ""Catalin Ionescu"", ""Steven Hansen"", ""Volodymyr Mnih""]","[""deep reinforcement learning"", ""goals"", ""UVFA"", ""mutual information""]",Unsupervised reinforcement learning method for learning a policy to robustly achieve perceptually specified goals.,,,,
r1eVX0EFvH,2020,Reject,False,Exploiting Excessive Invariance caused by Norm-Bounded Adversarial Robustness,"[""J\u00f6rn-Henrik Jacobsen"", ""Jens Behrmann"", ""Nicholas Carlini"", ""Florian Tram\u00e8r"", ""Nicolas Papernot""]","[""Invariance"", ""Robustness"", ""Adversarial Examples""]","We show that invariance-based adversarial examples are a threat to perturbation robust classifiers both theoretically and practically, e.g., by reducing the accuracy of a defense certified to give 87% accuracy to just 12%.",,,,
r1eVXa4KvH,2020,Reject,False,Concise Multi-head Attention Models,"[""Srinadh Bhojanapalli"", ""Chulhee Yun"", ""Ankit Singh Rawat"", ""Sashank Reddi"", ""Sanjiv Kumar""]","[""Transformers"", ""Attention"", ""Multihead"", ""expressive power"", ""embedding size""]",Fixing the head size of the Transformer models allows one to train them with a smaller embedding size.,,,,
r1eWdlBFwS,2020,Reject,False,Isolating Latent Structure with Cross-population Variational Autoencoders,"[""Joe Davison"", ""Kristen A. Severson"", ""Soumya Ghosh""]","[""variational autoencoder"", ""latent variable model"", ""probabilistic graphical model"", ""machine learning"", ""deep learning"", ""continual learning""]","A variant of the VAE which models data from differing distributions, isolating the latent factors which are unique to each set as well as the shared structure",,,,
r1eX1yrKwB,2020,Reject,False,Distribution Matching Prototypical Network for Unsupervised Domain Adaptation,"[""Lei Zhu"", ""Wei Wang"", ""Mei Hui Zhang"", ""Beng Chin Ooi"", ""Chang Yao""]","[""Deep Learning"", ""Unsupervised Domain Adaptation"", ""Distribution Modeling""]",We propose to explicitly model deep feature distributions of source and target data as Gaussian mixture distributions for Unsupervised Domain Adaptation (UDA) and achieve superior results in multiple UDA tasks than state-of-the-art methods.,,,,
r1e_FpNFDr,2020,Accept (Poster),False,Generalization bounds for deep convolutional neural networks,"[""Philip M. Long"", ""Hanie Sedghi""]","[""generalization"", ""convolutional networks"", ""statistical learning theory""]",We prove generalization bounds for convolutional neural networks that take account of weight-tying,,,,
r1ecqn4YwB,2020,Accept (Poster),True,N-BEATS: Neural basis expansion analysis for interpretable time series forecasting,"[""Boris N. Oreshkin"", ""Dmitri Carpov"", ""Nicolas Chapados"", ""Yoshua Bengio""]","[""time series forecasting"", ""deep learning""]",A novel deep interpretable architecture that achieves state of the art on three large scale univariate time series forecasting datasets ,1905.10437,cs.LG,2019-05-24 20:28:57+00:00,2020-02-20 21:08:57+00:00
r1efr3C9Ym,2019,Accept (Poster),False,Interpolation-Prediction Networks for Irregularly Sampled Time Series,"[""Satya Narayan Shukla"", ""Benjamin Marlin""]","[""irregular sampling"", ""multivariate time series"", ""supervised learning"", ""interpolation"", ""missing data""]",This paper presents a new deep learning architecture for addressing the problem of supervised learning with sparse and irregularly sampled multivariate time series.,,,,
r1egIyBFPS,2020,Accept (Poster),False,Deep Symbolic Superoptimization Without Human Knowledge,"[""Hui Shi"", ""Yang Zhang"", ""Xinyun Chen"", ""Yuandong Tian"", ""Jishen Zhao""]",[],,,,,
r1eh30NFwB,2020,Reject,False,Variational Autoencoders with Normalizing Flow Decoders,"[""Rogan Morrow"", ""Wei-Chen Chiu""]",[],,2004.05617,cs.LG,2020-04-12 14:11:15+00:00,2020-04-12 14:11:15+00:00
r1eiqi09K7,2019,Accept (Poster),False,Riemannian Adaptive Optimization Methods,"[""Gary Becigneul"", ""Octavian-Eugen Ganea""]","[""Riemannian optimization"", ""adaptive"", ""hyperbolic"", ""curvature"", ""manifold"", ""adam"", ""amsgrad"", ""adagrad"", ""rsgd"", ""convergence""]","Adapting Adam, Amsgrad, Adagrad to Riemannian manifolds. ",,,,
r1eiu2VtwH,2020,Accept (Poster),True,Neural Oblivious Decision Ensembles for Deep Learning on Tabular Data,"[""Sergei Popov"", ""Stanislav Morozov"", ""Artem Babenko""]","[""tabular data"", ""architectures"", ""DNN""]",We propose a new DNN architecture for deep learning on tabular data,1909.06312,cs.LG,2019-09-13 16:11:28+00:00,2019-09-19 13:30:23+00:00
r1elIi09K7,2019,Reject,False,Learning a Neural-network-based Representation for Open Set Recognition,"[""Mehadi Hassen"", ""Philip K. Chan""]","[""open set recognition""]","In this paper, we present a neural network based representation for addressing the open set recognition problem.",,,,
r1enqkBtwr,2020,Reject,False,Asymptotic learning curves of kernel methods: empirical data v.s. Teacher-Student paradigm,"[""Stefano Spigler"", ""Mario Geiger"", ""Matthieu Wyart""]",[],,,,,
r1eowANFvr,2020,Accept (Poster),False,Towards Fast Adaptation of Neural Architectures with Meta Learning,"[""Dongze Lian"", ""Yin Zheng"", ""Yintao Xu"", ""Yanxiong Lu"", ""Leyu Lin"", ""Peilin Zhao"", ""Junzhou Huang"", ""Shenghua Gao""]","[""Fast adaptation"", ""Meta learning"", ""NAS""]",A meta-learning method for fast adaptation of neural architectures.,,,,
r1erNxBtwr,2020,Reject,False,Demystifying Graph Neural Network Via Graph Filter Assessment,"[""Yewen Wang"", ""Ziniu Hu"", ""Yusong Ye"", ""Yizhou Sun""]","[""Graph Neural Networks"", ""Graph convolutional filter analysis"", ""representational power""]",Propose an assessment framework to analyze and learn graph convolutional filter,,,,
r1erRoCqtX,2019,Reject,False,LSH Microbatches for Stochastic Gradients:  Value in Rearrangement,"[""Eliav Buchnik"", ""Edith Cohen"", ""Avinatan Hassidim"", ""Yossi Matias""]","[""Stochastic Gradient Descent"", ""Metric Embeddings"", ""Locality  Sensitive Hashing"", ""Microbatches"", ""Sample coordination""]",Accelerating SGD by arranging examples differently,,,,
r1esnoAqt7,2019,Reject,False,Morpho-MNIST: Quantitative Assessment and Diagnostics for Representation Learning,"[""Daniel C. Castro"", ""Jeremy Tan"", ""Bernhard Kainz"", ""Ender Konukoglu"", ""Ben Glocker""]","[""quantitative evaluation"", ""diagnostics"", ""generative models"", ""representation learning"", ""morphometrics"", ""image perturbations""]","This paper introduces Morpho-MNIST, a collection of shape metrics and perturbations, in a step towards quantitative evaluation of representation learning.",,,,
r1espiA9YQ,2019,Reject,False,Towards More Theoretically-Grounded Particle Optimization Sampling for Deep Learning,"[""Jianyi Zhang"", ""Ruiyi Zhang"", ""Changyou Chen""]",[],,,,,
r1etN1rtPB,2020,Accept (Talk),False,Implementation Matters in Deep RL: A Case Study on PPO and TRPO,"[""Logan Engstrom"", ""Andrew Ilyas"", ""Shibani Santurkar"", ""Dimitris Tsipras"", ""Firdaus Janoos"", ""Larry Rudolph"", ""Aleksander Madry""]","[""deep policy gradient methods"", ""deep reinforcement learning"", ""trpo"", ""ppo""]",,2005.12729,cs.LG,2020-05-25 16:24:59+00:00,2020-05-25 16:24:59+00:00
r1evOhEKvH,2020,Accept (Poster),False,Graph inference learning for semi-supervised classification,"[""Chunyan Xu"", ""Zhen Cui"", ""Xiaobin Hong"", ""Tong Zhang"", ""Jian Yang"", ""Wei Liu""]","[""semi-supervised classification"", ""graph inference learning""]", We propose a novel graph inference learning framework by building structure relations to infer unknown node labels from those labeled nodes in an end-to-end way.,2001.06137,cs.LG,2020-01-17 02:52:30+00:00,2020-01-17 02:52:30+00:00
r1exVhActQ,2019,Reject,False,DEEP-TRIM: REVISITING L1 REGULARIZATION FOR CONNECTION PRUNING OF DEEP NETWORK,"[""Chih-Kuan Yeh"", ""Ian E.H. Yen"", ""Hong-You Chen"", ""Chun-Pei Yang"", ""Shou-De Lin"", ""Pradeep Ravikumar""]","[""L1 regularization"", ""deep neural network"", ""deep compression""]",We revisit the simple idea of pruning connections of DNNs through $\ell_1$ regularization achieving state-of-the-art results on multiple datasets with theoretic guarantees.,,,,
r1eyceSYPr,2020,Accept (Spotlight),False,Unbiased Contrastive Divergence Algorithm for Training Energy-Based Latent Variable Models,"[""Yixuan Qiu"", ""Lingsong Zhang"", ""Xiao Wang""]","[""energy model"", ""restricted Boltzmann machine"", ""contrastive divergence"", ""unbiased Markov chain Monte Carlo"", ""distribution coupling""]",We have developed a new training algorithm for energy-based latent variable models that completely removes the bias of contrastive divergence.,,,,
r1ez_sRcFQ,2019,Reject,False,Pixel Redrawn For A Robust Adversarial Defense,"[""Jiacang Ho"", ""Dae-Ki Kang""]","[""adversarial machine learning"", ""deep learning"", ""adversarial example""]",,,,,
r1ezqaEFPr,2020,Reject,False,Multi-Task Learning via Scale Aware Feature Pyramid Networks and Effective Joint Head,"[""Feng Ni""]","[""Multi-Task Learning"", ""Object Detection"", ""Instance Segmentation""]",Our work improve Mask R-CNN by using Scale Aware FPN to remedy scale variation issue and conbining detection and segmentation branches into Effective Joint Head for more expressive multi-task learning. ,,,,
r1f0YiCctm,2019,Accept (Poster),False,Minimal Random Code Learning: Getting Bits Back from Compressed Model Parameters,"[""Marton Havasi"", ""Robert Peharz"", ""Jos\u00e9 Miguel Hern\u00e1ndez-Lobato""]","[""compression"", ""neural networks"", ""bits-back argument"", ""Bayesian"", ""Shannon"", ""information theory""]",This paper proposes an effective method to compress neural networks based on recent results in information theory.,,,,
r1f78iAcFm,2019,Reject,False,GRAPH TRANSFORMATION POLICY NETWORK FOR CHEMICAL REACTION PREDICTION,"[""Kien Do"", ""Truyen Tran"", ""Svetha Venkatesh""]","[""Chemical Reaction"", ""Graph Transformation"", ""Reinforcement Learning""]",,,,,
r1fE3sAcYQ,2019,Reject,False,Overcoming Multi-model Forgetting,"[""Yassine Benyahia*"", ""Kaicheng Yu*"", ""Kamil Bennani-Smires"", ""Martin Jaggi"", ""Anthony Davison"", ""Mathieu Salzmann"", ""Claudiu Musat""]","[""multi-model forgetting"", ""deep learning"", ""machine learning"", ""multi-model training"", ""neural architecture search""]","We identify a phenomenon, neural brainwashing, and introduce a statistically-justified weight plasticity loss to overcome this.",,,,
r1fO8oC9Y7,2019,Reject,False,Multi-Task Learning for Semantic Parsing with Cross-Domain Sketch,"[""Huan Wang"", ""Yuxiang Hu"", ""Li Dong"", ""Feijun Jiang"", ""Zaiqing Nie""]","[""semantic parsing"", ""natural language understanding"", ""machine learning""]",General-to-detailed neural network(GDNN)  with Multi-Task Learning by incorporating cross-domain sketch(CDS) for semantic parsing,,,,
r1fWmnR5tm,2019,Reject,False,Learning to Search Efficient DenseNet with Layer-wise Pruning,"[""Xuanyang Zhang"", ""Hao liu"", ""Zhanxing Zhu"", ""Zenglin Xu""]","[""reinforcement learning"", ""DenseNet"", ""neural network compression""]",,,,,
r1fYuytex,2017,Accept (Poster),False,Sparsely-Connected Neural Networks: Towards Efficient VLSI Implementation of Deep Neural Networks,"[""Arash Ardakani"", ""Carlo Condo"", ""Warren J. Gross""]","[""Deep learning"", ""Applications"", ""Optimization""]",We show that the number of connections in fully-connected networks can be reduced by up to 90% while improving the accuracy performance.,,,,
r1fiFs09YX,2019,Reject,False,Sample-efficient policy learning in multi-agent Reinforcement Learning via meta-learning,"[""Jialian Li"", ""Hang Su"", ""Jun Zhu""]","[""Multi-agent"", ""Reinforcement Learning"", ""Meta-learning""]",Our work applies meta-learning to multi-agent Reinforcement Learning to help our agent efficiently adapted to new coming opponents.,,,,
r1g1CAEKDH,2020,Reject,False,Wyner VAE: A Variational Autoencoder with Succinct Common Representation Learning,"[""J. Jon Ryu"", ""Yoojin Choi"", ""Young-Han Kim"", ""Mostafa El-Khamy"", ""Jungwon Lee""]","[""Wyner's common information"", ""information theoretic regularization"", ""information bottleneck"", ""representation learning"", ""generative models"", ""conditional generation"", ""joint generation"", ""style transfer"", ""variational autoencoders""]",,,,,
r1g1LoAcFm,2019,Reject,False,Using Ontologies To Improve Performance In Massively Multi-label Prediction,"[""Ethan Steinberg"", ""Peter J. Liu""]","[""multi-label"", ""Bayesian network"", ""ontology""]", We propose a new method for using ontology information to improve performance on massively multi-label prediction/classification problems.,,,,
r1g4E3C9t7,2019,Accept (Poster),False,Characterizing Audio Adversarial Examples Using Temporal Dependency,"[""Zhuolin Yang"", ""Bo Li"", ""Pin-Yu Chen"", ""Dawn Song""]","[""audio adversarial example"", ""mitigation"", ""detection"", ""machine learning""]",Adversarial audio discrimination using temporal dependency,,,,
r1g5b2RcKm,2019,Reject,False,MLPrune: Multi-Layer Pruning for Automated Neural Network Compression,"[""Wenyuan Zeng"", ""Raquel Urtasun""]","[""Automated Model Compression"", ""Neural Network Pruning""]","MLPrune: an automated pruning method that doesn't require any tuning for per-layer compression ratio, achieves state-of-the-art pruning results on AlexNet and VGG16.",,,,
r1g6MCEtwr,2020,Reject,False,Zero-Shot Out-of-Distribution Detection with Feature Correlations,"[""Chandramouli S Sastry"", ""Sageev Oore""]","[""out-of-distribution"", ""gram matrices"", ""classification"", ""out-of-distribution detection""]","We extend Gram matrices to compute feature correlations that allow us to detect OOD examples without requiring any OOD examples, and achieve detection rates that are generally equal to or better current state-of-the-art.",,,,
r1g6ogrtDr,2020,Accept (Poster),False,Co-Attentive Equivariant Neural Networks: Focusing Equivariance On Transformations Co-Occurring in Data,"[""David W. Romero"", ""Mark Hoogendoorn""]","[""Equivariant Neural Networks"", ""Attention Mechanisms"", ""Deep Learning""]",We utilize attention to restrict equivariant neural networks to the set or co-occurring transformations in data. ,1911.07849,cs.CV,2019-11-18 12:41:12+00:00,2020-02-10 13:56:10+00:00
r1g7y2RqYX,2019,Reject,False,Label Propagation Networks,"[""Kojin Oshiba"", ""Nir Rosenfeld"", ""Amir Globerson""]","[""semi supervised learning"", ""graph networks"", ""deep learning architectures""]",Neural net for graph-based semi-supervised learning; revisits the classics and propagates *labels* rather than feature representations,,,,
r1g87C4KwB,2020,Accept (Spotlight),False,The Break-Even Point on Optimization Trajectories of Deep Neural Networks,"[""Stanislaw Jastrzebski"", ""Maciej Szymczak"", ""Stanislav Fort"", ""Devansh Arpit"", ""Jacek Tabor"", ""Kyunghyun Cho*"", ""Krzysztof Geras*""]","[""generalization"", ""sgd"", ""learning rate"", ""batch size"", ""hessian"", ""curvature"", ""trajectory"", ""optimization""]","In the early phase of training of deep neural networks there exists a ""break-even point"" which determines properties of the entire optimization trajectory.",,,,
r1gBOxSFwr,2020,Reject,True,Reweighted Proximal Pruning for Large-Scale Language Representation,"[""Fu-Ming Guo"", ""Sijia Liu"", ""Finlay S. Mungall"", ""Xue Lin"", ""Yanzhi Wang""]","[""Language Representation"", ""Machine Learning"", ""Deep Learning"", ""Optimizer"", ""Statistical Learning"", ""Model Compression""]","We develop the pruning algorithm Reweighted Proximal Pruning (RPP), which achieves the first effective weight pruning result on large-scale pre-trained language representation model-BERT.",1909.12486,cs.LG,2019-09-27 04:10:10+00:00,2019-12-23 01:23:53+00:00
r1gEXgBYDH,2020,Reject,False,Defensive Tensorization: Randomized Tensor Parametrization for Robust Neural Networks,"[""Adrian Bulat"", ""Jean Kossaifi"", ""Sourav Bhattacharya"", ""Yannis Panagakis"", ""Georgios Tzimiropoulos"", ""Nicholas D.  Lane"", ""Maja Pantic""]","[""tensor decomposition"", ""tensor factorization"", ""randomization"", ""robustness""]","We propose defensive tensorization, a novel adversarial defense technique that leverages a latent, randomized high order factorization of the network that renders it more robust.",,,,
r1gEqiC9FX,2019,Accept (Poster),False,Equi-normalization of Neural Networks,"[""Pierre Stock"", ""Benjamin Graham"", ""R\u00e9mi Gribonval"", ""Herv\u00e9 J\u00e9gou""]","[""convolutional neural networks"", ""Normalization"", ""Sinkhorn"", ""Regularization""]",Fast iterative algorithm to balance the energy of a network while staying in the same functional equivalence class,1902.10416,cs.CV,2019-02-27 09:52:43+00:00,2019-02-27 09:52:43+00:00
r1gGpjActQ,2019,Reject,False,Hint-based Training for Non-Autoregressive Translation,"[""Zhuohan Li"", ""Di He"", ""Fei Tian"", ""Tao Qin"", ""Liwei Wang"", ""Tie-Yan Liu""]","[""Natural Language Processing"", ""Machine Translation"", ""Non-Autoregressive Model""]","We develop a training algorithm for non-autoregressive machine translation models, achieving comparable accuracy to strong autoregressive baselines, but one order of magnitude faster in inference.  ",,,,
r1gIa0NtDH,2020,Reject,True,MelNet: A Generative Model for Audio in the Frequency Domain,"[""Sean Vasquez"", ""Mike Lewis""]",[],We introduce an autoregressive generative model for spectrograms and demonstrate applications to speech and music generation,1906.01083,eess.AS,2019-06-04 04:58:19+00:00,2019-06-04 04:58:19+00:00
r1gIdySFPH,2020,Reject,True,Skew-Fit: State-Covering Self-Supervised Reinforcement Learning,"[""Vitchyr H. Pong"", ""Murtaza Dalal"", ""Steven Lin"", ""Ashvin Nair"", ""Shikhar Bahl"", ""Sergey Levine""]","[""deep reinforcement learning"", ""goal space"", ""goal conditioned reinforcement learning"", ""self-supervised reinforcement learning"", ""goal sampling"", ""reinforcement learning""]","We propose a principled objective for autonomous goal-setting in high-dimensional, unknown goal spaces and present a method that theoretically and empirically learns the optimal goal distribution.",1903.03698,cs.LG,2019-03-08 23:32:17+00:00,2020-08-04 04:07:27+00:00
r1gIwgSYwr,2020,Reject,False,Localized Meta-Learning: A PAC-Bayes Analysis for Meta-Leanring Beyond Global Prior,"[""Chenghao Liu"", ""Tao Lu"", ""Doyen Sahoo"", ""Yuan Fang"", ""Steven C.H. Hoi.""]","[""localized meta-learning"", ""PAC-Bayes"", ""meta-learning""]",,,,,
r1gKNs0qYX,2019,Reject,False,Filter Training and Maximum Response: Classification via Discerning,"[""Lei Gu""]","[""filter training"", ""maximum response"", ""multiple check"", ""ensemble learning""]",The proposed scheme mimics the classification process mediated by a series of one component picking.,,,,
r1gNLAEFPS,2020,Reject,False,Neural ODEs for Image Segmentation with Level Sets,"[""Rafael Valle"", ""Fitsum Reda"", ""Mohammad Shoeybi"", ""Patrick Legresley"", ""Andrew Tao"", ""Bryan Catanzaro""]","[""neural odes"", ""level sets"", ""image segmentation""]",We propose a novel approach for image segmentation that combines Neural Ordinary Differential Equations (NODEs) and the Level Set method. ,1912.11683,cs.CV,2019-12-25 15:02:24+00:00,2019-12-25 15:02:24+00:00
r1gNni0qtm,2019,Accept (Poster),False,Generalized Tensor Models for Recurrent Neural Networks,"[""Valentin Khrulkov"", ""Oleksii Hrinchuk"", ""Ivan Oseledets""]","[""expressive power"", ""recurrent neural networks"", ""Tensor-Train decomposition""]",Analysis of expressivity and generality of recurrent neural networks with ReLu nonlinearities using Tensor-Train decomposition.,,,,
r1gOe209t7,2019,Reject,False,Reconciling Feature-Reuse and Overfitting in DenseNet with Specialized Dropout,"[""Kun Wan"", ""Boyuan Feng"", ""Lingwei Xie"", ""Yufei Ding""]","[""Specialized dropout"", ""computer vision""]","Realizing the drawbacks when applying original dropout on DenseNet, we craft the design of dropout method from three aspects, the idea of which could also be applied on other CNN models.",,,,
r1gPoCEKvH,2020,Reject,True,SINGLE PATH ONE-SHOT NEURAL ARCHITECTURE SEARCH WITH UNIFORM SAMPLING,"[""Zichao Guo"", ""Xiangyu Zhang"", ""Haoyuan Mu"", ""Wen Heng"", ""Zechun Liu"", ""Yichen Wei"", ""Jian Sun""]","[""Neural Architecture Search"", ""Single Path""]",,1904.00420,cs.CV,2019-03-31 14:34:43+00:00,2020-07-08 10:55:28+00:00
r1gR2sC9FX,2019,Reject,False,On the Spectral Bias of Neural Networks,"[""Nasim Rahaman"", ""Aristide Baratin"", ""Devansh Arpit"", ""Felix Draxler"", ""Min Lin"", ""Fred Hamprecht"", ""Yoshua Bengio"", ""Aaron Courville""]","[""deep learning theory"", ""fourier analysis""]",We investigate ReLU networks in the Fourier domain and demonstrate peculiar behaviour.,,,,
r1gRCiA5Ym,2019,Reject,False,Jumpout: Improved Dropout for Deep Neural Networks with Rectified Linear Units,"[""Shengjie Wang"", ""Tianyi Zhou"", ""Jeff Bilmes""]","[""Dropout"", ""deep neural networks with ReLU"", ""local linear model""]","Jumpout applies three simple yet effective modifications to dropout, based on novel understandings about the generalization performance of DNN with ReLU in local regions.",,,,
r1gRTCVFvB,2020,Accept (Poster),True,Decoupling Representation and Classifier for Long-Tailed Recognition,"[""Bingyi Kang"", ""Saining Xie"", ""Marcus Rohrbach"", ""Zhicheng Yan"", ""Albert Gordo"", ""Jiashi Feng"", ""Yannis Kalantidis""]","[""long-tailed recognition"", ""classification""]",,1910.09217,cs.CV,2019-10-21 09:03:19+00:00,2020-02-19 15:51:25+00:00
r1gV3nVKPS,2020,Reject,False,Beyond Classical Diffusion: Ballistic Graph Neural Network,"[""Yimeng Min""]","[""Graph Convolutional Network"", ""Diffusion"", ""Transportation"", ""Machine Learning""]",A new perspective on how to collect the correlation between nodes based on diffusion properties.,,,,
r1gVqsA9tQ,2019,Reject,False,ChainGAN: A sequential approach to GANs,"[""Safwan Hossain"", ""Kiarash Jamali"", ""Yuchen Li"", ""Frank Rudzicz""]","[""Machine Learning"", ""Sequential Models"", ""GANs""]",Multistep generation process for GANs,,,,
r1gc3lBFPH,2020,Reject,False,Keyword Spotter Model for Crop Pest and Disease Monitoring from Community Radio Data,"[""Benjamin Akera"", ""Joyce Nakatumba-Nabende"", ""Ali Hussein"", ""Daniel Ssendiwala"", ""Jonathan Mukiibi""]","[""keyword spotter"", ""radio data"", ""crop pest and disease"", ""agriculture""]",This paper describes an approach to analyse community radio data with machine learning-based speech keyword spotting techniques for crop pest and disease monitoring.,,,,
r1gdj2EKPB,2020,Accept (Poster),True,Scalable and Order-robust Continual Learning with Additive Parameter Decomposition,"[""Jaehong Yoon"", ""Saehoon Kim"", ""Eunho Yang"", ""Sung Ju Hwang""]","[""Continual Learning"", ""Lifelong Learning"", ""Catastrophic Forgetting"", ""Deep Learning""]",,1902.09432,cs.LG,2019-02-25 16:49:52+00:00,2020-02-15 14:13:27+00:00
r1ge8sCqFX,2019,Reject,False,An Exhaustive Analysis of Lazy vs. Eager Learning Methods for Real-Estate Property Investment,"[""Setareh Rafatirad"", ""Maryam Heidari""]","[""applied machine learning"", ""housing analytics"", ""eager learning"", ""lazy learning"", ""rent prediction""]",,,,,
r1geR1BKPr,2020,Reject,False,MULTI-STAGE INFLUENCE FUNCTION,"[""Hongge Chen"", ""Si Si"", ""Yang Li"", ""Ciprian Chelba"", ""Sanjiv Kumar"", ""Duane Boning"", ""Cho-Jui Hsieh""]","[""influence function"", ""multistage training"", ""pretrained model""]",We proposed a influence function for multi-stage training,2007.09081,cs.LG,2020-07-17 16:03:11+00:00,2020-07-17 16:03:11+00:00
r1gelyrtwH,2020,Accept (Poster),False,Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics,"[""Sungyong Seo*"", ""Chuizheng Meng*"", ""Yan Liu""]","[""physics-aware learning"", ""spatial difference operators"", ""sparsely-observed dynamics""]",We propose physics-aware difference graph networks designed to effectively learn spatial differences to modeling sparsely-observed dynamics.,,,,
r1genAVKPB,2020,Accept (Spotlight),True,Is a Good Representation Sufficient for Sample Efficient Reinforcement Learning?,"[""Simon S. Du"", ""Sham M. Kakade"", ""Ruosong Wang"", ""Lin F. Yang""]","[""reinforcement learning"", ""function approximation"", ""lower bound"", ""representation""]",Exponential lower bounds for value-based and policy-based reinforcement learning with function approximation.,1910.03016,cs.LG,2019-10-07 19:04:43+00:00,2020-02-28 03:31:55+00:00
r1gfQgSFDr,2020,Accept (Talk),True,High Fidelity Speech Synthesis with Adversarial Networks,"[""Miko\u0142aj Bi\u0144kowski"", ""Jeff Donahue"", ""Sander Dieleman"", ""Aidan Clark"", ""Erich Elsen"", ""Norman Casagrande"", ""Luis C. Cobo"", ""Karen Simonyan""]","[""texttospeech"", ""speechsynthesis"", ""audiosynthesis"", ""gans"", ""generativeadversarialnetworks"", ""implicitgenerativemodels""]","We introduce GAN-TTS, a Generative Adversarial Network for Text-to-Speech, which achieves Mean Opinion Score (MOS) 4.2.",1909.11646,cs.SD,2019-09-25 17:47:49+00:00,2019-09-26 21:12:19+00:00
r1gfweBFPB,2020,Reject,False,Learning by shaking: Computing policy gradients by physical forward-propagation,"[""Arash Mehrjou"", ""Ashkan Soleymani"", ""Stefan Bauer"", ""Bernhard Sch\u00f6lkopf""]","[""Reinforcement Learning"", ""Control Theory""]",We propose a method to learn the effect of changing the parameters of the policy on the produced trajectories directly from the physical system.,,,,
r1ghgxHtPH,2020,Reject,True,Blurring Structure and Learning to Optimize and Adapt Receptive Fields,"[""Evan Shelhamer"", ""Dequan Wang"", ""Trevor Darrell""]","[""scale"", ""deep learning"", ""dynamic inference"", ""fully convolutional""]",Composing structured Gaussian and free-form filters makes receptive field size and shape differentiable for end-to-end optimization and dynamic adaptation.,1904.11487,cs.CV,2019-04-25 17:57:10+00:00,2019-04-25 17:57:10+00:00
r1gixp4FPH,2020,Accept (Poster),True,Accelerating SGD with momentum for over-parameterized learning,"[""Chaoyue Liu"", ""Mikhail Belkin""]","[""SGD"", ""acceleration"", ""momentum"", ""stochastic"", ""over-parameterized"", ""Nesterov""]","This work proves the non-acceleration of Nesterov SGD with any hyper-parameters, and proposes new algorithm which provably accelerates SGD in the over-parameterized setting.",1810.13395,cs.LG,2018-10-31 16:44:05+00:00,2019-09-27 17:38:08+00:00
r1gkAoA5FQ,2019,Reject,False,"A bird's eye view on coherence, and a worm's eye view on cohesion","[""Woon Sang Cho"", ""Pengchuan Zhang"", ""Yizhe Zhang"", ""Xiujun Li"", ""Mengdi Wang"", ""Jianfeng Gao""]","[""text generation"", ""natural language processing"", ""neural language model""]","We encode linguistic properties, such as, coherence and cohesion, into expert discriminators and improve text generation.",,,,
r1gl7hC5Km,2019,Reject,False,Adapting Auxiliary Losses Using Gradient Similarity,"[""Yunshu Du"", ""Wojciech M. Czarnecki"", ""Siddhant M. Jayakumar"", ""Razvan Pascanu"", ""Balaji Lakshminarayanan""]","[""auxiliary losses"", ""transfer learning"", ""task similarity"", ""deep learning"", ""deep reinforcement learning""]",Auxiliary tasks need to match the main task to improve learning; we propose to use cosine distance between gradients of an unknown auxiliary task to protect from negative interference with learning the main task.,,,,
r1glDpNYwS,2020,Reject,False,LabelFool: A Trick in the Label Space,"[""Yujia Liu"", ""Tingting Jiang"", ""Ming Jiang""]","[""Adversarial attack"", ""LabelFool"", ""Imperceptibility"", ""Label space""]",A trick on adversarial samples so that the mis-classified labels are imperceptible in the label space to human observers,,,,
r1glehC5tQ,2019,Reject,False,Distinguishability of Adversarial Examples,"[""Yi Qin"", ""Ryan Hunt"", ""Chuan Yue""]","[""Adversarial Examples"", ""Machine Learning"", ""Neural Networks"", ""Distinguishability"", ""Defense""]",We propose a defensive distinction protection approach and demonstrate the strong distinguishability of adversarial examples.,,,,
r1glygHtDB,2020,Reject,True,A multi-task U-net for segmentation with lazy labels,"[""Rihuan Ke"", ""Aur\u00e9lie Bugeau"", ""Nicolas Papadakis"", ""Peter Schuetz"", ""Carola-Bibiane Sch\u00f6nlieb""]","[""multi-task learning"", ""weak labels"", ""semisupervised learning"", ""image segmentation""]",A novel multi-task learning strategy that integrates user-friendly labelling and an end-to-end model for image segmentation ,1906.12177,cs.CV,2019-06-20 17:38:54+00:00,2020-09-10 10:08:44+00:00
r1gnQ20qYX,2019,Reject,False,Pearl: Prototype lEArning via Rule Lists,"[""Tianfan Fu*"", ""Tian Gao*"", ""Cao Xiao*"", ""Tengfei Ma*"", ""Jimeng Sun""]","[""rule list learning"", ""prototype learning"", ""interpretability"", ""healthcare""]",a method combining rule list learning and prototype learning ,,,,
r1gs9JgRZ,2018,Accept (Poster),False,Mixed Precision Training,"[""Paulius Micikevicius"", ""Sharan Narang"", ""Jonah Alben"", ""Gregory Diamos"", ""Erich Elsen"", ""David Garcia"", ""Boris Ginsburg"", ""Michael Houston"", ""Oleksii Kuchaiev"", ""Ganesh Venkatesh"", ""Hao Wu""]","[""Half precision"", ""float16"", ""Convolutional neural networks"", ""Recurrent neural networks""]",,,,,
r1gx60NKPS,2020,Reject,False,JAUNE: Justified And Unified Neural language Evaluation,"[""Hassan Kan\u00e9"", ""Yusuf Kocyigit"", ""Ali Abdalla"", ""Pelkins Ajanoh"", ""Mohamed Coulibali""]","[""NLP"", ""Evaluation Metrics"", ""Summarization"", ""Translation"", ""BLEU"", ""ROUGE"", ""Transformers""]","Introduces JAUNE: a methodology to replace BLEU and ROUGE score with multidimensional, model-based evaluators for assessing summaries",,,,
r1gzdhEKvH,2020,Reject,True,Neural Linear Bandits: Overcoming Catastrophic Forgetting through Likelihood Matching,"[""Tom Zahavy"", ""Shie Mannor""]",[],Neural-linear bandits combine linear contextual bandits with deep neural networks to solve problems where both exploration and representation learning play an important role.,1901.08612,cs.LG,2019-01-24 19:15:17+00:00,2019-08-11 11:55:34+00:00
r1gzoaNtvr,2020,Reject,True,Emergence of Compositional Language with Deep Generational Transmission,"[""Michael Cogswell"", ""Jiasen Lu"", ""Stefan Lee"", ""Devi Parikh"", ""Dhruv Batra""]","[""Cultural Evolution"", ""Deep Learning"", ""Language Emergence""]",We use cultural transmission to encourage compositionality in languages that emerge from interactions between neural agents.,1904.09067,cs.LG,2019-04-19 04:09:12+00:00,2020-05-27 19:54:23+00:00
r1h2DllAW,2018,Reject,False,Discrete-Valued Neural Networks Using Variational Inference,"[""Wolfgang Roth"", ""Franz Pernkopf""]","[""low-precision"", ""neural networks"", ""resource efficient"", ""variational inference"", ""Bayesian""]",Variational Inference for infering a discrete distribution from which a low-precision neural network is derived,,,,
r1hsJCe0Z,2018,Invite to Workshop Track,False,Semantic Code Repair using Neuro-Symbolic Transformation Networks,"[""Jacob Devlin"", ""Jonathan  Uesato"", ""Rishabh Singh"", ""Pushmeet Kohli""]","[""semantic program repair"", ""neural program embeddings"", ""deep learning""]",A neural architecture for scoring and ranking program repair candidates to perform semantic program repair statically without access to unit tests.,,,,
r1iuQjxCZ,2018,Accept (Poster),False,On the importance of single directions for generalization,"[""Ari S. Morcos"", ""David G.T. Barrett"", ""Neil C. Rabinowitz"", ""Matthew Botvinick""]","[""generalization"", ""analysis"", ""deep learning"", ""selectivity""]","We find that deep networks which generalize poorly are more reliant on single directions than those that generalize well, and evaluate the impact of dropout and batch normalization, as well as class selectivity on single direction reliance.",,,,
r1j4zl5HsDj,2021,Reject,False,Learning to Actively Learn: A Robust Approach,"[""Jifan Zhang"", ""Kevin Jamieson""]","[""Active Learning"", ""Adversarial Learning"", ""Bandit Algorithms"", ""Meta-Learning""]",We propose a new training procedure that learns active learning policies achieving the best of both worlds: optimized to be as effective as possible while remaining robust.,,,,
r1kGbydxg,2017,Reject,False,Learning Locomotion Skills Using DeepRL: Does the Choice of Action Space Matter?,"[""Xue Bin Peng"", ""Michiel van de Panne""]","[""Reinforcement Learning"", ""Applications""]","We compare the impact of four different action parameterizations (torques, muscle-activations, target joint angles, and target joint-angle velocities) in terms of learning time, policy robustness, motion quality, and policy query rates.",,,,
r1kNDlbCb,2018,Reject,False,Learning to Encode Text as Human-Readable Summaries using Generative Adversarial Networks,"[""Yau-Shian Wang"", ""Hung-Yi Lee""]","[""unsupervised learning"", ""text summarization"", ""adversarial training""]",,,,,
r1kP7vlRb,2018,Reject,False,Toward learning better metrics for sequence generation training with policy gradient,"[""Joji Toyama"", ""Yusuke Iwasawa"", ""Kotaro Nakayama"", ""Yutaka Matsuo""]","[""sequence generation"", ""reinforcement learning"", ""unsupervised learning"", ""RNN""]","This paper aims to learn a better metric for unsupervised learning, such as text generation, and shows a significant improvement over SeqGAN.",,,,
r1kQkVFgl,2017,Reject,False,Learning Python Code Suggestion with a Sparse Pointer Network,"[""Avishkar Bhoopchand"", ""Tim Rockt\u00e4schel"", ""Earl Barr"", ""Sebastian Riedel""]",[],We augment a neural language model with a pointer network for code suggestion that is specialized to referring to predefined groups of identifiers,,,,
r1kj4ACp-,2018,Reject,False,Understanding Deep Learning Generalization by Maximum Entropy,"[""Guanhua Zheng"", ""Jitao Sang"", ""Changsheng Xu""]","[""generalization"", ""maximum entropy"", ""deep learning""]",We prove that DNN is a recursively approximated solution to the maximum entropy principle.,,,,
r1kjEuHpZ,2018,Reject,False,Learning Less-Overlapping Representations,"[""Hongbao Zhang"", ""Pengtao Xie"", ""Eric Xing""]","[""Less-overlapness"", ""regularization"", ""near-orthogonality"", ""sparsity""]","We propose a new type of regularization approach that encourages non-overlapness in representation learning, for the sake of improving interpretability and reducing overfitting.",,,,
r1l-5pEtDr,2020,Reject,False,AdaX: Adaptive Gradient Descent with Exponential Long Term Memory,"[""Wenjie Li"", ""Zhaoyang Zhang"", ""Xinjiang Wang"", ""Ping Luo""]","[""Optimization Algorithm"", ""Machine Learning"", ""Deep Learning"", ""Adam""]",A novel adaptive algorithm with extraordinary performance in deep learning tasks.,2004.09740,cs.LG,2020-04-21 03:46:58+00:00,2020-05-04 21:05:58+00:00
r1l-HTNtDB,2020,Reject,False,S2VG: Soft Stochastic Value Gradient method,"[""Xiaoyu Tan"", ""Chao Qu"", ""Junwu Xiong"", ""James Zhang""]","[""Model-based reinforcement learning"", ""soft stochastic value gradient""]",,,,,
r1l-VeSKwS,2020,Reject,True,SemanticAdv: Generating Adversarial Examples via Attribute-Conditional Image Editing,"[""Haonan Qiu"", ""Chaowei Xiao"", ""Lei Yang"", ""Xinchen Yan"", ""HongLak Lee"", ""Bo Li""]","[""adversarial examples"", ""semantic attack""]",A novel and effective semantic adversarial attack method.,1906.07927,cs.LG,2019-06-19 05:55:16+00:00,2020-07-02 19:47:47+00:00
r1l-e3Cqtm,2019,Reject,False,Deep Probabilistic Video Compression,"[""Jun Han"", ""Salvator Lombardo"", ""Christopher Schroers"", ""Stephan Mandt""]","[""variational inference"", ""video compression"", ""deep generative models""]",Deep Probabilistic Video Compression Via Sequential Variational Autoencoders,,,,
r1l0VCNKwB,2020,Reject,False,LOSSLESS SINGLE IMAGE SUPER RESOLUTION FROM LOW-QUALITY JPG IMAGES,"[""Yong Shi"", ""Biao Li"", ""Bo Wang"", ""Zhiquan Qi"", ""Jiabin Liu"", ""Fan Meng""]","[""Super Resolution"", ""Low-quality JPG"", ""Recovering details""]",We solve the specific SR issue of low-quality JPG images by functional sub-models.,,,,
r1l1myStwr,2020,Reject,False,Continuous Meta-Learning without Tasks,"[""James Harrison"", ""Apoorva Sharma"", ""Chelsea Finn"", ""Marco Pavone""]","[""Meta-learning"", ""Continual learning"", ""changepoint detection"", ""Bayesian learning""]",Bayesian changepoint detection enables meta-learning directly from time series data.,1912.08866,cs.LG,2019-12-18 20:10:40+00:00,2020-10-21 00:14:30+00:00
r1l3NiCqY7,2019,Reject,False,Lipschitz regularized Deep Neural Networks generalize,"[""Adam M. Oberman"", ""Jeff Calder""]","[""Deep Neural Networks"", ""Regularization"", ""Generalization"", ""Convergence"", ""Lipschitz"", ""Stability""]",We prove generalization of DNNs by adding a Lipschitz regularization term to the training loss. We resolve a question posed in Zhang et al. (2016).,,,,
r1l4eQW0Z,2018,Accept (Poster),False,Kernel Implicit Variational Inference,"[""Jiaxin Shi"", ""Shengyang Sun"", ""Jun Zhu""]","[""Variational inference"", ""Bayesian neural networks"", ""Implicit distribution""]",,,,,
r1l73iRqKm,2019,Accept (Poster),False,Wizard of Wikipedia: Knowledge-Powered Conversational Agents,"[""Emily Dinan"", ""Stephen Roller"", ""Kurt Shuster"", ""Angela Fan"", ""Michael Auli"", ""Jason Weston""]","[""dialogue"", ""knowledge"", ""language"", ""conversation""]",We build knowledgeable conversational agents by conditioning on Wikipedia + a new supervised task.,,,,
r1l7E1HFPH,2020,Reject,False,Multi-step Greedy Policies in Model-Free Deep Reinforcement Learning,"[""Yonathan Efroni"", ""Manan Tomar"", ""Mohammad Ghavamzadeh""]","[""Reinforcement Learning"", ""Multi-step greedy policies"", ""Model free Reinforcement Learning""]",Use model free algorithms like DQN/TRPO to solve short horizon problems (model free) iteratively in a Policy/Value Iteration fashion.,,,,
r1l9Nj09YQ,2019,Reject,False,Towards Language Agnostic Universal Representations,"[""Armen Aghajanyan"", ""Xia Song"", ""Saurabh Tiwary""]","[""universal representations"", ""language agnostic representations"", ""NLP"", ""GAN""]","By taking inspiration from linguistics, specifically the Universal Grammar hypothesis, we learn language agnostic universal representations which we can utilize to do zero-shot learning across languages.",,,,
r1lEd64YwH,2020,Reject,False,Learning Semantically Meaningful Representations Through Embodiment,"[""Viviane Clay"", ""Peter K\u00f6nig"", ""Kai-Uwe K\u00fchnberger"", ""Gordon Pipa""]","[""reinforcement learning"", ""deep learning"", ""embodied"", ""embodiment"", ""embodied cognition"", ""representation learning"", ""representations"", ""sparse coding""]",We show how a deep neural network can learn meaningful and robust representations of visual input when trained in an embodied framework.,,,,
r1lEjlHKPH,2020,Reject,False,Better Knowledge Retention through Metric Learning,"[""Ke Li*"", ""Shichong Peng*"", ""Kailas Vodrahalli*"", ""Jitendra Malik""]","[""metric learning"", ""continual learning"", ""catastrophic forgetting""]",We show metric learning can help reduce catastrophic forgetting,,,,
r1lFIiR9tQ,2019,Reject,False,Training generative latent models  by variational f-divergence minimization,"[""Mingtian Zhang"", ""Thomas Bird"", ""Raza Habib"", ""Tianlin Xu"", ""David Barber""]","[""variational inference"", ""generative model"", ""f divergence""]",Training generative models using an upper bound of the f divergence.,,,,
r1lF_CEYwS,2020,Accept (Poster),True,On the Need for Topology-Aware Generative Models for Manifold-Based Defenses,"[""Uyeong Jang"", ""Susmit Jha"", ""Somesh Jha""]","[""Manifold-based Defense"", ""Robust Learning"", ""Adversarial Attacks""]",,1909.03334,cs.LG,2019-09-07 20:36:17+00:00,2020-02-17 21:20:01+00:00
r1lGO0EKDH,2020,Accept (Talk),True,GraphZoom: A Multi-level Spectral Approach for Accurate and Scalable Graph Embedding,"[""Chenhui Deng"", ""Zhiqiang Zhao"", ""Yongyu Wang"", ""Zhiru Zhang"", ""Zhuo Feng""]","[""graph embedding"", ""unsupervised learning"", ""multi-level optimization"", ""spectral graph theory""]",A multi-level spectral approach to improving the quality and scalability of unsupervised graph embedding.,1910.02370,cs.LG,2019-10-06 04:43:46+00:00,2020-02-17 18:35:53+00:00
r1lHAAVtwr,2020,Reject,False,Deep Hierarchical-Hyperspherical Learning (DH^2L),"[""Youngsung Kim"", ""Jae-Joon Han""]",[],,,,,
r1lIKlSYvH,2020,Reject,False,The Usual Suspects? Reassessing Blame for VAE Posterior Collapse,"[""Bin Dai"", ""Ziyu Wang"", ""David Wipf""]","[""variational autoencoder"", ""posterior collapse""]",,1912.10702,cs.LG,2019-12-23 09:40:30+00:00,2019-12-23 09:40:30+00:00
r1lL4a4tDB,2020,Accept (Poster),False,Variational Recurrent Models for Solving Partially Observable Control Tasks,"[""Dongqi Han"", ""Kenji Doya"", ""Jun Tani""]","[""Reinforcement Learning"", ""Deep Learning"", ""Variational Inference"", ""Recurrent Neural Network"", ""Partially Observable"", ""Robotic Control"", ""Continuous Control""]",A deep RL algorithm for solving POMDPs by auto-encoding the underlying states using a variational recurrent model,1912.10703,cs.LG,2019-12-23 09:43:16+00:00,2019-12-24 05:05:00+00:00
r1lM_sA5Fm,2019,Reject,False,Assumption Questioning: Latent Copying and Reward Exploitation in Question Generation,"[""Tom Hosking"", ""Sebastian Riedel""]","[""question generation"", ""answer questioning"", ""pointer networks"", ""reinforcement learning""]",An investigation into latent copy mechanisms for question generation and correlations of external reward models with human evaluation.,,,,
r1lOgyrKDS,2020,Accept (Poster),False,Adaptive Correlated Monte Carlo for Contextual Categorical Sequence Generation,"[""Xinjie Fan"", ""Yizhe Zhang"", ""Zhendong Wang"", ""Mingyuan Zhou""]","[""binary softmax"", ""discrete variables"", ""policy gradient"", ""pseudo actions"", ""reinforcement learning"", ""variance reduction""]",,1912.13151,stat.ML,2019-12-31 03:01:55+00:00,2020-06-17 16:32:42+00:00
r1lPleBFvH,2020,Accept (Poster),False,Understanding the Limitations of Conditional Generative Models,"[""Ethan Fetaya"", ""Joern-Henrik Jacobsen"", ""Will Grathwohl"", ""Richard Zemel""]","[""Conditional Generative Models"", ""Generative Classifiers"", ""Robustness"", ""Adversarial Examples""]",,,,,
r1lQQeHYPr,2020,Reject,False,Embodied Multimodal Multitask Learning,"[""Devendra Singh Chaplot"", ""Lisa Lee"", ""Ruslan Salakhutdinov"", ""Devi Parikh"", ""Dhruv Batra""]","[""Visual Grounding"", ""Semantic Goal Navigation"", ""Embodied Question Answering""]",We propose a multitask model which facilitates knowledge transfer across multimodal tasks by disentangling the knowledge of words and visual concepts in the intermediate representations. ,,,,
r1lUOzWCW,2018,Accept (Poster),False,Demystifying MMD GANs,"[""Miko\u0142aj Bi\u0144kowski"", ""Danica J. Sutherland"", ""Michael Arbel"", ""Arthur Gretton""]","[""gans"", ""mmd"", ""ipms"", ""wgan"", ""gradient penalty"", ""unbiased gradients""]",Explain bias situation with MMD GANs; MMD GANs work with smaller critic networks than WGAN-GPs; new GAN evaluation metric.,1801.01401,stat.ML,2018-01-04 15:25:26+00:00,2021-01-14 05:36:59+00:00
r1lUdpVtwB,2020,Reject,False,Context Based Machine Translation With Recurrent Neural Network For English-Amharic Translation ,"[""Yeabsira Asefa Ashengo"", ""Rosa Tsegaye Aga"", ""Surafel Lemma Abebe""]","[""Context based machine translation"", ""machine translation"", ""Neural network machine translation"", ""English to Amharic machine translation""]",A context based machine translation system combined with a recurrent neural network machine translation system to translate English to Amharic.,,,,
r1lUl6NFDH,2020,Reject,True,Mirror Descent View For Neural Network Quantization,"[""Thalaiyasingam Ajanthan"", ""Kartik Gupta"", ""Philip H. S. Torr"", ""Richard Hartley"", ""Puneet K. Dokania""]","[""mirror descent"", ""network quantization"", ""numerical stability""]",We evaluate the mirror descent algorithm derived for various projections useful for neural network quantization and discuss the relationship of numerically stable updates of mirror descent to the widely used straight through estimator.,1910.08237,cs.LG,2019-10-18 03:19:21+00:00,2021-03-02 05:13:00+00:00
r1lWUoA9FQ,2019,Accept (Poster),False,Are adversarial examples inevitable?,"[""Ali Shafahi"", ""W. Ronny Huang"", ""Christoph Studer"", ""Soheil Feizi"", ""Tom Goldstein""]","[""adversarial examples"", ""neural networks"", ""security""]","This paper identifies classes of problems for which adversarial examples are inescapable, and derives fundamental bounds on the susceptibility of any classifier to adversarial examples. ",,,,
r1lYRjC9F7,2019,Accept (Oral),False,Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset,"[""Curtis Hawthorne"", ""Andriy Stasyuk"", ""Adam Roberts"", ""Ian Simon"", ""Cheng-Zhi Anna Huang"", ""Sander Dieleman"", ""Erich Elsen"", ""Jesse Engel"", ""Douglas Eck""]","[""music"", ""piano transcription"", ""transformer"", ""wavnet"", ""audio synthesis"", ""dataset"", ""midi""]","We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.",,,,
r1lZ7AEKvB,2020,Accept (Spotlight),False,The Logical Expressiveness of Graph Neural Networks,"[""Pablo Barcel\u00f3"", ""Egor V. Kostylev"", ""Mikael Monet"", ""Jorge P\u00e9rez"", ""Juan Reutter"", ""Juan Pablo Silva""]","[""Graph Neural Networks"", ""First Order Logic"", ""Expressiveness""]","We characterize the expressive power of GNNs in terms of classical logical languages, separating different GNNs and showing connections with standard notions in Knowledge Representation.",,,,
r1lZgyBYwS,2020,Accept (Poster),False,HiLLoC: lossless image compression with hierarchical latent variable models,"[""James Townsend"", ""Thomas Bird"", ""Julius Kunze"", ""David Barber""]","[""compression"", ""variational inference"", ""lossless compression"", ""deep latent variable models""]","We scale up lossless compression with latent variables, achieving state of the art on full-size ImageNet images.",1912.09953,eess.IV,2019-12-20 17:20:38+00:00,2019-12-20 17:20:38+00:00
r1la7krKPS,2020,Reject,False,Measuring Calibration in Deep Learning,"[""Jeremy Nixon"", ""Mike Dusenberry"", ""Ghassen Jerfel"", ""Linchuan Zhang"", ""Dustin Tran""]","[""Deep Learning"", ""Multiclass Classification"", ""Classification"", ""Uncertainty Estimation"", ""Calibration""]",,,,,
r1laEnA5Ym,2019,Accept (Poster),False,A Variational Inequality Perspective on Generative Adversarial Networks,"[""Gauthier Gidel"", ""Hugo Berard"", ""Ga\u00ebtan Vignoud"", ""Pascal Vincent"", ""Simon Lacoste-Julien""]","[""optimization"", ""variational inequality"", ""games"", ""saddle point"", ""extrapolation"", ""averaging"", ""extragradient"", ""generative modeling"", ""generative adversarial network""]",We cast GANs in the variational inequality framework and import techniques from this literature to optimize GANs better; we give algorithmic extensions and empirically test their performance for training GANs.,,,,
r1laNeBYPB,2020,Accept (Poster),False,Memory-Based Graph Networks,"[""Amir Hosein Khasahmadi"", ""Kaveh Hassani"", ""Parsa Moradi"", ""Leo Lee"", ""Quaid Morris""]","[""Graph Neural Networks"", ""Memory Networks"", ""Hierarchial Graph Representation Learning""]",We introduce an efficient memory layer to jointly learn representations and coarsen the input graphs.,,,,
r1lclxBYDS,2020,Reject,False,On the implicit minimization of alternative loss functions when training deep networks,"[""Alexandre Lemire Paquin"", ""Brahim Chaib-draa"", ""Philippe Gigu\u00e8re""]","[""implicit minimization"", ""optimization bias"", ""margin based loss functions"", ""flat minima""]",We study how the batch size and the learning affect the implicit minimization of different loss functions.,,,,
r1lczkHKPr,2020,Reject,False,Off-policy Multi-step Q-learning,"[""Gabriel Kalweit"", ""Maria Huegle"", ""Joschka Boedecker""]","[""Multi-step Learning"", ""Off-policy Learning"", ""Q-learning""]",The paper is about estimating the full return in off-policy Reinforcement Learning via a combination of short- and long-term predictions.,,,,
r1ledo0ctX,2019,Reject,False,Consistency-based anomaly detection with adaptive multiple-hypotheses predictions,"[""Duc Tam Nguyen"", ""Zhongyu Lou"", ""Michael Klar"", ""Thomas Brox""]","[""Anomaly detection"", ""outlier detection"", ""generative models"", ""VAE"", ""GAN""]",We propose an anomaly-detection approach that combines modeling the foreground class via multiple local densities with adversarial training.,,,,
r1lfF2NYvH,2020,Accept (Spotlight),False,InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization,"[""Fan-Yun Sun"", ""Jordan Hoffman"", ""Vikas Verma"", ""Jian Tang""]","[""graph-level representation learning"", ""mutual information maximization""]",,,,,
r1lfga4KvS,2020,Reject,False,Extreme Value k-means Clustering,"[""Sixiao Zheng"", ""Yanxi Hou"", ""Yanwei Fu"", ""Jianfeng Feng""]","[""unsupervised learning"", ""clustering"", ""k-means"", ""Extreme Value Theory""]",This paper introduces Extreme Value Theory into k-means to measure similarity and proposes a novel algorithm called Extreme Value k-means for clustering.,,,,
r1lfpfZAb,2018,Invite to Workshop Track,False,Learning to Write by Learning the Objective,"[""Ari Holtzman"", ""Jan Buys"", ""Maxwell Forbes"", ""Antoine Bosselut"", ""Yejin Choi""]","[""natural language generation""]",We build a stronger natural language generator by discriminatively training scoring functions that rank candidate generations with respect to various qualities of good writing.,,,,
r1lgm3C5t7,2019,Reject,False,Universal discriminative quantum neural networks,"[""Hongxiang Chen"", ""Leonard Wossnig"", ""Hartmut Neven"", ""Simone Severini"", ""Masoud Mohseni""]","[""quantum machine learning"", ""quantum data classification""]",,,,,
r1lh6C4FDr,2020,Reject,False,COMBINED FLEXIBLE ACTIVATION FUNCTIONS FOR DEEP NEURAL NETWORKS,"[""Renlong Jie"", ""Junbin Gao"", ""Andrey Vasnev"", ""Minh-Ngoc Tran""]","[""Flexible"", ""Activation Functions"", ""Deep Learning"", ""Regularization""]",,,,,
r1lkKn4KDS,2020,Reject,False,Learning Reusable Options for Multi-Task Reinforcement Learning,"[""Francisco M. Garcia"", ""Chris Nota"", ""Philip S. Thomas""]","[""Reinforcement Learning"", ""Temporal Abstraction"", ""Options"", ""Multi-Task RL""]",We discover options for multi-task RL by maximizing the probability of reproducing optimal trajectories while minimizing the number of decisions needed to do so.,2001.01577,cs.AI,2020-01-06 13:49:31+00:00,2020-01-06 13:49:31+00:00
r1ln504YvH,2020,Reject,False,Actor-Critic Approach for Temporal Predictive Clustering,"[""Changhee Lee"", ""Mihaela van der Schaar""]","[""Temporal Clustering"", ""Predictive Clustering"", ""Actor-Critic""]",,,,,
r1lnigSFDr,2020,Reject,False,Improving the Gating Mechanism of Recurrent Neural Networks,"[""Albert Gua"", ""Caglar Gulcehre"", ""Tom le Paine"", ""Razvan Pascanu"", ""Matt Hoffman""]","[""recurrent neural networks"", ""LSTM"", ""GRUs"", ""gating mechanisms"", ""deep learning"", ""reinforcement learning""]",Improving the gating mechanisms of recurrent neural networks by addressing the initialization of the biases and the saturation problem of sigmoid.,,,,
r1lnxTEYPS,2020,Reject,True,Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality,"[""Eric Nalisnick"", ""Akihiro Matsukawa"", ""Yee Whye Teh"", ""Balaji Lakshminarayanan""]","[""Deep generative models"", ""out-of-distribution detection"", ""safety""]",We propose detecting out-of-distribution inputs to deep generative models via a goodness-of-fit test based on the model entropy.,1906.02994,stat.ML,2019-06-07 10:03:16+00:00,2019-10-16 13:43:36+00:00
r1lohoCqY7,2019,Accept (Poster),False,Learning-Based Frequency Estimation Algorithms,"[""Chen-Yu Hsu"", ""Piotr Indyk"", ""Dina Katabi"", ""Ali Vakilian""]","[""streaming algorithms"", ""heavy-hitters"", ""Count-Min"", ""Count-Sketch""]","Data stream algorithms can be improved using deep learning, while retaining performance guarantees.",,,,
r1lpx3A9K7,2019,Reject,False,Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference,"[""Ruying Bao"", ""Sihang Liang"", ""Qingcan Wang""]",[],,,,,
r1lq1hRqYQ,2019,Accept (Poster),False,From Language to Goals: Inverse Reinforcement Learning for Vision-Based Instruction Following,"[""Justin Fu"", ""Anoop Korattikara"", ""Sergey Levine"", ""Sergio Guadarrama""]","[""inverse reinforcement learning"", ""language grounding"", ""instruction following"", ""language-based learning""]",We ground language commands in a high-dimensional visual environment by learning language-conditioned rewards using inverse reinforcement learning.,,,,
r1lrAiA5Ym,2019,Accept (Poster),False,Backpropamine: training self-modifying neural networks with differentiable neuromodulated plasticity,"[""Thomas Miconi"", ""Aditya Rawal"", ""Jeff Clune"", ""Kenneth O. Stanley""]","[""meta-learning"", ""reinforcement learning"", ""plasticity"", ""neuromodulation"", ""Hebbian learning"", ""recurrent neural networks""]","Neural networks can be trained to modify their own connectivity, improving their online learning performance on challenging tasks.",,,,
r1ltgp4FwS,2020,Reject,False,Learning Temporal Coherence via Self-Supervision for GAN-based Video Generation,"[""Mengyu Chu"", ""You Xie"", ""Jonas Mayer"", ""Laura Leal-Taix\u00e9"", ""Nils Th\u00fcrey""]","[""adversarial training"", ""generative models"", ""unpaired video translation"", ""video super-resolution"", ""temporal coherence"", ""self-supervision"", ""cycle-consistency""]",We propose temporal self-supervisions for learning stable temporal functions with GANs.,,,,
r1ltnp4KwS,2020,Reject,False,Training Interpretable Convolutional Neural Networks towards Class-specific Filters,"[""Haoyu Liang"", ""Zhihao Ouyang"", ""Hang Su"", ""Yuyuan Zeng"", ""Zihao He"", ""Shu-tao Xia"", ""Jun Zhu"", ""Bo Zhang""]","[""class-specific filters"", ""interpretability"", ""disentangled representation"", ""filter ambiguity"", ""gate""]",,,,,
r1luCsCqFm,2019,Reject,False,Learn From Neighbour: A Curriculum That Train Low Weighted Samples By Imitating,"[""Benyuan Sun"", ""Yizhou Wang""]","[""Curriculum Learning"", ""Internal Covariate Shift""]",,,,,
r1lyTjAqYX,2019,Accept (Poster),False,Recurrent Experience Replay in Distributed Reinforcement Learning,"[""Steven Kapturowski"", ""Georg Ostrovski"", ""John Quan"", ""Remi Munos"", ""Will Dabney""]","[""RNN"", ""LSTM"", ""experience replay"", ""distributed training"", ""reinforcement learning""]",Investigation on combining recurrent neural networks and experience replay leading to state-of-the-art agent on both Atari-57 and DMLab-30 using single set of hyper-parameters.,,,,
r1nSxrKPH,2020,Reject,False,Learning Functionally Decomposed Hierarchies for Continuous Navigation Tasks,"[""Lukas Jendele"", ""Sammy Christen"", ""Emre Aksan"", ""Otmar Hilliges""]","[""Hierarchical reinforcement learning"", ""planning"", ""navigation""]",Learning Functionally Decomposed Hierarchies for Continuous Navigation Tasks,,,,
r1nTpv9eg,2017,Accept (Poster),False,Learning to Perform Physics Experiments via Deep Reinforcement Learning,"[""Misha Denil"", ""Pulkit Agrawal"", ""Tejas D Kulkarni"", ""Tom Erez"", ""Peter Battaglia"", ""Nando de Freitas""]","[""Deep learning"", ""Reinforcement Learning""]",We train agents to conduct experiments in interactive simulated physical environments.,,,,
r1nmx5l0W,2018,Reject,False,SIC-GAN: A Self-Improving Collaborative GAN for Decoding Sketch RNNs,"[""Chi-Chun Chuang"", ""Zheng-Xin Weng"", ""Shan-Hung Wu""]","[""RNNs"", ""GANs"", ""Variational RNNs"", ""Sketch RNNs""]",,,,,
r1nzLmWAb,2018,Reject,False,Video Action Segmentation with Hybrid Temporal Networks,"[""Li Ding"", ""Chenliang Xu""]","[""action segmentation"", ""video labeling"", ""temporal networks""]",We propose a new hybrid temporal network that achieves state-of-the-art performance on video action segmentation on three public datasets.,,,,
r1osyr_xg,2017,Reject,False,Fuzzy paraphrases in learning word representations with a lexicon,"[""Yuanzhi Ke"", ""Masafumi Hagiwara""]","[""Natural language processing"", ""Unsupervised Learning""]",We propose a novel idea to address polysemy problem by annotating paraphrases with a degree of reliability like a member of a fuzzy set.,,,,
r1pW0WZAW,2018,Invite to Workshop Track,False,Analyzing and Exploiting NARX Recurrent Neural Networks for Long-Term Dependencies,"[""Robert DiPietro"", ""Christian Rupprecht"", ""Nassir Navab"", ""Gregory D. Hager""]","[""recurrent neural networks"", ""long-term dependencies"", ""long short-term memory"", ""LSTM""]","We introduce MIST RNNs, which a) exhibit superior vanishing-gradient properties in comparison to LSTM; b) improve performance substantially over LSTM and Clockwork RNNs on tasks requiring very long-term dependencies; and c) are much more efficient than previously-proposed NARX RNNs, with even fewer parameters and operations than LSTM.",,,,
r1q7n9gAb,2018,Accept (Poster),False,The Implicit Bias of Gradient Descent on Separable Data,"[""Daniel Soudry"", ""Elad Hoffer"", ""Mor Shpigel Nacson"", ""Nathan Srebro""]","[""gradient descent"", ""implicit regularization"", ""generalization"", ""margin"", ""logistic regression"", ""loss functions"", ""optimization"", ""exponential tail"", ""cross-entropy""]",The normalized solution of gradient descent on logistic regression (or a similarly decaying loss) slowly converges to the L2 max margin solution on separable data.,,,,
r1rhWnZkg,2017,Accept (Poster),False,Hadamard Product for Low-rank Bilinear Pooling,"[""Jin-Hwa Kim"", ""Kyoung-Woon On"", ""Woosang Lim"", ""Jeonghee Kim"", ""Jung-Woo Ha"", ""Byoung-Tak Zhang""]","[""Deep learning"", ""Supervised Learning"", ""Multi-modal learning""]",A new state-of-the-art on the VQA (real image) dataset using an attention mechanism of low-rank bilinear pooling,,,,
r1rz6U5lg,2017,Accept (Poster),False,Learning to superoptimize programs,"[""Rudy Bunel"", ""Alban Desmaison"", ""M. Pawan Kumar"", ""Philip H.S. Torr"", ""Pushmeet Kohli""]",[],,,,,
r1saNM-RW,2018,Reject,False,Small Coresets to Represent Large Training Data for Support Vector Machines,"[""Cenk Baykal"", ""Murad Tukan"", ""Dan Feldman"", ""Daniela Rus""]","[""coresets"", ""data compression""]",We present an algorithm for speeding up SVM training on massive data sets by constructing compact representations that provide efficient and provably approximate inference.,,,,
r1tHvHKge,2017,Reject,False,Combating Deep Reinforcement Learning's Sisyphean Curse with Intrinsic Fear,"[""Zachary C. Lipton"", ""Jianfeng Gao"", ""Lihong Li"", ""Jianshu Chen"", ""Li Deng""]","[""Deep learning"", ""Reinforcement Learning"", ""Applications""]","Owing to function approximation, DRL agents eventually forget about dangerous transitions once they learn to avoid them, putting them at risk of perpetually repeating mistakes. We propose techniques to avert catastrophic outcomes.",,,,
r1tJKuyRZ,2018,Reject,False,The Set Autoencoder: Unsupervised Representation Learning for Sets,"[""Malte Probst""]","[""set"", ""unsupervised learning"", ""representation learning""]","We propose the set autoencoder, a model for unsupervised representation learning for sets of elements.",,,,
r1te3Fqel,2017,Reject,False,End-to-End Answer Chunk Extraction and Ranking for Reading Comprehension,"[""Yang Yu"", ""Wei Zhang"", ""Bowen Zhou"", ""Kazi Hasan"", ""Mo Yu"", ""Bing Xiang""]","[""Natural language processing"", ""Deep learning"", ""Supervised Learning""]",,,,,
r1uOhfb0W,2018,Reject,False,Learning Sparse Structured Ensembles with SG-MCMC and Network Pruning,"[""Yichi Zhang"", ""Zhijian Ou""]","[""ensemble learning"", ""SG-MCMC"", ""group sparse prior"", ""network pruning""]","Propose a novel method by integrating SG-MCMC sampling, group sparse prior and network pruning to learn Sparse Structured Ensemble (SSE) with improved performance and significantly reduced cost than traditional methods. ",,,,
r1vccClCb,2018,Reject,False,Neighbor-encoder,"[""Chin-Chia Michael Yeh"", ""Yan Zhu"", ""Evangelos E. Papalexakis"", ""Abdullah Mueen"", ""Eamonn Keogh""]","[""unsupervised learning"", ""representation learning"", ""autoencoder""]",,,,,
r1vuQG-CW,2018,Accept (Poster),False,HexaConv,"[""Emiel Hoogeboom"", ""Jorn W.T. Peters"", ""Taco S. Cohen"", ""Max Welling""]","[""hexagonal"", ""group"", ""symmetry"", ""representation learning"", ""rotation"", ""equivariance"", ""invariance""]","We introduce G-HexaConv, a group equivariant convolutional neural network on hexagonal lattices.",,,,
r1w7Jdqxl,2017,Reject,False,Collaborative Deep Embedding via Dual Networks,"[""Yilei Xiong"", ""Dahua Lin"", ""Haoying Niu"", ""JIefeng Cheng"", ""Zhenguo Li""]",[],,,,,
r1wEFyWCW,2018,Accept (Poster),False,Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions,"[""Scott Reed"", ""Yutian Chen"", ""Thomas Paine"", ""A\u00e4ron van den Oord"", ""S. M. Ali Eslami"", ""Danilo Rezende"", ""Oriol Vinyals"", ""Nando de Freitas""]","[""few-shot learning"", ""density models"", ""meta learning""]",Few-shot learning PixelCNN,,,,
r1x0lxrFPS,2020,Accept (Poster),False,BinaryDuo: Reducing Gradient Mismatch in Binary Activation Network by Coupling Binary Activations,"[""Hyungjun Kim"", ""Kyungsu Kim"", ""Jinseok Kim"", ""Jae-Joon Kim""]",[],,2002.06517,cs.LG,2020-02-16 06:18:53+00:00,2020-02-16 06:18:53+00:00
r1x3unVKPS,2020,Reject,False,Support-guided Adversarial Imitation Learning,"[""Ruohan Wang"", ""Carlo Ciliberto"", ""Pierluigi Amadori"", ""Yiannis Demiris""]","[""Adversarial Imitation Learning"", ""Reinforcement Learning"", ""Learning from Demonstrations""]","We unify support estimation with the family of Adversarial Imitation Learning algorithms into Support-guided Adversarial Imitation Learning, a more robust and stable imitation learning framework.",2002.08803,cs.LG,2020-02-20 15:34:30+00:00,2020-02-20 15:34:30+00:00
r1x4BnCqKX,2019,Accept (Poster),False,A Generative Model For Electron Paths,"[""John Bradshaw"", ""Matt J. Kusner"", ""Brooks Paige"", ""Marwin H. S. Segler"", ""Jos\u00e9 Miguel Hern\u00e1ndez-Lobato""]","[""Molecules"", ""Reaction Prediction"", ""Graph Neural Networks"", ""Deep Generative Models""]",A generative model for reaction prediction that learns the mechanistic electron steps of a reaction directly from raw reaction data.,,,,
r1x63grFvH,2020,Reject,False,Limitations for Learning from Point Clouds,"[""Christian Bueno"", ""Alan G. Hylton""]","[""universal approximation"", ""point clouds"", ""deep learning"", ""hausdorff metric"", ""wasserstein metric""]",We prove new universal approximation theorems for PointNets and DeepSets and demonstrate new limitations.,,,,
r1xCMyBtPS,2020,Accept (Poster),False,Multilingual Alignment of Contextual Word Representations,"[""Steven Cao"", ""Nikita Kitaev"", ""Dan Klein""]","[""multilingual"", ""natural language processing"", ""embedding alignment"", ""BERT"", ""word embeddings"", ""transfer""]",We propose procedures for evaluating and strengthening contextual embedding alignment and show that they both improve multilingual BERT's zero-shot XNLI transfer and provide useful insights into the model.,2002.03518,cs.CL,2020-02-10 03:27:21+00:00,2020-02-12 23:28:06+00:00
r1xF7lSYDS,2020,Reject,False,Transferable Recognition-Aware Image Processing,"[""Zhuang Liu"", ""Tinghui Zhou"", ""Zhiqiang Shen"", ""Bingyi Kang"", ""Trevor Darrell""]","[""Image Recognition"", ""Image Processing""]","We propose simple and effective approaches to enhance the machine interpretability of image processing outputs; the improvement on recognition accuracy is transferable among different recognition architectures, object categories, and tasks.",,,,
r1xFE3Rqt7,2019,Reject,False,Adaptive Mixture of Low-Rank Factorizations for Compact Neural Modeling,"[""Ting Chen"", ""Ji Lin"", ""Tian Lin"", ""Song Han"", ""Chong Wang"", ""Denny Zhou""]","[""Low-Rank Factorization"", ""Compact Neural Nets"", ""Efficient Modeling"", ""Mixture models""]",We propose a simple modification to low-rank factorization that improves performances (in both image and language tasks) while still being compact.,,,,
r1xGP6VYwH,2020,Accept (Poster),False,Optimistic Exploration even with a Pessimistic Initialisation,"[""Tabish Rashid"", ""Bei Peng"", ""Wendelin Boehmer"", ""Shimon Whiteson""]","[""Reinforcement Learning"", ""Exploration"", ""Optimistic Initialisation""]","We augment the Q-value estimates with a count-based bonus that ensures optimism during action selection and bootstrapping, even if the Q-value estimates are pessimistic.",,,,
r1xGnA4Kvr,2020,Accept (Poster),False,Biologically inspired sleep algorithm for increased generalization and adversarial robustness in deep neural networks,"[""Timothy Tadros"", ""Giri Krishnan"", ""Ramyaa Ramyaa"", ""Maxim Bazhenov""]","[""Adversarial Robustness"", ""Generalization"", ""Neural Computing"", ""Deep Learning""]",We describe a biologically inspired sleep algorithm for increasing an artificial neural network's ability to extract the gist of a training set and exhibit increased robustness to adversarial attacks and general distortions.,,,,
r1xH5xHYwH,2020,Reject,False,Effects of Linguistic Labels on Learned Visual Representations in Convolutional Neural Networks: Labels matter!,"[""Seoyoung Ahn"", ""Gregory Zelinsky"", ""Gary Lupyan""]","[""category learning"", ""visual representation"", ""linguistic labels"", ""human behavior prediction""]",We investigated the changes in visual representations learnt by CNNs when using different linguistic labels,,,,
r1xHxgrKwr,2020,Reject,False,Anomaly Detection Based on Unsupervised Disentangled Representation Learning in Combination with Manifold Learning,"[""Xiaoyan Li"", ""Iluju Kiringa"", ""Tet Yeap"", ""Xiaodan Zhu"", ""Yifeng Li""]","[""anomaly detection"", ""disentangled representation learning"", ""manifold learning""]",We developed anomaly detection framework based on beta-VAE and t-SNE,,,,
r1xI-gHFDH,2020,Reject,False,How can we generalise learning distributed representations of graphs?,"[""Paul M Scherer"", ""Pietro Lio""]","[""graphs"", ""distributed representations"", ""similarity learning""]",We propose a general framework for building models that can learn distributed representations of discrete structures and test this on graphs.,,,,
r1xMH1BtvB,2020,Accept (Poster),False,ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators,"[""Kevin Clark"", ""Minh-Thang Luong"", ""Quoc V. Le"", ""Christopher D. Manning""]","[""Natural Language Processing"", ""Representation Learning""]",A text encoder trained to distinguish real input tokens from plausible fakes efficiently learns effective language representations.,2003.10555,cs.CL,2020-03-23 21:17:42+00:00,2020-03-23 21:17:42+00:00
r1xMnCNYvB,2020,Reject,False,"JAX MD: End-to-End Differentiable, Hardware Accelerated, Molecular Dynamics in Pure Python","[""Samuel S. Schoenholz"", ""Ekin D. Cubuk""]","[""Automatic Differentiation"", ""Software Library"", ""Physics Simulation"", ""Differentiable Physics""]","Software package to do fast, end-to-end differentiable, physics simulations with machine learning as a first class citizen.",,,,
r1xN5oA5tm,2019,Reject,True,Phrase-Based Attentions,"[""Phi Xuan Nguyen"", ""Shafiq Joty""]","[""neural machine translation"", ""natural language processing"", ""attention"", ""transformer"", ""seq2seq"", ""phrase-based"", ""phrase"", ""n-gram""]","Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.",1810.03444,cs.CL,2018-09-30 16:28:40+00:00,2018-09-30 16:28:40+00:00
r1xNJ0NYDH,2020,Reject,True,The Effect of Neural Net Architecture on Gradient Confusion & Training Performance,"[""Karthik A. Sankararaman"", ""Soham De"", ""Zheng Xu"", ""W. Ronny Huang"", ""Tom Goldstein""]","[""neural network architecture"", ""speed of training"", ""layer width"", ""network depth""]","We formally show that increased layer width helps training, while increased network depth makes training harder.",1904.06963,cs.LG,2019-04-15 11:02:22+00:00,2020-07-06 21:36:19+00:00
r1xPh2VtPB,2020,Accept (Poster),False,SVQN: Sequential Variational Soft Q-Learning Networks,"[""Shiyu Huang"", ""Hang Su"", ""Jun Zhu"", ""Ting Chen""]","[""reinforcement learning"", ""POMDP"", ""variational inference"", ""generative model""]",SVQNs  formalizes the inference of hidden states and maximum entropy reinforcement learning under a unified graphical model and optimizes the two modules jointly.,,,,
r1xQNlBYPS,2020,Reject,False,Multichannel Generative Language Models,"[""Harris Chan"", ""Jamie Kiros"", ""William Chan""]","[""text generation"", ""generative language models"", ""natural language processing""]","we propose Multichannel Generative Language Models (MGLM), which models the joint distribution over multiple channels, and all its decompositions using a single neural network",,,,
r1xQQhAqKX,2019,Accept (Poster),False,Modeling Uncertainty with Hedged Instance Embeddings,"[""Seong Joon Oh"", ""Kevin P. Murphy"", ""Jiyan Pan"", ""Joseph Roth"", ""Florian Schroff"", ""Andrew C. Gallagher""]","[""uncertainty"", ""instance embedding"", ""metric learning"", ""probabilistic embedding""]",The paper proposes using probability distributions instead of points for instance embeddings tasks such as recognition and verification.,,,,
r1xRW3A9YX,2019,Reject,False,Riemannian TransE: Multi-relational Graph Embedding in Non-Euclidean Space,"[""Atsushi Suzuki"", ""Yosuke Enokida"", ""Kenji Yamanishi""]","[""Riemannian TransE"", ""graph embedding"", ""multi-relational graph"", ""Riemannian manifold"", ""TransE"", ""hyperbolic space"", ""sphere"", ""knowledge base""]",Multi-relational graph embedding with Riemannian manifolds and TransE-like loss function. ,,,,
r1xUYDYgg,2017,Invite to Workshop Track,False,Development of JavaScript-based deep learning platform and application to distributed training,"[""Masatoshi Hidaka"", ""Ken Miura"", ""Tatsuya Harada""]","[""Deep learning""]",Development of JavaScript-based matrix library and deep learning library which uses GPGPU. VGGNet is trained distributedly using web browsers.,,,,
r1xX42R5Fm,2019,Accept (Poster),False,Beyond Greedy Ranking: Slate Optimization via List-CVAE,"[""Ray Jiang"", ""Sven Gowal"", ""Yuqiu Qian"", ""Timothy Mann"", ""Danilo J. Rezende""]","[""CVAE"", ""VAE"", ""recommendation system"", ""slate optimization"", ""whole page optimization""]",We used a CVAE type model structure to learn to directly generate slates/whole pages for recommendation systems.,,,,
r1xYr3C5t7,2019,Reject,False,Neural Message Passing for Multi-Label Classification,"[""Jack Lanchantin"", ""Arshdeep Sekhon"", ""Yanjun Qi""]","[""Multi-label Classification"", ""Graph Neural Networks"", ""Attention"", ""Graph Attention""]",We propose Message Passing Encoder-Decode networks for a fast and accurate way of modelling label dependencies for multi-label classification.,,,,
r1xZAkrFPr,2020,Reject,False,Deep Ensembles: A Loss Landscape Perspective,"[""Stanislav Fort"", ""Clara Huiyi Hu"", ""Balaji Lakshminarayanan""]","[""loss landscape"", ""deep ensemble"", ""subspace"", ""tunnel"", ""low loss"", ""connector"", ""weight averaging"", ""dropout"", ""gaussian"", ""connectivity"", ""diversity"", ""function space""]","We study deep ensembles through the lens of loss landscape and the space of predictions, demonstrating that the decorrelation power of random initializations is unmatched by subspace sampling that only explores a single mode.",,,,
r1x_DaVKwH,2020,Reject,True,Is Deep Reinforcement Learning Really Superhuman on Atari? Leveling the playing field,"[""Marin Toromanoff"", ""Emilie Wirbel"", ""Fabien Moutarde""]","[""Reinforcement Learning"", ""Deep Learning"", ""Atari benchmark"", ""Reproducibility""]",Introducing a Standardized Atari BEnchmark for general Reinforcement learning algorithms (SABER) and highlight the remaining gap between RL agents and best human players.,1908.04683,cs.AI,2019-08-13 14:55:09+00:00,2019-11-08 10:37:59+00:00
r1xa9TVFvH,2020,Reject,False,NeuralUCB: Contextual Bandits with Neural Network-Based Exploration,"[""Dongruo Zhou"", ""Lihong Li"", ""Quanquan Gu""]","[""contextual bandits"", ""neural network"", ""upper confidence bound""]",,,,,
r1xapAEKwS,2020,Reject,False,SDGM: Sparse Bayesian Classifier Based on a Discriminative Gaussian Mixture Model,"[""Hideaki Hayashi"", ""Seiichi Uchida""]","[""classification"", ""sparse Bayesian learning"", ""Gaussian mixture model""]","A sparse classifier based on a discriminative Gaussian mixture model, which can also be embedded into a neural network.",1911.06028,cs.LG,2019-11-14 10:42:41+00:00,2021-05-07 08:23:12+00:00
r1xbj2VKvr,2020,Reject,False,Dual Graph Representation Learning,"[""Huiling Zhu"", ""Xin Luo"", ""Hankz Hankui Zhuo""]",[],,2002.11501,cs.LG,2020-02-25 04:50:17+00:00,2020-02-25 04:50:17+00:00
r1xdH3CcKX,2019,Accept (Poster),False,Stochastic Prediction of Multi-Agent Interactions from Partial Observations,"[""Chen Sun"", ""Per Karlsson"", ""Jiajun Wu"", ""Joshua B Tenenbaum"", ""Kevin Murphy""]","[""Dynamics modeling"", ""partial observations"", ""multi-agent interactions"", ""predictive models""]",We present a method which learns to integrate temporal information and ambiguous visual information in the context of interacting agents.,,,,
r1xfECEKvr,2020,Reject,True,Analyzing the Role of Model Uncertainty for Electronic Health Records,"[""Michael W. Dusenberry"", ""Dustin Tran"", ""Edward Choi"", ""Jonas Kemp"", ""Jeremy Nixon"", ""Ghassen Jerfel"", ""Katherine Heller"", ""Andrew M. Dai""]","[""medicine"", ""uncertainty"", ""neural networks"", ""Bayesian"", ""electronic health records""]","We investigate the role of model uncertainty methods for domains like medicine, and compare a multitude of Bayesian RNN variants with deterministic RNN ensembles.",1906.03842,cs.LG,2019-06-10 08:46:24+00:00,2020-03-25 22:38:20+00:00
r1xjgxBFPB,2020,Reject,False,Continual Deep Learning by Functional Regularisation of Memorable Past,"[""Pingbo Pan"", ""Alexander Immer"", ""Siddharth Swaroop"", ""Runa Eschenhagen"", ""Richard E Turner"", ""Mohammad Emtiyaz Khan""]","[""Continual learning"", ""deep learning"", ""functional regularisation""]",This paper introduces a scalable functional-regularisation approach for continual learning that uses a GP formulation of neural networks to identify and regularise over a memorable past.,,,,
r1xkIjA9tX,2019,Reject,False,q-Neurons: Neuron Activations based on Stochastic Jackson's Derivative Operators,"[""Frank Nielsen"", ""Ke Sun""]","[""q-calculus"", ""neural activation function""]",q-calculus helps build simple and scalable neural activation functions,,,,
r1xlvi0qYm,2019,Accept (Oral),False,Learning to Remember More with Less Memorization,"[""Hung Le"", ""Truyen Tran"", ""Svetha Venkatesh""]","[""memory-augmented neural networks"", ""writing optimization""]",,,,,
r1xo9grKPr,2020,Reject,False,Flexible and Efficient Long-Range Planning Through Curious Exploration,"[""Aidan Curtis"", ""Minjian Xin"", ""Kevin Feigelis"", ""Dan Yamins""]","[""Curiosity"", ""Planning"", ""Reinforcement Learning"", ""Robotics"", ""Exploration""]",We designed a flexible and efficient curiosity-based planning algorithm and tested it on a wide range of physically realistic 3D tasks.,,,,
r1xpF0VYDS,2020,Reject,True,Quantum algorithm for finding the negative curvature direction,"[""Kaining Zhang"", ""Min-Hsiu Hsieh"", ""Liu Liu"", ""Dacheng Tao""]","[""quantum algorithm"", ""negative curvature""]",We present an efficient quantum algorithm aiming to find the negative curvature direction.,1909.07622,quant-ph,2019-09-17 07:23:58+00:00,2019-09-17 07:23:58+00:00
r1xrb3CqtQ,2019,Reject,False,Latent Domain Transfer: Crossing modalities with Bridging Autoencoders,"[""Yingtao Tian"", ""Jesse Engel""]","[""Generative Model"", ""Latent Space"", ""Domain Transfer""]",Conditional VAE on top of latent spaces of pre-trained generative models that enables  transfer between drastically different domains while preserving locality and semantic alignment.,,,,
r1xurn0cKQ,2019,Reject,False,Correction Networks: Meta-Learning for Zero-Shot Learning,"[""R. Lily Hu"", ""Caiming Xiong"", ""Richard Socher""]","[""zero-shot learning"", ""image classification"", ""fine-grained classification"", ""meta-learning""]",A model learns to perform zero-shot classification using a meta-learner that is trained to update predictions based on the learner's training data.,,,,
r1xwA34KDB,2020,Reject,True,Learning Invariants through Soft Unification,"[""Nuri Cingillioglu"", ""Alessandra Russo""]","[""representation learning"", ""neural networks"", ""unification""]",End-to-end learning of invariant representations with variables across examples such as if someone went somewhere then they are there.,1909.07328,cs.LG,2019-09-16 16:48:52+00:00,2020-10-24 10:24:14+00:00
r1xwKoR9Y7,2019,Accept (Poster),False,GamePad: A Learning Environment for Theorem Proving,"[""Daniel Huang"", ""Prafulla Dhariwal"", ""Dawn Song"", ""Ilya Sutskever""]","[""Theorem proving"", ""ITP"", ""systems"", ""neural embeddings""]",We introduce a system called GamePad to explore the application of machine learning methods to theorem proving in the Coq proof assistant.,,,,
r1xwS3RqKQ,2019,Reject,False,Differential Equation Networks,"[""MohamadAli Torkamani"", ""Phillip Wallis""]","[""deep learning"", ""activation function"", ""differential equations""]",We introduce a method to learn the nonlinear activation function for each neuron in the network.,,,,
r1xwqjRcY7,2019,Reject,False,Probabilistic Semantic Embedding,"[""Yue Jiao"", ""Jonathon Hare"", ""Adam Pr\u00fcgel-Bennett""]",[],,,,,
r1xxKJBKvr,2020,Reject,False,PassNet: Learning pass probability surfaces from single-location labels. An architecture for visually-interpretable soccer analytics,"[""Javier Fern\u00e1ndez"", ""Luke Bornn""]","[""fully convolutional neural networks"", ""convolutional neural networks"", ""sports analytics"", ""interpretable machine learning"", ""deep learning""]",A deep neural network architecture that is able to produce full pass probability surfaces from low level spatio-temporal soccer data.,,,,
r1xywsC9tQ,2019,Reject,False,Mapping the hyponymy relation of wordnet onto vector Spaces,"[""Jean-Philippe Bernardy"", ""Aleksandre Maskharashvili""]","[""fasttext"", ""hyponymy"", ""wordnet""]",We investigate mapping the hyponymy relation of wordnet to feature vectors,,,,
r1xyx3R9tQ,2019,Reject,False,"Prototypical Examples in Deep Learning: Metrics, Characteristics, and Utility","[""Nicholas Carlini"", ""Ulfar Erlingsson"", ""Nicolas Papernot""]","[""prototypes"", ""curriculum learning"", ""interpretability"", ""differential privacy"", ""adversarial robustness""]","We can identify prototypical and outlier examples in machine learning that are quantifiably very different, and make use of them to improve many aspects of neural networks.",,,,
r1y1aawlg,2017,Reject,False,Iterative Refinement for Machine Translation,"[""Roman Novak"", ""Michael Auli"", ""David Grangier""]","[""Natural language processing""]","We propose of novel decoding strategy for MT, after producing a full sentence the model can revisit its choice and substitute words; multiple words can iteratively be edited.",,,,
r1yjkAtxe,2017,Reject,False,Spatio-Temporal Abstractions in Reinforcement Learning Through Neural Encoding,"[""Nir Baram"", ""Tom Zahavy"", ""Shie Mannor""]","[""Reinforcement Learning"", ""Deep learning""]",A method for understanding and improving deep agents by creating spatio-temporal abstractions,,,,
r1zOg309tX,2019,Reject,False,Understanding the Effectiveness of Lipschitz-Continuity in Generative Adversarial Nets,"[""Zhiming Zhou"", ""Yuxuan Song"", ""Lantao Yu"", ""Hongwei Wang"", ""Weinan Zhang"", ""Zhihua Zhang"", ""Yong Yu""]","[""GANs"", ""Lipschitz-continuity"", ""convergence""]","We disclose the fundamental cause of failure in training of GANs, and demonstrate that Lipschitz-continuity is a general solution to this issue.",,,,
r1zmVhCqKm,2019,Reject,False,Text Infilling,"[""Wanrong Zhu"", ""Zhiting Hu"", ""Eric P. Xing""]","[""text generation"", ""text infilling"", ""self attention"", ""sequence to sequence""]",We study a general task of text infilling that fills missing portions of given text; an self-attention model is developed.,,,,
r1znKiAcY7,2019,Reject,False,Few-shot Classification on Graphs with Structural Regularized GCNs,"[""Shengzhong Zhang"", ""Ziang Zhou"", ""Zengfeng Huang"", ""Zhongyu Wei""]","[""Graph Convolutional Networks"", ""Few-shot"", ""Classification""]",,,,,
r1ztwiCcYQ,2019,Reject,False,"VARIATIONAL SGD: DROPOUT , GENERALIZATION AND CRITICAL POINT AT THE END OF CONVEXITY","[""Michael Tetelman""]","[""Bayesian inference"", ""neural networks"", ""generalization"", ""critical point solution""]",Proposed method for finding the most generalizable solution that is stable w.r.t. perturbations of trainig data.,,,,
r28GdiQF7vM,2021,Accept (Poster),False,Sharper Generalization Bounds for Learning with Gradient-dominated Objective Functions,"[""Yunwen Lei"", ""Yiming Ying""]","[""generalization bounds"", ""non-convex learning""]",We develop sharper generalization bounds for learning with gradient-dominated objective functions.,,,,
r4PibJdCyn,2022,Reject,False,TotalRecall: A Bidirectional Candidates Generation Framework for Large Scale Recommender \& Advertising Systems,"['Qifang Zhao', 'Yu Jiang', 'Yuqing Liu', 'Meng Du', 'Qinghui Sun', 'Chao Xu', 'huan xu', 'Zhongyao Wang']","[""Recommender System"", ""Advertising System"", ""Collaborative filtering"", ""Matrix Factorization"", ""Contrastive Learning"", ""Candidates Generation"", ""Embeddings""]",,,,,
r5qumLiYwf9,2022,Accept (Poster),True,MaGNET: Uniform Sampling from Deep Generative Network Manifolds Without Retraining,"['Ahmed Imtiaz Humayun', 'Randall Balestriero', 'Richard Baraniuk']","[""Deep Generative Networks"", ""Uniform Sampling"", ""Fairness"", ""Data Augmentation""]",We propose a differential-geometry-based technique to provably sample uniformly from the data manifold of a trained Deep Generative Network without the need for retraining.,2110.08009,cs.LG,2021-10-15 11:12:56+00:00,2022-01-21 03:10:39+00:00
r6I3EvB9eDO,2021,Reject,False,Necessary and Sufficient Conditions for Compositional Representations,"[""Yuanpeng Li""]","[""Compositionality""]",,,,,
r7L91opmsr,2021,Reject,False,Partial Rejection Control for Robust Variational Inference in Sequential Latent Variable Models,"[""Rahul Sharma"", ""Soumya Banerjee"", ""Dootika Vats"", ""Piyush Rai""]","[""dice enterprise"", ""partial rejection control"", ""sequential Monte-Carlo"", ""Bernoulli factory"", ""variational Inference"", ""Rejection Sampling""]","We present a new family of approximate distributions VSMC-PRC that combines sequential Monte-Carlo, variational inference, and rejection sampling in a synergistic manner.",,,,
r88Isj2alz,2022,Reject,False,NODEAttack: Adversarial Attack on the Energy Consumption of Neural ODEs,"['Mirazul Haque', 'Simin Chen', 'Wasif Arman Haque', 'Cong Liu', 'Wei Yang']","[""Adversarial Machine Learning"", ""Energy Consumption""]",The paper proposes adversarial energy attack on Neural ODEs.,,,,
r8S93OsHWEf,2022,Reject,False,Improving Adversarial Defense with Self-supervised Test-time Fine-tuning,"['Zhichao Huang', 'Chen Liu', 'Mathieu Salzmann', 'Sabine SÃ¼sstrunk', 'Tong Zhang']",[],,,,,
r9cpyzP-DQ,2022,Reject,False,Learning Efficient and Robust Ordinary Differential Equations via Diffeomorphisms,"['Weiming Zhi', 'Tin Lai', 'Lionel Ott', 'Edwin V Bonilla', 'Fabio Ramos']","[""Differentiable ODE integrator"", ""Neural ODEs"", ""diffeomorphisms"", ""differential geometry""]",,,,,
rABUmU3ulQh,2021,Accept (Poster),False,Learning to Generate 3D Shapes with Generative Cellular Automata,"[""Dongsu Zhang"", ""Changwoon Choi"", ""Jeonghwan Kim"", ""Young Min Kim""]","[""3D generation"", ""generative models""]","We present a Markov chain based 3D generative model named Generative Cellular Automata (GCA), that progressively evolves to a shape of the learned distribution using the local update rules of cellular automata.",2103.04130,cs.CV,2021-03-06 14:59:35+00:00,2021-03-06 14:59:35+00:00
rALA0Xo6yNJ,2021,Accept (Oral),False,Learning to Reach Goals via Iterated Supervised Learning,"[""Dibya Ghosh"", ""Abhishek Gupta"", ""Ashwin Reddy"", ""Justin Fu"", ""Coline Manon Devin"", ""Benjamin Eysenbach"", ""Sergey Levine""]","[""goal reaching"", ""reinforcement learning"", ""behavior cloning"", ""goal-conditioned RL""]","We present GCSL, a simple RL method that uses supervised learning to learn goal-reaching policies.",,,,
rC8sJ4i6kaH,2021,Accept (Oral),False,Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data,"[""Colin Wei"", ""Kendrick Shen"", ""Yining Chen"", ""Tengyu Ma""]","[""deep learning theory"", ""domain adaptation theory"", ""unsupervised learning theory"", ""semi-supervised learning theory""]","This paper provides accuracy guarantees for self-training with deep networks on polynomial unlabeled samples for semi-supervised learning, unsupervised domain adaptation, and unsupervised learning.",,,,
rEaz5uTcL6Q,2021,Reject,False,Neural spatio-temporal reasoning with object-centric self-supervised learning,"[""David Ding"", ""Felix Hill"", ""Adam Santoro"", ""Matthew Botvinick""]","[""self-attention"", ""object representations"", ""visual reasoning"", ""dynamics"", ""visual question answering""]",Self-attention with object representations can significantly improve upon state of the art for video and physical dynamics based causal reasoning tasks.,,,,
rF5UoZFrsF4,2022,Reject,False,VUT: Versatile UI Transformer for Multimodal Multi-Task User Interface Modeling ,"['Yang Li', 'Gang Li', 'Xin Zhou', 'Mostafa Dehghani', 'Alexey A. Gritsenko']","[""User Interface Modeling"", ""Multimodal input"", ""Multi-task learning"", ""Transformer"", ""Layout Detection"", ""Language Grounding"", ""Image Captioning"", ""Screen Summarization"", ""Tappability Prediction.""]",The work addresses unique challenges of multimodal multi-task learning of distinct tasks for user interface modeling.,,,,
rFJWoYoxrDB,2022,Accept (Poster),False,On Redundancy and Diversity in Cell-based Neural Architecture Search,"['Xingchen Wan', 'Binxin Ru', 'Pedro M EsperanÃ§a', 'Zhenguo Li']","[""NAS"", ""machine learning architectures"", ""AutoML""]",We analyse and explore the redundancies and diversity of popular cell-based search spaces in NAS.,,,,
rFbR4Fv-D6-,2022,Accept (Poster),True,Automated Self-Supervised Learning for Graphs,"['Wei Jin', 'Xiaorui Liu', 'Xiangyu Zhao', 'Yao Ma', 'Neil Shah', 'Jiliang Tang']","[""Self-supervised learning"", ""Graph neural networks"", ""AutoML""]",An automated self-supervised learning algorithm for graph neural networks.,2106.05470,cs.LG,2021-06-10 03:09:20+00:00,2021-06-15 12:59:03+00:00
rGg-Qcyplgq,2022,Reject,False,Distributional Perturbation for Efficient Exploration in Distributional Reinforcement Learning,"['Tae Hyun Cho', 'Sungyeob Han', 'Heesoo Lee', 'Kyungjae Lee', 'Jungwoo Lee']","[""distributional reinforcement learning"", ""perturbation"", ""exploration""]",,,,,
rHMaBYbkkRJ,2022,Accept (Poster),True,CLEVA-Compass: A Continual Learning Evaluation Assessment Compass to Promote Research Transparency and Comparability,"['Martin Mundt', 'Steven Lang', 'Quentin Delfosse', 'Kristian Kersting']","[""continual learning"", ""lifelong learning"", ""machine learning evaluation""]","We introduce the Continual Learning EValuation Assessment Compass, which provides the visual means to both identify how approaches are practically reported and how they can simultaneously be contextualized in the broader literature landscape.",2110.03331,cs.LG,2021-10-07 10:53:26+00:00,2022-02-01 10:31:29+00:00
rI0LYgGeYaw,2022,Accept (Poster),True,Understanding approximate and unrolled dictionary learning for pattern recovery,"['BenoÃ®t MalÃ©zieux', 'Thomas Moreau', 'Matthieu Kowalski']","[""Dictionary learning"", ""bi-level optimization"", ""unrolling"", ""pattern learning""]",,2106.06338,cs.LG,2021-06-11 12:21:26+00:00,2022-02-08 10:39:01+00:00
rI3RMgDkZqJ,2021,Reject,False,A Primal Approach to Constrained Policy Optimization: Global Optimality and Finite-Time Analysis,"[""Tengyu Xu"", ""Yingbin Liang"", ""Guanghui Lan""]","[""safe reinforcement learning"", ""constrained markov decision process"", ""policy optimization""]",This paper proposes an easy-to-implement approach for safe RL problems and establishes its global optimality guarantee.,2011.05869,cs.LG,2020-11-11 16:05:14+00:00,2021-05-31 04:41:09+00:00
rJ0-tY5xe,2017,Accept (Poster),False,"Learning to Query, Reason, and Answer Questions On Ambiguous Texts","[""Xiaoxiao Guo"", ""Tim Klinger"", ""Clemens Rosenbaum"", ""Joseph P. Bigus"", ""Murray Campbell"", ""Ban Kawas"", ""Kartik Talamadupula"", ""Gerry Tesauro"", ""Satinder   Singh""]","[""Natural language processing"", ""Deep learning"", ""Reinforcement Learning""]",A new dataset QRAQ of ambiguous stories in which an Agent must learn to reason and interact with a User to obtain important missing information needed to answer a challenge question.,,,,
rJ0JwFcex,2017,Accept (Poster),False,Neuro-Symbolic Program Synthesis,"[""Emilio Parisotto"", ""Abdel-rahman Mohamed"", ""Rishabh Singh"", ""Lihong Li"", ""Dengyong Zhou"", ""Pushmeet Kohli""]","[""Deep learning"", ""Structured prediction""]",A neural architecture for learning programs in a domain-specific language that are consistent with a given set of input-output examples,,,,
rJ1RPJWAW,2018,Reject,False,Learnability of Learned Neural Networks,"[""Rahul Anand Sharma"", ""Navin Goyal"", ""Monojit Choudhury"", ""Praneeth Netrapalli""]","[""Learnability"", ""Generalizability"", ""Understanding Deep Learning""]",Exploring the Learnability of Learned Neural Networks,,,,
rJ33wwxRb,2018,Accept (Poster),False,SGD Learns Over-parameterized Networks that Provably Generalize on Linearly Separable Data,"[""Alon Brutzkus"", ""Amir Globerson"", ""Eran Malach"", ""Shai Shalev-Shwartz""]","[""Deep Learning"", ""Non-convex Optmization"", ""Generalization"", ""Learning Theory"", ""Neural Networks""]",We show that SGD learns two-layer over-parameterized neural networks with Leaky ReLU activations that provably generalize on linearly separable data.,,,,
rJ3fy0k0Z,2018,Reject,False,Deterministic Policy Imitation Gradient Algorithm,"[""Fumihiro Sasaki"", ""Atsuo Kawaguchi""]","[""Imitation Learning""]",We propose a model free imitation learning algorithm that is able to reduce number of interactions with environment in comparison with state-of-the-art imitation learning algorithm namely GAIL.,,,,
rJ4km2R5t7,2019,Accept (Poster),False,GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding,"[""Alex Wang"", ""Amanpreet Singh"", ""Julian Michael"", ""Felix Hill"", ""Omer Levy"", ""Samuel R. Bowman""]","[""natural language understanding"", ""multi-task learning"", ""evaluation""]",We present a multi-task benchmark and analysis platform for evaluating generalization in natural language understanding systems.,,,,
rJ4qXnCqFX,2019,Reject,False,Probabilistic Knowledge Graph Embeddings,"[""Farnood Salehi"", ""Robert Bamler"", ""Stephan Mandt""]","[""knowledge graph"", ""variational inference"", ""probabilistic models"", ""representation learning""]",Scalable hyperparameter learning for knowledge graph embedding models using variational EM,,,,
rJ4uaX2aW,2018,Reject,False,Large Batch Training of Convolutional Networks with Layer-wise Adaptive Rate Scaling,"[""Boris Ginsburg"", ""Igor Gitman"", ""Yang You""]","[""large batch"", ""LARS"", ""adaptive rate scaling""]","A new large batch training algorithm  based on Layer-wise Adaptive Rate Scaling (LARS); using LARS, we scaled AlexNet  and ResNet-50 to a batch of 16K.",,,,
rJ4vlh0qtm,2019,Reject,False,SSoC: Learning Spontaneous and Self-Organizing Communication for Multi-Agent Collaboration,"[""Xiangyu Kong"", ""Jing Li"", ""Bo Xin"", ""Yizhou Wang""]","[""reinforcement learning"", ""multi-agent learning"", ""multi-agent communication"", ""deep learning""]",This paper proposes a spontaneous and self-organizing communication (SSoC) learning scheme for multi-agent RL tasks.,,,,
rJ5C67-C-,2018,Reject,False,Hyperedge2vec: Distributed Representations for Hyperedges,"[""Ankit Sharma"", ""Shafiq Joty"", ""Himanshu Kharkwal"", ""Jaideep Srivastava""]","[""hypergraph"", ""representation learning"", ""tensors""]",,,,,
rJ695PxRW,2018,Reject,False,Discovering Order in Unordered Datasets: Generative Markov Networks,"[""Yao-Hung Hubert Tsai"", ""Han Zhao"", ""Nebojsa Jojic"", ""Ruslan Salakhutdinov""]","[""Markov chain"", ""discovering orders"", ""generative model"", ""one-shot""]",Propose to observe implicit orders in datasets in a generative model viewpoint.,,,,
rJ6DhP5xe,2017,Invite to Workshop Track,False,Generalizable Features From Unsupervised Learning,"[""Mehdi Mirza"", ""Aaron Courville"", ""Yoshua Bengio""]","[""Unsupervised Learning"", ""Deep learning""]",Using generated data from a next frame predictor model to make a supervised model generalize better to unseen distributions.  ,,,,
rJ6iJmWCW,2018,Reject,False,POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION,"[""Prannay Khosla"", ""Preethi Jyothi"", ""Vinay P. Namboodiri"", ""Mukundhan Srinivasan""]","[""speech"", ""generation"", ""accent"", ""gan"", ""adversarial"", ""reinforcement"", ""memory"", ""lstm"", ""policy"", ""gradients"", ""human""]",,,,,
rJ7RBNe0-,2018,Reject,False,Generative Models for Alignment and Data Efficiency in Language,"[""Dustin Tran"", ""Yura Burda"", ""Ilya Sutskever""]",[],,,,,
rJ7yZ2P6-,2018,Reject,False,Enhance Word Representation for Out-of-Vocabulary on Ubuntu Dialogue Corpus,"[""JIANXIONG DONG"", ""Jim Huang""]","[""next utterance selection"", ""ubuntu dialogue corpus"", ""out-of-vocabulary"", ""word representation""]",Combine information between pre-built word embedding and task-specific word representation to address out-of-vocabulary issue,,,,
rJ8Je4clg,2017,Accept (Poster),False,Learning to Play in a Day: Faster Deep Reinforcement Learning by Optimality Tightening,"[""Frank S.He"", ""Yang Liu"", ""Alexander G. Schwing"", ""Jian Peng""]","[""Reinforcement Learning"", ""Optimization"", ""Games""]",We propose a novel training algorithm for reinforcement learning which combines the strength of deep Q-learning with a constrained optimization approach to tighten optimality and encourage faster reward propagation.,,,,
rJ8rHkWRb,2018,Reject,False,A Simple Fully Connected Network for Composing Word Embeddings from Characters,"[""Michael Traynor"", ""Thomas Trappenberg""]","[""natural language processing"", ""word embeddings"", ""language models"", ""neural network"", ""deep learning"", ""sparsity"", ""dropout""]","A fully connected architecture is used to produce word embeddings from character representations, outperforms traditional embeddings and provides insight into sparsity and dropout.",,,,
rJ8uNptgl,2017,Accept (Poster),False,Towards the Limit of Network Quantization,"[""Yoojin Choi"", ""Mostafa El-Khamy"", ""Jungwon Lee""]","[""Theory"", ""Deep learning""]",,,,,
rJA5Pz7lHKb,2021,Accept (Oral),False,Improved Autoregressive Modeling with Distribution Smoothing,"[""Chenlin Meng"", ""Jiaming Song"", ""Yang Song"", ""Shengjia Zhao"", ""Stefano Ermon""]","[""generative models"", ""autoregressive models""]",,2103.15089,cs.LG,2021-03-28 09:21:20+00:00,2021-03-28 09:21:20+00:00
rJBiunlAW,2018,Reject,False,Training RNNs as Fast as CNNs,"[""Tao Lei"", ""Yu Zhang"", ""Yoav Artzi""]","[""recurrent neural networks"", ""natural language processing""]",,,,,
rJBwoM-Cb,2018,Reject,False,Neural Tree Transducers for Tree to Tree Learning,"[""Jo\u00e3o Sedoc"", ""Dean Foster"", ""Lyle Ungar""]","[""deep learning"", ""tree transduction""]",,,,,
rJEgeXFex,2017,Accept (Poster),False,Predicting Medications from Diagnostic Codes with Recurrent Neural Networks,"[""Jacek M. Bajor"", ""Thomas A. Lasko""]","[""Deep learning"", ""Supervised Learning"", ""Applications""]",Applying recurrent neural networks to fix errors and omissions in patient medication records.,,,,
rJEjjoR9K7,2019,Accept (Oral),False,Learning Robust Representations by Projecting Superficial Statistics Out,"[""Haohan Wang"", ""Zexue He"", ""Zachary C. Lipton"", ""Eric P. Xing""]","[""domain generalization"", ""robustness""]","Building on previous work on domain generalization, we hope to produce a classifier that will generalize to previously unseen domains, even when domain identifiers are not available during training.",,,,
rJEyrjRqYX,2019,Reject,False,Reduced-Gate Convolutional LSTM Design Using Predictive Coding for Next-Frame Video Prediction,"[""Nelly Elsayed"", ""Anthony S. Maida"", ""Magdy Bayoumi""]","[""rgcLSTM"", ""convolutional LSTM"", ""unsupervised learning"", ""predictive coding"", ""video prediction"", ""moving MNIST"", ""KITTI datasets"", ""deep learning""]",A novel reduced-gate convolutional LSTM design using predictive coding for next-frame video prediction,,,,
rJFOptp6Z,2018,Reject,False,Model Distillation with Knowledge Transfer from Face Classification to Alignment and Verification,"[""Chong Wang"", ""Xipeng Lan"", ""Yangang Zhang""]","[""distill"", ""transfer"", ""classification"", ""alignment"", ""verification""]",We take face recognition as a breaking point and propose model distillation with knowledge transfer from face classification to alignment and verification,,,,
rJG8asRqKX,2019,Reject,False,A Deep Learning Approach for Dynamic Survival Analysis with Competing Risks,"[""Changhee Lee"", ""Mihaela van der Schaar""]","[""dynamic survival analysis"", ""survival analysis"", ""longitudinal measurements"", ""competing risks""]",,,,,
rJGY8GbR-,2018,Invite to Workshop Track,False,Deep Mean Field Theory: Layerwise Variance and Width Variation as Methods to Control Gradient Explosion,"[""Greg Yang"", ""Sam S. Schoenholz""]","[""mean field"", ""dynamics"", ""residual network"", ""variance variation"", ""width variation"", ""initialization""]","By setting the width or the initialization variance of each layer differently, we can actually subdue gradient explosion problems in residual networks (with fully connected layers and no batchnorm). A mathematical theory is developed that not only tells you how to do it, but also surprisingly is able to predict, after you apply such tricks, how fast your network trains to achieve a certain test set performance. This is some black magic stuff, and it's called ""Deep Mean Field Theory.""",,,,
rJGZq6g0-,2018,Accept (Poster),False,"Emergent Communication in a Multi-Modal, Multi-Step Referential Game","[""Katrina Evtimova"", ""Andrew Drozdov"", ""Douwe Kiela"", ""Kyunghyun Cho""]","[""emergent communication"", ""multi-agent systems"", ""multi-modal""]",,,,,
rJHcpW-CW,2018,Reject,False,NOVEL AND EFFECTIVE PARALLEL MIX-GENERATOR GENERATIVE ADVERSARIAL NETWORKS,"[""Xia Xiao"", ""Sanguthevar Rajasekaran""]","[""neural networks"", ""generative adversarial networks"", ""parallel""]","multi generator to capture Pdata, solve the competition and one-beat-all problem",,,,
rJIN_4lA-,2018,Reject,False,Maintaining cooperation in complex social dilemmas using deep reinforcement learning,"[""Alexander Peysakhovich"", ""Adam Lerer""]","[""reinforcement learning"", ""cooperation"", ""social dilemmas"", ""game theory""]",How can we build artificial agents that solve social dilemmas (situations where individuals face a temptation to increase their payoffs at a cost to total welfare)?,,,,
rJIgf7bAZ,2018,Reject,False,An inference-based policy gradient method for learning options,"[""Matthew J. A. Smith"", ""Herke van Hoof"", ""Joelle Pineau""]","[""reinforcement learning"", ""hierarchy"", ""options"", ""inference""]",We develop a novel policy gradient method for the automatic learning of policies with options using a differentiable inference step.,,,,
rJJ3YU5ge,2017,Reject,False,Is a picture worth a thousand words? A Deep Multi-Modal Fusion Architecture for Product Classification in e-commerce,"[""Tom Zahavy"", ""Alessandro Magnani"", ""Abhinandan Krishnan"", ""Shie Mannor""]","[""Multi-modal learning"", ""Deep learning""]",,,,,
rJJRDvcex,2017,Reject,False,Layer Recurrent Neural Networks,"[""Weidi Xie"", ""Alison Noble"", ""Andrew Zisserman""]","[""Deep learning"", ""Computer vision""]",We propose a Layer-RNN (L-RNN) network that is able to learn contextual information adaptively using within-layer recurrence. We further propose to insert L-RNN to pre-trained CNNs seamlessly.,,,,
rJJzTyWCZ,2018,Reject,False,Large-scale Cloze Test Dataset Designed by Teachers,"[""Qizhe Xie"", ""Guokun Lai"", ""Zihang Dai"", ""Eduard Hovy""]","[""dataset"", ""human-designed"", ""language understanding""]",A cloze test dataset designed by teachers to assess language proficiency,,,,
rJL6pz-CZ,2018,Reject,False,Transfer Learning on Manifolds via Learned Transport Operators,"[""Marissa Connor"", ""Christopher Rozell""]","[""manifold learning"", ""transfer learning""]",Learning transport operators on manifolds forms a valuable representation for doing tasks like transfer learning.,,,,
rJLS7qKel,2017,Accept (Oral),False,Learning to Act by Predicting the Future,"[""Alexey Dosovitskiy"", ""Vladlen Koltun""]",[],We present an approach to sensorimotor control in immersive environments.,,,,
rJLTTe-0W,2018,Reject,False,Bayesian Time Series Forecasting with Change Point and Anomaly Detection,"[""Anderson Y. Zhang"", ""Miao Lu"", ""Deguang Kong"", ""Jimmy Yang""]","[""Time Series Forecasting"", ""Change Point Detection"", ""Anomaly Detection"", ""State Space Model"", ""Bayesian""]","We propose a novel state space time series model with the capability to capture the structure of change points and anomaly points, so that it has a better forecasting performance when there exist change points and anomalies in the time series.",,,,
rJM69B5xx,2017,Reject,False,Finding a Jack-of-All-Trades: An Examination of Semi-supervised Learning in Reading Comprehension,"[""Rudolf Kadlec"", ""Ond\u0159ej Bajgar"", ""Peter Hrincar"", ""Jan Kleindienst""]","[""Natural language processing"", ""Semi-Supervised Learning"", ""Deep learning"", ""Transfer Learning""]",We examine effect of transfer learning in AS Reader model from two source domains (CNN/DM and BookTest) to two target domains (bAbI and SQuAD).,,,,
rJMcdsA5FX,2019,Reject,False,On Accurate Evaluation of GANs for Language Generation,"[""Stanislau Semeniuta"", ""Aliaksei Severyn"", ""Sylvain Gelly""]","[""GANs"", ""Evaluation"", ""Generative Models""]","We discuss how to evaluate GANs for language generation, propose a protocol and show that simple Language Models achieve results as good as GANs.",,,,
rJNH6sAqY7,2019,Accept (Poster),False,On Computation and Generalization of Generative Adversarial Networks under Spectrum Control,"[""Haoming Jiang"", ""Zhehui Chen"", ""Minshuo Chen"", ""Feng Liu"", ""Dingding Wang"", ""Tuo Zhao""]",[],,,,,
rJNpifWAb,2018,Accept (Poster),False,Flipout: Efficient Pseudo-Independent Weight Perturbations on Mini-Batches,"[""Yeming Wen"", ""Paul Vicol"", ""Jimmy Ba"", ""Dustin Tran"", ""Roger Grosse""]","[""weight perturbation"", ""reparameterization gradient"", ""gradient variance reduction"", ""evolution strategies"", ""LSTM"", ""regularization"", ""optimization""]","We introduce flipout, an efficient method for decorrelating the gradients computed by stochastic neural net weights within a mini-batch by implicitly sampling pseudo-independent weight perturbations for each example.",,,,
rJNwDjAqYX,2019,Accept (Poster),False,Large-Scale Study of Curiosity-Driven Learning,"[""Yuri Burda"", ""Harri Edwards"", ""Deepak Pathak"", ""Amos Storkey"", ""Trevor Darrell"", ""Alexei A. Efros""]","[""exploration"", ""curiosity"", ""intrinsic reward"", ""no extrinsic reward"", ""unsupervised"", ""no-reward"", ""skills""]","An agent trained only with curiosity, and no extrinsic reward, does surprisingly well on 54 popular environments, including the suite of Atari games, Mario etc.",,,,
rJPcZ3txx,2017,Accept (Poster),False,Faster CNNs with Direct Sparse Convolutions and Guided Pruning,"[""Jongsoo Park"", ""Sheng Li"", ""Wei Wen"", ""Ping Tak Peter Tang"", ""Hai Li"", ""Yiran Chen"", ""Pradeep Dubey""]","[""Deep learning"", ""Optimization""]","Highly-performance sparse convolution outperforms dense with only 70% sparsity. Performance model that guides training to find useful sparsity range, applied to AlexNet and GoogLeNet",,,,
rJQDjk-0b,2018,Accept (Poster),False,Unbiased Online Recurrent Optimization,"[""Corentin Tallec"", ""Yann Ollivier""]","[""RNN""]","Introduces an online, unbiased and easily implementable gradient estimate for recurrent models.",,,,
rJQKYt5ll,2017,Accept (Poster),False,Steerable CNNs,"[""Taco S. Cohen"", ""Max Welling""]",[],,,,,
rJR2ylbRb,2018,Reject,False,Spectral Graph Wavelets for Structural Role Similarity in Networks,"[""Claire Donnat"", ""Marinka Zitnik"", ""David Hallac"", ""Jure Leskovec""]","[""Graphs"", ""Structural Similarities"", ""Spectral Graph Wavelets"", ""Graph Signal Processing"", ""Unsupervised Learning""]",We develop a method for learning structural signatures in networks based on the diffusion of spectral graph wavelets.,,,,
rJRhzzKxl,2017,Reject,False,Knowledge Adaptation: Teaching to Adapt,"[""Sebastian Ruder"", ""Parsa Ghaffari"", ""John G. Breslin""]","[""Natural language processing"", ""Deep learning"", ""Transfer Learning"", ""Unsupervised Learning""]",We propose a teacher-student framework for domain adaptation together with a novel confidence measure that achieves state-of-the-art results on single-source and multi-source adaptation on a standard sentiment analysis benchmark.,,,,
rJSr0GZR-,2018,Reject,False,Learning Priors for Adversarial Autoencoders,"[""Hui-Po Wang"", ""Wei-Jan Ko"", ""Wen-Hsiao Peng""]","[""deep learning"", ""computer vision"", ""generative adversarial networks""]",Learning Priors for Adversarial Autoencoders,,,,
rJTGkKxAZ,2018,Reject,False,Learning Generative Models with Locally Disentangled Latent Factors,"[""Brady Neal"", ""Alex Lamb"", ""Sherjil Ozair"", ""Devon Hjelm"", ""Aaron Courville"", ""Yoshua Bengio"", ""Ioannis Mitliagkas""]","[""Generative Models"", ""Hierarchical Models"", ""Latent Variable Models""]",Decompose the task of learning a generative model into learning disentangled latent factors for subsets of the data and then learning the joint over those latent factors.  ,,,,
rJTKKKqeg,2017,Accept (Poster),False,Tracking the World State with Recurrent Entity Networks,"[""Mikael Henaff"", ""Jason Weston"", ""Arthur Szlam"", ""Antoine Bordes"", ""Yann LeCun""]","[""Natural language processing"", ""Deep learning""]","A new memory-augmented model which learns to track the world state, obtaining SOTA on the bAbI tasks amongst other results.",,,,
rJTutzbA-,2018,Accept (Oral),False,On the insufficiency of existing momentum schemes for Stochastic Optimization,"[""Rahul Kidambi"", ""Praneeth Netrapalli"", ""Prateek Jain"", ""Sham M. Kakade""]","[""Stochastic Gradient Descent"", ""Deep Learning"", ""Momentum"", ""Acceleration"", ""Heavy Ball"", ""Nesterov Acceleration"", ""Stochastic Optimization"", ""SGD"", ""Accelerated Stochastic Gradient Descent""]","Existing momentum/acceleration schemes such as heavy ball method and Nesterov's acceleration employed with stochastic gradients do not improve over vanilla stochastic gradient descent, especially when employed with small batch sizes.",,,,
rJUBryZ0W,2018,Reject,False,Lifelong Learning by Adjusting Priors,"[""Ron Amit"", ""Ron Meir""]","[""Lifelong learning"", ""Transfer learning"", ""PAC-Bayes theory""]","We develop a lifelong learning approach to transfer learning based on PAC-Bayes theory, whereby priors are adjusted as new tasks are encountered thereby facilitating the learning of novel tasks.",,,,
rJUYGxbCW,2018,Accept (Poster),False,PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples,"[""Yang Song"", ""Taesup Kim"", ""Sebastian Nowozin"", ""Stefano Ermon"", ""Nate Kushman""]","[""Adversarial Examples"", ""Generative Models"", ""Purification"", ""Hypothesis Testing""]",,,,,
rJVoEiCqKQ,2019,Reject,False,Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks,"[""S. Hamid Rezatofighi"", ""Roman Kaskman"", ""Farbod T. Motlagh"", ""Qinfeng Shi"", ""Daniel Cremers"", ""Laura Leal-Taix\u00e9"", ""Ian Reid""]","[""Set learning"", ""Permutation invariant"", ""Object detection"", ""CAPTCHA test""]",We present a novel approach for learning to predict sets with unknown permutation and cardinality using feed-forward deep neural networks.,,,,
rJVorjCcKQ,2019,Accept (Oral),False,"Slalom: Fast, Verifiable and Private Execution of Neural Networks in Trusted Hardware","[""Florian Tramer"", ""Dan Boneh""]","[""Trusted hardware"", ""integrity"", ""privacy"", ""secure inference"", ""SGX""]",We accelerate secure DNN inference in trusted execution environments (by a factor 4x-20x) by selectively outsourcing the computation of linear layers to a faster yet untrusted co-processor.,,,,
rJVruWZRW,2018,Reject,False,Dense Recurrent Neural Network with Attention Gate,"[""Yong-Ho Yoo"", ""Kook Han"", ""Sanghyun Cho"", ""Kyoung-Chul Koh"", ""Jong-Hwan Kim""]","[""recurrent neural network"", ""language modeling"", ""dense connection""]",Dense RNN that has fully connections from each hidden state to multiple preceding hidden states of all layers directly.,,,,
rJWechg0Z,2018,Accept (Poster),False,Minimal-Entropy Correlation Alignment for Unsupervised Deep Domain Adaptation,"[""Pietro Morerio"", ""Jacopo Cavazza"", ""Vittorio Murino""]","[""unsupervised domain adaptation"", ""entropy minimization"", ""image classification"", ""deep transfer learning""]",A new unsupervised deep domain adaptation technique which efficiently unifies correlation alignment and entropy minimization,,,,
rJWrK9lAb,2018,Invite to Workshop Track,False,Autoregressive Generative Adversarial Networks,"[""Yasin Yazici"", ""Kim-Hui Yap"", ""Stefan Winkler""]","[""Generative Adversarial Networks"", ""Latent Space Modeling""]",,,,,
rJXMpikCZ,2018,Accept (Poster),False,Graph Attention Networks,"[""Petar Veli\u010dkovi\u0107"", ""Guillem Cucurull"", ""Arantxa Casanova"", ""Adriana Romero"", ""Pietro Li\u00f2"", ""Yoshua Bengio""]","[""Deep Learning"", ""Graph Convolutions"", ""Attention"", ""Self-Attention""]","A novel approach to processing graph-structured data by neural networks, leveraging attention over a node's neighborhood. Achieves state-of-the-art results on transductive citation network tasks and an inductive protein-protein interaction task.",,,,
rJXTf9Bxg,2017,Reject,False,Conditional Image Synthesis With Auxiliary Classifier GANs,"[""Augustus Odena"", ""Christopher Olah"", ""Jonathon Shlens""]","[""Deep learning""]",We introduce a special GAN architecture that results in high quality 128x128 ImageNet samples; we introduce 2 new quantitative metrics of sample quality.,,,,
rJY0-Kcll,2017,Accept (Oral),False,Optimization as a Model for Few-Shot Learning,"[""Sachin Ravi"", ""Hugo Larochelle""]",[],We propose an LSTM-based meta-learner model to learn the exact optimization algorithm used to train another learner neural network in the few-shot regime,,,,
rJY3vK9eg,2017,Reject,False,Neural Combinatorial Optimization with Reinforcement Learning,"[""Irwan Bello*"", ""Hieu Pham*"", ""Quoc V. Le"", ""Mohammad Norouzi"", ""Samy Bengio""]","[""Reinforcement Learning"", ""Deep learning""]",This paper presents a framework to tackle combinatorial optimization problems using neural networks and reinforcement learning.,,,,
rJYFzMZC-,2018,Accept (Poster),False,Simulating Action Dynamics with Neural Process Networks,"[""Antoine Bosselut"", ""Omer Levy"", ""Ari Holtzman"", ""Corin Ennis"", ""Dieter Fox"", ""Yejin Choi""]","[""representation learning"", ""memory networks"", ""state tracking""]",We propose a new recurrent memory architecture that can track common sense state changes of entities by simulating the causal effects of actions.,,,,
rJa90ceAb,2018,Reject,False,Learning to Generate Filters for Convolutional Neural Networks,"[""Wei Shen"", ""Rujie Liu""]","[""filter generation"", ""meta-learning"", ""filter repository"", ""image classification"", ""dynamic generation""]",dynamically generate filters conditioned on the input image for CNNs in each forward pass ,,,,
rJaE2alRW,2018,Reject,False,Autoregressive Convolutional Neural Networks for Asynchronous Time Series,"[""Mikolaj Binkowski"", ""Gautier Marti"", ""Philippe Donnat""]","[""neural networks"", ""convolutional neural networks"", ""time series"", ""asynchronous data"", ""regression""]",Convolutional architecture for learning data-dependent weights for autoregressive forecasting of time series.,,,,
rJbPBt9lg,2017,Reject,False,Neural Code Completion,"[""Chang Liu"", ""Xin Wang"", ""Richard Shin"", ""Joseph E. Gonzalez"", ""Dawn Song""]","[""Deep learning"", ""Applications""]",,,,,
rJbbOLcex,2017,Accept (Poster),False,TopicRNN: A Recurrent Neural Network with Long-Range Semantic Dependency,"[""Adji B. Dieng"", ""Chong Wang"", ""Jianfeng Gao"", ""John Paisley""]","[""Natural language processing"", ""Deep learning""]",,,,,
rJbs5gbRW,2018,Reject,False,On the Generalization Effects of DenseNet Model Structures ,"[""Yin Liu"", ""Vincent Chen""]","[""Skip connection"", ""generalization"", ""gegularization"", ""deep network"", ""representation.""]","Our paper analyses the tremendous representational power of networks especially with 'skip connections', which may be used as a method  for better generalization.",,,,
rJe-Pr9le,2017,Reject,False,Multi-task learning with deep model based reinforcement learning,"[""Asier Mujika""]","[""Reinforcement Learning"", ""Deep learning"", ""Games"", ""Transfer Learning""]","We build a world model, based on CNN's and RNN's, to play multiple ATARI games simultaneously, achieving super-human performance.",,,,
rJe04p4YDB,2020,Reject,False,Semi-supervised Learning by Coaching,"[""Hieu Pham"", ""Quoc V. Le""]","[""semi-supervised"", ""teacher"", ""student"", ""label propagation"", ""image classification""]",,,,,
rJe10iC5K7,2019,Accept (Poster),False,"Unsupervised Discovery of Parts, Structure, and Dynamics","[""Zhenjia Xu*"", ""Zhijian Liu*"", ""Chen Sun"", ""Kevin Murphy"", ""William T. Freeman"", ""Joshua B. Tenenbaum"", ""Jiajun Wu""]","[""Self-Supervised Learning"", ""Visual Prediction"", ""Hierarchical Models""]","Learning object parts, hierarchical structure, and dynamics by watching how they move",,,,
rJe1DTNYPH,2020,Reject,True,Towards Disentangling Non-Robust and Robust Components in Performance Metric,"[""Yujun Shi"", ""Benben Liao"", ""Guangyong Chen"", ""Yun Liu"", ""Ming-ming Cheng"", ""Jiashi Feng""]","[""adversarial examples"", ""robust machine learning""]",We show the relation between standard performance and adversarial robustness by disentangling the non-robust and robust components in a proposed performance metric.,1906.02494,stat.ML,2019-06-06 09:31:14+00:00,2019-06-06 09:31:14+00:00
rJe1y3CqtX,2019,Reject,False,Deep Reinforcement Learning of Universal Policies with Diverse Environment Summaries,"[""Felix Berkenkamp"", ""Debadeepta Dey"", ""Ashish Kapoor""]","[""Domain Randomization"", ""Diverse Summaries"", ""Reinforcement learning""]","As an alternative to domain randomization, we summarize simulator configurations to ensure that the policy is trained on a diverse set of induced state-trajectories.",,,,
rJe2syrtvS,2020,Accept (Spotlight),False,The Ingredients of Real World Robotic Reinforcement Learning,"[""Henry Zhu"", ""Justin Yu"", ""Abhishek Gupta"", ""Dhruv Shah"", ""Kristian Hartikainen"", ""Avi Singh"", ""Vikash Kumar"", ""Sergey Levine""]","[""Reinforcement Learning"", ""Robotics""]",System to learn robotic tasks in the real world with reinforcement learning without instrumentation,2004.12570,cs.LG,2020-04-27 03:36:10+00:00,2020-04-27 03:36:10+00:00
rJe4ShAcF7,2019,Accept (Poster),False,Music Transformer: Generating Music with Long-Term Structure,"[""Cheng-Zhi Anna Huang"", ""Ashish Vaswani"", ""Jakob Uszkoreit"", ""Ian Simon"", ""Curtis Hawthorne"", ""Noam Shazeer"", ""Andrew M. Dai"", ""Matthew D. Hoffman"", ""Monica Dinculescu"", ""Douglas Eck""]","[""music generation""]",We show the first successful use of Transformer in generating music that exhibits long-term structure. ,,,,
rJe4_xSFDB,2020,Accept (Poster),False,Lipschitz constant estimation of Neural Networks via sparse polynomial optimization,"[""Fabian Latorre"", ""Paul Rolland"", ""Volkan Cevher""]","[""robust networks"", ""Lipschitz constant"", ""polynomial optimization""]",LP-based upper bounds on the Lipschitz constant of Neural Networks,2004.08688,cs.LG,2020-04-18 18:55:02+00:00,2020-04-18 18:55:02+00:00
rJe5_CNtPB,2020,Reject,False,Attention Forcing for Sequence-to-sequence Model Training,"[""Qingyun Dou"", ""Yiting Lu"", ""Joshua Efiong"", ""Mark J.F. Gales""]","[""deep learning"", ""sequence-to-sequence model"", ""attention mechanism"", ""speech synthesis"", ""machine translation""]",A method to train attention-based sequence-to-sequence models,,,,
rJe7CkrFvS,2020,Reject,False,Improving Exploration of Deep Reinforcement Learning using Planning for Policy Search,"[""Jakob J. Hollenstein"", ""Erwan Renaudo"", ""Justus Piater""]","[""reinforcement learning"", ""kinodynamic planning"", ""policy search""]",We employ a sample-based planning method for more directed exploration and efficiency in policy learning,,,,
rJe7FW-Cb,2018,Reject,False,A Painless Attention Mechanism for Convolutional Neural Networks,"[""Pau Rodr\u00edguez"", ""Guillem Cucurull"", ""Jordi Gonz\u00e0lez"", ""Josep M. Gonfaus"", ""Xavier Roca""]","[""computer vision"", ""deep learning"", ""convolutional neural networks"", ""attention""]",We enhance CNNs with a novel attention mechanism for fine-grained recognition. Superior performance is obtained on 5 datasets.,,,,
rJe8pxSFwr,2020,Reject,True,End-to-end learning of energy-based representations for irregularly-sampled signals and images,"[""Ronan Fablet"", ""Lucas Drumetz"", ""Fran\u00e7ois Rousseau""]","[""end-to-end-learning"", ""irregularly-sampled data"", ""energy representations"", ""optimal interpolation""]",We address the end-to-end learning of energy-based representations for signal and image observation dataset with irregular sampling patterns.,1910.00556,cs.CV,2019-10-01 17:31:31+00:00,2019-10-01 17:31:31+00:00
rJe9fTNtPS,2020,Reject,False,AHash: A Load-Balanced One Permutation Hash,"[""Chenxingyu Zhao"", ""Jie Gui"", ""Yixiao Guo"", ""Jie Jiang"", ""Tong Yang"", ""Bin Cui"", ""Gong Zhang""]","[""Data Representation"", ""Probabilistic Algorithms""]",Compact high-dimensional data for efficient learning and searching.,,,,
rJe9lpEFDH,2020,Reject,False,The Geometry of Sign Gradient Descent,"[""Lukas Balles"", ""Fabian Pedregosa"", ""Nicolas Le Roux""]","[""Sign gradient descent"", ""signSGD"", ""steepest descent"", ""Adam""]",We investigate which properties of an objective function favor sign gradient descent.,2002.08056,cs.LG,2020-02-19 08:45:54+00:00,2020-02-19 08:45:54+00:00
rJeA_aVtPB,2020,Reject,False,Decaying momentum helps neural network training,"[""John Chen"", ""Anastasios Kyrillidis""]","[""sgd"", ""momentum"", ""adam"", ""optimization"", ""deep learning""]",We introduce a momentum decay rule which significantly improves the performance of Adam and momentum SGD,,,,
rJeB22VFvS,2020,Reject,False,Towards More Realistic Neural Network Uncertainties,"[""Joachim Sicking"", ""Alexander Kister"", ""Matthias Fahrland"", ""Stefan Eickeler"", ""Fabian Hueger"", ""Stefan Rueping"", ""Peter Schlicht"", ""Tim Wirtz""]","[""uncertainty"", ""variational inference"", ""MC dropout"", ""variational autoencoder"", ""evaluation""]",We assess and improve the quality of neural network uncertainties by proposing an evaluation criterion and introducing a new uncertainty mechanism.,,,,
rJeB36NKvB,2020,Accept (Spotlight),False,How much Position Information Do Convolutional Neural Networks Encode?,"[""Md Amirul Islam*"", ""Sen Jia*"", ""Neil D. B. Bruce""]","[""network understanding"", ""absolute position information""]","Our work shows positional information has been implicitly encoded in a network. This information is important for detecting position-dependent features, e.g. semantic and saliency.",,,,
rJeBJJBYDB,2020,Reject,False,Chart Auto-Encoders for Manifold Structured  Data,"[""Stephan Schonsheck"", ""Jie Chen"", ""Rongjie Lai""]","[""Auto-encoder"", ""differential manifolds"", ""multi-charted latent space""]",Manifold-structured latent space for generative models,,,,
rJeEqiC5KQ,2019,Reject,False,ON THE USE OF CONVOLUTIONAL AUTO-ENCODER FOR INCREMENTAL CLASSIFIER LEARNING IN CONTEXT AWARE ADVERTISEMENT,"[""Tin Lay Nwe"", ""Shudong Xie"", ""Balaji Nataraj"", ""Yiqun Li"", ""Joo-Hwee Lim""]","[""Incremental learning"", ""deep learning"", ""autoencoder"", ""privacy"", ""convolutional neural network""]",Human brain inspired incremental learning system,,,,
rJeGJaEtPH,2020,Reject,False,MIST: Multiple Instance Spatial Transformer Networks,"[""Baptiste Angles"", ""Simon Kornblith"", ""Shahram Izadi"", ""Andrea Tagliasacchi"", ""Kwang Moo Yi""]",[],,,,,
rJeIGkBKPS,2020,Reject,False,Improving Confident-Classifiers For Out-of-distribution Detection,"[""Sachin Vernekar"", ""Ashish Gaurav"", ""Vahdat Abdelzad"", ""Taylor Denouden"", ""Rick Salay"", ""Krzysztof Czarnecki""]","[""Out-of-distribution detection"", ""Manifold"", ""Nullspace"", ""Variational Auto-encoder"", ""GAN"", ""Confident-classifier""]",It is a classifier based Out-of-distribution detection method,,,,
rJeINp4KwH,2020,Accept (Poster),False,Population-Guided Parallel Policy Search for Reinforcement Learning,"[""Whiyoung Jung"", ""Giseung Park"", ""Youngchul Sung""]","[""Reinforcement Learning"", ""Parallel Learning"", ""Population Based Learning""]",,2001.02907,cs.LG,2020-01-09 10:13:57+00:00,2020-01-09 10:13:57+00:00
rJeIcTNtvS,2020,Accept (Poster),False,Low-Resource Knowledge-Grounded Dialogue Generation,"[""Xueliang Zhao"", ""Wei Wu"", ""Chongyang Tao"", ""Can Xu"", ""Dongyan Zhao"", ""Rui Yan""]",[],,2002.10348,cs.CL,2020-02-24 16:20:32+00:00,2020-02-24 16:20:32+00:00
rJeKjwvclx,2017,Accept (Poster),False,Dynamic Coattention Networks For Question Answering,"[""Caiming Xiong"", ""Victor Zhong"", ""Richard Socher""]","[""Natural language processing"", ""Deep learning"", ""Applications""]",An end-to-end dynamic neural network model for question answering that achieves the state of the art and best leaderboard performance on the Stanford QA dataset.,,,,
rJeO3aVKPB,2020,Reject,True,Faster Neural Network Training with Data Echoing,"[""Dami Choi"", ""Alexandre Passos"", ""Christopher J. Shallue"", ""George E. Dahl""]","[""systems"", ""faster training"", ""large scale""]",When training is I/O bound reuse already-read examples without losing accuracy for faster training.,1907.05550,cs.LG,2019-07-12 02:17:12+00:00,2020-05-08 01:38:51+00:00
rJePwgSYwB,2020,Reject,True,SGD Learns One-Layer Networks in WGANs,"[""Qi Lei"", ""Jason D. Lee"", ""Alexandros G. Dimakis"", ""Constantinos Daskalakis""]","[""Wasserstein GAN"", ""global min-max"", ""one-layer network""]",We show that stochastic gradient descent ascent converges to a global optimum for WGAN with one-layer generator network.,1910.07030,cs.LG,2019-10-15 20:01:27+00:00,2020-07-02 02:35:27+00:00
rJeQYjRqYX,2019,Reject,False,Effective Path: Know the Unknowns of Neural Network,"[""Yuxian Qiu"", ""Jingwen Leng"", ""Yuhao Zhu"", ""Quan Chen"", ""Chao Li"", ""Minyi Guo""]",[],,,,,
rJeQoCNYDS,2020,Accept (Poster),True,Single Episode Policy Transfer in Reinforcement Learning,"[""Jiachen Yang"", ""Brenden Petersen"", ""Hongyuan Zha"", ""Daniel Faissol""]","[""transfer learning"", ""reinforcement learning""]","Single episode policy transfer in a family of environments with related dynamics, via optimized probing for rapid inference of latent variables and immediate execution of a universal policy.",1910.07719,cs.LG,2019-10-17 05:37:50+00:00,2020-02-12 19:54:41+00:00
rJeU_1SFvr,2020,Reject,False,LOGAN:  Latent Optimisation for Generative Adversarial Networks,"[""Yan Wu"", ""Jeff Donahue"", ""David Balduzzi"", ""Karen Simonyan"", ""Timothy Lillicrap""]","[""GAN"", ""adversarial training"", ""generative model"", ""game theory""]",Latent optimisation improves adversarial training dynamics. We present both theoretical analysis and state-of-the-art image generation with ImageNet 128x128.,1912.00953,cs.LG,2019-12-02 17:30:05+00:00,2020-07-01 16:53:32+00:00
rJeW1yHYwH,2020,Accept (Poster),False,Inductive representation learning on temporal graphs,"[""da Xu"", ""chuanwei ruan"", ""evren korpeoglu"", ""sushant kumar"", ""kannan achan""]","[""temporal graph"", ""inductive representation learning"", ""functional time encoding"", ""self-attention""]",,2002.07962,cs.LG,2020-02-19 02:05:37+00:00,2020-02-19 02:05:37+00:00
rJeXCo0cYX,2019,Accept (Poster),False,BabyAI: A Platform to Study the Sample Efficiency of Grounded Language Learning,"[""Maxime Chevalier-Boisvert"", ""Dzmitry Bahdanau"", ""Salem Lahlou"", ""Lucas Willems"", ""Chitwan Saharia"", ""Thien Huu Nguyen"", ""Yoshua Bengio""]","[""language"", ""learning"", ""efficiency"", ""imitation learning"", ""reinforcement learning""]",We present the BabyAI platform for studying data efficiency of language learning with a human in the loop,,,,
rJeXDANKwr,2020,Reject,False,NADS: Neural Architecture Distribution Search for Uncertainty Awareness,"[""Randy Ardywibowo"", ""Shahin Boluki"", ""Xinyu Gong"", ""Zhangyang Wang"", ""Xiaoning Qian""]","[""Neural Architecture Search"", ""Bayesian ensembling"", ""out-of-distribution detection"", ""uncertainty quantification"", ""density estimation""]",We propose an architecture search method to identify a distribution of architectures and use it to construct a Bayesian ensemble for outlier detection.,2006.06646,cs.LG,2020-06-11 17:39:07+00:00,2020-06-11 17:39:07+00:00
rJeXS04FPH,2020,Accept (Poster),False,DeFINE: Deep Factorized Input Token Embeddings for Neural Sequence Modeling,"[""Sachin Mehta"", ""Rik Koncel-Kedziorski"", ""Mohammad Rastegari"", ""Hannaneh Hajishirzi""]","[""sequence modeling"", ""input representations"", ""language modeling"", ""word embedding""]","DeFINE uses a deep, hierarchical, sparse network with new skip connections to learn better word embeddings efficiently. ",1911.12385,cs.CL,2019-11-27 19:09:41+00:00,2020-02-06 01:32:06+00:00
rJeZS3RcYm,2019,Reject,False,Simple Black-box Adversarial Attacks,"[""Chuan Guo"", ""Jacob R. Gardner"", ""Yurong You"", ""Andrew G. Wilson"", ""Kilian Q. Weinberger""]",[],,,,,
rJe_cyrKPB,2020,Reject,False,GroSS Decomposition: Group-Size Series Decomposition for Whole Search-Space Training,"[""Henry Howard-Jenkins"", ""Yiwen Li"", ""Victor Adrian Prisacariu""]","[""architecture search"", ""block term decomposition"", ""network decomposition"", ""network acceleration"", ""group convolution""]",A decomposition method which allows for simultaneous training of an entire search space of group convolution architectures. ,,,,
rJebgkSFDB,2020,Reject,False,Learning to Learn Kernels with Variational Random Features,"[""Haoliang Sun"", ""Yingjun Du"", ""Jun Xu"", ""Yilong Yin"", ""Xiantong Zhen"", ""Ling Shao""]","[""Meta-learning"", ""few-shot learning"", ""Random Fourier Feature"", ""Kernel learning""]",A novel meta-learning approach for few-shot classification and regression that achieves strong performance with meta variational random features by leveraging variational inference to learn adaptive kernels.,,,,
rJecSyHtDS,2020,Reject,False,Learning to Recognize the Unseen Visual Predicates,"[""Defa Zhu"", ""Si Liu"", ""Wentao Jiang"", ""Guanbin Li"", ""Tianyi Wu"", ""Guodong Guo""]","[""Visual Relationship Detection"", ""Scene Graph Generation"", ""Knowledge"", ""Zero-shot Learning""]",We propose and address a new problem named predicate zero-shot learning in visual relationship recognition. ,,,,
rJecbgHtDH,2020,Reject,False,A Boolean Task Algebra for Reinforcement Learning,"[""Geraud Nangue Tasse"", ""Steven James"", ""Benjamin Rosman""]","[""Reinforcement Learning"", ""Transfer"", ""Composition"", ""Lifelong"", ""Multi-task"", ""Deep Reinforcement learning""]",We formalise the composition of tasks as a Boolean algebra and provide a method for producing the optimal value functions of the composed tasks with no further learning.,2001.01394,cs.LG,2020-01-06 04:46:25+00:00,2020-10-15 17:45:49+00:00
rJed6j0cKX,2019,Accept (Poster),False,Analyzing Inverse Problems with Invertible Neural Networks,"[""Lynton Ardizzone"", ""Jakob Kruse"", ""Carsten Rother"", ""Ullrich K\u00f6the""]","[""Inverse problems"", ""Neural Networks"", ""Uncertainty"", ""Invertible Neural Networks""]",To analyze inverse problems with Invertible Neural Networks,,,,
rJedV3R5tm,2019,Accept (Poster),False,RelGAN: Relational Generative Adversarial Networks for Text Generation,"[""Weili Nie"", ""Nina Narodytska"", ""Ankit Patel""]","[""RelGAN"", ""text generation"", ""relational memory"", ""Gumbel-Softmax relaxation"", ""multiple embedded representations""]",,,,,
rJedbn0ctQ,2019,Reject,False,Zero-training Sentence Embedding via Orthogonal Basis,"[""Ziyi Yang"", ""Chenguang Zhu"", ""Weizhu Chen""]","[""Natural Language Processing"", ""Sentence Embeddings""]",A simple and training-free approach for sentence embeddings with competitive performance compared with sophisticated models requiring either large amount of training data or prolonged training time.,,,,
rJeeKTNKDB,2020,Reject,True,Hierarchical Graph-to-Graph Translation for Molecules,"[""Wengong Jin"", ""Regina Barzilay"", ""Tommi Jaakkola""]","[""graph generation"", ""deep learning""]","We propose a multi-resolution, hierarchically coupled encoder-decoder for graph-to-graph translation.",1907.11223,physics.chem-ph,2019-06-11 21:50:42+00:00,2019-10-18 19:52:58+00:00
rJeg7TEYwB,2020,Accept (Poster),False,Pruned Graph Scattering Transforms,"[""Vassilis N. Ioannidis"", ""Siheng Chen"", ""Georgios B. Giannakis""]","[""Graph scattering transforms"", ""pruning"", ""graph convolutional networks"", ""stability"", ""deep learning""]",,,,,
rJehNT4YPr,2020,Accept (Poster),False,I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively,"[""Haotao Wang"", ""Tianlong Chen"", ""Zhangyang Wang"", ""Kede Ma""]","[""model comparison""]","We present an efficient and adaptive framework for comparing image classifiers to maximize the discrepancies between the classifiers, in place of comparing on fixed test sets.",2002.10648,cs.LG,2020-02-25 03:32:29+00:00,2020-02-25 03:32:29+00:00
rJehVyrKwH,2020,Accept (Spotlight),True,And the Bit Goes Down: Revisiting the Quantization of Neural Networks,"[""Pierre Stock"", ""Armand Joulin"", ""R\u00e9mi Gribonval"", ""Benjamin Graham"", ""Herv\u00e9 J\u00e9gou""]","[""compression"", ""quantization""]",Using a structured quantization technique aiming at better in-domain reconstruction to compress convolutional neural networks,1907.05686,cs.CV,2019-07-12 11:52:54+00:00,2020-11-09 10:11:15+00:00
rJehf0VKwS,2020,Reject,False,Proactive Sequence Generator via Knowledge Acquisition,"[""Qing Sun"", ""James Cross"", ""Dmitriy Genzel""]","[""neural machine translation"", ""knowledge distillation"", ""exposure bias"", ""reinforcement learning""]","We develop a knowledge acquisition framework to transfer knowledge from larger sequence models to small models, which helps to alleviate exposure bias. We observed +0.7-1.1 BLEU gains on benchmark datasets",,,,
rJehllrtDS,2020,Reject,False,Rethinking deep active learning: Using unlabeled data at model training,"[""Oriane Sim\u00e9oni"", ""Mateusz Budnik"", ""Yannis Avrithis"", ""Guillaume Gravier""]","[""active learning"", ""deep learning"", ""semi-supervised learning"", ""unsupervised feature learning""]","We revisit deep active learning be making use of the unlabeled data through unsupervised and semi-supervised learning, allowing us to improve drastically the results using the same annotation effort.",,,,
rJeidA4KvS,2020,Reject,False,Role-Wise Data Augmentation for Knowledge Distillation,"[""Jie Fu"", ""Xue Geng"", ""Bohan Zhuang"", ""Xingdi Yuan"", ""Adam Trischler"", ""Jie Lin"", ""Vijay Chandrasekhar"", ""Chris Pal""]","[""Data Augmentation"", ""Knowledge Distillation""]",We study whether and how adaptive data augmentation and knowledge distillation can be leveraged simultaneously in a synergistic manner for better training student networks.,,,,
rJejta4KDS,2020,Reject,False,SELF-KNOWLEDGE DISTILLATION ADVERSARIAL ATTACK,"[""Ma Xiaoxiong[1]"", ""Wang Renzhi[1]"", ""Tian Cong"", ""Dong Zeqian"", ""Duan Zhenhua""]","[""Adversarial Examples"", ""Transferability"", ""black-box targeted attack"", ""Distillation""]",,,,,
rJel41BtDH,2020,Reject,True,Pseudo-Labeling and Confirmation Bias in Deep Semi-Supervised Learning,"[""Eric Arazo"", ""Diego Ortego"", ""Paul Albert"", ""Noel E. O'Connor"", ""Kevin McGuinness""]","[""Semi-supervised learning"", ""pseudo-labeling"", ""deep semi-supervised learning"", ""confirmation bias"", ""image classification""]","Pseudo-labeling has shown to be a weak alternative for semi-supervised learning. We, conversely, demonstrate that dealing with confirmation bias with several regularizations makes pseudo-labeling a suitable approach.",1908.02983,cs.CV,2019-08-08 09:17:54+00:00,2020-06-29 08:18:31+00:00
rJeqeCEtvH,2020,Accept (Poster),True,Semi-Supervised Generative Modeling for Controllable Speech Synthesis,"[""Raza Habib"", ""Soroosh Mariooryad"", ""Matt Shannon"", ""Eric Battenberg"", ""RJ Skerry-Ryan"", ""Daisy Stanton"", ""David Kao"", ""Tom Bagby""]","[""TTS"", ""Speech Synthesis"", ""Semi-supervised Models"", ""VAE"", ""disentanglement""]",,1910.01709,cs.CL,2019-10-03 20:18:45+00:00,2019-10-03 20:18:45+00:00
rJerHlrYwH,2020,Reject,False,Data-Efficient Image Recognition with Contrastive Predictive Coding,"[""Olivier J Henaff"", ""Aravind Srinivas"", ""Jeffrey De Fauw"", ""Ali Razavi"", ""Carl Doersch"", ""S. M. Ali Eslami"", ""Aaron van den Oord""]","[""Deep learning"", ""representation learning"", ""contrastive methods"", ""unsupervised learning"", ""self-supervised learning"", ""vision"", ""data-efficiency""]",Unsupervised representations learned with Contrastive Predictive Coding enable data-efficient image classification.,,,,
rJeuMREKwS,2020,Reject,False,Using Logical Specifications of Objectives in Multi-Objective Reinforcement Learning,"[""Kolby Nottingham"", ""Anand Balakrishnan"", ""Jyotirmoy Deshmukh"", ""Connor Christopherson"", ""David Wingate""]","[""reinforcement learning"", ""multi-objective"", ""multi-task"", ""propositional logic""]","We present a multi-objective reinforcement learning agent able to generalize, post-training, to novel behaviors specified by a custom language based on propositional logic.",,,,
rJevYoA9Fm,2019,Accept (Poster),False,The Singular Values of Convolutional Layers,"[""Hanie Sedghi"", ""Vineet Gupta"", ""Philip M. Long""]","[""singular values"", ""operator norm"", ""convolutional layers"", ""regularization""]","We characterize the singular values of the linear transformation associated with a standard 2D multi-channel convolutional layer, enabling their efficient computation. ",,,,
rJf0BjAqYX,2019,Reject,False,Like What You Like: Knowledge Distill via Neuron Selectivity Transfer,"[""Zehao Huang"", ""Naiyan Wang""]","[""Knowledge Distill""]",We treat knowledge distill as a distribution matching problem and adopt Maximum Mean Discrepancy to minimize the distances between student features and teacher features.,,,,
rJfMusFll,2017,Accept (Poster),False,Batch Policy Gradient  Methods for  Improving Neural Conversation Models,"[""Kirthevasan Kandasamy"", ""Yoram Bachrach"", ""Ryota Tomioka"", ""Daniel Tarlow"", ""David Carter""]","[""Natural language processing"", ""Reinforcement Learning""]",,,,,
rJfUCoR5KX,2019,Accept (Poster),False,An Empirical study of Binary Neural Networks' Optimisation,"[""Milad Alizadeh"", ""Javier Fern\u00e1ndez-Marqu\u00e9s"", ""Nicholas D. Lane"", ""Yarin Gal""]","[""binary neural networks"", ""quantized neural networks"", ""straight-through-estimator""]",,,,,
rJfW5oA5KQ,2019,Accept (Poster),False,Approximability of Discriminators Implies Diversity in GANs,"[""Yu Bai"", ""Tengyu Ma"", ""Andrej Risteski""]","[""Theory"", ""Generative adversarial networks"", ""Mode collapse"", ""Generalization""]","GANs can in principle learn distributions sample-efficiently, if the discriminator class is compact and has strong distinguishing power against the particular generator class.",,,,
rJg3zxBYwH,2020,Reject,False,Learning Likelihoods with Conditional Normalizing Flows ,"[""Christina Winkler"", ""Daniel Worrall"", ""Emiel Hoogeboom"", ""Max Welling""]","[""Likelihood learning"", ""conditional normalizing flows"", ""generative modelling"", ""super-resolution"", ""vessel segmentation""]",,1912.00042,cs.LG,2019-11-29 19:17:58+00:00,2019-11-29 19:17:58+00:00
rJg46kHYwH,2020,Reject,True,Adaptive Generation of Unrestricted Adversarial Inputs,"[""Isaac Dunn"", ""Hadrien Pouget"", ""Tom Melham"", ""Daniel Kroening""]","[""Adversarial Examples"", ""Adversarial Robustness"", ""Generative Adversarial Networks"", ""Image Classification""]",Training GANs to generate unrestricted adversarial examples,1905.02463,cs.LG,2019-05-07 10:54:43+00:00,2019-10-01 12:43:55+00:00
rJg4J3CqFm,2019,Accept (Poster),False,Learning Embeddings into Entropic Wasserstein Spaces,"[""Charlie Frogner"", ""Farzaneh Mirzazadeh"", ""Justin Solomon""]","[""Embedding"", ""Wasserstein"", ""Sinkhorn"", ""Optimal Transport""]",We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.,,,,
rJg4YGWRb,2018,Reject,False,Attention-based Graph Neural Network for Semi-supervised Learning,"[""Kiran K. Thekumparampil"", ""Sewoong Oh"", ""Chong Wang"", ""Li-Jia Li""]","[""Graph Neural Network"", ""Attention"", ""Semi-supervised Learning""]",We propose a novel attention-based interpretable Graph Neural Network architecture which outperforms the current state-of-the-art Graph Neural Networks in standard benchmark datasets,,,,
rJg6ssC5Y7,2019,Accept (Poster),False,DeepOBS: A Deep Learning Optimizer Benchmark Suite,"[""Frank Schneider"", ""Lukas Balles"", ""Philipp Hennig""]","[""deep learning"", ""optimization""]","We provide a software package that drastically simplifies, automates, and improves the evaluation of deep learning optimizers.",1903.05499,cs.LG,2019-03-13 14:05:31+00:00,2019-03-13 14:05:31+00:00
rJg76kStwH,2020,Accept (Poster),False,Efficient Probabilistic Logic Reasoning with Graph Neural Networks,"[""Yuyu Zhang"", ""Xinshi Chen"", ""Yuan Yang"", ""Arun Ramamurthy"", ""Bo Li"", ""Yuan Qi"", ""Le Song""]","[""probabilistic logic reasoning"", ""Markov Logic Networks"", ""graph neural networks""]",We employ graph neural networks in the variational EM framework for efficient inference and learning of Markov Logic Networks.,2001.11850,cs.AI,2020-01-29 23:34:36+00:00,2020-02-04 01:10:16+00:00
rJg7BA4YDr,2020,Reject,False,NEURAL EXECUTION ENGINES,"[""Yujun Yan"", ""Kevin Swersky"", ""Danai Koutra"", ""Parthasarathy Ranganathan"", ""Milad Hashemi""]","[""neural computation"", ""strong generalization"", ""numerical reasoning""]","We propose neural execution engines (NEEs), which leverage a learned mask and supervised execution traces to mimic the functionality of subroutines and demonstrate strong generalization.",,,,
rJg851rYwH,2020,Reject,False,"Making the Shoe Fit: Architectures, Initializations, and Tuning for Learning with Privacy","[""Nicolas Papernot"", ""Steve Chien"", ""Shuang Song"", ""Abhradeep Thakurta"", ""Ulfar Erlingsson""]","[""differential privacy"", ""deep learning""]",,,,,
rJg8NertPr,2020,Reject,False,Top-down training for neural networks,"[""Shucong Zhang"", ""Cong-Thanh Do"", ""Rama Doddipatla"", ""Erfan Loweimi"", ""Peter Bell"", ""Steve Renals""]","[""Neural network training"", ""speech recognition""]",,,,,
rJg8TeSFDH,2020,Accept (Spotlight),True,An Exponential Learning Rate Schedule for Deep Learning,"[""Zhiyuan Li"", ""Sanjeev Arora""]","[""batch normalization"", ""weight decay"", ""learning rate"", ""deep learning theory""]","We propose an exponentially growing learning rate schedule for networks with BatchNorm, which surprisingly performs well in practice and is provably equivalent to popular LR schedules like Step Decay.",1910.07454,cs.LG,2019-10-16 16:22:58+00:00,2019-11-21 11:01:34+00:00
rJg8yhAqKm,2019,Accept (Poster),False,InfoBot: Transfer and Exploration via the Information Bottleneck,"[""Anirudh Goyal"", ""Riashat Islam"", ""DJ Strouse"", ""Zafarali Ahmed"", ""Hugo Larochelle"", ""Matthew Botvinick"", ""Yoshua Bengio"", ""Sergey Levine""]","[""Information bottleneck"", ""policy transfer"", ""policy generalization"", ""exploration""]",Training agents with goal-policy information bottlenecks promotes transfer and yields a powerful exploration bonus,,,,
rJg9OANFwS,2020,Reject,False,Topic Models with Survival Supervision: Archetypal Analysis and Neural Approaches,"[""George H. Chen"", ""Linhong Li"", ""Ren Zuo"", ""Amanda Coston"", ""Jeremy C. Weiss""]",[],,,,,
rJgBd2NYPH,2020,Accept (Poster),False,Learning deep graph matching with channel-independent embedding and Hungarian attention,"[""Tianshu Yu"", ""Runzhong Wang"", ""Junchi Yan"", ""Baoxin Li""]","[""deep graph matching"", ""edge embedding"", ""combinatorial problem"", ""Hungarian loss""]","We proposed a deep graph matching method with novel channel-independent embedding and Hungarian loss, which achieved state-of-the-art performance.",,,,
rJgCOySYwH,2020,Reject,False,Function Feature Learning of Neural Networks,"[""Guangcong Wang"", ""Jianhuang Lai"", ""Guangrun Wang"", ""Wenqi Liang""]",[],,,,,
rJgD2ySFDr,2020,Reject,False,Neural Communication Systems with Bandwidth-limited Channel,"[""Karen Ullrich"", ""Fabio Viola"", ""Danilo J. Rezende""]","[""variational inference"", ""joint coding"", ""bandwidth-limited channel"", ""deep learning"", ""representation learning"", ""compression""]",We learn neural joint coding with bandwidth-limited channel models. ,,,,
rJgDT04twH,2020,Reject,False,Deep Reinforcement Learning with Implicit Human Feedback,"[""Duo Xu"", ""Mohit Agarwal"", ""Raghupathy Sivakumar"", ""Faramarz Fekri""]","[""Error-Potentials"", ""Implicit Human Feedback"", ""Deep Reinforcement Learning"", ""Human-assistance""]","We use implicit human feedback (via error-potentials, EEG) to accelerate and optimize the training of a DRL algorithm, in a practical manner.",,,,
rJgDb1SFwB,2020,Reject,False,MGP-AttTCN: An Interpretable Machine Learning Model for the Prediction of Sepsis,"[""Margherita Rosnati"", ""Vincent Fortuin""]","[""time series analysis"", ""interpretability"", ""Gaussian Processes"", ""attention neural networks""]",We propose MGP-AttTCN: a joint multitask Gaussian Process and attention-based deep learning model to early predict the occurrence of sepsis in an interpretable  and robust manner.,,,,
rJgE9CEYPS,2020,Reject,False,Discriminability Distillation in Group Representation Learning,"[""Manyuan Zhang\uff0cGuanglu Song\uff0cYu Liu\uff0cHang Zhou""]",[],,,,,
rJgFDnEYPr,2020,Reject,False,Count-guided Weakly Supervised Localization Based on Density Map,"[""Ming Ma"", ""Stephan Chalup"", ""Fayeem Aziz"", ""Yang Liu"", ""Defu Cheng"", ""Zhijian Zhou""]","[""Semi-supervised Learning"", ""Weakly Supervised Localization"", ""Variational Autoencoder"", ""Density Map"", ""Counting""]",This paper uses the density map for counting to localize objects and proposes a method that helps generate cleaner density maps.,,,,
rJgFjREtwr,2020,Reject,False,Distribution-Guided Local Explanation for Black-Box Classifiers,"[""Weijie Fu"", ""Meng Wang"", ""Mengnan Du"", ""Ninghao Liu"", ""Shijie Hao"", ""Xia Hu""]","[""explanation"", ""cnn"", ""saliency map""]",distribution-guided local explanation framework to provide discriminative saliency maps with easy-to-set hyper-parameters,,,,
rJgHC2VKvB,2020,Reject,False,Recurrent Neural Networks are Universal Filters,"[""Wenjie Xu"", ""Xiuqiong Chen"", ""Stephen S.-T. Yau""]","[""Recurrent Neural Networks"", ""Expressive Power"", ""Deep Learning Theory""]",We show that recurrent neural networks can approximate a large class of optimal filters.,,,,
rJgJDAVKvB,2020,Accept (Spotlight),True,Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees,"[""Binghong Chen"", ""Bo Dai"", ""Qinjie Lin"", ""Guo Ye"", ""Han Liu"", ""Le Song""]","[""learning to plan"", ""representation learning"", ""learning to design algorithm"", ""reinforcement learning"", ""meta learning""]",We propose a meta path planning algorithm which exploits a novel attention-based neural module that can learn generalizable structures from prior experiences to drastically reduce the sample requirement for solving new path planning problems.,1903.00070,cs.LG,2019-02-28 20:53:13+00:00,2020-02-23 08:49:42+00:00
rJgLlAVYPr,2020,Reject,False,White Box Network: Obtaining a right composition ordering of functions,"[""Eun saem Lee"", ""Hyung Ju Hwang""]","[""white box"", ""black box"", ""function composition"", ""neural network"", ""ordering functions"", ""reverse engineering"", ""programmable logic controller"", ""plc"", ""white box network"", ""WBN""]","We presented a new model called the WBN, which obtains the exact order and correct inputs of function blocks to compose them for constructing target functions.",,,,
rJgMlhRctm,2019,Accept (Oral),False,"The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision","[""Jiayuan Mao"", ""Chuang Gan"", ""Pushmeet Kohli"", ""Joshua B. Tenenbaum"", ""Jiajun Wu""]","[""Neuro-Symbolic Representations"", ""Concept Learning"", ""Visual Reasoning""]","We propose the Neuro-Symbolic Concept Learner (NS-CL), a model that learns visual concepts, words, and semantic parsing of sentences without explicit supervision on any of them.",,,,
rJgP7hR5YQ,2019,Reject,False,COMPOSITION AND DECOMPOSITION OF GANS,"[""Yeu-Chern Harn"", ""Zhenghao Chen"", ""Vladimir Jojic""]",[],GANs can be composed to build more complex models and decomposed to obtain building blocks,,,,
rJgPFgHFwr,2020,Reject,False,Laconic Image Classification: Human vs. Machine Performance,"[""Javier Carrasco"", ""Aidan Hogan"", ""Jorge P\u00e9rez""]","[""minimal images"", ""entropy"", ""human vs. machine performance""]",A framework for minimal entropy image classification and a comparison between machines and humans,,,,
rJgQkT4twH,2020,Accept (Poster),False,Analysis of Video Feature Learning in Two-Stream CNNs on the Example of Zebrafish Swim Bout Classification,"[""Bennet Breier"", ""Arno Onken""]","[""convolutional neural networks"", ""neural network transparency"", ""AI explainability"", ""deep Taylor decomposition"", ""supervised classification"", ""zebrafish"", ""transparency"", ""behavioral research"", ""optical flow""]",We demonstrate the utility of a recent AI explainability technique by visualizing the learned features of a CNN trained on binary classification of zebrafish movements.,1912.09857,cs.CV,2019-12-20 14:51:35+00:00,2019-12-20 14:51:35+00:00
rJgRMkrtDr,2020,Reject,True,Learning Video Representations using Contrastive Bidirectional Transformer,"[""Chen Sun"", ""Fabien Baradel"", ""Kevin Murphy"", ""Cordelia Schmid""]","[""self-supervised learning"", ""video representations"", ""cross-modal learning""]",Generalized BERT for continuous and cross-modal inputs; state-of-the-art self-supervised video representations.,1906.05743,cs.LG,2019-06-13 15:03:52+00:00,2019-09-27 21:59:59+00:00
rJgSV3AqKQ,2019,Reject,False,Combining adaptive algorithms and hypergradient method: a performance and robustness study,"[""Akram Erraqabi"", ""Nicolas Le Roux""]","[""optimization"", ""adaptive methods"", ""learning rate decay""]","We provide a study trying to see how the recent online learning rate adaptation extends the conclusion made by Wilson et al. 2018 about adaptive gradient methods, along with comparison and sensitivity analysis.",,,,
rJgSk04tDH,2020,Reject,True,Why Does Hierarchy (Sometimes) Work So Well in Reinforcement Learning?,"[""Ofir Nachum"", ""Haoran Tang"", ""Xingyu Lu"", ""Shixiang Gu"", ""Honglak Lee"", ""Sergey Levine""]","[""rl"", ""hierarchy"", ""reinforcement learning""]",We perform a methodical evaluation of the benefits of hierarchy and find that oftentimes explicitly imposed hierarchical structures are not necessary for good performance.,1909.10618,cs.LG,2019-09-23 21:11:30+00:00,2019-12-30 17:21:22+00:00
rJgTTjA9tX,2019,Accept (Poster),False,The Comparative Power of ReLU Networks and Polynomial Kernels in the Presence of Sparse Latent Structure,"[""Frederic Koehler"", ""Andrej Risteski""]","[""theory"", ""representational power"", ""universal approximators"", ""polynomial kernels"", ""latent sparsity"", ""beyond worst case"", ""separation result""]",Beyond-worst-case analysis of the representational power of  ReLU nets & polynomial kernels  -- in particular in the presence of sparse latent structure.,,,,
rJgTciR9tm,2019,Reject,False,Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy,"[""Gaurav Gupta"", ""Mohamed Ridha Znaidi"", ""Paul Bogdan""]","[""compact representation"", ""perception"", ""dynamical systems"", ""information bottleneck""]",Compact perception of dynamical process,,,,
rJgUfTEYvH,2020,Accept (Poster),True,VideoFlow: A Conditional Flow-Based Model for Stochastic Video Generation,"[""Manoj Kumar"", ""Mohammad Babaeizadeh"", ""Dumitru Erhan"", ""Chelsea Finn"", ""Sergey Levine"", ""Laurent Dinh"", ""Durk Kingma""]","[""Video generation"", ""flow-based generative models"", ""stochastic video prediction""]",We demonstrate that flow-based generative models offer a viable and competitive approach to generative modeling of video.,1903.01434,cs.CV,2019-03-04 18:55:45+00:00,2020-02-12 16:55:25+00:00
rJgVwTVtvS,2020,Reject,False,Gradient Perturbation is Underrated for Differentially Private Convex Optimization,"[""Da Yu"", ""Huishuai Zhang"", ""Wei Chen"", ""Tie-yan Liu"", ""Jian Yin""]","[""minimum curvature"", ""gradient perturbation"", ""DP-GD"", ""DP-SGD""]","We establish a new and tighter utility guarantee for DP-GD and DP-SGD, and justify the advantage of gradient perturbation theoretically over output/objective pertubation.",,,,
rJgYxn09Fm,2019,Accept (Poster),False,Learning Implicitly Recurrent CNNs Through Parameter Sharing,"[""Pedro Savarese"", ""Michael Maire""]","[""deep learning"", ""architecture search"", ""computer vision""]",We propose a method that enables CNN folding to create recurrent connections,,,,
rJg_1L5gg,2017,Reject,False,Incremental Sequence Learning,"[""Edwin D. de Jong""]","[""Deep learning"", ""Supervised Learning""]","We investigate a technique for sequence learning where the initial parts of the sequences are learned first; this is found to not only greatly speed up learning, but moreover to strongly improve generalization performance.",,,,
rJg_NjCqtX,2019,Reject,False,CHEMICAL NAMES STANDARDIZATION USING NEURAL SEQUENCE TO SEQUENCE MODEL,"[""Junlang Zhan"", ""Hai Zhao""]","[""Chemical Names Standardization"", ""Byte Pair Encoding"", ""Sequence to Sequence Model""]",We designed an end-to-end framework using sequence to sequence model to do the  chemical names standardization.,,,,
rJgbSn09Ym,2019,Accept (Poster),False,"Learning Particle Dynamics for Manipulating Rigid Bodies, Deformable Objects, and Fluids","[""Yunzhu Li"", ""Jiajun Wu"", ""Russ Tedrake"", ""Joshua B. Tenenbaum"", ""Antonio Torralba""]","[""Dynamics modeling"", ""Control"", ""Particle-Based Representation""]","Learning particle dynamics with dynamic interaction graphs for simulating and control rigid bodies, deformable objects, and fluids. ",,,,
rJgffkSFPS,2020,Reject,False,Multi-objective Neural Architecture Search via Predictive Network Performance Optimization,"[""Han Shi"", ""Renjie Pi"", ""Hang Xu"", ""Zhenguo Li"", ""James T. Kwok"", ""Tong Zhang""]",[],,,,,
rJgfjjC9Ym,2019,Reject,False,Backprop with Approximate Activations for Memory-efficient Network Training,"[""Ayan Chakrabarti"", ""Benjamin Moseley""]","[""Back-propagation"", ""Memory Efficient Training"", ""Approximate Gradients"", ""Deep Learning""]","An algorithm to reduce the amount of memory required for training deep networks, based on an approximation strategy.",,,,
rJggX0EKwS,2020,Reject,False,The Benefits of Over-parameterization at Initialization in Deep ReLU Networks,"[""Devansh Arpit"", ""Yoshua Bengio""]","[""deep relu networks"", ""he initialization"", ""norm preserving"", ""gradient preserving""]",We show that the norm of hidden activations and the norm of weight gradients are a function of the norm of input data and error at output. We relax the assumption made by previous papers that study weight initialization in deep ReLU networks.,,,,
rJgjGxrFPS,2020,Reject,False,A Simple and Scalable Shape Representation for 3D Reconstruction,"[""Mateusz Michalkiewicz"", ""Eugene Belilovsky"", ""Mahsa Baktashmotagh"", ""Anders Eriksson""]","[""Computer Vision"", ""3D Reconstruction""]",We show that a shape representation based on applying PCA to the signed distance transform can be effective for shape inference tasks.,,,,
rJgqMRVYvr,2020,Accept (Poster),True,Differentially Private Meta-Learning,"[""Jeffrey Li"", ""Mikhail Khodak"", ""Sebastian Caldas"", ""Ameet Talwalkar""]","[""Differential Privacy"", ""Meta-Learning"", ""Federated Learning""]",,1909.05830,cs.LG,2019-09-12 17:37:08+00:00,2020-02-21 17:08:10+00:00
rJgqalBKvH,2020,Reject,False,Deceptive Opponent Modeling with Proactive Network Interdiction for Stochastic Goal Recognition Control,"[""Junren Luo"", ""Wei Gao"", ""Zhiyong Liao"", ""Weilin Yuan"", ""Wanpeng Zhang"", ""Shaofei Chen""]",[],,,,,
rJgqjREtvS,2020,Reject,False,CRNet: Image Super-Resolution Using A Convolutional Sparse Coding  Inspired Network,"[""Menglei Zhang"", ""Zhou Liu"", ""Jingwei He"", ""Lei Yu""]","[""Convolutional sparse coding"", ""LISTA"", ""image super-resolution""]",,,,,
rJgsskrFwH,2020,Accept (Spotlight),True,Scaling Autoregressive Video Models,"[""Dirk Weissenborn"", ""Oscar T\u00e4ckstr\u00f6m"", ""Jakob Uszkoreit""]","[""autoregressive models"", ""video prediction"", ""generative models"", ""video generation""]",We present a novel autoregressive video generation that achieves strong results on popular datasets and produces encouraging continuations of real world videos.,1906.02634,cs.CV,2019-06-06 15:06:21+00:00,2020-02-10 19:29:56+00:00
rJguRyBYvr,2020,Reject,False,Improved Detection of Adversarial Attacks via Penetration Distortion Maximization,"[""Shai Rozenberg"", ""Gal Elidan"", ""Ran El-Yaniv""]","[""Adversarial Examples"", ""Adversarial Attacks"", ""Adversarial Defense"", ""White-Box threat models""]",Adversarial detection method based on separating class clusters in the embedding space. ,,,,
rJgvf3RcFQ,2019,Reject,False,On Inductive Biases in Deep Reinforcement Learning,"[""Matteo Hessel"", ""Hado van Hasselt"", ""Joseph Modayil"", ""David Silver""]",[],,1907.02908,cs.LG,2019-07-05 16:14:55+00:00,2019-07-05 16:14:55+00:00
rJgz8sA5F7,2019,Reject,False,HC-Net: Memory-based Incremental Dual-Network System for Continual learning,"[""Jangho Kim"", ""Jeesoo Kim"", ""Nojun Kwak""]","[""continual learning"", ""lifelong learning"", ""catastrophic forgetting""]","In this paper, we propose a network which efficiently increases its complexity without degrading the performance of previous tasks inspired by the brain system of human being",,,,
rJgzzJHtDB,2020,Accept (Poster),False,"Triple Wins: Boosting Accuracy, Robustness and Efficiency Together by Enabling Input-Adaptive Inference","[""Ting-Kuei Hu"", ""Tianlong Chen"", ""Haotao Wang"", ""Zhangyang Wang""]","[""adversarial robustness"", ""efficient inference""]","Is it possible to co-design model accuracy, robustness and efficiency to achieve their triple wins? Yes!",2002.10025,cs.CV,2020-02-24 00:40:22+00:00,2020-02-25 03:27:42+00:00
rJhR_pxCZ,2018,Reject,False,Interpretable Classification via Supervised Variational Autoencoders and Differentiable Decision Trees,"[""Eleanor Quint"", ""Garrett Wirka"", ""Jacob Williams"", ""Stephen Scott"", ""N.V. Vinodchandran""]","[""interpretable classification"", ""decision trees"", ""deep learning"", ""variational autoencoder""]",We combine differentiable decision trees with supervised variational autoencoders to enhance interpretability of classification. ,,,,
rJiNwv9gg,2017,Accept (Poster),False,Lossy Image Compression with Compressive Autoencoders,"[""Lucas Theis"", ""Wenzhe Shi"", ""Andrew Cunningham"", ""Ferenc Husz\u00e1r""]","[""Computer vision"", ""Deep learning"", ""Applications""]",A simple approach to train autoencoders to compress images as well or better than JPEG 2000.,,,,
rJiaRbk0-,2018,Reject,False,Towards Binary-Valued Gates for Robust LSTM Training ,"[""Zhuohan Li"", ""Di He"", ""Fei Tian"", ""Wei Chen"", ""Tao Qin"", ""Liwei Wang"", ""Tie-Yan Liu""]","[""recurrent neural network"", ""LSTM"", ""long-short term memory network"", ""machine translation"", ""generalization""]",We propose a new algorithm for LSTM training by learning towards binary-valued gates which we shown has many nice properties.,,,,
rJk51gJRb,2018,Invite to Workshop Track,False,Adversarial Policy Gradient for Alternating Markov Games,"[""Chao Gao"", ""Martin Mueller"", ""Ryan Hayward""]",[],,,,,
rJl-HsR9KX,2019,Reject,False,Discriminative Active Learning,"[""Daniel Gissin"", ""Shai Shalev-Shwartz""]","[""Active Learning"", ""Neural Networks""]",A new active learning algorithm for the batch mode setting using neural networks,,,,
rJl-b3RcF7,2019,Accept (Oral),False,"The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks","[""Jonathan Frankle"", ""Michael Carbin""]","[""Neural networks"", ""sparsity"", ""pruning"", ""compression"", ""performance"", ""architecture search""]",Feedforward neural networks that can have weights pruned after training could have had the same weights pruned before training,,,,
rJl05AVtwB,2020,Reject,False,Chordal-GCN: Exploiting sparsity in training large-scale graph convolutional networks,"[""Xin Jiang*"", ""Kewei Cheng*"", ""Song Jiang*"", ""Yizhou Sun""]","[""graph convolutional network"", ""semi-supervised learning""]","Chordal-GCN is a scalable graph neural network which exploits the exact graph structure (i.e., without approximation or sampling) and requires limited memory usage.",,,,
rJl0ceBtDH,2020,Reject,False,Semi-Supervised Boosting via Self Labelling,"[""Akul Goyal"", ""Yang Liu""]","[""semi-supervised learning"", ""boosting"", ""noise-resistant""]","In this paper we introduce Boosting via Self Labelling (BSL), a solution to semi-supervised boosting when there is a very limited access to labelled instances.",,,,
rJl0r3R9KX,2019,Accept (Poster),False,Regularized Learning for  Domain Adaptation under Label Shifts,"[""Kamyar Azizzadenesheli"", ""Anqi Liu"", ""Fanny Yang"", ""Animashree Anandkumar""]","[""Deep Learning"", ""Domain Adaptation"", ""Label Shift"", ""Importance Weights"", ""Generalization""]",A practical and provably guaranteed approach for training efficiently classifiers in the presence of label shifts between Source and Target data sets,,,,
rJl2E3AcF7,2019,Reject,False,Doubly Sparse: Sparse Mixture of Sparse Experts for Efficient Softmax Inference,"[""Shun Liao"", ""Ting Chen"", ""Tian Lin"", ""Chong Wang"", ""Dengyong Zhou""]","[""hierarchical softmax"", ""model compression""]","We present doubly sparse softmax, the sparse mixture of sparse of sparse experts, to improve the efficiency for softmax inference through exploiting the two-level overlapping hierarchy. ",,,,
rJl31TNYPr,2020,Accept (Poster),False,Fooling Detection Alone is Not Enough: Adversarial Attack against Multiple Object Tracking,"[""Yunhan Jia"", ""Yantao Lu"", ""Junjie Shen"", ""Qi Alfred Chen"", ""Hao Chen"", ""Zhenyu Zhong"", ""Tao Wei""]","[""Adversarial examples"", ""object detection"", ""object tracking"", ""security"", ""autonomous vehicle"", ""deep learning""]",We study the adversarial machine learning attacks against the Multiple Object Tracking mechanisms for the first time. ,,,,
rJl3S2A9t7,2019,Reject,False,Policy Optimization via Stochastic Recursive Gradient Algorithm,"[""Huizhuo Yuan"", ""Chris Junchi Li"", ""Yuhao Tang"", ""Yuren Zhou""]","[""reinforcement learning"", ""policy gradient"", ""variance reduction"", ""stochastic recursive gradient algorithm""]","This paper proposes the StochAstic Recursive Gradient Policy Optimization (SARAPO) algorithm based on the novel SARAH method, and exemplifies its advantages over existing policy gradient methods from both theory and experiments.",,,,
rJl3YC4YPH,2020,Reject,False,GUIDEGAN:  ATTENTION  BASED  SPATIAL  GUIDANCE FOR  IMAGE-TO-IMAGE TRANSLATION,"[""Yu Lin"", ""Yigong Wang"", ""Yifan Li"", ""Zhuoyi Wang"", ""Yang Gao"", ""Latifur Khan""]","[""Image-to-Image translation"", ""Attention Learning"", ""GAN""]",A general method that improves the image translation performance of GAN framework by using an attention embedded discriminator,,,,
rJl3yM-Ab,2018,Accept (Poster),True,Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering,"[""Shuohang Wang"", ""Mo Yu"", ""Jing Jiang"", ""Wei Zhang"", ""Xiaoxiao Guo"", ""Shiyu Chang"", ""Zhiguo Wang"", ""Tim Klinger"", ""Gerald Tesauro"", ""Murray Campbell""]","[""Question Answering"", ""Deep Learning""]",We propose a method that can make use of the multiple passages information for open-domain QA.,1711.05116,cs.CL,2017-11-14 14:39:51+00:00,2018-04-26 15:50:25+00:00
rJl4BsR5KX,2019,Reject,False,k-Nearest Neighbors by Means of Sequence to Sequence Deep Neural Networks and Memory Networks,"[""Yiming Xu"", ""Diego Klabjan""]",[],,,,,
rJl5MeHKvB,2020,Reject,False,Learning Through Limited Self-Supervision: Improving Time-Series Classification Without Additional Data via Auxiliary Tasks,"[""Ian Fox"", ""Harry Rubin-Falcone"", ""Jenna Wiens""]","[""Sequential Representation Learning"", ""Self-Supervision"", ""Function Approximation""]","We show that extra unlabeled data is not required for self-supervised auxiliary tasks to be useful for time series classification, and present new and effective auxiliary tasks.",,,,
rJl5rRVFvH,2020,Reject,True,Way Off-Policy Batch Deep Reinforcement Learning of Human Preferences in Dialog,"[""Natasha Jaques"", ""Asma Ghandeharioun"", ""Judy Hanwen Shen"", ""Craig Ferguson"", ""Agata Lapedriza"", ""Noah Jones"", ""Shixiang Gu"", ""Rosalind Picard""]","[""batch reinforcement learning"", ""deep learning"", ""dialog"", ""off-policy"", ""human preferences""]","We show that KL-control from a pre-trained prior can allow RL models to learn from a static batch of collected data, without the ability to explore online in the environment.",1907.00456,cs.LG,2019-06-30 20:53:19+00:00,2019-07-08 17:21:46+00:00
rJl63fZRb,2018,Accept (Poster),False,Parametrized Hierarchical Procedures for Neural Programming,"[""Roy Fox"", ""Richard Shin"", ""Sanjay Krishnan"", ""Ken Goldberg"", ""Dawn Song"", ""Ion Stoica""]","[""Neural programming"", ""Hierarchical Control""]","We introduce the PHP model for hierarchical representation of neural programs, and an algorithm for learning PHPs from a mixture of strong and weak supervision.",,,,
rJl6M2C5Y7,2019,Reject,False,Online Hyperparameter Adaptation via Amortized Proximal Optimization,"[""Paul Vicol"", ""Jeffery Z. HaoChen"", ""Roger Grosse""]","[""hyperparameters"", ""optimization"", ""learning rate adaptation""]","We introduce amortized proximal optimization (APO), a method to adapt a variety of optimization hyperparameters online during training, including learning rates, damping coefficients, and gradient variance exponents.",,,,
rJl8BhRqF7,2019,Reject,False,Improving machine classification using human uncertainty measurements,"[""Ruairidh M. Battleday"", ""Joshua C. Peterson"", ""Thomas L. Griffiths""]","[""image classification"", ""human experiments"", ""risk minimization""]",improving classifiers using human uncertainty measurements,,,,
rJl8FoRcY7,2019,Reject,False,Deep Generative Models for learning Coherent Latent Representations from Multi-Modal Data,"[""Timo Korthals"", ""Marc Hesse"", ""J\u00fcrgen Leitner""]","[""Multi-Modal Deep Generative Models"", ""Sensor Fusion"", ""Data Generation"", ""VAE""]",Deriving a general formulation of a multi-modal VAE from the joint marginal log-likelihood.,,,,
rJl8viCqKQ,2019,Reject,False,Low Latency Privacy Preserving Inference,"[""Alon Brutzkus"", ""Oren Elisha"", ""Ran Gilad-Bachrach""]","[""privacy"", ""classification"", ""homomorphic encryption"", ""neural networks""]","This work presents methods, combining neural-networks and encryptions, to make predictions while preserving the privacy of the data owner with low latency",,,,
rJlDO64KPH,2020,Reject,False,Self-Supervised Speech Recognition via Local Prior Matching,"[""Wei-Ning Hsu"", ""Ann Lee"", ""Gabriel Synnaeve"", ""Awni Hannun""]","[""speech recognition"", ""self-supervised learning"", ""language model"", ""semi-supervised learning"", ""pseudo labeling""]",on-the-fly soft pseudo-labeling with LM weighting is better than [off-line hard pseudo-labeling | alternatives] for semi-supervised speech recognition,2002.10336,cs.CL,2020-02-24 16:07:11+00:00,2020-02-24 16:07:11+00:00
rJlDnoA5Y7,2019,Accept (Poster),False,Von Mises-Fisher Loss for Training Sequence to Sequence Models with Continuous Outputs,"[""Sachin Kumar"", ""Yulia Tsvetkov""]","[""Language Generation"", ""Regression"", ""Word Embeddings"", ""Machine Translation""]",Language generation using seq2seq models which produce word embeddings instead of a softmax based distribution over the vocabulary at each step enabling much faster training while maintaining generation quality,,,,
rJlDoT4twr,2020,Reject,False,Unified Probabilistic Deep Continual Learning through Generative Replay and Open Set Recognition,"[""Martin Mundt"", ""Sagnik Majumder"", ""Iuliia Pliushch"", ""Visvanathan Ramesh""]","[""Continual Learning"", ""Open Set Recognition"", ""Probabilistic Deep Learning"", ""Variational Inference""]",Deep continual learning with a single model with open set recognition and resulting improved generative replay,,,,
rJlEojAqFm,2019,Accept (Poster),False,Relational Forward Models for Multi-Agent Learning,"[""Andrea Tacchetti"", ""H. Francis Song"", ""Pedro A. M. Mediano"", ""Vinicius Zambaldi"", ""J\u00e1nos Kram\u00e1r"", ""Neil C. Rabinowitz"", ""Thore Graepel"", ""Matthew Botvinick"", ""Peter W. Battaglia""]","[""multi-agent reinforcement learning"", ""relational reasoning"", ""forward models""]","Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.",,,,
rJlHIo09KQ,2019,Reject,False,Gradient-based Training of Slow Feature Analysis by Differentiable Approximate Whitening,"[""Merlin Sch\u00fcler"", ""Hlynur Dav\u00ed\u00f0 Hlynsson"", ""Laurenz Wiskott""]","[""Slow Feature Analysis"", ""Deep Learning"", ""Spectral Embedding"", ""Temporal Coherence""]",We propose a way to train Slow Feature Analysis with stochastic gradient descent eliminating the need for greedy layer-wise training.,,,,
rJlJ-2CqtX,2019,Reject,False,Success at any cost: value constrained model-free continuous control,"[""Steven Bohez"", ""Abbas Abdolmaleki"", ""Michael Neunert"", ""Jonas Buchli"", ""Nicolas Heess"", ""Raia Hadsell""]","[""reinforcement learning"", ""continuous control"", ""robotics"", ""constrained optimization"", ""multi-objective optimization""]","We apply constrained optimization to continuous control tasks subject to a penalty to ensure a lower bound on the return, and learn the resulting conditional Lagrangian multipliers simultaneously with the policy.",,,,
rJlMAAeC-,2018,Accept (Poster),False,Improving the Universality and Learnability of Neural Programmer-Interpreters with Combinator Abstraction,"[""Da Xiao"", ""Jo-Yu Liao"", ""Xingyuan Yuan""]","[""neural programming"", ""Neural Programmer-Interpreter""]",,,,,
rJlMBjAcYX,2019,Reject,False,Optimizing for Generalization in Machine Learning with Cross-Validation Gradients,"[""Barratt"", ""Shane"", ""Sharma"", ""Rishi""]",[],,,,,
rJlNKCNtPB,2020,Reject,True,Adaptive Learned Bloom Filter (Ada-BF): Efficient Utilization of the Classifier,"[""Zhenwei Dai"", ""Anshumali Shrivastava""]","[""Ada-BF"", ""Bloom filter"", ""machine learning"", ""memory efficient""]",Propose an efficient algorithm to improve the Bloom filter by incorporating the machine learning model in a clever way,1910.09131,cs.DS,2019-10-21 03:21:24+00:00,2019-10-21 03:21:24+00:00
rJlRKjActQ,2019,Reject,False,Manifold Mixup: Learning Better Representations by Interpolating Hidden States,"[""Vikas Verma"", ""Alex Lamb"", ""Christopher Beckham"", ""Amir Najafi"", ""Aaron Courville"", ""Ioannis Mitliagkas"", ""Yoshua Bengio""]","[""Regularizer"", ""Supervised Learning"", ""Semi-supervised Learning"", ""Better representation learning"", ""Deep Neural Networks.""]","A method for learning better representations, that acts as a regularizer and despite its no significant additional computation cost , achieves improvements over strong baselines on Supervised and Semi-supervised Learning tasks.",,,,
rJlTXxSFPr,2020,Reject,False,A Quality-Diversity Controllable GAN for Text Generation,"[""Xingyu Lou"", ""Kaihe Xu"", ""Zhongliang Li"", ""Tian Xia"", ""Shaojun Wang"", ""Jing Xiao""]","[""text generation"", ""GAN"", ""quality-diversity"", ""generalized Jensen-Shannon divergence""]",A GAN that can control quality-diversity trade-off through a single hyper-parameter and is more competitive with MLE model than other GANs variants.,,,,
rJlUhhVYvS,2020,Reject,False,Understanding Isomorphism Bias in Graph Data Sets ,"[""Ivanov Sergey"", ""Sviridov Sergey"", ""Evgeny Burnaev""]","[""graph classification"", ""data sets"", ""graph representation learning""]","Many graph classification data sets have duplicates, thus raising questions about generalization abilities and fair comparison of the models. ",,,,
rJlUt0EYwS,2020,Accept (Poster),False,Learning from Explanations with Neural Execution Tree,"[""Ziqi Wang*"", ""Yujia Qin*"", ""Wenxuan Zhou"", ""Jun Yan"", ""Qinyuan Ye"", ""Leonardo Neves"", ""Zhiyuan Liu"", ""Xiang Ren""]",[],,,,,
rJlVdREKDS,2020,Reject,False,Learning from Imperfect Annotations: An End-to-End Approach,"[""Emmanouil Antonios Platanios"", ""Maruan Al-Shedivat"", ""Eric Xing"", ""Tom Mitchell""]",[],,2004.03473,cs.LG,2020-04-07 15:21:08+00:00,2020-04-07 15:21:08+00:00
rJlWOj0qF7,2019,Accept (Poster),False,Imposing Category Trees Onto Word-Embeddings Using A Geometric Construction,"[""Tiansi Dong"", ""Chrisitan Bauckhage"", ""Hailong Jin"", ""Juanzi Li"", ""Olaf Cremers"", ""Daniel Speicher"", ""Armin B. Cremers"", ""Joerg Zimmermann""]","[""category tree"", ""word-embeddings"", ""geometry""]",we show a geometric method to perfectly encode categroy tree information into pre-trained word-embeddings.,,,,
rJlYsn4YwS,2020,Reject,False,Gradient-free Neural Network Training by Multi-convex Alternating Optimization,"[""Junxiang Wang"", ""Fuxun Yu"", ""Xiang Chen"", ""Liang Zhao""]","[""neural network"", ""alternating minimization"", ""global convergence""]",We propose a novel Deep Learning Alternating Minimization (DLAM) algorithm to solve the fully- connected neural network problem with convergence guarantee,,,,
rJl_NhR9K7,2019,Reject,False,ISA-VAE: Independent Subspace Analysis with Variational Autoencoders,"[""Jan St\u00fchmer"", ""Richard Turner"", ""Sebastian Nowozin""]","[""representation learning"", ""disentanglement"", ""interpretability"", ""variational autoencoders""]",We present structured priors for unsupervised learning of disentangled representations in VAEs that significantly mitigate the trade-off between disentanglement and reconstruction loss.,,,,
rJlcLaVFvB,2020,Reject,False,Effect of top-down connections in Hierarchical Sparse Coding,"[""Victor Boutin"", ""Angelo Franciosini"", ""Franck Ruffier"", ""Laurent Perrinet""]","[""Hierarchical Sparse Coding"", ""Convolutional Sparse Coding"", ""Top-down connections""]",This paper experimentally demonstrates the beneficial effect of top-down connections in Hierarchical Sparse Coding algorithm.,2002.00892,cs.CV,2020-02-03 17:12:01+00:00,2020-02-03 17:12:01+00:00
rJlcV2Actm,2019,Reject,False,MahiNet: A Neural Network for Many-Class Few-Shot Learning with Class Hierarchy,"[""Lu Liu"", ""Tianyi Zhou"", ""Guodong Long"", ""Jing Jiang"", ""Chengqi Zhang""]","[""deep learning"", ""many-class few-shot"", ""class hierarchy"", ""meta learning""]",A memory-augmented neural network that addresses many-class few-shot problem by leveraging class hierarchy in both supervised learning and meta-learning.,,,,
rJld3hEYvS,2020,Accept (Poster),True,Ranking Policy Gradient,"[""Kaixiang Lin"", ""Jiayu Zhou""]","[""Sample-efficient reinforcement learning"", ""off-policy learning.""]","We propose ranking policy gradient that learns the optimal rank of actions to maximize return. We propose a general off-policy learning framework with the properties of optimality preserving, variance reduction, and sample-efficiency.",1906.09674,cs.LG,2019-06-24 00:13:42+00:00,2019-11-26 16:00:15+00:00
rJleFREKDr,2020,Reject,False,Learning to Control Latent Representations for Few-Shot Learning of Named Entities,"[""Omar U. Florez"", ""Erik Mueller""]","[""Memory management"", ""neuroscience"", ""reinforcement learning"", ""learning with small data""]",We want to learning with small data by introducing a RL trainable controller that learn to write and read in an external memory.,1911.08542,cs.LG,2019-11-19 20:15:08+00:00,2019-11-19 20:15:08+00:00
rJleKgrKwS,2020,Accept (Poster),False,Differentiable learning of numerical rules in knowledge graphs,"[""Po-Wei Wang"", ""Daria Stepanova"", ""Csaba Domokos"", ""J. Zico Kolter""]","[""knowledge graphs"", ""rule learning"", ""differentiable neural logic""]",We present an efficient approach to integrating numerical comparisons into differentiable rule learning in knowledge graphs,,,,
rJleN20qK7,2019,Accept (Poster),False,Two-Timescale Networks for Nonlinear Value Function Approximation,"[""Wesley Chung"", ""Somjit Nath"", ""Ajin Joseph"", ""Martha White""]","[""Reinforcement learning"", ""policy evaluation"", ""nonlinear function approximation""]",We propose an architecture for learning value functions which allows the use of any linear policy evaluation algorithm in tandem with nonlinear feature learning.,,,,
rJlf_RVKwr,2020,Reject,False,Sensible adversarial learning,"[""Jungeum Kim"", ""Xiao Wang""]","[""adversarial learning"", ""deep neural networks"", ""trade-off"", ""margins"", ""sensible reversion"", ""sensible robustness""]",We introduce sensible robustness in an effort to resolve the trade-off between robustness and accuracy of the current adversarial robustness framework.,,,,
rJlg1n05YX,2019,Reject,False,Penetrating the Fog: the Path to Efficient CNN Models,"[""Kun Wan"", ""Boyuan Feng"", ""Shu Yang"", ""Yufei Ding""]","[""Efficient CNN models"", ""Computer Vision""]","We are the first in the field to show how to craft an effective sparse kernel design from three aspects: composition, performance and efficiency.",,,,
rJliMh09F7,2019,Accept (Poster),False,Diversity-Sensitive Conditional Generative Adversarial Networks,"[""Dingdong Yang"", ""Seunghoon Hong"", ""Yunseok Jang"", ""Tianchen Zhao"", ""Honglak Lee""]","[""Conditional Generative Adversarial Network"", ""mode-collapse"", ""multi-modal generation"", ""image-to-image translation"", ""image in-painting"", ""video prediction""]",We propose a simple and general approach that avoids a mode collapse problem in various conditional GANs.,,,,
rJljdh4KDH,2020,Accept (Spotlight),False,Multi-Scale Representation Learning  for Spatial Feature Distributions using Grid Cells,"[""Gengchen Mai"", ""Krzysztof Janowicz"", ""Bo Yan"", ""Rui Zhu"", ""Ling Cai"", ""Ni Lao""]","[""Grid cell"", ""space encoding"", ""spatially explicit model"", ""multi-scale periodic representation"", ""unsupervised learning""]", We propose a representation learning model called Space2vec to encode the absolute positions and spatial relationships of places.,2003.00824,cs.CV,2020-02-16 04:22:18+00:00,2020-02-16 04:22:18+00:00
rJlk6iRqKX,2019,Accept (Poster),False,Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach,"[""Minhao Cheng"", ""Thong Le"", ""Pin-Yu Chen"", ""Huan Zhang"", ""JinFeng Yi"", ""Cho-Jui Hsieh""]","[""Adversarial example"", ""Hard-label"", ""Black-box attack"", ""Query-efficient""]",,,,,
rJlk71rYvH,2020,Reject,False,Counterfactual Regularization for Model-Based Reinforcement Learning,"[""Lawrence Neal"", ""Li Fuxin"", ""Xiaoli Fern""]","[""Counterfactual"", ""Model-Based Reinforcement Learning""]","When training a world model, you can encode useful assumptions into the loss by using training-time counterfactuals.",,,,
rJlnB3C5Ym,2019,Accept (Poster),False,Rethinking the Value of Network Pruning,"[""Zhuang Liu"", ""Mingjie Sun"", ""Tinghui Zhou"", ""Gao Huang"", ""Trevor Darrell""]","[""network pruning"", ""network compression"", ""architecture search"", ""train from scratch""]","In structured network pruning, fine-tuning a pruned model only gives comparable performance with training it from scratch.",,,,
rJlnOhVYPS,2020,Accept (Poster),False,Mutual Mean-Teaching: Pseudo Label Refinery for Unsupervised Domain Adaptation on Person Re-identification,"[""Yixiao Ge"", ""Dapeng Chen"", ""Hongsheng Li""]","[""Label Refinery"", ""Unsupervised Domain Adaptation"", ""Person Re-identification""]",A framework that conducts online refinement of pseudo labels with a novel soft softmax-triplet loss for unsupervised domain adaptation on person re-identification.,2001.01526,cs.CV,2020-01-06 12:42:58+00:00,2020-01-30 06:37:43+00:00
rJlnfaNYvB,2020,Reject,True,Adaptive Loss Scaling for Mixed Precision Training,"[""Ruizhe Zhao"", ""Brian Vogel"", ""Tanvir Ahmed""]","[""Deep Learning"", ""Mixed Precision Training"", ""Loss Scaling"", ""Backpropagation""]",We devise adaptive loss scaling to improve mixed precision training that surpass the state-of-the-art results.,1910.12385,cs.LG,2019-10-28 00:13:08+00:00,2019-10-28 00:13:08+00:00
rJlnxkSYPS,2020,Accept (Poster),False,Unsupervised Clustering using Pseudo-semi-supervised Learning,"[""Divam Gupta"", ""Ramachandran Ramjee"", ""Nipun Kwatra"", ""Muthian Sivathanu""]","[""Unsupervised Learning"", ""Unsupervised Clustering"", ""Deep Learning""]",Using ensembles and pseudo labels for unsupervised clustering ,,,,
rJlpUiAcYX,2019,Reject,False,Holographic and other Point Set Distances for Machine Learning,"[""Lukas Balles"", ""Thomas Fischbacher""]","[""point set"", ""set"", ""permutation-invariant"", ""loss function""]",Permutation-invariant loss function for point set prediction.,,,,
rJlqoTEtDB,2020,Reject,False,PowerSGD: Powered Stochastic Gradient Descent Methods for Accelerated Non-Convex Optimization,"[""Jun Liu"", ""Beitong Zhou"", ""Weigao Sun"", ""Ruijuan Chen"", ""Claire J. Tomlin"", ""Ye Yuan""]","[""stochastic gradient descent"", ""non-convex optimization"", ""powerball function"", ""acceleration""]",We propose a new class of optimizers for accelerated non-convex optimization via a nonlinear gradient transformation. ,,,,
rJlwAa4YwS,2020,Reject,False,Lattice Representation Learning,"[""Luis A Lastras""]","[""lattices"", ""representation learning"", ""coding theory"", ""lossy source coding"", ""information theory""]",We propose to use lattices to represent objects and prove a fundamental result on how to train networks that use them.,,,,
rJm7VfZA-,2018,Accept (Poster),False,Learning Parametric Closed-Loop Policies for Markov Potential Games,"[""Sergio Valcarcel Macua"", ""Javier Zazo"", ""Santiago Zazo""]","[""Stochastic games"", ""potential games"", ""closed loop"", ""reinforcement learning"", ""multiagent systems""]",We present general closed loop analysis for Markov potential games and show that deep reinforcement learning can be used for learning approximate closed-loop Nash equilibrium.,,,,
rJma2bZCW,2018,Reject,False,Three factors influencing minima in SGD,"[""Stanis\u0142aw Jastrz\u0119bski"", ""Zac Kenton"", ""Devansh Arpit"", ""Nicolas Ballas"", ""Asja Fischer"", ""Amos Storkey"", ""Yoshua Bengio""]","[""SGD"", ""Deep Learning"", ""Generalization""]","Three factors (batch size, learning rate, gradient noise) change in predictable way the properties (e.g. sharpness) of minima found by SGD.",,,,
rJo9n9Feg,2017,Reject,False,Chess Game Concepts Emerge under Weak Supervision: A Case Study of Tic-tac-toe,"[""Hao Zhao"", ""Ming Lu"", ""Anbang Yao"", ""Yurong Chen"", ""Li Zhang""]","[""Semi-Supervised Learning""]",investigating whether a CNN understands concepts from a new perspective,,,,
rJoXrxZAZ,2018,Reject,False,HybridNet: A Hybrid Neural Architecture to Speed-up Autoregressive  Models,"[""Yanqi Zhou"", ""Wei Ping"", ""Sercan Arik"", ""Kainan Peng"", ""Greg Diamos""]","[""neural architecture"", ""inference time reduction"", ""hybrid model""]",It is a hybrid neural architecture to speed-up autoregressive model. ,,,,
rJqBEPcxe,2017,Accept (Poster),False,Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations,"[""David Krueger"", ""Tegan Maharaj"", ""Janos Kramar"", ""Mohammad Pezeshki"", ""Nicolas Ballas"", ""Nan Rosemary Ke"", ""Anirudh  Goyal"", ""Yoshua Bengio"", ""Aaron Courville"", ""Christopher Pal""]","[""Deep learning""]",Zoneout is like dropout (for RNNs) but uses identity masks instead of zero masks,,,,
rJqFGTslg,2017,Accept (Poster),False,Pruning Filters for Efficient ConvNets,"[""Hao Li"", ""Asim Kadav"", ""Igor Durdanovic"", ""Hanan Samet"", ""Hans Peter Graf""]","[""Computer vision"", ""Deep learning""]",,,,,
rJq_YBqxx,2017,Reject,False,Deep Character-Level Neural Machine Translation By Learning Morphology,"[""Shenjian Zhao"", ""Zhihua Zhang""]","[""Natural language processing"", ""Deep learning""]","We devise a character-level neural machine translation built on six recurrent networks, and obtain a  BLEU score comparable to the state-of-the-art NMT on En-Fr and Cs-En translation tasks. ",,,,
rJqfKPJ0Z,2018,Reject,False,Clipping Free Attacks Against Neural Networks,"[""Boussad ADDAD""]","[""Adversarial examples"", ""Neural Networks"", ""Clipping""]"," In this paper, a new method we call Centered Initial Attack (CIA) is provided. It insures by construction the maximum perturbation to be smaller than a threshold fixed beforehand, without the clipping process.",,,,
rJr4kfWCb,2018,Reject,False,Lung Tumor Location and Identification with AlexNet and a Custom CNN,"[""Allison M Rossetto"", ""Wenjin Zhou""]",[],,,,,
rJrTwxbCb,2018,Invite to Workshop Track,False,Empirical Analysis of the Hessian of Over-Parametrized Neural Networks,"[""Levent Sagun"", ""Utku Evci"", ""V. Ugur Guney"", ""Yann Dauphin"", ""Leon Bottou""]","[""Deep Learning"", ""Over-parametrization"", ""Hessian"", ""Eigenvalues"", ""Flat minima"", ""Large batch Small batch""]","The loss surface is *very* degenerate, and there are no barriers between large batch and small batch solutions.",,,,
rJsiFTYex,2017,Reject,False,A Way out of the Odyssey: Analyzing and Combining Recent Insights for LSTMs,"[""Shayne Longpre"", ""Sabeek Pradhan"", ""Caiming Xiong"", ""Richard Socher""]","[""Natural language processing"", ""Deep learning"", ""Supervised Learning""]","Relatively simple augmentations to the LSTM, such as Monte Carlo test time averaging, deep vector averaging, and residual connections, can yield massive accuracy improvements on text classification datasets.",,,,
rJssAZ-0-,2018,Reject,False,TRL: Discriminative Hints for Scalable Reverse Curriculum Learning,"[""Chen Wang"", ""Xiangyu Chen"", ""Zelin Ye"", ""Jialu Wang"", ""Ziruo Cai"", ""Shixiang Gu"", ""Cewu Lu""]","[""deep learning"", ""deep reinforcement learning"", ""robotics"", ""perception""]","We propose Tendency RL to efficiently solve goal-oriented tasks with large state space using automated curriculum learning and discriminative shaping reward, which has the potential to tackle robot manipulation tasks with perception.",,,,
rJv4XWZA-,2018,Reject,False,Generating Differentially Private Datasets Using GANs,"[""Aleksei Triastcyn"", ""Boi Faltings""]","[""generative adversarial networks"", ""differential privacy"", ""synthetic data""]",Train GANs with differential privacy to generate artificial privacy-preserving datasets.,,,,
rJvJXZb0W,2018,Accept (Poster),False,An efficient framework for learning sentence representations,"[""Lajanugen Logeswaran"", ""Honglak Lee""]","[""sentence"", ""embeddings"", ""unsupervised"", ""representations"", ""learning"", ""efficient""]",A framework for learning high-quality sentence representations efficiently.,,,,
rJvY_5OzoI,2022,Accept (Poster),False,Multi-Critic Actor Learning: Teaching RL Policies to Act with Style,"['Siddharth Mysore', 'George Cheng', 'Yunqi Zhao', 'Kate Saenko', 'Meng Wu']","[""Reinforcement Learning"", ""Multi-Style Learning"", ""Multi-Task Learning"", ""Actor-Critic""]","MultiCriticAL is a single-actor, multi-critic framework for multi-task reinforcement learning, where task-based critic separation provides explicit per-task value-function approximation and enables improved performance over single-critic frameworks.",,,,
rJwelMbR-,2018,Accept (Poster),False,Divide-and-Conquer Reinforcement Learning,"[""Dibya Ghosh"", ""Avi Singh"", ""Aravind Rajeswaran"", ""Vikash Kumar"", ""Sergey Levine""]","[""deep reinforcement learning"", ""reinforcement learning"", ""policy gradients"", ""model-free""]",,1711.09874,cs.LG,2017-11-27 18:46:00+00:00,2018-04-27 17:55:06+00:00
rJx0Q6EFPB,2020,Reject,False,TinyBERT: Distilling BERT for Natural Language Understanding,"[""Xiaoqi Jiao"", ""Yichun Yin"", ""Lifeng Shang"", ""Xin Jiang"", ""Xiao Chen"", ""Linlin Li"", ""Fang Wang"", ""Qun Liu""]","[""BERT Compression"", ""Transformer Distillation"", ""TinyBERT""]",,,,,
rJx1Na4Fwr,2020,Accept (Poster),False,MACER: Attack-free and Scalable Robust Training via Maximizing Certified Radius,"[""Runtian Zhai"", ""Chen Dan"", ""Di He"", ""Huan Zhang"", ""Boqing Gong"", ""Pradeep Ravikumar"", ""Cho-Jui Hsieh"", ""Liwei Wang""]","[""Adversarial Robustness"", ""Provable Adversarial Defense"", ""Randomized Smoothing"", ""Robustness Certification""]",We propose MACER: a provable defense algorithm that trains robust models by maximizing the certified radius. It does not use adversarial training but performs better than all existing provable l2-defenses.,2001.02378,cs.LG,2020-01-08 05:08:56+00:00,2020-02-15 03:02:26+00:00
rJx2slSKDS,2020,Reject,False,Latent Variables on Spheres for Sampling and Inference,"[""Deli Zhao"", ""Jiapeng Zhu"", ""Bo Zhang""]","[""variational autoencoder"", ""generative adversarial network""]",,,,,
rJx4p3NYDB,2020,Accept (Poster),True,Lazy-CFR: fast and near-optimal regret minimization for extensive games with imperfect information,"[""Yichi Zhou"", ""Tongzheng Ren"", ""Jialian Li"", ""Dong Yan"", ""Jun Zhu""]",[],,1810.04433,cs.LG,2018-10-10 09:24:39+00:00,2018-12-25 04:54:33+00:00
rJx7wlSYvB,2020,Reject,False,Differentiable Bayesian Neural Network Inference for Data Streams,"[""Namuk Park"", ""Taekyu Lee"", ""Songkuk Kim""]","[""Bayesian neural network"", ""approximate predictive inference"", ""data stream"", ""histogram""]",We propose approximate Bayesian neural network that predicts results for data stream as fast as deterministic deep neural network does,,,,
rJx8I1rFwr,2020,Reject,False,Meta-Learning by Hallucinating Useful Examples,"[""Yu-Xiong Wang"", ""Yuki Uchiyama"", ""Martial Hebert"", ""Karteek Alahari""]","[""few-shot learning"", ""meta-learning""]",,,,,
rJx8ylSKvr,2020,Reject,False,Leveraging Entanglement Entropy for Deep Understanding of  Attention Matrix in Text Matching,"[""Peng Zhang"", ""XiaoLiu Mao"", ""XinDian Ma"", ""BenYou Wang"", ""Jing Zhang"", ""Jun Wang"", ""DaWei Song""]","[""Quantum entanglement entropy"", ""Attention Matrix""]",,,,,
rJx9vaVtDS,2020,Reject,False,Individualised Dose-Response Estimation using Generative Adversarial Nets,"[""Ioana Bica"", ""James Jordon"", ""Mihaela van der Schaar""]","[""individualised dose-response estimation"", ""treatment effects"", ""causal inference"", ""generative adversarial networks""]",,,,,
rJxAo2VYwr,2020,Accept (Poster),False,Transferable Perturbations of Deep Feature Distributions,"[""Nathan Inkawhich"", ""Kevin Liang"", ""Lawrence Carin"", ""Yiran Chen""]","[""adversarial attacks"", ""transferability"", ""interpretability""]",We show that perturbations based-on intermediate feature distributions yield more transferable adversarial examples and allow for analysis of the affects of adversarial perturbations on intermediate representations.,,,,
rJxBa1HFvS,2020,Reject,False,Value-Driven Hindsight Modelling,"[""Arthur Guez"", ""Fabio Viola"", ""Theophane Weber"", ""Lars Buesing"", ""Steven Kapturowski"", ""Doina Precup"", ""David Silver"", ""Nicolas Heess""]",[],,,,,
rJxDkvqee,2017,Accept (Poster),False,Multi-view Recurrent Neural Acoustic Word Embeddings,"[""Wanjia He"", ""Weiran Wang"", ""Karen Livescu""]",[],,,,,
rJxF73R9tX,2019,Reject,False,Knows When it Doesnât Know: Deep Abstaining Classifiers,"[""Sunil Thulasidasan"", ""Tanmoy Bhattacharya"", ""Jeffrey Bilmes"", ""Gopinath Chennupati"", ""Jamal Mohd-Yusof""]","[""deep learning"", ""robust learning"", ""abstention"", ""representation learning"", ""abstaining classifier"", ""open-set detection""]",A deep abstaining neural network trained with a novel loss function that learns representations for when to abstain enabling robust learning in the presence of different types of noise.,,,,
rJxFpp4Fvr,2020,Reject,False,"Feature-Robustness, Flatness and Generalization Error for Deep Neural Networks","[""Henning Petzka"", ""Linara Adilova"", ""Michael Kamp"", ""Cristian Sminchisescu""]","[""robustness"", ""flatness"", ""generalization error"", ""loss surface"", ""deep neural networks"", ""feature space""]",We introduce a novel measure of flatness at local minima of the loss surface of deep neural networks which is invariant with respect to layer-wise reparameterizations and we connect flatness to feature robustness and generalization.,1912.00058,cs.LG,2019-11-29 20:05:35+00:00,2019-11-29 20:05:35+00:00
rJxG3pVKPB,2020,Reject,False,"Translation Between Waves,  wave2wave","[""Tsuyoshi Okita"", ""Hirotaka Hachiya"", ""Sozo Inoue"", ""Naonori Ueda""]","[""sequence to sequence model"", ""signal to signal"", ""deep learning"", ""RNN"", ""encoder-decoder model""]",,2007.10394,cs.LG,2020-07-20 18:29:09+00:00,2020-07-20 18:29:09+00:00
rJxGGlSKwH,2020,Reject,False,Sentence embedding with contrastive multi-views learning,"[""Antoine Simoulin""]","[""contrastive"", ""multi-views"", ""linguistic"", ""embedding""]",We aim to exploit the diversity of linguistic structures to build sentence representations.,,,,
rJxGLlBtwH,2020,Accept (Poster),False,On the interaction between supervision and self-play in emergent communication,"[""Ryan Lowe*"", ""Abhinav Gupta*"", ""Jakob Foerster"", ""Douwe Kiela"", ""Joelle Pineau""]","[""multi-agent communication"", ""self-play"", ""emergent languages""]",,,,,
rJxHcgStwr,2020,Reject,False,Handwritten Amharic Character Recognition System Using Convolutional Neural Networks,"[""Fetulhak Abdurahman""]","[""Amharic"", ""Handwritten"", ""Character"", ""Convolutional neural network"", ""Recognition""]",Recognition of handwritten Amharic characters based on convolutional neural network.,,,,
rJxHsjRqFQ,2019,Accept (Poster),False,Hyperbolic Attention Networks,"[""Caglar Gulcehre"", ""Misha Denil"", ""Mateusz Malinowski"", ""Ali Razavi"", ""Razvan Pascanu"", ""Karl Moritz Hermann"", ""Peter Battaglia"", ""Victor Bapst"", ""David Raposo"", ""Adam Santoro"", ""Nando de Freitas""]","[""Hyperbolic Geometry"", ""Attention Methods"", ""Reasoning on Graphs"", ""Relation Learning"", ""Scale Free Graphs"", ""Transformers"", ""Power Law""]",We propose to incorporate inductive biases and operations coming from hyperbolic geometry to improve the attention mechanism of the neural networks.,,,,
rJxMM2C5K7,2019,Reject,False,Nested Dithered Quantization for Communication Reduction in Distributed Training,"[""Afshin Abdi"", ""Faramarz Fekri""]","[""machine learning"", ""distributed training"", ""dithered quantization"", ""nested quantization"", ""distributed compression""]",The paper proposes and analyzes two quantization schemes for communicating Stochastic Gradients in distributed learning which would reduce communication costs compare to the state of the art while maintaining the same accuracy.  ,,,,
rJxNAjC5F7,2019,Reject,False,Learning Hash Codes via Hamming Distance Targets,"[""Martin Loncaric"", ""Ryan Weber"", ""Bowei Liu""]","[""information retrieval"", ""learning to hash"", ""cbir""]",We present a new loss function for training any differentiable model to hash that can vastly improve recall and lookup speed.,,,,
rJxRJeStvB,2020,Reject,True,Learning scalable and transferable multi-robot/machine sequential assignment planning via graph embedding,"[""Hyunwook Kang"", ""Aydar Mynbay"", ""James R. Morrison"", ""Jinkyoo Park""]","[""reinforcement learning"", ""multi-robot/machine"", ""scheduling"", ""planning"", ""scalability"", ""transferability"", ""mean-field inference"", ""graph embedding""]",RL can solve (stochastic) multi-robot/scheduling problems scalably and transferably using graph embedding,1905.12204,cs.LG,2019-05-29 04:02:41+00:00,2019-09-30 18:44:13+00:00
rJxRmlStDB,2020,Reject,False,Self-Induced Curriculum Learning in Neural Machine Translation,"[""Dana Ruiter"", ""Cristina Espa\u00f1a-Bonet"", ""Josef van Genabith""]","[""curriculum learning"", ""neural machine translation"", ""self-supervised learning""]",Analysis of the self-induced curriculum of a self-supervised neural machine translation system.,,,,
rJxWxxSYvB,2020,Accept (Poster),False,Spike-based causal inference for weight alignment,"[""Jordan Guerguiev"", ""Konrad Kording"", ""Blake Richards""]","[""causal"", ""inference"", ""weight"", ""transport"", ""rdd"", ""regression"", ""discontinuity"", ""design"", ""cifar10"", ""biologically"", ""plausible""]",We present a learning rule for feedback weights in a spiking neural network that addresses the weight transport problem.,,,,
rJxX8T4Kvr,2020,Accept (Poster),False,Learning Efficient Parameter Server Synchronization Policies for Distributed SGD,"[""Rong Zhu"", ""Sheng Yang"", ""Andreas Pfadler"", ""Zhengping Qian"", ""Jingren Zhou""]","[""Distributed SGD"", ""Paramter-Server"", ""Synchronization Policy"", ""Reinforcement Learning""]",We apply a reinforcement learning based approach to learning optimal synchronization policies used for Parameter Server-based distributed training  of SGD.,,,,
rJxXDsCqYX,2019,Reject,False,Sentence Encoding with Tree-Constrained Relation Networks,"[""Lei Yu"", ""Cyprien de Masson d'Autume"", ""Chris Dyer"", ""Phil Blunsom"", ""Lingpeng Kong"", ""Wang Ling""]","[""sentence encoder"", ""relation networks"", ""tree"", ""machine translation""]",,,,,
rJxYMCEFDr,2020,Reject,False,Leveraging Adversarial Examples to Obtain Robust Second-Order Representations,"[""Mohit Prabhushankar"", ""Gukyeong Kwon"", ""Dogancan Temel"", ""Ghassan AlRegib""]","[""Second-order representation"", ""adversarial examples"", ""robustness"", ""gradients""]",We introduce a robust plug-in representation based on relative positioning derived from targeted multi-class adversarial image generation.,,,,
rJx_b3RqY7,2019,Reject,False,AIM: Adversarial Inference by Matching Priors and Conditionals,"[""Hanbo Li"", ""Yaqing Wang"", ""Changyou Chen"", ""Jing Gao""]","[""Generative adversarial network"", ""inference"", ""generative model""]",,,,,
rJxbJeHFPS,2020,Accept (Spotlight),True,What Can Neural Networks Reason About?,"[""Keyulu Xu"", ""Jingling Li"", ""Mozhi Zhang"", ""Simon S. Du"", ""Ken-ichi Kawarabayashi"", ""Stefanie Jegelka""]","[""reasoning"", ""deep learning theory"", ""algorithmic alignment"", ""graph neural networks""]",We develop a theoretical framework to characterize what a neural network can learn to reason about.,1905.13211,cs.LG,2019-05-30 17:53:30+00:00,2020-02-15 06:56:25+00:00
rJxcBpNKPr,2020,Reject,False,OvA-INN: Continual Learning with Invertible Neural Networks,"[""HOCQUET Guillaume"", ""BICHLER Olivier"", ""QUERLIOZ Damien""]","[""Deep Learning"", ""Continual Learning"", ""Invertible Neural Networks""]",We propose to train an Invertible Neural Network for each class to perform class-by-class Continual Learning.,,,,
rJxcHnRqYQ,2019,Reject,False,Local Binary Pattern Networks for Character Recognition,"[""Jeng-Hau Lin"", ""Yunfan Yang"", ""Rajesh K. Gupta"", ""Zhuowen Tu""]","[""deep learning"", ""local binary pattern"", ""supervised learning"", ""hardware-friendly""]",,,,,
rJxdQ3jeg,2017,Accept (Oral),False,End-to-end Optimized Image Compression,"[""Johannes Ball\u00e9"", ""Valero Laparra"", ""Eero P. Simoncelli""]",[],,,,,
rJxe3xSYDS,2020,Accept (Poster),False,Extreme Classification via Adversarial Softmax Approximation,"[""Robert Bamler"", ""Stephan Mandt""]","[""Extreme classification"", ""negative sampling""]","An efficient, unbiased approximation of the softmax loss function for extreme classification",2002.06298,stat.ML,2020-02-15 01:42:52+00:00,2020-02-15 01:42:52+00:00
rJxgknCcK7,2019,Accept (Oral),False,FFJORD: Free-Form Continuous Dynamics for Scalable Reversible Generative Models,"[""Will Grathwohl"", ""Ricky T. Q. Chen"", ""Jesse Bettencourt"", ""Ilya Sutskever"", ""David Duvenaud""]","[""generative models"", ""density estimation"", ""approximate inference"", ""ordinary differential equations""]",We use continuous time dynamics to define a generative model with exact likelihoods and efficient sampling that is parameterized by unrestricted neural networks.,,,,
rJxlc0EtDr,2020,Accept (Poster),False,MEMO: A Deep Network for Flexible Combination of Episodic Memories,"[""Andrea Banino"", ""Adri\u00e0 Puigdom\u00e8nech Badia"", ""Raphael K\u00f6ster"", ""Martin J. Chadwick"", ""Vinicius Zambaldi"", ""Demis Hassabis"", ""Caswell Barry"", ""Matthew Botvinick"", ""Dharshan Kumaran"", ""Charles Blundell""]","[""Memory Augmented Neural Networks"", ""Deep Learning""]",A memory architecture that support inferential reasoning.,2001.10913,cs.LG,2020-01-29 15:56:16+00:00,2020-01-29 15:56:16+00:00
rJxok1BYPr,2020,Reject,False,Black Box Recursive Translations for Molecular Optimization,"[""Farhan Damani"", ""Vishnu Sresht"", ""Stephen Ra""]","[""molecules"", ""chemistry"", ""drug design"", ""generative models"", ""application"", ""translation""]",We introduce a black box algorithm for repeated optimization of compounds using a translation framework.,1912.10156,cs.LG,2019-12-21 00:53:12+00:00,2019-12-21 00:53:12+00:00
rJxotpNYPS,2020,Reject,True,DIVA: Domain Invariant Variational Autoencoder,"[""Maximilian Ilse"", ""Jakub M. Tomczak"", ""Christos Louizos"", ""Max Welling""]","[""representation learning"", ""generative models"", ""domain generalization"", ""invariance""]","Domain Invariant Variational Autoencoder that learns three independent latent subspaces, one for the domain, one for the class, and one for any residual variations.",1905.10427,stat.ML,2019-05-24 19:57:39+00:00,2019-10-07 13:15:48+00:00
rJxpuoCqtQ,2019,Reject,False,Likelihood-based Permutation Invariant Loss Function for Probability Distributions,"[""Masataro Asai""]","[""Set reconstruction"", ""maximum likelihood"", ""permutation invariance""]","The proposed method, Set Cross Entropy, measures the information-theoretic similarity of sets in a permutation-invariant manner.",,,,
rJxq3kHKPH,2020,Reject,False,A Simple Approach to the Noisy Label Problem Through the Gambler's Loss,"[""Liu Ziyin"", ""Ru Wang"", ""Paul Pu Liang"", ""Ruslan Salakhutdinov"", ""Louis-Philippe Morency"", ""Masahito Ueda""]","[""noisy labels"", ""robust learning"", ""early stopping"", ""generalization""]",We propose to a simple loss function and an analytical early stopping criterion to deal with the label noise problem.,,,,
rJxqZkSFDB,2020,Reject,False,Searching to Exploit Memorization Effect in Learning from Corrupted Labels,"[""Hansi Yang"", ""Quanming Yao"", ""Bo Han"", ""Gang Niu""]","[""Noisy Label"", ""Deep Learning"", ""Automated Machine Learning""]",Using automated machine learning techniques to exploit memorization effect in learning from corrupted labels,,,,
rJxt0JHKvS,2020,Reject,False,Coloring graph neural networks for node disambiguation,"[""George Dasoulas"", ""Ludovic Dos Santos"", ""Kevin Scaman"", ""Aladin Virmaux""]","[""Graph neural networks"", ""separability"", ""node disambiguation"", ""universal approximation"", ""representation learning""]","This paper introduces a coloring scheme for node disambiguation in graph neural networks based on separability, proven to be a universal MPNN extension.",1912.06058,cs.LG,2019-12-12 16:06:47+00:00,2019-12-12 16:06:47+00:00
rJxtgJBKDr,2020,Accept (Poster),False,SNOW: Subscribing to Knowledge via Channel Pooling for Transfer & Lifelong Learning of Convolutional Neural Networks,"[""Chungkuk Yoo"", ""Bumsoo Kang"", ""Minsik Cho""]","[""channel pooling"", ""efficient training and inferencing"", ""lifelong learning"", ""transfer learning"", ""multi task""]","We propose SNOW, an efficient way of transfer and lifelong learning by subscribing knowledge of a source model for new tasks through a novel channel pooling block.",,,,
rJxug2R9Km,2019,Reject,False,Meta-Learning for Contextual Bandit Exploration,"[""Amr Sharaf"", ""Hal Daum\u00e9 III""]","[""meta-learning"", ""bandits"", ""exploration"", ""imitation learning""]","We present a meta-learning algorithm, MEÌLEÌE, for learning a good exploration function in the interactive contextual bandit setting.",1901.08159,cs.LG,2019-01-23 22:52:13+00:00,2019-01-23 22:52:13+00:00
rJxvD3VKvr,2020,Reject,False,Wide Neural Networks are Interpolating Kernel Methods: Impact of Initialization on Generalization,"[""Manuel Nonnenmacher"", ""David Reeb"", ""Ingo Steinwart""]","[""overparametrization"", ""generalization"", ""initialization"", ""gradient descent"", ""kernel methods"", ""deep learning theory""]",We show that the generalization behavior of wide neural networks depends strongly on their initialization.,,,,
rJxwDTVFDB,2020,Reject,True,Pushing the bounds of dropout,"[""G\u00e1bor Melis"", ""Charles Blundell"", ""Tom\u00e1\u0161 Ko\u010disk\u00fd"", ""Karl Moritz Hermann"", ""Chris Dyer"", ""Phil Blunsom""]","[""dropout"", ""language""]",A new view of dropout training as optimizing lower bound for an entire family of models.,1805.09208,stat.ML,2018-05-23 14:55:39+00:00,2018-09-27 15:19:20+00:00
rJxycxHKDS,2020,Accept (Poster),False,Domain Adaptive Multibranch Networks,"[""R\u00f3ger Berm\u00fadez-Chac\u00f3n"", ""Mathieu Salzmann"", ""Pascal Fua""]","[""Domain Adaptation"", ""Computer Vision""]","A Multiflow Network is a dynamic architecture for domain adaptation that learns potentially different computational graphs per domain, so as to map them to a common representation where inference can be performed in a domain-agnostic fashion.",,,,
rJxyqkSYDH,2020,Reject,False,A Simple Dynamic Learning Rate Tuning Algorithm For Automated Training of DNNs,"[""Koyel Mukherjee"", ""Alind Khare"", ""Yogish Sabharwal"", ""Ashish Verma""]","[""adaptive LR tuning algorithm"", ""generalization""]","We propose an automated, adaptive LR tuning algorithm for training DNNs that works as well or better than SOTA for different model-dataset combinations tried for natural as well as adversarial training, with theoretical convergence analysis.",,,,
rJzIBfZAb,2018,Accept (Poster),True,Towards Deep Learning Models Resistant to Adversarial Attacks,"[""Aleksander Madry"", ""Aleksandar Makelov"", ""Ludwig Schmidt"", ""Dimitris Tsipras"", ""Adrian Vladu""]","[""adversarial examples"", ""robust optimization"", ""ML security""]","We provide a principled, optimization-based re-look at the notion of adversarial examples, and develop methods that produce models that are adversarially robust against a wide range of adversaries.",1706.06083,stat.ML,2017-06-19 17:53:11+00:00,2019-09-04 18:53:10+00:00
rJzLciCqKm,2019,Accept (Poster),False,Learning from Positive and Unlabeled Data with a Selection Bias,"[""Masahiro Kato"", ""Takeshi Teshima"", ""Junya Honda""]","[""PU learning"", ""deep learning"", ""machine learning"", ""anomaly detection"", ""sampling bias""]",,,,,
rJzaDdYxx,2017,Reject,False,Gradients of Counterfactuals,"[""Mukund Sundararajan"", ""Ankur Taly"", ""Qiqi Yan""]","[""Deep learning"", ""Computer vision"", ""Theory""]",A method for identifying feature importance in deep networks using gradients of counterfactual inputs,,,,
rJzoujRct7,2019,Reject,False,A Solution to China Competitive Poker Using Deep Learning,"[""Zhenxing Liu"", ""Maoyu Hu"", ""Zhangfei Zhang""]","[""artificial intelligence"", ""China competitive poker"", ""Dou dizhu"", ""CNN"", ""imperfect information game""]","This paper introduces a method to play China competitive poker using deep neural network, gets the state of the art performance.",,,,
rLj5jTcCUpp,2021,Reject,False,Distribution Embedding Network for Meta-Learning with Variable-Length Input,"[""Lang Liu"", ""Mahdi Milani Fard"", ""Sen Zhao""]","[""meta-learning"", ""variable-length input"", ""distribution embedding""]","In this paper we propose Distribution Embedding Network for meta-learning, which is designed for applications where both the distribution and the number of features could vary across tasks.",,,,
rMbLORc8oS,2022,Reject,False,SemiRetro: Semi-template framework boosts deep retrosynthesis prediction,"['Zhangyang Gao', 'Cheng Tan', 'Lirong Wu', 'Haitao Lin', 'Stan Z. Li']","[""Retrosynthesis prediction"", ""molecular graph learning""]",We propose a deep graph learning framework using semi-template to facilitate retrosynthesis  prediction.,,,,
rN9tjzY9UD,2022,Reject,False,Adaptive Learning of Tensor Network Structures,"['Meraj Hashemizadeh', 'Michelle Liu', 'Jacob Miller', 'Guillaume Rabusseau']","[""Tensor Networks"", ""Tensor Network Topology"", ""Structure Learning"", ""Tensor Completion"", ""Tensor Decomposition""]",We propose an efficient greedy algorithm to jointly learn the parameters and structure of tensor network models from data. ,,,,
rOGm97YR22N,2022,Reject,False,Mixed-Memory RNNs for Learning Long-term Dependencies in Irregularly Sampled Time Series,"['Mathias Lechner', 'Ramin Hasani']",[],Separating RNN's time-continuous and memory states improve learning of irregularly sampled long-term data,,,,
rQYyXqHPgZR,2021,Reject,False,Success-Rate Targeted Reinforcement Learning by Disorientation Penalty,"[""Haichuan Gao"", ""Zhile Yang"", ""Tian Tan"", ""Feng Chen""]","[""reinforcement learning"", ""undiscounted return"", ""success rate""]","This paper analyzes the uniformity problem in directly optimizing success rate in reinforcement learning, and proposes Loop Penalty (LP) to alleviate it.",,,,
rRFIni1CYmy,2021,Accept (Poster),False,End-to-End Egospheric Spatial Memory,"[""Daniel James Lenton"", ""Stephen James"", ""Ronald Clark"", ""Andrew Davison""]","[""egocentric"", ""differentiable memory"", ""spatial awareness"", ""mapping"", ""image-to-action learning""]",End-to-End Egospheric Spatial Memory (ESM) forms a bridge between real-time mapping and differentiable memory,,,,
rRg0ghtqRw2,2022,Reject,False,That Escalated Quickly: Compounding Complexity by Editing Levels at the Frontier of Agent Capabilities,"['Jack Parker-Holder', 'Minqi Jiang', 'Michael D Dennis', 'Mikayel Samvelyan', 'Jakob Nicolaus Foerster', 'Edward Grefenstette', 'Tim RocktÃ¤schel']","[""Reinforcement Learning"", ""Unsupervised Environment Design""]","Generating curricula for RL agents by making edits to levels which previously had high learning potential, making sure the agent is constantly tested at the frontier of its capabilities.",,,,
rS9-7AuPKWK,2022,Accept (Poster),True,Towards Understanding Generalization via Decomposing Excess Risk Dynamics,"['Jiaye Teng', 'Jianhao Ma', 'Yang Yuan']","[""generalization"", ""excess risk"", ""stability"", ""dynamics""]",This paper proposes a decomposition framework to improve the stability-based bound. ,2106.06153,cs.LG,2021-06-11 03:42:45+00:00,2021-10-09 03:16:48+00:00
rS9t6WH34p,2022,Reject,True,Decomposing 3D Scenes into Objects via Unsupervised Volume Segmentation,"['Karl Stelzner', 'Kristian Kersting', 'Adam R. Kosiorek']","[""Representation Learning"", ""Unsupervised Object Discovery"", ""Neural Radiance Fields""]","ObSuRF: A method which turns a single image of a scene into a 3D model represented as a set of Neural Radiance Fields (NeRFs), each corresponding to a different object.",2104.01148,cs.CV,2021-04-02 16:59:29+00:00,2021-04-02 16:59:29+00:00
rSI-tyrv-ni,2022,Reject,False,Does Entity Abstraction Help Generative Transformers Reason?,"['Nicolas Gontier', 'Siva Reddy', 'Christopher Pal']","[""Transformers"", ""reasoning"", ""compositional generalization"", ""entity type"", ""abstraction""]",,,,,
rSwTMomgCz,2021,Reject,True,Decoupling Exploration and Exploitation for Meta-Reinforcement Learning without Sacrifices,"[""Evan Zheran Liu"", ""Aditi Raghunathan"", ""Percy Liang"", ""Chelsea Finn""]","[""meta-reinforcement learning"", ""reinforcement learning"", ""exploration""]",We introduce a new meta-reinforcement learning algorithm that avoids local optima faced by prior algorithms while still yielding optimal exploration.,2008.02790,cs.LG,2020-08-06 17:57:36+00:00,2021-11-12 02:08:50+00:00
rTAclwH46Tb,2022,Accept (Poster),True,Eigencurve: Optimal Learning Rate Schedule for SGD on Quadratic Objectives with Skewed Hessian Spectrums,"['Rui Pan', 'Haishan Ye', 'Tong Zhang']","[""optimization"", ""learning rate schedule"", ""optimal convergence rate""]",A learning rate schedule which achieves minimax optimal convergence rate (up to a constant) for SGD on quadratic objectives with skewed Hessian spectrums.,2110.14109,cs.LG,2021-10-27 01:17:53+00:00,2021-10-28 00:59:30+00:00
rUVFU1oyAoy,2021,Reject,False,Nonconvex Continual Learning with Episodic Memory,"[""Sungyeob Han"", ""Yeongmo Kim"", ""Jungwoo Lee""]","[""continual learning"", ""nonconvex optimization""]",We provide a theoretical convergence analysis of continual learning and propose a simple gradient scaling based continual learning algorithm.,,,,
rUwm9wCjURV,2022,Accept (Poster),True,"In a Nutshell, the Human Asked for This: Latent Goals for Following Temporal Specifications","['Borja G. LeÃ³n', 'Murray Shanahan', 'Francesco Belardinelli']","[""Deep Reinforcement Learning"", ""Out-Of-Distribution Generalisation"", ""Temporal Logic""]",Inducing architectures to generate low-dimensional representations of their current goal processing observations and instructions together yields stronger out-of-distribution generalisation,2110.09461,cs.AI,2021-10-18 16:53:31+00:00,2021-10-18 16:53:31+00:00
rVdLv-uzYup,2021,Reject,True,Joint Perception and Control as Inference with an Object-based Implementation,"[""Minne Li"", ""Zheng Tian"", ""Pranav Nashikkar"", ""Ian Davies"", ""Ying Wen"", ""Jun Wang""]","[""model-based reinforcement learning"", ""perception modeling"", ""object-based reinforcement learning""]",,1903.01385,cs.LG,2019-03-04 17:30:12+00:00,2020-10-13 12:54:29+00:00
rWXfFogxRJN,2022,Accept (Poster),False,AdaAug: Learning Class- and Instance-adaptive Data Augmentation Policies,"['Tsz-Him Cheung', 'Dit-Yan Yeung']","[""Data Augmentation"", ""Automated Data Augmentation""]",We propose a novel Automated Data Augmentation method called \texttt{AdaAug} to efficiently learn adaptive augmentation policies in a class-dependent and potentially instance-dependent manner.,,,,
rWZz3sJfCkm,2021,Accept (Poster),False,Efficient Generalized Spherical CNNs,"[""Oliver Cobb"", ""Christopher G. R. Wallis"", ""Augustine N. Mavor-Parker"", ""Augustin Marignier"", ""Matthew A. Price"", ""Mayeul d'Avezac"", ""Jason McEwen""]",[],,,,,
rX3rZYP8zZF,2022,Reject,False,CareGraph: A Graph-based Recommender System for Diabetes Self-Care,"['Sirinart Tangruamsub', 'Karthik Kappaganthu', ""John O'Donovan"", 'Anmol Madan']","[""knowledge graph"", ""knowledge graph embedding"", ""recommendation system""]",,,,,
rYt0p0Um9r,2021,Reject,False,Do Deeper Convolutional Networks Perform Better?,"[""Eshaan Nichani"", ""Adityanarayanan Radhakrishnan"", ""Caroline Uhler""]","[""Depth"", ""Over-parameterization"", ""Neural Networks""]","In contrast to what is observed for increasing width, we demonstrate that test performance of convolutional neural networks worsens beyond a critical depth.",,,,
rbFPSQHlllm,2022,Reject,False,AutoMO-Mixer: An automated multi-objective multi-layer perspecton Mixer model for medical image based diagnosis,"['Xi Chen', 'Jiahuan Lv', 'Xuanqing Mou', 'Zhiguo Zhou']",[],,,,,
rbPg0zkHGi,2022,Reject,False,Deep Active Learning with Noise Stability,"['Xingjian Li', 'Pengkun Yang', 'Tianyang Wang', 'Min Xu', 'Dejing Dou', 'Cheng-zhong Xu']","[""deep learning"", ""active learning"", ""noise stability""]",This paper presents a novel active learning algorithm that leverages noise stability to estimate data uncertainty.,,,,
rcQdycl0zyk,2021,Accept (Spotlight),False,Beyond Fully-Connected Layers with Quaternions: Parameterization of Hypercomplex Multiplications with $1/n$ Parameters,"[""Aston Zhang"", ""Yi Tay"", ""SHUAI Zhang"", ""Alvin Chan"", ""Anh Tuan Luu"", ""Siu Hui"", ""Jie Fu""]","[""hypercomplex representation learning""]",We propose to parameterize hypercomplex multiplications using arbitrarily $1/n$ learnable parameters compared with the fully-connected layer counterpart.,,,,
rczz7TUKIIB,2022,Reject,False,Loss meta-learning for forecasting,"['Alan Collet', 'Antonio Bazco-Nogueras', 'Albert Banchs', 'Marco Fiore']","[""meta-learning"", ""loss function"", ""forecasting"", ""learning to learn""]",We propose a meta-learning approach for loss functions that improves the performance of supervised forecasting tasks,,,,
rdBuE6EigGl,2022,Reject,False,The Importance of the Current Input in Sequence Modeling,"['Christian Oliva', 'Luis F. Lago-Fernandez']",[],,,,,
rd_bm8CK7o0,2021,Reject,False,Q-Value Weighted Regression: Reinforcement Learning with Limited Data,"[""Piotr Kozakowski"", ""Lukasz Kaiser"", ""Henryk Michalewski"", ""Afroz Mohiuddin"", ""Katarzyna Ka\u0144ska""]","[""reinforcement learning"", ""rl"", ""offline rl"", ""continuous control"", ""atari"", ""sample efficiency""]","We analyze the sample-efficiency of actor-critic RL algorithms, and introduce a new algorithm, achieving superior sample-efficiency while maintaining competitive final performance on the MuJoCo task suite and on Atari games.",,,,
reFFte7mA0F,2022,Reject,False,Conditional Expectation based Value Decomposition for Scalable On-Demand Ride Pooling,"['Avinandan Bose', 'Pradeep Varakantham']","[""Ride-Pool Matching Problem(RMP)"", ""Value Decomposition"", ""Approximate Dynamic Programming(ADP)"", ""Reinforcement Learning""]",Improving city scale ride pool matching by capturing dependencies of other agents actions traditionally ignored in value based decomposition approaches.,2112.00579,cs.LG,2021-12-01 15:53:16+00:00,2021-12-01 15:53:16+00:00
refmbBH_ysO,2021,Reject,False,SpreadsheetCoder: Formula Prediction from Semi-structured Context,"[""Xinyun Chen"", ""Petros Maniatis"", ""Rishabh Singh"", ""Charles Sutton"", ""Hanjun Dai"", ""Max Lin"", ""Denny Zhou""]","[""neural program synthesis"", ""spreadsheet formula prediction""]",,,,,
rgFNuJHHXv,2021,Accept (Poster),True,Group Equivariant Generative Adversarial Networks,"[""Neel Dey"", ""Antong Chen"", ""Soheil Ghafurian""]","[""Group Equivariance"", ""Geometric Deep Learning"", ""Generative Adversarial Networks""]",Equivariance to symmetry groups improves the generative adversarial synthesis of symmetric images.,2005.01683,cs.CV,2020-05-04 17:38:49+00:00,2021-03-30 18:00:21+00:00
rhDaUTtfsqs,2022,Reject,True,Curriculum Learning: A Regularization Method for Efficient and Stable Billion-Scale GPT Model Pre-Training,"['Conglong Li', 'Minjia Zhang', 'Yuxiong He']","[""curriculum learning"", ""natural language processing"", ""language model pre-training""]",Curriculum learning improves stability and efficiency of language model pre-training.,2108.06084,cs.LG,2021-08-13 06:32:53+00:00,2022-02-01 05:22:37+00:00
rhOiUS8KQM9,2022,Accept (Poster),False,Enabling Arbitrary Translation Objectives with Adaptive Tree Search,"['Wang Ling', 'Wojciech Stokowiec', 'Domenic Donato', 'Chris Dyer', 'Lei Yu', 'Laurent Sartran', 'Austin Matthews']","[""Machine Translation"", ""Decoding"", ""MCTS"", ""Beam Search""]",MCTS is used as a decoder for autoregressive and non-autoregressive machine translation models.,,,,
rk07ZXZRb,2018,Accept (Poster),False,Learning an Embedding Space for Transferable Robot Skills,"[""Karol Hausman"", ""Jost Tobias Springenberg"", ""Ziyu Wang"", ""Nicolas Heess"", ""Martin Riedmiller""]","[""Deep Reinforcement Learning"", ""Variational Inference"", ""Control"", ""Robotics""]",,,,,
rk1FQA0pW,2018,Reject,False,End-to-End Abnormality Detection in Medical Imaging,"[""Dufan Wu"", ""Kyungsang Kim"", ""Bin Dong"", ""Quanzheng Li""]","[""End-to-End training"", ""deep neural networks"", ""medical imaging"", ""image reconstruction""]",Detection of lung nodule starting from projection data rather than images.,,,,
rk3b2qxCW,2018,Reject,False,Policy Gradient For Multidimensional Action Spaces: Action Sampling and Entropy Bonus,"[""Vuong Ho Quan"", ""Yiming Zhang"", ""Kenny Song"", ""Xiao-Yue Gong"", ""Keith W. Ross""]","[""deep reinforcement learning"", ""policy gradient"", ""multidimensional action space"", ""entropy bonus"", ""entropy regularization"", ""discrete action space""]",policy parameterizations and unbiased policy entropy estimators for MDP with large multidimensional discrete action space,,,,
rk3mjYRp-,2018,Reject,False,Diffusing Policies : Towards Wasserstein Policy Gradient Flows,"[""Pierre H. Richemond"", ""Brendan Maginnis""]","[""Optimal transport"", ""policy gradients"", ""entropy regularization"", ""reinforcement learning"", ""heat equation"", ""Wasserstein"", ""JKO"", ""gradient flows""]","Linking Wasserstein-trust region entropic policy gradients, and the heat equation.",,,,
rk3pnae0b,2018,Invite to Workshop Track,False,Topic-Based Question Generation,"[""Wenpeng Hu"", ""Bing Liu"", ""Rui Yan"", ""Dongyan Zhao"", ""Jinwen Ma""]",[],We propose a neural network that is able to generate topic-specific questions.,,,,
rk49Mg-CW,2018,Accept (Poster),True,Stochastic Variational Video Prediction,"[""Mohammad Babaeizadeh"", ""Chelsea Finn"", ""Dumitru Erhan"", ""Roy H. Campbell"", ""Sergey Levine""]","[""video prediction"", ""stochastic prediction"", ""variational inference"", ""unsupervised learning""]",Stochastic variational video prediction in real-world settings.,1710.11252,cs.CV,2017-10-30 21:48:54+00:00,2018-03-06 16:35:06+00:00
rk4Fz2e0b,2018,Invite to Workshop Track,False,Graph Partition Neural Networks for Semi-Supervised Classification,"[""Renjie Liao"", ""Marc Brockschmidt"", ""Daniel Tarlow"", ""Alexander Gaunt"", ""Raquel Urtasun"", ""Richard S. Zemel""]",[],,,,,
rk4Qso0cKm,2019,Accept (Poster),False,Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network,"[""Xuanqing Liu"", ""Yao Li"", ""Chongruo Wu"", ""Cho-Jui Hsieh""]",[],"We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks",,,,
rk4Wf30qKQ,2019,Reject,False,Security Analysis of Deep Neural Networks Operating in the Presence of Cache Side-Channel Attacks,"[""Sanghyun Hong"", ""Michael Davinroy"", ""Yigitcan Kaya"", ""Stuart Nevans Locke"", ""Ian Rackow"", ""Kevin Kulda"", ""Dana Dachman-Soled"", ""Tudor Dumitra\u0219""]","[""DNN Security Analysis"", ""Fingerprinting Attacks"", ""Cache Side-Channel""]","We conduct the first in-depth security analysis of DNN fingerprinting attacks that exploit cache side-channels, which represents a step toward understanding the DNNâs vulnerability to side-channel attacks.",,,,
rk5upnsxe,2017,Accept (Poster),False,Normalizing the Normalizers: Comparing and Extending Network Normalization Schemes,"[""Mengye Ren"", ""Renjie Liao"", ""Raquel Urtasun"", ""Fabian H. Sinz"", ""Richard S. Zemel""]",[],,,,,
rk6H0ZbRb,2018,Invite to Workshop Track,False,Intriguing Properties of Adversarial Examples,"[""Ekin Dogus Cubuk"", ""Barret Zoph"", ""Samuel Stern Schoenholz"", ""Quoc V. Le""]","[""adversarial examples"", ""universality"", ""neural architecture search""]","Adversarial error has similar power-law form for all datasets and models studied, and architecture matters.",,,,
rk6cfpRjZ,2018,Accept (Poster),False,Learning Intrinsic Sparse Structures within Long Short-Term Memory,"[""Wei Wen"", ""Yuxiong He"", ""Samyam Rajbhandari"", ""Minjia Zhang"", ""Wenhan Wang"", ""Fang Liu"", ""Bin Hu"", ""Yiran Chen"", ""Hai Li""]","[""Sparsity"", ""Model Compression"", ""Acceleration"", ""LSTMs"", ""Recurrent Neural Networks"", ""Structural Learning""]",,,,,
rk6qdGgCZ,2018,Reject,False,Fixing Weight Decay Regularization in Adam,"[""Ilya Loshchilov"", ""Frank Hutter""]","[""Adam"", ""Adaptive Gradient Methods"", ""weight decay"", ""L2 regularization""]",Fixing weight decay regularization in adaptive gradient methods such as Adam,,,,
rk8R_JWRW,2018,Reject,False,Gating out sensory noise in a spike-based Long Short-Term Memory network,"[""Davide Zambrano"", ""Isabella Pozzi"", ""Roeland Nusselder"", ""Sander Bohte""]","[""spiking neural networks"", ""LSTM"", ""recurrent neural networks""]", We demonstrate a gated recurrent asynchronous spiking neural network that corresponds to an LSTM unit.,,,,
rk8wKk-R-,2018,Invite to Workshop Track,False,Convolutional Sequence Modeling Revisited,"[""Shaojie Bai"", ""J. Zico Kolter"", ""Vladlen Koltun""]","[""Temporal Convolutional Network"", ""Sequence Modeling"", ""Deep Learning""]",We argue that convolutional networks should be considered the default starting point for sequence modeling tasks.,,,,
rk9eAFcxg,2017,Accept (Poster),False,Variational Recurrent Adversarial Deep Domain Adaptation,"[""Sanjay Purushotham"", ""Wilka Carvalho"", ""Tanachat Nilanon"", ""Yan Liu""]","[""Deep learning"", ""Transfer Learning""]",We propose Variational Recurrent Adversarial Deep Domain Adaptation approach to capture and transfer temporal latent dependencies in multivariate time-series data,,,,
rk9kKMZ0-,2018,Reject,False,LEAP: Learning Embeddings for Adaptive Pace,"[""Vithursan Thangarasa"", ""Graham W. Taylor""]","[""deep metric learning"", ""self-paced learning"", ""representation learning"", ""cnn""]",LEAP combines the strength of adaptive sampling with that of mini-batch online learning and adaptive representation learning to formulate a representative self-paced strategy in an end-to-end DNN training protocol. ,,,,
rkA1f3NpZ,2018,Reject,True,Ensemble Methods as a Defense to Adversarial Perturbations Against Deep Neural Networks,"[""Thilo Strauss"", ""Markus Hanselmann"", ""Andrej Junginger"", ""Holger Ulmer""]","[""Ensemble Method"", ""Adversarial Perturbations"", ""Deep Neural Networks"", ""Defense"", ""Attack""]",Using ensemble methods as a defense to adversarial perturbations against deep neural networks.,1709.03423,stat.ML,2017-09-11 15:01:03+00:00,2018-02-08 08:48:03+00:00
rkE3y85ee,2017,Accept (Poster),False,Categorical Reparameterization with Gumbel-Softmax,"[""Eric Jang"", ""Shixiang Gu"", ""Ben Poole""]","[""Deep learning"", ""Semi-Supervised Learning"", ""Optimization"", ""Structured prediction""]","Simple, differentiable sampling mechanism for categorical variables that can be trained in neural nets via standard backprop.",,,,
rkE8pVcle,2017,Accept (Poster),False,Learning through Dialogue Interactions by Asking Questions,"[""Jiwei Li"", ""Alexander H. Miller"", ""Sumit Chopra"", ""Marc'Aurelio Ranzato"", ""Jason Weston""]","[""Natural language processing""]",We investigate how a bot can benefit from interacting with users and asking questions.,,,,
rkEFLFqee,2017,Accept (Poster),False,Decomposing Motion and Content for Natural Video Sequence Prediction,"[""Ruben Villegas"", ""Jimei Yang"", ""Seunghoon Hong"", ""Xunyu Lin"", ""Honglak Lee""]","[""Computer vision"", ""Deep learning"", ""Unsupervised Learning""]",,,,,
rkEfPeZRb,2018,Invite to Workshop Track,False,Variance-based Gradient Compression for Efficient Distributed Deep Learning,"[""Yusuke Tsuzuku"", ""Hiroto Imachi"", ""Takuya Akiba""]","[""distributed deep learning"", ""gradient compression"", ""collective communication"", ""data parallel distributed sgd"", ""image classification""]",A new algorithm to reduce the communication overhead of distributed deep learning by distinguishing âunambiguousâ gradients.,,,,
rkEtzzWAb,2018,Invite to Workshop Track,False,Parametric Adversarial Divergences are Good Task Losses for Generative Modeling,"[""Gabriel Huang"", ""Hugo Berard"", ""Ahmed Touati"", ""Gauthier Gidel"", ""Pascal Vincent"", ""Simon Lacoste-Julien""]","[""parametric"", ""adversarial"", ""divergence"", ""generative"", ""modeling"", ""gan"", ""neural"", ""network"", ""task"", ""loss"", ""structured"", ""prediction""]","Parametric adversarial divergences implicitly define more meaningful task losses for generative modeling, we make parallels with structured prediction to study the properties of these divergences and their ability to encode the task of interest.",,,,
rkFBJv9gg,2017,Accept (Poster),False,Learning Features of Music From Scratch,"[""John Thickstun"", ""Zaid Harchaoui"", ""Sham Kakade""]","[""Applications""]","We introduce a new large-scale music dataset, define a multi-label classification task, and benchmark machine learning architectures on this task.",,,,
rkFd2P5gl,2017,Reject,False,Leveraging Asynchronicity in Gradient Descent for Scalable Deep Learning,"[""Jeff Daily"", ""Abhinav Vishnu"", ""Charles Siegel""]","[""Deep learning""]",Overlapping communication and computation for distributed gradient descent.,,,,
rkGG6s0qKQ,2019,Reject,False,"The GAN Landscape: Losses, Architectures, Regularization, and Normalization","[""Karol Kurach"", ""Mario Lucic"", ""Xiaohua Zhai"", ""Marcin Michalski"", ""Sylvain Gelly""]","[""GANs"", ""empirical evaluation"", ""large-scale"", ""reproducibility""]",A sober view on the current state of GANs from a practical perspective,,,,
rkGZuJb0b,2018,Reject,False,Compact Neural Networks based on the Multiscale Entanglement Renormalization Ansatz,"[""Andrew Hallam"", ""Edward Grant"", ""Vid Stojevic"", ""Simone Severini"", ""Andrew G. Green""]","[""Neural Networks"", ""Tensor Networks"", ""Tensor Trains""]","We replace the fully connected layers of a neural network with the multi-scale entanglement renormalization ansatz, a type of quantum operation which describes long range correlations. ",,,,
rkGabzZgl,2017,Accept (Poster),False,Dropout with Expectation-linear Regularization,"[""Xuezhe Ma"", ""Yingkai Gao"", ""Zhiting Hu"", ""Yaoliang Yu"", ""Yuntian Deng"", ""Eduard Hovy""]","[""Theory"", ""Deep learning"", ""Supervised Learning""]",,,,,
rkGcYi09Km,2019,Reject,False,NUTS: Network for Unsupervised Telegraphic Summarization,"[""Chanakya Malireddy"", ""Tirth Maniar"", ""Sajal Maheshwari"", ""Manish Shrivastava""]","[""nlp"", ""summarization"", ""unsupervised learning"", ""deep learning""]","In this paper, we propose an unsupervised deep learning network (NUTS) to generate telegraphic summaries.",,,,
rkHVZWZAZ,2018,Accept (Poster),False,The Reactor: A fast and sample-efficient Actor-Critic agent for  Reinforcement Learning,"[""Audrunas Gruslys"", ""Will Dabney"", ""Mohammad Gheshlaghi Azar"", ""Bilal Piot"", ""Marc Bellemare"", ""Remi Munos""]","[""reinforcement learning"", ""policy gradient"", ""distributional reinforcement learning"", ""distributed computing""]",Reactor combines multiple algorithmic and architectural contributions to produce an agent with higher sample-efficiency than Prioritized Dueling DQN while giving better run-time performance than A3C.,,,,
rkHywl-A-,2018,Accept (Poster),True,Learning Robust Rewards with Adverserial Inverse Reinforcement Learning,"[""Justin Fu"", ""Katie Luo"", ""Sergey Levine""]","[""inverse reinforcement learning"", ""deep reinforcement learning""]","We propose an adversarial inverse reinforcement learning algorithm capable of learning reward functions which can transfer to new, unseen environments.",1710.11248,cs.LG,2017-10-30 21:22:28+00:00,2018-08-13 18:33:24+00:00
rkKCdAdgx,2017,Reject,False,Compact Embedding of Binary-coded Inputs and Outputs using Bloom Filters,"[""Joan Serr\u00e0"", ""Alexandros Karatzoglou""]","[""Applications"", ""Deep learning"", ""Unsupervised Learning""]",Bloom embeddings compactly represent sparse high-dimensional binary-coded instances without compromising accuracy,,,,
rkLyJl-0-,2018,Accept (Poster),False,Neumann Optimizer: A Practical Optimization Algorithm for Deep Neural Networks,"[""Shankar Krishnan"", ""Ying Xiao"", ""Rif. A. Saurous""]","[""Deep Learning"", ""Optimization""]",We describe a practical optimization algorithm for deep neural networks that works faster and generates better models compared to widely used algorithms.,,,,
rkMD73A5FX,2019,Reject,False,Can I trust you more? Model-Agnostic Hierarchical Explanations,"[""Michael Tsang"", ""Youbang Sun"", ""Dongxu Ren"", ""Beibei Xin"", ""Yan Liu""]","[""interpretability"", ""interactions"", ""context-dependent"", ""context-free""]",A new framework for context-dependent and context-free explanations of predictions,,,,
rkMW1hRqKX,2019,Accept (Poster),False,Optimal Completion Distillation for Sequence Learning,"[""Sara Sabour"", ""William Chan"", ""Mohammad Norouzi""]","[""Sequence Learning"", ""Edit Distance"", ""Speech Recognition"", ""Deep Reinforcement Learning""]",Optimal Completion Distillation (OCD) is a training procedure for optimizing sequence to sequence models based on edit distance which achieves state-of-the-art on end-to-end Speech Recognition tasks.,,,,
rkMhusC5Y7,2019,Reject,False,Learning to Coordinate Multiple Reinforcement Learning Agents for Diverse Query Reformulation,"[""Rodrigo Nogueira"", ""Jannis Bulian"", ""Massimiliano Ciaramita""]","[""Reinforcement Learning"", ""Multi-agent"", ""Information Retrieval"", ""Question-Answering"", ""Query Reformulation"", ""Query Expansion""]",Multiple diverse query reformulation agents trained with reinforcement learning to improve search engines.,,,,
rkMnHjC5YQ,2019,Reject,False,Improved Learning of One-hidden-layer Convolutional Neural Networks with Overlaps,"[""Simon S. Du"", ""Surbhi Goel""]","[""deep learning"", ""parameter recovery"", ""convolutional neural networks"", ""non-convex optimization""]",We propose an algorithm for provably recovering parameters (convolutional and output weights) of a convolutional network with overlapping patches.,,,,
rkMt1bWAZ,2018,Reject,False,Bias-Variance Decomposition for Boltzmann Machines,"[""Mahito Sugiyama"", ""Koji Tsuda"", ""Hiroyuki Nakahara""]","[""Boltzmann machine"", ""bias-variance decomposition"", ""information geometry""]",We achieve bias-variance decomposition for Boltzmann machines using an information geometric formulation.,,,,
rkN2Il-RZ,2018,Accept (Poster),False,SCAN: Learning Hierarchical Compositional Visual Concepts,"[""Irina Higgins"", ""Nicolas Sonnerat"", ""Loic Matthey"", ""Arka Pal"", ""Christopher P Burgess"", ""Matko Bo\u0161njak"", ""Murray Shanahan"", ""Matthew Botvinick"", ""Demis Hassabis"", ""Alexander Lerchner""]","[""grounded visual concepts"", ""compositional representation"", ""concept hierarchy"", ""disentangling"", ""beta-VAE"", ""variational autoencoder"", ""deep learning"", ""generative model""]",We present a neural variational model for learning language-guided compositional visual concepts.,,,,
rkO3uTkAZ,2018,Accept (Poster),False,Memorization Precedes Generation: Learning Unsupervised GANs with Memory Networks,"[""Youngjin Kim"", ""Minjung Kim"", ""Gunhee Kim""]","[""Generative Adversarial Networks"", ""Memory Networks""]",,,,,
rkONG0xAW,2018,Reject,False,Recursive Binary Neural Network Learning Model  with 2-bit/weight Storage Requirement,"[""Tianchan Guan"", ""Xiaoyang Zeng"", ""Mingoo Seok""]",[],"We propose a learning model enabling DNN to learn with only 2 bit/weight, which is especially useful for on-device learning",,,,
rkPLzgZAZ,2018,Accept (Poster),False,Modular Continual Learning in a Unified Visual Environment,"[""Kevin T. Feigelis"", ""Blue Sheffer"", ""Daniel L. K. Yamins""]","[""Continual Learning"", ""Neural Modules"", ""Interface Learning"", ""Task Switching"", ""Reinforcement Learning"", ""Visual Decision Making""]",We propose a neural module approach to continual learning using a unified visual environment with a large action space.,,,,
rkQkBnJAb,2018,Accept (Poster),False,Improving GANs Using Optimal Transport,"[""Tim Salimans"", ""Han Zhang"", ""Alec Radford"", ""Dimitris Metaxas""]","[""GAN"", ""generative modeling"", ""adversarial"", ""optimal transport""]",An extension of GANs combining optimal transport in primal form with an energy distance defined in an adversarially learned feature space.,1803.05573,cs.LG,2018-03-15 02:34:46+00:00,2018-03-15 02:34:46+00:00
rkQsMCJCb,2018,Reject,False,Generative Adversarial Networks using Adaptive Convolution,"[""Nhat M. Nguyen"", ""Nilanjan Ray""]","[""Generative Adversarial Networks"", ""Unsupervised Learning"", ""GANs""]",We replace normal convolutions with adaptive convolutions to improve GANs generator.,,,,
rkQu4Wb0Z,2018,Reject,False,DNN Representations as Codewords: Manipulating Statistical Properties via Penalty Regularization,"[""Daeyoung Choi"", ""Changho Shin"", ""Hyunghun Cho"", ""Wonjong Rhee""]","[""DNN representation"", ""penalty regularization"", ""channel coding""]",,,,,
rkQuFUmUOg3,2021,Accept (Poster),False,Rapid Neural Architecture Search by Learning to Generate Graphs from Datasets,"[""Hayeon Lee"", ""Eunyoung Hyung"", ""Sung Ju Hwang""]","[""Machine Learning"", ""Neural Architecture Search"", ""Meta-learning""]",We propose an efficient NAS framework that is trained once on a database consisting of datasets and pretrained networks and can rapidly generate a neural architecture for a novel dataset.,2107.00860,cs.LG,2021-07-02 06:33:59+00:00,2021-07-02 06:33:59+00:00
rkRwGg-0Z,2018,Accept (Oral),False,Beyond Word Importance:  Contextual Decomposition to Extract Interactions from LSTMs,"[""W. James Murdoch"", ""Peter J. Liu"", ""Bin Yu""]","[""interpretability"", ""LSTM"", ""natural language processing"", ""sentiment analysis"", ""interactions""]","We introduce contextual decompositions, an interpretation algorithm for LSTMs capable of extracting word, phrase and interaction-level importance score",,,,
rkTBjG-AZ,2018,Reject,False,DeepArchitect: Automatically Designing and Training Deep Architectures,"[""Renato Negrinho"", ""Geoff Gordon""]","[""architecture search"", ""deep learning"", ""hyperparameter tuning""]",We describe a modular and composable language for describing expressive search spaces over architectures and simple model search algorithms applied to these search spaces. ,,,,
rkTS8lZAb,2018,Accept (Poster),False,Boundary Seeking GANs,"[""R Devon Hjelm"", ""Athul Paul Jacob"", ""Adam Trischler"", ""Gerry Che"", ""Kyunghyun Cho"", ""Yoshua Bengio""]","[""Generative adversarial networks"", ""generative learning"", ""deep learning"", ""neural networks"", ""adversarial learning"", ""discrete data""]",We address training GANs with discrete data by formulating a policy gradient that generalizes across f-divergences,,,,
rkVOXhAqY7,2019,Reject,False,The Conditional Entropy Bottleneck,"[""Ian Fischer""]","[""representation learning"", ""information theory"", ""uncertainty"", ""out-of-distribution detection"", ""adversarial example robustness"", ""generalization"", ""objective function""]",The Conditional Entropy Bottleneck is an information-theoretic objective function for learning optimal representations.,,,,
rkWN3g-AZ,2018,Reject,False,XGAN: Unsupervised Image-to-Image Translation for many-to-many Mappings,"[""Amelie Royer"", ""Konstantinos Bousmalis"", ""Stephan Gouws"", ""Fred Bertsch"", ""Inbar Mosseri"", ""Forrester Cole"", ""Kevin Murphy""]","[""unsupervised"", ""gan"", ""domain adaptation"", ""style transfer"", ""semantic"", ""image translation"", ""dataset""]","XGAN is an unsupervised model for feature-level image-to-image translation applied to semantic style transfer problems such as the face-to-cartoon task, for which we introduce a new dataset.",,,,
rkYTTf-AZ,2018,Accept (Poster),False,Unsupervised Machine Translation Using Monolingual Corpora Only,"[""Guillaume Lample"", ""Alexis Conneau"", ""Ludovic Denoyer"", ""Marc'Aurelio Ranzato""]","[""unsupervised"", ""machine translation"", ""adversarial""]",We propose a new unsupervised machine translation model that can learn without using parallel corpora; experimental results show impressive performance on multiple corpora and pairs of languages.,,,,
rkYgAJWCZ,2018,Reject,False,One-shot and few-shot learning of word embeddings,"[""Andrew Kyle Lampinen"", ""James Lloyd McClelland""]","[""One-shot learning"", ""embeddings"", ""word embeddings"", ""natural language processing"", ""NLP""]","We highlight a technique by which natural language processing systems can learn a new word from context, allowing them to be much more flexible.",,,,
rkYmiD9lg,2017,Invite to Workshop Track,False,Exponential Machines,"[""Alexander Novikov"", ""Mikhail Trofimov"", ""Ivan Oseledets""]","[""Supervised Learning"", ""Optimization""]",A supervised machine learning algorithm with a polynomial decision function (like SVM with a polynomial kernel) that models exponentially many polynomial terms by factorizing the tensor of the parameters.,,,,
rkZB1XbRZ,2018,Accept (Poster),False,Scalable Private Learning with PATE,"[""Nicolas Papernot"", ""Shuang Song"", ""Ilya Mironov"", ""Ananth Raghunathan"", ""Kunal Talwar"", ""Ulfar Erlingsson""]","[""privacy"", ""differential privacy"", ""machine learning"", ""deep learning""]",,,,,
rkZvSe-RZ,2018,Accept (Poster),False,Ensemble Adversarial Training: Attacks and Defenses,"[""Florian Tram\u00e8r"", ""Alexey Kurakin"", ""Nicolas Papernot"", ""Ian Goodfellow"", ""Dan Boneh"", ""Patrick McDaniel""]","[""Adversarial Examples"", ""Adversarial Training"", ""Attacks"", ""Defenses"", ""ImageNet""]","Adversarial training with single-step methods overfits, and remains vulnerable to simple black-box and white-box attacks. We show that including adversarial examples from multiple sources helps defend against black-box attacks.",,,,
rkZzY-lCb,2018,Reject,False,Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features,"[""Luis Armona"", ""Jos\u00e9 P. Gonz\u00e1lez-Brenes"", ""Ralph Edezhath""]","[""unsupervised learning"", ""supervised learning"", ""knowledge representation"", ""deep learning""]",Learn dense vector representations of arbitrary types of features in labeled and unlabeled datasets,,,,
rkaRFYcgl,2017,Reject,False,Low-rank passthrough neural networks,"[""Antonio Valerio Miceli Barone""]","[""Deep learning""]","Describe low-rank and low-rank plus diagonal parametrizations for Highway Neural Networks, GRUs and other kinds of passthrough neural networks. Present competitive experimental results.",,,,
rkaT3zWCZ,2018,Invite to Workshop Track,False,Building Generalizable Agents with a Realistic and Rich 3D Environment,"[""Yi Wu"", ""Yuxin Wu"", ""Georgia Gkioxari"", ""Yuandong Tian""]","[""reinforcement learning"", ""generalization"", ""navigation"", ""3D scenes""]",,,,,
rkaqxm-0b,2018,Reject,False,Neural Compositional Denotational Semantics for Question Answering,"[""Nitish Gupta"", ""Mike Lewis""]","[""question answering"", ""knowledge graph"", ""compositional model"", ""semantics""]","We describe an end-to-end differentiable model for QA that learns to represent spans of text in the question as denotations in knowledge graph, by learning both neural modules for composition and the syntactic structure of the sentence.",,,,
rkcQFMZRb,2018,Accept (Poster),False,Variational image compression with a scale hyperprior,"[""Johannes Ball\u00e9"", ""David Minnen"", ""Saurabh Singh"", ""Sung Jin Hwang"", ""Nick Johnston""]",[],,,,,
rkc_hGb0Z,2018,Reject,False,A dynamic game approach to training robust deep policies,"[""Olalekan Ogunmolu""]","[""game-theory"", ""reinforcement-learning"", ""guided-policy-search"", ""dynamic-programming""]",This paper demonstrates how H-infinity control theory can help better design robust deep policies for robot motor taks,,,,
rkcya1ZAW,2018,Reject,False,Continuous-Time Flows for Efficient Inference and Density Estimation,"[""Changyou Chen"", ""Chunyuan Li"", ""Liqun Chen"", ""Wenlin Wang"", ""Yunchen Pu"", ""Lawrence Carin""]","[""continuous-time flows"", ""efficient inference"", ""density estimation"", ""deep generative models""]",,,,,
rkdU7tCaZ,2018,Reject,False,Dynamic Evaluation of Neural Sequence Models,"[""Ben Krause"", ""Emmanuel Kahembwe"", ""Iain Murray"", ""Steve Renals""]","[""sequence modelling"", ""language"", ""recurrent neural networks"", ""adaptation""]",Paper presents dynamic evaluation methodology for adaptive sequence modelling,,,,
rke-f6NKvS,2020,Accept (Poster),True,Learning Self-Correctable Policies and Value Functions from Demonstrations with Negative Sampling,"[""Yuping Luo"", ""Huazhe Xu"", ""Tengyu Ma""]","[""imitation learning"", ""model-based imitation learning"", ""model-based RL"", ""behavior cloning"", ""covariate shift""]","We introduce a notion of conservatively-extrapolated value functions, which provably lead to policies that can self-correct to stay close to the demonstration states, and learn them with a novel negative sampling technique.",1907.05634,cs.LG,2019-07-12 09:00:49+00:00,2019-10-11 05:44:14+00:00
rke2HRVYvH,2020,Reject,True,Stochastic Prototype Embeddings,"[""Tyler R. Scott"", ""Karl Ridgeway"", ""Michael C. Mozer""]","[""deep embeddings"", ""stochastic embeddings"", ""probabilistic embeddings"", ""deep metric learning"", ""few-shot learning""]","The paper proposes a probabilistic extension of Prototypical Networks that achieves superior few-shot, large-, and open-set classification performance, while gracefully handling label noise and out-of-distribution inputs.",1909.11702,stat.ML,2019-09-25 18:38:36+00:00,2019-09-25 18:38:36+00:00
rke2P1BFwS,2020,Accept (Poster),False,Tensor Decompositions for Temporal Knowledge Base Completion,"[""Timoth\u00e9e Lacroix"", ""Guillaume Obozinski"", ""Nicolas Usunier""]","[""knowledge base completion"", ""temporal embeddings""]",We propose new tensor decompositions and associated regularizers to obtain state of the art performances on temporal knowledge base completion.,2004.04926,stat.ML,2020-04-10 07:09:30+00:00,2020-04-10 07:09:30+00:00
rke3OxSKwr,2020,Reject,False,Improved Training Techniques for Online Neural Machine Translation,"[""Maha Elbayad"", ""Laurent Besacier"", ""Jakob Verbeek""]","[""Deep learning"", ""natural language processing"", ""Machine translation""]",Improved training of wait-k decoders for online machine translation,,,,
rke3TJrtPS,2020,Accept (Poster),False,Projection-Based Constrained Policy Optimization,"[""Tsung-Yen Yang"", ""Justinian Rosca"", ""Karthik Narasimhan"", ""Peter J. Ramadge""]","[""Reinforcement learning with constraints"", ""Safe reinforcement learning""]","We propose a new algorithm that learns constraint-satisfying policies, and provide theoretical analysis and empirical demonstration in the context of reinforcement learning with constraints.",2010.03152,cs.LG,2020-10-07 04:22:45+00:00,2020-10-07 04:22:45+00:00
rke3U6NtwH,2020,Reject,False,MxPool: Multiplex Pooling for Hierarchical Graph Representation Learning,"[""Yanyan Liang"", ""Yanfeng Zhang"", ""Fangjing Wang"", ""Qian Xu""]","[""GNN"", ""graph pooling"", ""graph representation learning""]",,,,,
rke41hC5Km,2019,Reject,False,Generating Realistic Stock Market Order Streams,"[""Junyi Li"", ""Xintong Wang"", ""Yaoyang Lin"", ""Arunesh Sinha"", ""Michael P. Wellman""]","[""application in finance"", ""stock markets"", ""generative models""]",We propose an approach to generate realistic and high-fidelity stock market data based on generative adversarial networks.,,,,
rke4HiAcY7,2019,Accept (Poster),False,Caveats for information bottleneck in deterministic scenarios,"[""Artemy Kolchinsky"", ""Brendan D. Tracey"", ""Steven Van Kuyk""]","[""information bottleneck"", ""supervised learning"", ""deep learning"", ""information theory""]",Information bottleneck behaves in surprising ways whenever the output is a deterministic function of the input.,,,,
rke5R1SFwS,2020,Reject,True,Learning to Remember from a Multi-Task Teacher,"[""Yuwen Xiong"", ""Mengye Ren"", ""Raquel Urtasun""]","[""Meta-learning"", ""sequential learning"", ""catastrophic forgetting""]",We propose a new meta-learning algorithm for sequential representation learning,1910.04650,cs.LG,2019-10-10 15:33:19+00:00,2020-02-13 07:27:07+00:00
rke7geHtwH,2020,Accept (Poster),False,Keep Doing What Worked: Behavior Modelling Priors for Offline Reinforcement Learning,"[""Noah Siegel"", ""Jost Tobias Springenberg"", ""Felix Berkenkamp"", ""Abbas Abdolmaleki"", ""Michael Neunert"", ""Thomas Lampe"", ""Roland Hafner"", ""Nicolas Heess"", ""Martin Riedmiller""]","[""Reinforcement Learning"", ""Off-policy"", ""Multitask"", ""Continuous Control""]","We develop a method for stable offline reinforcement learning from logged data. The key is to regularize the RL policy towards a learned ""advantage weighted"" model of the data.",,,,
rke8ZhCcFQ,2019,Reject,False,ATTACK GRAPH CONVOLUTIONAL NETWORKS BY ADDING FAKE NODES,"[""Xiaoyun Wang"", ""Joe Eaton"", ""Cho-Jui Hsieh"", ""Felix Wu""]","[""Graph Convolutional Network"", ""adversarial attack"", ""node classification""]",non-targeted and targeted attack on GCN by adding fake nodes,,,,
rkeIIkHKvS,2020,Accept (Poster),False,Measuring and Improving the Use of Graph Information in Graph Neural Networks,"[""Yifan Hou"", ""Jian Zhang"", ""James Cheng"", ""Kaili Ma"", ""Richard T. B. Ma"", ""Hongzhi Chen"", ""Ming-Chang Yang""]",[],,,,,
rkeIq2VYPr,2020,Accept (Poster),False,Deep Learning of Determinantal Point Processes via Proper Spectral Sub-gradient,"[""Tianshu Yu"", ""Yikang Li"", ""Baoxin Li""]","[""determinantal point processes"", ""deep learning"", ""optimization""]",We proposed a specific back-propagation method via proper spectral sub-gradient to integrate determinantal point process to deep learning framework.,,,,
rkeJRhNYDH,2020,Accept (Poster),True,TabFact: A Large-scale Dataset for Table-based Fact Verification,"[""Wenhu Chen"", ""Hongmin Wang"", ""Jianshu Chen"", ""Yunkai Zhang"", ""Hong Wang"", ""Shiyang Li"", ""Xiyou Zhou"", ""William Yang Wang""]","[""Fact Verification"", ""Tabular Data"", ""Symbolic Reasoning""]",We propose a new dataset to investigate the entailment problem under semi-structured table as premise,1909.02164,cs.CL,2019-09-05 00:25:17+00:00,2020-06-14 19:14:22+00:00
rkeMHjR9Ym,2019,Reject,False,Stochastic Gradient Descent Learns State Equations with Nonlinear Activations,"[""Samet Oymak""]","[""recurrent neural network"", ""state equation"", ""gradient descent"", ""sample complexity""]",We study the state equation of a recurrent neural network. We show that SGD can efficiently learn the unknown dynamics from few input/output observations under proper assumptions.,,,,
rkeNfp4tPr,2020,Accept (Poster),False,Escaping Saddle Points Faster with Stochastic Momentum,"[""Jun-Kun Wang"", ""Chi-Heng Lin"", ""Jacob Abernethy""]","[""SGD"", ""momentum"", ""escaping saddle point""]",Higher momentum parameter $\beta$ helps for escaping saddle points faster,2106.02985,cs.LG,2021-06-05 23:34:02+00:00,2021-06-05 23:34:02+00:00
rkeNqkBFPB,2020,Reject,False,Deep automodulators,"[""Ari Heljakka"", ""Yuxin Hou"", ""Juho Kannala"", ""Arno Solin""]","[""unsupervised learning"", ""generative models"", ""autoencoders"", ""disentanglement"", ""style transfer""]","A novel autoencoder model that supports mutually independent decoder layers, enabling e.g. style mixing.",1912.10321,cs.LG,2019-12-21 19:16:33+00:00,2020-10-29 12:58:09+00:00
rkeNr6EKwB,2020,Reject,True,Small-GAN: Speeding up GAN Training using Core-Sets,"[""Samarth Sinha"", ""Han Zhang"", ""Anirudh Goyal"", ""Yoshua Bengio"", ""Hugo Larochelle"", ""Augustus Odena""]","[""GANs"", ""Coreset""]",We use Core-set sampling to help alleviate the problem of using large mini-batches for GAN training.,1910.13540,stat.ML,2019-10-29 21:26:05+00:00,2019-10-29 21:26:05+00:00
rkeO-lrYwr,2020,Reject,False,Mode Connectivity and Sparse Neural Networks,"[""Jonathan Frankle"", ""Gintare Karolina Dziugaite"", ""Daniel M. Roy"", ""Michael Carbin""]","[""sparsity"", ""mode connectivity"", ""lottery ticket"", ""optimization landscape""]",Whether or not a sparse subnetwork trains to the same accuracy of the full network depends on whether two runs of SGD on the subnetwork land in the same convex levelset.,,,,
rkePU0VYDr,2020,Reject,False,A Perturbation Analysis of Input Transformations for Adversarial Attacks,"[""Adam Dziedzic"", ""Sanjay Krishnan""]","[""adversarial examples"", ""defenses"", ""stochastic channels"", ""deterministic channels"", ""input transformations"", ""compression"", ""noise"", ""convolutional neural networks""]",We identify a family of defense techniques and show that both deterministic lossy compression and randomized perturbations to the input lead to similar gains in robustness.,,,,
rkeS1RVtPS,2020,Accept (Talk),True,Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning,"[""Ruqi Zhang"", ""Chunyuan Li"", ""Jianyi Zhang"", ""Changyou Chen"", ""Andrew Gordon Wilson""]",[],,1902.03932,cs.LG,2019-02-11 15:03:30+00:00,2020-05-11 20:49:28+00:00
rkeSiiA5Fm,2019,Accept (Poster),False,Deep Learning 3D Shapes Using Alt-az Anisotropic 2-Sphere Convolution,"[""Min Liu"", ""Fupin Yao"", ""Chiho Choi"", ""Ayan Sinha"", ""Karthik Ramani""]","[""Spherical Convolution"", ""Geometric deep learning"", ""3D shape analysis""]",A method for applying deep learning to 3D surfaces using their spherical descriptors and alt-az anisotropic convolution on 2-sphere.,,,,
rkeT8iR9Y7,2019,Reject,False,Directional Analysis of Stochastic Gradient Descent via von Mises-Fisher Distributions in Deep Learning,"[""Cheolhyoung Lee"", ""Kyunghyun Cho"", ""Wanmo Kang""]","[""directional statistics"", ""deep learning"", ""SNR"", ""gradient stochasticity"", ""SGD"", ""stochastic gradient"", ""von Mises-Fisher"", ""angle""]",One of theoretical issues in deep learning,,,,
rkeUcRNtwS,2020,Reject,False,Salient Explanation for Fine-grained Classification,"[""Kanghan Oh"", ""Sungchan Kim"", ""Il-Seok Oh""]","[""Visual explanation"", ""XAI"", ""Constitutional Neural Network""]",,,,,
rkeUrjCcYQ,2019,Reject,False,Monge-Amp\`ere Flow for Generative Modeling,"[""Linfeng Zhang"", ""Weinan E"", ""Lei Wang""]","[""generative modeling"", ""Monge-Amp\\`ere equation"", ""dynamical system"", ""optimal transport"", ""density estimation"", ""free energy calculation""]",A gradient flow based dynamical system for invertible generative modeling,,,,
rkeX-3Rqtm,2019,Reject,False,Training Hard-Threshold Networks with Combinatorial Search in a Discrete Target Propagation Setting,"[""Lukas Nabergall"", ""Justin Toth"", ""Leah Cousins""]","[""hard-threshold network"", ""combinatorial optimization"", ""search"", ""target propagation""]",,,,,
rkeYL1SFvH,2020,Reject,True,WikiMatrix: Mining 135M Parallel Sentences in 1620 Language Pairs from Wikipedia,"[""Holger Schwenk"", ""Vishrav Chaudhary"", ""Shuo Sun"", ""Hongyu Gong"", ""Francisco Guzm\u00e1n""]","[""multilinguality"", ""bitext mining"", ""neural MT"", ""Wikipedia"", ""low-resource languages"", ""joint sentence representation""]","Large-scale bitext extraction from Wikipedia: 1620 language pairs in 85 languages, 135M parallel sentences, Systematic NMT evaluation on TED test set.",1907.05791,cs.CL,2019-07-10 23:57:30+00:00,2019-07-16 00:14:48+00:00
rkeYUsRqKQ,2019,Reject,False,An Adversarial Learning Framework for a Persona-based Multi-turn Dialogue Model,"[""Oluwatobi O. Olabiyi"", ""Anish Khazane"", ""Alan Salimov"", ""Erik T.Mueller""]","[""conversation model"", ""dialogue system"", ""adversarial net"", ""persona""]",This paper develops an adversarial learning framework for neural conversation models with persona,,,,
rkeYvaNKPr,2020,Reject,False,Trajectory representation learning for Multi-Task NMRDPs planning,"[""Firas JARBOUI"", ""Vianney PERCHET"", ""Roman EGGER""]","[""Representation Learning"", ""State Estimation"", ""Non Markovian Decision Process""]",Expanding NMRDPs into MDPs using trajectory representation learning,,,,
rkeZ9a4Fwr,2020,Reject,False,Disentangling Improves VAEs' Robustness to Adversarial Attacks,"[""Matthew Willetts"", ""Alexander Camuto"", ""Stephen Roberts"", ""Chris Holmes""]",[],"We show that disentangled VAEs are more robust than vanilla VAEs to adversarial attacks that aim to trick them into decoding the adversarial input to a chosen target. We then develop an even more robust hierarchical disentangled VAE, Seatbelt-VAE.",,,,
rkeZIJBYvr,2020,Accept (Talk),True,Learning to Balance: Bayesian Meta-Learning for Imbalanced and Out-of-distribution Tasks,"[""Hae Beom Lee"", ""Hayeon Lee"", ""Donghyun Na"", ""Saehoon Kim"", ""Minseop Park"", ""Eunho Yang"", ""Sung Ju Hwang""]","[""meta-learning"", ""few-shot learning"", ""Bayesian neural network"", ""variational inference"", ""learning to learn"", ""imbalanced and out-of-distribution tasks for few-shot learning""]","A novel meta-learning model that adaptively balances the effect of the meta-learning and task-specific learning, and also class-specific learning within each task.",1905.12917,cs.LG,2019-05-30 09:07:22+00:00,2020-02-25 10:29:03+00:00
rkeZNREFDr,2020,Reject,True,Not All Features Are Equal: Feature Leveling Deep Neural Networks for Better Interpretation,"[""Yingjing Lu"", ""Runde Yang""]",[],,1905.10009,cs.LG,2019-05-24 02:53:45+00:00,2019-05-29 21:01:43+00:00
rkeZRGbRW,2018,Reject,False,Variance Regularizing Adversarial Learning,"[""Karan Grewal"", ""R Devon Hjelm"", ""Yoshua Bengio""]","[""Generative Adversarial Network"", ""Integral Probability Metric"", ""Meta-Adversarial Learning""]","We introduce meta-adversarial learning, a new technique to regularize GANs, and propose a training method by explicitly controlling the discriminator's output distribution.",,,,
rke_YiRct7,2019,Accept (Poster),True,Small nonlinearities in activation functions create bad local minima in neural networks,"[""Chulhee Yun"", ""Suvrit Sra"", ""Ali Jadbabaie""]","[""spurious local minima"", ""loss surface"", ""optimization landscape"", ""neural network""]","We constructively prove that even the slightest nonlinear activation functions introduce spurious local minima, for general datasets and activation functions.",1802.03487,cs.LG,2018-02-10 00:49:17+00:00,2019-05-28 15:25:47+00:00
rkecJ6VFvr,2020,Accept (Poster),False,Logic and the 2-Simplicial Transformer,"[""James Clift"", ""Dmitry Doryn"", ""Daniel Murfet"", ""James Wallbridge""]","[""transformer"", ""logic"", ""reinforcement learning"", ""reasoning""]",We introduce the 2-simplicial Transformer and show that this architecture is a useful inductive bias for logical reasoning in the context of deep reinforcement learning.,,,,
rkecl1rtwB,2020,Accept (Poster),True,PairNorm: Tackling Oversmoothing in GNNs,"[""Lingxiao Zhao"", ""Leman Akoglu""]","[""Graph Neural Network"", ""oversmoothing"", ""normalization""]",We proposed a normalization layer for GNN models to solve the oversmoothing problem.,1909.12223,cs.LG,2019-09-26 16:20:37+00:00,2020-02-13 02:27:25+00:00
rkedXgrKDH,2020,Reject,False,Trajectory growth through random deep ReLU networks,"[""Ilan Price"", ""Jared Tanner""]","[""Deep networks"", ""expressivity"", ""trajectory growth"", ""sparse neural networks""]",The expected trajectory growth of a random sparsely connected deep neural network is exponential in depth across many distributions including the default initialisations used in Tensorflow and Pytorch,1911.10651,stat.ML,2019-11-25 01:01:10+00:00,2019-11-25 01:01:10+00:00
rked_6NFwH,2020,Reject,False,Path Space for Recurrent Neural Networks with ReLU Activations,"[""Yue Wang"", ""Qi Meng"", ""Wei Chen"", ""Yuting Liu"", ""Zhi-Ming Ma"", ""Tie-Yan Liu""]","[""optimization"", ""neural network"", ""positively scale-invariant"", ""path space"", ""deep learning"", ""RNN""]","We construct a new parameter space, called path space, for the ReLU RNN and employ optimization algorithms in it. We can obtain more effective RNN models in path space than using conventional optimization methods in the weight space.",,,,
rkeeoeHYvr,2020,Reject,False,AdvCodec: Towards A Unified Framework for Adversarial Text Generation,"[""Boxin Wang"", ""Hengzhi Pei"", ""Han Liu"", ""Bo Li""]","[""adversarial text generation"", ""tree-autoencoder"", ""human evaluation""]","we propose a novel framework AdvCodec to generate adversarial text agaist general NLP tasks based on tree-autoencoder, and we show that AdvCodec outperforms other baselines and achieves high performance in human evaluation.",,,,
rkegcC4YvS,2020,Reject,False,Removing the Representation Error of GAN Image Priors Using the Deep Decoder,"[""Max Daniels"", ""Reinhard Heckel"", ""Paul Hand""]","[""deep decoder"", ""deep image prior"", ""GAN"", ""inverse problems""]","A linear combination of a GAN and a Deep Decoder is an effective natural signal prior for inverse problems, outperforming both components on both in- and out-of-distribution images.",,,,
rkehoAVtvS,2020,Reject,True,Adversarial Paritial Multi-label Learning,"[""Yan Yan"", ""Yuhong Guo""]",[],,1909.06717,cs.LG,2019-09-15 02:34:07+00:00,2020-06-05 04:11:26+00:00
rkeiQlBFPB,2020,Accept (Talk),True,Meta-Learning with Warped Gradient Descent,"[""Sebastian Flennerhag"", ""Andrei A. Rusu"", ""Razvan Pascanu"", ""Francesco Visin"", ""Hujun Yin"", ""Raia Hadsell""]","[""meta-learning"", ""transfer learning""]","We propose a novel framework for meta-learning a gradient-based update rule that scales to beyond few-shot learning and is applicable to any form of learning, including continual learning.",1909.00025,cs.LG,2019-08-30 18:27:35+00:00,2020-02-18 08:57:58+00:00
rkej86VYvB,2020,Reject,False,Temporal Difference Weighted Ensemble For Reinforcement Learning,"[""Takuma Seno"", ""Michita Imai""]","[""reinforcement learning"", ""ensemble"", ""deep q-network""]",Ensemble method for reinforcement learning that weights Q-functions based on accumulated TD errors.,,,,
rkem91rtDB,2020,Accept (Poster),False,Inductive and Unsupervised Representation Learning on Graph Structured Objects,"[""Lichen Wang"", ""Bo Zong"", ""Qianqian Ma"", ""Wei Cheng"", ""Jingchao Ni"", ""Wenchao Yu"", ""Yanchi Liu"", ""Dongjin Song"", ""Haifeng Chen"", ""Yun Fu""]","[""Graph representation learning"", ""Graph isomorphism"", ""Graph similarity learning""]",This paper proposed a novel framework for graph similarity learning in inductive and unsupervised scenario.,,,,
rkemqsC9Fm,2019,Accept (Poster),False,Information Theoretic lower bounds on negative log likelihood,"[""Luis A. Lastras-Monta\u00f1o""]","[""latent variable modeling"", ""rate-distortion theory"", ""log likelihood bounds""]",Use rate-distortion theory to bound how much a latent variable model can be improved,,,,
rkenmREFDr,2020,Accept (Poster),True,Learning Space Partitions for Nearest Neighbor Search,"[""Yihe Dong"", ""Piotr Indyk"", ""Ilya Razenshteyn"", ""Tal Wagner""]","[""space partition"", ""lsh"", ""locality sensitive hashing"", ""nearest neighbor search""]",We use supervised learning (and in particular deep learning) to produce better space partitions for fast nearest neighbor search.,1901.08544,cs.LG,2019-01-24 18:07:59+00:00,2020-09-29 02:50:54+00:00
rkeqCoA5tX,2019,Reject,False,LEARNING GENERATIVE MODELS FOR DEMIXING OF STRUCTURED SIGNALS FROM THEIR SUPERPOSITION USING GANS,"[""Mohammadreza Soltani"", ""Swayambhoo Jain"", ""Abhinav V. Sambasivan""]","[""Generative Models"", ""GANs"", ""Denosing"", ""Demixing"", ""Structured Recovery""]",,,,,
rkeqn1rtDH,2020,Reject,False,Hierarchical Graph Matching Networks for Deep Graph Similarity Learning,"[""Xiang Ling"", ""Lingfei Wu"", ""Saizhuo Wang"", ""Tengfei Ma"", ""Fangli Xu"", ""Chunming Wu"", ""Shouling Ji""]","[""Graph Neural Network"", ""Graph Matching Network"", ""Graph Similarity Learning""]",Hierarchical Graph Matching Networks,,,,
rkerLaVtDr,2020,Reject,True,A General Upper Bound for Unsupervised Domain Adaptation,"[""Dexuan Zhang"", ""Tatsuya Harada""]","[""unsupervised domain adaptation"", ""upper bound"", ""joint error"", ""hypothesis space constraint"", ""cross margin discrepancy""]",joint error matters for unsupervised domain adaptation especially when the domain shift is huge,1910.01409,cs.LG,2019-10-03 11:31:14+00:00,2019-10-04 07:40:18+00:00
rkesVkHtDr,2020,Reject,False,Meta-Learning Runge-Kutta,"[""Nadine Behrmann"", ""Patrick Schramowski"", ""Kristian Kersting""]",[],,,,,
rket4i0qtX,2019,Reject,False,"The meaning of ""most"" for visual question answering models","[""Alexander Kuhnle"", ""Ann Copestake""]","[""quantifier"", ""evaluation methodology"", ""psycholinguistics"", ""visual question answering""]",Psychology-inspired evaluation of quantifier understanding for visual question answering models,,,,
rketraEtPr,2020,Reject,False,Learning Time-Aware Assistance Functions for Numerical Fluid Solvers,"[""Kiwon Um"", ""Yun (Raymond) Fei"", ""Philipp Holl"", ""Nils Thuerey""]","[""PDEs"", ""convolutional neural networks"", ""numerical simulation"", ""fluids""]",We introduce a neural network approach to assist partial differential equation solvers.,,,,
rkeu30EtvS,2020,Accept (Spotlight),False,Network Deconvolution,"[""Chengxi Ye"", ""Matthew Evanusa"", ""Hua He"", ""Anton Mitrokhin"", ""Tom Goldstein"", ""James A. Yorke"", ""Cornelia Fermuller"", ""Yiannis Aloimonos""]","[""convolutional networks"", ""network deconvolution"", ""whitening""]",We propose a method called network deconvolution that resembles animal vision system to train convolution networks better.,,,,
rkeuAhVKvB,2020,Accept (Poster),True,Dynamically Pruned Message Passing Networks for Large-scale Knowledge Graph Reasoning,"[""Xiaoran Xu"", ""Wei Feng"", ""Yunsheng Jiang"", ""Xiaohui Xie"", ""Zhiqing Sun"", ""Zhi-Hong Deng""]","[""knowledge graph reasoning"", ""graph neural networks"", ""attention mechanism""]"," We propose to learn an input-dependent subgraph, dynamically and selectively expanded, to explicitly model a sequential reasoning process.",1909.11334,cs.AI,2019-09-25 08:15:41+00:00,2020-04-07 21:39:59+00:00
rkevMnRqYQ,2019,Accept (Poster),False,Preferences Implicit in the State of the World,"[""Rohin Shah"", ""Dmitrii Krasheninnikov"", ""Jordan Alexander"", ""Pieter Abbeel"", ""Anca Dragan""]","[""Preference learning"", ""Inverse reinforcement learning"", ""Inverse optimal stochastic control"", ""Maximum entropy reinforcement learning"", ""Apprenticeship learning""]","When a robot is deployed in an environment that humans have been acting in, the state of the environment is already optimized for what humans want, and we can use this to infer human preferences.",,,,
rkevSgrtPr,2020,Accept (Poster),False,A closer look at the approximation capabilities of neural networks,"[""Kai Fong Ernest Chong""]","[""deep learning"", ""approximation"", ""universal approximation theorem""]",A quantitative refinement of the universal approximation theorem via an algebraic approach.,2002.06505,cs.LG,2020-02-16 04:58:43+00:00,2020-02-16 04:58:43+00:00
rkewaxrtvr,2020,Reject,False,Privacy-preserving Representation Learning by Disentanglement,"[""Tassilo Klein"", ""Moin Nabi""]",[],,,,,
rkezdaEtvH,2020,Reject,True,Hyperbolic Discounting and Learning Over Multiple Horizons,"[""William Fedus"", ""Carles Gelada"", ""Yoshua Bengio"", ""Marc G. Bellemare"", ""Hugo Larochelle""]","[""Deep learning"", ""reinforcement learning"", ""discounting"", ""hyperbolic discounting"", ""auxiliary tasks""]",A deep RL agent that learns hyperbolic (and other non-exponential) Q-values and a new multi-horizon auxiliary task.,1902.06865,stat.ML,2019-02-19 02:36:14+00:00,2019-02-28 18:32:24+00:00
rkfOvGbCW,2018,Accept (Poster),False,Memory-based Parameter Adaptation,"[""Pablo Sprechmann"", ""Siddhant M. Jayakumar"", ""Jack W. Rae"", ""Alexander Pritzel"", ""Adria Puigdomenech Badia"", ""Benigno Uria"", ""Oriol Vinyals"", ""Demis Hassabis"", ""Razvan Pascanu"", ""Charles Blundell""]",[],,,,,
rkfbLilAb,2018,Reject,False,Improving Search Through A3C Reinforcement Learning Based Conversational Agent,"[""Milan Aggarwal"", ""Aarushi Arora"", ""Shagun Sodhani"", ""Balaji Krishnamurthy""]","[""Subjective search"", ""Reinforcement Learning"", ""Conversational Agent"", ""Virtual user model"", ""A3C"", ""Context aggregation""]",A Reinforcement Learning based conversational search assistant which provides contextual assistance in subjective search (like digital assets).,,,,
rkg-TJBFPB,2020,Accept (Poster),False,RIDE: Rewarding Impact-Driven Exploration for Procedurally-Generated Environments,"[""Roberta Raileanu"", ""Tim Rockt\u00e4schel""]","[""reinforcement learning"", ""exploration"", ""curiosity""]",Reward agents for taking actions that lead to changes in the environment state.,2002.12292,cs.LG,2020-02-27 18:03:16+00:00,2020-02-29 16:12:58+00:00
rkg-mA4FDr,2020,Accept (Poster),False,Pre-training Tasks for Embedding-based Large-scale Retrieval,"[""Wei-Cheng Chang"", ""Felix X. Yu"", ""Yin-Wen Chang"", ""Yiming Yang"", ""Sanjiv Kumar""]","[""natural language processing"", ""large-scale retrieval"", ""unsupervised representation learning"", ""paragraph-level pre-training"", ""two-tower Transformer models""]",We consider large-scale retrieval problems such as question answering retrieval and present a comprehensive study of how different sentence level pre-training improving the BERT-style token-level pre-training for two-tower Transformer models.,2002.03932,cs.LG,2020-02-10 16:44:00+00:00,2020-02-10 16:44:00+00:00
rkg0_eHtDr,2020,Reject,False,Benefits of Overparameterization in Single-Layer Latent Variable Generative Models,"[""Rares-Darius Buhai"", ""Andrej Risteski"", ""Yoni Halpern"", ""David Sontag""]","[""overparameterization"", ""unsupervised"", ""parameter recovery"", ""rigorous experiments""]",Overparameterization aids parameter recovery in unsupervised settings.,,,,
rkg1ngrFPr,2020,Accept (Poster),False,Information Geometry of Orthogonal Initializations and Training,"[""Piotr Aleksander Sok\u00f3\u0142"", ""Il Memming Park""]","[""Fisher"", ""mean-field"", ""deep learning""]","nearly isometric DNN initializations imply low parameter space curvature, and a lower condition number, but that's not always great",,,,
rkg3kRNKvH,2020,Reject,False,Linguistic Embeddings as a Common-Sense Knowledge Repository: Challenges and Opportunities,"[""Nancy Fulda""]","[""knowledge representation"", ""word embeddings"", ""sentence embeddings"", ""common-sense knowledge""]","This paper presents a paradigm and methodology for using learned sentence representations as emergent, flexible knowledge bases that can be queried using linear algebra.",,,,
rkg5fh0ctQ,2019,Reject,False,Transferring SLU Models in Novel Domains,"[""Yaohua Tang"", ""Kaixiang Mo"", ""Qian Xu"", ""Chao Zhang"", ""Qiang Yang""]","[""transfer learning"", ""semantic representation"", ""spoken language understanding""]",v3,,,,
rkg6FgrtPB,2020,Reject,False,Biologically Plausible Neural Networks via Evolutionary Dynamics and Dopaminergic Plasticity,"[""Sruthi Gorantla"", ""Anand Louis"", ""Christos H. Papadimitriou"", ""Santosh Vempala"", ""Naganand Yadati""]","[""Biological plausibility"", ""dopaminergic plasticity"", ""allele frequency"", ""neural net evolution""]",,,,,
rkg6PhNKDr,2020,Reject,False,HOW IMPORTANT ARE NETWORK WEIGHTS? TO WHAT EXTENT DO THEY NEED AN UPDATE?,"[""Fawaz Sammani"", ""Mahmoud Elsayed"", ""Abdelsalam Hamdi""]","[""weights update"", ""weights importance"", ""weight freezing""]","An experimental paper that proves the amount of redundant weights that can be freezed from the third epoch only, with only a very slight drop in accuracy.",,,,
rkg6sJHYDr,2020,Accept (Talk),True,Intrinsically Motivated Discovery of Diverse Patterns in Self-Organizing Systems,"[""Chris Reinke"", ""Mayalen Etcheverry"", ""Pierre-Yves Oudeyer""]","[""deep learning"", ""unsupervised Learning"", ""self-organization"", ""game-of-life""]",We study how an unsupervised exploration and feature learning approach addresses efficiently a new problem: automatic discovery of diverse self-organized patterns in high-dim complex systems such as the game of life.,1908.06663,cs.LG,2019-08-19 09:32:46+00:00,2020-02-17 14:43:54+00:00
rkg8FJBYDS,2020,Reject,True,Variational Diffusion Autoencoders with Random Walk Sampling,"[""Henry Li"", ""Ofir Lindenbaum"", ""Xiuyuan Cheng"", ""Alexander Cloninger""]","[""generative models"", ""variational inference"", ""manifold learning"", ""diffusion maps""]",We combine variational inference and manifold learning (specifically VAEs and diffusion maps) to build a generative model based on a diffusion random walk on a data manifold; we generate samples by drawing from the walk's stationary distribution.,1905.12724,cs.LG,2019-05-29 21:06:09+00:00,2020-08-27 12:52:00+00:00
rkg8xTEtvB,2020,Reject,False,Hierarchical Disentangle Network for Object Representation Learning,"[""Shishi Qiao"", ""Ruiping Wang"", ""Shiguang Shan"", ""Xilin Chen""]",[],Disentangle the primitives of objects in different hierarchy levels,,,,
rkg98yBFDr,2020,Reject,False,Reject Illegal Inputs: Scaling Generative Classifiers with Supervised Deep Infomax,"[""Xin WANG"", ""SiuMing Yiu""]","[""generative classifiers"", ""selective classification"", ""classification with rejection""]","scale generative classifiers  on complex datasets, and evaluate their effectiveness to reject illegal inputs including out-of-distribution samples and adversarial examples.",,,,
rkgAGAVKPr,2020,Accept (Poster),True,Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples,"[""Eleni Triantafillou"", ""Tyler Zhu"", ""Vincent Dumoulin"", ""Pascal Lamblin"", ""Utku Evci"", ""Kelvin Xu"", ""Ross Goroshin"", ""Carles Gelada"", ""Kevin Swersky"", ""Pierre-Antoine Manzagol"", ""Hugo Larochelle""]","[""few-shot learning"", ""meta-learning"", ""few-shot classification""]","We propose a new large-scale diverse environment for few-shot learning, and evaluate popular models' performance on it, revealing important research challenges.",1903.03096,cs.LG,2019-03-07 18:48:55+00:00,2020-04-08 15:58:20+00:00
rkgAb1Btvr,2020,Reject,False,Fourier networks for uncertainty estimates and out-of-distribution detection,"[""Hartmut Maennel"", ""Alexandru \u021aifrea""]","[""Fourier network"", ""out-of-distribution detection"", ""large initialization"", ""uncertainty"", ""ensembles""]",Using sine activations and large weight initialization to mitigate some of the issues regular ensembles face on out-of-distribution detection tasks.,,,,
rkgBHoCqYX,2019,Accept (Poster),False,A Kernel Random Matrix-Based Approach for Sparse PCA,"[""Mohamed El Amine Seddik"", ""Mohamed Tamaazousti"", ""Romain Couillet""]","[""Random Matrix Theory"", ""Concentration of Measure"", ""Sparse PCA"", ""Covariance Thresholding""]",,,,,
rkgCJ64tDB,2020,Reject,True,Scale-Equivariant Neural Networks with Decomposed Convolutional Filters,"[""Wei Zhu"", ""Qiang Qiu"", ""Robert Calderbank"", ""Guillermo Sapiro"", ""Xiuyuan Cheng""]","[""scale-equivariant"", ""convolutional neural network"", ""deformation robustness""]",We construct scale-equivariant convolutional neural networks in the most general form with both computational efficiency and proved deformation robustness.,1909.11193,cs.LG,2019-09-24 21:23:19+00:00,2021-05-18 18:41:42+00:00
rkgFXR4KPr,2020,Reject,False,A Simple Recurrent Unit with Reduced Tensor Product Representations,"[""Shuai Tang"", ""Paul Smolensky"", ""Virginia R. de Sa""]","[""RNNs"", ""TPRs""]",,,,,
rkgHY0NYwr,2020,Accept (Poster),False,Discovering Motor Programs by Recomposing Demonstrations,"[""Tanmay Shankar"", ""Shubham Tulsiani"", ""Lerrel Pinto"", ""Abhinav Gupta""]","[""Learning from Demonstration"", ""Imitation Learning"", ""Motor Primitives""]","We learn a space of motor primitives from unannotated robot demonstrations, and show these primitives are semantically meaningful and can be composed for new robot tasks.",,,,
rkgIW1HKPB,2020,Reject,False,Unsupervised Representation Learning by Predicting Random Distances,"[""Hu Wang"", ""Guansong Pang"", ""Chunhua Shen"", ""Congbo Ma""]","[""representation learning"", ""unsupervised learning"", ""anomaly detection"", ""clustering""]","This paper introduces a novel Random Distance Prediction model to learn expressive feature representations in a fully unsupervised fashion by predicting random distances, enabling substantially improved anomaly detection and clustering performance.",1912.12186,cs.CV,2019-12-22 05:09:11+00:00,2020-07-19 11:57:46+00:00
rkgIllBtwB,2020,Reject,False,Exploring the Correlation between Likelihood of Flow-based Generative Models and Image Semantics,"[""Xin WANG"", ""SiuMing Yiu""]","[""flow-based generative models"", ""out-of-distribution samples detection"", ""likelihood robustness""]",show experimental evidences about the weak correlation between flows' likelihoods and image semantics.,,,,
rkgK3oC5Fm,2019,Accept (Poster),False,Bayesian Prediction of Future Street Scenes using Synthetic Likelihoods,"[""Apratim Bhattacharyya"", ""Mario Fritz"", ""Bernt Schiele""]","[""bayesian inference"", ""segmentation"", ""anticipation"", ""multi-modality""]",Dropout based Bayesian inference is extended to deal with multi-modality and is evaluated on scene anticipation tasks.,,,,
rkgKBhA5Y7,2019,Accept (Poster),False,There Are Many Consistent Explanations of Unlabeled Data: Why You Should Average,"[""Ben Athiwaratkun"", ""Marc Finzi"", ""Pavel Izmailov"", ""Andrew Gordon Wilson""]","[""semi-supervised learning"", ""computer vision"", ""classification"", ""consistency regularization"", ""flatness"", ""weight averaging"", ""stochastic weight averaging""]",Consistency-based models for semi-supervised learning do not converge to a single point but continue to explore a diverse set of plausible solutions on the perimeter of a flat region. Weight averaging helps improve generalization performance.,,,,
rkgKW64FPH,2020,Reject,True,Constant Time Graph Neural Networks,"[""Ryoma Sato"", ""Makoto Yamada"", ""Hisashi Kashima""]","[""graph neural networks"", ""constant time algorithm""]",We propose an approximation algorithm of GNNs that works in constant time with respect to the input size.,1901.07868,cs.LG,2019-01-23 13:25:16+00:00,2020-02-08 12:42:08+00:00
rkgMNnC9YQ,2019,Reject,False,ATTENTIVE EXPLAINABILITY FOR PATIENT TEMPORAL EMBEDDING,"[""Daby Sow"", ""Mohamed Ghalwash"", ""Zach Shahn"", ""Sanjoy Dey"", ""Moulay Draidia"", ""Li-wei Lehmann""]",[],,,,,
rkgMkCEtPB,2020,Accept (Poster),True,Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML,"[""Aniruddh Raghu"", ""Maithra Raghu"", ""Samy Bengio"", ""Oriol Vinyals""]","[""deep learning analysis"", ""representation learning"", ""meta-learning"", ""few-shot learning""]","The success of MAML relies on feature reuse from the meta-initialization, which also yields a natural simplification of the algorithm, with the inner loop removed for the network body, as well as other insights on the head and body.",1909.09157,cs.LG,2019-09-19 16:30:42+00:00,2020-02-12 15:29:39+00:00
rkgNKkHtvB,2020,Accept (Talk),False,Reformer: The Efficient Transformer,"[""Nikita Kitaev"", ""Lukasz Kaiser"", ""Anselm Levskaya""]","[""attention"", ""locality sensitive hashing"", ""reversible layers""]",Efficient Transformer with locality-sensitive hashing and reversible layers,,,,
rkgO66VKDS,2020,Accept (Poster),True,LEARNED STEP SIZE QUANTIZATION,"[""Steven K. Esser"", ""Jeffrey L. McKinstry"", ""Deepika Bablani"", ""Rathinakumar Appuswamy"", ""Dharmendra S. Modha""]","[""deep learning"", ""low precision"", ""classification"", ""quantization""]",A method for learning quantization configuration for low precision networks that achieves state of the art performance for quantized networks.,1902.08153,cs.LG,2019-02-21 17:31:32+00:00,2020-05-07 03:30:49+00:00
rkgOLb-0W,2018,Accept (Poster),False,Neural Language Modeling by Jointly Learning Syntax and Lexicon,"[""Yikang Shen"", ""Zhouhan Lin"", ""Chin-wei Huang"", ""Aaron Courville""]","[""Language model"", ""unsupervised parsing""]","In this paper, We propose a novel neural language model, called the Parsing-Reading-Predict Networks (PRPN), that can simultaneously induce the syntactic structure from unannotated sentences and leverage the inferred structure to learn a better language model.",,,,
rkgOlCVYvB,2020,Accept (Poster),True,Pure and Spurious Critical Points: a Geometric Study of Linear Networks,"[""Matthew Trager"", ""Kathl\u00e9n Kohn"", ""Joan Bruna""]","[""Loss landscape"", ""linear networks"", ""algebraic geometry""]",,1910.01671,cs.LG,2019-10-03 18:22:30+00:00,2020-04-03 02:46:46+00:00
rkgPnhNFPB,2020,Reject,False,Random Matrix Theory Proves that Deep Learning Representations of GAN-data Behave as Gaussian Mixtures,"[""Mohamed El Amine Seddik"", ""Cosme Louart"", ""Mohamed Tamaazousti"", ""Romain Couillet""]","[""Random Matrix Theory"", ""Deep Learning Representations"", ""GANs""]",,2001.08370,cs.LG,2020-01-21 22:17:09+00:00,2020-01-21 22:17:09+00:00
rkgQL6VFwr,2020,Reject,False,Learning Generative Image Object Manipulations from Language Instructions,"[""Martin L\u00e4ngkvist"", ""Andreas Persson"", ""Amy Loutfi""]",[],,,,,
rkgT3jRct7,2019,Accept (Poster),False,Large-Scale Answerer in Questioner's Mind for Visual Dialog Question Generation,"[""Sang-Woo Lee"", ""Tong Gao"", ""Sohee Yang"", ""Jaejun Yoo"", ""Jung-Woo Ha""]",[],,,,,
rkgTdkrtPH,2020,Reject,False,NoiGAN: NOISE AWARE KNOWLEDGE GRAPH EMBEDDING WITH GAN,"[""Kewei Cheng"", ""Yikai Zhu"", ""Ming Zhang"", ""Yizhou Sun""]","[""Knowledge graph embedding"", ""Noise aware""]",We proposed a unified Generative Adversarial Networks (GAN) framework to learn noise-aware knowledge graph embedding.,,,,
rkgU1gHtvr,2020,Accept (Poster),True,Infinite-horizon Off-Policy Policy Evaluation with Multiple Behavior Policies,"[""Xinyun Chen"", ""Lu Wang"", ""Yizhe Hang"", ""Heng Ge"", ""Hongyuan Zha""]","[""off-policy policy evaluation"", ""multiple importance sampling"", ""kernel method"", ""variance reduction""]",A new partially policy-agnostic method for infinite-horizon off-policy policy evalution with multiple known or unknown behavior policies.,1910.04849,cs.LG,2019-10-10 21:01:07+00:00,2019-10-10 21:01:07+00:00
rkgW0oA9FX,2019,Accept (Poster),False,Graph HyperNetworks for Neural Architecture Search,"[""Chris Zhang"", ""Mengye Ren"", ""Raquel Urtasun""]","[""neural"", ""architecture"", ""search"", ""graph"", ""network"", ""hypernetwork"", ""meta"", ""learning"", ""anytime"", ""prediction""]",,,,,
rkgZ3oR9FX,2019,Reject,False,Learning to Refer to 3D Objects with Natural Language,"[""Panos Achlioptas"", ""Judy E. Fan"", ""Robert X.D. Hawkins"", ""Noah D. Goodman"", ""Leo Guibas""]","[""Referential Language"", ""3D Objects"", ""Part-Awareness"", ""Neural Speakers"", ""Neural Listeners""]","How to build neural-speakers/listeners that learn fine-grained characteristics of 3D objects, from referential language.",,,,
rkgb9kSKwS,2020,Reject,False,Spectral Nonlocal Block for Neural Network,"[""Lei Zhu"", ""Qi She"", ""Lidan Zhang"", ""Ping guo""]","[""Nonlocal Neural Network"", ""Image Classification"", ""Action Recgonition""]",,,,,
rkgbYyHtwB,2020,Accept (Spotlight),False,Disagreement-Regularized Imitation Learning,"[""Kiante Brantley"", ""Wen Sun"", ""Mikael Henaff""]","[""imitation learning"", ""reinforcement learning"", ""uncertainty""]",Method for addressing covariate shift in imitation learning using ensemble uncertainty,,,,
rkgbwsAcYm,2019,Accept (Poster),False,DELTA: DEEP LEARNING TRANSFER USING FEATURE MAP WITH ATTENTION FOR CONVOLUTIONAL NETWORKS,"[""Xingjian Li"", ""Haoyi Xiong"", ""Hanchao Wang"", ""Yuxuan Rao"", ""Liping Liu"", ""Jun Huan""]","[""transfer learning"", ""deep learning"", ""regularization"", ""attention"", ""cnn""]",improving deep transfer learning with regularization using attention based feature maps,,,,
rkgc06VtwH,2020,Reject,True,Improving Semantic Parsing with Neural Generator-Reranker Architecture,"[""Huseyin A. Inan"", ""Gaurav Singh Tomar"", ""Huapu Pan""]","[""Natural Language Processing"", ""Semantic Parsing"", ""Neural Reranking""]",,1909.12764,cs.CL,2019-09-27 16:10:06+00:00,2019-09-27 16:10:06+00:00
rkgd0iA9FQ,2019,Reject,True,Convergence Guarantees for RMSProp and ADAM in Non-Convex Optimization and an Empirical Comparison to Nesterov Acceleration,"[""Soham De"", ""Anirbit Mukherjee"", ""Enayat Ullah""]","[""adaptive gradient descent"", ""deeplearning"", ""ADAM"", ""RMSProp"", ""autoencoders""]",In this paper we prove convergence to criticality of (stochastic and deterministic) RMSProp and deterministic ADAM for smooth non-convex objectives and we demonstrate an interesting beta_1 sensitivity for ADAM on autoencoders. ,1807.06766,cs.LG,2018-07-18 03:58:02+00:00,2018-11-20 21:57:15+00:00
rkgdYhVtvH,2020,Reject,False,Unifying Graph Convolutional Neural Networks and Label Propagation,"[""Hongwei Wang"", ""Jure Leskovec""]","[""graph convolutional neural networks"", ""label propagation"", ""node classification""]","This paper studies theoretical relationships between Graph Convolutional Neural Networks (GCN) and Label Propagation Algorithm (LPA), then proposes an end-to-end model that unifies GCN and LPA for node classification.",2002.06755,cs.LG,2020-02-17 03:23:13+00:00,2020-02-17 03:23:13+00:00
rkgfWh0qKX,2019,Reject,False,Do Language Models Have Common Sense?,"[""Trieu H. Trinh"", ""Quoc V. Le""]",[],We present evidence that LMs do capture common sense with state-of-the-art results on both Winograd Schema Challenge and Commonsense Knowledge Mining.,,,,
rkgfdeBYvH,2020,Accept (Poster),True,Effect of Activation Functions on the Training of Overparametrized Neural Nets,"[""Abhishek Panigrahi"", ""Abhishek Shetty"", ""Navin Goyal""]","[""activation functions"", ""deep learning theory"", ""neural networks""]",We provide theoretical results about the effect of activation function on the training of highly overparametrized 2-layer neural networks,1908.05660,cs.LG,2019-08-16 16:22:07+00:00,2020-04-10 13:22:00+00:00
rkgg6xBYDH,2020,Accept (Poster),False,Understanding Generalization in Recurrent Neural Networks,"[""Zhuozhuo Tu"", ""Fengxiang He"", ""Dacheng Tao""]","[""generalization"", ""recurrent neural networks"", ""learning theory""]",We prove generalization bounds for recurrent neural networks based on matrix 1-norm and Fisher-Rao norm.,,,,
rkgiURVFDS,2020,Reject,False,Certified Robustness to Adversarial Label-Flipping Attacks via Randomized Smoothing,"[""Elan Rosenfeld"", ""Ezra Winston"", ""Pradeep Ravikumar"", ""J. Zico Kolter""]","[""Adversarial Robustness"", ""Label Flipping Attack"", ""Data Poisoning Attack""]",We propose a classifier that is certifiably robust against an adversary that flips labels to target each test point independently; we then show how this classifier can be evaluated at no additional runtime cost over traditional classification.,2002.03018,cs.LG,2020-02-07 21:28:30+00:00,2020-08-11 13:17:30+00:00
rkgl51rKDB,2020,Reject,False,Efficient meta reinforcement learning via meta goal generation,"[""Haotian Fu"", ""Hongyao Tang"", ""Jianye Hao""]",[],,,,,
rkglZyHtvH,2020,Reject,False,Refining the variational posterior through iterative optimization,"[""Marton Havasi"", ""Jasper Snoek"", ""Dustin Tran"", ""Jonathan Gordon"", ""Jos\u00e9 Miguel Hern\u00e1ndez-Lobato""]","[""uncertainty estimation"", ""variational inference"", ""auxiliary variables"", ""Bayesian neural networks""]",The paper proposes an algorithm to increase the flexibility of the variational posterior in Bayesian neural networks through iterative optimization.,,,,
rkglvsC9Ym,2019,Reject,False,Log Hyperbolic Cosine Loss Improves Variational Auto-Encoder,"[""Pengfei Chen"", ""Guangyong Chen"", ""Shengyu Zhang""]","[""Unsupervised Generative Model"", ""VAE"", ""log hyperbolic cosine loss""]","We propose to train VAE with a new reconstruction loss, the log hyperbolic cosine (log-cosh) loss, which can significantly improve the performance of VAE and its variants in output quality, measured by sharpness and FID score.",,,,
rkgoyn09KQ,2019,Accept (Poster),False,textTOvec: DEEP CONTEXTUALIZED NEURAL AUTOREGRESSIVE TOPIC MODELS OF LANGUAGE WITH DISTRIBUTED COMPOSITIONAL PRIOR,"[""Pankaj Gupta"", ""Yatin Chaudhary"", ""Florian Buettner"", ""Hinrich Schuetze""]","[""neural topic model"", ""natural language processing"", ""text representation"", ""language modeling"", ""information retrieval"", ""deep learning""]",Unified neural model of topic and language modeling to introduce language structure  in topic models for contextualized topic vectors ,,,,
rkgpCoRctm,2019,Reject,False,Detecting Out-Of-Distribution Samples Using Low-Order Deep Features Statistics,"[""Igor M. Quintanilha"", ""Roberto de M. E. Filho"", ""Jos\u00e9 Lezama"", ""Mauricio Delbracio"", ""Leonardo O. Nunes""]","[""computer vision"", ""out-of-distribution detection"", ""image classification""]",Detecting out-of-distribution samples by using low-order feature statistics without requiring any change in underlying DNN.,,,,
rkgpv2VFvr,2020,Accept (Poster),False,Sharing Knowledge in Multi-Task Deep Reinforcement Learning,"[""Carlo D'Eramo"", ""Davide Tateo"", ""Andrea Bonarini"", ""Marcello Restelli"", ""Jan Peters""]","[""Deep Reinforcement Learning"", ""Multi-Task""]",A study on the benefit of sharing representation in Multi-Task Reinforcement Learning.,,,,
rkgpy3C5tX,2019,Accept (Poster),False,Amortized Bayesian Meta-Learning,"[""Sachin Ravi"", ""Alex Beatson""]","[""variational inference"", ""meta-learning"", ""few-shot learning"", ""uncertainty quantification""]",We propose a meta-learning method which efficiently amortizes hierarchical variational inference across training episodes.,,,,
rkgqCiRqKQ,2019,Reject,False,Inferring Reward Functions from Demonstrators with Unknown Biases,"[""Rohin Shah"", ""Noah Gundotra"", ""Pieter Abbeel"", ""Anca Dragan""]","[""Inverse reinforcement learning"", ""differentiable planning""]","When we infer preferences from behavior, we can try to improve accuracy by jointly learning a bias model and preferences, though this requires new assumptions to make progress.",,,,
rkgqN1SYvr,2020,Accept (Poster),False,Provable Benefit of Orthogonal Initialization in Optimizing Deep Linear Networks,"[""Wei Hu"", ""Lechao Xiao"", ""Jeffrey Pennington""]","[""deep learning theory"", ""non-convex optimization"", ""orthogonal initialization""]","We provide for the first time a rigorous proof that orthogonal initialization speeds up convergence relative to Gaussian initialization, for deep linear networks.",2001.05992,cs.LG,2020-01-16 18:48:34+00:00,2020-01-16 18:48:34+00:00
rkgqm0VKwB,2020,Reject,False,End-to-end named entity recognition and relation extraction using pre-trained language models,"[""John Giorgi"", ""Xindi Wang"", ""Nicola Sahar"", ""Won Young Shin"", ""Gary Bader"", ""Bo Wang""]","[""named entity recognition"", ""relation extraction"", ""information extraction"", ""information retrival"", ""transfer learning"", ""multi-task learning"", ""BERT"", ""transformers"", ""language models""]","A novel, high-performing architecture for end-to-end named entity recognition and relation extraction that is fast to train.",,,,
rkgrbTNtDr,2020,Reject,False,Style-based Encoder Pre-training for Multi-modal Image Synthesis,"[""Moustafa Meshry"", ""Yixuan Ren"", ""Ricardo Martin-Brualla"", ""Larry Davis"", ""Abhinav Shrivastava""]","[""image-to_image translation"", ""representation learning"", ""multi-modal image synthesis"", ""GANs""]",Multi-modal image-to-image translation via encoder pre-training to encode the distribution of output variability.,,,,
rkgsvoA9K7,2019,Reject,False,Dirichlet Variational Autoencoder,"[""Weonyoung Joo"", ""Wonsung Lee"", ""Sungrae Park"", ""and Il-Chul Moon""]","[""Variational autoencoder"", ""Unsupervised learning"", ""(Semi-)Supervised learning"", ""Topic modeling""]",,,,,
rkgt0REKwS,2020,Accept (Poster),True,Curriculum Loss: Robust Learning and Generalization  against Label Corruption,"[""Yueming Lyu"", ""Ivor W. Tsang""]","[""Curriculum Learning"", ""deep learning""]",A novel loss bridges curriculum learning and robust learning,1905.10045,cs.LG,2019-05-24 06:04:18+00:00,2020-02-21 00:10:43+00:00
rkguLC4tPB,2020,Reject,False,Unknown-Aware Deep Neural Network,"[""Lei Cao"", ""Yizhou Yan"", ""Samuel Madden"", ""Elke Rundensteiner""]","[""unknown"", ""rejection"", ""CNN"", ""product relationship""]",A CNN architecture that can effective rejects the unknowns in test objects,,,,
rkgv9oRqtQ,2019,Reject,False,Compound Density Networks,"[""Agustinus Kristiadi"", ""Asja Fischer""]","[""uncertainty in neural networks"", ""ensemble"", ""mixture model""]",,,,,
rkgvXlrKwH,2020,Accept (Talk),False,SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference,"[""Lasse Espeholt"", ""Rapha\u00ebl Marinier"", ""Piotr Stanczyk"", ""Ke Wang"", ""Marcin Michalski\u200e""]","[""machine learning"", ""reinforcement learning"", ""scalability"", ""distributed"", ""DeepMind Lab"", ""ALE"", ""Atari-57"", ""Google Research Football""]","SEED RL, a scalable and efficient deep reinforcement learning agent with accelerated central inference. State of the art results, reduces cost and can process millions of frames per second. ",,,,
rkgwuiA9F7,2019,Reject,False,Cramer-Wold AutoEncoder,"[""Jacek Tabor"", ""Szymon Knop"", ""Przemys\u0142aw Spurek"", ""Igor Podolak"", ""Marcin Mazur"", ""Stanis\u0142aw Jastrz\u0119bski""]","[""autoencoder"", ""generative models"", ""deep neural networks""]",Inspired by prior work on Sliced-Wasserstein Autoencoders (SWAE) and kernel smoothing we construct a new generative model â Cramer-Wold AutoEncoder (CWAE).,,,,
rkgyS0VFvr,2020,Accept (Poster),False,DBA: Distributed Backdoor Attacks against Federated Learning,"[""Chulin Xie"", ""Keli Huang"", ""Pin-Yu Chen"", ""Bo Li""]","[""distributed backdoor attack"", ""federated learning""]","We proposed a novel distributed backdoor attack on federated learning and show that it is not only more effective compared with standard centralized attacks, but also harder to be defended by existing robust FL methods",,,,
rkgz2aEKDr,2020,Accept (Poster),True,On the Variance of the Adaptive Learning Rate and Beyond,"[""Liyuan Liu"", ""Haoming Jiang"", ""Pengcheng He"", ""Weizhu Chen"", ""Xiaodong Liu"", ""Jianfeng Gao"", ""Jiawei Han""]","[""warmup"", ""adam"", ""adaptive learning rate"", ""variance""]","If warmup is the answer, what is the question?",1908.03265,cs.LG,2019-08-08 20:51:17+00:00,2021-10-26 02:48:30+00:00
rkhCSO4T-,2018,Reject,False,Distributed non-parametric deep and wide networks,"[""Biswa Sengupta"", ""Yu Qian""]",[],,,,,
rkhlb8lCZ,2018,Accept (Poster),False,Wavelet Pooling for Convolutional Neural Networks,"[""Travis Williams"", ""Robert Li""]","[""Pooling"", ""Wavelet"", ""CNN"", ""Neural Network"", ""Deep Learning"", ""Classification"", ""Machine Learning"", ""Object Recognition""]","Pooling is achieved using wavelets instead of traditional neighborhood approaches (max, average, etc).",,,,
rkhxwltab,2018,Reject,False,AANN: Absolute Artificial Neural Network,"[""Animesh Karnewar""]","[""Neural Network architecture"", ""Learned representation space"", ""absolute valued function"", ""bidirectional neuron""]","Tied weights auto-encoder with abs function as activation function, learns to do classification in the forward direction and regression in the backward direction due to specially defined cost function.",,,,
rkjZ2Pcxe,2017,Reject,False,Adding Gradient Noise Improves Learning for Very Deep Networks,"[""Arvind Neelakantan"", ""Luke Vilnis"", ""Quoc V. Le"", ""Lukasz Kaiser"", ""Karol Kurach"", ""Ilya Sutskever"", ""James Martens""]",[],Adding annealed Gaussian noise to the gradient improves training of neural networks in ways complementary to adaptive learning algorithms and the noise introduced by SGD.,,,,
rkl03ySYDH,2020,Accept (Poster),False,SPACE: Unsupervised Object-Oriented Scene Representation via Spatial Attention and Decomposition,"[""Zhixuan Lin"", ""Yi-Fu Wu"", ""Skand Vishwanath Peri"", ""Weihao Sun"", ""Gautam Singh"", ""Fei Deng"", ""Jindong Jiang"", ""Sungjin Ahn""]","[""Generative models"", ""Unsupervised scene representation"", ""Object-oriented representation"", ""spatial attention""]",We propose a generative latent variable model for unsupervised scene decomposition that provides factorized object representation per foreground object while also decomposing background segments of complex morphology.,2001.02407,cs.LG,2020-01-08 07:44:32+00:00,2020-03-15 20:21:38+00:00
rkl2s34twS,2020,Reject,True,Wildly Unsupervised Domain Adaptation and Its Powerful and Efficient Solution,"[""Feng Liu"", ""Jie Lu"", ""Bo Han"", ""Gang Niu"", ""Guangquan Zhang"", ""Masashi Sugiyama""]",[],,1905.07720,cs.LG,2019-05-19 10:25:32+00:00,2021-02-18 02:53:04+00:00
rkl3-hA5Y7,2019,Reject,False,Towards Decomposed Linguistic Representation with Holographic Reduced Representation,"[""Jiaming Luo"", ""Yuan Cao"", ""Yonghui Wu""]",[],Holographic Reduced Representation enables language model to discover linguistic roles.,,,,
rkl3m1BFDB,2020,Accept (Poster),False,Exploratory Not Explanatory: Counterfactual Analysis of Saliency Maps for Deep Reinforcement Learning,"[""Akanksha Atrey"", ""Kaleigh Clary"", ""David Jensen""]","[""explainability"", ""saliency maps"", ""representations"", ""deep reinforcement learning""]",Proposing a new counterfactual-based methodology to evaluate the hypotheses generated from saliency maps about deep RL agent behavior. ,1912.05743,cs.LG,2019-12-09 12:42:07+00:00,2020-02-20 21:40:15+00:00
rkl42iA5t7,2019,Reject,False,NETWORK COMPRESSION USING CORRELATION ANALYSIS OF LAYER RESPONSES,"[""Xavier Suau"", ""Luca Zappella"", ""Nicholas Apostoloff""]","[""Artificial Intelligence"", ""Deep learning"", ""Machine learning"", ""Compression""]","We propose an easy to implement, yet effective method for neural network compression. PFA exploits the intrinsic correlation between filter responses within network layers to recommend a smaller network footprints.",,,,
rkl44TEtwH,2020,Reject,False,Composable Semi-parametric Modelling for Long-range Motion Generation,"[""Jingwei Xu"", ""Huazhe Xu"", ""Bingbing Ni"", ""Xiaokang Yang"", ""Trevor Darrell""]","[""Semi-parametric"", ""Long-range"", ""Motion Generation""]","We propose a semi-parametric model to generate long-range, diverse and visually natural motion sequence.",,,,
rkl4M3R5K7,2019,Reject,False,Optimal Attacks against Multiple Classifiers,"[""Juan C. Perdomo"", ""Yaron Singer""]","[""online learning"", ""nonconvex optimization"", ""robust optimization""]","Paper analyzes the problem of designing adversarial attacks against multiple classifiers, introducing algorithms that are optimal for linear classifiers and which provide state-of-the-art results for deep learning.",,,,
rkl6As0cF7,2019,Accept (Poster),False,Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning,"[""Ying Wen"", ""Yaodong Yang"", ""Rui Luo"", ""Jun Wang"", ""Wei Pan""]","[""Multi-agent Reinforcement Learning"", ""Recursive Reasoning""]",We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.,,,,
rkl8dlHYvB,2020,Accept (Poster),False,Learning to Group: A Bottom-Up Framework for 3D Part Discovery in Unseen Categories,"[""Tiange Luo"", ""Kaichun Mo"", ""Zhiao Huang"", ""Jiarui Xu"", ""Siyu Hu"", ""Liwei Wang"", ""Hao Su""]","[""Shape Segmentation"", ""Zero-Shot Learning"", ""Learning Representations""]","A zero-shot segmentation framework for 3D shapes. Model the segmentation as a decision-making process, we propose an iterative method to dynamically extend the receptive field for achieving universal shape segmentation.",2002.06478,cs.CV,2020-02-16 00:23:43+00:00,2021-09-18 03:30:24+00:00
rkl8sJBYvH,2020,Accept (Spotlight),True,Harnessing the Power of Infinitely Wide Deep Nets on Small-data Tasks,"[""Sanjeev Arora"", ""Simon S. Du"", ""Zhiyuan Li"", ""Ruslan Salakhutdinov"", ""Ruosong Wang"", ""Dingli Yu""]","[""small data"", ""neural tangent kernel"", ""UCI database"", ""few-shot learning"", ""kernel SVMs"", ""deep learning theory"", ""kernel design""]","We verify neural tangent kernel is powerful on small data via experiments on UCI datasets, small CIFAR 10 and low-shot learning on VOC07.",1910.01663,cs.LG,2019-10-03 18:04:17+00:00,2019-10-27 17:53:30+00:00
rklB76EKPr,2020,Accept (Poster),False,Can gradient clipping mitigate label noise?,"[""Aditya Krishna Menon"", ""Ankit Singh Rawat"", ""Sashank J. Reddi"", ""Sanjiv Kumar""]",[],"Gradient clipping doesn't endow robustness to label noise, but a simple loss-based variant does.",,,,
rklEUjR5tm,2019,Reject,False,SHE2: Stochastic Hamiltonian Exploration and Exploitation for Derivative-Free Optimization,"[""Haoyi Xiong"", ""Wenqing Hu"", ""Zhanxing Zhu"", ""Xinjian Li"", ""Yunchao Zhang"", ""Jun Huan""]","[""derivative-free optimization""]",a new derivative-free optimization algorithms derived from Nesterov's accelerated gradient methods and Hamiltonian dynamics,,,,
rklEj2EFvB,2020,Accept (Spotlight),False,Estimating Gradients for Discrete Random Variables by Sampling without Replacement,"[""Wouter Kool"", ""Herke van Hoof"", ""Max Welling""]","[""gradient"", ""estimator"", ""discrete"", ""categorical"", ""sampling"", ""without replacement"", ""reinforce"", ""baseline"", ""variance"", ""gumbel"", ""vae"", ""structured prediction""]","We derive a low-variance, unbiased gradient estimator for expectations over discrete random variables based on sampling without replacement",2002.06043,cs.LG,2020-02-14 14:15:18+00:00,2020-02-14 14:15:18+00:00
rklFh34Kwr,2020,Reject,True,Bayesian Inference for Large Scale Image Classification,"[""Jonathan Heek"", ""Nal Kalchbrenner""]","[""image classification"", ""bayesian inference"", ""mcmc"", ""imagenet""]",We scale Bayesian Inference to ImageNet classification and achieve competitive results accuracy and uncertainty calibration.,1908.03491,cs.LG,2019-08-09 15:15:56+00:00,2019-08-09 15:15:56+00:00
rklHqRVKvH,2020,Accept (Talk),True,Harnessing Structures for Value-Based Planning and Reinforcement Learning,"[""Yuzhe Yang"", ""Guo Zhang"", ""Zhi Xu"", ""Dina Katabi""]","[""Deep reinforcement learning"", ""value-based reinforcement learning""]",We propose a generic framework that allows for exploiting the low-rank structure in both planning and deep reinforcement learning.,1909.12255,cs.LG,2019-09-26 17:01:23+00:00,2020-07-04 15:53:48+00:00
rklJ2CEYPH,2020,Reject,False,Point Process Flows,"[""Nazanin Mehrasa"", ""Ruizhi Deng"", ""Mohamed Osama Ahmed"", ""Bo Chang"", ""Jiawei He"", ""Thibaut Durand"", ""Marcus Brubaker"", ""Greg Mori""]","[""Temporal Point Process"", ""Intensity-free Point Process""]",A non-parametric point process model via Normalizing Flow,,,,
rklMnyBtPB,2020,Reject,False,Adversarial Robustness Against the Union of Multiple Perturbation Models,"[""Pratyush Maini"", ""Eric Wong"", ""Zico Kolter""]","[""adversarial"", ""robustness"", ""multiple perturbation"", ""MNIST"", ""CIFAR10""]","We develop a generalization of the standard PGD-based procedure to train architectures which are robust against multiple perturbation models, outperforming past approaches on the MNIST and CIFAR10 datasets.",,,,
rklOg6EFwS,2020,Accept (Poster),False,Improving Adversarial Robustness Requires Revisiting Misclassified Examples,"[""Yisen Wang"", ""Difan Zou"", ""Jinfeng Yi"", ""James Bailey"", ""Xingjun Ma"", ""Quanquan Gu""]","[""Robustness"", ""Adversarial Defense"", ""Adversarial Training""]","By differentiating misclassified and correctly classified data, we propose a new misclassification aware defense that improves the state-of-the-art adversarial robustness.",,,,
rklPITVKvS,2020,Reject,False,BRIDGING ADVERSARIAL SAMPLES AND ADVERSARIAL NETWORKS,"[""Faqiang Liu"", ""Mingkun Xu"", ""Guoqi Li"", ""Jing Pei"", ""Luping Shi""]","[""ADVERSARIAL SAMPLES"", ""ADVERSARIAL NETWORKS""]","We introduce adversarial training on real samples that does not exist in standard GANs to make discriminator more robust, which can stabilize training, accelerate convergence, and achieve better performance.",,,,
rklQas09tm,2019,Reject,False,Learning Corresponded Rationales for Text Matching,"[""Mo Yu"", ""Shiyu Chang"", ""Tommi S Jaakkola""]","[""interpretability"", ""rationalization"", ""text matching"", ""dependent selection""]","We propose a novel self-explaining architecture to predict matches between two sequences of texts. Specifically, we introduce the notion of corresponded rationales and learn to extract them by the distal supervision from the downstream task.",,,,
rklTmyBKPH,2020,Accept (Poster),False,Fast Neural Network Adaptation via Parameter Remapping and Architecture Search,"[""Jiemin Fang*"", ""Yuzhu Sun*"", ""Kangjian Peng*"", ""Qian Zhang"", ""Yuan Li"", ""Wenyu Liu"", ""Xinggang Wang""]",[],,,,,
rklVOnNtwH,2020,Reject,False,Out-of-Distribution Detection Using Layerwise Uncertainty in Deep Neural Networks,"[""Hirono Okamoto"", ""Masahiro Suzuki"", ""Yutaka Matsuo""]","[""out-of-distribution"", ""uncertainty""]",We propose a method that extracts the uncertainties of features in each layer of DNNs and combines them for detecting OOD samples when solving classification tasks.,,,,
rklXaoAcFX,2019,Reject,False,Geomstats: a Python Package for Riemannian Geometry in Machine Learning,"[""Nina Miolane"", ""Johan Mathe"", ""Claire Donnat"", ""Mikael Jorda"", ""Xavier Pennec""]","[""Riemannian geometry"", ""Python package"", ""machine learning"", ""deep learning""]","We introduce geomstats, an efficient Python package for Riemannian modelization and optimization over manifolds compatible with both numpy and tensorflow .",,,,
rkl_Ch4YwS,2020,Reject,False,A TWO-STAGE FRAMEWORK FOR MATHEMATICAL EXPRESSION RECOGNITION,"[""Jin Zhang"", ""Weipeng Ming"", ""Pengfei Liu""]","[""mathematical expressions recognition"", ""seq2seq model""]",,,,,
rkl_f6EFPS,2020,Reject,True,The Probabilistic Fault Tolerance of Neural Networks in the Continuous Limit,"[""El-Mahdi El-Mhamdi"", ""Rachid Guerraoui"", ""Andrei Kucharavy"", ""Sergei Volodin""]","[""Robustness"", ""theory of neural networks"", ""fault tolerance"", ""continuous limit"", ""Taylor expansion"", ""error bound"", ""neuromorphic computing"", ""continuous networks"", ""functional derivative""]",We give a bound for NNs on the output error in case of random weight failures using a Taylor expansion in the continuous limit where nearby neurons are similar,1902.01686,stat.ML,2019-02-05 14:08:21+00:00,2019-09-25 14:18:27+00:00
rklaWn0qK7,2019,Accept (Poster),False,Learning Neural PDE Solvers with Convergence Guarantees,"[""Jun-Ting Hsieh"", ""Shengjia Zhao"", ""Stephan Eismann"", ""Lucia Mirabella"", ""Stefano Ermon""]","[""Partial differential equation"", ""deep learning""]",We learn a fast neural solver for PDEs that has convergence guarantees.,,,,
rklbKA4YDS,2020,Accept (Poster),True,Gradient-Based Neural DAG Learning,"[""S\u00e9bastien Lachapelle"", ""Philippe Brouillard"", ""Tristan Deleu"", ""Simon Lacoste-Julien""]","[""Structure Learning"", ""Causality"", ""Density estimation""]",We are proposing a new score-based approach to structure/causal learning leveraging neural networks and a recent continuous constrained formulation to this problem,1906.02226,cs.LG,2019-06-05 18:09:55+00:00,2020-02-18 14:49:33+00:00
rkle3i09K7,2019,Reject,False,Robust Determinantal Generative Classifier for Noisy Labels and Adversarial Attacks,"[""Kimin Lee"", ""Sukmin Yun"", ""Kibok Lee"", ""Honglak Lee"", ""Bo Li"", ""Jinwoo Shin""]","[""Noisy Labels"", ""Adversarial Attacks"", ""Generative Models""]",,,,,
rklfIeSFwS,2020,Reject,False,CNAS: Channel-Level Neural Architecture Search,"[""Heechul Lim"", ""Min-Soo Kim"", ""Jinjun Xiong""]","[""Neural architecture search""]",,,,,
rklhb2R9Y7,2019,Reject,False,Reinforced Imitation Learning from Observations,"[""Konrad Zolna"", ""Negar Rostamzadeh"", ""Yoshua Bengio"", ""Sungjin Ahn"", ""Pedro O. Pinheiro""]","[""imitation learning"", ""state-only observations"", ""self-exploration""]",,1904.03438,cs.LG,2019-04-06 13:07:12+00:00,2019-08-26 15:26:06+00:00
rklhqkHFDB,2020,Reject,False,LARGE SCALE REPRESENTATION LEARNING FROM TRIPLET COMPARISONS,"[""Siavash Haghiri"", ""Leena Chennuru Vankadara"", ""Ulrike von Luxburg""]","[""representation learning"", ""triplet comparison"", ""contrastive learning"", ""ordinal embedding""]",,,,,
rkliHyrFDB,2020,Reject,False,Information Theoretic Model Predictive Q-Learning,"[""Mohak Bhardwaj"", ""Ankur Handa"", ""Dieter Fox"", ""Byron Boots""]","[""entropy regularized reinforcement learning"", ""information theoretic MPC"", ""robotics""]",Combining model free soft Q learning and information theoretic model predictive control for efficient learning in robotics problems  ,,,,
rklj3gBYvH,2020,Reject,False,NORML: Nodal Optimization for Recurrent Meta-Learning,"[""David van Niekerk""]","[""meta-learning"", ""learning to learn"", ""few-shot classification"", ""memory-based optimization""]",A novel meta-learning method is introduced where a meta-learner learns to optimize a learner's weight updates by optimizing the input and output to and from each node in the learner network.,,,,
rklk_ySYPB,2020,Accept (Poster),True,Provable robustness against all adversarial $l_p$-perturbations for $p\geq 1$,"[""Francesco Croce"", ""Matthias Hein""]","[""adversarial robustness"", ""provable guarantees""]",We introduce a method to train models with provable robustness wrt all the $l_p$-norms for $p\geq 1$ simultaneously.,1905.11213,cs.LG,2019-05-27 13:49:08+00:00,2020-04-24 13:32:07+00:00
rklklCVYvB,2020,Reject,False,Time2Vec: Learning a Vector Representation of Time,"[""Seyed Mehran Kazemi"", ""Rishab Goel"", ""Sepehr Eghbali"", ""Janahan Ramanan"", ""Jaspreet Sahota"", ""Sanjay Thakur"", ""Stella Wu"", ""Cathal Smyth"", ""Pascal Poupart"", ""Marcus Brubaker""]",[],,,,,
rkllGyBFPH,2020,Accept (Poster),True,Beyond Linearization: On Quadratic and Higher-Order Approximation of Wide Neural Networks,"[""Yu Bai"", ""Jason D. Lee""]","[""Neural Tangent Kernels"", ""over-parametrized neural networks"", ""deep learning theory""]","Wide neural networks can escape the NTK regime and couple with quadratic models, with provably nice optimization landscape and better generalization.",1910.01619,cs.LG,2019-10-03 17:38:10+00:00,2020-02-14 22:55:51+00:00
rklnA34twH,2020,Reject,False,Universal Learning Approach for Adversarial Defense,"[""Uriya Pesso"", ""Koby Bibas"", ""Meir Feder""]","[""Adversarial examples"", ""Adversarial training"", ""Universal learning"", ""pNML for DNN""]",We demonstrate a novel universal-learning driven adversarial defense method to increase robustness and detect adversarial examples.,,,,
rklnDgHtDS,2020,Accept (Poster),False,Compositional Language Continual Learning,"[""Yuanpeng Li"", ""Liang Zhao"", ""Kenneth Church"", ""Mohamed Elhoseiny""]","[""Compositionality"", ""Continual Learning"", ""Lifelong Learning"", ""Sequence to Sequence Modeling""]",,,,,
rklp93EtwH,2020,Accept (Poster),False,Automated Relational Meta-learning,"[""Huaxiu Yao"", ""Xian Wu"", ""Zhiqiang Tao"", ""Yaliang Li"", ""Bolin Ding"", ""Ruirui Li"", ""Zhenhui Li""]","[""meta-learning"", ""task heterogeneity"", ""meta-knowledge graph""]",Addressing task heterogeneity problem in meta-learning by introducing meta-knowledge graph,2001.00745,cs.LG,2020-01-03 07:02:25+00:00,2020-01-03 07:02:25+00:00
rklr9kHFDB,2020,Accept (Talk),False,Rotation-invariant clustering of neuronal responses in primary visual cortex,"[""Ivan Ustyuzhaninov"", ""Santiago A. Cadena"", ""Emmanouil Froudarakis"", ""Paul G. Fahey"", ""Edgar Y. Walker"", ""Erick Cobos"", ""Jacob Reimer"", ""Fabian H. Sinz"", ""Andreas S. Tolias"", ""Matthias Bethge"", ""Alexander S. Ecker""]","[""computational neuroscience"", ""neural system identification"", ""functional cell types"", ""deep learning"", ""rotational equivariance""]",We classify mouse V1 neurons into putative functional cell types based on their representations in a CNN predicting neural responses,,,,
rklraTNFwB,2020,Reject,False,Robust Instruction-Following in a Situated Agent via Transfer-Learning from Text,"[""Felix Hill"", ""Sona Mokra"", ""Nathaniel Wong"", ""Tim Harley""]","[""agent"", ""language"", ""3D"", ""simulation"", ""policy"", ""instruction"", ""transfer""]",Transfer learning from powerful text-based language models makes an agent more robust to human instructions in a 3D simulated world.,2005.09382,cs.CL,2020-05-19 12:16:58+00:00,2020-05-19 12:16:58+00:00
rkltE0VKwH,2020,Reject,True,Coordinated Exploration via Intrinsic Rewards for Multi-Agent Reinforcement Learning,"[""Shariq Iqbal"", ""Fei Sha""]","[""multi-agent reinforcement learning"", ""multi-agent"", ""exploration"", ""intrinsic motivation"", ""MARL"", ""coordinated exploration""]","We propose several intrinsic reward functions for encouraging coordinated exploration in multi-agent problems, and introduce an approach to dynamically selecting the best exploration method for a given task, online.",1905.12127,cs.LG,2019-05-28 23:01:02+00:00,2021-05-22 20:19:01+00:00
rkluJ2R9KQ,2019,Accept (Poster),False,A new dog learns old tricks:  RL finds classic optimization algorithms,"[""Weiwei Kong"", ""Christopher Liaw"", ""Aranyak Mehta"", ""D. Sivakumar""]","[""reinforcement learning"", ""algorithms"", ""adwords"", ""knapsack"", ""secretary""]","By combining ideas from traditional algorithms design and reinforcement learning, we introduce a novel framework for learning algorithms that solve online combinatorial optimization problems.",,,,
rklv-a4tDB,2020,Reject,True,Mesh-Free Unsupervised Learning-Based PDE Solver of Forward and Inverse problems,"[""Leah Bar"", ""Nir Sochen""]","[""PDEs"", ""forward problems"", ""inverse problems"", ""unsupervised learning"", ""deep networks"", ""EIT""]",Solving PDEs with deep learning techniques in an unsupervised fashion with regularizers for forward and inverse problems.,1904.05417,cs.LG,2019-04-10 20:01:48+00:00,2019-04-10 20:01:48+00:00
rklw4AVtDH,2020,Reject,False,Optimistic Adaptive Acceleration for Optimization,"[""Jun-Kun Wang"", ""Xiaoyun Li"", ""Ping Li""]",[],,,,,
rklwwo05Ym,2019,Reject,True,Pushing the bounds of dropout,"[""G\u00e1bor Melis"", ""Charles Blundell"", ""Tom\u00e1\u0161 Ko\u010disk\u00fd"", ""Karl Moritz Hermann"", ""Chris Dyer"", ""Phil Blunsom""]",[],,1805.09208,stat.ML,2018-05-23 14:55:39+00:00,2018-09-27 15:19:20+00:00
rklx-gSYPS,2020,Reject,False,Learning to Optimize via Dual space Preconditioning,"[""S\u00e9lim Chraibi"", ""Adil Salim"", ""Samuel Horv\u00e1th"", ""Filip Hanzely"", ""Peter Richt\u00e1rik""]","[""Optimization"", ""meta-learning""]",,,,,
rklxF0NtDr,2020,Reject,True,Policy Message Passing: A New Algorithm for Probabilistic Graph Inference,"[""Zhiwei Deng"", ""Greg Mori""]","[""graph inference algorithm"", ""graph reasoning"", ""variational inference""]",An probabilistic inference algorithm driven by neural network for graph-structured models,1909.13196,cs.LG,2019-09-29 03:23:17+00:00,2019-09-29 03:23:17+00:00
rkly70EKDH,2020,Reject,True,Mildly Overparametrized Neural Nets can Memorize Training Data Efficiently,"[""Rong Ge"", ""Runzhe Wang"", ""Haoyu Zhao""]","[""nonconvex optimization"", ""optimization landscape"", ""overparametrization""]",We show even mildly overparametrized networks (much smaller than existing results) can be trained to perfectly memorize training data.,1909.11837,cs.LG,2019-09-26 01:19:21+00:00,2019-09-26 01:19:21+00:00
rklz16Vtvr,2020,Reject,False,ISBNet: Instance-aware Selective Branching Networks,"[""Shaofeng Cai"", ""Yao Shu"", ""Wei Wang"", ""Gang Chen"", ""Beng Chin Ooi""]","[""neural networks"", ""neural architecture search"", ""efficient inference""]",,,,,
rklz9iAcKQ,2019,Accept (Poster),True,Deep Graph Infomax,"[""Petar Veli\u010dkovi\u0107"", ""William Fedus"", ""William L. Hamilton"", ""Pietro Li\u00f2"", ""Yoshua Bengio"", ""R Devon Hjelm""]","[""Unsupervised Learning"", ""Graph Neural Networks"", ""Graph Convolutions"", ""Mutual Information"", ""Infomax"", ""Deep Learning""]","A new method for unsupervised representation learning on graphs, relying on maximizing mutual information between local and global representations in a graph. State-of-the-art results, competitive with supervised learning.",1809.10341,stat.ML,2018-09-27 04:53:24+00:00,2018-12-21 15:44:59+00:00
rkmDI85ge,2017,Invite to Workshop Track,False,Efficient Softmax Approximation for GPUs,"[""\u00c9douard Grave"", ""Armand Joulin"", ""Moustapha Ciss\u00e9"", ""David Grangier"", ""Herv\u00e9 J\u00e9gou""]","[""Natural language processing""]",,,,,
rkmoiMbCb,2018,Reject,False,Tandem Blocks in Deep Convolutional Neural Networks,"[""Chris Hettinger"", ""Tanner Christensen"", ""Jeff Humpherys"", ""Tyler J Jarvis""]","[""resnet"", ""residual"", ""shortcut"", ""convolutional"", ""linear"", ""skip"", ""highway""]","We generalize residual blocks to tandem blocks, which use arbitrary linear maps instead of shortcuts, and improve performance over ResNets.",,,,
rkmtTJZCb,2018,Reject,False,Unsupervised Hierarchical Video Prediction,"[""Nevan Wichers"", ""Dumitru Erhan"", ""Honglak Lee""]","[""video prediction"", ""visual analogy network"", ""unsupervised"", ""hierarchical""]",We show ways to train a hierarchical video prediction model without needing pose labels.,,,,
rkmu5b0a-,2018,Accept (Poster),False,MGAN: Training Generative Adversarial Nets with Multiple Generators,"[""Quan Hoang"", ""Tu Dinh Nguyen"", ""Trung Le"", ""Dinh Phung""]","[""GANs"", ""Mode Collapse"", ""Mixture"", ""Jensen-Shannon Divergence"", ""Inception Score"", ""Generator"", ""Discriminator"", ""CIFAR-10"", ""STL-10"", ""ImageNet""]",We propose a new approach to train GANs with a mixture of generators to overcome the mode collapsing problem.,,,,
rknt2Be0-,2018,Accept (Poster),False,Compositional Obverter Communication Learning from Raw Visual Input,"[""Edward Choi"", ""Angeliki Lazaridou"", ""Nando de Freitas""]","[""compositional language"", ""obverter"", ""multi-agent communication"", ""raw pixel input""]",We train neural network agents to develop a language with compositional properties from raw pixel input.,,,,
rkpACe1lx,2017,Accept (Poster),False,HyperNetworks,"[""David Ha"", ""Andrew M. Dai"", ""Quoc V. Le""]","[""Natural language processing"", ""Deep learning"", ""Supervised Learning""]","We train a small RNN to generate weights for a larger RNN, and train the system end-to-end.  We obtain state-of-the-art results on a variety of sequence modelling tasks.",,,,
rkpdnIqlx,2017,Reject,False,The Variational Walkback Algorithm,"[""Anirudh Goyal"", ""Nan Rosemary Ke"", ""Alex Lamb"", ""Yoshua Bengio""]","[""Unsupervised Learning""]",A new algorithm for training undirected graphical models.,,,,
rkpoTaxA-,2018,Accept (Poster),False,Self-ensembling for visual domain adaptation,"[""Geoff French"", ""Michal Mackiewicz"", ""Mark Fisher""]","[""deep learning"", ""neural networks"", ""domain adaptation"", ""images"", ""visual"", ""computer vision""]","Self-ensembling based algorithm for visual domain adaptation, state of the art results, won VisDA-2017 image classification domain adaptation challenge.",,,,
rkr1UDeC-,2018,Accept (Poster),False,Large scale distributed neural network training through online distillation,"[""Rohan Anil"", ""Gabriel Pereyra"", ""Alexandre Passos"", ""Robert Ormandi"", ""George E. Dahl"", ""Geoffrey E. Hinton""]","[""distillation"", ""distributed training"", ""neural networks"", ""deep learning""]",We perform large scale experiments to show that a simple online variant of distillation can help us scale distributed neural network training to more machines.,,,,
rkrC3GbRW,2018,Accept (Poster),False,Learning a Generative Model for Validity in Complex Discrete Structures,"[""Dave Janz"", ""Jos van der Westhuizen"", ""Brooks Paige"", ""Matt Kusner"", ""Jos\u00e9 Miguel Hern\u00e1ndez-Lobato""]","[""Active learning"", ""Reinforcement learning"", ""Molecules""]",,,,,
rkrWCJWAW,2018,Reject,False,Unbiasing Truncated Backpropagation Through Time,"[""Corentin Tallec"", ""Yann Ollivier""]","[""RNN""]",Provides an unbiased version of truncated backpropagation by sampling truncation lengths and reweighting accordingly.,,,,
rksfwnFxl,2017,Reject,False,LSTM-Based System-Call Language Modeling and Ensemble Method for Host-Based Intrusion Detection,"[""Gyuwan Kim"", ""Hayoon Yi"", ""Jangho Lee"", ""Yunheung Paek"", ""Sungroh Yoon""]",[],,,,,
rkuDV6iex,2017,Reject,False,An Empirical Analysis of Deep Network Loss Surfaces,"[""Daniel Jiwoong Im"", ""Michael Tao"", ""Kristin Branson""]","[""Deep learning""]",Analyzing the loss surface of deep neural network trained with different optimization methods,,,,
rkvDssyRb,2018,Reject,False,Multi-Advisor Reinforcement Learning,"[""Romain Laroche"", ""Mehdi Fatemi"", ""Joshua Romoff"", ""Harm van Seijen""]","[""Reinforcement Learning""]",We consider tackling a single-agent RL problem by distributing it to $n$ learners.,,,,
rkw-jlb0W,2018,Reject,False,Deep Lipschitz networks and Dudley GANs,"[""Ehsan Abbasnejad"", ""Javen Shi"", ""Anton van den Hengel""]","[""GAN"", ""Lipschitz neural network""]",,,,,
rkx-wA4YPS,2020,Reject,False,Adapting to Label Shift with Bias-Corrected Calibration,"[""Avanti Shrikumar"", ""Amr M. Alexandari"", ""Anshul Kundaje""]","[""calibration"", ""label shift"", ""domain adaptation"", ""temperature scaling"", ""em"", ""bbse""]",calibration strategies that use class-specific bias correction produce strong performance on label shift domain adaptation,,,,
rkx0g3R5tX,2019,Reject,False,Partially Mutual Exclusive Softmax for Positive and Unlabeled data,"[""Ugo Tanielian"", ""Flavian vasile"", ""Mike Gartrell""]","[""Negative Sampling"", ""Sampled Softmax"", ""Word embeddings"", ""Adversarial Networks""]",Defining a partially mutual exclusive softmax loss for postive data and implementing a cooperative based sampling scheme,,,,
rkx1b64Fvr,2020,Reject,False,A New Multi-input Model with the Attention Mechanism for Text Classification,"[""Junhao Qiu"", ""Ronghua Shi"", ""Fangfang Li (the corresponding author)"", ""Jinjing Shi"", ""Wangmin Liao""]","[""Natural Language Processing"", ""Text Classification"", ""Densent"", ""Multi-input Model"", ""Attention Mechanism""]","We propose a new multi-input  model with a novel attention mechanism, can effectively solve the issues of the shallow text classification model such as  doing not extract long-range associations, global representations, and hierarchical features.",,,,
rkx1m2C5YQ,2019,Reject,False,Recurrent Kalman Networks: Factorized Inference in High-Dimensional Deep Feature Spaces,"[""Philipp Becker"", ""Harit Pandya"", ""Gregor H.W. Gebhardt"", ""Cheng Zhao"", ""Gerhard Neumann""]","[""state estimation"", ""recurrent neural networks"", ""Kalman Filter"", ""deep learning""]","Kalman Filter based recurrent model for efficient state estimation,  principled uncertainty handling and end to end learning of dynamic models in high dimensional spaces.",,,,
rkx3-04FwB,2020,Reject,True,MONET: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit,"[""John Palowitch"", ""Bryan Perozzi""]","[""Graph Embeddings"", ""Representation Learning""]",Introduces a novel graph neural network method for debiasing graph embeddings from metadata and embedding the metadata effect.,1909.11793,cs.LG,2019-09-25 22:12:08+00:00,2020-02-25 07:25:32+00:00
rkx35lHKwB,2020,Reject,False,Generalizing Reinforcement Learning to Unseen Actions,"[""Ayush Jain*"", ""Andrew Szot*"", ""Jincheng Zhou"", ""Joseph J. Lim""]","[""reinforcement learning"", ""unsupervised representation learning"", ""generalization""]",We address the problem of generalization of reinforcement learning to unseen action spaces.,,,,
rkx8l3Cctm,2019,Reject,False,Safe Policy Learning from Observations,"[""Elad Sarafian"", ""Aviv Tamar"", ""Sarit Kraus""]","[""learning from observations"", ""safe reinforcement learning"", ""deep reinforcement learning""]","An algorithm for learning to improve upon the behavior demonstrated by multiple unknown policies, by combining imitation learning and a novel safe policy improvement step that is resilient to value estimation errors.",,,,
rkxDoJBYPB,2020,Accept (Poster),True,Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs,"[""Aditya Paliwal"", ""Felix Gimeno"", ""Vinod Nair"", ""Yujia Li"", ""Miles Lubin"", ""Pushmeet Kohli"", ""Oriol Vinyals""]","[""reinforcement learning"", ""learning to optimize"", ""combinatorial optimization"", ""computation graphs"", ""model parallelism"", ""learning for systems""]","We use deep RL to learn a policy that directs the search of a genetic algorithm to better optimize the execution cost of computation graphs, and show improved results on real-world TensorFlow graphs.",1905.02494,cs.LG,2019-05-07 12:15:06+00:00,2020-02-10 11:57:18+00:00
rkxDon4Yvr,2020,Reject,False,Discriminator Based Corpus Generation for General Code Synthesis,"[""Alexander Wild"", ""Barry Porter""]","[""Code Synthesis"", ""Neural Code Synthesis""]",A way to generate training corpora for neural code synthesis using a discriminator trained on unlabelled data,,,,
rkxEKp4Fwr,2020,Reject,False,Training Data Distribution Search with Ensemble Active Learning,"[""Kashyap Chitta"", ""Jose M. Alvarez"", ""Elmar Haussmann"", ""Clement Farabet""]",[],,,,,
rkxJus0cFX,2019,Reject,False,RedSync : Reducing Synchronization Traffic for Distributed Deep Learning,"[""Jiarui Fang"", ""Cho-Jui Hsieh""]","[""Data parallel"", ""Deep Learning"", ""Multiple GPU system"", ""Communication Compression"", ""Sparsification"", ""Quantization""]",We proposed an implementation to accelerate DNN data parallel training by reducing communication bandwidth requirement.,,,,
rkxKwJrKPS,2020,Reject,False,QXplore: Q-Learning Exploration by Maximizing Temporal Difference Error,"[""Riley Simmons-Edler"", ""Ben Eisner"", ""Daniel Yang"", ""Anthony Bisulco"", ""Eric Mitchell"", ""Sebastian Seung"", ""Daniel Lee""]","[""Deep Reinforcement Learning"", ""Exploration""]",A method for reward-focused efficient exploration in RL using temporal difference errors to train an exploration Q-function,,,,
rkxMKerYwr,2020,Reject,False,Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors,"[""Jiezhang Cao"", ""Jincheng Li"", ""Xiping Hu"", ""Peilin Zhao"", ""Mingkui Tan""]","[""Interpretability of DNNs"", ""Wasserstein distance"", ""Layer behavior""]",Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors,,,,
rkxNelrKPB,2020,Reject,True,On Stochastic Sign Descent Methods,"[""Mher Safaryan"", ""Peter Richt\u00e1rik""]","[""non-convex optimization"", ""stochastic optimization"", ""gradient compression""]","General analysis of sign-based methods (e.g. signSGD) for non-convex optimization, built on intuitive bounds on success probabilities.",1905.12938,math.OC,2019-05-30 09:52:51+00:00,2021-06-24 15:04:42+00:00
rkxNh1Stvr,2020,Accept (Poster),True,Quantifying Point-Prediction Uncertainty in Neural Networks via Residual Estimation with an I/O Kernel,"[""Xin Qiu"", ""Elliot Meyerson"", ""Risto Miikkulainen""]","[""Uncertainty Estimation"", ""Neural Networks"", ""Gaussian Process""]",Learning to Estimate Point-Prediction Uncertainty and Correct Output in Neural Networks,1906.00588,cs.LG,2019-06-03 06:08:57+00:00,2020-06-04 15:26:07+00:00
rkxQ-nA9FX,2019,Accept (Poster),False,Theoretical Analysis of Auto Rate-Tuning by Batch Normalization,"[""Sanjeev Arora"", ""Zhiyuan Li"", ""Kaifeng Lyu""]","[""batch normalization"", ""scale invariance"", ""learning rate"", ""stationary point""]","We give a theoretical analysis of the ability of batch normalization to automatically tune learning rates, in the context of finding stationary points for a deep learning objective.",,,,
rkxUfANKwB,2020,Reject,False,All SMILES Variational Autoencoder for Molecular Property Prediction and Optimization,"[""Zaccary Alperstein"", ""Artem Cherkasov"", ""Jason Rolfe""]","[""generative modelling"", ""variational autoencoder"", ""chemistry"", ""cheminformatics"", ""chemoinformatics"", ""molecular property optimization""]","We pool messages amongst multiple SMILES strings of the same molecule to pass information along all paths through the molecular graph, producing latent representations that significantly surpass the state-of-the-art in a variety of tasks.",,,,
rkxVz1HKwB,2020,Reject,True,Certifiably Robust Interpretation in Deep Learning,"[""Alexander Levine"", ""Sahil Singla"", ""Soheil Feizi""]","[""deep learning interpretation"", ""robustness certificates"", ""adversarial examples""]",We develop an interpretation procedure for deep learning models which is certifiably robust to adversarial attack.,1905.12105,cs.LG,2019-05-28 21:49:40+00:00,2019-10-17 23:09:36+00:00
rkxWpCNKvS,2020,Reject,False,Improved Image Augmentation for Convolutional Neural Networks by Copyout and CopyPairing,"[""Philip May""]","[""image augmentation"", ""cnn"", ""images"", ""augmentation""]",In this work we present two improvements of the state-of-the-art image augmentation techniques. ,,,,
rkxXNR4tvH,2020,Reject,False,Semantic Pruning for Single Class Interpretability,"[""Kamila Abdiyeva"", ""Martin Lukac"", ""Kanat Alimanov""]","[""deep learning"", ""semantic pruning"", ""filter correlation""]",Semantic Pruning for Filter Interpretability,,,,
rkxY-sl0W,2018,Invite to Workshop Track,False,Tree-to-tree Neural Networks for Program Translation,"[""Xinyun Chen"", ""Chang Liu"", ""Dawn Song""]",[],,,,,
rkxZCJrtwS,2020,Reject,False,D3PG: Deep Differentiable Deterministic Policy Gradients,"[""Tao Du"", ""Yunfei Li"", ""Jie Xu"", ""Andrew Spielberg"", ""Kui Wu"", ""Daniela Rus"", ""Wojciech Matusik""]","[""differentiable simulator"", ""model-based control"", ""policy gradients""]",We propose a novel method that leverages the gradients from differentiable simulators to improve the performance of RL for robotics control,,,,
rkxZyaNtwB,2020,Accept (Spotlight),False,Online and stochastic optimization beyond Lipschitz continuity: A Riemannian approach,"[""Kimon Antonakopoulos"", ""E. Veronica Belmega"", ""Panayotis Mertikopoulos""]","[""Online optimization"", ""stochastic optimization"", ""Poisson inverse problems""]",We introduce a novel version of Lipschitz objective continuity that allows stochastic mirror descent methodologies to achieve optimal convergence rates in problems with singularities.,,,,
rkxaNjA9Ym,2019,Accept (Poster),False,Per-Tensor Fixed-Point Quantization of the Back-Propagation Algorithm,"[""Charbel Sakr"", ""Naresh Shanbhag""]","[""deep learning"", ""reduced precision"", ""fixed-point"", ""quantization"", ""back-propagation algorithm""]","We analyze and determine the precision requirements for training neural networks when all tensors, including back-propagated signals and weight accumulators, are quantized to fixed-point format.",,,,
rkxacs0qY7,2019,Accept (Poster),False,FUNCTIONAL VARIATIONAL BAYESIAN NEURAL NETWORKS,"[""Shengyang Sun"", ""Guodong Zhang"", ""Jiaxin Shi"", ""Roger Grosse""]","[""functional variational inference"", ""Bayesian neural networks"", ""stochastic processes""]",We perform functional variational inference on the stochastic processes defined by Bayesian neural networks.,,,,
rkxawlHKDr,2020,Accept (Poster),False,End to End Trainable Active Contours via Differentiable Rendering,"[""Shir Gur"", ""Tal Shaharabany"", ""Lior Wolf""]",[],,1912.00367,cs.CV,2019-12-01 09:27:22+00:00,2019-12-01 09:27:22+00:00
rkxciiC9tm,2019,Accept (Poster),False,NADPEx: An on-policy temporally consistent exploration method for deep reinforcement learning,"[""Sirui Xie"", ""Junning Huang"", ""Lanxin Lei"", ""Chunxiao Liu"", ""Zheng Ma"", ""Wei Zhang"", ""Liang Lin""]","[""Reinforcement learning"", ""exploration""]",,1812.09028,cs.LG,2018-12-21 10:17:29+00:00,2018-12-24 14:22:28+00:00
rkxd2oR9Y7,2019,Reject,False,The Case for Full-Matrix Adaptive Regularization,"[""Naman Agarwal"", ""Brian Bullins"", ""Xinyi Chen"", ""Elad Hazan"", ""Karan Singh"", ""Cyril Zhang"", ""Yi Zhang""]","[""adaptive regularization"", ""non-convex optimization""]","fast, truly scalable full-matrix AdaGrad/Adam, with theory for adaptive stochastic non-convex optimization",,,,
rkxdexBYPB,2020,Reject,False,Group-Transformer: Towards A Lightweight Character-level Language Model,"[""Sungrae Park"", ""Geewook Kim"", ""Junyeop Lee"", ""Junbum Cha"", ""Ji-Hoon Kim Hwalsuk Lee""]","[""Transformer"", ""Lightweight model"", ""Language Modeling"", ""Character-level language modeling""]","This paper proposes a novel lightweight Transformer for character-level language modeling, utilizing group-wise operations.",,,,
rkxfjjA5Km,2019,Reject,False,Auto-Encoding Knockoff Generator for FDR  Controlled Variable Selection,"[""Ying Liu"", ""Cheng Zheng""]","[""Model-X Knockoff Generator"", ""model-free FDR control"", ""variable selection""]","This paper provide model free method for generating Knockoffs, which is critical step in Model-X procedure to choose important variables with any supervised learning method under rigorous FDR control.",,,,
rkxgHerKvH,2020,Reject,False,DEEP GRAPH SPECTRAL EVOLUTION NETWORKS FOR GRAPH TOPOLOGICAL TRANSFORMATION,"[""Liang Zhao"", ""Qingzhe Li"", ""Negar Etemadyrad"", ""Xiaojie Guo""]","[""deep graph learning"", ""graph transformation"", ""brain network""]",,,,,
rkxhX209FX,2019,Reject,False,An Active Learning Framework for Efficient Robust Policy Search,"[""Sai Kiran Narayanaswami"", ""Nandan Sudarsanam"", ""Balaraman Ravindran""]","[""Deep Reinforcement Learning""]",An Active Learning framework that leads to efficient robust RL and opens up possibilities in Multi-Task RL,,,,
rkxjnjA5KQ,2019,Reject,False,Transfer Learning for Related Reinforcement Learning Tasks via Image-to-Image Translation,"[""Shani Gamrian"", ""Yoav Goldberg""]","[""Transfer Learning"", ""Reinforcement Learning"", ""Generative Adversarial Networks"", ""Video Games""]","We propose a method of transferring knowledge between related RL tasks using visual mappings, and demonstrate its effectiveness on visual variants of the Atari Breakout game and different levels of Road Fighter, a Nintendo car driving game.",,,,
rkxkHnA5tX,2019,Reject,False,Learning from Noisy Demonstration Sets via Meta-Learned Suitability Assessor,"[""Te-Lin Wu"", ""Jaedong Hwang"", ""Jingyun Yang"", ""Shaofan Lai"", ""Carl Vondrick"", ""Joseph J. Lim""]","[""Imitation Learning"", ""Noisy Demonstration Set"", ""Meta-Learning""]",We propose a framework to learn a good policy through imitation learning from a noisy demonstration set via meta-training a demonstration suitability assessor.,,,,
rkxmPgrKwB,2020,Reject,False,Weight-space symmetry in neural network loss landscapes revisited,"[""Berfin Simsek"", ""Johanni Brea"", ""Bernd Illing"", ""Wulfram Gerstner""]","[""Weight-space symmetry"", ""neural network landscapes""]",Weight-space symmetry in neural network landscapes gives rise to numerous number of saddles and flat high-dimensional subspaces.,,,,
rkxn7nR5KX,2019,Reject,False,Incremental Few-Shot Learning with Attention Attractor Networks,"[""Mengye Ren"", ""Renjie Liao"", ""Ethan Fetaya"", ""Richard S. Zemel""]","[""meta-learning"", ""few-shot learning"", ""incremental learning""]",,,,,
rkxoNnC5FQ,2019,Accept (Poster),False,SPIGAN: Privileged Adversarial Learning from Simulation,"[""Kuan-Hui Lee"", ""German Ros"", ""Jie Li"", ""Adrien Gaidon""]","[""domain adaptation"", ""GAN"", ""semantic segmentation"", ""simulation"", ""privileged information""]",An unsupervised sim-to-real domain adaptation method for semantic segmentation using privileged information from a simulator with GAN-based image translation.,,,,
rkxoh24FPH,2020,Accept (Poster),False,On Mutual Information Maximization for Representation Learning,"[""Michael Tschannen"", ""Josip Djolonga"", ""Paul K. Rubenstein"", ""Sylvain Gelly"", ""Mario Lucic""]","[""mutual information"", ""representation learning"", ""unsupervised learning"", ""self-supervised learning""]",The success of recent mutual information (MI)-based representation learning approaches strongly depends on the inductive bias in both the choice of network architectures and the parametrization of the employed MI estimators.,,,,
rkxraoRcF7,2019,Reject,False,Learning Disentangled Representations with Reference-Based Variational Autoencoders,"[""Adria Ruiz"", ""Oriol Martinez"", ""Xavier Binefa"", ""Jakob Verbeek""]","[""Disentangled representations"", ""Variational Autoencoders"", ""Adversarial Learning"", ""Weakly-supervised learning""]",,,,,
rkxs0yHFPH,2020,Accept (Poster),False,SpikeGrad: An ANN-equivalent Computation Model for Implementing Backpropagation with Spikes,"[""Johannes C. Thiele"", ""Olivier Bichler"", ""Antoine Dupret""]","[""spiking neural network"", ""neuromorphic engineering"", ""backpropagation""]",An implementation of the backpropagation algorithm using spiking neurons for forward and backward propagation.,,,,
rkxt8oC9FQ,2019,Reject,False,Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks,"[""Patrick Schwab"", ""Lorenz Linhardt"", ""Walter Karlen""]",[],,,,,
rkxtNaNKwr,2020,Reject,True,Evolutionary Reinforcement Learning for Sample-Efficient Multiagent Coordination,"[""Shauharda Khadka"", ""Somdeb Majumdar"", ""Santiago Miret"", ""Stephen McAleer"", ""Kagan Tumer""]","[""reinforcement learning"", ""multiagent"", ""neuroevolution""]",Reinforcement learning for problems that involve multiple agents coordinating to achieve a sparse team objective,1906.07315,cs.LG,2019-06-18 00:25:27+00:00,2020-06-11 17:03:43+00:00
rkxtl3C5YX,2019,Reject,False,Understanding & Generalizing AlphaGo Zero,"[""Ravichandra Addanki"", ""Mohammad Alizadeh"", ""Shaileshh Bojja Venkatakrishnan"", ""Devavrat Shah"", ""Qiaomin Xie"", ""Zhi Xu""]","[""reinforcement learning"", ""AlphaGo Zero""]",,,,,
rkxuWaVYDB,2020,Reject,True,Optimal Attacks on Reinforcement Learning Policies,"[""Alessio Russo"", ""Alexandre Proutiere""]",[],,1907.13548,cs.LG,2019-07-31 15:16:00+00:00,2019-07-31 15:16:00+00:00
rkxusjRctQ,2019,Reject,False,Learning models for visual 3D localization with implicit mapping,"[""Dan Rosenbaum"", ""Frederic Besse"", ""Fabio Viola"", ""Danilo J. Rezende"", ""S. M. Ali Eslami""]","[""generative learning"", ""generative models"", ""generative query networks"", ""camera re-localization""]","We propose a generative approach based on Generative Query Networks + attention for localization with implicit mapping, and compare to a discriminative baseline with a similar architecture.",,,,
rkxw-hAcFQ,2019,Accept (Poster),False,Generating Multi-Agent Trajectories using Programmatic Weak Supervision,"[""Eric Zhan"", ""Stephan Zheng"", ""Yisong Yue"", ""Long Sha"", ""Patrick Lucey""]","[""deep learning"", ""generative models"", ""imitation learning"", ""hierarchical methods"", ""data programming"", ""weak supervision"", ""spatiotemporal""]",We blend deep generative models with programmatic weak supervision to generate coordinated multi-agent trajectories of significantly higher quality than previous baselines.,,,,
rkxwShA9Ym,2019,Accept (Poster),False,Label super-resolution networks,"[""Kolya Malkin"", ""Caleb Robinson"", ""Le Hou"", ""Rachel Soobitsky"", ""Jacob Czawlytko"", ""Dimitris Samaras"", ""Joel Saltz"", ""Lucas Joppa"", ""Nebojsa Jojic""]","[""weakly supervised segmentation"", ""land cover mapping"", ""medical imaging""]","Super-resolving coarse labels into pixel-level labels, applied to aerial imagery and medical scans.",,,,
rkxxA24FDr,2020,Accept (Poster),True,Neural Stored-program Memory,"[""Hung Le"", ""Truyen Tran"", ""Svetha Venkatesh""]","[""Memory Augmented Neural Networks"", ""Universal Turing Machine"", ""fast-weight""]",A neural simulation of Universal Turing Machine,1906.08862,cs.NE,2019-05-25 06:30:11+00:00,2019-12-26 00:44:44+00:00
rky3QW9le,2017,Reject,False,Transformational Sparse Coding,"[""Dimitrios C. Gklezakos"", ""Rajesh P. N. Rao""]","[""Unsupervised Learning"", ""Computer vision"", ""Optimization""]",We extend sparse coding to include general affine transformations. We present a novel technical approach to circumvent inference intractability.,,,,
rkzDIiA5YQ,2019,Accept (Poster),False,ANYTIME MINIBATCH: EXPLOITING STRAGGLERS IN ONLINE DISTRIBUTED OPTIMIZATION,"[""Nuwan Ferdinand"", ""Haider Al-Lawati"", ""Stark Draper"", ""Matthew Nokleby""]","[""distributed optimization"", ""gradient descent"", ""minibatch"", ""stragglers""]",Accelerate distributed optimization by exploiting stragglers.,,,,
rkzUYjCcFm,2019,Reject,False,FAST OBJECT LOCALIZATION VIA SENSITIVITY ANALYSIS,"[""Mohammad K. Ebrahimpour"", ""David C. Noelle""]","[""Internal Representations"", ""Sensitivity Analysis"", ""Object Detection""]",Proposing a novel object localization(detection) approach based on interpreting the deep CNN using internal representation and network's thoughts,,,,
rkzfuiA9F7,2019,Reject,False,Projective Subspace Networks For Few-Shot Learning,"[""Christian Simon"", ""Piotr Koniusz"", ""Mehrtash Harandi""]","[""few-shot"", ""one-shot"", ""semi-supervised"", ""meta-learning""]",We proposed Projective Subspace Networks for few-shot and semi-supervised few-shot learning,,,,
rkzjUoAcFX,2019,Accept (Poster),False,Sample Efficient Adaptive Text-to-Speech,"[""Yutian Chen"", ""Yannis Assael"", ""Brendan Shillingford"", ""David Budden"", ""Scott Reed"", ""Heiga Zen"", ""Quan Wang"", ""Luis C. Cobo"", ""Andrew Trask"", ""Ben Laurie"", ""Caglar Gulcehre"", ""A\u00e4ron van den Oord"", ""Oriol Vinyals"", ""Nando de Freitas""]","[""few shot"", ""meta learning"", ""text to speech"", ""wavenet""]",Sample efficient algorithms to adapt a text-to-speech model to a new voice style with the state-of-the-art performance.,,,,
rl8jF3GENq,2022,Reject,True,Wavelet-Packet Powered Deepfake Image Detection,"['Moritz Wolter', 'Felix Blanke', 'Charles Tapley Hoyt', 'Jochen Garcke']","[""signal processing"", ""wavelets"", ""wavelet packets"", ""deepfake detection""]",Wavelet packets are used to detect fake images.,2106.09369,cs.CV,2021-06-17 10:41:44+00:00,2021-10-06 11:48:41+00:00
rlYiXFdSy70,2022,Accept (Poster),False,Graph-Enhanced Exploration for Goal-oriented Reinforcement Learning,"['Jiarui Jin', 'Sijin Zhou', 'Weinan Zhang', 'Tong He', 'Yong Yu', 'Rasool Fakoor']","[""Deep Reinforcement Learning"", ""Goal-oriented Reinforcement Learning"", ""Graph Structure"", ""Exploration""]","In this paper, we propose G2RL, a new goal-oriented RL that leverages the state-transition graph for effective exploration and efficient training.",,,,
rmd-D7h_2zP,2021,Reject,False,Domain-slot Relationship Modeling using  a Pre-trained Language Encoder for Multi-Domain Dialogue State Tracking,"[""Jinwon An"", ""Misuk Kim"", ""Sungzoon Cho"", ""Junseong Bang""]","[""Dialogue State Tracking"", ""Domain-slot Relationship Modeling"", ""Pre-trained Language Encoder""]",We propose a model for multi-domain dialogue state tracking that effectively models the relationship among domain-slot pairs using a pre-trained language encoder.,,,,
roNqYL0_XP,2021,Accept (Spotlight),False,Learning Mesh-Based Simulation with Graph Networks,"[""Tobias Pfaff"", ""Meire Fortunato"", ""Alvaro Sanchez-Gonzalez"", ""Peter Battaglia""]","[""graph networks"", ""simulation"", ""mesh"", ""physics""]",We introduce a general method for learning the dynamics of complex physics systems accurately and efficiently on meshes,,,,
roxWnqcguNq,2022,Reject,False,Constituency Tree Representation for Argument Unit Recognition,"['Samuel Guilluy', 'Florian MÃ©hats', 'Billal Chouli']","[""transformer"", ""attention"", ""bert"", ""graph attention network"", ""constituency parsing"", ""deep learning""]",We investigate the advantages of using a grammatical tree representation of sentences for the task of argument identification in Natural Language Processing.,,,,
rpxJc9j04U,2022,Accept (Poster),False,Proof Artifact Co-Training for Theorem Proving with Language Models,"['Jesse Michael Han', 'Jason Rute', 'Yuhuai Wu', 'Edward Ayers', 'Stanislas Polu']","[""self-supervised learning"", ""mathematics"", ""reasoning"", ""theorem proving"", ""language modeling""]",Co-training on low-level proof tasks in a Transformer theorem prover improves success from 32% to 48% on Lean theorems.,,,,
rq1-7_lwisw,2022,Reject,False,Beyond Object Recognition: A New Benchmark towards Object Concept Learning,"['Yong-Lu Li', 'Yue Xu', 'Xinyu Xu', 'Xiaohan Mao', 'Yuan Yao', 'Siqi Liu', 'Cewu Lu']","[""Object Concept Learning"", ""Attributes"", ""Affordance"", ""Causal Inference""]","A new benchmark affording extensive object category, attribute, affordance, and causal relation annotations to evaluate object concept learning.",,,,
rq_Qr0c1Hyo,2021,Accept (Poster),False,On the Origin of Implicit Regularization in Stochastic Gradient Descent,"[""Samuel L Smith"", ""Benoit Dherin"", ""David Barrett"", ""Soham De""]","[""SGD"", ""learning rate"", ""batch size"", ""optimization"", ""generalization"", ""implicit regularization"", ""backward error analysis"", ""SDE"", ""stochastic differential equation"", ""ODE"", ""ordinary differential equation""]","For small finite learning rates, the iterates of Random Shuffling SGD stay close to the path of gradient flow on a modified loss function containing an implicit regularizer.",,,,
rqcLsG8Kme9,2022,Reject,False,rQdia: Regularizing Q-Value Distributions With Image Augmentation,"['Samuel Lerman', 'Jing Bi', 'Chenliang Xu']","[""deep reinforcement learning"", ""regularization"", ""q-value distributions"", ""invariance"", ""image augmentation"", ""continuous control"", ""Atari""]",rQdia (pronounced âArcadiaâ) regularizes Q-value distributions with augmented images in pixel-based deep reinforcement learning.,,,,
rqolQhuq6Hs,2022,Reject,True,Logarithmic landscape and power-law escape rate of SGD,"['Takashi Mori', 'Liu Ziyin', 'Kangqiao Liu', 'Masahito Ueda']","[""stochastic gradient descent"", ""noise structure"", ""escape rate"", ""flat minima"", ""statistical physics""]","We have derived the Langevin equation in the logarithmized loss landscape for SGD with the mean-square loss, which yields a power-law escape rate from local minima.",2105.09557,cs.LG,2021-05-20 07:25:07+00:00,2022-01-29 14:48:50+00:00
rqzZDh8jqGj,2021,Reject,True,Experimental Design for Overparameterized Learning with Application to Single Shot Deep Active Learning,"[""Neta Shoham"", ""Haim Avron""]",[],,2009.12820,cs.LG,2020-09-27 11:27:49+00:00,2021-04-25 18:46:07+00:00
rrWeE9ZDw_,2022,Accept (Poster),False,Autonomous Learning of Object-Centric Abstractions for High-Level Planning,"['Steven James', 'Benjamin Rosman', 'George Konidaris']","[""reinforcement learning"", ""planning"", ""multitask"", ""transfer"", ""objects""]",We learn object-centric PDDL representations directly from raw observation data,,,,
rryJiPXifr,2021,Reject,False,Optimization Planning for 3D ConvNets,"[""Zhaofan Qiu"", ""Ting Yao"", ""Chong-wah Ngo"", ""Tao Mei""]","[""3D ConvNets"", ""Network Training"", ""Video Recognition""]",We propose optimization planning mechanism to automate the design of training strategy for 3D ConvNets.,,,,
rsf1z-JSj87,2021,Accept (Oral),False,End-to-end Adversarial Text-to-Speech,"[""Jeff Donahue"", ""Sander Dieleman"", ""Mikolaj Binkowski"", ""Erich Elsen"", ""Karen Simonyan""]","[""text-to-speech"", ""speech synthesis"", ""adversarial"", ""GAN"", ""end-to-end"", ""feed-forward"", ""generative model""]","Efficient, adversarially trained feed-forward text-to-speech model producing high-quality speech, learnt end-to-end in a single stage.",,,,
rsogjAnYs4z,2021,Accept (Poster),False,Understanding the effects of data parallelism and sparsity on neural network training,"[""Namhoon Lee"", ""Thalaiyasingam Ajanthan"", ""Philip Torr"", ""Martin Jaggi""]","[""data parallelism"", ""sparsity"", ""neural network training""]",We accurately measure the effects of data parallelism and sparsity on neural network training and develop a theoretical analysis to precisely account for their effects.,,,,
rumv7QmLUue,2021,Accept (Spotlight),False,A Gradient Flow Framework For Analyzing Network Pruning,"[""Ekdeep Singh Lubana"", ""Robert Dick""]","[""Network pruning"", ""Gradient flow"", ""Early pruning""]","This paper establishes the relationship between regularly used importance measures for network pruning and evolution of model parameters under gradient flow, thus providing useful insights into pruning early-on in training.",,,,
rvosiWfMoMR,2021,Reject,False,Automatic Music Production Using Generative Adversarial Networks,"[""Giorgio Barnab\u00f2"", ""Giovanni Trappolini"", ""Lorenzo Lastilla"", ""Cesare Campagnano"", ""Angela Fan"", ""Fabio Petroni"", ""Fabrizio Silvestri""]","[""music arrangement"", ""generative adversarial networks"", ""music generation""]",We propose a novel framework for music arrangement from raw audio in the frequency domain,2104.00353,eess.AS,2021-04-01 09:17:48+00:00,2021-04-09 10:43:12+00:00
rvost-n5X4G,2022,Reject,False,SPP-RL: State Planning Policy Reinforcement Learning,"['Jacek Cyranka', 'Zuzanna OpaÅa', 'Jacek PÅocharczyk', 'Mikhail Zanka']","[""reinforcement learning"", ""off-policy"", ""constrained optimization"", ""robotics"", ""state planning"", ""state-state"", ""mujoco"", ""safety-gym"", ""antpush""]",We introduce a novel algorithm for reinforcement learning dedicated for continuous environments in which the actor for the current state proposes the target next state instead of an action,,,,
rw1mZl_ss3L,2022,Accept (Poster),False,Concurrent Adversarial Learning for Large-Batch Training,"['Yong Liu', 'Xiangning Chen', 'Minhao Cheng', 'Cho-Jui Hsieh', 'Yang You']","[""Distributed Machine Learnig"", ""Large-Batch Training"", ""Adversarial Learning""]",,,,,
rwE8SshAlxw,2022,Accept (Poster),False,Unsupervised Discovery of Object Radiance Fields,"['Hong-Xing Yu', 'Leonidas Guibas', 'Jiajun Wu']","[""object discovery"", ""scene decomposition"", ""3D scene representations"", ""object-centric learning""]","Inferring object-centric factorized 3D scene representations from a single image, learned without 3D geometry or segmentation supervision.",,,,
rwEv1SklKFt,2022,Reject,False,"Poisoned classifiers are not only backdoored, they are fundamentally broken","['Mingjie Sun', 'Siddhant Agarwal', 'J Zico Kolter']","[""Backdoor attacks"", ""Randomized Smoothing"", ""Trigger construction""]",We describe a new human-in-the-loop procedure to attack backdoor poisoned classifiers without access to the initial trigger.,,,,
rx19UMFbC9u,2021,Reject,False,"Waste not, Want not: All-Alive Pruning for Extremely Sparse Networks","[""Daejin Kim"", ""Hyunjung Shim"", ""Jongwuk Lee""]","[""Model compression"", ""Network pruning"", ""Iterative pruning"", ""Dead connections""]","We propose a simple-yet-effective and versatile unstructured pruning method, namely all-alive pruning (AAP), to eliminate dead connections and make all weights in the subnetwork trainable.",,,,
rxF4IN3R2ml,2022,Reject,True,MQTransformer: Multi-Horizon Forecasts with Context Dependent and Feedback-Aware Attention,"['Carson Eisenach', 'Yagna Patel', 'Dhruv Madeka']",[],,2009.14799,cs.LG,2020-09-30 17:12:46+00:00,2022-01-27 03:02:39+00:00
ry-TW-WAb,2018,Accept (Poster),False,Variational Network Quantization,"[""Jan Achterhold"", ""Jan Mathias Koehler"", ""Anke Schmeink"", ""Tim Genewein""]","[""Network compression"", ""variational inferene"", ""ternary network"", ""Bayesian neural network"", ""weight quantization"", ""weight sharing""]","We quantize and prune neural network weights using variational Bayesian inference with a multi-modal, sparsity inducing prior.",,,,
ry018WZAZ,2018,Accept (Poster),False,Deep Active Learning for Named Entity Recognition,"[""Yanyao Shen"", ""Hyokun Yun"", ""Zachary C. Lipton"", ""Yakov Kronrod"", ""Animashree Anandkumar""]","[""active learning"", ""deep learning"", ""named entity recognition""]","We introduce a lightweight architecture for named entity recognition and carry out incremental active learning, which is able to match state-of-the-art performance with just 25% of the original training data.",,,,
ry0WOxbRZ,2018,Reject,False,IVE-GAN: Invariant Encoding Generative Adversarial Networks,"[""Robin Winter"", ""Djork-Arn\u00e8 Clevert""]","[""Deep learning"", ""Unsupervised Learning""]",A noval GAN framework that utilizes transformation-invariant features to learn rich representations and strong generators.,,,,
ry18Ww5ee,2017,Accept (Poster),False,Hyperband: Bandit-Based Configuration Evaluation for Hyperparameter Optimization,"[""Lisha Li"", ""Kevin Jamieson"", ""Giulia DeSalvo"", ""Afshin Rostamizadeh"", ""Ameet Talwalkar""]",[],,,,,
ry1arUgCW,2018,Accept (Poster),False,DORA The Explorer: Directed Outreaching Reinforcement Action-Selection,"[""Lior Fox"", ""Leshem Choshen"", ""Yonatan Loewenstein""]","[""Reinforcement Learning"", ""Exploration"", ""Model-Free""]","We propose a generalization of visit-counters that evaluate the propagating exploratory value over trajectories, enabling efficient exploration for model-free RL",,,,
ry2YOrcge,2017,Accept (Poster),False,Learning a Natural Language Interface with Neural Programmer,"[""Arvind Neelakantan"", ""Quoc V. Le"", ""Martin Abadi"", ""Andrew McCallum"", ""Dario Amodei""]","[""Natural language processing"", ""Deep learning""]","To our knowledge, this paper presents the first weakly supervised, end-to-end neural network model to induce programs on a real-world  dataset.",,,,
ry3iBFqgl,2017,Reject,False,NEWSQA: A MACHINE COMPREHENSION DATASET,"[""Adam Trischler"", ""Tong Wang"", ""Xingdi Yuan"", ""Justin Harris"", ""Alessandro Sordoni"", ""Philip Bachman"", ""Kaheer Suleman""]","[""Natural language processing"", ""Deep learning""]",Crowdsourced QA dataset with natural language questions and multi-word answers,,,,
ry4S90l0b,2018,Reject,False,A Self-Training Method for Semi-Supervised GANs,"[""Alan Do-Omri"", ""Dalei Wu"", ""Xiaohua Liu""]","[""self-training"", ""generative adversarial networks"", ""semi-supervised""]",,,,,
ry4SNTe0-,2018,Reject,False,Improve Training Stability of Semi-supervised Generative Adversarial Networks with Collaborative Training,"[""Dalei Wu"", ""Xiaohua Liu""]","[""generative adversarial training"", ""semi-supervised training"", ""collaborative training""]",Improve Training Stability of Semi-supervised Generative Adversarial Networks with Collaborative Training,,,,
ry4Vrt5gl,2017,Accept (Poster),False,Learning to Optimize,"[""Ke Li"", ""Jitendra Malik""]","[""Reinforcement Learning"", ""Optimization""]",We explore learning an optimization algorithm automatically. ,,,,
ry54RWtxx,2017,Reject,False,Learning a Static Analyzer: A Case Study on a Toy Language,"[""Manzil Zaheer"", ""Jean-Baptiste Tristan"", ""Michael L. Wick"", ""Guy L. Steele Jr.""]",[],,,,,
ry6-G_66b,2018,Accept (Poster),False,Active Neural Localization,"[""Devendra Singh Chaplot"", ""Emilio Parisotto"", ""Ruslan Salakhutdinov""]",[],"""Active Neural Localizer"", a fully differentiable neural network that learns to localize efficiently using deep reinforcement learning.",,,,
ry7O1ssex,2017,Reject,False,Generative Adversarial Networks as Variational Training of Energy Based Models,"[""Shuangfei Zhai"", ""Yu Cheng"", ""Rogerio Feris"", ""Zhongfei Zhang""]",[],,,,,
ry80wMW0W,2018,Accept (Poster),False,Hierarchical Subtask Discovery with Non-Negative Matrix Factorization,"[""Adam C. Earle"", ""Andrew M. Saxe"", ""Benjamin Rosman""]","[""Reinforcement Learning"", ""Hierarchy"", ""Subtask Discovery"", ""Linear Markov Decision Process""]",We present a novel algorithm for hierarchical subtask discovery which leverages the multitask linear Markov decision process framework.,,,,
ry831QWAb,2018,Reject,False,BLOCK-NORMALIZED GRADIENT METHOD: AN EMPIRICAL STUDY FOR TRAINING DEEP NEURAL NETWORK,"[""Adams Wei Yu"", ""Lei Huang"", ""Qihang Lin"", ""Ruslan Salakhutdinov"", ""Jaime Carbonell""]",[],,,,,
ry8_g12nVD,2021,Reject,False,SEMANTIC APPROACH TO AGENT ROUTING USING A HYBRID ATTRIBUTE-BASED RECOMMENDER SYSTEM,"[""Anwitha Paruchuri""]","[""Hybrid Recommendation"", ""Customer Relationship Management"", ""Semantic Embedding"", ""Approximate Nearest Neighbor""]",A Hybrid Recommendation based approach that recommends top N agents for a ticket by jointly modelling on the interactions between the agents and categories as well as on the semantic features of the categories and the agents,,,,
ry8dvM-R-,2018,Accept (Poster),False,Routing Networks: Adaptive Selection of Non-Linear Functions for Multi-Task Learning,"[""Clemens Rosenbaum"", ""Tim Klinger"", ""Matthew Riemer""]","[""multi-task"", ""transfer"", ""routing"", ""marl"", ""multi-agent"", ""reinforcement"", ""self-organizing""]",routing networks: a new kind of neural network which learns to adaptively route its input for multi-task learning,,,,
ry9tUX_6-,2018,Reject,False,Entropy-SGD optimizes the prior of a PAC-Bayes bound: Data-dependent PAC-Bayes priors via differential privacy,"[""Gintare Karolina Dziugaite"", ""Daniel M. Roy""]","[""generalization error"", ""neural networks"", ""statistical learning theory"", ""PAC-Bayes theory""]","We show that Entropy-SGD optimizes the prior of a PAC-Bayes bound, violating the requirement that the prior be independent of data; we use differential privacy to resolve this and improve generalization.",,,,
ryA-jdlA-,2018,Reject,False,A closer look at the word analogy problem,"[""Siddharth Krishna Kumar""]","[""word2vec"", ""glove"", ""word analogy"", ""word relationships"", ""word vectors""]","Simple generative approach to solve the word analogy problem which yields insights into word relationships, and the problems with estimating them",,,,
ryALZdAT-,2018,Invite to Workshop Track,False,Feature Incay for Representation Regularization,"[""Yuhui Yuan"", ""Kuiyuan Yang"", ""Jianyuan Guo"", ""Jingdong Wang"", ""Chao Zhang""]","[""feature norm"", ""regularization"", ""softmax loss"", ""feature incay""]",,,,,
ryAe2WBee,2017,Reject,False,Multi-label learning with semantic embeddings,"[""Liping Jing"", ""MiaoMiao Cheng"", ""Liu Yang"", ""Alex Gittens"", ""Michael W. Mahoney""]","[""Supervised Learning""]","The SEM approach to multi-label learning models labels using multinomial distributions parametrized by nonlinear functions of the instance features, is scalable and outperforms current state-of-the-art algorithms",,,,
ryBnUWb0b,2018,Accept (Poster),False,Predicting Floor-Level for 911 Calls with Neural Networks and Smartphone Sensor Data,"[""William Falcon"", ""Henning Schulzrinne""]","[""Recurrent Neural Networks"", ""RNN"", ""LSTM"", ""Mobile Device"", ""Sensors""]",We used an LSTM to detect when a smartphone walks into a building. Then we predict the device's floor level using data from sensors aboard the smartphone.,,,,
ryCM8zWRb,2018,Reject,False,Recurrent Neural Networks with Top-k Gains for Session-based Recommendations,"[""Bal\u00e1zs Hidasi"", ""Alexandros Karatzoglou""]","[""gru4rec"", ""session-based recommendations"", ""recommender systems"", ""recurrent neural network""]",Improving session-based recommendations with RNNs (GRU4Rec) by 35% using newly designed loss functions and sampling.,,,,
ryCcJaqgl,2017,Reject,False,TreNet: Hybrid Neural Networks for Learning the Local Trend in Time Series,"[""Tao Lin"", ""Tian Guo"", ""Karl Aberer""]",[],,,,,
ryDNZZZAW,2018,Invite to Workshop Track,False,Multiple Source Domain Adaptation with Adversarial Learning,"[""Han Zhao"", ""Shanghang Zhang"", ""Guanhang Wu"", ""Jo\\~{a}o  P. Costeira"", ""Jos\\'{e} M. F.  Moura"", ""Geoffrey J. Gordon""]","[""adversarial learning"", ""domain adaptation""]",,,,,
ryE98iR5tm,2019,Accept (Poster),False,Practical lossless compression with latent variables using bits back coding,"[""James Townsend"", ""Thomas Bird"", ""David Barber""]","[""compression"", ""variational auto-encoders"", ""deep latent gaussian models"", ""lossless compression"", ""latent variables"", ""approximate inference"", ""variational inference""]","We do lossless compression of large image datasets using a VAE, beat existing compression algorithms.",,,,
ryEGFD9gl,2017,Reject,False,Submodular Sum-product Networks for Scene Understanding,"[""Abram L. Friesen"", ""Pedro Domingos""]","[""Computer vision"", ""Structured prediction""]","A novel extension of sum-product networks that incorporates submodular Markov random fields into the sum nodes, resulting in a highly expressive class of models in which efficient inference is still possible.",,,,
ryEkcsActX,2019,Reject,False,Teacher Guided Architecture Search,"[""Pouya Bashivan"", ""Mark Tensen"", ""James J DiCarlo""]","[""hyperparameter search"", ""architecture search"", ""convolutional neural networks""]",Faster architecture search by maximizing representational similarity with a teacher network,,,,
ryF-cQ6T-,2018,Reject,False,Machine Learning by Two-Dimensional Hierarchical Tensor Networks: A Quantum Information Theoretic Perspective on Deep Architectures,"[""Ding Liu"", ""Shi-Ju Ran"", ""Peter Wittek"", ""Cheng Peng"", ""Raul Bl\u00e1zquez Garc\u00eda"", ""Gang Su"", ""Maciej Lewenstein""]","[""quantum machine learning"", ""tensor network"", ""quantum information""]","This approach overcomes scalability issues and implies novel mathematical connections among quantum many-body physics, quantum information theory, and machine learning.",,,,
ryF7rTqgl,2017,Reject,False,Understanding intermediate layers using linear classifier probes,"[""Guillaume Alain"", ""Yoshua Bengio""]",[],New useful concept of information to understand deep learning.,,,,
ryG2Cs09Y7,2019,Reject,False,Feature prioritization and regularization improve standard accuracy and adversarial robustness,"[""Chihuang Liu"", ""Joseph JaJa""]","[""adversarial robustness"", ""feature prioritization"", ""regularization""]",We propose a model that employs feature prioritization and regularization to improve the adversarial robustness and the standard accuracy.,,,,
ryG6xZ-RZ,2018,Invite to Workshop Track,False,DLVM: A modern compiler infrastructure for deep learning systems,"[""Richard Wei"", ""Lane Schwartz"", ""Vikram Adve""]","[""deep learning"", ""automatic differentiation"", ""algorithmic differentiation"", ""domain specific languages"", ""neural networks"", ""programming languages"", ""DSLs""]",We introduce a novel compiler infrastructure that addresses shortcomings of existing deep learning frameworks.,,,,
ryG8UsR5t7,2019,Reject,False,MERCI: A NEW METRIC TO EVALUATE THE CORRELATION BETWEEN PREDICTIVE UNCERTAINTY AND TRUE ERROR,"[""michel moukari"", ""lo\u00efc simon"", ""sylvaine picard"", ""fr\u00e9d\u00e9ric jurie""]","[""evaluation metric"", ""predictive uncertainty"", ""deep learning""]",We review existing metrics and propose a new one to evaluate predictive uncertainty in deep learning,,,,
ryGDEjCcK7,2019,Reject,False,CONTROLLING COVARIATE SHIFT USING EQUILIBRIUM NORMALIZATION OF WEIGHTS,"[""Aaron Defazio""]","[""normalization"", ""optimization""]",An alternative normalization technique to batch normalization,,,,
ryGWhJBtDB,2020,Reject,False,Hyperparameter Tuning and Implicit Regularization in Minibatch SGD,"[""Samuel L Smith"", ""Erich Elsen"", ""Soham De""]","[""SGD"", ""momentum"", ""batch size"", ""learning rate"", ""noise"", ""temperature"", ""implicit regularization"", ""optimization"", ""generalization""]",Smaller batch sizes can outperform very large batches on the test set under constant step budgets and with properly tuned learning rate schedules.,,,,
ryGfnoC5KQ,2019,Accept (Poster),False,Kernel RNN Learning (KeRNL),"[""Christopher Roth"", ""Ingmar Kanitscheider"", ""Ila Fiete""]","[""RNNs"", ""Biologically plausible learning rules"", ""Algorithm"", ""Neural Networks"", ""Supervised Learning""]",A biologically plausible learning rule for training recurrent neural networks,,,,
ryGgSsAcFQ,2019,Accept (Poster),False,"Deep, Skinny Neural Networks are not Universal Approximators","[""Jesse Johnson""]","[""neural network"", ""universality"", ""expressability""]","This paper proves that skinny neural networks cannot approximate certain functions, no matter how deep they are.",,,,
ryGiYoAqt7,2019,Reject,False,Learning  agents with prioritization and parameter noise in continuous state and action space,"[""Rajesh Devaraddi"", ""G. Srinivasaraghavan""]","[""reinforcement learning"", ""continuous action space"", ""prioritization"", ""parameter"", ""noise"", ""policy gradients""]",Improving the performance of an RL agent in the continuous action and state space domain by using prioritised experience replay and parameter noise.,,,,
ryGkSo0qYm,2019,Accept (Poster),False,Large Scale Graph Learning From Smooth Signals,"[""Vassilis Kalofolias"", ""Nathana\u00ebl Perraudin""]","[""Graph learning"", ""Graph signal processing"", ""Network inference""]",,,,,
ryGpEiAcFQ,2019,Reject,False,A Synaptic Neural Network and Synapse Learning,"[""Chang Li""]","[""synaptic neural network"", ""surprisal"", ""synapse"", ""probability"", ""excitation"", ""inhibition"", ""synapse learning"", ""bose-einstein distribution"", ""tensor"", ""gradient"", ""loss function"", ""mnist"", ""topologically conjugate""]",A synaptic neural network with synapse graph and learning that has the feature of topological conjugation and Bose-Einstein distribution in surprisal space.  ,,,,
ryGs6iA5Km,2019,Accept (Oral),False,How Powerful are Graph Neural Networks?,"[""Keyulu Xu*"", ""Weihua Hu*"", ""Jure Leskovec"", ""Stefanie Jegelka""]","[""graph neural networks"", ""theory"", ""deep learning"", ""representational power"", ""graph isomorphism"", ""deep multisets""]",We develop theoretical foundations for the expressive power of GNNs and design a provably most powerful GNN.,,,,
ryGvcoA5YX,2019,Accept (Poster),False,Overcoming Catastrophic Forgetting for Continual Learning via Model Adaptation,"[""Wenpeng Hu"", ""Zhou Lin"", ""Bing Liu"", ""Chongyang Tao"", ""Zhengwei Tao"", ""Jinwen Ma"", ""Dongyan Zhao"", ""Rui Yan""]","[""overcoming forgetting"", ""model adaptation"", ""continual learning""]",,,,,
ryH20GbRW,2018,Accept (Poster),False,Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions,"[""Sjoerd van Steenkiste"", ""Michael Chang"", ""Klaus Greff"", ""J\u00fcrgen Schmidhuber""]","[""Common-sense Physical Reasoning"", ""Intuitive Physics"", ""Representation Learning"", ""Model building""]",We introduce a novel approach to common-sense physical reasoning that learns to discover objects and model their physical interactions from raw visual images in a purely unsupervised fashion,1802.10353,cs.LG,2018-02-28 10:55:36+00:00,2018-02-28 10:55:36+00:00
ryHM_fbA-,2018,Reject,False,Learning Document Embeddings With CNNs,"[""Shunan Zhao"", ""Chundi Lui"", ""Maksims Volkovs""]","[""unsupervised embedding"", ""convolutional neural network""]",Convolutional neural network model for unsupervised document embedding.,,,,
ryH_bShhW,2018,Reject,False,DOUBLY STOCHASTIC ADVERSARIAL AUTOENCODER,"[""Mahdi Azarafrooz""]","[""Generative adversarial Networks"", ""Deep Generative models"", ""Kernel Methods""]",,,,,
ryHlUtqge,2017,Accept (Poster),False,Generalizing Skills with Semi-Supervised Reinforcement Learning,"[""Chelsea Finn"", ""Tianhe Yu"", ""Justin Fu"", ""Pieter Abbeel"", ""Sergey Levine""]","[""Reinforcement Learning""]","We propose an algorithm for generalizing a deep neural network policy using ""unlabeled"" experience collected in MDPs where rewards are not available.",,,,
ryM07h0cYX,2019,Reject,False,Reinforced Pipeline Optimization: Behaving Optimally with Non-Differentiabilities,"[""Aijun Bai"", ""Dongdong Chen"", ""Gang Hua"", ""Lu Yuan""]","[""Pipeline Optimization"", ""Reinforcement Learning"", ""Stochastic Computation Graph"", ""Faster R-CNN""]","By converting an originally non-differentiable pipeline into a stochastic counterpart, we can then train the converted pipeline completely end-to-end while optimizing any criterion attached to it.",,,,
ryMQ5sRqYX,2019,Reject,False,Finding Mixed Nash Equilibria of Generative Adversarial Networks,"[""Ya-Ping Hsieh"", ""Chen Liu"", ""Volkan Cevher""]","[""GANs"", ""mixed Nash equilibrium"", ""mirror descent"", ""sampling""]",,,,,
ryM_IoAqYX,2019,Accept (Poster),False,Analysis of Quantized Models,"[""Lu Hou"", ""Ruiliang Zhang"", ""James T. Kwok""]","[""weight quantization"", ""gradient quantization"", ""distributed learning""]","In this paper, we studied efficient training of loss-aware weight-quantized  networks with  quantized gradient  in a distributed environment, both theoretically and empirically.",,,,
ryMxXPFex,2017,Accept (Poster),False,Discrete Variational Autoencoders,"[""Jason Tyler Rolfe""]","[""Deep learning"", ""Unsupervised Learning""]","We present a novel method to train a class of probabilistic models with discrete latent variables using the variational autoencoder framework, including backpropagation through the discrete latent variables.",,,,
ryOG3fWCW,2018,Reject,False,"Model Specialization for Inference Via End-to-End Distillation, Pruning, and Cascades","[""Daniel Kang"", ""Karey Shi"", ""Thao Ngyuen"", ""Stephanie Mallard"", ""Peter Bailis"", ""Matei Zaharia""]",[],,,,,
ryPx38qge,2017,Reject,False,A hybrid network: Scattering and Convnet,"[""Edouard Oyallon""]","[""Computer vision"", ""Unsupervised Learning"", ""Deep learning""]","This paper shows how, by combining prior and supervised representations, one can create architectures that lead to nearly state-of-the-art results on standard benchmarks.",,,,
ryQbbFile,2017,Reject,False,CAN AI GENERATE LOVE ADVICE?: TOWARD NEURAL ANSWER GENERATION FOR NON-FACTOID QUESTIONS,"[""Makoto Nakatsuji"", ""Hisashi Ito"", ""Naruhiro Ikeda"", ""Shota Sagara"", ""Akihisa Fujita""]",[],,,,,
ryQu7f-RZ,2018,Accept (Oral),False,On the Convergence of Adam and Beyond,"[""Sashank J. Reddi"", ""Satyen Kale"", ""Sanjiv Kumar""]","[""optimization"", ""deep learning"", ""adam"", ""rmsprop""]","We investigate the convergence of popular optimization algorithms like Adam , RMSProp and propose new variants of these methods which provably converge to optimal solution in convex  settings. ",1904.09237,cs.LG,2019-04-19 16:21:38+00:00,2019-04-19 16:21:38+00:00
ryRh0bb0Z,2018,Accept (Poster),False,Multi-View Data Generation Without View Supervision,"[""Mickael Chen"", ""Ludovic Denoyer"", ""Thierry Arti\u00e8res""]","[""multi-view"", ""adversarial learning"", ""generative model""]","We describe a novel multi-view generative model that can generate multiple views of the same object, or multiple objects in the same view with no need of label on views.",,,,
ryT4pvqll,2017,Accept (Poster),False,Improving Policy Gradient by Exploring Under-appreciated Rewards,"[""Ofir Nachum"", ""Mohammad Norouzi"", ""Dale Schuurmans""]","[""Reinforcement Learning""]",We present a novel form of policy gradient for model-free reinforcement learning with improved exploration properties.,,,,
ryT9R3Yxe,2017,Reject,False,Generative Paragraph Vector,"[""Ruqing Zhang"", ""Jiafeng Guo"", ""Yanyan Lan"", ""Jun Xu"", ""Xueqi Cheng""]","[""Natural language processing"", ""Deep learning"", ""Unsupervised Learning"", ""Supervised Learning""]","With a complete generative process, our models are able to infer vector representations as well as labels over unseen texts.",,,,
ryTYxh5ll,2017,Reject,False,CONTENT2VEC: SPECIALIZING JOINT REPRESENTATIONS OF PRODUCT IMAGES AND TEXT FOR THE TASK OF PRODUCT RECOMMENDATION,"[""Thomas Nedelec"", ""Elena Smirnova"", ""Flavian Vasile""]","[""Applications""]",We propose a unified product embedded representation that is optimized for the task of retrieval-based product recommendation.,,,,
ryTp3f-0-,2018,Accept (Poster),False,Reinforcement Learning on Web Interfaces using Workflow-Guided Exploration,"[""Evan Zheran Liu"", ""Kelvin Guu"", ""Panupong Pasupat"", ""Tianlin Shi"", ""Percy Liang""]","[""reinforcement learning"", ""sparse rewards"", ""web"", ""exploration""]",We solve the sparse rewards problem on web UI tasks using exploration guided by demonstrations,,,,
ryUPiRvge,2017,Invite to Workshop Track,False,Extrapolation and learning equations,"[""Georg Martius"", ""Christoph H. Lampert""]","[""Supervised Learning"", ""Deep learning"", ""Structured prediction""]",We present the learning of analytical equation from data using a new forward network architecture.,,,,
ryUlhzWCZ,2018,Accept (Poster),False,TRUNCATED HORIZON POLICY SEARCH: COMBINING REINFORCEMENT LEARNING & IMITATION LEARNING,"[""Wen Sun"", ""J. Andrew Bagnell"", ""Byron Boots""]","[""Imitation Learning"", ""Reinforcement Learning""]",Combining Imitation Learning and Reinforcement Learning to learn to outperform the expert,,,,
ryUprTOv7q0,2021,Reject,True,Quantum Deformed Neural Networks,"[""Roberto Bondesan"", ""Max Welling""]","[""Quantum machine learning"", ""Binary neural networks"", ""Bayesian deep learning""]","We develop a new quantum neural network and simulate a restricted version classically for real world data sizes for the first time, showing modest improvements over standard architectures.",2010.11189,quant-ph,2020-10-21 09:46:12+00:00,2020-11-25 16:36:41+00:00
ryWKREqxx,2017,Reject,False,Emergent Predication Structure in Vector Representations of Neural Readers,"[""Hai Wang"", ""Takeshi Onishi"", ""Kevin Gimpel"", ""David McAllester""]","[""Natural language processing"", ""Deep learning"", ""Applications""]",Provide some novel insights on reading comprehension models and boost the performance of those models,,,,
ryXZmzNeg,2017,Reject,False,Improving Sampling from Generative Autoencoders with Markov Chains,"[""Antonia Creswell"", ""Kai Arulkumaran"", ""Anil Anthony Bharath""]","[""Deep learning"", ""Unsupervised Learning"", ""Theory""]",Iteratively encoding and decoding samples from generative autoencoders recovers samples from the true latent distribution learned by the model,,,,
ryY4RhkCZ,2018,Reject,False,DEEP DENSITY NETWORKS AND UNCERTAINTY IN RECOMMENDER SYSTEMS,"[""Yoel Zeldes"", ""Stavros Theodorakis"", ""Efrat Solodnik"", ""Aviv Rotman"", ""Gil Chamiel"", ""Dan Friedman""]","[""deep learning"", ""recommendation system"", ""uncertainty"", ""context-based and collaborative filtering""]","We have introduced Deep Density Network, a unified DNN model to estimate uncertainty for exploration/exploitation in recommendation systems.",,,,
ryZ283gAZ,2018,Invite to Workshop Track,False,Beyond Finite Layer Neural Networks: Bridging Deep Architectures and Numerical Differential Equations,"[""Yiping Lu"", ""Aoxiao Zhong"", ""Quanzheng Li"", ""Bin Dong""]","[""deep convolutional network"", ""residual network"", ""dynamic system"", ""stochastic dynamic system"", ""modified equation""]",This paper bridges deep network architectures with numerical (stochastic) differential equations. This new perspective enables new designs of more effective deep neural networks.,,,,
ryZ3KCy0W,2018,Reject,False,Link Weight Prediction with Node Embeddings,"[""Yuchen Hou"", ""Lawrence B. Holder""]",[],,,,,
ryZ8sz-Ab,2018,Invite to Workshop Track,False,"Fast and Accurate Text Classification: Skimming, Rereading and Early Stopping","[""Keyi Yu"", ""Yang Liu"", ""Alexander G. Schwing"", ""Jian Peng""]","[""Topic Classification"", ""Sentiment Analysis"", ""Natural Language Processing""]","We develop an end-to-end trainable approach for skimming, rereading and early stopping applicable to classification tasks. ",,,,
ryZERzWCZ,2018,Reject,False,The Information-Autoencoding Family: A Lagrangian Perspective on Latent Variable Generative Modeling,"[""Shengjia Zhao"", ""Jiaming Song"", ""Stefano Ermon""]","[""Generative Models"", ""Variational Autoencoder"", ""Generative Adversarial Network""]",,,,,
ryZElGZ0Z,2018,Reject,False,Discovery of Predictive Representations With a Network of General Value Functions,"[""Matthew Schlegel"", ""Andrew Patterson"", ""Adam White"", ""Martha White""]","[""Reinforcement Learning"", ""General Value Functions"", ""Predictive Representations""]","We investigate a framework for discovery: curating a large collection of predictions, which are used to construct the agentâs representation in partially observable domains.",,,,
ryZqPN5xe,2017,Reject,False,Beyond Fine Tuning: A Modular Approach to Learning on Small Data,"[""Aryk Anderson"", ""Kyle Shaffer"", ""Artem Yankov"", ""Court Corley"", ""Nathan Hodas""]","[""Deep learning"", ""Supervised Learning"", ""Transfer Learning""]",A better way to do deep learning with small amounts of training data,,,,
ry_4vpixl,2017,Reject,False,Rotation Plane Doubly Orthogonal Recurrent Neural Networks,"[""Zoe McCarthy"", ""Andrew Bai"", ""Xi Chen"", ""Pieter Abbeel""]","[""Deep learning"", ""Theory""]","Recurrent equation for RNNs that uses the composition of two orthogonal transitions, one time invariant and one modulated by input, that doesn't suffer from vanishing or exploding gradients.",,,,
ry_WPG-A-,2018,Accept (Poster),False,On the Information Bottleneck Theory of Deep Learning,"[""Andrew Michael Saxe"", ""Yamini Bansal"", ""Joel Dapello"", ""Madhu Advani"", ""Artemy Kolchinsky"", ""Brendan Daniel Tracey"", ""David Daniel Cox""]","[""information bottleneck"", ""deep learning"", ""deep linear networks""]",We show that several claims of the information bottleneck theory of deep learning are not true in the general case.,,,,
ry_sjFqgx,2017,Accept (Poster),False,Program Synthesis for Character Level Language Modeling,"[""Pavol Bielik"", ""Veselin Raychev"", ""Martin Vechev""]",[],,,,,
ryaFG5ige,2017,Reject,False,Introducing Active Learning for CNN under the light of Variational Inference,"[""Melanie Ducoffe"", ""Frederic Precioso""]","[""Deep learning"", ""Supervised Learning"", ""Optimization""]",Building automatically the labeled training set with active learning for CNN. The criterion is developed on a variational inference for NN and a kronecker approximation of Fisher matrices for CNN,,,,
ryacTMZRZ,2018,Reject,False,Jiffy: A Convolutional Approach to Learning Time Series Similarity,"[""Divya Shanmugam"", ""Davis Blalock"", ""John Guttag""]","[""Time Series"", ""Time Series Classification""]",Jiffy is a convolutional approach to learning a distance metric  for multivariate time series that outperforms existing methods in terms of nearest-neighbor classification accuracy.,,,,
ryazCMbR-,2018,Accept (Poster),False,Communication Algorithms via Deep Learning,"[""Hyeji Kim"", ""Yihan Jiang"", ""Ranvir B. Rana"", ""Sreeram Kannan"", ""Sewoong Oh"", ""Pramod Viswanath""]","[""coding theory"", ""recurrent neural network"", ""communication""]",We show that creatively designed and trained RNN architectures can decode well known sequential codes and achieve close to optimal performances.,,,,
ryb-q1Olg,2017,Reject,False,Rectified Factor Networks for Biclustering,"[""Djork-Arn\u00e9 Clevert"", ""Thomas Unterthiner"", ""Sepp Hochreiter""]","[""Deep learning"", ""Unsupervised Learning"", ""Applications""]",,,,,
ryb83alCZ,2018,Reject,False,Towards Unsupervised Classification with Deep Generative Models,"[""Dimitris Kalatzis"", ""Konstantia Kotta"", ""Ilias Kalamaras"", ""Anastasios Vafeiadis"", ""Andrew Rawstron"", ""Dimitris Tzovaras"", ""Kostas Stamatopoulos""]","[""variational inference"", ""vae"", ""variational autoencoders"", ""generative modeling"", ""representation learning"", ""classification""]",Unsupervised classification via deep generative modeling with controllable feature learning evaluated in a difficult real world task,,,,
rybAWfx0b,2018,Invite to Workshop Track,False,COLD FUSION: TRAINING SEQ2SEQ MODELS TOGETHER WITH LANGUAGE MODELS,"[""Anuroop Sriram"", ""Heewoo Jun"", ""Sanjeev Satheesh"", ""Adam Coates""]","[""Sequence-to-Sequence Models"", ""Speech Recognition"", ""Language Models""]","We introduce a novel method to train Seq2Seq models with language models that converge faster, generalize better and can almost completely transfer to a new domain using less than 10% of labeled data.",,,,
rybDdHe0Z,2018,Reject,False,Sequence Transfer Learning for Neural Decoding,"[""Venkatesh Elango*"", ""Aashish N Patel*"", ""Kai J Miller"", ""Vikash Gilja""]","[""Transfer Learning"", ""Applications"", ""Neural decoding""]",,,,,
rydeCEhs-,2018,Accept (Poster),False,SMASH: One-Shot Model Architecture Search through HyperNetworks,"[""Andrew Brock"", ""Theo Lim"", ""J.M. Ritchie"", ""Nick Weston""]","[""meta-learning"", ""architecture search"", ""deep learning"", ""computer vision""]",A technique for accelerating neural architecture selection by approximating the weights of each candidate architecture instead of training them individually.,,,,
rye4g3AqFm,2019,Accept (Poster),False,Deep learning generalizes because the parameter-function map is biased towards simple functions,"[""Guillermo Valle-Perez"", ""Chico Q. Camargo"", ""Ard A. Louis""]","[""generalization"", ""deep learning theory"", ""PAC-Bayes"", ""Gaussian processes"", ""parameter-function map"", ""simplicity bias""]",The parameter-function map of deep networks is hugely biased; this can explain why they generalize. We use PAC-Bayes and Gaussian processes to obtain nonvacuous bounds.,,,,
rye5YaEtPr,2020,Accept (Poster),False,SAdam: A Variant of Adam for Strongly Convex Functions,"[""Guanghui Wang"", ""Shiyin Lu"", ""Quan Cheng"", ""Wei-wei Tu"", ""Lijun Zhang""]","[""Online convex optimization"", ""Adaptive online learning"", ""Adam""]",A variant of Adam for strongly convex functions,,,,
rye7IMbAZ,2018,Reject,False, Explicit Induction Bias for Transfer Learning with Convolutional Networks,"[""Xuhong LI"", ""Yves GRANDVALET"", ""Franck DAVOINE""]","[""transfer Learning"", ""convolutional networks"", ""fine-tuning"", ""regularization"", ""induction bias""]","In inductive transfer learning, fine-tuning pre-trained convolutional networks substantially outperforms training from scratch.",,,,
rye7XnRqFm,2019,Reject,False,Q-map: a Convolutional Approach for Goal-Oriented Reinforcement Learning,"[""Fabio Pardo"", ""Vitaly Levdik"", ""Petar Kormushev""]","[""reinforcement learning"", ""goal-oriented"", ""convolutions"", ""off-policy""]",Q-map is a reinforcement learning agent that uses a convolutional autoencoder-like architecture to efficiently learn to navigate its environment.,,,,
rye7knCqK7,2019,Accept (Poster),False,Learning when to Communicate at Scale in Multiagent Cooperative and Competitive Tasks,"[""Amanpreet Singh"", ""Tushar Jain"", ""Sainbayar Sukhbaatar""]","[""multiagent"", ""communication"", ""competitive"", ""cooperative"", ""continuous"", ""emergent"", ""reinforcement learning""]","We introduce IC3Net, a single network which can be used to train agents in cooperative, competitive and mixed scenarios. We also show that agents can learn when to communicate using our model.",,,,
rye9LT8cee,2017,Reject,False,Alternating Direction Method of Multipliers for Sparse Convolutional Neural Networks,"[""Farkhondeh Kiaee"", ""Christian Gagn\u00e9"", ""and Mahdieh Abbasi""]","[""Deep learning"", ""Computer vision"", ""Optimization""]",A method to sparsify (prune) pre-trained deep neural networks.,,,,
ryeAy3AqYm,2019,Reject,False,Distilled Agent DQN for Provable Adversarial Robustness,"[""Matthew Mirman"", ""Marc Fischer"", ""Martin Vechev""]","[""reinforcement learning"", ""dqn"", ""adversarial examples"", ""robustness analysis"", ""adversarial defense"", ""robust learning"", ""robust rl""]","We introduce a way of (provably) defending Deep-RL against adversarial perturbations, including a new poisoning attack.",,,,
ryeEr0EFvS,2020,Reject,False,A Hierarchy of Graph Neural Networks Based on Learnable Local Features,"[""Michael Lingzhi Li"", ""Meng Dong"", ""Jiawei Zhou"", ""Alexander M. Rush""]","[""Graph Neural Networks"", ""Hierarchy"", ""Weisfeiler-Lehman"", ""Discriminative Power""]","We developed a theoretically-sound hierarchy of graph neural networks (GNNs) based on aggregation regions, and demonstrated how to create powerful GNNs systematically using such framework.",,,,
ryeFY0EFwS,2020,Accept (Poster),False,Coherent Gradients: An Approach to Understanding Generalization in Gradient Descent-based Optimization,"[""Satrajit Chatterjee""]","[""generalization"", ""deep learning""]",We propose a hypothesis for why gradient descent generalizes based on how per-example gradients interact with each other.,2002.10657,cs.LG,2020-02-25 03:59:31+00:00,2020-02-25 03:59:31+00:00
ryeFzT4YPr,2020,Reject,True,"Lift-the-flap: what, where and when for context reasoning","[""Mengmi Zhang"", ""Claire Tseng"", ""Karla Montejo"", ""Joseph Kwon"", ""Gabriel Kreiman""]","[""contextual reasoning"", ""visual recognition"", ""human behavior"", ""intelligent sampling""]",Putting vision in context: a recurrent neural network model captures human visual reasoning,1902.00163,cs.CV,2019-02-01 03:37:17+00:00,2019-09-25 01:34:56+00:00
ryeG924twB,2020,Accept (Poster),False,Learning Expensive Coordination: An Event-Based Deep RL Approach,"[""Zhenyu Shi*"", ""Runsheng Yu*"", ""Xinrun Wang*"", ""Rundong Wang"", ""Youzhi Zhang"", ""Hanjiang Lai"", ""Bo An""]","[""Multi-Agent Deep Reinforcement Learning"", ""Deep Reinforcement Learning"", ""Leader\u2013Follower Markov Game"", ""Expensive Coordination""]",We propose an event-based policy gradient  to train the leader and an action abstraction policy gradient to train the followers in leader-follower Markov game.,,,,
ryeHuJBtPH,2020,Accept (Poster),False,Hyper-SAGNN: a self-attention based graph neural network for hypergraphs,"[""Ruochi Zhang"", ""Yuesong Zou"", ""Jian Ma""]","[""graph neural network"", ""hypergraph"", ""representation learning""]",We develop a new self-attention based graph neural network called Hyper-SAGNN applicable to homogeneous and heterogeneous hypergraphs with variable hyperedge sizes that can fulfill tasks like node classification and hyperedge prediction. ,1911.02613,cs.LG,2019-11-06 20:10:24+00:00,2019-11-06 20:10:24+00:00
ryeK6nNFDr,2020,Reject,False,Effective and Robust Detection of Adversarial Examples via Benford-Fourier Coefficients,"[""Chengcheng Ma"", ""Baoyuan Wu"", ""Shibiao Xu"", ""Yanbo Fan"", ""Yong Zhang"", ""Xiaopeng Zhang"", ""Zhifeng Li""]",[],,2005.05552,cs.CV,2020-05-12 05:20:59+00:00,2020-05-12 05:20:59+00:00
ryeN5aEYDH,2020,Reject,False,"Deep RL for Blood Glucose Control: Lessons, Challenges, and Opportunities","[""Ian Fox"", ""Joyce Lee"", ""Rodica Busui"", ""Jenna Wiens""]","[""Deep Reinforcement Learning"", ""Diabetes"", ""Artificial Pancreas"", ""Control""]",We develop a deep reinforcement learning algorithm to control blood glucose in people with diabetes. ,,,,
ryeNPi0qKX,2019,Reject,False,Language Modeling Teaches You More Syntax than Translation Does: Lessons Learned Through Auxiliary Task Analysis,"[""Kelly W. Zhang"", ""Samuel R. Bowman""]","[""representation learning"", ""recurrent neural networks"", ""syntax"", ""part-of-speech tagging""]","We throughly compare several pretraining tasks on their ability to induce syntactic information and find that representations from language models consistently perform best, even when trained on relatively small amounts of data.",,,,
ryeOSnAqYm,2019,Accept (Poster),False,Synthetic Datasets for Neural Program Synthesis,"[""Richard Shin"", ""Neel Kant"", ""Kavi Gupta"", ""Chris Bender"", ""Brandon Trabucco"", ""Rishabh Singh"", ""Dawn Song""]",[],,,,,
ryeQmCVYPS,2020,Reject,False,Defective Convolutional Layers Learn Robust CNNs,"[""Tiange Luo"", ""Tianle Cai"", ""Xiaomeng Zhang"", ""Siyu Chen"", ""Di He"", ""Liwei Wang""]","[""adversarial examples"", ""robust machine learning"", ""cnn structure"", ""deep feature representations""]",We propose a technique that modifies CNN structures to make predictions more relying on shape information and improve the defense ability against several types of attack.,,,,
ryeRn3NtPH,2020,Reject,False,Adversarial Inductive Transfer Learning with input and output space adaptation,"[""Hossein Sharifi-Noghabi"", ""Shuman Peng"", ""Olga Zolotareva"", ""Colin C. Collins"", ""Martin Ester""]","[""Inductive transfer learning"", ""adversarial learning"", ""multi-task learning"", ""pharmacogenomics"", ""precision oncology""]",A novel method of inductive transfer learning that employs adversarial learning and multi-task learning to address the discrepancy in input and output space,,,,
ryeRwlSYPH,2020,Reject,False,Learning transitional skills with intrinsic motivation,"[""Qiangxing Tian"", ""Jinxin Liu"", ""Donglin Wang""]",[],,,,,
ryeT10VKDH,2020,Reject,False,Adapt-to-Learn: Policy Transfer in Reinforcement Learning,"[""Girish Joshi"", ""Girish Chowdhary""]","[""Transfer Learning"", ""Reinforcement Learning"", ""Adaptation""]","In this paper, we present an architecture for adapting the policies learned from one RL domain to another.",2105.04699,cs.LG,2021-05-10 22:42:03+00:00,2021-05-10 22:42:03+00:00
ryeUg0VFwr,2020,Reject,True,Striving for Simplicity in Off-Policy Deep Reinforcement Learning,"[""Rishabh Agarwal"", ""Dale Schuurmans"", ""Mohammad Norouzi""]","[""reinforcement learning"", ""off-policy"", ""batch RL"", ""offline RL"", ""benchmark""]",,1907.04543,cs.LG,2019-07-10 07:23:27+00:00,2020-06-22 04:32:50+00:00
ryeX-nC9YQ,2019,Reject,False,Dimension-Free Bounds for Low-Precision Training,"[""Zheng Li"", ""Christopher De Sa""]","[""low precision"", ""stochastic gradient descent""]",we proved dimension-independent bounds for low-precision training algorithms,,,,
ryeYHi0ctQ,2019,Accept (Poster),False,DPSNet: End-to-end Deep Plane Sweep Stereo,"[""Sunghoon Im"", ""Hae-Gon Jeon"", ""Stephen Lin"", ""In So Kweon""]","[""Deep Learning"", ""Stereo"", ""Depth"", ""Geometry""]",A convolution neural network for multi-view stereo matching whose design is inspired by best practices of traditional geometry-based approaches,,,,
ryeYpJSKwr,2020,Accept (Spotlight),True,Meta-Learning Acquisition Functions for Transfer Learning in Bayesian Optimization,"[""Michael Volpp"", ""Lukas P. Fr\u00f6hlich"", ""Kirsten Fischer"", ""Andreas Doerr"", ""Stefan Falkner"", ""Frank Hutter"", ""Christian Daniel""]","[""Transfer Learning"", ""Meta Learning"", ""Bayesian Optimization"", ""Reinforcement Learning""]",We perform efficient and flexible transfer learning in the framework of Bayesian optimization through meta-learned neural acquisition functions.,1904.02642,stat.ML,2019-04-04 16:27:06+00:00,2020-02-14 13:24:57+00:00
ryeaZhRqFm,2019,Reject,False,Link Prediction in Hypergraphs using Graph Convolutional Networks,"[""Naganand Yadati"", ""Vikram Nitin"", ""Madhav Nimishakavi"", ""Prateek Yadav"", ""Anand Louis"", ""Partha Talukdar""]","[""Graph convolution"", ""hypergraph"", ""hyperlink prediction""]",We propose Neural Hyperlink Predictor (NHP). NHP adapts graph convolutional networks for link prediction in hypergraphs,,,,
ryebG04YvB,2020,Accept (Poster),False,Adversarially robust transfer learning,"[""Ali Shafahi"", ""Parsa Saadatpanah"", ""Chen Zhu"", ""Amin Ghiasi"", ""Christoph Studer"", ""David Jacobs"", ""Tom Goldstein""]",[],Robust models have robust feature extractors which can be useful for transferring robustness to other domains,,,,
ryedjkSFwr,2020,Reject,True,Global Momentum Compression for Sparse Communication in Distributed SGD,"[""Shen-Yi Zhao"", ""Yin-Peng Xie"", ""Hao Gao"", ""Wu-Jun Li""]","[""Distributed momentum SGD"", ""Communication compression""]","We propose a novel method combining global momentum and memory gradient for sparse communication, with an extra convergence guarantee.",1905.12948,stat.ML,2019-05-30 10:33:11+00:00,2019-09-17 16:46:30+00:00
ryedqa4FwS,2020,Reject,True,MANAS: Multi-Agent Neural Architecture Search,"[""Fabio Maria Carlucci"", ""Pedro M Esperan\u00e7a"", ""Marco Singh"", ""Victor Gabillon"", ""Antoine Yang"", ""Hang Xu"", ""Zewei Chen"", ""Jun Wang""]","[""Neural Architecture Search"", ""NAS"", ""AutoML"", ""Computer Vision""]",Scalable multi-agent formulation of neural architecture search,1909.01051,cs.CV,2019-09-03 10:36:37+00:00,2020-02-25 11:37:52+00:00
ryefE1SYDr,2020,Reject,False,LIA: Latently Invertible Autoencoder with Adversarial Learning,"[""Jiapeng Zhu"", ""Deli Zhao"", ""Bolei Zhou"", ""Bo Zhang""]","[""variational autoencoder"", ""generative adversarial network""]",A new model Latently Invertible Autoencoder is proposed to solve the problem of variational inference in VAE using the invertible network and two-stage adversarial training.,,,,
ryefmpEYPr,2020,Reject,False,iSparse: Output Informed Sparsification of Neural Networks,"[""Yash Garg"", ""K. Selcuk Candan""]","[""dropout"", ""dropconnect"", ""sparsification"", ""deep learning"", ""neural network""]",iSparse eliminates irrelevant or insignificant network edges with minimal impact on network performance by determining edge importance w.r.t. the final network output. ,,,,
ryeh4jA9F7,2019,Reject,False,Playing the Game of Universal Adversarial Perturbations,"[""Julien Perolet"", ""Mateusz Malinowski"", ""Bilal Piot"", ""Olivier Pietquin""]","[""adversarial perturbations"", ""universal adversarial perturbations"", ""game theory"", ""robust machine learning""]","We propose a robustification method under the presence of universal adversarial perturbations, by connecting a game theoretic method (fictitious play) with the problem of robustification, and making it more scalable.",,,,
ryekdoCqF7,2019,Reject,False,Incremental training of multi-generative adversarial networks,"[""Qi Tan"", ""Pingzhong Tang"", ""Ke Xu"", ""Weiran Shen"", ""Song Zuo""]","[""GAN"", ""Incremental training"", ""Information projection"", ""Mixture distribution""]",We propose a new method to incrementally train a mixture generative model to approximate the information projection of the real data distribution.,,,,
ryelgY5eg,2017,Accept (Poster),False,Optimal Binary Autoencoding with Pairwise Correlations,"[""Akshay Balsubramani""]","[""Theory"", ""Unsupervised Learning"", ""Games""]","Efficient biconvex learning of binary autoencoders, using pairwise correlations between encodings and decodings, is strongly optimal.",,,,
ryemosC9tm,2019,Reject,False,Representation-Constrained Autoencoders and an Application to Wireless Positioning,"[""Pengzhi Huang"", ""Emre Gonultas"", ""Said Medjkouh"", ""Oscar Castaneda"", ""Olav Tirkkonen"", ""Tom Goldstein"", ""Christoph Studer""]","[""Autoencoder"", ""dimensionality reduction"", ""wireless positioning"", ""channel charting"", ""localization""]",We propose to impose representation constraints to autoencoders in order to localize wireless transmitters in space from their channel state information. ,,,,
ryen_CEFwr,2020,Reject,False,"Unsupervised Disentanglement of Pose, Appearance and Background from Images and Videos","[""Aysegul Dundar"", ""Kevin J Shih"", ""Animesh Garg"", ""Robert Pottorf"", ""Andrew Tao"", ""Bryan Catanzaro""]","[""unsupervised landmark discovery""]",,,,,
ryenvpEKDr,2020,Accept (Poster),True,A Constructive Prediction of the Generalization Error Across Scales,"[""Jonathan S. Rosenfeld"", ""Amir Rosenfeld"", ""Yonatan Belinkov"", ""Nir Shavit""]","[""neural networks"", ""deep learning"", ""generalization error"", ""scaling"", ""scalability"", ""vision"", ""language""]",We predict the generalization error and specify the model which attains it across model/data scales.,1909.12673,cs.LG,2019-09-27 13:27:53+00:00,2019-12-20 18:20:34+00:00
ryeoxnRqKQ,2019,Reject,False,NATTACK: A STRONG AND UNIVERSAL GAUSSIAN BLACK-BOX ADVERSARIAL ATTACK,"[""Yandong Li"", ""Lijun Li"", ""Liqiang Wang"", ""Tong Zhang"", ""Boqing Gong""]","[""adversarial attack"", ""black-box"", ""evolutional strategy"", ""policy gradient""]",,,,,
ryepFJbA-,2018,Reject,False,On Convergence and Stability of GANs,"[""Naveen Kodali"", ""James Hays"", ""Jacob Abernethy"", ""Zsolt Kira""]","[""GAN"", ""Generative Adversarial Networks"", ""Mode Collapse"", ""Stability"", ""Game Theory"", ""Regret Minimization"", ""Convergence"", ""Gradient Penalty""]",Analysis of convergence and mode collapse by studying GAN training process as regret minimization,,,,
ryepUj0qtX,2019,Accept (Poster),False,Conditional Network Embeddings,"[""Bo Kang"", ""Jefrey Lijffijt"", ""Tijl De Bie""]","[""Network embedding"", ""graph embedding"", ""learning node representations"", ""link prediction"", ""multi-label classification of nodes""]","We introduce a network embedding method that accounts for prior information about the network, yielding superior empirical performance.",,,,
ryesZANKPB,2020,Reject,False,Meta Learning via Learned Loss,"[""Sarah Bechtle"", ""Artem Molchanov"", ""Yevgen Chebotar"", ""Edward Grefenstette"", ""Ludovic Righetti"", ""Gaurav Sukhatme"", ""Franziska Meier""]","[""Meta Learning"", ""Reinforcement Learning"", ""Loss Learning""]",Meta learning a loss function for optimisation for supervised learning tasks as well as reinforcement learning,,,,
ryestJBKPB,2020,Reject,False,Graph Neural Networks for Soft Semi-Supervised Learning on Hypergraphs,"[""Naganand Yadati"", ""Tingran Gao"", ""Shahab Asoodeh"", ""Partha Talukdar"", ""Anand Louis""]","[""Graph Neural Networks"", ""Soft Semi-supervised Learning"", ""Hypergraphs""]",We explore Graph Neural Networks for semi-supervised learning of probability distributions,,,,
ryetZ20ctX,2019,Accept (Poster),False,Defensive Quantization: When Efficiency Meets Robustness,"[""Ji Lin"", ""Chuang Gan"", ""Song Han""]","[""defensive quantization"", ""model quantization"", ""adversarial attack"", ""efficiency"", ""robustness""]",We designed a novel quantization methodology to jointly optimize the efficiency and robustness of deep learning models.,,,,
ryevtyHtPr,2020,Reject,False,Do Deep Neural Networks for Segmentation Understand Insideness?,"[""Kimberly M Villalobos"", ""Vilim Stih"", ""Amineh Ahmadinejad"", ""Jamell Dozier"", ""Andrew Francl"", ""Frederico Azevedo"", ""Tomotake Sasaki"", ""Xavier Boix""]","[""Image Segmentation"", ""Deep Networks for Spatial Relationships"", ""Visual Routines"", ""Recurrent Neural Networks""]",DNNs for image segmentation can implement solutions for the insideness problem but only some recurrent nets could learn them with a specific type of supervision.,,,,
ryewE3R5YX,2019,Reject,False,Characterizing Attacks on Deep Reinforcement Learning,"[""Chaowei Xiao"", ""Xinlei Pan"", ""Warren He"", ""Bo Li"", ""Jian Peng"", ""Mingjie Sun"", ""Jinfeng Yi"", ""Mingyan Liu"", ""Dawn Song.""]",[],,,,,
ryex8CEKPr,2020,Reject,False,Knockoff-Inspired Feature Selection via Generative Models,"[""Marco F. Duarte"", ""Siwei Feng""]","[""feature selection"", ""variable selection"", ""knockoff variables"", ""supervised learning""]",We propose a feature selection algorithm for supervised learning inspired by the recently introduced  knockoff framework for variable selection in statistical regression.,,,,
ryeyti0qKX,2019,Reject,False,On the Statistical and Information Theoretical Characteristics of DNN Representations,"[""Daeyoung Choi"", ""Wonjong Rhee"", ""Kyungeun Lee"", ""Changho Shin""]","[""learned representation"", ""statistical characteristics"", ""information theoretical characteristics"", ""deep network""]",,,,,
ryf6Fs09YX,2019,Accept (Poster),False,GO Gradient for Expectation-Based Objectives,"[""Yulai Cong"", ""Miaoyun Zhao"", ""Ke Bai"", ""Lawrence Carin""]","[""generalized reparameterization gradient"", ""variance reduction"", ""non-reparameterizable"", ""discrete random variable"", ""GO gradient"", ""general and one-sample gradient"", ""expectation-based objective"", ""variable nabla"", ""statistical back-propagation"", ""hierarchical"", ""graphical model""]","a Rep-like gradient for non-reparameterizable continuous/discrete distributions; further generalized to deep probabilistic models, yielding statistical back-propagation",,,,
ryf7ioRqFX,2019,Accept (Poster),False,h-detach: Modifying the LSTM Gradient Towards Better Optimization,"[""Bhargav Kanuparthi"", ""Devansh Arpit"", ""Giancarlo Kerg"", ""Nan Rosemary Ke"", ""Ioannis Mitliagkas"", ""Yoshua Bengio""]","[""LSTM"", ""Optimization"", ""Long term dependencies"", ""Back-propagation through time""]",A simple algorithm to improve optimization and handling of long term dependencies in LSTM,,,,
ryfMLoCqtQ,2019,Accept (Poster),False,An analytic theory of generalization dynamics and transfer learning in deep linear networks,"[""Andrew K. Lampinen"", ""Surya Ganguli""]","[""Generalization"", ""Theory"", ""Transfer"", ""Multi-task"", ""Linear""]",We provide many insights into neural network generalization from the theoretically tractable linear case.,,,,
ryfaViR9YX,2019,Reject,False,Variation Network: Learning High-level Attributes for Controlled Input Manipulation,"[""Ga\u00ebtan Hadjeres""]","[""Generative models"", ""Input manipulation"", ""Unsupervised feature learning"", ""Variations""]",The Variation Network is a generative model able to learn high-level attributes without supervision that can then be used for controlled input manipulation.,,,,
ryfcCo0ctQ,2019,Reject,False,Convergent Reinforcement Learning with Function Approximation: A Bilevel Optimization Perspective,"[""Zhuoran Yang"", ""Zuyue Fu"", ""Kaiqing Zhang"", ""Zhaoran Wang""]","[""reinforcement learning"", ""Deep Q-networks"", ""actor-critic algorithm"", ""ODE approximation""]",,,,,
ryfz73C9KQ,2019,Reject,False,Neural Predictive Belief Representations,"[""Zhaohan Daniel Guo"", ""Mohammad Gheshlaghi Azar"", ""Bilal Piot"", ""Bernardo Avila Pires"", ""R\u00e9mi Munos""]","[""belief states"", ""representation learning"", ""contrastive predictive coding"", ""reinforcement learning"", ""predictive state representations"", ""deep reinforcement learning""]",We investigate the quality of belief state representations of partially observable dynamic environments learned with modern neural architectures.,,,,
ryg48p4tPH,2020,Accept (Poster),True,Action Semantics Network: Considering the Effects of Actions in Multiagent Systems,"[""Weixun Wang"", ""Tianpei Yang"", ""Yong Liu"", ""Jianye Hao"", ""Xiaotian Hao"", ""Yujing Hu"", ""Yingfeng Chen"", ""Changjie Fan"", ""Yang Gao""]","[""multiagent coordination"", ""multiagent learning""]",Our proposed ASN characterizes different actions' influence on other agents using neural networks based on the action semantics between them.,1907.11461,cs.MA,2019-07-26 09:51:30+00:00,2020-01-16 02:08:54+00:00
ryg7jhEtPB,2020,Reject,False,On importance-weighted autoencoders,"[""Axel Finke"", ""Alexandre H. Thiery""]","[""variational inference"", ""autoencoders"", ""importance sampling""]",We show that most variants of importance-weighted autoencoders can be derived in a more principled manner as special cases of adaptive importance-sampling approaches like the reweighted-wake sleep algorithm.,,,,
ryg7vA4tPB,2020,Reject,False,Rigging the Lottery: Making All Tickets Winners,"[""Utku Evci"", ""Erich Elsen"", ""Pablo Castro"", ""Trevor Gale""]","[""sparse training"", ""sparsity"", ""pruning"", ""lottery tickets"", ""imagenet"", ""resnet"", ""mobilenet"", ""efficiency"", ""optimization"", ""local minima""]","We demonstrate state-of-the-art sparse training results with ResNet-50, MobileNet v1 and MobileNet v2 on the ImageNet-2012 dataset.",,,,
ryg8WJSKPr,2020,Reject,False,ConQUR: Mitigating Delusional Bias in Deep Q-Learning,"[""DiJia-Andy Su"", ""Jayden Ooi"", ""Tyler Lu"", ""Dale Schuurmans"", ""Craig Boutilier\u200e""]","[""reinforcement learning"", ""q-learning"", ""deep reinforcement learning"", ""Atari""]",We developed a search framework and consistency penalty to mitigate delusional bias.,,,,
ryg8wpEtvB,2020,Reject,True,Evaluating and Calibrating Uncertainty Prediction in Regression Tasks,"[""Dan Levi"", ""Liran Gispan"", ""Niv Giladi"", ""Ethan Fetaya""]","[""Uncertainty Estimation"", ""Regression"", ""Deep learning""]",We propose a new definition for calibrated uncertainty prediction in regression tasks and a method for uncertainty calibration,1905.11659,cs.LG,2019-05-28 07:52:01+00:00,2020-02-03 14:42:54+00:00
rygBVTVFPB,2020,Reject,False,Learning to Discretize: Solving 1D Scalar Conservation Laws via Deep Reinforcement Learning,"[""Yufei Wang*"", ""Ziju Shen*"", ""Zichao Long"", ""Bin Dong""]","[""Numerical Methods"", ""Conservation Laws"", ""Reinforcement Learning""]","We observe that numerical PDE solvers can be regarded as Markov Desicion Processes, and propose to use Reinforcement Learning to solve 1D scalar Conservation Laws",,,,
rygEokBKPS,2020,Reject,False,Yet another but more efficient black-box adversarial attack: tiling and evolution strategies,"[""Laurent Meunier"", ""Jamal Atif"", ""Olivier Teytaud""]","[""adversarial examples"", ""black-box attacks"", ""derivative free optimization"", ""deep learning""]",We propose a new black-box adversarial attack based on tiling and evolution strategies,,,,
rygFWAEFwS,2020,Accept (Poster),False,Stochastic Weight Averaging in Parallel: Large-Batch Training That Generalizes Well,"[""Vipul Gupta"", ""Santiago Akle Serrano"", ""Dennis DeCoste""]","[""Large batch training"", ""Distributed neural network training"", ""Stochastic Weight Averaging""]","We propose SWAP, a distributed algorithm for large-batch training of neural networks.",2001.02312,cs.LG,2020-01-07 23:13:35+00:00,2020-01-07 23:13:35+00:00
rygFmh0cKm,2019,Reject,False,On Difficulties of Probability Distillation,"[""Chin-Wei Huang"", ""Faruk Ahmed"", ""Kundan Kumar"", ""Alexandre Lacoste"", ""Aaron Courville""]","[""Probability distillation"", ""Autoregressive models"", ""normalizing flows"", ""wavenet"", ""pixelcnn""]","We point out an optimization issue of distillation with KL divergence, and explore different alternatives",,,,
rygG4AVFvH,2020,Accept (Poster),False,Chameleon: Adaptive Code Optimization for Expedited Deep Neural Network Compilation,"[""Byung Hoon Ahn"", ""Prannoy Pilligundla"", ""Amir Yazdanbakhsh"", ""Hadi Esmaeilzadeh""]","[""Reinforcement Learning"", ""Learning to Optimize"", ""Combinatorial Optimization"", ""Compilers"", ""Code Optimization"", ""Neural Networks"", ""ML for Systems"", ""Learning for Systems""]",Reinforcement Learning and Adaptive Sampling for Optimized Compilation of Deep Neural Networks.,2001.08743,cs.LG,2020-01-23 20:42:47+00:00,2020-01-23 20:42:47+00:00
rygG7AEtvB,2020,Reject,False,Finding Mixed Strategy Nash Equilibrium for Continuous Games through Deep Learning,"[""Zehao Dou"", ""Xiang Yan"", ""Dongge Wang"", ""Xiaotie Deng""]","[""Mixed strategy Nash Equilibrium"", ""Continuous Game"", ""Pushforward Measure"", ""NI Function""]",Design a very first algorithm to compute the mixed strategy Nash equilibrium of games with continuous action space.,,,,
rygGQyrFvH,2020,Accept (Poster),True,The Curious Case of Neural Text Degeneration,"[""Ari Holtzman"", ""Jan Buys"", ""Li Du"", ""Maxwell Forbes"", ""Yejin Choi""]","[""generation"", ""text"", ""NLG"", ""NLP"", ""natural language"", ""natural language generation"", ""language model"", ""neural"", ""neural language model""]",Current language generation systems either aim for high likelihood and devolve into generic repetition or miscalibrate their stochasticityâwe provide evidence of both and propose a solution: Nucleus Sampling.,1904.09751,cs.CL,2019-04-22 07:17:18+00:00,2020-02-14 21:56:30+00:00
rygHe64FDS,2020,Reject,False,Zeno++: Robust Fully Asynchronous SGD,"[""Cong Xie"", ""Oluwasanmi Koyejo"", ""Indranil Gupta""]","[""fault-tolerance"", ""Byzantine-tolerance"", ""security"", ""SGD"", ""asynchronous""]","We propose Zeno++, a new robust asynchronous Stochastic Gradient Descent algorithm which tolerates Byzantine failures of the workers.",,,,
rygHq6EFwr,2020,Reject,True,GResNet: Graph Residual Network for Reviving Deep GNNs from Suspended Animation,"[""Jiawei Zhang"", ""Lin Meng""]","[""Graph Neural Networks"", ""Node Classification"", ""Representation Learning""]","Identifying suspended animation problem with GNNs, propose a new model to resolve the problem with graph residual learning.",1909.05729,cs.LG,2019-09-12 14:46:12+00:00,2019-09-24 17:13:36+00:00
rygMWT4twS,2020,Reject,True,Stochastic Gradient Descent with Biased but Consistent Gradient Estimators,"[""Jie Chen"", ""Ronny Luss""]","[""Stochastic optimization"", ""biased gradient estimator"", ""graph convolutional networks""]",Convergence theory for biased (but consistent) gradient estimators in stochastic optimization and application to graph convolutional networks,1807.11880,cs.LG,2018-07-31 15:51:08+00:00,2019-12-23 15:03:36+00:00
rygPm64tDH,2020,Reject,False,Learning Explainable Models Using Attribution Priors,"[""Gabriel Erion"", ""Joseph D. Janizek"", ""Pascal Sturmfels"", ""Scott M. Lundberg"", ""Su-In Lee""]","[""Deep Learning"", ""Interpretability"", ""Attributions"", ""Explanations"", ""Biology"", ""Health"", ""Computational Biology""]",A method for encouraging axiomatic feature attributions of a deep model to match human intuition.,,,,
rygRP2VYwB,2020,Reject,False,Stochastically Controlled Compositional Gradient for the Composition problem,"[""Liu Liu"", ""Ji Liu"", ""Cho-Jui Hsieh"", ""Dacheng Tao""]","[""Non-convex optimisation"", ""Composition problem"", ""Stochastically controlled compositional gradient""]",We devise a stochastically controlled compositional gradient algorithm for the composition problem,,,,
rygT_JHtDr,2020,Reject,False,Scalable Deep Neural Networks via Low-Rank Matrix Factorization,"[""Atsushi Yaguchi"", ""Taiji Suzuki"", ""Shuhei Nitta"", ""Yukinobu Sakata"", ""Akiyuki Tanizawa""]","[""Deep Learning"", ""Deep Neural Networks"", ""Low-Rank Matrix Factorization"", ""Model Compression""]","In this paper, we propose a novel method that enables DNNs to flexibly change their size after training. We factorize the weight matrices of the DNNs via singular value decomposition (SVD) and change their ranks according to the target size.",,,,
rygUoeHKvB,2020,Reject,False,Deep exploration by novelty-pursuit with maximum state entropy,"[""Zi-Niu Li"", ""Xiong-Hui Chen"", ""Yang Yu""]","[""Exploration"", ""Reinforcement Learning""]",We propose an efficient exploration method called Novelty-pursuit for reinforcement learning. This method bridges the intrinsically motivated goal exploration process and the the maximum state entropy exploration.,,,,
rygVV205KQ,2019,Reject,False,Visual Imitation with a Minimal Adversary,"[""Scott Reed"", ""Yusuf Aytar"", ""Ziyu Wang"", ""Tom Paine"", ""A\u00e4ron van den Oord"", ""Tobias Pfaff"", ""Sergio Gomez"", ""Alexander Novikov"", ""David Budden"", ""Oriol Vinyals""]","[""imitation"", ""from pixels"", ""adversarial""]","Imitation from pixels, with sparse or no reward, using off-policy RL and a tiny adversarially-learned reward function.",,,,
rygZJ2RcF7,2019,Reject,False,Out-of-Sample Extrapolation with Neuron Editing,"[""Matthew Amodio"", ""David van Dijk"", ""Ruth Montgomery"", ""Guy Wolf"", ""Smita Krishnaswamy""]","[""generative adversarial networks"", ""computational biology"", ""generating"", ""generation"", ""extrapolation"", ""out-of-sample"", ""neural network inference""]","We reframe the generation problem as one of editing existing points, and as a result extrapolate better than traditional GANs.",,,,
ryga2CNKDH,2020,Reject,False,Evaluating Lossy Compression Rates of Deep Generative Models,"[""Sicong Huang"", ""Alireza Makhzani"", ""Yanshuai Cao"", ""Roger Grosse""]","[""Deep Learning"", ""Generative Models"", ""Information Theory"", ""Rate Distortion Theory""]","We study rate distortion approximations for evaluating deep generative models, and show that rate distortion curves provide more insights about the model than the log-likelihood alone while requiring roughly the same computational cost.",2008.06653,cs.LG,2020-08-15 05:08:28+00:00,2020-08-15 05:08:28+00:00
rygeHgSFDH,2020,Accept (Spotlight),False,Disentanglement by Nonlinear ICA with General Incompressible-flow Networks (GIN),"[""Peter Sorrenson"", ""Carsten Rother"", ""Ullrich K\u00f6the""]","[""disentanglement"", ""nonlinear ICA"", ""representation learning"", ""feature discovery"", ""theoretical justification""]",,2001.04872,cs.LG,2020-01-14 16:25:08+00:00,2020-01-14 16:25:08+00:00
rygePJHYPH,2020,Reject,False,Towards trustworthy predictions from deep neural networks with fast adversarial calibration,"[""Christian Tomani"", ""Florian Buettner""]","[""deep learning"", ""uncertainty"", ""calibration"", ""domain shift"", ""robustness""]",,2012.10923,cs.LG,2020-12-20 13:39:29+00:00,2021-03-02 19:27:46+00:00
rygf-kSYwH,2020,Accept (Spotlight),True,Behaviour Suite for Reinforcement Learning,"[""Ian Osband"", ""Yotam Doron"", ""Matteo Hessel"", ""John Aslanides"", ""Eren Sezener"", ""Andre Saraiva"", ""Katrina McKinney"", ""Tor Lattimore"", ""Csaba Szepesvari"", ""Satinder Singh"", ""Benjamin Van Roy"", ""Richard Sutton"", ""David Silver"", ""Hado Van Hasselt""]","[""reinforcement learning"", ""benchmark"", ""core issues"", ""scalability"", ""reproducibility""]",Bsuite is a collection of carefully-designed experiments that investigate the core capabilities of RL agents.,1908.03568,cs.LG,2019-08-09 08:34:08+00:00,2020-02-14 15:18:17+00:00
rygfC0VKPS,2020,Reject,False,Improved Modeling of Complex Systems Using Hybrid Physics/Machine Learning/Stochastic Models,"[""Anand Ramakrishnan"", ""Warren B. Jackson"", ""Kent Evans""]","[""Composition"", ""extrapolation"", ""boosting"", ""autocorrelation"", ""systematic errors""]","Improved modeling of complex systems uses hybrid neural/domain model composition, new decorrelation loss functions and extrapolative test sets ",,,,
rygfnn4twS,2020,Accept (Poster),False,AutoQ: Automated Kernel-Wise Neural Network Quantization ,"[""Qian Lou"", ""Feng Guo"", ""Minje Kim"", ""Lantao Liu"", ""Lei Jiang.""]","[""AutoML"", ""Kernel-Wise Neural Networks Quantization"", ""Hierarchical Deep Reinforcement Learning""]","Accurate, Fast and Automated Kernel-Wise Neural Network Quantization with Mixed Precision using Hierarchical Deep Reinforcement Learning",,,,
ryggIs0cYQ,2019,Accept (Poster),False,Differentiable Learning-to-Normalize via Switchable Normalization,"[""Ping Luo"", ""Jiamin Ren"", ""Zhanglin Peng"", ""Ruimao Zhang"", ""Jingyu Li""]","[""normalization"", ""deep learning"", ""CNN"", ""computer vision""]",,,,,
ryghPCVYvH,2020,Reject,False,Generative Restricted Kernel Machines,"[""Arun Pandey"", ""Joachim Schreurs"", ""Johan A.K. Suykens""]","[""Generative models"", ""Kernel methods"", ""Deep learning""]",Gen-RKM: a novel framework for generative models using Restricted Kernel Machines with multi-view generation and uncorrelated feature learning.,,,,
ryghZJBKPS,2020,Accept (Talk),True,"Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds","[""Jordan T. Ash"", ""Chicheng Zhang"", ""Akshay Krishnamurthy"", ""John Langford"", ""Alekh Agarwal""]","[""deep learning"", ""active learning"", ""batch active learning""]","We introduce a new batch active learning algorithm that's robust to model architecture, batch size, and dataset.",1906.03671,cs.LG,2019-06-09 16:52:09+00:00,2020-02-24 02:14:51+00:00
rygixkHKDH,2020,Accept (Talk),False,Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning,"[""Qing Qu"", ""Yuexiang Zhai"", ""Xiao Li"", ""Yuqian Zhang"", ""Zhihui Zhu""]","[""dictionary learning"", ""sparse representations"", ""nonconvex optimization""]",,1912.02427,cs.LG,2019-12-05 08:14:24+00:00,2019-12-10 18:54:46+00:00
rygjHxrYDB,2020,Accept (Poster),False,Deep Audio Priors Emerge From Harmonic Convolutional Networks,"[""Zhoutong Zhang"", ""Yunyun Wang"", ""Chuang Gan"", ""Jiajun Wu"", ""Joshua B. Tenenbaum"", ""Antonio Torralba"", ""William T. Freeman""]","[""Audio"", ""Deep Prior""]",A new operation called Harmonic Convolution makes deep network model audio priors without training.,,,,
rygjN3C9F7,2019,Reject,False,The Variational Deficiency Bottleneck,"[""Pradeep Kr. Banerjee"", ""Guido Montufar""]","[""Variational Information Bottleneck"", ""Blackwell Sufficiency"", ""Le Cam Deficiency"", ""Information Channel""]",We develop a new bottleneck method based on channel deficiency.,,,,
rygjcsR9Y7,2019,Accept (Poster),False,SOM-VAE: Interpretable Discrete Representation Learning on Time Series,"[""Vincent Fortuin"", ""Matthias H\u00fcser"", ""Francesco Locatello"", ""Heiko Strathmann"", ""Gunnar R\u00e4tsch""]","[""deep learning"", ""self-organizing map"", ""variational autoencoder"", ""representation learning"", ""time series"", ""machine learning"", ""interpretability""]","We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.",,,,
rygjmpVFvB,2020,Accept (Poster),False,Difference-Seeking Generative Adversarial Network--Unseen Sample Generation,"[""Yi Lin Sung"", ""Sung-Hsien Hsieh"", ""Soo-Chang Pei"", ""Chun-Shien Lu""]","[""generative adversarial network"", ""semi-supervised learning"", ""novelty detection""]",We proposed a novel GAN framework to generate unseen data.,,,,
rygk9oA9Ym,2019,Reject,False,3D-RelNet: Joint Object and Relational Network for 3D Prediction,"[""Nilesh Kulkarni"", ""Ishan Misra"", ""Shubham Tulsiani"", ""Abhinav Gupta""]","[""3D Reconstruction"", ""3D Scene Understanding"", ""Relative Prediction""]",We reason about relative spatial relationships between the objects in a scene to produce better 3D predictions,,,,
rygkk305YQ,2019,Accept (Poster),False,Hierarchical Generative Modeling for Controllable Speech Synthesis,"[""Wei-Ning Hsu"", ""Yu Zhang"", ""Ron J. Weiss"", ""Heiga Zen"", ""Yonghui Wu"", ""Yuxuan Wang"", ""Yuan Cao"", ""Ye Jia"", ""Zhifeng Chen"", ""Jonathan Shen"", ""Patrick Nguyen"", ""Ruoming Pang""]","[""speech synthesis"", ""representation learning"", ""deep generative model"", ""sequence-to-sequence model""]","Building a TTS model with Gaussian Mixture VAEs enables fine-grained control of speaking style, noise condition, and more.",,,,
rygnfn0qF7,2019,Reject,False,Language Model Pre-training for Hierarchical Document Representations,"[""Ming-Wei Chang"", ""Kristina Toutanova"", ""Kenton Lee"", ""Jacob Devlin""]",[],,,,,
rygo9iR9F7,2019,Reject,False,Progressive Weight Pruning Of Deep Neural Networks Using ADMM,"[""Shaokai Ye"", ""Tianyun Zhang"", ""Kaiqi Zhang"", ""Jiayu Li"", ""Kaidi Xu"", ""Yunfei Yang"", ""Fuxun Yu"", ""Jian Tang"", ""Makan Fardad"", ""Sijia Liu"", ""Xiang Chen"", ""Xue Lin"", ""Yanzhi Wang""]","[""deep learning"", ""model compression"", ""optimization"", ""ADMM"", ""weight pruning""]",We implement a DNN weight pruning approach that achieves the highest pruning rates.,,,,
rygoURNYvS,2020,Reject,False,Pre-trained Contextual Embedding of Source Code,"[""Aditya Kanade"", ""Petros Maniatis"", ""Gogul Balakrishnan"", ""Kensen Shi""]",[],,2001.00059,cs.SE,2019-12-21 05:05:22+00:00,2020-08-17 21:40:59+00:00
rygp3iRcF7,2019,Reject,False,Area Attention,"[""Yang Li"", ""Lukasz Kaiser"", ""Samy Bengio"", ""Si Si""]","[""Deep Learning"", ""attentional mechanisms"", ""neural machine translation"", ""image captioning""]",The paper presents a novel approach for attentional mechanisms that can benefit a range of tasks such as machine translation and image captioning.,,,,
rygqqsA9KX,2019,Accept (Poster),False,Learning Factorized Multimodal Representations,"[""Yao-Hung Hubert Tsai"", ""Paul Pu Liang"", ""Amir Zadeh"", ""Louis-Philippe Morency"", ""Ruslan Salakhutdinov""]","[""multimodal learning"", ""representation learning""]","We propose a model to learn factorized multimodal representations that are discriminative, generative, and interpretable.",,,,
rygrBhC5tQ,2019,Accept (Poster),False,Composing Complex Skills by Learning Transition Policies,"[""Youngwoon Lee*"", ""Shao-Hua Sun*"", ""Sriram Somasundaram"", ""Edward S. Hu"", ""Joseph J. Lim""]","[""reinforcement learning"", ""hierarchical reinforcement learning"", ""continuous control"", ""modular framework""]",Transition policies enable agents to compose complex skills by smoothly connecting previously acquired primitive skills.,,,,
rygtPhVtDS,2020,Reject,True,Noise Regularization for Conditional Density Estimation,"[""Jonas Rothfuss"", ""Fabio Ferreira"", ""Simon Boehm"", ""Simon Walther"", ""Maxim Ulrich"", ""Tamim Asfour"", ""Andreas Krause""]",[],A model-agnostic regularization scheme for neural network-based conditional density estimation.,1907.08982,stat.ML,2019-07-21 14:17:28+00:00,2020-02-14 09:37:59+00:00
ryguP1BFwr,2020,Reject,False,Walking the Tightrope: An Investigation of the Convolutional Autoencoder Bottleneck,"[""Ilja Manakov"", ""Markus Rohm"", ""Volker Tresp""]","[""convolutional autoencoder"", ""bottleneck"", ""representation learning""]",We conduct experiments on how the bottlneck in convolutional autoencoder influences their behavior and find that heigth/widht matters significantly more than number of channels and that complete CAEs do not learn to simply copy their input.,1911.07460,cs.LG,2019-11-18 07:19:14+00:00,2020-05-12 19:27:36+00:00
rygunsAqYQ,2019,Reject,False,Implicit Maximum Likelihood Estimation,"[""Ke Li"", ""Jitendra Malik""]","[""likelihood-free inference"", ""implicit probabilistic models""]",We develop a new likelihood-free parameter estimation method that is equivalent to maximum likelihood under some conditions,,,,
rygvFyrKwH,2020,Reject,True,Adversarial Robustness as a Prior for Learned Representations,"[""Logan Engstrom"", ""Andrew Ilyas"", ""Shibani Santurkar"", ""Dimitris Tsipras"", ""Brandon Tran"", ""Aleksander Madry""]","[""adversarial robustness"", ""adversarial examples"", ""robust optimization"", ""representation learning"", ""feature visualization""]","Representations learned by robust neural networks align better with our idealization of representations as high-level feature extractors, and thus allow for representation inversion, as well as direct feature visualization and manipulation.",1906.00945,stat.ML,2019-06-03 17:55:20+00:00,2019-09-27 17:39:54+00:00
rygw7aNYDS,2020,Reject,True,Efficient Inference and Exploration for Reinforcement Learning,"[""Yi Zhu"", ""Jing Dong"", ""Henry Lam""]","[""Reinforcement Learning"", ""Efficient Exploration"", ""Asymptotic Analysis"", ""Statistical Inference""]",We investigate the large-sample behaviors of the Q-value estimates and proposed an efficient exploration strategy that relies on estimating the relative discrepancies among the Q estimates. ,1910.05471,cs.LG,2019-10-12 03:02:14+00:00,2019-11-04 20:25:09+00:00
rygwLgrYPB,2020,Accept (Poster),False,Regularizing activations in neural networks via distribution matching with the Wasserstein metric,"[""Taejong Joo"", ""Donggu Kang"", ""Byunghoon Kim""]","[""regularization"", ""Wasserstein metric"", ""deep learning""]",,2002.05366,cs.LG,2020-02-13 06:42:01+00:00,2020-04-27 02:31:16+00:00
rygxdA4YPS,2020,Reject,False,AdaScale SGD: A Scale-Invariant Algorithm for Distributed Training,"[""Tyler B. Johnson"", ""Pulkit Agrawal"", ""Haijie Gu"", ""Carlos Guestrin""]","[""Large-batch SGD"", ""large-scale learning"", ""distributed training""]","A practical and principled algorithm for distributed SGD, which simplifies the process of scaling up training",2007.05105,cs.LG,2020-07-09 23:26:13+00:00,2020-07-09 23:26:13+00:00
ryh9pmcee,2017,Accept (Poster),False,Energy-based Generative Adversarial Networks,"[""Junbo Zhao"", ""Michael Mathieu"", ""Yann LeCun""]","[""Deep learning"", ""Unsupervised Learning"", ""Semi-Supervised Learning""]","We introduce the ""Energy-based Generative Adversarial Network"" (EBGAN) model.",,,,
ryh_8f9lg,2017,Reject,False,Classless Association using Neural Networks,"[""Federico Raue"", ""Sebastian Palacio"", ""Andreas Dengel"", ""Marcus Liwicki""]",[],Learning based on the relation between two instances of the same unknown class,,,,
ryhqQFKgl,2017,Accept (Poster),False,Towards Deep Interpretability (MUS-ROVER II): Learning Hierarchical Representations of Tonal Music,"[""Haizi Yu"", ""Lav R. Varshney""]",[],,,,,
ryiAv2xAZ,2018,Accept (Poster),True,Training Confidence-calibrated Classifiers for Detecting Out-of-Distribution Samples,"[""Kimin Lee"", ""Honglak Lee"", ""Kibok Lee"", ""Jinwoo Shin""]",[],,1711.09325,stat.ML,2017-11-26 02:50:39+00:00,2018-02-23 19:42:15+00:00
ryj0790hb,2018,Reject,False,Incremental Learning through Deep Adaptation,"[""Amir Rosenfeld"", ""John K. Tsotsos""]","[""Transfer Learning"", ""Learning without forgetting"", ""Multitask Learning""]","An alternative to transfer learning that learns faster, requires much less parameters (3-13 %), usually achieves better results and precisely preserves performance on old tasks.",,,,
ryj38zWRb,2018,Reject,False,Optimizing the Latent Space of Generative Networks,"[""Piotr Bojanowski"", ""Armand Joulin"", ""David Lopez-Paz"", ""Arthur Szlam""]","[""generative models"", ""latent variable models"", ""image generation"", ""generative adversarial networks"", ""convolutional neural networks""]",Are GANs successful because of adversarial training or the use of ConvNets? We show a ConvNet generator trained with a simple reconstruction loss and learnable noise vectors leads many of the desirable properties of a  GAN.,,,,
ryjp1c9xg,2017,Reject,False,Extensions and Limitations of the Neural GPU,"[""Eric Price"", ""Wojciech Zaremba"", ""Ilya Sutskever""]",[],,,,,
ryjw_eAaZ,2018,Reject,False,Unsupervised Deep Structure Learning by Recursive Dependency Analysis,"[""Raanan Y. Yehezkel Rohekar"", ""Guy Koren"", ""Shami Nisimov"", ""Gal Novik""]","[""unsupervised learning"", ""structure learning"", ""deep belief networks"", ""probabilistic graphical models"", ""Bayesian networks""]",A principled approach for structure learning of deep neural networks with a new interpretation for depth and inter-layer connectivity. ,,,,
ryk77mbRZ,2018,Reject,False,Noise-Based Regularizers for Recurrent Neural Networks,"[""Adji B. Dieng"", ""Jaan Altosaar"", ""Rajesh Ranganath"", ""David M. Blei""]",[],,,,,
ryl-RTEYvB,2020,Reject,True,Robust Learning with Jacobian Regularization,"[""Judy Hoffman"", ""Daniel A. Roberts"", ""Sho Yaida""]","[""Supervised Representation Learning"", ""Few-Shot Learning"", ""Regularization"", ""Adversarial Defense"", ""Deep Learning""]",We analyze and develop a computationally efficient implementation of Jacobian regularization that increases the classification margins of neural networks.,1908.02729,stat.ML,2019-08-07 17:04:26+00:00,2019-08-07 17:04:26+00:00
ryl0cAVtPH,2020,Reject,True,On The Difficulty of Warm-Starting Neural Network Training,"[""Jordan T. Ash"", ""Ryan P. Adams""]","[""deep learning"", ""neural networks""]",We empirically study the gap in generalization between warm-started and randomly-initialized neural networks.,1910.08475,cs.LG,2019-10-18 15:35:59+00:00,2020-12-31 07:58:30+00:00
ryl1r1BYDS,2020,Reject,False,Multiagent Reinforcement Learning in Games with an Iterated Dominance Solution,"[""Yoram Bachrach"", ""Tor Lattimore"", ""Marta Garnelo"", ""Julien Perolat"", ""David Balduzzi"", ""Thomas Anthony"", ""Satinder Singh"", ""Thore Graepel""]","[""multiagent"", ""reinforcement learning"", ""iterated dominance"", ""mechanism design"", ""Nash equilibrium""]","For games that are solvable by iterated elimination of dominated strategies, we prove that simple standard reinforcement learning algorithms converge to the iterated dominance solution.",,,,
ryl3blSFPr,2020,Reject,True,Denoising Improves Latent Space Geometry in Text Autoencoders,"[""Tianxiao Shen"", ""Jonas Mueller"", ""Regina Barzilay"", ""Tommi Jaakkola""]","[""controllable text generation"", ""autoencoders"", ""denoising"", ""latent space geometry""]",,1905.12777,cs.LG,2019-05-29 23:22:56+00:00,2020-07-07 17:51:30+00:00
ryl3ygHYDB,2020,Accept (Poster),False,Lookahead: A Far-sighted Alternative of Magnitude-based Pruning,"[""Sejun Park*"", ""Jaeho Lee*"", ""Sangwoo Mo"", ""Jinwoo Shin""]","[""network magnitude-based pruning""]",We study a multi-layer generalization of the magnitude-based pruning.,,,,
ryl4-pEKvB,2020,Reject,False,DeepAGREL: Biologically plausible deep learning via direct reinforcement,"[""Isabella Pozzi"", ""Sander M. Bohte"", ""Pieter R. Roelfsema""]","[""biologically plausible deep learning"", ""reinforcement learning"", ""feedback gating"", ""image claassification""]","We show how deep learning can be implemented in the brain using direct reinforcement learning just as well as error-backprop for hard tasks, with a surprisingly small penalty to the speed of convergence",,,,
ryl5CJSFPS,2020,Reject,True,GENERALIZATION GUARANTEES FOR NEURAL NETS VIA HARNESSING THE LOW-RANKNESS OF JACOBIAN,"[""Samet Oymak"", ""Zalan Fabian"", ""Mingchen Li"", ""Mahdi Soltanolkotabi""]","[""Theory of neural nets"", ""low-rank structure of Jacobian"", ""optimization and generalization theory""]",We empirically demonstrate that the Jacobian of neural networks exhibit a low-rank structure and harness this property to develop new optimization and generalization guarantees.,1906.05392,cs.LG,2019-06-12 21:39:06+00:00,2019-07-04 00:17:07+00:00
ryl5khRcKm,2019,Accept (Poster),False,Human-level Protein Localization with Convolutional Neural Networks,"[""Elisabeth Rumetshofer"", ""Markus Hofmarcher"", ""Clemens R\u00f6hrl"", ""Sepp Hochreiter"", ""G\u00fcnter Klambauer""]","[""Convolutional Neural Networks"", ""High-resolution images"", ""Multiple-Instance Learning"", ""Microscopy Imaging"", ""Protein Localization""]",,,,,
ryl71a4YPB,2020,Reject,False,A Unified framework for randomized smoothing based certified defenses,"[""Tianhang Zheng"", ""Di Wang"", ""Baochun Li"", ""Jinhui Xu""]","[""Certificated Defense"", ""Randomized Smoothing"", ""A Unified and Self-Contained Framework""]",,2005.07347,cs.LG,2020-05-15 03:54:53+00:00,2020-06-07 18:39:33+00:00
ryl8-3AcFX,2019,Accept (Poster),False,Environment Probing Interaction Policies,"[""Wenxuan Zhou"", ""Lerrel Pinto"", ""Abhinav Gupta""]","[""Reinforcement Learning""]",,,,,
rylBK34FDS,2020,Accept (Poster),True,DeepHoyer: Learning Sparser Neural Network with Differentiable Scale-Invariant Sparsity Measures,"[""Huanrui Yang"", ""Wei Wen"", ""Hai Li""]","[""Deep neural network"", ""Sparsity inducing regularizer"", ""Model compression""]","We propose almost everywhere differentiable and scale invariant regularizers for DNN pruning, which can lead to supremum sparsity through standard SGD training.",1908.09979,cs.LG,2019-08-27 01:34:25+00:00,2020-01-19 18:04:11+00:00
rylCP6NFDB,2020,Reject,False,Hindsight Trust Region Policy Optimization,"[""Hanbo Zhang"", ""Site Bai"", ""Xuguang Lan"", ""Nanning Zheng""]","[""Hindsight"", ""Sparse Reward"", ""Reinforcement Learning"", ""Policy Gradients""]",This paper proposes an advanced policy optimization method with hindsight experience for sparse reward reinforcement learning.,,,,
rylDfnCqF7,2019,Accept (Poster),False,Lagging Inference Networks and Posterior Collapse in Variational Autoencoders,"[""Junxian He"", ""Daniel Spokoyny"", ""Graham Neubig"", ""Taylor Berg-Kirkpatrick""]","[""variational autoencoders"", ""posterior collapse"", ""generative models""]","To address posterior collapse in VAEs, we propose a novel yet simple training procedure that aggressively optimizes inference network with more updates. This new training procedure mitigates posterior collapse and leads to a better VAE model. ",1901.05534,cs.LG,2019-01-16 21:32:33+00:00,2019-01-28 19:16:09+00:00
rylDzTEKwr,2020,Reject,False,Variational Hashing-based Collaborative Filtering with Self-Masking,"[""Casper Hansen"", ""Christian Hansen"", ""Jakob Grue Simonsen"", ""Stephen Alstrup"", ""Christina Lioma""]","[""hashing"", ""collaborative filtering"", ""information retrieval"", ""supervised learning""]","We propose a new variational hashing-based collaborative filtering approach optimized for a novel self-mask variant of the Hamming distance, which outperforms state-of-the-art by up to 12% on NDCG.",,,,
rylHspEKPr,2020,Accept (Poster),False,Learning to Represent Programs with Property Signatures,"[""Augustus Odena"", ""Charles Sutton""]","[""Program Synthesis""]",We represent a computer program using a set of simpler programs and use this representation to improve program synthesis techniques.,2002.09030,cs.PL,2020-02-13 01:50:11+00:00,2020-02-13 01:50:11+00:00
rylIAsCqYm,2019,Accept (Poster),False,A2BCD: Asynchronous Acceleration with Optimal Complexity,"[""Robert Hannah"", ""Fei Feng"", ""Wotao Yin""]","[""asynchronous"", ""optimization"", ""parallel"", ""accelerated"", ""complexity""]",We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.,,,,
rylIy3R9K7,2019,Reject,False,Understand the dynamics of GANs via Primal-Dual Optimization,"[""Songtao Lu"", ""Rahul Singh"", ""Xiangyi Chen"", ""Yongxin Chen"", ""Mingyi Hong""]","[""non-convex optimization"", ""generative adversarial network"", ""primal dual algorithm""]","We show that, with a proper stepsize choice, the widely used first-order iterative algorithm in training GANs would in fact converge to a stationary solution with a sublinear rate.",,,,
rylJkpEtwS,2020,Accept (Poster),False,Learning the Arrow of Time for Problems in Reinforcement Learning,"[""Nasim Rahaman"", ""Steffen Wolf"", ""Anirudh Goyal"", ""Roman Remme"", ""Yoshua Bengio""]","[""Arrow of Time"", ""Reinforcement Learning"", ""AI-Safety""]","We learn the arrow of time for MDPs and use it to measure reachability, detect side-effects and obtain a curiosity reward signal. ",,,,
rylKB3A9Fm,2019,Reject,False,Assessing Generalization in Deep Reinforcement Learning,"[""Charles Packer*"", ""Katelyn Gao*"", ""Jernej Kos"", ""Philipp Krahenbuhl"", ""Vladlen Koltun"", ""Dawn Song""]","[""reinforcement learning"", ""generalization"", ""benchmark""]","We provide the first benchmark and common experimental protocol for investigating generalization in RL, and conduct a systematic evaluation of state-of-the-art deep RL algorithms.",,,,
rylMgCNYvS,2020,Reject,False,On the Linguistic Capacity of Real-time Counter Automata,"[""William Merrill""]","[""formal language theory"", ""counter automata"", ""natural language processing"", ""deep learning""]","We study the class of formal languages acceptable by real-time counter automata, a model of computation related to some types of recurrent neural networks.",2004.06866,cs.CL,2020-04-15 03:37:47+00:00,2021-09-09 05:24:50+00:00
rylNH20qFQ,2019,Accept (Poster),False,Learning to Infer and Execute 3D Shape Programs,"[""Yonglong Tian"", ""Andrew Luo"", ""Xingyuan Sun"", ""Kevin Ellis"", ""William T. Freeman"", ""Joshua B. Tenenbaum"", ""Jiajun Wu""]","[""Program Synthesis"", ""3D Shape Modeling"", ""Self-supervised Learning""]","We propose 3D shape programs, a structured, compositional shape representation. Our model learns to infer and execute shape programs to explain 3D shapes.",,,,
rylNJlStwB,2020,Reject,False,Learning to Infer User Interface Attributes from Images,"[""Philippe Schlattner"", ""Pavol Bielik"", ""Martin Vechev""]",[],,1912.13243,cs.CV,2019-12-31 09:45:59+00:00,2019-12-31 09:45:59+00:00
rylSzl-R-,2018,Accept (Poster),False,On Unifying Deep Generative Models,"[""Zhiting Hu"", ""Zichao Yang"", ""Ruslan Salakhutdinov"", ""Eric P. Xing""]","[""deep generative models"", ""generative adversarial networks"", ""variational autoencoders"", ""variational inference""]",A unified statistical view of the broad class of deep generative models ,,,,
rylT0AVtwH,2020,Reject,False,Learning from Partially-Observed Multimodal Data with Variational Autoencoders,"[""Yu Gong"", ""Hossein Hajimirsadeghi"", ""Jiawei He"", ""Megha Nawhal"", ""Thibaut Durand"", ""Greg Mori""]","[""data imputation"", ""variational autoencoders"", ""generative models""]",We propose a novel VAE-based framework learning from partially-observed data for imputation and generation. ,,,,
rylUOn4Yvr,2020,Reject,False,ROBUST DISCRIMINATIVE REPRESENTATION LEARNING VIA GRADIENT RESCALING: AN EMPHASIS REGULARISATION PERSPECTIVE,"[""Xinshao Wang"", ""Yang Hua"", ""Elyor Kodirov"", ""Neil M. Robertson""]","[""examples weighting"", ""emphasis regularisation"", ""gradient scaling"", ""abnormal training examples""]",ROBUST DISCRIMINATIVE REPRESENTATION LEARNING VIA GRADIENT RESCALING: AN EMPHASIS REGULARISATION PERSPECTIVE,,,,
rylV-2C9KQ,2019,Accept (Poster),False,Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks,"[""Reinhard Heckel"", ""Paul Hand""]","[""natural image model"", ""image prior"", ""under-determined neural networks"", ""untrained network"", ""non-convolutional network"", ""denoising"", ""inverse problem""]","We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.",,,,
rylV6i09tX,2019,Reject,False,Interpreting Adversarial Robustness: A View from Decision Surface in Input Space,"[""Fuxun Yu"", ""Chenchen Liu"", ""Yanzhi Wang"", ""Xiang Chen""]","[""Adversarial examples"", ""Robustness""]",,,,,
rylVHR4FPB,2020,Accept (Poster),False,Sampling-Free Learning of Bayesian Quantized Neural Networks,"[""Jiahao Su"", ""Milan Cvitkovic"", ""Furong Huang""]","[""Bayesian neural networks"", ""Quantized neural networks""]","We propose Bayesian quantized networks, for which we learn a posterior distribution over their quantized parameters.",1912.02992,cs.LG,2019-12-06 06:27:06+00:00,2019-12-06 06:27:06+00:00
rylVTTVtvH,2020,Reject,True,Tensor Graph Convolutional Networks for Prediction on Dynamic Graphs,"[""Osman Asif Malik"", ""Shashanka Ubaru"", ""Lior Horesh"", ""Misha E. Kilmer"", ""Haim Avron""]","[""graph convolutional networks"", ""graph learning"", ""dynamic graphs"", ""edge classification"", ""tensors""]",We propose a novel tensor based method for graph convolutional networks on dynamic graphs,1910.07643,cs.LG,2019-10-16 23:06:34+00:00,2021-01-23 02:46:40+00:00
rylWVnR5YQ,2019,Reject,False,Context Dependent Modulation of Activation Function,"[""Long Sha"", ""Jonathan Schwarcz"", ""Pengyu Hong""]","[""Artificial Neural Network"", ""Convolution Neural Network"", ""Long Short-Term Memory"", ""Activation Function"", ""Neuromodulation""]",We propose a modification to traditional Artificial Neural Networks motivated by the biology of neurons to enable the shape of the activation function to be context dependent.,,,,
rylXBkrYDS,2020,Accept (Poster),False,A Baseline for Few-Shot Image Classification,"[""Guneet Singh Dhillon"", ""Pratik Chaudhari"", ""Avinash Ravichandran"", ""Stefano Soatto""]","[""few-shot learning"", ""transductive learning"", ""fine-tuning"", ""baseline"", ""meta-learning""]",Transductive fine-tuning of a deep network is a strong baseline for few-shot image classification and outperforms the state-of-the-art on all standard benchmarks.,,,,
rylZKTNYPr,2020,Reject,False,Inferring Dynamical Systems with Long-Range Dependencies through Line Attractor Regularization,"[""Dominik Schmidt"", ""Georgia Koppe"", ""Max Beutelspacher"", ""Daniel Durstewitz""]","[""Recurrent Neural Networks"", ""Nonlinear State Space Models"", ""Generative Models"", ""Long short-term memory"", ""vanishing/exploding gradient problem"", ""Nonlinear dynamics"", ""Interpretable machine learning"", ""Time series analysis""]",We develop a new optimization approach for vanilla ReLU-based RNN that enables long short-term memory and identification of arbitrary nonlinear dynamical systems with widely differing time scales.,,,,
rylb3eBtwr,2020,Accept (Poster),True,Robust Subspace Recovery Layer for Unsupervised Anomaly Detection,"[""Chieh-Hsin Lai"", ""Dongmian Zou"", ""Gilad Lerman""]","[""robust subspace recovery"", ""unsupervised anomaly detection"", ""outliers"", ""latent space"", ""autoencoder""]",This work proposes an autoencoder with a novel robust subspace recovery layer for unsupervised anomaly detection and demonstrates state-of-the-art results on various datasets.,1904.00152,cs.LG,2019-03-30 05:30:54+00:00,2019-12-24 22:44:25+00:00
rylbWhC5Ym,2019,Reject,False,HR-TD: A Regularized TD Method to Avoid Over-Generalization,"[""Ishan Durugkar"", ""Bo Liu"", ""Peter Stone""]","[""Reinforcement Learning"", ""TD Learning"", ""Deep Learning""]","A regularization technique for TD learning that avoids temporal over-generalization, especially in Deep Networks",,,,
rylejExC-,2018,Reject,False,Stochastic Training of Graph Convolutional Networks,"[""Jianfei Chen"", ""Jun Zhu""]","[""Graph convolutional networks"", ""stochastic gradient descent"", ""variance reduction"", ""control variate""]",A control variate based stochastic training algorithm for graph convolutional networks that the receptive field can be only two neighbors per node.,,,,
rylfl6VFDH,2020,Reject,True,Adaptive network sparsification with dependent variational beta-Bernoulli dropout,"[""Juho Lee"", ""Saehoon Kim"", ""Jaehong Yoon"", ""Hae Beom Lee"", ""Eunho Yang"", ""Sung Ju Hwang""]","[""network sparsification"", ""variational inference"", ""pruning""]",,1805.10896,stat.ML,2018-05-28 12:50:02+00:00,2019-03-04 03:27:59+00:00
rylhToC5YQ,2019,Reject,False,Unsupervised Neural Multi-Document Abstractive Summarization of Reviews,"[""Eric Chu"", ""Peter J. Liu""]","[""unsupervised learning"", ""abstractive summarization"", ""reviews"", ""text generation""]","We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.",,,,
ryljMpNtwr,2020,Reject,True,Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming,"[""Claudio Michaelis"", ""Benjamin Mitzkus"", ""Robert Geirhos"", ""Evgenia Rusak"", ""Oliver Bringmann"", ""Alexander S. Ecker"", ""Matthias Bethge"", ""Wieland Brendel""]","[""deep learning"", ""object detection"", ""robustness"", ""neural networks"", ""data augmentation"", ""autonomous driving""]","A benchmark to asses the robustness of object detection models towards common image corruptions. Like classification models, object detection models perform worse on corrupted images. Training with stylized data reduces the gap for all corruptions.",1907.07484,cs.CV,2019-07-17 12:51:10+00:00,2020-03-31 08:42:46+00:00
ryljV2A5KX,2019,Reject,False,IB-GAN: Disentangled Representation Learning with Information Bottleneck GAN,"[""Insu Jeon"", ""Wonkwang Lee"", ""Gunhee Kim""]","[""Unsupervised disentangled representation learning"", ""GAN"", ""Information Bottleneck"", ""Variational Inference""]","Inspired by Information Bottleneck theory,  we propose a new architecture of GAN for a disentangled representation learning",,,,
rylkma4twr,2020,Reject,False,Min-Max Optimization without Gradients: Convergence and Applications to Adversarial ML,"[""Sijia Liu"", ""Songtao Lu"", ""Xiangyi Chen"", ""Yao Feng"", ""Kaidi Xu"", ""Abdullah Al-Dujaili"", ""Minyi Hong"", ""Una-May Obelilly""]","[""nonconvex optimization"", ""min-max optimization"", ""robust optimization"", ""adversarial attack""]",Towards principled and efficient black-box min-max optimization with applications to design of evasion and poisoning adversarial attacks,,,,
rylmoxrFDH,2020,Accept (Poster),False,Critical initialisation in continuous approximations of binary neural networks,"[""George Stamatescu"", ""Federica Gerace"", ""Carlo Lucibello"", ""Ian Fuss"", ""Langford White""]",[],signal propagation theory applied to continuous surrogates of binary nets;  counter intuitive initialisation; reparameterisation trick not helpful,,,,
rylnK6VtDH,2020,Accept (Poster),False,Multiplicative Interactions and Where to Find Them,"[""Siddhant M. Jayakumar"", ""Wojciech M. Czarnecki"", ""Jacob Menick"", ""Jonathan Schwarz"", ""Jack Rae"", ""Simon Osindero"", ""Yee Whye Teh"", ""Tim Harley"", ""Razvan Pascanu""]","[""multiplicative interactions"", ""hypernetworks"", ""attention""]","We explore the role of multiplicative interaction as a unifying framework to describe a range of classical and modern neural network architectural motifs, such as gating, attention layers, hypernetworks, and dynamic convolutions amongst others.",,,,
ryloogSKDS,2020,Accept (Poster),False,Deep Orientation Uncertainty Learning based on a Bingham Loss,"[""Igor Gilitschenski"", ""Roshni Sahoo"", ""Wilko Schwarting"", ""Alexander Amini"", ""Sertac Karaman"", ""Daniela Rus""]","[""Orientation Estimation"", ""Directional Statistics"", ""Bingham Distribution""]",A method for learning to predict uncertainties over orientations using the Bingham Distribution,,,,
rylqmxBKvH,2020,Reject,False,Unsupervised Spatiotemporal Data Inpainting,"[""Yuan Yin"", ""Arthur Pajot"", ""Emmanuel de B\u00e9zenac"", ""Patrick Gallinari""]","[""Deep Learning"", ""Adversarial"", ""MAP"", ""GAN"", ""neural networks"", ""video""]",,,,,
rylqooRqK7,2019,Accept (Poster),False,SNAS: stochastic neural architecture search,"[""Sirui Xie"", ""Hehui Zheng"", ""Chunxiao Liu"", ""Liang Lin""]","[""Neural Architecture Search""]",,,,,
rylrI1HtPr,2020,Reject,False,Pixel Co-Occurence Based Loss Metrics for Super Resolution Texture Recovery,"[""Ying Da Wang"", ""Pawel Swietojanski"", ""Ryan T Armstrong"", ""Peyman Mostaghimi""]","[""Super Resolution Generative Adversarial Networks"", ""Perceptual Loss Functions""]",We introduce an unbiased perceptual loss function and metric and show that it improves recovery of texture during super resolution,,,,
rylrdxHFDr,2020,Accept (Poster),False,State Alignment-based Imitation Learning,"[""Fangchen Liu"", ""Zhan Ling"", ""Tongzhou Mu"", ""Hao Su""]","[""Imitation learning"", ""Reinforcement Learning""]",,1911.10947,cs.LG,2019-11-21 22:18:16+00:00,2019-11-21 22:18:16+00:00
rylvAA4YDB,2020,Reject,True,IsoNN: Isomorphic Neural Network for Graph Representation Learning and Classification,"[""Lin Meng"", ""Jiawei Zhang""]","[""Deep Learning"", ""Graph Neural Network""]",,1907.09495,cs.LG,2019-07-22 18:01:04+00:00,2019-09-28 03:55:50+00:00
rylvYaNYDH,2020,Accept (Poster),True,Finding and Visualizing Weaknesses of Deep Reinforcement Learning Agents,"[""Christian Rupprecht"", ""Cyril Ibrahim"", ""Christopher J. Pal""]","[""Visualization"", ""Reinforcement Learning"", ""Safety""]",We generate critical states of a trained RL algorithms to visualize potential weaknesses. ,1904.01318,cs.CV,2019-04-02 10:21:23+00:00,2019-04-02 10:21:23+00:00
rylwJxrYDS,2020,Accept (Poster),True,vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations,"[""Alexei Baevski"", ""Steffen Schneider"", ""Michael Auli""]","[""speech recognition"", ""speech representation learning""]",Learn how to quantize speech signal and apply algorithms requiring discrete inputs to audio data such as BERT.,1910.05453,cs.CL,2019-10-12 00:55:06+00:00,2020-02-16 18:35:27+00:00
rylxpA4YwH,2020,Reject,False,On the Evaluation of Conditional GANs,"[""Terrance DeVries"", ""Adriana Romero"", ""Luis Pineda"", ""Graham W. Taylor"", ""Michal Drozdzal""]","[""FJD"", ""Frechet Joint Distance"", ""GAN"", ""cGAN"", ""generative adversarial network"", ""conditional"", ""evaluation"", ""metric"", ""FID"", ""Frechet Inception Distance""]","We propose a new metric for evaluating conditional GANs that captures image quality, conditional consistency, and intra-conditioning diversity in a single measure.",,,,
rylxxhRctX,2019,Reject,False,Coverage and Quality Driven Training of Generative Image Models,"[""Thomas LUCAS"", ""Konstantin SHMELKOV"", ""Karteek ALAHARI"", ""Cordelia SCHMID"", ""Jakob VERBEEK""]","[""deep learning"", ""generative modeling"", ""unsupervised learning"", ""maximum likelihood"", ""adversarial learning"", ""gan"", ""vae""]",Generative models that yield Gan-like samples and achieve competitive likelihood on held-out data. ,,,,
rylztAEYvr,2020,Reject,False,Iterative Target Augmentation for Effective Conditional Generation,"[""Kevin Yang"", ""Wengong Jin"", ""Kyle Swanson"", ""Regina Barzilay"", ""Tommi Jaakkola""]","[""data augmentation"", ""generative models"", ""self-training"", ""molecular optimization"", ""program synthesis""]",We improve generative models by proposing a meta-algorithm that filters new training data from the model's outputs.,2002.04720,cs.LG,2020-02-11 22:40:04+00:00,2021-08-15 18:40:15+00:00
rypT3fb0b,2018,Accept (Poster),False,LEARNING TO SHARE: SIMULTANEOUS PARAMETER TYING AND SPARSIFICATION IN DEEP LEARNING,"[""Dejiao Zhang"", ""Haozhu Wang"", ""Mario Figueiredo"", ""Laura Balzano""]","[""Compressing neural network"", ""simultaneously parameter tying and sparsification"", ""group ordered l1 regularization""]",We have proposed using the recent GrOWL regularizer for simultaneous parameter sparsity and tying in DNN learning. ,,,,
ryrGawqex,2017,Accept (Poster),False,Deep Learning with Dynamic Computation Graphs,"[""Moshe Looks"", ""Marcello Herreshoff"", ""DeLesley Hutchins"", ""Peter Norvig""]","[""Deep learning""]",We make batching effective and easy to use for neural nets where every input may have a different shape (e.g. TreeRNNs).,,,,
ryserbZR-,2018,Reject,False,Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach,"[""Pierre Courtiol"", ""Eric W. Tramel"", ""Marc Sanselme"", ""Gilles Wainrib""]","[""Weakly Supervised Learning"", ""Medical Imaging"", ""Histopathology"", ""Deep Feature Extraction""]",We propose a weakly supervised learning method for the classification and localization of cancers in extremely high resolution histopathology whole slide images using only image-wide labels.,,,,
rytNfI1AZ,2018,Accept (Poster),False,Training wide residual networks for deployment using a single bit for each weight,"[""Mark D. McDonnell""]","[""wide residual networks"", ""model compression"", ""quantization"", ""1-bit weights""]","We train wide residual networks that can be immediately deployed using only a single bit for each convolutional weight, with signficantly better accuracy than past methods.",,,,
rytstxWAW,2018,Accept (Poster),False,FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling,"[""Jie Chen"", ""Tengfei Ma"", ""Cao Xiao""]","[""Graph convolutional networks"", ""importance sampling""]",,,,,
ryup8-WCW,2018,Accept (Poster),False,Measuring the Intrinsic Dimension of Objective Landscapes,"[""Chunyuan Li"", ""Heerad Farkhoor"", ""Rosanne Liu"", ""Jason Yosinski""]","[""machine learning"", ""neural networks"", ""intrinsic dimension"", ""random subspace"", ""model understanding""]",We train in random subspaces of parameter space to measure how many dimensions are really needed to find a solution.,,,,
ryuxYmvel,2017,Accept (Poster),False,HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving,"[""Cezary Kaliszyk"", ""Fran\u00e7ois Chollet"", ""Christian Szegedy""]",[],,,,,
ryvxcPeAb,2018,Reject,False,Enhancing the Transferability of Adversarial Examples with Noise Reduced Gradient,"[""Lei Wu"", ""Zhanxing Zhu"", ""Cheng Tai"", ""Weinan E""]","[""black-box attack"", ""adversarial example"", ""deep learning"", ""transferability""]",We propose a new method for enhancing the transferability of adversarial examples by using the noise-reduced gradient.,,,,
rywDjg-RW,2018,Accept (Poster),False,Neural-Guided Deductive Search for Real-Time Program Synthesis from Examples,"[""Ashwin Kalyan"", ""Abhishek Mohta"", ""Oleksandr Polozov"", ""Dhruv Batra"", ""Prateek Jain"", ""Sumit Gulwani""]","[""Program synthesis"", ""deductive search"", ""deep learning"", ""program induction"", ""recurrent neural networks""]",We integrate symbolic (deductive) and statistical (neural-based) methods to enable real-time program synthesis with almost perfect generalization from 1 input-output example.,,,,
rywHCPkAW,2018,Accept (Poster),False,Noisy Networks For Exploration,"[""Meire Fortunato"", ""Mohammad Gheshlaghi Azar"", ""Bilal Piot"", ""Jacob Menick"", ""Matteo Hessel"", ""Ian Osband"", ""Alex Graves"", ""Volodymyr Mnih"", ""Remi Munos"", ""Demis Hassabis"", ""Olivier Pietquin"", ""Charles Blundell"", ""Shane Legg""]","[""Deep Reinforcement Learning"", ""Exploration"", ""Neural Networks""]",A deep reinforcement learning agent with parametric noise added to its weights can be used to aid efficient exploration.,,,,
rywUcQogx,2017,Reject,False,Differentiable Canonical Correlation Analysis,"[""Matthias Dorfer"", ""Jan Schl\u00fcter"", ""Gerhard Widmer""]","[""Multi-modal learning""]",We propose Differentiable CCA a  formulation of CCA that enables gradient flow through the  computation of the CCA projection matrices.,,,,
ryx0nnEKwH,2020,Reject,False,Improving Batch Normalization with Skewness Reduction for Deep Neural Networks,"[""Pak Lun Kevin Ding"", ""Sarah Martin"", ""Baoxin Li""]","[""Batch Normalization"", ""Deep Learning""]",Reduce Skewness,,,,
ryx1wRNFvB,2020,Accept (Poster),False,Improved memory in recurrent neural networks with sequential non-normal dynamics,"[""Emin Orhan"", ""Xaq Pitkow""]","[""recurrent neural networks"", ""memory"", ""non-normal dynamics""]","a feedforward, chain-like motif (1->2->3->...) is proposed as a useful inductive bias for better memory in RNNs.",,,,
ryx2wp4tvS,2020,Reject,False,MLModelScope: A Distributed Platform for ML Model Evaluation and Benchmarking at Scale,"[""Cheng Li"", ""Abdul Dakkak"", ""Jinjun Xiong"", ""Wen-mei Hwu""]","[""Evaluation"", ""Scalable"", ""Repeatable"", ""Fair"", ""System""]",MLModelScope is a platform that allows for repeatable and fair ML model evaluation at scale.,,,,
ryx3_iAcY7,2019,Reject,False,Contextualized Role Interaction for Neural Machine Translation,"[""Dirk Weissenborn"", ""Douwe Kiela"", ""Jason Weston"", ""Kyunghyun Cho""]","[""Neural Machine Translation"", ""Natural Language Processing""]",We propose a role interaction layer that explicitly models the modulation of token representations by contextualized roles.,,,,
ryx4PJrtvS,2020,Reject,True,A Copula approach for hyperparameter transfer learning,"[""David Salinas"", ""Huibin Shen"", ""Valerio Perrone""]","[""Hyperparameter optimization"", ""Bayesian Optimization"", ""Gaussian Process"", ""Copula"", ""Transfer-learning""]",We show how using semi-parametric prior estimations can speed up HPO significantly across datasets and metrics.,1909.13595,stat.ML,2019-09-30 11:28:09+00:00,2021-04-19 11:43:02+00:00
ryx4TlHKDS,2020,Reject,False,EXACT ANALYSIS OF CURVATURE CORRECTED LEARNING DYNAMICS IN DEEP LINEAR NETWORKS,"[""Dongsung Huh""]",[],,,,,
ryx6WgStPB,2020,Accept (Poster),False,Hypermodels for Exploration,"[""Vikranth Dwaracherla"", ""Xiuyuan Lu"", ""Morteza Ibrahimi"", ""Ian Osband"", ""Zheng Wen"", ""Benjamin Van Roy""]","[""exploration"", ""hypermodel"", ""reinforcement learning""]",Hypermodels can encode posterior distributions similar to large ensembles at much smaller computational cost. This can facilitate significant improvements in exploration.,2006.07464,cs.LG,2020-06-12 20:59:21+00:00,2020-06-12 20:59:21+00:00
ryx6daEtwr,2020,Reject,False,GPNET: MONOCULAR 3D VEHICLE DETECTION BASED ON LIGHTWEIGHT WHEEL GROUNDING POINT DETECTION NETWORK,"[""zizhang.wu""]","[""applications in vision"", ""audio"", ""speech"", ""natural language processing"", ""robotics""]",Method for detecting vehicle 3D information based on fisheye camera with high efficiency,,,,
ryxAY34YwB,2020,Reject,False,Make Lead Bias in Your Favor: A Simple and Effective Method for News Summarization,"[""Chenguang Zhu"", ""Ziyi Yang"", ""Robert Gmyr"", ""Michael Zeng"", ""Xuedong Huang""]","[""Summarization"", ""Pretraining""]",A method to leverage lead bias in large-scale pretraining for abstractive news summarization,,,,
ryxB0Rtxx,2017,Accept (Poster),False,Identity Matters in Deep Learning,"[""Moritz Hardt"", ""Tengyu Ma""]",[],Emerging theory explaining residual networks alongside new empirical progress,,,,
ryxB2lBtvH,2020,Accept (Poster),False,Learning to Coordinate Manipulation Skills via Skill Behavior Diversification,"[""Youngwoon Lee"", ""Jingyun Yang"", ""Joseph J. Lim""]","[""reinforcement learning"", ""hierarchical reinforcement learning"", ""modular framework"", ""skill coordination"", ""bimanual manipulation""]",We propose to tackle complex tasks of multiple agents by learning composable primitive skills and coordination of the skills. ,,,,
ryxC-kBYDS,2020,Reject,False,Gaussian Conditional Random Fields for Classification,"[""Andrija Petrovic"", ""Mladen Nikolic"", ""Milos Jovanovic"", ""Boris Delibasic""]","[""Structured classification"", ""Gaussian conditional random fields"", ""Empirical Bayes"", ""Local variational approximation"", ""discriminative graph-based model""]",,,,,
ryxC6kSYPr,2020,Accept (Poster),False,Infinite-Horizon Differentiable Model Predictive Control,"[""Sebastian East"", ""Marco Gallieri"", ""Jonathan Masci"", ""Jan Koutnik"", ""Mark Cannon""]","[""Model Predictive Control"", ""Riccati Equation"", ""Imitation Learning"", ""Safe Learning""]",,2001.02244,math.OC,2020-01-07 19:00:39+00:00,2020-01-07 19:00:39+00:00
ryxDUs05KQ,2019,Reject,False,Difference-Seeking Generative Adversarial Network,"[""Yi-Lin Sung"", ""Sung-Hsien Hsieh"", ""Soo-Chang Pei"", ""Chun-Shien Lu""]","[""Generative Adversarial Network"", ""Semi-Supervised Learning"", ""Adversarial Training""]","We proposed ""Difference-Seeking Generative Adversarial Network"" (DSGAN) model to learn the target distribution which is hard to collect training data.",,,,
ryxDjjCqtQ,2019,Reject,False,Deconfounding Reinforcement Learning in Observational Settings,"[""Chaochao Lu"", ""Jos\u00e9 Miguel Hern\u00e1ndez Lobato""]","[""confounder"", ""causal inference"", ""reinforcement learning""]",This is the first attempt to build a bridge between confounding and the full reinforcement learning problem.,,,,
ryxF80NYwS,2020,Reject,False,Neural Clustering Processes,"[""Ari Pakman"", ""Yueqi Wang"", ""Catalin Mitelut"", ""JinHyung Lee"", ""Liam Paninski""]","[""amortized inference"", ""probabilistic clustering"", ""mixture models"", ""exchangeability"", ""spike sorting""]",A novel neural architecture for efficient amortized inference over discrete variables in mixture models. An application is presented to neural spike sorting.,,,,
ryxGuJrFvS,2020,Accept (Poster),False,Distributionally Robust Neural Networks,"[""Shiori Sagawa*"", ""Pang Wei Koh*"", ""Tatsunori B. Hashimoto"", ""Percy Liang""]","[""distributionally robust optimization"", ""deep learning"", ""robustness"", ""generalization"", ""regularization""]","Overparameterized neural networks can be distributionally robust, but only when you account for generalization. ",,,,
ryxHii09KQ,2019,Reject,False,In Your Pace: Learning the Right Example at the Right Time,"[""Guy Hacohen"", ""Daphna Weinshall""]","[""Curriculum Learning"", ""Transfer Learning"", ""Self-Paced Learning"", ""Image Recognition""]","We provide a formal definition of curriculum learning for deep neural networks, empirically showing how it can improve learning performance without additional human supervision and in a problem-free manner.",,,,
ryxIZR4tvS,2020,Reject,True,Knowledge Hypergraphs: Prediction Beyond Binary Relations,"[""Bahare Fatemi"", ""Perouz Taslakian"", ""David Vazquez"", ""David Poole""]","[""knowledge graphs"", ""knowledge hypergraphs"", ""knowledge hypergraph completion""]",,1906.00137,cs.LG,2019-06-01 03:03:15+00:00,2020-07-15 13:39:31+00:00
ryxK0JBtPr,2020,Accept (Poster),False,Gradient $\ell_1$ Regularization for Quantization Robustness,"[""Milad Alizadeh"", ""Arash Behboodi"", ""Mart van Baalen"", ""Christos Louizos"", ""Tijmen Blankevoort"", ""Max Welling""]","[""quantization"", ""regularization"", ""robustness"", ""gradient regularization""]",We show that regularizing the $\ell_1$-norm of gradients improves robustness to post-training quantization in neural networks.,2002.07520,cs.LG,2020-02-18 12:31:34+00:00,2020-02-18 12:31:34+00:00
ryxLG2RcYX,2019,Reject,False,Learning Abstract Models for Long-Horizon Exploration,"[""Evan Zheran Liu"", ""Ramtin Keramati"", ""Sudarshan Seshadri"", ""Kelvin Guu"", ""Panupong Pasupat"", ""Emma Brunskill"", ""Percy Liang""]","[""Reinforcement Learning"", ""Hierarchical Reinforcement Learning"", ""Model-based Reinforcement Learning"", ""Exploration""]","We automatically construct and explore a small abstract Markov Decision Process, enabling us to achieve state-of-the-art results on Montezuma's Revenge, Pitfall!, and Private Eye by a significant margin.",,,,
ryxMW6EtPB,2020,Reject,False,DG-GAN: the GAN with the duality gap,"[""Cheng Peng"", ""Hao Wang"", ""Xiao Wang"", ""Zhouwang Yang""]","[""GAN"", ""duality gap"", ""metric"", ""saddle point"", ""game""]",,,,,
ryxMX2R9YQ,2019,Reject,False,CGNF: Conditional Graph Neural Fields,"[""Tengfei Ma"", ""Cao Xiao"", ""Junyuan Shang"", ""Jimeng Sun""]","[""graph neural networks"", ""energy models"", ""conditional random fields"", ""label correlation""]",,,,,
ryxOBgBFPH,2020,Reject,False,Preventing Imitation Learning with Adversarial Policy Ensembles,"[""Albert Zhan"", ""Pieter Abbeel"", ""Stas Tiomkin""]","[""Imitation Learning"", ""Reinforcement Learning"", ""Representation Learning""]",We propose a framework to study policy ensembles that cannot be cloned.,,,,
ryxOIsA5FQ,2019,Reject,False,Stacking for Transfer Learning,"[""Peng Yuankai""]","[""data diversi\ufb01cation"", ""domain adaptation"", ""transfer learning"", ""stacked generalization""]",How to use stacked generalization to improve the performance of existing transfer learning algorithms when limited labeled data is available.,,,,
ryxOUTVYDH,2020,Accept (Poster),True,Robust training with ensemble consensus,"[""Jisoo Lee"", ""Sae-Young Chung""]","[""Annotation noise"", ""Noisy label"", ""Robustness"", ""Ensemble"", ""Perturbation""]",This work presents a method to robustly train neural networks by using ensemble in the presence of label noise.,1910.09792,cs.LG,2019-10-22 06:58:10+00:00,2020-11-11 09:59:16+00:00
ryxPRpEtvH,2020,Reject,False,Omnibus Dropout for Improving The Probabilistic Classification Outputs of ConvNets,"[""Zhilu Zhang"", ""Adrian V. Dalca"", ""Mert R. Sabuncu""]","[""Uncertainty Estimation"", ""Calibration"", ""Deep Learning""]",We propose to combine structured dropout methods at different scales for improved model diversity and performance of dropout uncertainty estimates.,,,,
ryxPbkrtvr,2020,Reject,True,BOSH: An Efficient Meta Algorithm for Decision-based Attacks,"[""Zhenxin Xiao"", ""Puyudi Yang"", ""Yuchen Jiang"", ""Kai-Wei Chang"", ""Cho-Jui Hsieh""]",[],,1909.04288,cs.LG,2019-09-10 05:00:06+00:00,2019-10-14 14:14:57+00:00
ryxQ6T4YwB,2020,Reject,False,GraphNVP: an Invertible Flow-based Model for Generating Molecular Graphs,"[""Kaushalya Madhawa"", ""Katsuhiko Ishiguro"", ""Kosuke Nakago"", ""Motoki Abe""]","[""Graph Neural Networks"", ""graph generative model"", ""invertible flow"", ""graphNVP""]",The first fully invertible flow-based generative model for molecular graphs is proposed. ,,,,
ryxQuANKPB,2020,Accept (Poster),True,Augmenting Non-Collaborative Dialog Systems with Explicit Semantic and Strategic Dialog History,"[""Yiheng Zhou"", ""Yulia Tsvetkov"", ""Alan W Black"", ""Zhou Yu""]","[""dialog systems"", ""history tracking""]",,1909.13425,cs.CL,2019-09-30 02:08:47+00:00,2019-09-30 02:08:47+00:00
ryxSrhC9KX,2019,Accept (Poster),False,Revealing interpretable object representations from human behavior,"[""Charles Y. Zheng"", ""Francisco Pereira"", ""Chris I. Baker"", ""Martin N. Hebart""]","[""category representation"", ""sparse coding"", ""representation learning"", ""interpretable representations""]",Human behavioral judgments are used to obtain sparse and interpretable representations of objects that generalize to other tasks,,,,
ryxUMREYPr,2020,Reject,False,Is There Mode Collapse? A Case Study on Face Generation and Its Black-box Calibration,"[""Zhenyu Wu"", ""Ye Yuan"", ""Zhaowen Wang"", ""Jianming Zhang"", ""Zhangyang Wang"", ""Hailin Jin""]","[""Generative Adversarial Networks"", ""Mode Collapse"", ""Calibration""]",,,,,
ryxUkTVYvH,2020,Reject,False,Towards Controllable and Interpretable Face Completion via  Structure-Aware and Frequency-Oriented Attentive GANs,"[""Zeyuan Chen"", ""Shaoliang Nie"", ""Tianfu Wu"", ""Christopher G. Healey""]","[""Face Completion"", ""GANs"", ""Conditional Image Synthesis"", ""Interpretability"", ""Frequency-Oriented Attention""]",Structure-aware and frequency-oriented attentive GANs for high-resolution and fast face completion,,,,
ryxW804FPH,2020,Reject,False,ADAPTING PRETRAINED LANGUAGE MODELS FOR LONG DOCUMENT CLASSIFICATION,"[""Matthew Lyle Olson"", ""Lisa Zhang"", ""Chun-Nam Yu""]","[""NLP"", ""Deep Learning"", ""Language Models"", ""Long Document""]",We acheive state of the art results on long document classication by combining pretrained language models representations with attention.,,,,
ryxWIgBFPS,2020,Accept (Poster),False,A Meta-Transfer Objective for Learning to Disentangle Causal Mechanisms,"[""Yoshua Bengio"", ""Tristan Deleu"", ""Nasim Rahaman"", ""Nan Rosemary Ke"", ""Sebastien Lachapelle"", ""Olexa Bilaniuk"", ""Anirudh Goyal"", ""Christopher Pal""]","[""meta-learning"", ""transfer learning"", ""structure learning"", ""modularity"", ""causality""]",This paper proposes a meta-learning objective based on speed of adaptation to transfer distributions to discover a modular decomposition and causal variables.,,,,
ryxY73AcK7,2019,Reject,False,Sorting out Lipschitz function approximation,"[""Cem Anil"", ""James Lucas"", ""Roger B. Grosse""]","[""deep learning"", ""lipschitz neural networks"", ""generalization"", ""universal approximation"", ""adversarial examples"", ""generative models"", ""optimal transport"", ""adversarial robustness""]",We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.,,,,
ryxaSsActQ,2019,Reject,False,Dual Skew Divergence Loss for Neural Machine Translation,"[""Yingting Wu"", ""Hai Zhao"", ""Rui Wang""]",[],,,,,
ryxdEkHtPS,2020,Accept (Talk),True,A Closer Look at Deep Policy Gradients,"[""Andrew Ilyas"", ""Logan Engstrom"", ""Shibani Santurkar"", ""Dimitris Tsipras"", ""Firdaus Janoos"", ""Larry Rudolph"", ""Aleksander Madry""]","[""deep policy gradient methods"", ""deep reinforcement learning"", ""trpo"", ""ppo""]",,1811.02553,cs.LG,2018-11-06 18:54:21+00:00,2020-05-25 16:24:26+00:00
ryxeB30cYX,2019,Reject,False,Stochastic Quantized Activation: To prevent Overfitting in Fast Adversarial Training,"[""Wonjun Yoon"", ""Jisuk Park"", ""Daeshik Kim""]","[""adversarial examples"", ""deep learning""]",This paper proposes Stochastic Quantized Activation that solves overfitting problems in FGSM adversarial training and fastly achieves the robustness comparable to multi-step training.,,,,
ryxepo0cFX,2019,Accept (Poster),False,AntisymmetricRNN: A Dynamical System View on Recurrent Neural Networks,"[""Bo Chang"", ""Minmin Chen"", ""Eldad Haber"", ""Ed H. Chi""]",[],,,,,
ryxf9CEKDr,2020,Reject,False,Efficient Saliency Maps for Explainable AI,"[""T. Nathan Mundhenk"", ""Barry Chen"", ""Gerald Friedland""]","[""Saliency"", ""XAI"", ""Efficent"", ""Information""]",An efficent method for determining which locations in an image are informative to a CNN.,,,,
ryxgJTEYDr,2020,Accept (Poster),True,Reinforcement Learning with Competitive  Ensembles of Information-Constrained Primitives,"[""Anirudh Goyal"", ""Shagun Sodhani"", ""Jonathan Binas"", ""Xue Bin Peng"", ""Sergey Levine"", ""Yoshua Bengio""]","[""Reinforcement Learning"", ""Variational Information Bottleneck"", ""Learning primitives""]","Learning an implicit master policy, as a master policy in HRL can fail to generalize.",1906.10667,cs.LG,2019-06-25 17:04:48+00:00,2019-06-25 17:04:48+00:00
ryxgsCVYPr,2020,Accept (Poster),False,NeurQuRI: Neural Question Requirement Inspector for Answerability Prediction in Machine Reading Comprehension,"[""Seohyun Back"", ""Sai Chetan Chinthakindi"", ""Akhil Kedia"", ""Haejun Lee"", ""Jaegul Choo""]","[""Question Answering"", ""Machine Reading Comprehension"", ""Answerability Prediction"", ""Neural Checklist""]","We propose a neural question requirement inspection model called NeurQuRI that extracts a list of conditions from the question, each of which should be satisfied by the candidate answer generated by an MRC model.",,,,
ryxhB3CcK7,2019,Reject,False,Probabilistic Neural-Symbolic Models for Interpretable Visual Question Answering,"[""Ramakrishna Vedantam"", ""Stefan Lee"", ""Marcus Rohrbach"", ""Dhruv Batra"", ""Devi Parikh""]","[""Neural-symbolic models"", ""visual question answering"", ""reasoning"", ""interpretability"", ""graphical models"", ""variational inference""]","A probabilistic neural symbolic model with a latent program space, for more interpretable question answering",,,,
ryxhynC9KX,2019,Reject,False,"CNNSAT: Fast, Accurate Boolean Satisfiability using Convolutional Neural Networks","[""Yu Wang"", ""Fengjuan Gao"", ""Amin Alipour"", ""Linzhang Wang"", ""Xuandong Li"", ""Zhendong Su""]","[""Convolutional Neural Networks"", ""Boolean satisfiability problem"", ""Satisfiability modulo theories""]","We introduce CNNSAT, a fast and accurate statistical decision procedure for SAT based on convolutional neural networks.",,,,
ryxjH3R5KQ,2019,Reject,False,Single Shot Neural Architecture Search Via Direct Sparse Optimization,"[""Xinbang Zhang"", ""Zehao Huang"", ""Naiyan Wang""]","[""Neural Architecture Search"", ""Sparse Optimization""]",single shot neural architecture search via direct sparse optimization,,,,
ryxjnREFwH,2020,Accept (Spotlight),False,Neural Symbolic Reader: Scalable Integration of Distributed and Symbolic Representations for Reading Comprehension,"[""Xinyun Chen"", ""Chen Liang"", ""Adams Wei Yu"", ""Denny Zhou"", ""Dawn Song"", ""Quoc V. Le""]","[""neural symbolic"", ""reading comprehension"", ""question answering""]",,,,,
ryxmb1rKDS,2020,Accept (Poster),True,Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control,"[""Yaofeng Desmond Zhong"", ""Biswadip Dey"", ""Amit Chakraborty""]","[""Deep Model Learning"", ""Physics-based Priors"", ""Control of Mechanical Systems""]","This work enforces Hamiltonian dynamics with control to learn system models from embedded position and velocity data, and exploits this physically-consistent dynamics to synthesize model-based control via energy shaping.",1909.12077,cs.LG,2019-09-26 13:13:16+00:00,2020-04-30 03:02:07+00:00
ryxmrpNtvH,2020,Reject,False,Deeper Insights into Weight Sharing in Neural Architecture Search,"[""Yuge Zhang"", ""Quanlu Zhang"", ""Junyang Jiang"", ""Zejun Lin"", ""Yujing Wang""]","[""Neural Architecture Search"", ""NAS"", ""AutoML"", ""AutoDL"", ""Deep Learning"", ""Machine Learning""]",A comprehensive study of the impact of weight-sharing in Neural Architecture Search,,,,
ryxn8RNtvr,2020,Reject,True,NormLime: A New Feature Importance Metric for Explaining Deep Neural Networks,"[""Isaac Ahern"", ""Adam Noack"", ""Luis Guzman-Nateras"", ""Dejing Dou"", ""Boyang Li"", ""Jun Huan""]","[""Machine Learning"", ""Deep Learning"", ""Interpretability"", ""Feature Importance"", ""Salience""]","We introduce a new salience map (feature importance function) to generate global interpretations, and evaluate the method both quantitatively using a standard ablation technique, as well as qualitatively through a human user study.",1909.04200,cs.LG,2019-09-10 00:01:51+00:00,2019-10-15 04:43:35+00:00
ryxnHhRqFm,2019,Accept (Poster),False,Global-to-local Memory Pointer Networks for Task-Oriented Dialogue,"[""Chien-Sheng Wu"", ""Richard Socher"", ""Caiming Xiong""]","[""pointer networks"", ""memory networks"", ""task-oriented dialogue systems"", ""natural language processing""]","GLMP: Global memory encoder (context RNN, global pointer) and local memory decoder (sketch RNN, local pointer) that share external knowledge (MemNN) are proposed to strengthen response generation in task-oriented dialogue.",,,,
ryxnJlSKvr,2020,Reject,False,SCELMo: Source Code Embeddings from Language Models,"[""Rafael - Michael Karampatsis"", ""Charles Sutton""]","[""Transfer Learning"", ""Pretraining"", ""Program Repair""]",A new set of deep contextualized word representations for computer programs based on language models.,,,,
ryxnY3NYPS,2020,Accept (Poster),False,Diverse Trajectory Forecasting with Determinantal Point Processes,"[""Ye Yuan"", ""Kris M. Kitani""]","[""Diverse Inference"", ""Generative Models"", ""Trajectory Forecasting""]",We learn a diversity sampling function with DPPs to obtain a diverse set of samples from a generative model.,,,,
ryxsS3A5Km,2019,Reject,False,Continual Learning via Explicit Structure Learning,"[""Xilai Li"", ""Yingbo Zhou"", ""Tianfu Wu"", ""Richard Socher"", ""Caiming Xiong""]","[""continuous learning"", ""catastrophic forgetting"", ""architecture learning""]",,,,,
ryxsUySFwr,2020,Reject,False,Neural Network Out-of-Distribution Detection for Regression Tasks,"[""Geoff Pleiss"", ""Amauri Souza"", ""Joseph Kim"", ""Boyi Li"", ""Kilian Q. Weinberger""]","[""Out-of-distribution"", ""deep learning"", ""regression""]",Detect out-of-distribution data on regression neural networks with a generative model of the hidden features,,,,
ryxtCpNtDS,2020,Reject,False,Autoencoders and Generative Adversarial Networks for Imbalanced Sequence Classification,"[""Stephanie Ger"", ""Diego Klabjan""]","[""imbalanced multivariate time series classification""]","We introduce a novel oversampling method for variable length,  multivariate time series data that significantly improves classification accuracy.",,,,
ryxtWgSKPB,2020,Reject,True,Quantum Optical Experiments Modeled by Long Short-Term Memory,"[""Thomas Adler"", ""Manuel Erhard"", ""Mario Krenn"", ""Johannes Brandstetter"", ""Johannes Kofler"", ""Sepp Hochreiter""]","[""Recurrent Networks"", ""LSTM"", ""Sequence Analysis"", ""Binary Classification""]",We demonstrate how machine learning is able to model experiments in quantum physics.,1910.13804,cs.LG,2019-10-30 12:35:46+00:00,2019-10-30 12:35:46+00:00
ryxwJhC9YX,2019,Accept (Poster),False,InstaGAN: Instance-aware Image-to-Image Translation,"[""Sangwoo Mo"", ""Minsu Cho"", ""Jinwoo Shin""]","[""Image-to-Image Translation"", ""Generative Adversarial Networks""]",We propose a novel method to incorporate the set of instance attributes for image-to-image translation.,,,,
ryxxCiRqYX,2019,Accept (Poster),False,Deep Layers as Stochastic Solvers,"[""Adel Bibi"", ""Bernard Ghanem"", ""Vladlen Koltun"", ""Rene Ranftl""]","[""deep networks"", ""optimization""]",A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.,,,,
ryxyCeHtPB,2020,Accept (Poster),False,"Pay Attention to Features, Transfer Learn Faster CNNs","[""Kafeng Wang"", ""Xitong Gao"", ""Yiren Zhao"", ""Xingjian Li"", ""Dejing Dou"", ""Cheng-Zhong Xu""]","[""transfer learning"", ""pruning"", ""faster CNNs""]","We introduce attentive feature distillation and selection, to fine-tune a large model and produce a faster one.",,,,
ryxyHnR5tX,2019,Reject,False,Accelerated Sparse Recovery Under Structured Measurements,"[""Ke Li"", ""Jitendra Malik""]","[""sparse recovery""]",,,,,
ryxz8CVYDH,2020,Accept (Poster),True,Learning to Learn by Zeroth-Order Oracle,"[""Yangjun Ruan"", ""Yuanhao Xiong"", ""Sashank Reddi"", ""Sanjiv Kumar"", ""Cho-Jui Hsieh""]","[""learning to learn"", ""zeroth-order optimization"", ""black-box adversarial attack""]",Novel variant of learning to learn framework for zeroth-order optimization that learns both the update rule and the Gaussian sampling rule.,1910.09464,cs.LG,2019-10-21 15:48:46+00:00,2020-02-07 06:45:00+00:00
ryykVe-0W,2018,Reject,False,Learning Independent Features with Adversarial Nets for Non-linear ICA,"[""Philemon Brakel"", ""Yoshua Bengio""]","[""adversarial networks"", ""ica"", ""unsupervised"", ""independence""]",,,,,
ryzECoAcY7,2019,Accept (Poster),False,Learning Multi-Level Hierarchies with Hindsight,"[""Andrew Levy"", ""George Konidaris"", ""Robert Platt"", ""Kate Saenko""]","[""Hierarchical Reinforcement Learning"", ""Reinforcement Learning"", ""Deep Reinforcement Learning""]",We introduce the first Hierarchical RL approach to successfully learn 3-level hierarchies in parallel in tasks with continuous state and action spaces.,,,,
ryzHXnR5Y7,2019,Reject,False,Select Via Proxy: Efficient Data Selection For Training Deep Networks,"[""Cody Coleman"", ""Stephen Mussmann"", ""Baharan Mirzasoleiman"", ""Peter Bailis"", ""Percy Liang"", ""Jure Leskovec"", ""Matei Zaharia""]","[""data selection"", ""deep learning"", ""uncertainty sampling""]",we develop an efficient method for selecting training data to quickly and efficiently learn large machine learning models.,,,,
ryza73R9tQ,2019,Reject,False,Machine Translation With Weakly Paired Bilingual Documents,"[""Lijun Wu"", ""Jinhua Zhu"", ""Di He"", ""Fei Gao"", ""Xu Tan"", ""Tao Qin"", ""Tie-Yan Liu""]","[""Natural Language Processing"", ""Machine Translation"", ""Unsupervised Learning""]",,,,,
ryzfcoR5YQ,2019,Reject,False,Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting,"[""Peize Zhao"", ""Danfeng Cai"", ""Shaokun Zhang"", ""Feng Chen"", ""Zhemin Zhang"", ""Cheng Wang"", ""Jonathan Li""]","[""traffic flow forecasting"", ""spatiotemporal dependencies"", ""deep learning"", ""intelligent transportation system""]",We propose Layerwise Recurrent Autoencoder with effective spatiotemporal dependencies modeling for general traffic flow forecasting.,,,,
ryzm6BATZ,2018,Reject,False,Image Quality Assessment Techniques Improve Training and Evaluation of Energy-Based Generative Adversarial Networks,"[""Michael O. Vertolli"", ""Jim Davies""]","[""generative adversarial networks"", ""gans"", ""deep learning"", ""image modeling"", ""image generation"", ""energy based models""]",Image Quality Assessment Techniques Improve Training and Evaluation of Energy-Based Generative Adversarial Networks,,,,
rzvOQrnclO0,2022,Accept (Poster),False,Gradient Information Matters in Policy Optimization by Back-propagating through Model,"['Chongchong Li', 'Yue Wang', 'Wei Chen', 'Yuting Liu', 'Zhi-Ming Ma', 'Tie-Yan Liu']","[""Model-based RL"", ""Policy Optimization""]","Considering the gradient information in the model learning is crucial for the model-based policy optimization according to our theoritical results. Motivated by such conclusion, we design a novel DDPPO algorithm that can achieve the SOTA performance.",,,,
s-b95PMK4E6,2022,Reject,False,Hierarchical Modular Framework for Long Horizon Instruction Following ,"['Suvaansh Bhambri', 'Byeonghwi Kim', 'Roozbeh Mottaghi', 'Jonghyun Choi']",[],We present a hierarchical approach for interactive instruction following by compositional reasoning.,,,,
s03AQxehtd_,2022,Accept (Oral),False,ProtoRes: Proto-Residual Network for Pose Authoring via Learned Inverse Kinematics,"['Boris N. Oreshkin', 'Florent Bocquelet', 'Felix G. Harvey', 'Bay Raitt', 'Dominic Laflamme']","[""inverse kinematics"", ""deep learning"", ""pose modeling""]",,,,,
s0Chrsstpv2,2021,Reject,False,Better sampling in explanation methods can prevent dieselgate-like deception,"[""Domen Vre\u0161"", ""Marko Robnik \u0160ikonja""]","[""Explaniable AI"", ""explanation methods"", ""robust explanations""]","Using better sampling, the work prevents unethical use of current explanation methods, like SHAP and LIME.",2101.11702,cs.LG,2021-01-26 13:41:37+00:00,2021-01-26 13:41:37+00:00
s2UpjzX82FS,2022,Reject,False,Privacy-preserving Task-Agnostic Vision Transformer for Image Processing,"['Boah Kim', 'Jeongsol Kim', 'Jong Chul Ye']","[""Federated learning"", ""Split learning"", ""Transformer"", ""Image processing""]",,,,,
s3V9I71JvkD,2022,Reject,True,Offline Meta-Reinforcement Learning with Online Self-Supervision,"['Vitchyr H. Pong', 'Ashvin Nair', 'Laura Smith', 'Catherine Huang', 'Sergey Levine']","[""reinforcement learning"", ""meta learning"", ""meta reinforcement learning"", ""offline reinforcement learning""]","We discuss how offline meta-reinforcement learning (RL) suffers from distribution shift in the adaptation parameters, and we present a method that mitigates this distribution shift by using the offline data to bootstrap self-supervised meta-RL.",2107.03974,cs.LG,2021-07-08 17:01:32+00:00,2022-01-31 06:12:02+00:00
s4D2nnwCcM,2021,Reject,False,Uncertainty-Based Adaptive Learning for Reading Comprehension,"[""Jing Wang"", ""Jie Shen"", ""Xiaofei Ma"", ""Andrew Arnold""]","[""machine reading comprehension"", ""uncertainty-based sampling"", ""adaptive loss minimization""]","We propose an uncertainty-based adaptive learning algorithm for reading comprehension, which interleaves data annotation and model updating to mitigate the demand of labeling.",,,,
s51gCxF70pq,2022,Reject,False,Learning Temporally-Consistent Representations for Data-Efficient Reinforcement Learning,"['Trevor McInroe', 'Lukas SchÃ¤fer', 'Stefano V Albrecht']","[""Reinforcement learning"", ""representation learning"", ""continuous control""]",KSL is an auxiliary task that encourages temporally-consistent representations that propel RL agents to SotA results in the PlaNet benchmark suite.,,,,
s5lIqsrOu3Z,2022,Reject,False,Closed-Loop Data Transcription to an LDR via Minimaxing Rate Reduction,"['Xili Dai', 'Shengbang Tong', 'Mingyang Li', 'Ziyang Wu', 'Kwan Ho Ryan Chan', 'Pengyuan Zhai', 'Yaodong Yu', 'Michael Psenka', 'Xiaojun Yuan', 'Heung-Yeung Shum', 'Yi Ma']","[""Linear discriminative representation"", ""Generative model""]",A new computational framework for automatically learning a closed-loop transcription between multi-class multi-dimensional data and a linear discriminative representation (LDR) that consists of multiple multi-dimensional linear subspaces. ,,,,
s6roE3ZocH1,2022,Reject,False,Genetic Algorithm for Constrained Molecular Inverse Design,"['Yurim Lee', 'Kyudam Choi', 'Cheongwon Kim']","[""Genetic Algorithm"", ""Constrained Optimization"", ""Molecular Inverse Design"", ""Molecular Generation""]",We introduce a genetic algorithm featuring a constrained molecular inverse design.,,,,
s9788-pPB2,2021,Reject,False,LLBoost: Last Layer Perturbation to Boost Pre-trained Neural Networks,"[""Adityanarayanan Radhakrishnan"", ""Neha Prasad"", ""Caroline Uhler""]","[""Pre-trained Neural Networks"", ""Over-parameterization"", ""Perturbations""]","We present LLBoost, a theoretically-grounded, computationally-efficient method to boost the test accuracy of pre-trained neural networks without impacting the original training accuracy.",,,,
sA4qIu3zv6v,2022,Accept (Poster),True,Towards General Function Approximation in Zero-Sum Markov Games,"['Baihe Huang', 'Jason D. Lee', 'Zhaoran Wang', 'Zhuoran Yang']",[],,2107.14702,cs.GT,2021-07-30 15:25:13+00:00,2021-10-30 16:57:14+00:00
sAX7Z7uIJ_Y,2021,Reject,False,Calibrated Adversarial Refinement for Stochastic Semantic Segmentation,"[""Elias Kassapis"", ""Georgi Dikov"", ""Deepak Gupta"", ""Cedric Nugteren""]","[""stochastic semantic segmentation"", ""conditional generative models"", ""adversarial training"", ""calibration"", ""uncertainty""]","We propose a framework for learning a calibrated, multimodal predictive distribution by combining a segmentation network predicting pixelwise probabilities with an adversarial network using these probabilities to sample coherent segmentation maps.",,,,
sAzh_FTFDxz,2021,Reject,False,Understanding the Effect of Bias in Deep Anomaly Detection,"[""Ziyu Ye"", ""Yuxin Chen"", ""Haitao Zheng""]","[""deep anomaly detection"", ""bias"", ""PAC guarantee""]",A supervised view of anomaly detection with pac guarantees on the relative scoring bias.,2105.07346,cs.LG,2021-05-16 03:55:02+00:00,2021-05-16 03:55:02+00:00
sBT5nxwt18Q,2022,Reject,False,Advancing Nearest Neighbor Explanation-by-Example with Critical Classification Regions,"['Eoin M. Kenny', 'Eoin D. Delaney', 'Mark T. Keane']","[""Explainable AI"", ""Post-hoc Nearest Neighbor Explanation-by-Example"", ""User Study"", ""Case-based Reasoning"", ""Convolutional Neural Network""]","We show how to identify important ""parts"" of images in post-hoc nearest neighbor explanation-by-example, before testing it both computationally and in a user study.",,,,
sCZbhBvqQaU,2021,Accept (Poster),False,Robust Reinforcement Learning on State Observations with Learned Optimal Adversary,"[""Huan Zhang"", ""Hongge Chen"", ""Duane S Boning"", ""Cho-Jui Hsieh""]","[""reinforcement learning"", ""robustness"", ""adversarial attacks"", ""adversarial defense""]","We study the robustness of RL agents under perturbations on states and find that using an ""optimal"" adversary learned online in an alternating training manner can improve the robustness of agent policy.",,,,
sEIl_stzQyB,2022,Reject,False,Greedy-based Value Representation for Efficient Coordination in Multi-agent Reinforcement Learning,"['Lipeng Wan', 'Zeyang Liu', 'Xingyu Chen', 'Han Wang', 'Xuguang Lan']","[""multi-agent cooperation"", ""reinforcement learning algorithm""]",,2112.04454,cs.MA,2021-12-08 18:26:26+00:00,2021-12-08 18:26:26+00:00
sFDJNhwz7S,2021,Reject,False,Semantic Hashing with Locality Sensitive Embeddings,"[""Levi Boyles"", ""Aniket Anand Deshmukh"", ""Urun Dogan"", ""Rajesh Koduru"", ""Charles Denis"", ""Eren Manavoglu""]","[""Semantic Hashing"", ""Approximate Nearest Neighbor""]",We extend semantic hashing methods to problems with substantial observation noise and to the exact hashing retrieval case; applied to large scale text the method discovers hash clusters for words that are meaningful and outperform baselines.,,,,
sHSzfA4J7p,2021,Reject,False,Transferable Recognition-Aware Image Processing,"[""Zhuang Liu"", ""Tinghui Zhou"", ""Hung-Ju Wang"", ""Zhiqiang Shen"", ""Bingyi Kang"", ""Evan Shelhamer"", ""Trevor Darrell""]","[""Image processing"", ""Image recognition"", ""Transferability"", ""Decision Boundary""]","We propose approaches to enhance the machine recognizability of image processing outputs; the gain is transferable to different recognition architectures, categories and tasks, which could be explained by our analysis on modelsâ decision boundaries.",,,,
sI4SVtktqJ2,2021,Reject,False,Efficient randomized smoothing by denoising with learned score function,"[""Kyungmin Lee"", ""Seyoon Oh""]","[""Adversarial Robustness"", ""Provable Adversarial Defense"", ""Randomized Smoothing"", ""Image Denoising"", ""Score Estimation""]",We provide efficient method to generate smoothed classifier for provable defense by exploiting score-based image denoiser,,,,
sMEpviTLi1h,2021,Reject,False,Provably Faster Algorithms for Bilevel Optimization and Applications to Meta-Learning,"[""Kaiyi Ji"", ""Junjie Yang"", ""Yingbin Liang""]","[""Bilevel Optimization"", ""Computational Complexity"", ""Meta-Learning"", ""Hyper-Parameter Optimization""]",This paper develops a general and enhanced theory and proposes provably faster algorithms for bilevel optimization.,,,,
sMqybmUh_u8,2022,Reject,True,Provable Hierarchy-Based Meta-Reinforcement Learning,"['Kurtland Chua', 'Qi Lei', 'Jason D. Lee']","[""RL theory"", ""regret bounds"", ""hierarchical RL"", ""meta-RL""]","We provide an algorithm for recovering latent hierarchies from tasks under natural coverage assumptions, and regret bounds for learning downstream tasks with the hierarchy.",2110.09507,cs.LG,2021-10-18 17:56:02+00:00,2021-10-18 17:56:02+00:00
sNuFKTMktcY,2022,Accept (Poster),True,Active Hierarchical Exploration with Stable Subgoal Representation Learning,"['Siyuan Li', 'Jin Zhang', 'Jianhao Wang', 'Yang Yu', 'Chongjie Zhang']","[""Hierarchical Reinforcement Learning"", ""Exploration"", ""Representation Learning""]",We propose a regularization to stabilize subgoal representation learning in goal-conditioned HRL and develop an active exploration strategy upon this stable representation.,2105.14750,cs.LG,2021-05-31 07:28:59+00:00,2021-10-08 01:36:19+00:00
sOK-zS6WHB,2022,Accept (Spotlight),False,Responsible Disclosure of Generative Models Using Scalable Fingerprinting,"['Ning Yu', 'Vladislav Skripniuk', 'Dingfan Chen', 'Larry S. Davis', 'Mario Fritz']","[""Generative models"", ""fingerprinting"", ""responsible disclosure"", ""deep fake detection and attribution""]","Our work enables a responsible disclosure of generative models, that allows model inventors to fingerprint their models, so that the generated samples containing a fingerprint can be accurately detected and attributed to a source.",,,,
sPIFuucA3F,2022,Accept (Poster),False,"Offline Neural Contextual Bandits: Pessimism, Optimization and Generalization","['Thanh Nguyen-Tang', 'Sunil Gupta', 'A. Tuan Nguyen', 'Svetha Venkatesh']","[""offline policy learning"", ""offline contextual bandits"", ""neural network function approximation""]",Provably efficient offline contextual bandits with neural network function approximation ,,,,
sPfB2PI87BZ,2022,Accept (Poster),True,Mapping conditional distributions for domain adaptation under generalized target shift,"['Matthieu Kirchmeyer', 'Alain Rakotomamonjy', 'Emmanuel de Bezenac', 'patrick gallinari']","[""Unsupervised domain adaptation"", ""generalized target shift""]",We propose a novel theoretically grounded approach for domain adaptation under Generalized Target Shift; it learns a map between pretrained source and target representations that matches conditional distributions and recovers target proportions.,2110.15057,cs.LG,2021-10-26 14:25:07+00:00,2021-10-26 14:25:07+00:00
sRA5rLNpmQc,2021,Accept (Poster),False,Provably robust classification of adversarial examples with detection,"[""Fatemeh Sheikholeslami"", ""Ali Lotfi"", ""J Zico Kolter""]","[""Adversarial robustness"", ""robust deep learning""]",We propose a joint classifier/detector training scheme with provable performance guarantees against adversarial perturbations.,,,,
sRZ3GhmegS,2022,Accept (Spotlight),False,CoBERL: Contrastive BERT for Reinforcement Learning,"['Andrea Banino', 'Adria Puigdomenech Badia', 'Jacob C Walker', 'Tim Scholtes', 'Jovana Mitrovic', 'Charles Blundell']","[""Reinforcement Learning"", ""Contrastive Learning"", ""Representation Learning"", ""Transformer"", ""Deep Reinforcement Learning""]",A new loss and an improved architecture to efficiently train attentional models in reinforcement learning. ,,,,
sS0dHmaH1I,2022,Reject,False,Fast Adaptive Anomaly Detection,"['Ze Wang', 'Yipin Zhou', 'Rui Wang', 'Tsung-Yu Lin', 'Ashish Shah', 'Ser-Nam Lim']",[],,,,,
sSjqmfsk95O,2021,Accept (Spotlight),False,Large Scale Image Completion via Co-Modulated Generative Adversarial Networks,"[""Shengyu Zhao"", ""Jonathan Cui"", ""Yilun Sheng"", ""Yue Dong"", ""Xiao Liang"", ""Eric I-Chao Chang"", ""Yan Xu""]","[""image completion"", ""generative adversarial networks"", ""co-modulation""]",Bridging the gap between between image-conditional and unconditional GAN architectures via co-modulation,,,,
sTNHCrIKDQc,2022,Accept (Poster),True,Graphon based Clustering and Testing of Networks: Algorithms and Theory,"['Mahalakshmi Sabanayagam', 'Leena Chennuru Vankadara', 'Debarghya Ghoshdastidar']","[""Clustering"", ""Networks"", ""Graphs"", ""Two-sample testing"", ""Graphon""]",,2110.02722,cs.LG,2021-10-06 13:14:44+00:00,2021-11-07 12:05:48+00:00
sTeoJiB4uR,2021,Accept (Poster),False,Reducing the Computational Cost of Deep Generative Models with Binary Neural Networks,"[""Thomas Bird"", ""Friso Kingma"", ""David Barber""]","[""binary"", ""generative"", ""optimization"", ""compression""]",We demonstrate that deep generative models can be effectively trained using binary weights and/or activations,,,,
sTkY-RVYBz,2022,Reject,False,Counterbalancing Teacher: Regularizing Batch Normalized Models for Robustness,"['Saeid Asgari', 'Fereshte Khani', 'Ali Gholami', 'Kristy Choi', 'Linh Tran', 'Ran Zhang']","[""Robust representation learning"", ""domain generalization""]",A robust representation learning method for generalzing to common data corruptions and out-of-domain samples,,,,
sWbXSWzHPa,2022,Reject,False,Invariant Learning with Partial Group Labels,"['Vishnu Suresh Lokhande', 'Kihyuk Sohn', 'Jinsung Yoon', 'Madeleine Udell', 'Chen-Yu Lee', 'Tomas Pfister']","[""Distributional Robust Optimization"", ""Invariant Representation Learning"", ""Semi-supervised learning"", ""Dataset bias""]",We propose a new learning objective called Worst-off DRO for learning invariant representations across known groups when group labels are available only for a subset of training data.,2201.03668,cs.LG,2022-01-10 22:04:48+00:00,2022-01-10 22:04:48+00:00
sWqjiqlUDso,2022,Reject,False,Path-specific Causal Fair Prediction via Auxiliary Graph Structure Learning,"['Liuyi Yao', 'Yaliang Li', 'Bolin Ding', 'Jingren Zhou', 'Jinduo Liu', 'Mengdi Huai', 'Jing Gao']",[],,,,,
sX3XaHwotOg,2022,Accept (Poster),False,Pretraining Text Encoders with Adversarial Mixture of Training Signal Generators,"['Yu Meng', 'Chenyan Xiong', 'Payal Bajaj', 'saurabh tiwary', 'Paul N. Bennett', 'Jiawei Han', 'Xia Song']","[""Language Model Pretraining""]","We present AMOS, a new method that pretrains text encoders with an Adversarial learning curriculum via a Mixture Of Signals from multiple auxiliary generators.",,,,
sXNVFBc-0aP,2022,Reject,False,Public Data-Assisted Mirror Descent for Private Model Training,"['Ehsan Amid', 'Arun Ganesh', 'Rajiv Mathews', 'Swaroop Ramaswamy', 'Shuang Song', 'Thomas Steinke', 'Vinith Menon Suriyakumar', 'Om Thakkar', 'Abhradeep Guha Thakurta']","[""Differential Privacy"", ""Public Data"", ""Mirror Descent""]","In this paper we show, via the theory of mirror maps,  that one can effectively use the loss function generated by public data as a regularizer to control noise variance in differentially private model training.",,,,
saNgDizIODl,2022,Reject,False,NUQ: Nonparametric Uncertainty Quantification for Deterministic Neural Networks,"['Nikita Yurevich Kotelevskii', 'Alexander Fishkov', 'Kirill Fedyanin', 'Aleksandr Petiushko', 'Maxim Panov']","[""Out-of-distribution detection"", ""uncertainty quantification"", ""epistemic uncertainty"", ""aleatoric uncertainty"", ""non-parametric models"", ""Nadaraya-Watson estimator"", ""Misclassification detection""]",A new scalable non-parametric uncertainty estimation method applicable to any neural network.,,,,
sbyjwhxxT8K,2021,Reject,False,Near-Black-Box Adversarial Attacks on Graph Neural Networks as An Influence Maximization Problem,"[""Jiaqi Ma"", ""Junwei Deng"", ""Qiaozhu Mei""]","[""Graph Neural Network"", ""Adversarial Attack"", ""Influence Maximization""]",We establish a connection between adversarial attack on graph neural networks and the influence maximization problem and propose a group of effective black-box attack strategies based on this connection.,2106.10785,cs.LG,2021-06-21 00:47:44+00:00,2021-06-21 00:47:44+00:00
scSheedMzl,2022,Reject,False,Locally Invariant Explanations: Towards Causal Explanations through Local Invariant Learning,"['Amit Dhurandhar', 'Karthikeyan Natesan Ramamurthy', 'Kartik Ahuja', 'Vijay Arya']","[""explainable AI""]",Novel local explanation method that is stable and unidirectional,,,,
sebtMY-TrXh,2021,Reject,False,AriEL: Volume Coding for Sentence Generation Comparisons,"[""Luca Celotti"", ""Simon Brodeur"", ""Jean Rouat""]",[],Coding discrete information into volumes in a continuous space can improve generation by random sampling retrieval.,,,,
sfgcqgOm2F_,2021,Reject,False,Natural Compression  for Distributed Deep Learning,"[""Samuel Horv\u00e1th"", ""Chen-Yu Ho"", ""Ludovit Horv\u00e1th"", ""Atal Narayan Sahu"", ""Marco Canini"", ""Peter Richtarik""]",[],,,,,
sfy1DGc54-M,2021,Reject,True,Towards Robustness against Unsuspicious Adversarial Examples,"[""Liang Tong"", ""Minzhe Guo"", ""Atul Prakash"", ""Yevgeniy Vorobeychik""]",[],,2005.04272,cs.LG,2020-05-08 20:06:47+00:00,2020-10-08 16:58:09+00:00
sgJJjd3-Y3,2021,Reject,False,Semi-supervised regression with skewed data via adversarially forcing the distribution of predicted values,"[""Dae-Woong Jeong"", ""Kiyoung Kim"", ""Changyoung Park"", ""Sehui Han"", ""Woohyung Lim""]","[""Semi-supervised learning"", ""Adversarial"", ""regression""]",We propose a new approach to improve the regression models trained with a skewed dataset by using a semi-supervised learning framework with an adversarial network to force the distribution of the predicted values to follow the true distribution.,,,,
sgNhTKrZjaT,2021,Reject,False,Guiding Representation Learning in Deep Generative Models with Policy Gradients,"[""Luca Lach"", ""Timo Korthals"", ""Malte Schilling"", ""Helge Ritter""]","[""VAE"", ""RL"", ""PPO""]",,,,,
sgnp-qFYtN,2021,Reject,False,Sparsifying Networks via Subdifferential Inclusion,"[""Sagar Verma"", ""Jean-Christophe Pesquet""]","[""neural networks"", ""pruning after training"", ""weight pruning"", ""proximal operator"", ""fixed point iteration""]",We present a network sparsification method that utilizes the properties of nonlinear activation functions.,,,,
shbAgEsk3qM,2022,Accept (Poster),False,Understanding and Leveraging Overparameterization in Recursive Value Estimation,"['Chenjun Xiao', 'Bo Dai', 'Jincheng Mei', 'Oscar A Ramirez', 'Ramki Gummadi', 'Chris Harris', 'Dale Schuurmans']","[""Temporal Difference Learning"", ""Residual Minimization"", ""Value Estimation"", ""Overparameterization""]","We present an analysis of value estimation under overparameterized linear representations, and develop new algorithmic tools for improving recursive value estimation with deep models based on the new findings.",,,,
shpkpVXzo3h,2022,Accept (Spotlight),True,8-bit Optimizers via Block-wise Quantization,"['Tim Dettmers', 'Mike Lewis', 'Sam Shleifer', 'Luke Zettlemoyer']","[""language models"", ""pretraining"", ""finetuning"", ""GPU memory""]",We develop 8-bit optimizers reduce the memory footprint of training and maintain 32-bit optimizer performance across NLP/CV benchmarks.,2110.02861,cs.LG,2021-10-06 15:43:20+00:00,2021-10-06 15:43:20+00:00
siCt4xZn5Ve,2022,Accept (Spotlight),True,What Happens after SGD Reaches Zero Loss? --A Mathematical Framework,"['Zhiyuan Li', 'Tianhao Wang', 'Sanjeev Arora']","[""SGD"", ""implicit bias"", ""generalization"", ""deep learning"", ""implicit regularization"", ""manifold""]","We propose a mathematical framework to study the implicit bias of SGD after reaching zero loss, based on which we prove label noise can help SGD escape the kernel regime and achieve optimal sample complexity for overparametrized linear model.",2110.06914,cs.LG,2021-10-13 17:50:46+00:00,2022-02-03 18:27:59+00:00
size4UxXVCY,2022,Reject,False,Graph Tree Neural Networks,"['Seokjun Kim', 'Jaeeun Jang', 'Heeseok Jung', 'Hyeoncheol Kim']","[""Graph neural networks"", ""Tree based convolutional neural network"", ""Domain general learning""]",We propose graph tree neural networks that is freer from architecture by integrating various developed models.,,,,
sjGBjudWib,2021,Reject,False,FAST GRAPH ATTENTION NETWORKS USING EFFECTIVE RESISTANCE BASED GRAPH SPARSIFICATION,"[""Rakshith Sharma Srinivasa"", ""Cao Xiao"", ""Lucas Glass"", ""Justin Romberg"", ""Jimeng Sun""]","[""Graph neural networks"", ""Graph attention networks"", ""graph sparsification"", ""spectral sparsification""]",This paper studies graph sparsification to accelerate training times of attention based graph neural networks,,,,
sjuuTm4vj0,2021,Accept (Poster),False,Using latent space regression to analyze and leverage compositionality in GANs,"[""Lucy Chai"", ""Jonas Wulff"", ""Phillip Isola""]","[""Image Synthesis"", ""Composition"", ""Generative Adversarial Networks"", ""Image Editing"", ""Interpretability""]",We use a latent regressor network to investigate compositional properties of image synthesis with GANs.,2103.10426,cs.CV,2021-03-18 17:58:01+00:00,2021-06-03 19:52:33+00:00
sk63PSiUyci,2022,Reject,False,AI-SARAH: Adaptive and Implicit Stochastic Recursive Gradient Methods,"['Zheng Shi', 'Nicolas Loizou', 'Peter RichtÃ¡rik', 'Martin Takac']","[""practical variant of SARAH"", ""adaptive step-size"", ""tune-free algorithm"", ""implicit approach"", ""convex optimization in machine learning""]",A tune-free & fully adaptive algorithm and a practical variant of SARAH.,,,,
snOgiCYZgJ7,2021,Accept (Poster),False,Neural representation and generation for RNA secondary structures,"[""Zichao Yan"", ""William L. Hamilton"", ""Mathieu Blanchette""]","[""Graph neural network"", ""Deep generative modeling"", ""Machine learning"", ""Drug discovery"", ""RNA structure"", ""RNA structure embedding"", ""RNA-protein interaction prediction""]",We investigate a new direction in computational drug discovery for designing large scale and complex macromolecular structures known as the RNAs.,2102.00925,q-bio.BM,2021-02-01 15:49:25+00:00,2021-02-01 15:49:25+00:00
snaT4xewUfX,2021,Reject,False,Variational inference for diffusion modulated Cox processes,"[""Prateek Jaiswal"", ""Harsha Honnappa"", ""Vinayak Rao""]","[""Cox process"", ""variational inference"", ""stochastic differential equation"", ""smoothing posterior density""]",This paper proposes a variational inference method for computing an approximate smoothing posterior path measure of a Cox process with intensity as a solution to a stochastic differential equation.,,,,
sojnduJtbfQ,2021,Reject,False,Improving Hierarchical Adversarial Robustness of Deep Neural Networks,"[""Avery Ma"", ""Aladin Virmaux"", ""Kevin Scaman"", ""Juwei Lu""]","[""Adversarial Robustness""]","We introduce the hierarchical adversarial examples, along with a way to improve hierarchical adversarial robustness of neural network.",2102.09012,cs.LG,2021-02-17 20:14:31+00:00,2021-02-17 20:14:31+00:00
sr68jSUakP,2021,Reject,False,Orthogonal Subspace Decomposition: A New Perspective of Learning Discriminative Features for Face Clustering,"[""Jianfeng Wang"", ""Thomas Lukasiewicz"", ""zhongchao shi""]",[],,,,,
srtIXtySfT4,2022,Accept (Poster),False,Neural Parameter Allocation Search,"['Bryan A. Plummer', 'Nikoli Dryden', 'Julius Frost', 'Torsten Hoefler', 'Kate Saenko']","[""efficient training methods"", ""cross-layer parameter sharing""]",An efficient approach for searching for the optimal allocation of parameters to layers across any neural network,,,,
swbAS4OpXW,2022,Reject,False,One-Shot Generative Domain Adaptation,"['Ceyuan Yang', 'Yujun Shen', 'Zhiyi Zhang', 'Yinghao Xu', 'Jiapeng Zhu', 'Zhirong Wu', 'Bolei Zhou']","[""generative domain adaptation""]",This work aims at transferring a Generative Adversarial Network (GAN) pre-trained on one image domain to a new domain referring to as few as just one target image.,,,,
swiyAeGzFhQ,2022,Accept (Poster),False,Learning to Guide and to be Guided in the Architect-Builder Problem,"['Paul Barde', 'Tristan Karch', 'Derek Nowrouzezahrai', 'ClÃ©ment Moulin-Frier', 'Christopher Pal', 'Pierre-Yves Oudeyer']","[""Social Learning"", ""Interactive Learning"", ""Teacher-Student Learning"", ""Computational Experimental Semiotics"", ""Socially Supervised Learning""]","We formulate -- and propose a solution to -- the Architect-Builder Problem, a new asymmetrical Interactive Learning setting where one agent must guide the other agent towards the goal at hand. ",2112.07342,cs.LG,2021-12-14 12:57:27+00:00,2022-02-02 15:10:20+00:00
swrMQttr6wN,2022,Accept (Poster),False,Learning to Map for Active Semantic Goal Navigation,"['Georgios Georgakis', 'Bernadette Bucher', 'Karl Schmeckpeper', 'Siddharth Singh', 'Kostas Daniilidis']","[""visual navigation"", ""semantic map"", ""uncertainty estimation""]",A framework for object goal navigation that actively learns to predict semantic maps and choose long-term goals based on uncertainty measures.,,,,
sxZvLS2ZPfH,2021,Reject,False,MVP-BERT: Redesigning Vocabularies for Chinese BERT and Multi-Vocab Pretraining,"[""Wei Zhu""]","[""pretrained language models"", ""multi-vocab pretraining"", ""Chinese BERT""]",Redesign Chinese BERT's vocab and propse multi-vocab pretraining,2011.08539,cs.CL,2020-11-17 10:15:36+00:00,2020-11-17 10:15:36+00:00
sy4Kg_ZQmS7,2021,Accept (Poster),True,Learning Deep Features in Instrumental Variable Regression,"[""Liyuan Xu"", ""Yutian Chen"", ""Siddarth Srinivasan"", ""Nando de Freitas"", ""Arnaud Doucet"", ""Arthur Gretton""]","[""Causal Inference"", ""Instrumental Variable Regression"", ""Deep Learning"", ""Reinforcement Learning""]",Propose a novel deep learning based method for instrumental variable regression,2010.07154,cs.LG,2020-10-14 15:14:49+00:00,2020-11-01 15:36:04+00:00
syzTg1vyBtL,2022,Reject,False,Congested bandits: Optimal routing via short-term resets,"['Pranjal Awasthi', 'Kush Bhatia', 'Sreenivas Gollapudi', 'Kostas Kollias']","[""Multi-armed bandits"", ""linear contextual bandits"", ""policy regret"", ""congestion aware routing""]",We introduce the problem of congested bandits to model traffic routing applications and provide no policy regret algorithms for various setups.,,,,
szUsQ3NcQwV,2021,Reject,False,Randomized Entity-wise Factorization for Multi-Agent Reinforcement Learning,"[""Shariq Iqbal"", ""Christian Schroeder de Witt"", ""Bei Peng"", ""Wendelin Boehmer"", ""Shimon Whiteson"", ""Fei Sha""]","[""MARL"", ""multi-agent reinforcement learning"", ""value function factorization"", ""attention""]",We propose an auxiliary objective to disentangle value function predictions from irrelevant entities in cooperative MARL and find that it significantly improves performance in settings with varying quantities and types of agents.,,,,
szXGN2CLjwf,2021,Reject,False,Adam$^+$: A Stochastic Method with Adaptive Variance Reduction,"[""Mingrui Liu"", ""Wei Zhang"", ""Francesco Orabona"", ""Tianbao Yang""]","[""Adaptive Gradient Methods"", ""Deep Learning"", ""Nonconvex Optimization""]","This paper introduces an algorithm called Adamplus, which empirically works better than Adam, requires less parameter tuning than Adam, and enjoys data-dependent adaptive convergence rate and fast rate.",,,,
t0TaKv0Gx6Z,2021,Accept (Poster),True,Sliced Kernelized Stein Discrepancy,"[""Wenbo Gong"", ""Yingzhen Li"", ""Jos\u00e9 Miguel Hern\u00e1ndez-Lobato""]","[""kernel methods"", ""variational inference"", ""particle inference""]","We proposed a method to tackle the curse-of-dimensionality issue of kernelized Stein discrepancy with RBF kernel, along with a novel particle inference algorithm resolving the vanishing repulsive issue of Stein variational gradient descent.",2006.16531,cs.LG,2020-06-30 04:58:55+00:00,2021-03-17 09:54:48+00:00
t1QXzSGwr9,2022,Reject,False,Image Compression and Classification Using Qubits and Quantum Deep Learning,"['Ali Mohsen', 'Mo Tiwari']","[""quantum machine learning"", ""flexible representation of quantum images"", ""quantum neural network""]","We construct quantum circuits to efficiently embed larger-than-previously-possible images in qubit systems and classify them using quantum neural networks, achieving performance comparable to classical approaches.",,,,
t2LJBsPxQM,2022,Reject,True,Scaling-up Diverse Orthogonal Convolutional Networks by a Paraunitary Framework,"['Jiahao Su', 'Wonmin Byeon', 'Furong Huang']","[""orthogonal convolutions"", ""adversarial robustness"", ""spectral analysis"", ""paraunitary systems""]","We propose a paraunitary framework for orthogonal convolutions, which allows for efficient and expressive layers for diverse orthogonal convolutional neural networks.",2106.09121,cs.LG,2021-06-16 20:50:59+00:00,2021-06-16 20:50:59+00:00
t3BFUDHwEJU,2022,Reject,False,Delayed Geometric Discounts: An alternative criterion for Reinforcement Learning,"['Firas Jarboui', 'Ahmed Akakzia']",[],,,,,
t3E10H8UNz,2022,Reject,False,Transferring Hierarchical Structure with Dual Meta Imitation Learning,"['Chongkai Gao', 'Yizhou Jiang', 'Feng Chen']","[""imitation learning"", ""meta learning"", ""hierarchical structure"", ""robot learning""]",This paper presents dual meta imitation learning (DMIL) to meta learn a hierarchical network from multi-task demonstrations that can quickly adapt to new tasks with few shot demonstrations.,2201.11981,cs.RO,2022-01-28 08:22:38+00:00,2022-01-28 08:22:38+00:00
t4EWDRLHwcZ,2021,Reject,False,Graph Learning via Spectral Densification,"[""Zhuo Feng"", ""Yongyu Wang"", ""Zhiqiang Zhao""]","[""Spectral Graph Theory"", ""Undirected Graphical models"", ""Gaussian Markov Random Fields""]",A highly-efficient graph learning approach exploiting high-performance spectral graph algorithms,,,,
t4hNn7IvNZX,2021,Reject,False,Certified Distributional Robustness via Smoothed Classifiers ,"[""Jungang Yang"", ""Liyao Xiang"", ""Ruidong Chen"", ""Yukun Wang"", ""Wei Wang"", ""Xinbing Wang""]",[],,,,,
t5EmXZ3ZLR,2022,Accept (Spotlight),False,SOSP: Efficiently Capturing Global Correlations by Second-Order Structured Pruning,"['Manuel Nonnenmacher', 'Thomas Pfeil', 'Ingo Steinwart', 'David Reeb']","[""Structured Pruning"", ""Saliency-based Pruning"", ""Network Compression"", ""Hessian Approximation"", ""Neural Architecture Search"", ""Deep Learning"", ""Computer Vision""]",We introduce a second-order structured pruning method which efficiently captures global correlations among structures of deep neural networks.,,,,
t5lNr0Lw84H,2021,Reject,False,Benchmarking Multi-Agent Deep Reinforcement Learning Algorithms,"[""Chao Yu"", ""Akash Velu"", ""Eugene Vinitsky"", ""Yu Wang"", ""Alexandre Bayen"", ""Yi Wu""]","[""Multi-agent Reinforcement Learning"", ""Benchmarking""]",We provide an analysis of the relative performance of multi-agent reinforcement learning algorithms as well as an analysis of how easy they are to tune for new tasks.,,,,
t5s-hd1bqLk,2022,Accept (Poster),False,Conditioning Sequence-to-sequence Networks with Learned Activations,"['Alberto Gil Couto Pimentel Ramos', 'Abhinav Mehrotra', 'Nicholas Donald Lane', 'Sourav Bhattacharya']","[""Conditional Neural Networks"", ""Sound Enhancement"", ""Personalized ASR""]",Conditioning neural networks by learning the layer activations based on the conditioning vector,,,,
t7y6MKiyiWx,2022,Reject,False,Classical and Quantum Algorithms for Orthogonal Neural Networks,"['Jonas Landman', 'Natansh Mathur', 'Iordanis Kerenidis']","[""orthogonal neural networks"", ""orthogonality"", ""quantum computing"", ""quantum machine learning"", ""quantum deep learning"", ""complexity"", ""quantum computer""]","A new and fast way of implementing orthogonal neural networks, both for classical and quantum computers, with numerical simulations.",,,,
t86MwoUCCNe,2021,Accept (Poster),False,New Bounds For Distributed Mean Estimation and Variance Reduction,"[""Peter Davies"", ""Vijaykrishna Gurunanthan"", ""Niusha Moshrefi"", ""Saleh Ashkboos"", ""Dan Alistarh""]","[""distributed machine learning"", ""mean estimation"", ""variance reduction"", ""lattices""]","We provide optimal algorithms and lower bounds for distributed mean estimation and variance reduction via a new connection to lattice theory, and show that this technique can be used to improve upon current approaches in practice.",,,,
t8O-4LKFVx,2022,Accept (Spotlight),False,Learning Optimal Conformal Classifiers,"['David Stutz', 'Krishnamurthy Dj Dvijotham', 'Ali Taylan Cemgil', 'Arnaud Doucet']","[""conformal prediction"", ""conformal classification"", ""uncertainty estimation""]","Conformal training allows to train classifier and conformal predictor end-to-end, optimizing average confidence set size (inefficiency) or other application-specific losses defined on confidence sets.",,,,
t98k9ePQQpn,2022,Accept (Poster),False,Optimal Transport for Long-Tailed Recognition with Learnable Cost Matrix,"['Hanyu Peng', 'Mingming Sun', 'Ping Li']","[""Long-tailed recognition"", ""imbalanced classification"", ""optimal transport""]",A new paradigm for post-hoc correction based on optimal transport to cope with long-tailed recognition.,,,,
tADlrawCrVU,2021,Reject,False,CoLES: Contrastive learning for event sequences with self-supervision,"[""Dmitrii Babaev"", ""Nikita Ovsov"", ""Ivan A Kireev"", ""Gleb Gusev"", ""Maria Ivanova"", ""Alexander Tuzhilin""]","[""representation learning"", ""contrastive learning"", ""neural networks"", ""event sequiences""]","We propose a new method CoLES, which adapts self-supervised contrastive learning, to the discrete event sequence domain",,,,
tBIQEvApZK5,2022,Accept (Poster),False,Feature Kernel Distillation,"['Bobby He', 'Mete Ozay']","[""Knowledge distillation"", ""Neural Network (NN) Feature learning"", ""ensembling NNs"", ""Deep learning fundamentals"", ""Image classification""]","A feature-learning perspective of (ensemble) Knowledge Distillation (KD) in Neural Networks to propose a new method (FKD), with both theoretical & experimental results demonstrating FKD's advantages over standard KD baselines.",,,,
tBtoZYKd9n,2022,Accept (Spotlight),True,"Evaluation Metrics for Graph Generative Models: Problems, Pitfalls, and Practical Solutions","[""Leslie O'Bray"", 'Max Horn', 'Bastian Rieck', 'Karsten Borgwardt']","[""graph generative models"", ""model evaluation""]",We investigate the potential pitfalls of using MMD to evaluate graph generative models and propose recommendations for the practitioner on how to mitigate those challenges.,2106.01098,cs.LG,2021-06-02 12:04:29+00:00,2021-10-11 06:50:28+00:00
tC6iW2UUbJf,2021,Accept (Poster),True,What Makes Instance Discrimination Good for Transfer Learning?,"[""Nanxuan Zhao"", ""Zhirong Wu"", ""Rynson W. H. Lau"", ""Stephen Lin""]","[""Transfer Learning"", ""Unsupervised Learning"", ""Self-supervised Learning""]",Understanding why self-supervised contrastive learning outperforms supervised counterparts for image pretraining,2006.06606,cs.CV,2020-06-11 16:55:07+00:00,2021-01-19 15:45:44+00:00
tCx6AefvuPf,2022,Reject,False,Node-Level Differentially Private Graph Neural Networks,"['Ameya Daigavane', 'Gagan Madan', 'Aditya Sinha', 'Abhradeep Guha Thakurta', 'Gaurav Aggarwal', 'Prateek Jain']","[""differential privacy"", ""graph neural networks"", ""node-level privacy""]",We propose the first mechanism to train node-level differentially private graph neural networks.,2111.15521,cs.LG,2021-11-23 16:18:53+00:00,2021-12-06 10:29:09+00:00
tD7eCtaSkR,2022,Accept (Spotlight),False,Improved deterministic l2 robustness on CIFAR-10 and CIFAR-100,"['Sahil Singla', 'Surbhi Singla', 'Soheil Feizi']","[""provable robustness"", ""adversarial examples""]","Improving provable robustness of 1 Lipschitz CNNs by relaxing orthogonalization of last layer, certificate regularization and a novel activation function.",,,,
tDirSp3pczB,2022,Reject,True,Sharp Learning Bounds for Contrastive Unsupervised Representation Learning,"['Han Bao', 'Yoshihiro Nagano', 'Kento Nozawa']",[],,2110.02501,cs.LG,2021-10-06 04:29:39+00:00,2021-10-06 04:29:39+00:00
tEFhwX8s1GN,2021,Reject,False,Training By Vanilla SGD with Larger Learning Rates,"[""Yueyao Yu"", ""Jie Wang"", ""Wenye Li"", ""Yin Zhang""]",[],,,,,
tEw4vEEhHjI,2021,Reject,True,Fixing Asymptotic Uncertainty of Bayesian Neural Networks with Infinite ReLU Features,"[""Agustinus Kristiadi"", ""Matthias Hein"", ""Philipp Hennig""]","[""Bayesian deep learning"", ""Gaussian processes"", ""uncertainty quantification""]","A way to add infinitely many ReLU features away from the support of the data to achieve uniform asymptotic uncertainty, at negligible additional cost.",2010.02709,cs.LG,2020-10-06 13:32:18+00:00,2021-10-29 13:33:45+00:00
tFPAIXpb13,2021,Reject,False,Graph Deformer Network,"[""Wenting Zhao"", ""Yuan Fang"", ""Zhen Cui"", ""Tong Zhang"", ""Jian Yang"", ""Wei Liu""]","[""Graph Convolution"", ""Anchor Space"", ""Anisotropic Convolution"", ""Graph Classification"", ""Node Classification""]","We propose an effective graph deformer network (GDN) to implement an anisotropic convolution filtering on graphs, and verify its superiority in theory and experiment.",,,,
tFQyjbOz34,2022,Reject,False,Detecting Modularity in Deep Neural Networks,"['Shlomi Hod', 'Stephen Casper', 'Daniel Filan', 'Cody Wild', 'Andrew Critch', 'Stuart Russell']","[""Modularity"", ""clustering"", ""interpretability"", ""feature visualization"", ""lesions""]",Graph-based clusterings of the neurons in networks reveal subsets that exhibit modularity. ,,,,
tFgdrQbbaa,2022,Accept (Poster),False,Learning curves for continual learning in neural networks: Self-knowledge transfer and forgetting,"['Ryo Karakida', 'Shotaro Akaho']","[""continual learning"", ""neural tangent kernel"", ""statistical mechanics""]",We analyze the generalization performance of continual learning in the NTK regime and identify key properties of knowledge transfer and forgetting. ,2112.01653,stat.ML,2021-12-03 00:25:01+00:00,2021-12-03 00:25:01+00:00
tG8QrhMwEqS,2022,Reject,False,Adaptive Activation-based Structured Pruning,"['Kaiqi Zhao', 'Animesh Jain', 'Ming Zhao']","[""model compression"", ""structured pruning""]","This paper presents an adaptive, activation-based, structured pruning approach to automatically and efficiently generate small and accurate models that meet user requirements.",2201.10520,cs.CV,2022-01-21 22:21:31+00:00,2022-01-21 22:21:31+00:00
tGZu6DlbreV,2021,Accept (Poster),True,RNNLogic: Learning Logic Rules for Reasoning on Knowledge Graphs,"[""Meng Qu"", ""Junkun Chen"", ""Louis-Pascal Xhonneux"", ""Yoshua Bengio"", ""Jian Tang""]","[""Knowledge Graph Reasoning"", ""Logic Rules"", ""EM""]",Learn Logic Rules for Reasoning on Knowledge Graphs.,2010.04029,cs.AI,2020-10-08 14:47:02+00:00,2021-07-16 02:52:53+00:00
tH6_VWZjoq,2021,Accept (Poster),False,Local Search Algorithms for Rank-Constrained Convex Optimization,"[""Kyriakos Axiotis"", ""Maxim Sviridenko""]","[""low rank"", ""rank-constrained convex optimization"", ""matrix completion""]",Efficient greedy and local search algorithms for optimizing a convex objective under a rank constraint.,2101.06262,cs.LG,2021-01-15 18:52:02+00:00,2021-01-15 18:52:02+00:00
tHgJoMfy6nI,2021,Accept (Poster),True,Remembering for the Right Reasons: Explanations Reduce Catastrophic Forgetting,"[""Sayna Ebrahimi"", ""Suzanne Petryk"", ""Akash Gokul"", ""William Gan"", ""Joseph E. Gonzalez"", ""Marcus Rohrbach"", ""trevor darrell""]","[""Continual Learning"", ""Lifelong Learning"", ""Catastrophic Forgetting"", ""XAI"", ""Explainability""]",Introducing a connection between continual learning and model explainability by regularizing saliency maps to avoid forgetting and showing its effect on memory and regularization-based continual learning approaches. ,2010.01528,cs.CV,2020-10-04 10:05:27+00:00,2021-05-03 03:26:30+00:00
tHx6q2dM86s,2022,Reject,False,HYPOCRITE: Homoglyph Adversarial Examples for Natural Language Web Services in the Physical World,"['JINYONG KIM', 'JEONGHYEON KIM', 'MOSE GU', 'SANGHAK OHH', 'GILTEUN CHOI', 'JAEHOON JEONG']","[""Adversarial Examples"", ""Homograph"", ""Natural Language"", ""Web Services"", ""Physical World""]",Adversarial Attacks against Natural Language Web Services in the Physical World,,,,
tIjRAiFmU3y,2021,Accept (Poster),False,An Unsupervised Deep Learning Approach for Real-World Image Denoising,"[""Dihan Zheng"", ""Sia Huat Tan"", ""Xiaowen Zhang"", ""Zuoqiang Shi"", ""Kaisheng Ma"", ""Chenglong Bao""]","[""Real-world image denoising"", ""unsupervised image denoising""]",We propose an unsupervised real-world image denoising approach that combines DNNs with classical MAP approaches.  ,,,,
tJCwZBHm-jW,2022,Reject,True,Image2Point: 3D Point-Cloud Understanding with 2D Image Pretrained Models,"['Chenfeng Xu', 'Shijia Yang', 'Bohan Zhai', 'Bichen Wu', 'Xiangyu Yue', 'Wei Zhan', 'Peter Vajda', 'Kurt Keutzer', 'Masayoshi Tomizuka']","[""Computer vision"", ""Point-cloud"", ""Cross-modality.""]","With minimal fine-tuning efforts, pretrained-image models can be directly used for point-cloud understanding.",2106.04180,cs.CV,2021-06-08 08:42:55+00:00,2021-06-08 08:42:55+00:00
tJhIY38d2TS,2022,Reject,False,Local Reweighting for Adversarial Training,"['Ruize Gao', 'Feng Liu', 'Kaiwen Zhou', 'Gang Niu', 'Bo Han', 'James Cheng']","[""adversarial training""]",The locally reweighted adversarial training (LRAT) can take care of diverse attacks.,,,,
tJz_QUXB7C,2021,Reject,False,Generating Plannable Lifted Action Models for Visually Generated Logical Predicates,"[""Masataro Asai""]","[""Object-Centric Representation"", ""Planning"", ""Discrete VAE""]","From pixel data of objects, FOSAE++ generates a symbolic planning domain description generalized over objects. The system is fully neural and requires no manual tagging.",,,,
tL89RnzIiCd,2021,Accept (Poster),False,Hopfield Networks is All You Need,"[""Hubert Ramsauer"", ""Bernhard Sch\u00e4fl"", ""Johannes Lehner"", ""Philipp Seidl"", ""Michael Widrich"", ""Lukas Gruber"", ""Markus Holzleitner"", ""Thomas Adler"", ""David Kreil"", ""Michael K Kopp"", ""G\u00fcnter Klambauer"", ""Johannes Brandstetter"", ""Sepp Hochreiter""]","[""Modern Hopfield Network"", ""Energy"", ""Attention"", ""Convergence"", ""Storage Capacity"", ""Hopfield layer"", ""Associative Memory""]",A novel continuous Hopfield network is proposed whose update rule is the attention mechanism of the transformer model and which can be integrated into deep learning architectures.,,,,
tQ2yZj4sCnk,2022,Reject,False,Divergence-Regularized Multi-Agent Actor-Critic,"['Su Kefan', 'Zongqing Lu']","[""multi-agent reinforcement learning""]",,,,,
tT9t_ZctZRL,2022,Accept (Poster),False,Towards Deepening Graph Neural Networks: A GNTK-based Optimization Perspective,"['Wei Huang', 'Yayong Li', 'weitao Du', 'Richard Xu', 'Jie Yin', 'Ling Chen', 'Miao Zhang']","[""Trainablity"", ""Graph Neural Tangent Kernel"", ""Critical DropEdge""]","This work theoretically studies the trainability of deep graph neural networks, and is inspired to design algorithms to deepen the network.",,,,
tUMr0Iox8XW,2022,Accept (Poster),False,Efficient Computation of Deep Nonlinear Infinite-Width Neural Networks that Learn Features,"['Greg Yang', 'Michael Santacroce', 'Edward J Hu']","[""infinite-width neural network"", ""feature learning"", ""maximal update parametrization"", ""NTK""]",A new feature learning â-width limit for deep nonlinear networks closes the performance gap between finite- and infinite-width neural networks previously left by NTK.,,,,
tUa4REjGjTf,2022,Accept (Poster),True,On the Certified Robustness for Ensemble Models and Beyond,"['Zhuolin Yang', 'Linyi Li', 'Xiaojun Xu', 'Bhavya Kailkhura', 'Tao Xie', 'Bo Li']","[""robustness"", ""ensemble"", ""certified robustness""]","Inspired by theoretical analysis, we propose Diversity Regularized Training to enhance the certified robustness of ensemble models and DRT significantly outperforms existing methods.",2107.10873,cs.LG,2021-07-22 18:10:41+00:00,2021-07-22 18:10:41+00:00
tV3N0DWMxCg,2022,Accept (Spotlight),True,Natural Posterior Network: Deep Bayesian Predictive Uncertainty for Exponential Family Distributions,"['Bertrand Charpentier', 'Oliver Borchert', 'Daniel ZÃ¼gner', 'Simon Geisler', 'Stephan GÃ¼nnemann']","[""Uncertainty"", ""Exponential Family"", ""Bayesian Update"", ""Conjugate Prior""]",,2105.04471,cs.LG,2021-05-10 16:10:26+00:00,2021-05-10 16:10:26+00:00
tV6oBfuyLTQ,2021,Accept (Poster),False,Parameter-Based Value Functions,"[""Francesco Faccio"", ""Louis Kirsch"", ""J\u00fcrgen Schmidhuber""]","[""Reinforcement Learning"", ""Off-Policy Reinforcement Learning""]",We propose value functions whose inputs include the policy parameters and which can generalize across different policies,,,,
tW4QEInpni,2021,Accept (Oral),False,When Do Curricula Work?,"[""Xiaoxia Wu"", ""Ethan Dyer"", ""Behnam Neyshabur""]","[""Curriculum Learning"", ""Understanding Deep Learning"", ""Empirical Investigation""]","We conduct extensive experiments over thousands of orderings to investigate the effectiveness of  three kinds of learning: curriculum, anti-curriculum, and random-curriculum.",2012.03107,cs.LG,2020-12-05 19:41:30+00:00,2021-02-09 17:38:58+00:00
tY38nwwdCDa,2021,Reject,False,USING OBJECT-FOCUSED IMAGES AS AN IMAGE AUGMENTATION TECHNIQUE TO IMPROVE THE ACCURACY OF IMAGE-CLASSIFICATION MODELS WHEN VERY LIMITED DATA SETS ARE AVAILABLE,"[""Ahmad Melhem Hammoud"", ""Ahmad Rabih Ghandour""]","[""Machine Learning"", ""Computer Vision"", ""Data Augmentation"", ""Background Removal""]","Before training an image classifying model, removing backgrounds from all training images and keeping just the labeled object will generate a new set of images, which will augment the data and increase the accuracy of the trained model",,,,
tYRrOdSnVUy,2022,Accept (Oral),True,Non-Transferable Learning: A New Approach for Model Ownership Verification and Applicability Authorization,"['Lixu Wang', 'Shichao Xu', 'Ruiqi Xu', 'Xiao Wang', 'Qi Zhu']","[""Domain Adaptation"", ""Transfer Learning"", ""Societal Considerations of Representation Learning"", ""Model Watermark""]",We propose a novel Non-Transferable Learning (NTL) method to restrict the model generalization ability to certain domains for model ownership verification and applicability authorization.,2106.06916,cs.LG,2021-06-13 04:57:16+00:00,2021-06-13 04:57:16+00:00
tYxG_OMs9WE,2021,Accept (Poster),False,Property Controllable Variational Autoencoder via Invertible Mutual Dependence,"[""Xiaojie Guo"", ""Yuanqi Du"", ""Liang Zhao""]","[""deep generative models"", ""interpretable latent representation"", ""disentangled representation learning""]",A novel generative model for learning interpretable latent representation for generating data with desired properties.,,,,
taQNxF9Sj6,2021,Reject,True, Adding Recurrence to Pretrained Transformers,"[""Davis Yoshida"", ""Allyson Ettinger"", ""Kevin Gimpel""]","[""Language modeling"", ""Transformers"", ""Recurrence"", ""Gradient checkpointing"", ""Pretraining""]",Adding a small recurrence module to pretrained transformer language models allows maintaining performance while lowering memory cost,2008.07027,cs.CL,2020-08-16 23:19:30+00:00,2020-08-16 23:19:30+00:00
tbwjUvUzQRU,2021,Reject,False,A Communication Efficient Federated Kernel $k$-Means,"[""Xiaochen Zhou"", ""Xudong Wang""]","[""federated learning"", ""kernel $k$-means"", ""communication efficient""]",,,,,
tc5qisoB-C,2021,Accept (Poster),False,C-Learning: Learning to Achieve Goals via Recursive Classification,"[""Benjamin Eysenbach"", ""Ruslan Salakhutdinov"", ""Sergey Levine""]","[""reinforcement learning"", ""goal reaching"", ""density estimation"", ""Q-learning"", ""hindsight relabeling""]","We reframe the goal-conditioned RL problem as one of predicting and controlling the future state of the world, and derive a principled algorithm to solve this problem. ",2011.08909,cs.LG,2020-11-17 19:58:56+00:00,2021-04-19 18:33:47+00:00
tckGH8K9y6o,2021,Reject,False,Symmetric Wasserstein Autoencoders,"[""Sun Sun"", ""Hongyu Guo""]","[""generative models"", ""variational autoencoders""]","We introduce a new family of generative autoencoders with a learnable prior, called Symmetric Wasserstein Autoencoders.",2106.13024,cs.LG,2021-06-24 13:56:02+00:00,2021-06-24 13:56:02+00:00
te7PVH1sPxJ,2021,Accept (Poster),False,Convex Potential Flows: Universal Probability Distributions with Optimal Transport and Convex Optimization,"[""Chin-Wei Huang"", ""Ricky T. Q. Chen"", ""Christos Tsirigotis"", ""Aaron Courville""]","[""Normalizing flows"", ""generative models"", ""variational inference"", ""invertible neural networks"", ""universal approximation"", ""optimal transport"", ""convex optimization""]",We propose to use an input-convex neural network to parameterize an invertible model with universal density approximation guarantees. ,2012.05942,cs.LG,2020-12-10 19:36:34+00:00,2021-02-23 20:15:35+00:00
tf8a4jDRFCv,2021,Reject,False,Learning Aggregation Functions,"[""Giovanni Pellegrini"", ""Alessandro Tibo"", ""Paolo Frasconi"", ""Andrea Passerini"", ""Manfred Jaeger""]","[""Deep learning"", ""Neural networks"", ""Relational and structured data"", ""Aggregation functions""]",,,,,
tgcAoUVHRIB,2022,Accept (Poster),False,Neural Methods for Logical Reasoning over Knowledge Graphs,"['Alfonso Amayuelas', 'Shuai Zhang', 'Xi Susie Rao', 'Ce Zhang']","[""Knowledge Graphs"", ""Knowledge Graph Reasoning"", ""Graph Mining"", ""Data Mining"", ""Machine Learning"", ""Artificial Intelligence"", ""Deep Learning""]",Neural Network models for answering multi-hop queris on Knowledge Graphs,,,,
tge0BZv1Ay,2022,Reject,False,PDQN - A Deep Reinforcement Learning Method for Planning with Long Delays: Optimization of Manufacturing Dispatching,"['David C Jenkins', 'RenÃ© Arendt SÃ¸rensen', 'Vikramank Singh', 'Philip Kaminsky', 'Anil Aswani', 'Ramakrishna Akella']","[""This paper proposes the PDQN"", ""a novel method based on integrating Deep Reinforcement Learning and abstract planning for developing dynamic scheduling for policies in  systems with very delayed rewards"", ""e.g. manufacturing.""]","This paper proposes the PDQN, a novel method based on integrating Deep Reinforcement Learning and abstract planning for developing dynamic scheduling for policies in  systems with very delayed rewards, e.g. manufacturing.",,,,
thhdrl4IdMm,2021,Reject,True,A Chain Graph Interpretation of Real-World Neural Networks,"[""Yuesong Shen"", ""Daniel Cremers""]","[""neural network interpretation"", ""chain graph"", ""deep learning theory"", ""probabilistic graphical model""]",Real world neural networks can be interpreted as chain graphs.,2006.16856,cs.LG,2020-06-30 14:46:08+00:00,2020-10-06 11:14:19+00:00
tiKNfYpH8le,2022,Reject,True,Pareto Navigation Gradient Descent: a First Order Algorithm for Optimization in Pareto Set,"['Mao Ye', 'qiang liu']","[""Pareto set"", ""Multitask learning""]",We propose a first-order algorithm for solving optimization with parameter space constrained in the Pareto set of the multi-objective optimization problem.,2110.08713,math.OC,2021-10-17 04:07:04+00:00,2021-10-17 04:07:04+00:00
tiQ5Zh2S3zV,2022,Reject,False,A multi-domain splitting framework for time-varying graph structure,"['Zehua Yu', 'Xianwei Zheng', 'Zhulun Yang', 'Xutao Li']","[""graph signal processing"", ""time-varying structure"", ""anomaly detection"", ""multi-domain analysis"", ""graph learning""]","This paper propose a novel multi-domain splitting framework for time-varying graph structure analysis, and apply it to anomaly detection.",,,,
tij5dHg5Hk,2021,Reject,False,Run Away From your Teacher: a New Self-Supervised Approach Solving the Puzzle of BYOL,"[""Haizhou Shi"", ""Dongliang Luo"", ""Siliang Tang"", ""Jian Wang"", ""Yueting Zhuang""]","[""representation learning"", ""self-supervised learning"", ""contrastive learning"", ""regularization"", ""theory""]",We propose a new interpretable self-supervised approach RAFT solving the puzzle why BYOL works without collapse.,2011.10944,cs.LG,2020-11-22 05:49:50+00:00,2020-11-22 05:49:50+00:00
tilovEHA3YS,2021,Accept (Spotlight),False,Learning-based Support Estimation in Sublinear Time,"[""Talya Eden"", ""Piotr Indyk"", ""Shyam Narayanan"", ""Ronitt Rubinfeld"", ""Sandeep Silwal"", ""Tal Wagner""]","[""support estimation"", ""sublinear"", ""learning-based"", ""distinct elements"", ""chebyshev polynomial""]","A learning-based algorithm for support size estimation, which given a sufficiently accurate predictor, improves both provably and empirically over state-of-the-art algorithms that do not use a predictor.",,,,
tiqI7w64JG2,2021,Accept (Poster),True,On Graph Neural Networks versus Graph-Augmented MLPs,"[""Lei Chen"", ""Zhengdao Chen"", ""Joan Bruna""]","[""Graph Neural Networks"", ""expressive power"", ""feature propagation"", ""rooted graphs"", ""attributed walks"", ""community detection"", ""depth separation""]",We establish a separation in expressive power and flexibility of learning between GNNs and Graph-Augmented MLPs.,2010.15116,cs.LG,2020-10-28 17:59:59+00:00,2020-12-02 16:46:23+00:00
tkAtoZkcUnm,2021,Accept (Poster),True,Neural Thompson Sampling,"[""Weitong ZHANG"", ""Dongruo Zhou"", ""Lihong Li"", ""Quanquan Gu""]","[""Deep Learning"", ""Contextual Bandits"", ""Thompson sampling""]","We propose NeuralTS, a provable neural work-based Thompson sampling algorithm for stochastic contextual bandits.",2010.00827,cs.LG,2020-10-02 07:44:09+00:00,2020-10-02 07:44:09+00:00
tkra4vFiFq,2021,Reject,False,GINN: Fast GPU-TEE Based Integrity for Neural Network Training,"[""Aref Asvadishirehjini"", ""Murat Kantarcioglu"", ""Bradley A. Malin""]","[""Deep Learning"", ""Trusted Execution Environments"", ""Integrity-Preserving Computation"", ""Intel SGX""]",Integrity preserving SGD training of Deep Neural Networks using GPU and Trusted Execution Environments,,,,
tlV90jvZbw,2021,Accept (Poster),True,Early Stopping in Deep Networks: Double Descent and How to Eliminate it,"[""Reinhard Heckel"", ""Fatih Furkan Yilmaz""]","[""early stopping"", ""double descent""]",Epoch wise double descent can be explained as a superposition of two or more bias-variance tradeoffs that arise because different parts of the network are learned at different epochs.,2007.10099,cs.LG,2020-07-20 13:43:33+00:00,2020-09-19 22:21:12+00:00
tlkHrUlNTiL,2022,Reject,False,Disentangling deep neural networks with rectified linear units using duality,"['CHANDRA SHEKAR LAKSHMINARAYANAN', 'Amit Vikram Singh']",[],,,,,
tlkMbWBEAFb,2022,Reject,False,Fully Steerable 3D Spherical Neurons,"['Pavlo Melnyk', 'Michael Felsberg', 'MÃ¥rten WadenbÃ¤ck']","[""geometric deep learning"", ""steerable network"", ""conformal embedding"", ""spherical neuron"", ""3D shape classification""]",We propose a fully steerable feed-forward geometric network for classification of 3D shapes.,,,,
tm9-r3-O2lt,2022,Reject,False,CONTROLLING THE MEMORABILITY OF REAL AND UNREAL FACE IMAGES,"['Mohammad Younesi', 'Yalda Mohsenzadeh']","[""Memorability"", ""Face Memorability"", ""Face Memorability Modification"", ""StyleGAN"", ""Latent Vector"", ""Image2Style""]",In this work we propose a new method to modify face memorability. ,,,,
tnSo6VRLmT,2021,Accept (Poster),False,Efficient Conformal Prediction via Cascaded Inference with Expanded Admission,"[""Adam Fisch"", ""Tal Schuster"", ""Tommi S. Jaakkola"", ""Regina Barzilay""]","[""conformal prediction"", ""uncertainty estimation"", ""efficient inference methods"", ""natural language processing"", ""chemistry""]",This work proposes two complementary techniques for improving the efficiency of conformal prediction in large-scale domains---while still retaining performance guarantees.,,,,
tnq_O52RVbR,2021,Reject,False,SHADOWCAST: Controllable Graph Generation with Explainability,"[""Wesley Joon-Wie Tann"", ""Ee-Chien Chang"", ""Bryan Hooi""]","[""Controllable Graph Generation"", ""Explainability"", ""Conditional Generative Adversarial Network""]",We introduce the problem of controlling the graph generation process and propose a novel approach based on a conditional generative adversarial network to produce deliberate graphs with explainable structures.,,,,
tq5JAGsedIP,2021,Reject,True,Time-varying Graph Representation Learning via Higher-Order Skip-Gram with Negative Sampling,"[""Simone Piaggesi"", ""Andr\u00e9 Panisson""]","[""representation learning"", ""node embeddings"", ""temporal graphs"", ""tensor factorization"", ""disease spreading""]",Unsupervised representation learning algorithm for temporal graphs which disentagles structural and temporal features into different embedding matrices.,2006.14330,cs.LG,2020-06-25 12:04:48+00:00,2020-06-25 12:04:48+00:00
tqOvYpjPax2,2021,Accept (Poster),False,Intraclass clustering: an implicit learning ability that regularizes DNNs,"[""Simon Carbonnelle"", ""Christophe De Vleeschouwer""]","[""deep learning"", ""generalization"", ""implicit regularization""]",This paper provides empirical evidence that deep neural networks are implicitly regularized through their ability to extract meaningful clusters among the samples of a class.,,,,
tqc8n6oHCtZ,2021,Reject,True,"Length-Adaptive Transformer: Train Once with Length Drop, Use Anytime with Search","[""Gyuwan Kim"", ""Kyunghyun Cho""]","[""transformer"", ""efficiency"", ""anytime prediction"", ""sequence length"", ""evolutionary search""]",,2010.07003,cs.CL,2020-10-14 12:28:08+00:00,2021-06-11 20:00:20+00:00
trPMYEn1FCX,2021,Reject,False,GENERATIVE MODEL-ENHANCED HUMAN MOTION PREDICTION,"[""Anthony Bourached"", ""Ryan-Rhys Griffiths"", ""Robert Gray"", ""Ashwani Jha"", ""Parashkev Nachev""]",[],,,,,
trYkgJMOXhy,2021,Reject,False,Generative Fairness Teaching,"[""Rongmei Lin"", ""Hanjun Dai"", ""Li Xiong"", ""Wei Wei""]","[""fairness"", ""student teacher model"", ""counterfactual generative model""]",Teaching machines to achieve fairness by using a counterfactual generative model,,,,
trj4iYJpIvy,2021,Reject,False,Approximation Algorithms for Sparse Principal Component Analysis,"[""Agniva Chowdhury"", ""Petros Drineas"", ""David Woodruff"", ""Samson Zhou""]","[""Sparse PCA"", ""Principal component analysis"", ""Randomized linear algebra"", ""Singular value decomposition""]","We present three provably accurate approximation algorithms for the Sparse Principal Component Analysis (SPCA)  problem, without imposing any restrictive assumptions on the input covariance matrix.",,,,
tsg-Lf1MYp,2022,Reject,False,Natural Attribute-based Shift Detection,"['Jeonghoon Park', 'Jimin Hong', 'Radhika Dua', 'Daehoon Gwak', 'Jaegul Choo', 'Sharon Li', 'Edward Choi']","[""attribute shift"", ""out-of-distribution detection"", ""distribution shift""]",,,,,
tu29GQT0JFy,2021,Accept (Poster),False,not-MIWAE: Deep Generative Modelling with Missing not at Random Data,"[""Niels Bruun Ipsen"", ""Pierre-Alexandre Mattei"", ""Jes Frellsen""]",[],We present an approach for building and fitting deep latent variable models (DLVMs) in cases where the missing process is dependent on the missing data.,,,,
tuIt1aIb6Co,2021,Reject,False,Counterfactual Self-Training,"[""Ruijiang Gao"", ""Max Biggs"", ""Wei Sun"", ""Ligong Han""]","[""self-training"", ""counterfactual inference""]",,,,,
tv8n52XbO4p,2021,Reject,False,Learning to Generate Noise for Multi-Attack Robustness,"[""Divyam Madaan"", ""Jinwoo Shin"", ""Sung Ju Hwang""]","[""adversarial learning"", ""robust machine learning"", ""robust optimization"", ""meta learning""]",We propose a novel method that meta-learns a noise generator to improve the generalization and label consistency across multiple attacks.,,,,
tvwNdOKhuF5,2022,Reject,False,Superior Performance with Diversified Strategic Control in FPS Games Using General Reinforcement Learning,"['Shuxing Li', 'Jiawei Xu', 'Chun Yuan', 'peng sun', 'Zhuobin Zheng', 'Zhengyou Zhang', 'Lei Han']","[""Reinforcement Learning"", ""Hindsight Experience Replay"", ""FPS Games""]",This paper offers an overall solution for first-person shooter (FPS) games to achieve superior performance using general reinforcement learning (RL). ,,,,
tw60PTRSda2,2021,Reject,False,Understanding Mental Representations Of Objects Through Verbs Applied To Them,"[""Ka Chun Lam"", ""Francisco Pereira"", ""Maryam Vaziri-Pashkam"", ""Kristin Woodard"", ""Emalie McMahon""]","[""Affordance"", ""affordance embedding"", ""object representation""]",We propose an approach for creating interpretable affordance embedding which can be used to predict mental representation of objects.,,,,
twgEkDwFTP,2022,Reject,False,Understanding Overfitting in Reweighting Algorithms for Worst-group Performance,"['Runtian Zhai', 'Chen Dan', 'J Zico Kolter', 'Pradeep Kumar Ravikumar']","[""Reweighting algorithms"", ""Worst-group performance"", ""Implicit bias"", ""Fairness""]","We prove the pessimistic result that reweighting algorithms always overfit, and a useful regularization must be large enough to lower the training performance.",,,,
twv2QlJhXzo,2022,Accept (Poster),False,Imitation Learning from Observations under Transition Model Disparity,"['Tanmay Gangwani', 'Yuan Zhou', 'Jian Peng']","[""Imitation Learning"", ""Deep Reinforcement Learning""]",Imitation learning from observations when the expert and the learner agents operate in environments with dissimilar transition dynamics models.,,,,
tx4qfdJSFvG,2022,Reject,False,On the Unreasonable Effectiveness of Feature Propagation in Learning on Graphs with Missing Node Features,"['Emanuele Rossi', 'Henry Kenlay', 'Maria I. Gorinova', 'Benjamin Paul Chamberlain', 'Xiaowen Dong', 'Michael M. Bronstein']","[""graph neural networks"", ""missing features"", ""graphs"", ""feature propagation""]","We propose a diffusion-based framework to learn on graphs with missing features, and we show that it can gracefully withstand surprisingly high rates of missing features",,,,
txC1ObHJ0wB,2021,Reject,True,How to Train Your Super-Net: An Analysis of Training Heuristics in Weight-Sharing NAS,"[""Kaicheng Yu"", ""Rene Ranftl"", ""Mathieu Salzmann""]","[""autoML"", ""neural architecture search"", ""NAS"", ""one-shot NAS"", ""weight-sharing NAS"", ""super-net""]",We show that simple random search achieves competitive performance to complex state-of-the-art NAS algorithms when the super-net is properly trained.,2003.04276,cs.LG,2020-03-09 17:34:32+00:00,2020-06-17 13:42:15+00:00
tyTH9kOxcvh,2022,Accept (Poster),False,Modeling Label Space Interactions in Multi-label Classification using Box Embeddings,"['Dhruvesh Patel', 'Pavitra Dangati', 'Jay-Yoon Lee', 'Michael Boratko', 'Andrew McCallum']","[""Multi-label classification"", ""Box Embeddings"", ""Representation Learning"", ""Embeddings""]",Improving the consistency for multi-label classification by modeling label space interactions using Box Embeddings.,,,,
tyd9yxioXgO,2021,Reject,False,Compositional Video Synthesis with Action Graphs,"[""Amir Bar"", ""Roei Herzig"", ""Xiaolong Wang"", ""Gal Chechik"", ""Trevor Darrell"", ""Amir Globerson""]","[""Video Synthesis"", ""Vision and Language"", ""Representation Learning""]","We introduce Action Graphs, a natural and convenient structure representing the dynamics of actions between objects over time. We show we can synthesize goal-oriented videos and generate novel compositions of unseen actions from it on two datasets.",,,,
tyrJsbKAe6,2022,Accept (Poster),False,Pessimistic Model-based Offline Reinforcement Learning under Partial Coverage,"['Masatoshi Uehara', 'Wen Sun']","[""Reinforcement learning Theory"", ""Offline reinforcement learning"", ""PAC Bounds""]",We study model-based offline Reinforcement Learning with general function approximation without a full coverage assumption on the offline data distribution.,,,,
tzO3RXxzuM,2022,Reject,False,Stability based Generalization Bounds for Exponential Family Langevin Dynamics,"['Arindam Banerjee', 'Tiancong Chen', 'Xinyan Li', 'Yingxue Zhou']",[],,2201.03064,cs.LG,2022-01-09 18:15:22+00:00,2022-01-09 18:15:22+00:00
u15gHPQViL,2021,Reject,False,Zero-Shot Recognition through Image-Guided Semantic Classification,"[""Mei-Chen Yeh"", ""Fang Li"", ""Bo-Heng Li""]","[""zero-shot learning"", ""visual-semantic embedding"", ""deep learning""]",,,,,
u2GZOiUTbt,2022,Accept (Poster),False,Task Affinity with Maximum Bipartite Matching in Few-Shot Learning,"['Cat Phuoc Le', 'Juncheng Dong', 'Mohammadreza Soltani', 'Vahid Tarokh']","[""Task Affinity"", ""Transfer Learning"", ""Few-Shot Learning""]",Task affinity and its application in few-shot learning,,,,
u2JeVfXIQa,2022,Reject,False,Adaptive Cross-Layer Attention for Image Restoration,"['Yancheng Wang', 'Yingzhen Yang', 'Chong Chen', 'Ning Xu']","[""image restoration"", ""neural architecture search"", ""non-local attention""]",,,,,
u2YNJPcQlwq,2021,Accept (Poster),True,Efficient Empowerment Estimation for Unsupervised Stabilization,"[""Ruihan Zhao"", ""Kevin Lu"", ""Pieter Abbeel"", ""Stas Tiomkin""]","[""unsupervised stabilization"", ""representation of dynamical systems"", ""neural networks"", ""empowerment"", ""intrinsic motivation""]","We propose an efficient estimation of empowerment which is demonstrated on unsupervised stabilization of dynamical systems, and compared to the existing relevant methods.",2007.07356,cs.LG,2020-07-14 21:10:16+00:00,2021-05-09 06:16:25+00:00
u4C_qLuEpZ,2022,Reject,False,Exploring General Intelligence of Program Analysis for Multiple Tasks,"['Yixin Guo', 'Pengcheng Li', 'Yingwei Luo', 'Xiaolin Wang', 'Zhenlin Wang']","[""GNN"", ""program analysis""]",,,,,
u4WfreuXxnk,2021,Reject,True,Single-Node Attack for Fooling Graph Neural Networks,"[""Ben Finkelshtein"", ""Chaim Baskin"", ""Evgenii Zheltonozhskii"", ""Uri Alon""]","[""graphs"", ""GNN"", ""adversarial"", ""attack""]",GNNs are vulnerable to adversarial attacks from a single attacker node.,2011.03574,cs.LG,2020-11-06 19:59:39+00:00,2020-11-06 19:59:39+00:00
u6TRGdzhfip,2022,Accept (Poster),True,Reliable Adversarial Distillation with Unreliable Teachers,"['Jianing Zhu', 'Jiangchao Yao', 'Bo Han', 'Jingfeng Zhang', 'Tongliang Liu', 'Gang Niu', 'Jingren Zhou', 'Jianliang Xu', 'Hongxia Yang']",[],,2106.04928,cs.LG,2021-06-09 09:22:39+00:00,2021-06-09 09:22:39+00:00
u6s8dSporO8,2022,Accept (Poster),False,Group equivariant neural posterior estimation,"['Maximilian Dax', 'Stephen R Green', 'Jonathan Gair', 'Michael Deistler', 'Bernhard SchÃ¶lkopf', 'Jakob H. Macke']","[""simulation-based inference"", ""likelihood-free inference"", ""machine learning for science"", ""equivariances"", ""group transformations""]",We describe a method to incorporate group equivariances into neural posterior estimation.,,,,
u6sUACr7feW,2022,Reject,False,DPP-TTS: Diversifying prosodic features of speech via determinantal point processes,"['Seongho Joo', 'Kyomin Jung']","[""Text to speech synthesis"", ""determinantal point processes"", ""prosody modeling""]",In this paper we propose DPP-TTS:  a text-to-speech model based on determinantal point processes for diversifying speech prosody.,,,,
u6ybkty-bL,2022,Reject,False,When Complexity Is Good: Do We Need Recurrent Deep Learning For Time Series Outlier Detection?,"['Alexander Capstick', 'Samaneh Kouchaki', 'Mazdak Ghajari', 'David J. Sharp', 'Payam M. Barnaghi']","[""Outlier Detection"", ""Time Series"", ""Deep Learning"", ""Recurrent Neural Networks""]",This paper asks whether we need recurrent deep learning for outlier detection on time series data.,,,,
u7PVCewFya,2022,Reject,False,Losing Less: A Loss for Differentially Private Deep Learning,"['Ali Shahin Shamsabadi', 'Nicolas Papernot']","[""Differentially Private Deep Learning"", ""DP-SGD""]",We propose a novel loss function tailored to specificities of Differentially Private Stochastic Gradient Descent.,,,,
u7UxOTefG2,2022,Reject,True,Uncertainty-based out-of-distribution detection requires suitable function space priors,"[""Francesco D'Angelo"", 'Christian Henning']","[""Bayesian Statistics"", ""Out-of-distribution Detection"", ""Machine Learning"", ""Neural Networks"", ""Epistemic Uncertainty"", ""Gaussian Process""]",We study how principled it is to use Bayesian neural networks for uncertainty-based out-of-distribution detection.,2110.06020,cs.LG,2021-10-12 14:11:37+00:00,2021-10-12 14:11:37+00:00
u846Bqhry_,2021,Reject,False,Asynchronous Modeling: A Dual-phase Perspective for Long-Tailed Recognition,"[""Hu Zhang"", ""Linchao Zhu"", ""Yi Yang""]","[""long-tailed classification"", ""gradient distortion"", ""asynchronous modeling""]",,,,,
u8APpiJX3u,2021,Reject,False,ItNet: iterative neural networks for fast and efficient anytime prediction,"[""Thomas Pfeil""]","[""efficient deep neural network"", ""semantic segmentation"", ""parameter sharing"", ""anytime prediction"", ""tiny network graph"", ""massively parallel hardware systems"", ""recurrent convolutional network""]",We investigate the trade-off between the prediction accuracy and the size of the computational graph to allow the neural network to be executed on massively-parallel hardware systems.,,,,
u8X280hw1Mt,2021,Reject,False,EqCo:   Equivalent Rules for Self-supervised Contrastive Learning,"[""Benjin Zhu"", ""Junqiang Huang"", ""Zeming Li"", ""Xiangyu Zhang"", ""Jian Sun""]",[],,,,,
u9ax42K7ND,2021,Reject,False,Hierarchical Meta Reinforcement Learning for Multi-Task Environments,"[""Dongyang Zhao"", ""Yue Huang"", ""Changnan Xiao"", ""Yue Li"", ""Shihong Deng""]","[""Reinforcement Learning"", ""Multi-task"", ""Hierarchical"", ""Meta Learning""]",A new multi-task environment & a hierarchical meta reinforcement learning framework,,,,
uAX8q61EVRu,2021,Accept (Oral),False,Neural Synthesis of Binaural Speech From Mono Audio,"[""Alexander Richard"", ""Dejan Markovic"", ""Israel D. Gebru"", ""Steven Krenn"", ""Gladstone Alexander Butler"", ""Fernando Torre"", ""Yaser Sheikh""]","[""binaural audio"", ""sound spatialization"", ""neural sound synthesis"", ""binaural speech"", ""speech processing"", ""speech generation""]",We propose an end-to-end approach to neural binaural sound synthesis that for the first time outperforms DSP-based methods in a qualitative evaluation and in a perceptual study.,,,,
uB12zutkXJR,2022,Reject,False,GRAPHIX: A Pre-trained Graph Edit Model for Automated Program Repair,"['Thanh V Nguyen', 'Srinivasan H. Sengamedu']","[""Program Repair"", ""Graph Neural Networks"", ""Pre-training""]",We present a pre-trained graph edit model for automatically detecting and fixing bugs and code quality issues in Java programs,,,,
uBHs6zpY4in,2021,Reject,False,H-divergence: A Decision-Theoretic Probability Discrepancy Measure ,"[""Shengjia Zhao"", ""Abhishek Sinha"", ""Yutong He"", ""Aidan Perreault"", ""Jiaming Song"", ""Stefano Ermon""]","[""probability divergence"", ""two sample test"", ""maximum mean discrepancy""]",,,,,
uCQfPZwRaUu,2021,Accept (Spotlight),False,Data-Efficient Reinforcement Learning with Self-Predictive Representations,"[""Max Schwarzer"", ""Ankesh Anand"", ""Rishab Goel"", ""R Devon Hjelm"", ""Aaron Courville"", ""Philip Bachman""]","[""Reinforcement Learning"", ""Self-Supervised Learning"", ""Representation Learning"", ""Sample Efficiency""]","We propose a temporal, self-supervised objective for RL agents and show that it significantly improves data efficiency in a setting limited to just 2h of gameplay on Atari. ",,,,
uCY5MuAxcxU,2021,Accept (Oral),True,Why Are Convolutional Nets More Sample-Efficient than Fully-Connected Nets?,"[""Zhiyuan Li"", ""Yi Zhang"", ""Sanjeev Arora""]","[""sample complexity separation"", ""equivariance"", ""convolutional neural networks"", ""fully-connected""]",We construct a single natural distribution on which any  fully-connected networks trained with SGD requires \Omega(d^2) samples to generalize while O (1) samples suffices for convolutional architectures.,2010.08515,cs.LG,2020-10-16 17:15:39+00:00,2021-05-04 17:54:15+00:00
uDN8pRAdsoC,2021,Reject,False,Hard Masking for Explaining Graph Neural Networks,"[""Thorben Funke"", ""Megha Khosla"", ""Avishek Anand""]","[""Interpretability"", ""Graph Neural Networks"", ""Hard Masks""]",We propose a novel method to calculate post-hoc explanations of GNNs using discrete explanation masks.,,,,
uEBrNNEfceE,2022,Reject,True,Safe Linear-Quadratic Dual Control with Almost Sure Performance Guarantee,"['Yiwen Lu', 'Yilin Mo']","[""reinforcement learning""]",,2103.13278,eess.SY,2021-03-24 15:51:28+00:00,2021-11-19 14:16:39+00:00
uELnyih9gqb,2021,Reject,False,WAVEQ: GRADIENT-BASED DEEP QUANTIZATION OF NEURAL NETWORKS THROUGH SINUSOIDAL REGULARIZATION,"[""Ahmed T. Elthakeb"", ""Prannoy Pilligundla"", ""Tarek Elgindi"", ""Fatemehsadat Mireshghallah"", ""Charles-Alban Deledalle"", ""Hadi Esmaeilzadeh""]",[],GRADIENT-BASED DEEP QUANTIZATION OF NEURAL NETWORKS THROUGH SINUSOIDAL REGULARIZATION,,,,
uFA24r7v4wL,2021,Reject,False,BDS-GCN: Efficient Full-Graph Training of Graph Convolutional Nets with Partition-Parallelism and Boundary Sampling,"[""Cheng Wan"", ""Youjie Li"", ""Nam Sung Kim"", ""Yingyan Lin""]","[""Graph Neural Networks"", ""Graph Convolutional Networks"", ""Full-Graph Training"", ""Large-Graph Training"", ""Distributed Training"", ""Partition Parallelism"", ""Sampling""]",,,,,
uFBBOJ7xnu,2021,Reject,False,Learning representations from temporally smooth data,"[""Shima Rahimi Moghaddam"", ""Fanjun Bu"", ""Christopher Honey""]","[""biologically plausible"", ""incremental learning"", ""leaky integrator"", ""multiscale"", ""hierarchical processing"", ""timescales""]","We identified simple mechanisms enabling neural networks to learn more quickly from temporally smooth data, and to generate internal representations that separate timescales in the training signal.",,,,
uFHwB6YTxXz,2021,Reject,False,Distribution-Based Invariant Deep Networks for Learning Meta-Features,"[""Gwendoline de Bie"", ""Herilalaina Rakotoarison"", ""Gabriel Peyr\u00e9"", ""Mich\u00e8le Sebag""]","[""invariant neural networks"", ""universal approximation"", ""meta-feature learning""]","Existing distributional-based neural network are extended to achieve invariance under permutation of the features, with theoritical guarantees of universal approximation and robustness, suitable for learning dataset meta-features.",,,,
uF_Wl0xSA7O,2022,Reject,False,Independent Component Alignment for Multi-task Learning,"['Dmitry Senushkin', 'Iaroslav Melekhov', 'Mikhail Romanov', 'Anton Konushin', 'Juho Kannala', 'Arno Solin']","[""multi-task learning"", ""optimization""]",,,,,
uFk038O5wZ,2021,Reject,False,Improving Abstractive Dialogue Summarization with Conversational Structure and Factual Knowledge,"[""Lulu Zhao"", ""Zeyuan Yang"", ""Weiran Xu"", ""Sheng Gao"", ""Jun Guo""]","[""abstractive dialogue summarization"", ""long-distance cross-sentence relation"", ""conversational structure"", ""factual knowledge"", ""sparse relational graph self-attention network"", ""dual-copy mechanism""]",,,,,
uFkGzn9RId8,2021,Reject,True,The act of remembering: A study in partially observable reinforcement learning,"[""Rodrigo Toro Icarte"", ""Richard Valenzano"", ""Toryn Q. Klassen"", ""Phillip Christoffersen"", ""Amir-massoud Farahmand"", ""Sheila A. McIlraith""]","[""Reinforcement Learning"", ""Partial Observability"", ""Memory Representations"", ""External Memories"", ""POMDPs.""]",We study a lightweight approach to tackle partial observability in reinforcement learning by providing an agent with external memory and actions that modify the memory.,2010.01753,cs.LG,2020-10-05 02:56:43+00:00,2020-10-05 02:56:43+00:00
uHNEe2aR4qJ,2021,Reject,False,The Negative Pretraining Effect in Sequential Deep Learning and Three Ways to Fix It,"[""Julian G. Zilly"", ""Franziska Eckert"", ""Bhairav Mehta"", ""Andrea Censi"", ""Emilio Frazzoli""]","[""Transfer learning"", ""Deep learning"", ""Sequential learning"", ""Critical learning periods"", ""Curriculum learning""]",We conceptualize and formalize the problem setting of the negative pretraining effect and offer three empirical interventions to fix it.,,,,
uHjLW-0tsCu,2021,Reject,False,Exploring  the Potential of Low-Bit Training of Convolutional Neural Networks,"[""Kai Zhong"", ""Xuefei Ning"", ""Tianchen Zhao"", ""Zhenhua Zhu"", ""Shulin Zeng"", ""Guohao Dai"", ""Yu Wang"", ""Huazhong Yang""]","[""CNN"", ""training"", ""quantization"", ""low-bit"", ""energy efficiency""]","We propose a low-bit training framework with multi-level scaling tensor format, so that the data bit-width for all the convolution inputs in training can be reduced, and the energy efficiency can be improved.",,,,
uHq5rHHektz,2022,Reject,False,Contextual Fusion For Adversarial Robustness,"['Aiswarya Akumalla', 'Seth D Haney', 'Maxim Bazhenov']","[""Image processing"", ""Neuroscience"", ""Multi-modal representations""]",Fusion between two distinct channels of information can help to overcome adversarial robustness.,,,,
uHv20yi8saL,2022,Reject,False,Monotonic Improvement Guarantees under Non-stationarity for Decentralized PPO,"['Mingfei Sun', 'Sam Devlin', 'Jacob Austin Beck', 'Katja Hofmann', 'Shimon Whiteson']","[""Multi-Agent Reinforcement Learning""]",,,,,
uIc4W6MtbDA,2021,Reject,False,ERMAS: Learning Policies Robust to Reality Gaps in Multi-Agent Simulations,"[""Eric Zhao"", ""Alexander R Trott"", ""Caiming Xiong"", ""Stephan Zheng""]","[""Robustness"", ""Multi-Agent Learning"", ""Sim2Real"", ""Reinforcement Learning""]","ERMAS efficiently trains RL agents that are robust to reality gaps in multi-agent simulations, such as complex economic simulations.",,,,
uJSBC7QCfrX,2021,Reject,False,Differential-Critic GAN: Generating What You Want by a Cue of Preferences,"[""Yinghua Yao"", ""Yuangang Pan"", ""Ivor Tsang"", ""Xin Yao""]","[""GAN"", ""user-desired data distribution"", ""user preference"", ""critic""]","This paper proposes DiCGAN to learn the distribution of user-desired data from the entire dataset using pairwise preferences, where a differential critic is introduced to learn the preference direction from the pairwise preferences.",,,,
uKZsVyFKbaj,2021,Reject,True,It's Hard for Neural Networks to Learn the Game of Life,"[""Jacob M. Springer"", ""Garrett T. Kenyon""]","[""Deep Learning"", ""Game of Life""]","We show that Conway's Game of Life can be represented by a simple neural network, yet find that traditional gradient descent methods do not often converge on a solution without significant overparameterization.",2009.01398,cs.LG,2020-09-03 00:47:08+00:00,2020-09-03 00:47:08+00:00
uKhGRvM8QNH,2021,Accept (Poster),False,Improve Object Detection with Feature-based Knowledge Distillation: Towards Accurate and Efficient Detectors,"[""Linfeng Zhang"", ""Kaisheng Ma""]","[""Knowledge Distillation"", ""Object Detection"", ""Teacher-Student Learning"", ""Non-Local Modules"", ""Attention Modules""]",We propose two knowledge distillation methods on object detection - attention-guided distillation and non-local distillation which lead to 4.1 AP improvements on Faster RCNN101 in MS COCO2017.,,,,
uMDbGsVjCS4,2021,Reject,False,Frequency-aware Interface Dynamics with Generative Adversarial Networks,"[""Lukas Prantl"", ""Tassilo Kugelstadt"", ""Jan Bender"", ""Nils Thuerey""]","[""physical simulations"", ""spatio-temporal dynamics"", ""generative adversarial networks"", ""fluids"", ""elasto-plasticity""]",We present a method for learning frequency-aware interface dynamics of physical systems such as fluids and elasto-plastic materials with Generative Adversarial Networks.,,,,
uMNWbpIQP26,2021,Reject,True,Linear Convergence and Implicit Regularization of Generalized Mirror Descent with Time-Dependent Mirrors,"[""Adityanarayanan Radhakrishnan"", ""Mikhail Belkin"", ""Caroline Uhler""]","[""Generalized Mirror Descent"", ""Linear Convergence"", ""Implicit Regularization""]",We provide sufficient conditions for linear convergence and establish approximate implicit regularization results for generalized mirror descent.,2009.08574,cs.LG,2020-09-18 01:05:14+00:00,2021-10-06 15:09:20+00:00
uPv9Y3gmAI5,2022,Accept (Poster),False,Language model compression with weighted low-rank factorization,"['Yen-Chang Hsu', 'Ting Hua', 'Sungen Chang', 'Qian Lou', 'Yilin Shen', 'Hongxia Jin']","[""model compression"", ""low-rank approximation"", ""transformer"", ""language model""]",Fisher-weighted SVD for language model compression,,,,
uQfOy7LrlTR,2021,Accept (Poster),False,Scaling the Convex Barrier with Active Sets,"[""Alessandro De Palma"", ""Harkirat Behl"", ""Rudy R Bunel"", ""Philip Torr"", ""M. Pawan Kumar""]","[""Neural Network Verification"", ""Neural Network Bounding"", ""Optimisation for Deep Learning""]",We present a specialised dual solver for a tight ReLU convex relaxation and show that it speeds up formal network verification.,,,,
uQnJqzkhrmj,2021,Reject,False,Ranking Cost: One-Stage Circuit Routing by Directly Optimizing Global Objective Function,"[""Shiyu Huang"", ""Bin Wang"", ""Dong Li"", ""Jianye Hao"", ""Jun Zhu"", ""Ting Chen""]","[""Evolution Strategy"", ""Circuit Routing"", ""A*"", ""PCB""]","We propose a new novel algorithm, denoted as Ranking Cost (RC),  to solve the challenging circuit routing problem, and our method combines the search-based method and learning-based method which makes it more powerful, flexible and scalable.",,,,
uR9LaO_QxF,2021,Accept (Poster),False,Efficient Transformers in Reinforcement Learning using Actor-Learner Distillation,"[""Emilio Parisotto"", ""Russ Salakhutdinov""]","[""Deep Reinforcement Learning"", ""Memory"", ""Transformers"", ""Distillation""]",Actor-Learner Distillation uses an continual form of distillation to attain the high sample-efficiency of transformers while maintaining the reduced total training time of LSTMs in RL applications.,,,,
uRKqXoN-Ic9,2021,Reject,False,Evaluating Robustness of Predictive Uncertainty Estimation: Are Dirichlet-based Models Reliable?,"[""Anna-Kathrin Kopetzki"", ""Bertrand Charpentier"", ""Daniel Z\u00fcgner"", ""Sandhya Giri"", ""Stephan G\u00fcnnemann""]",[],,,,,
uRuGNovS11,2021,Reject,False,Bayesian Metric Learning for Robust Training of Deep Models under Noisy Labels,"[""Toan Tran"", ""Hieu Vu"", ""Gustavo Carneiro"", ""Hung Bui""]","[""Noisy labels"", ""Deep metric learning"", ""Bayesian inference"", ""Variational inference""]",This paper aims to introduce a novel theoretically sound Bayesian deep metric learning that is robust against noisy labels. ,,,,
uSE03demja,2022,Accept (Oral),False,RISP: Rendering-Invariant State Predictor with Differentiable Simulation and Rendering for Cross-Domain Parameter Estimation,"['Pingchuan Ma', 'Tao Du', 'Joshua B. Tenenbaum', 'Wojciech Matusik', 'Chuang Gan']","[""differentiable rendering"", ""differentiable simulation"", ""system identification""]",We propose a novel approach to address the problem of identifying parameters characterizing a physical system's dynamic motion directly from a video whose rendering configurations are inaccessible.,,,,
uSYfytRBh-f,2021,Reject,False,Efficiently Troubleshooting Image Segmentation Models with Human-In-The-Loop,"[""Haotao Wang"", ""Tianlong Chen"", ""Zhangyang Wang"", ""Kede Ma""]",[],,,,,
uUAuBTcIIwq,2021,Reject,False,Unsupervised Learning of Global Factors in Deep Generative Models,"[""Ignacio Peis"", ""Pablo M. Olmos"", ""Antonio Art\u00e9s""]","[""unsupervised"", ""autoencoders"", ""disentanglement"", ""generative models"", ""representation learning""]","We present a deep generative model based on non i.i.d. VAEs for capturing global dependencies among observations in a fully unsupervised fashion, leading to global disentanglement, domain alignment and detection of underlying structures.",,,,
uUN0Huq-n_V,2022,Reject,False,Polyphonic Music Composition: An Adversarial Inverse Reinforcement Learning Approach,"['Kelvin Xavier Munguia Velez', 'Von-Wun Soo']","[""music"", ""reinforcement learning"", ""airl"", ""deep learning""]",Polyphonic music composition using adversial inverse reinforcement learning,,,,
uUTx2LOBMV,2021,Reject,False,TextTN: Probabilistic Encoding of Language on Tensor Network,"[""Peng Zhang"", ""Jing Zhang"", ""Xindian Ma"", ""Siwei Rao"", ""Guangjian Tian"", ""Jun Wang""]","[""Tensor Network"", ""Language Representation"", ""Natural Language Processing"", ""Quantum Machine Learning"", ""Entanglement Entropy""]","In this paper, our proposed TextTN exhibits high accuracy that is competitive to the state-of-the-art NNs, while, importantly, maintaining the theoretical analysis of TN's expressive power.",,,,
uUX49ez8P06,2021,Reject,False,Efficient Architecture Search for Continual Learning,"[""Qiang Gao"", ""Zhipeng Luo"", ""Diego Klabjan"", ""Fengli Zhang""]","[""continual learning"", ""reinforcement learning"", ""recurrent neural network"", ""deep neural network""]",Our proposed CLEAS works closely with neural architecture search (NAS) which leverages reinforcement learning techniques to search for the best neural architecture that fits a new task.,,,,
uUlGTEbBRL,2021,Reject,False,Rethinking Compressed Convolution Neural Network from a Statistical Perspective,"[""Feiqing Huang"", ""Yuefeng Si"", ""Guodong Li""]","[""Compressed Convolutional Neural Network"", ""Tensor Decomposition"", ""Sample Complexity Analysis""]",We theoretically explore the mechanism of tensor factorized convolutional neural networks.,,,,
uV7hcsjqM-,2021,Reject,False,Contrastive Code Representation Learning,"[""Paras Jain"", ""Ajay Jain"", ""Tianjun Zhang"", ""Pieter Abbeel"", ""Joseph E. Gonzalez"", ""Ion Stoica""]","[""programming languages"", ""representation learning"", ""contrastive learning"", ""unsupervised learning"", ""self-supervised learning"", ""transfer learning"", ""nlp"", ""pretraining"", ""type inference"", ""summarization""]",We learn to represent programs in a self-supervised manner by using compiler transformations as data augmentations.,,,,
uVTp9Z-IUOC,2022,Reject,True,Test-Time Adaptation to Distribution Shifts by Confidence Maximization and Input Transformation,"['Chaithanya Kumar Mummadi', 'Robin Hutmacher', 'Kilian Rambach', 'Evgeny Levinkov', 'Thomas Brox', 'Jan Hendrik Metzen']","[""natural corruptions"", ""corruption robustness"", ""distribution shift"", ""test time adaptation"", ""domain shift""]","We improve neural network performance on distribution shift (e.g. natural corruptions) in a fully test time adaptation setting with a non-saturating loss function, diversity maximization and input transformation module.",2106.14999,stat.ML,2021-06-28 22:06:10+00:00,2021-06-28 22:06:10+00:00
uVXEKeqJbNa,2022,Accept (Poster),False,Stiffness-aware neural network for learning Hamiltonian systems,"['SENWEI Liang', 'Zhongzhan Huang', 'Hong Zhang']","[""Hamiltonain systems"", ""Neural network"", ""Stiff dynamical systems"", ""Data-driven method""]",,,,,
uVnhiRaW3J,2021,Reject,False,Learning Safe Policies with Cost-sensitive Advantage Estimation,"[""Bingyi Kang"", ""Shie Mannor"", ""Jiashi Feng""]","[""Safe Reinforcement Learning""]",,,,,
uXl3bZLkr3c,2021,Accept (Spotlight),True,Tent: Fully Test-Time Adaptation by Entropy Minimization,"[""Dequan Wang"", ""Evan Shelhamer"", ""Shaoteng Liu"", ""Bruno Olshausen"", ""Trevor Darrell""]","[""deep learning"", ""unsupervised learning"", ""domain adaptation"", ""self-supervision"", ""robustness""]",Deep networks can generalize better during testing by adapting to feedback from their own predictions.,2006.10726,cs.LG,2020-06-18 17:55:28+00:00,2021-03-18 17:58:01+00:00
uYLFoz1vlAC,2022,Accept (Oral),False,Efficiently Modeling Long Sequences with Structured State Spaces,"['Albert Gu', 'Karan Goel', 'Christopher Re']","[""sequence models"", ""state space"", ""RNN"", ""CNN"", ""Long Range Arena""]",We introduce the S3 model based on new algorithms for state spaces that is particularly effective on long-range dependencies.,,,,
u_bGm5lrm72,2021,Reject,True,DIET-SNN: A Low-Latency Spiking Neural Network with Direct Input Encoding & Leakage and Threshold Optimization,"[""Nitin Rathi"", ""Kaushik Roy""]","[""Spiking neural networks"", ""threshold optimization"", ""leak optimization"", ""input encoding"", ""deep convolutional networks""]",Gradient based training of threshold and leak in deep spiking networks to achieve high activation sparsity and low inference latency,2008.03658,cs.NE,2020-08-09 05:07:17+00:00,2020-12-02 02:55:31+00:00
uc8UsmcInvB,2022,Reject,False,Statistically Meaningful Approximation: a Theoretical Analysis for Approximating Turing Machines with Transformers,"['Colin Wei', 'Yining Chen', 'Tengyu Ma']","[""approximation theory"", ""generalization bounds"", ""sample complexity bounds"", ""learning theory""]","We propose a new theoretical notion of ""statistically meaningful"" approximation and prove that neural nets can statistically-meaningfully approximate Boolean circuits and Turing machines.",,,,
ucASPPD9GKN,2022,Accept (Poster),True,Is Homophily a Necessity for Graph Neural Networks?,"['Yao Ma', 'Xiaorui Liu', 'Neil Shah', 'Jiliang Tang']",[],,2106.06134,cs.LG,2021-06-11 02:44:00+00:00,2021-10-18 15:29:38+00:00
ucEXZQncukK,2021,Reject,False,Bayesian Online Meta-Learning,"[""Pauching Yap"", ""Hippolyt Ritter"", ""David Barber""]","[""Bayesian online learning"", ""few-shot learning"", ""meta-learning""]","We introduce the BOML framework that can few-shot classify tasks originating from different distributions, and can handle few-shot online learning in sequential tasks setting.",,,,
ucuia1JiY9,2021,Reject,False,A Probabilistic Approach to Constrained Deep Clustering,"[""Laura Manduchi"", ""Kieran Chin-Cheong"", ""Holger Michel"", ""Sven Wellmann"", ""Julia E Vogt""]","[""constrained clustering"", ""semi-supervised representation learning"", ""generative model"", ""deep learning""]","We present a novel deep constrained clustering method, CVaDE, that incorporates clustering preferences in the form of pairwise constraints, with varying degrees of certainty.",,,,
udaowxM8rz,2021,Reject,False,Increasing the Coverage and Balance of Robustness Benchmarks by Using Non-Overlapping Corruptions,"[""Alfred LAUGROS"", ""Alice Caplier"", ""Matthieu Ospici""]","[""Computer Vision"", ""Robustness"", ""Common Corruptions"", ""Benchmark""]",,,,,
udbMZR1cKE6,2021,Reject,False,Grounding Language to Entities for Generalization in Reinforcement Learning,"[""H. J. Austin Wang"", ""Karthik R Narasimhan""]","[""reinforcement learning"", ""language grounding""]",We use textual descriptions to improve generalization of control policies to new environments without prior knowledge connecting text and state observations.,,,,
ue4CArRAsct,2022,Reject,False,Structure by Architecture: Disentangled Representations without Regularization,"['Felix Leeb', 'Giulia Lanzillotta', 'Yashas Annadani', 'Michel Besserve', 'Stefan Bauer', 'Bernhard SchÃ¶lkopf']","[""Autoencoder"", ""Structure"", ""Disentanglement"", ""Generative"", ""Hybridization""]",A novel autoencoder architecture to structure the learned representation and make use of independence for improved sampling.,,,,
ueiBFzt7CiK,2021,Reject,False,A Framework For Differentiable Discovery Of Graph Algorithms,"[""Hanjun Dai"", ""Xinshi Chen"", ""Yu Li"", ""Xin Gao"", ""Le Song""]","[""graph neural networks"", ""combinatorial optimization"", ""differentiable search"", ""model explanation""]",A framework for discovering explainable graph combinatorial optimization algorithms,,,,
ufGMqIM0a4b,2022,Accept (Poster),True,InfinityGAN: Towards Infinite-Pixel Image Synthesis,"['Chieh Hubert Lin', 'Hsin-Ying Lee', 'Yen-Chi Cheng', 'Sergey Tulyakov', 'Ming-Hsuan Yang']","[""generative modeling"", ""image synthesis"", ""generative adversarial networks"", ""infinite-pixel synthesis"", ""GANs""]",InfinityGAN learns to synthesize arbitrary-sized images with limited resources and enables multiple new applications.,2104.03963,cs.CV,2021-04-08 17:59:30+00:00,2021-10-07 09:22:26+00:00
ufS1zWbRCEa,2021,Reject,False,Parallel Training of Deep Networks with Local Updates,"[""Michael Laskin"", ""Luke Metz"", ""Seth Nabarro"", ""Mark Saroufim"", ""Badreddine Noune"", ""Carlo Luschi"", ""Jascha Sohl-Dickstein"", ""Pieter Abbeel""]","[""deep learning"", ""parallelized training"", ""local learning"", ""compute-efficient learning"", ""hebbian learning"", ""biologically inspired learning""]",We perform a large scale investigation into parallelized training with local update methods for deep neural networks and show that local parallelism enables compute-efficiency gains in the high-compute regime compared to data parallelism.,2012.03837,cs.LG,2020-12-07 16:38:45+00:00,2021-06-15 14:50:45+00:00
ufZN2-aehFa,2021,Accept (Poster),False,Bayesian Context Aggregation for Neural Processes,"[""Michael Volpp"", ""Fabian Fl\u00fcrenbrock"", ""Lukas Grossberger"", ""Christian Daniel"", ""Gerhard Neumann""]","[""Aggregation Methods"", ""Neural Processes"", ""Latent Variable Models"", ""Meta Learning"", ""Multi-task Learning"", ""Deep Sets""]",We propose a Bayesian Aggregation mechanism for Neural Process-based models which improves upon traditional mean aggregation.,,,,
ugxdsne_TlO,2022,Reject,False,GCF: Generalized Causal Forest for Heterogeneous Treatment Effect Estimation Using Nonparametric Methods,"['Shu Wan', 'Chen Zheng', 'Zhonggen Sun', 'Mengfan Xu', 'Xiaoqing Yang', 'Jiecheng Guo', 'Hongtu Zhu']","[""Heterogeneous Treatment Effect"", ""Causal Inference"", ""Double/Debiased Machine Learning"", ""Continuous Treatment""]",We propose Generalized Causal Forest to efficiently estimate continuous treatment effects using a kernel-based DML estimator and a distance-based splitting criterion.,,,,
uhiF-dV99ir,2021,Reject,False,Visualizing High-Dimensional Trajectories on the Loss-Landscape of ANNs,"[""Stefan Horoi"", ""Jessie Huang"", ""Guy Wolf"", ""Smita Krishnaswamy""]",[],,2102.00485,cs.LG,2021-01-31 16:30:50+00:00,2021-01-31 16:30:50+00:00
uie1cYdC2B,2021,Reject,False,A Simple Unified Information Regularization Framework for Multi-Source Domain Adaptation,"[""Geon Yeong Park"", ""Sang wan Lee""]","[""Multi-source Domain Adaptation"", ""Transfer learning"", ""Adversarial learning"", ""Information theory""]","This paper proposes an adversarial multi-source, unsupervised domain adaptation algorithm with a theoretical justification for using a single domain discriminator.",2104.01568,cs.LG,2021-04-04 09:11:35+00:00,2021-04-04 09:11:35+00:00
ujmgfuxSLrO,2021,Accept (Poster),False,DeLighT: Deep and Light-weight Transformer,"[""Sachin Mehta"", ""Marjan Ghazvininejad"", ""Srinivasan Iyer"", ""Luke Zettlemoyer"", ""Hannaneh Hajishirzi""]","[""Transformers"", ""Sequence Modeling"", ""Machine Translation"", ""Language Modeling"", ""Representation learning"", ""Efficient Networks""]",Deep and light-weight transformer that matches or improves the performance of baseline Transformers with 2 to 3 times fewer parameters on standard machine translation and language modeling tasks,,,,
umIdUL8rMH,2021,Accept (Poster),True,BOIL: Towards Representation Change for Few-shot Learning,"[""Jaehoon Oh"", ""Hyungjun Yoo"", ""ChangHwan Kim"", ""Se-Young Yun""]",[],"We propose a novel meta-learning algorithm, BOIL, based on representation change.",2008.08882,cs.LG,2020-08-20 10:52:23+00:00,2021-03-03 05:16:52+00:00
unI5ucw_Jk,2021,Accept (Poster),False,Explaining by Imitating: Understanding Decisions by Interpretable Policy Learning,"[""Alihan H\u00fcy\u00fck"", ""Daniel Jarrett"", ""Cem Tekin"", ""Mihaela van der Schaar""]","[""interpretable policy learning"", ""understanding decision-making""]","We present a method for learning interpretable representations of behavior to enable auditing, quantifying, and understanding human decision-making processes.",,,,
uoBAKAFkVKx,2022,Reject,False,Hypothesis Driven Coordinate Ascent for Reinforcement Learning,"['John Kenton Moore', 'Junier Oliva']","[""Reinforcement Learning"", ""Black-Box Optimization"", ""Hypothesis Testing"", ""Coordinate Ascent"", ""Block Coordinate Ascent"", ""Random Search"", ""MDP""]",This work develops a novel black box optimization technique that combines coordinate ascent with hypothesis testing to learn robust policies for stochastic environments.,,,,
uorVGbWV5sw,2022,Accept (Spotlight),False,Strength of Minibatch Noise in SGD,"['Liu Ziyin', 'Kangqiao Liu', 'Takashi Mori', 'Masahito Ueda']","[""stochastic gradient descent"", ""minibatch noise"", ""discrete-time SGD"", ""noise and fluctuation"", ""exact solvable models""]",We solve the strength and shape of the minibatch noise in SGD exactly. ,,,,
upnDJ7itech,2022,Accept (Poster),False,Knowledge Infused Decoding,"['Ruibo Liu', 'Guoqing Zheng', 'Shashank Gupta', 'Radhika Gaonkar', 'Chongyang Gao', 'Soroush Vosoughi', 'Milad Shokouhi', 'Ahmed Hassan Awadallah']","[""natural language"", ""decoding"", ""reinforcement learning"", ""knowledge integration"", ""generation""]","We propose a new decoding algorithm for language model generation, to obtain better performance in knowledge-intensive tasks.",,,,
uqBOne3LUKy,2022,Accept (Poster),False,Is Importance Weighting Incompatible with Interpolating Classifiers?,"['Ke Alexander Wang', 'Niladri Shekhar Chatterji', 'Saminul Haque', 'Tatsunori Hashimoto']","[""overparameterization"", ""distribution shifts"", ""importance weighting"", ""implicit bias"", ""generalization analysis"", ""interpolation""]",We theoretically and empirically demonstrate that importance weighting can be effective in handling distribution shifts in overparameterized classifiers.,,,,
uqD-un_Mzd-,2021,Reject,False,Polynomial Graph Convolutional Networks,"[""Luca Pasa"", ""Nicol\u00f2 Navarin"", ""Alessandro Sperduti""]","[""Graph Convolutional Networks"", ""Graph Neural Network"", ""Deep Learning"", ""Structured Data"", ""Machine Learning on Graphs""]","The contribution of this paper is toÂ propose the Polynomial Graph ConvolutionalÂ Network, where the depth of the network is decoupled from the receptive field size, allowing to build deep Graph Neural Networks avoiding the oversmoothing problem.",,,,
uut_j3UrRCg,2022,Reject,False,Provable hierarchical lifelong learning with a sketch-based modular architecture,"['Rina Panigrahy', 'Brendan Juba', 'Zihao Deng', 'Xin Wang', 'Zee Fryer']",[],,,,,
uvEgLKYMBF9,2021,Reject,False,Variance Reduction in Hierarchical Variational Autoencoders,"[""Adeel Pervez"", ""Efstratios Gavves""]",[],,,,,
uwnOHjgUrTa,2022,Reject,False,DNN Quantization with Attention,"['Ghouthi BOUKLI HACENE', 'Lukas Mauch', 'Shubhankar Chowdhury', 'Stefan Uhlich', 'Fabien Cardinaux']","[""Deep learning"", ""Computer vision"", ""Quantization""]",Improving existing quantization methods using a learnable relaxation method,,,,
uxYjVEXx48i,2021,Reject,False,An Examination of Preference-based Reinforcement Learning for Treatment Recommendation,"[""Nan Xu"", ""Nitin Kamra"", ""Yan Liu""]","[""Preference-based Reinforcement Learning"", ""Treatment Recommendation"", ""healthcare""]",Develop a simulation platform and investigate preference-based reinforcement learning approaches for treatment recommendation,,,,
uxgg9o7bI_3,2022,Accept (Oral),False,"A New Perspective on ""How Graph Neural Networks Go Beyond Weisfeiler-Lehman?""","['Asiri Wijesinghe', 'Qing Wang']","[""Graph Neural Networks"", ""Graph Isomorphism"", ""Weisfeiler Lehman""]",,,,,
uxpzitPEooJ,2021,Accept (Poster),False,Graph Coarsening with Neural Networks,"[""Chen Cai"", ""Dingkang Wang"", ""Yusu Wang""]","[""graph coarsening"", ""graph neural network"", ""Doubly-weighted Laplace operator""]",We significantly improve the quality of existing graph coarsening algorithms with graph neural network.,2102.01350,cs.LG,2021-02-02 06:50:07+00:00,2021-02-02 06:50:07+00:00
uxxFrDwrE7Y,2022,Accept (Poster),False,"Learning Fast, Learning Slow: A General Continual Learning Method based on Complementary Learning System","['Elahe Arani', 'Fahad Sarfraz', 'Bahram Zonooz']","[""Continual Learning"", ""Catastrophic Forgetting"", ""Complementary Learning Systems Theory"", ""Experience Replay""]",A dual memory experience replay method which aims to mimic the interplay between fast learning and slow learning mechanisms for enabling effective CL in DNNs.,2201.12604,cs.LG,2022-01-29 15:15:23+00:00,2022-01-29 15:15:23+00:00
uy602F8cTrh,2022,Reject,False,CausalDyna: Improving Generalization of Dyna-style Reinforcement Learning via Counterfactual-Based Data Augmentation,"['Deyao Zhu', 'Li Erran Li', 'Mohamed Elhoseiny']",[],,,,,
uydP1ykieNv,2022,Reject,True,Ensemble-in-One: Learning Ensemble within Random Gated Networks for Enhanced Adversarial Robustness,"['Yi Cai', 'Xuefei Ning', 'Huazhong Yang', 'Yu Wang']","[""Adversarial robustness"", ""ensemble learning"", ""random gated network"", ""parameter sharing""]",Ensemble-in-One augments a network into multi-path random-gated network to provide great scalability for conducting ensemble. The adversarial robustness of CNN model can be significantly improved without sacrificing the clean accuracy much. ,2103.14795,cs.LG,2021-03-27 03:13:03+00:00,2021-03-27 03:13:03+00:00
uys9OcmXNtU,2021,Reject,True,MQTransformer: Multi-Horizon Forecasts with Context Dependent and Feedback-Aware Attention,"[""Carson Eisenach"", ""Yagna Patel"", ""Dhruv Madeka""]",[],,2009.14799,cs.LG,2020-09-30 17:12:46+00:00,2020-12-02 21:14:11+00:00
uz5uw6gM0m,2021,Accept (Poster),False,One Network Fits All? Modular versus Monolithic Task Formulations in Neural Networks,"[""Atish Agarwala"", ""Abhimanyu Das"", ""Brendan Juba"", ""Rina Panigrahy"", ""Vatsal Sharan"", ""Xin Wang"", ""Qiuyi Zhang""]","[""deep learning theory"", ""multi-task learning""]","Theoretical bounds and experimental results showing that neural networks trained with SGD can provably solve multiple, very different tasks simultaneously.",2103.15261,cs.LG,2021-03-29 01:16:42+00:00,2021-03-29 01:16:42+00:00
v-27phh2c8O,2022,Reject,False,AARL: Automated Auxiliary Loss for Reinforcement Learning,"['Tairan He', 'Yuge Zhang', 'Kan Ren', 'Che Wang', 'Weinan Zhang', 'Dongsheng Li', 'Yuqing Yang']","[""Reinforcement learning"", ""Representation learning"", ""Auxiliary Loss""]","In this work, we introduce Automated Auxiliary Loss for Reinforcement Learning (AARL), a principled approach that automatically searches for the optimal auxiliary loss function for RL. ",,,,
v-9E8egy_i,2021,Reject,False,Gated Relational Graph Attention Networks,"[""Denis Lukovnikov"", ""Asja Fischer""]","[""graph neural networks"", ""GNN"", ""long-range dependencies"", ""deep GNN"", ""relational GNN""]",We propose a novel GAT-based architecture to better model long-range patterns in multi-relational graphs.,,,,
v-f7ifhKYps,2022,Reject,False,Maximum Entropy Population Based Training for Zero-Shot Human-AI Coordination,"['Rui Zhao', 'Jinming Song', 'Hu Haifeng', 'Yang Gao', 'Yi Wu', 'Zhongqian Sun', 'Yang Wei']","[""Human-AI Coordination"", ""Reinforcement Learning"", ""Zero-Shot Human-AI Coordination"", ""Deep Reinforcement Learning""]","This paper introduces Maximum Entropy Population-based training (MEP), a deep reinforcement learning method for robust human-AI coordination.",,,,
v-v1cpNNK_v,2022,Accept (Poster),True,NASI: Label- and Data-agnostic Neural Architecture Search at Initialization,"['Yao Shu', 'Shaofeng Cai', 'Zhongxiang Dai', 'Beng Chin Ooi', 'Bryan Kian Hsiang Low']","[""Neural Architecture Search"", ""Initialization"", ""Label- and Data-agnostic"", ""Transferability"", ""Neural Tangent Kernel""]",,2109.00817,cs.LG,2021-09-02 09:49:28+00:00,2021-09-02 09:49:28+00:00
v2tmeZVV9-c,2021,Reject,False,Accurately Solving Rod Dynamics with Graph Learning,"[""Han Shao"", ""Tassilo Kugelstadt"", ""Torsten H\u00e4drich"", ""Wojciech Pa\u0142ubicki"", ""Jan Bender"", ""Soren Pirk"", ""Dominik Michels""]","[""Dynamical Systems"", ""Representation Learning""]",We introduce a novel method to accelerate iterative solvers for physical systems with graph networks by predicting the initial guesses to reduce the number of iterations.,,,,
v3LXWP63qOZ,2022,Reject,False,Learning Minimal Representations with Model Invariance,"['Manan Tomar', 'Amy Zhang', 'Matthew E. Taylor']","[""Representation Learning"", ""Minimal Representations"", ""Reinforcement Learning"", ""Self-supervised Learning""]","A practical method for learning minimal-sufficient representations, with applications to both RL and Vision.",,,,
v3aeIsY_vVX,2022,Accept (Poster),True,Chunked Autoregressive GAN for Conditional Waveform Synthesis,"['Max Morrison', 'Rithesh Kumar', 'Kundan Kumar', 'Prem Seetharaman', 'Aaron Courville', 'Yoshua Bengio']","[""audio generation"", ""speech synthesis"", ""deep learning"", ""generative models"", ""autoregression"", ""generative adversarial networks""]",We improve the state-of-the-art of conditional waveform synthesis by combining the strengths of GANs and autoregression,2110.10139,eess.AS,2021-10-19 17:48:12+00:00,2021-10-19 17:48:12+00:00
v5WXtSXsVCJ,2021,Reject,False,Faster Training of Word Embeddings,"[""Eliza Wszola"", ""Martin Jaggi"", ""Markus P\u00fcschel""]","[""multicore"", ""performance"", ""machine learning"", ""word embeddings"", ""word2vec"", ""fasttext""]","Design, hardware-oriented implementation and evaluation of various algorithmic variants of fastText and word2vec",,,,
v5gjXpmR8J,2021,Accept (Poster),False,SSD: A Unified Framework for Self-Supervised Outlier Detection,"[""Vikash Sehwag"", ""Mung Chiang"", ""Prateek Mittal""]","[""Outlier detection"", ""Out-of-distribution detection in deep learning"", ""Anomaly detection with deep neural networks"", ""Self-supervised learning""]",We achieve competitive performance on outlier/out-of-distribution detection using only unlabeled training data.,,,,
v6s3HVjPerv,2022,Accept (Poster),False,"Do Users Benefit From Interpretable Vision? A User Study, Baseline, And Dataset","['Leon Sixt', 'Martin Schuessler', 'Oana-Iuliana Popescu', 'Philipp WeiÃ', 'Tim Landgraf']","[""Interpretable ML"", ""User Study"", ""Human Subject Evaluation"", ""Invertible Neural Networks"", ""Convolutional Networks""]","Do Users Benefit From Interpretable Vision? A User Study, Baseline, And Dataset",,,,
v8OlxjGn23S,2022,Accept (Poster),False,Low-Budget Active Learning via Wasserstein Distance: An Integer Programming Approach,"['Rafid Mahmood', 'Sanja Fidler', 'Marc T Law']","[""active learning"", ""integer optimization""]",We propose an integer optimization problem for active learning and demonstrate how optimally selecting which points to label can significantly improve classifiers under low labeling budgets.,,,,
v8b3e5jN66j,2021,Accept (Poster),True,Conditional Negative Sampling for Contrastive Learning of Visual Representations,"[""Mike Wu"", ""Milan Mosse"", ""Chengxu Zhuang"", ""Daniel Yamins"", ""Noah Goodman""]","[""contrastive learning"", ""hard negative mining"", ""mutual information"", ""lower bound"", ""detection"", ""segmentation"", ""MoCo""]",Theoretical and experimental evidence that choosing difficult negative examples in contrastive learning can learn stronger representations as measured by several downstream tasks and image distributions.,2010.02037,cs.LG,2020-10-05 14:17:32+00:00,2020-10-05 14:17:32+00:00
v9c7hr9ADKx,2021,Accept (Spotlight),False,UPDeT: Universal Multi-agent RL via Policy Decoupling with Transformers,"[""Siyi Hu"", ""Fengda Zhu"", ""Xiaojun Chang"", ""Xiaodan Liang""]","[""Multi-agent Reinforcement Learning"", ""Transfer Learning""]",,,,,
v9hAX77--cZ,2021,Accept (Poster),False,Learning Structural Edits via Incremental Tree Transformations,"[""Ziyu Yao"", ""Frank F. Xu"", ""Pengcheng Yin"", ""Huan Sun"", ""Graham Neubig""]","[""Tree-structured Data"", ""Edit"", ""Incremental Tree Transformations"", ""Representation Learning"", ""Imitation Learning"", ""Source Code""]",A generic incremental editing model for tree-structured data,2101.12087,cs.LG,2021-01-28 16:11:32+00:00,2021-03-05 00:46:18+00:00
vA7doMdgi75,2022,Accept (Spotlight),False,Implicit Bias of Projected Subgradient Method Gives Provable Robust Recovery of Subspaces of Unknown Codimension,"['Paris Giampouras', 'Benjamin David Haeffele', 'Rene Vidal']","[""representation learning"", ""robust subspace recovery"", ""dual principals component pursuit"", ""outliers"", ""model selection""]",We study the robust subspace recovery problem when subspace codimension is unknown.,,,,
vBn2OXZuQCF,2022,Reject,False,How does Contrastive Pre-training Connect Disparate Domains?,"['Kendrick Shen', 'Robbie Matthew Jones', 'Ananya Kumar', 'Sang Michael Xie', 'Percy Liang']","[""pre-training"", ""contrastive learning"", ""robustness"", ""out-of-distribution"", ""domain shift""]","Off-the-shelf contrastive pre-training is a competitive method for domain adaptation, and we develop a connectivity framework to understand how it learns representations that generalize across domains.",,,,
vC8hNRk9dOR,2021,Reject,False,Evaluating Online Continual Learning with CALM,"[""Germ\u00e1n Kruszewski"", ""Ionut Teodor Sorodoc"", ""Tomas Mikolov""]","[""online continual learning"", ""catastrophic forgetting"", ""benchmark"", ""language modelling""]","We introduce a benchmark for Online Continual Learning based on language modelling, evaluating multiple baselines and improving one of them.",,,,
vCEhC7nOb6,2021,Reject,False,Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets,"[""Depen Morwani"", ""Harish Guruprasad Ramaswamy""]","[""Deep Learning Theory"", ""Weight Normalization"", ""Inductive Bias"", ""Gradient Descent""]",,,,,
vDa28vlSBCP,2022,Reject,True,Interactively Generating Explanations for Transformer Language Models,"['Patrick Schramowski', 'Felix Friedrich', 'Christopher Tauchmann', 'Kristian Kersting']",[],,2110.02058,cs.CL,2021-09-02 11:34:29+00:00,2021-10-07 08:00:10+00:00
vDwBW49HmO,2022,Accept (Poster),False,Gradient Matching for Domain Generalization,"['Yuge Shi', 'Jeffrey Seely', 'Philip Torr', 'Siddharth N', 'Awni Hannun', 'Nicolas Usunier', 'Gabriel Synnaeve']","[""Domain generalization"", ""multi-source domain adaptation""]",We propose to learn features that are invariant across domains by maximizing the gradient inner product between domains.,,,,
vEIVxSN8Xhx,2022,Reject,True,Log-Polar Space Convolution,"['Bing Su', 'Ji-Rong Wen']",[],,2107.11943,cs.CV,2021-07-26 03:41:40+00:00,2021-07-26 03:41:40+00:00
vEZyTBRPP6o,2022,Accept (Poster),True,Actor-critic is implicitly biased towards high entropy optimal policies,"['Yuzheng Hu', 'Ziwei Ji', 'Matus Telgarsky']","[""implicit bias"", ""reinforcement learning"", ""actor-critic"", ""policy gradient"", ""mixing time"", ""convergence rate"", ""mirror ascent.""]","We show that actor-critic, without any explicit exploration or regularization, can obtain an $\epsilon$-optimal high entropy policy in $\text{poly}(1/\epsilon)$ samples via a single trajectory without the usual uniform mixing assumptions.",2110.11280,cs.LG,2021-10-21 17:06:59+00:00,2021-10-21 17:06:59+00:00
vHVcB-ak3Si,2022,Accept (Poster),False,Dive Deeper Into Integral Pose Regression,"['Kerui Gu', 'Linlin Yang', 'Angela Yao']",[],,,,,
vIC-xLFuM6,2022,Accept (Poster),False,Overcoming The Spectral Bias of Neural Value Approximation,"['Ge Yang', 'Anurag Ajay', 'Pulkit Agrawal']","[""spectral bias"", ""neural value approximation"", ""Q learning"", ""reinforcement learning"", ""neural tangent kernels"", ""kernel regression""]",Overcoming the spectral bias of neural value approximation via fourier features,,,,
vJZ7dPIjip3,2022,Accept (Poster),True,Generalization of Neural Combinatorial Solvers Through the Lens of Adversarial Robustness,"['Simon Geisler', 'Johanna Sommer', 'Jan Schuchardt', 'Aleksandar Bojchevski', 'Stephan GÃ¼nnemann']","[""Generalization"", ""Neural Combinatorial Optimization"", ""Adversarial Robustness""]",We study the generalization of combinatorial optimization w.r.t. to adversarial attacks since current evaluation protocols are too optimistic and we show that neural solvers are indeed vulnerable under label-preserving perturbations.,2110.10942,cs.LG,2021-10-21 07:28:11+00:00,2021-10-21 07:28:11+00:00
vJb4I2ANmy,2022,Accept (Poster),True,Noisy Feature Mixup,"['Soon Hoe Lim', 'N. Benjamin Erichson', 'Francisco Utrera', 'Winnie Xu', 'Michael W. Mahoney']","[""Data augmentation"", ""implicit regularization"", ""mixup"", ""noise injection"", ""model robustness""]","We propose and study Noisy Feature Mixup, a simple yet effective data augmentation method that leads to improved model robustness when compared to training with manifold mixup or noise injection alone.",2110.02180,cs.LG,2021-10-05 17:13:51+00:00,2021-11-21 13:50:36+00:00
vK9WrZ0QYQ,2021,Accept (Poster),True,Deep Neural Tangent Kernel and Laplace Kernel Have the Same RKHS,"[""Lin Chen"", ""Sheng Xu""]","[""Neural tangent kernel"", ""Reproducing kernel Hilbert space"", ""Laplace kernel"", ""Singularity analysis""]",We prove that the reproducing kernel Hilbert spaces of a deep neural tangent kernel and the Laplace kernel include the same set of functions.,2009.10683,cs.LG,2020-09-22 16:58:26+00:00,2021-03-18 14:56:31+00:00
vKMVrqvXbXu,2022,Reject,False,Effects of Data Geometry in Early Deep Learning,"['Saket Tiwari', 'George Konidaris']","[""Deep learning"", ""geometry"", ""manifolds"", ""deep learning theory""]",We provide theoretical results for understanding the capacity of neural networks in light of the manifold hypothesis and corroborate them with experiments.,,,,
vLaHRtHvfFp,2021,Accept (Poster),True,PDE-Driven Spatiotemporal Disentanglement,"[""J\u00e9r\u00e9mie Don\u00e0"", ""Jean-Yves Franceschi"", ""sylvain lamprier"", ""patrick gallinari""]","[""disentanglement"", ""spatiotemporal prediction"", ""representation learning"", ""dynamical systems"", ""separation of variables""]","We introduce a novel interpretation of spatiotemporal disentanglement, inducing a simple and performant disentangled prediction model.",2008.01352,cs.LG,2020-08-04 06:10:30+00:00,2021-03-23 09:44:40+00:00
vLz0e9S-iF3,2022,Reject,True,Quasi-potential theory for escape problem: Quantitative sharpness effect on SGD's escape from local minima,"['Hikaru Ibayashi', 'Masaaki Imaizumi']","[""deep learning"", ""learning dynamics"", ""SGD"", ""flat minima""]","We develop a novel quasi-potential theory for the escape of SGD, which is more formal and flexible than existing theories.",2111.04004,cs.LG,2021-11-07 05:00:35+00:00,2021-11-07 05:00:35+00:00
vNw0Gzw8oki,2021,Reject,False,Physics Informed Deep Kernel Learning,"[""Zheng Wang"", ""Wei Xing"", ""Robert Kirby"", ""Shandian Zhe""]","[""Deep Kernel"", ""Bayesian Learning""]",,,,,
vOchfRdvPy7,2021,Reject,False,To be Robust or to be Fair: Towards Fairness in Adversarial Training,"[""Han Xu"", ""Xiaorui Liu"", ""Yaxin Li"", ""Jiliang Tang""]","[""Adversarial Examples"", ""Robustness"", ""Safety"", ""Fairness""]",Adversarial training may cause unfair accuracy & robustness disparity between various groups of data. ,,,,
vPK-G5HbnWg,2022,Reject,False,PACE: A Parallelizable Computation Encoder for Directed Acyclic Graphs,"['Zehao Dong', 'Muhan Zhang', 'Fuhai Li', 'Yixin Chen']","[""DAG encoder"", ""graph neural network"", ""Transformer""]",This paper introduces a novel DAG encoder based on Transformer to encode the computation structure defined by DAGs in a fully parallelizable manner.,,,,
vQmIksuciu2,2022,Reject,False,EXPLAINABLE AI-BASED DYNAMIC FILTER PRUNING OF CONVOLUTIONAL NEURAL NETWORKS,"['Muhammad Sabih', 'Frank Hannig', 'JÃ¼rgen Teich']","[""XAI"", ""Pruning"", ""CNN"", ""Explainable-AI""]","This paper proposes dynamic pruning method, which utilizes early exit along with early coarse prediction based on explainable AI to reduce average latency of inference as well longest-path latency of inference for CNNs.",,,,
vQzcqQWIS0q,2021,Accept (Poster),False,Learnable Embedding sizes for Recommender Systems,"[""Siyi Liu"", ""Chen Gao"", ""Yihong Chen"", ""Depeng Jin"", ""Yong Li""]","[""Recommender Systems"", ""Deep Learning"", ""Embedding Size""]",Learning flexible feature-aware embedding sizes effectively and efficiently for recommendation models.,2101.07577,cs.LG,2021-01-19 11:50:33+00:00,2021-03-11 10:38:59+00:00
vRhkfX8G_H9,2022,Reject,False,SpSC: A Fast and Provable Algorithm for Sampling-Based GNN Training,"['Shihui Song', 'Peng Jiang']",[],,,,,
vSix3HPYKSU,2022,Accept (Spotlight),False,Message Passing Neural PDE Solvers,"['Johannes Brandstetter', 'Daniel E. Worrall', 'Max Welling']","[""neural PDE solvers"", ""message passing"", ""autoregressive models"", ""zero-stability""]",This paper introduces a message passing neural PDE solver that replaces all heuristically designed components in numerical PDE solvers with backprop-optimized neural function approximators. ,,,,
vSttC0bV3Ji,2021,Reject,False,Deep Convolution for Irregularly Sampled Temporal Point Clouds,"[""Erich Merrill III"", ""Stefan Lee"", ""Li Fuxin"", ""Thomas G Dietterich"", ""Alan Fern""]","[""point cloud"", ""convolution"", ""irregular sampling"", ""starcraft"", ""nowcasting""]",We use a set function which is equivalent to convolution to reason about irregularly sampled spatio-temporal point clouds and make predictions for arbitrary domain-specific queries.,,,,
vT0NSQlTA,2021,Reject,True,Learning to Plan Optimistically: Uncertainty-Guided Deep Exploration via Latent Model Ensembles,"[""Tim Seyde"", ""Wilko Schwarting"", ""Sertac Karaman"", ""Daniela Rus""]","[""Model-Based Reinforcement Learning"", ""Deep Exploration"", ""Continuous Visual Control"", ""UCB"", ""Latent Space"", ""Ensembling""]","Our RL algorithm for visual control in continuous state-action spaces enables deep exploration by training its policy on a UCB objective over predicted infinite-horizon returns, derived via latent model ensembling and value function estimation.",2010.14641,cs.LG,2020-10-27 22:06:57+00:00,2021-01-11 09:02:23+00:00
vUH85MOXO7h,2022,Accept (Poster),True,A Neural Tangent Kernel Perspective of Infinite Tree Ensembles,"['Ryuichi Kanoh', 'Mahito Sugiyama']","[""Neural Tangent Kernel"", ""Tree Ensemble"", ""Soft Tree""]","By considering an ensemble of infinite trees, we introduce and study the Tree Neural Tangent Kernel (TNTK), which provides new insights into the behavior of the infinite ensemble of soft trees.",2109.04983,cs.LG,2021-09-10 16:48:24+00:00,2021-09-10 16:48:24+00:00
vVjIW3sEc1s,2021,Accept (Poster),True,A Mathematical Exploration of Why Language Models Help Solve Downstream Tasks,"[""Nikunj Saunshi"", ""Sadhika Malladi"", ""Sanjeev Arora""]","[""language models"", ""theory"", ""representation learning"", ""self-supervised learning"", ""unsupervised learning"", ""transfer learning"", ""natural language processing""]",We develop a mathematical framework for understanding why language model features help with downstream linear classification tasks of interest,2010.03648,cs.CL,2020-10-07 20:56:40+00:00,2021-04-14 17:59:14+00:00
vXGcHthY6v,2022,Reject,False,Invariance Through Inference,"['Takuma Yoneda', 'Ge Yang', 'Matthew Walter', 'Bradly C. Stadie']","[""invariance"", ""representation learning"", ""out-of-distribution"", ""domain adaptation"", ""generalization""]",Enable out-of-distribution generalization via invariance through inference,,,,
vXj_ucZQ4hA,2021,Accept (Poster),True,Robust Pruning at Initialization,"[""Soufiane Hayou"", ""Jean-Francois Ton"", ""Arnaud Doucet"", ""Yee Whye Teh""]","[""Pruning"", ""Initialization"", ""Compression""]",Making pruning at initialization robust to Gradient vanishing/exploding,2002.08797,stat.ML,2020-02-19 17:09:50+00:00,2021-05-19 22:43:36+00:00
vY0bnzBBvtr,2021,Reject,True,Provably More Efficient Q-Learning in the One-Sided-Feedback/Full-Feedback Settings,"[""Xiao-Yue Gong"", ""David Simchi-Levi""]","[""Q-learning"", ""episodic MDP"", ""full-feedback"", ""one-sided-feedback"", ""inventory control"", ""inventory""]","We propose a new Q-learning algorithm that is provably more efficient for the one-sided/full feedback settings than existing Q-learning algorithms, showing the potential for adapting reinforcement learning to more varied structures of problems",2007.00080,cs.LG,2020-06-30 19:47:38+00:00,2020-10-02 20:25:44+00:00
vYVI1CHPaQg,2021,Accept (Poster),False,A Better Alternative to Error Feedback for Communication-Efficient Distributed Learning,"[""Samuel Horv\u00e1th"", ""Peter Richtarik""]","[""distributed optimization"", ""communication efficiency""]",,,,,
vYeQQ29Tbvx,2021,Accept (Poster),True,Training BatchNorm and Only BatchNorm: On the Expressive Power of Random Features in CNNs,"[""Jonathan Frankle"", ""David J. Schwab"", ""Ari S. Morcos""]","[""affine parameters"", ""random features"", ""batchnorm""]",We study the role and expressive power of learned affine parameters that transform features by freezing all weights at their random initializations and training only BatchNorm.,2003.00152,cs.LG,2020-02-29 01:57:37+00:00,2021-03-21 21:48:35+00:00
v_1Soh8QUNc,2021,Accept (Poster),False,Learning Energy-Based Models by Diffusion Recovery Likelihood,"[""Ruiqi Gao"", ""Yang Song"", ""Ben Poole"", ""Ying Nian Wu"", ""Diederik P Kingma""]","[""energy-based model"", ""EBM"", ""recovery likelihood"", ""generative model"", ""diffusion process"", ""MCMC"", ""Langevin dynamics"", ""HMC""]","We present a diffusion recovery likelihood method to tractably learn and sample from a sequence of EBMs based on a diffusion process. High sample quality, stable long-run MCMC chains and good estimation of likelihood. ",,,,
vaRCHVj0uGI,2022,Accept (Poster),False,Solving Inverse Problems in Medical Imaging with Score-Based Generative Models,"['Yang Song', 'Liyue Shen', 'Lei Xing', 'Stefano Ermon']","[""score-based generative modeling"", ""inverse problems"", ""sparse-view CT"", ""undersampled MRI"", ""metal artifact removal"", ""diffusion""]",,2111.08005,eess.IV,2021-11-15 05:41:12+00:00,2021-11-15 05:41:12+00:00
vcKVhY7AZqK,2021,Reject,False,Quantifying Task Complexity Through Generalized Information Measures,"[""Aditya Chattopadhyay"", ""Benjamin David Haeffele"", ""Donald Geman"", ""Rene Vidal""]","[""Task Complexity"", ""Information Pursuit"", ""Deep Generative Models"", ""Information Theory"", ""Variational Autoencoders"", ""Normalizing Flows""]",We propose a novel measure for quantifying the complexity of a learning task,,,,
vcUmUvQCloe,2022,Accept (Poster),True,Joint Shapley values: a measure of joint feature importance,"['Chris Harris', 'Richard Pymar', 'Colin Rowat']","[""explainable AI"", ""Shapley value"", ""interaction index"", ""cooperative game theory""]","We present a direct extension of Shapley's value to sets of features, thus extending the Shapley value's intuition: a set of feature's average effect on a model's prediction",2107.11357,stat.ML,2021-07-23 17:22:37+00:00,2022-02-10 11:45:29+00:00
vcopnwZ7bC,2021,Accept (Poster),False,Learning Task Decomposition with Ordered Memory Policy Network,"[""Yuchen Lu"", ""Yikang Shen"", ""Siyuan Zhou"", ""Aaron Courville"", ""Joshua B. Tenenbaum"", ""Chuang Gan""]","[""Task Segmentation"", ""Hierarchical Imitation Learning"", ""Network Inductive Bias""]",We introduce an Ordered Memory Policy Network (OMPN) to discover task decomposition by imitation learning from demonstration.,2103.10972,cs.LG,2021-03-19 18:13:35+00:00,2021-03-19 18:13:35+00:00
vdKncX1WclT,2022,Reject,True,Red Alarm for Pre-trained Models: Universal Vulnerability to Neuron-Level Backdoor Attacks,"['Zhengyan Zhang', 'Guangxuan Xiao', 'Yongwei Li', 'Tian Lv', 'Fanchao Qi', 'Zhiyuan Liu', 'Yasheng Wang', 'Xin Jiang', 'Maosong Sun']","[""Pre-trained models"", ""Backdoor attacks""]",Backdoor attacks on pre-trained models without foreknowing task information.,2101.06969,cs.CL,2021-01-18 10:18:42+00:00,2021-06-13 08:30:39+00:00
vdbidlOkeF0,2022,Reject,False,Scaling Densities For Improved Density Ratio Estimation,"['Akash Srivastava', 'Seungwook Han', 'Benjamin Rhodes', 'Kai Xu', 'Michael U. Gutmann']","[""density ratio estimation"", ""scaled bregman divergence"", ""mutual information estimation"", ""representation learning""]",Improving density ratio estimation when densities are too far apart by estimating log p/q as log p/m - log q/m with a multi-class classifier,,,,
vds4SNooOe,2022,Accept (Spotlight),False,Superclass-Conditional Gaussian Mixture Model For Learning Fine-Grained Embeddings,"['Jingchao Ni', 'Wei Cheng', 'Zhengzhang Chen', 'Takayoshi Asakura', 'Tomoya Soma', 'Sho Kato', 'Haifeng Chen']","[""Deep learning"", ""represenation learning"", ""generative model""]",We propose a training framework characterized by a novel superclass conditional Gaussian mixture (SCGM) based generative model for learning fine-grained representations for cross-granularity adaptation.,,,,
vfsRB5MImo9,2022,Accept (Poster),True,Towards Continual Knowledge Learning of Language Models,"['Joel Jang', 'Seonghyeon Ye', 'Sohee Yang', 'Joongbo Shin', 'Janghoon Han', 'Gyeonghun KIM', 'Stanley Jungkyu Choi', 'Minjoon Seo']","[""continual learning"", ""knowledge acquisition"", ""catastrophic forgetting"", ""large language models"", ""pretraining"", ""natural language processing""]",We propose a novel continual learning formulation named Continual Knowledge Learning which allows large language models to constantly obtain new and updated knowledge while mitigating forgetting of previous learned time-invariant knowledge.,2110.03215,cs.CL,2021-10-07 07:00:57+00:00,2021-10-26 14:39:10+00:00
vgqS1vkkCbE,2022,Accept (Poster),False,Value Function Spaces: Skill-Centric State Abstractions for Long-Horizon Reasoning,"['Dhruv Shah', 'Alexander T Toshev', 'Sergey Levine', 'brian ichter']","[""hierarchical reinforcement learning"", ""planning"", ""representation learning"", ""robotics""]","We introduce value function spaces, a learned representation of state through the values of low-level skills, which capture affordances and ignores distractors to enable long-horizon reasoning and zero-shot generalization.",,,,
vh-0sUt8HlG,2022,Accept (Poster),False,"MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer","['Sachin Mehta', 'Mohammad Rastegari']","[""Vision transformer"", ""Mobile"", ""Edge Devices"", ""Transformer"", ""CNN"", ""Efficient Network"", ""Detection"", ""Segmentation"", ""ImageNet""]",Light-weight and general-purpose vision transformers for mobile devices,,,,
vhKe9UFbrJo,2021,Accept (Poster),False,Relating by Contrasting: A Data-efficient Framework for Multimodal Generative Models,"[""Yuge Shi"", ""Brooks Paige"", ""Philip Torr"", ""Siddharth N""]","[""Deep generative model"", ""multi-modal learning"", ""representation learning""]",,,,,
viWF5cyz6i,2022,Reject,False,An Efficient and Reliable Tolerance-Based Algorithm for Principal Component Analysis,"['Michael Yeh', 'Ming Gu']","[""principal component analysis"", ""dimensionality reduction"", ""data compression""]",,,,,
vkZtFD0zga8,2022,Reject,False,Uncertainty-Aware Deep Video Compression with Ensembles,"['Wufei Ma', 'Jiahao Li', 'Bin Li', 'Yan Lu']","[""Video compression"", ""uncertainty"", ""ensemble learning""]",We investigate the inherent uncertainty in two-stage video compression models and propose an ensemble-based method to effectively capture the predictive uncertainty and to save bits by an average of 15% compared to DVC Pro.,,,,
vkaMaq95_rX,2022,Accept (Poster),False,EXACT: Scalable Graph Neural Networks Training via Extreme Activation Compression,"['Zirui Liu', 'Kaixiong Zhou', 'Fan Yang', 'Li Li', 'Rui Chen', 'Xia Hu']","[""graph neural networks"", ""scalable GNN training"", ""quantization"", ""random projection""]",,,,,
vkxGQB9f2Vg,2021,Reject,False,Fourier Stochastic Backpropagation,"[""Amine Echraibi"", ""Joachim Flocon Cholet"", ""St\u00e9phane Gosselin"", ""Sandrine Vaton""]","[""Stochastic Backpropagation"", ""Variational Inference"", ""Probabilistic Graphical Models"", ""Deep Learning""]",Communicating new theoretical results concerning stochastic backpropagation. ,,,,
vlcVTDaufN,2021,Reject,True,Differentiable Combinatorial Losses through Generalized Gradients of Linear Programs,"[""Xi Gao"", ""Han Zhang"", ""Aliakbar Panahi"", ""Tom Arodz""]","[""combinatorial optimization"", ""linear programs"", ""generalized gradient""]","We show how to differentiate over the objective value of the optimal solution to a combinatorial problem, using a single run to a black-box combinatorial solver.",1910.08211,cs.LG,2019-10-18 00:53:55+00:00,2020-10-02 16:44:27+00:00
vnENCLwVBET,2022,Reject,False,OUMG: Objective and Universal Metric for Text Generation with Guiding Ability,"['Hanxu Liu', 'Nianmin Yao']","[""evaluation metric"", ""text generation"", ""objective""]",We propose an objective and universal automatic evaluation metric for text generation.,,,,
vnF5gDNvcKX,2022,Reject,False,Variance Reduced Domain Randomization for Policy Gradient,"['Yuankun Jiang', 'Chenglin Li', 'Wenrui Dai', 'Junni Zou', 'Hongkai Xiong']","[""Reinforcement learning"", ""generalization"", ""variance reduction""]","We theoretically derive an optimal baseline for domain randomization that depends on both the state and environment, and propose a practical variance reduced domain randomization approach for policy gradient methods.",,,,
vnOHGQY4FP1,2022,Reject,False,Rethinking Temperature in Graph Contrastive Learning,"['Ziyang Liu', 'Hao Feng', 'Chaokun Wang']","[""self-supervised learning"", ""graph contrastive learning"", ""uniformity""]","We argue that global uniformity and local separation are both necessary to the learning quality of graph contrastive learning, and develop a simple but effective GLATE algorithm. ",,,,
vnlqCDH1b6n,2021,Reject,True,Learning disentangled representations with the Wasserstein Autoencoder,"[""Benoit Gaujac"", ""Ilya Feige"", ""David Barber""]","[""generative modeling"", ""disentangle learning"", ""wasserstein autoencoder""]",Improving the reconstruction-disentanglement trade off with the Wasserstein Autoencoder.,2010.03459,stat.ML,2020-10-07 14:52:06+00:00,2020-10-07 14:52:06+00:00
voEpzgY8gsT,2022,Reject,True,Additive Poisson Process: Learning Intensity of Higher-Order Interaction in Poisson Processes,"['Simon Luo', 'Feng Zhou', 'lamiae azizi', 'Mahito Sugiyama']","[""Poisson Process"", ""Log-Linear Model"", ""Energy-Based Model"", ""Generalized Additive Models"", ""Information Geometry""]",An efficient technique that uses a log-linear model on a partial order structure to approximate a high-dimensional intensity functions in a Poisson Process.,2006.08982,stat.ML,2020-06-16 08:25:36+00:00,2020-06-16 08:25:36+00:00
vpiOnyOBTzQ,2022,Reject,False,Disentangled generative models for robust dynamical system prediction,"['Stathi Fotiadis', 'Shunlong Hu', 'Mario Lino Valencia', 'Chris D Cantwell', 'Anil Anthony Bharath']","[""disentanglement"", ""dynamical systems"", ""prediction"", ""generative models"", ""robustness"", ""out-of-distribution"", ""distribution shift"", ""causal inference""]",Disentangling ODE parameters from dynamics leads to better long-term and out-of-distribution predictions,,,,
vqGi8Kp0wM,2022,Accept (Poster),True,Mind the Gap: Domain Gap Control for Single Shot Domain Adaptation for Generative Adversarial Networks,"['Peihao Zhu', 'Rameen Abdal', 'John Femiani', 'Peter Wonka']","[""GAN"", ""StyleGAN"", ""Clip"", ""Domain Adaptation"", ""Style Transfer"", ""Single Shot""]",We propose several regularizers to control the domain transfer for single shot domain adaptation in the context of generative adversarial networks.,2110.08398,cs.CV,2021-10-15 22:32:12+00:00,2021-11-28 23:47:36+00:00
vr39r4Rjt3z,2022,Reject,False,Designing Less Forgetful Networks for Continual Learning,"['Nicholas I-Hsien Kuo', 'Mehrtash Harandi', 'Nicolas Fourrier', 'Gabriela Ferraro', 'Christian Walder', 'Hanna Suominen']","[""Continual Learning""]","The results of this paper showed that classifiers with Masked Highway Connections and Layer-Wise Normalisations could mitigate forgetting in continual learning even if reply, regularisation, and dynamic architectural methods were not applied.",,,,
vr4Wo33bd1,2022,Reject,False,Semi-supervised Long-tailed Recognition using Alternate Sampling,"['Bo Liu', 'Haoxiang Li', 'Hao Kang', 'Nuno Vasconcelos', 'Gang Hua']",[],,,,,
vrCiOrqgl3B,2021,Reject,False,Outlier Robust Optimal Transport,"[""Debarghya Mukherjee"", ""Aritra Guha"", ""Justin Solomon"", ""Yuekai Sun"", ""Mikhail Yurochkin""]","[""Optimal transport"", ""outliers"", ""robustness""]",We propose optimal transport formulation robust to outliers.,2012.07363,stat.ME,2020-12-14 09:28:16+00:00,2021-06-20 14:05:12+00:00
vrW3tvDfOJQ,2022,Accept (Spotlight),False,Sample Efficient Deep Reinforcement Learning via Uncertainty Estimation,"['Vincent Mai', 'Kaustubh Mani', 'Liam Paull']","[""Deep reinforcement learning"", ""uncertainty estimation"", ""inverse-variance"", ""heteroscedastic""]",The sample efficiency and performance of model-free DRL is improved by estimating the predictive uncertainty of the targets using probabilistic ensembles and down-weighting the uncertain samples using batch inverse-variance weighting.,2201.01666,cs.LG,2022-01-05 15:46:06+00:00,2022-01-05 15:46:06+00:00
vruwp11pWnO,2022,Reject,False,Improving and Assessing Anomaly Detectors for Large-Scale Settings,"['Dan Hendrycks', 'Steven Basart', 'Mantas Mazeika', 'Andy Zou', 'Joseph Kwon', 'Mohammadreza Mostajabi', 'Jacob Steinhardt']","[""anomaly"", ""ood"", ""distribution shift"", ""out-of-distribution""]","We introduce a dataset of novel species and road anomalies to benchmark our new, simple, state-of-the-art anomaly detector.",,,,
vsU0efpivw,2021,Accept (Poster),False,Shapley Explanation Networks,"[""Rui Wang"", ""Xiaoqian Wang"", ""David I. Inouye""]","[""Shapley values"", ""Feature Attribution"", ""Interpretable Machine Learning""]","To enable new capabilities, we propose to use Shapley values as inter-layer representations in deep neural networks rather than as post-hoc explanations.",2104.02297,cs.LG,2021-04-06 05:42:12+00:00,2021-04-06 05:42:12+00:00
vtDzHJOsmfJ,2022,Reject,False,Non-convex Optimization for Learning a Fair Predictor under Equalized Loss Fairness Constraint,"['Mohammad Mahdi Khalili', 'Xueru Zhang', 'Mahed Abroshan', 'Iman Vakilinia']","[""Non-convex Optimization"", ""Fairness"", ""Supervised Learning""]",This paper solves a non-convex optimization problem to find a fair predictor under the equalized loss fairness constraint. ,,,,
vttv9ADGuWF,2021,Reject,False,Certified robustness against physically-realizable patch attack via randomized cropping,"[""Wan-Yi Lin"", ""Fatemeh Sheikholeslami"", ""jinghao shi"", ""Leslie Rice"", ""J Zico Kolter""]","[""adversarial machine learning"", ""certifiable defense"", ""patch attack""]",This paper studies certifiable defense against adversarial patch attacks on image classification using random sub-regions of the original image.,,,,
vujTf_I8Kmc,2021,Accept (Poster),False,Attentional Constellation Nets for Few-Shot Learning,"[""Weijian Xu"", ""yifan xu"", ""Huaijin Wang"", ""Zhuowen Tu""]","[""few-shot learning"", ""constellation models""]",We tackle the few-shot learning problem by introducing an explicit cell feature clustering procedure with relation learning via self-attention.,,,,
vwLLQ-HwqhZ,2022,Accept (Poster),False,Continual Normalization: Rethinking Batch Normalization for Online Continual Learning,"['Quang Pham', 'Chenghao Liu', 'Steven HOI']","[""Continual Learning"", ""Batch Normalization""]",A negative effect of BN in online continual learning and a simple strategy to alleviate it.,,,,
vwj6aUeocyf,2022,Accept (Spotlight),True,Long Expressive Memory for Sequence Modeling,"['T. Konstantin Rusch', 'Siddhartha Mishra', 'N. Benjamin Erichson', 'Michael W. Mahoney']","[""sequence modeling"", ""long-term dependencies"", ""multiscale ordinary differential equations"", ""dynamical systems""]",A novel method for sequence modeling based on multiscale ODEs that is provably able to learn very long-term dependencies while being sufficiently expressive to outperform state-of-the-art recurrent sequence models.,2110.04744,cs.LG,2021-10-10 09:43:02+00:00,2021-10-10 09:43:02+00:00
vxlAHR9AyZ6,2022,Reject,False,$\alpha$-Weighted Federated Adversarial Training,"['Jianing Zhu', 'Jiangchao Yao', 'Tongliang Liu', 'Kunyang Jia', 'Jingren Zhou', 'Bo Han', 'Hongxia Yang']",[],,,,,
vyY0jnWG-tK,2021,Accept (Poster),False,"Physics-aware, probabilistic model order reduction with guaranteed stability","[""Sebastian Kaltenbach"", ""Phaedon Stelios Koutsourelakis""]","[""inductive bias"", ""probabilistic generative models"", ""state-space models"", ""model order reduction"", ""slowness"", ""long-term stability""]","We propose a novel physics-aware, generative, probabilistic state-space model for learning an effective, lower-dimensional description that can produce long-term predictions.",,,,
vyn49BUAkoD,2022,Reject,False,Bayesian Active Learning with Fully Bayesian Gaussian Processes,"['Christoffer Riis', 'Francisco Antunes', 'Frederik Boe HÃ¼ttel', 'Carlos Lima Azevedo', 'Francisco C. Pereira']",[],,,,,
w-CPUXXrAj,2022,Accept (Poster),False,On the Limitations of Multimodal VAEs,"['Imant Daunhawer', 'Thomas M. Sutter', 'Kieran Chin-Cheong', 'Emanuele Palumbo', 'Julia E Vogt']","[""multimodal learning"", ""variational autoencoder"", ""variational information bottleneck"", ""information theory""]",,,,,
w01vBAcewNX,2022,Accept (Poster),True,On Covariate Shift of Latent Confounders in Imitation and Reinforcement Learning,"['Guy Tennenholtz', 'Assaf Hallak', 'Gal Dalal', 'Shie Mannor', 'Gal Chechik', 'Uri Shalit']","[""imitation learning"", ""reinforcement learning"", ""expert data"", ""hidden confounding"", ""causal inference"", ""covariate shift""]","We use expert data with unobserved confounders for both imitation and reinforcement learning. Such hidden confounding is prone to a shifted distribution, which may severely hurt performance unless accounted for.",2110.06539,cs.LG,2021-10-13 07:31:31+00:00,2021-10-13 07:31:31+00:00
w1UbdvWH_R3,2022,Accept (Oral),False,Neural Collapse Under MSE Loss: Proximity to and Dynamics on the Central Path,"['X.Y. Han', 'Vardan Papyan', 'David L. Donoho']","[""neural collapse"", ""deep learning theory"", ""deep learning"", ""inductive bias"", ""equiangular tight frame"", ""ETF"", ""nearest class center"", ""mean squared error loss"", ""MSE loss"", ""invariance"", ""renormalization"", ""gradient flow"", ""dynamics"", ""adversarial robustness""]",Neural Collapse occurs empirically on deep nets trained with MSE loss and studying this setting leads to insightful closed-form dynamics.,,,,
w2Z2OwVNeK,2021,Accept (Poster),False,Plan-Based Relaxed Reward Shaping for Goal-Directed Tasks,"[""Ingmar Schubert"", ""Ozgur S Oguz"", ""Marc Toussaint""]","[""reinforcement learning"", ""reward shaping"", ""plan-based reward shaping"", ""robotics"", ""robotic manipulation""]","We introduce Final-Volume-Preserving Reward Shaping, and show in a plan-based setting that it significantly increases the sample efficiency of reinforcement learning.",,,,
w2mYg3d0eot,2021,Accept (Poster),False,Fast convergence of stochastic subgradient method under interpolation,"[""Huang Fang"", ""Zhenan Fan"", ""Michael Friedlander""]","[""Optimization"", ""stochastic subgradient method"", ""interpolation"", ""convergence analysis""]",,,,,
w4cXZDDib1H,2022,Accept (Poster),True,ViDT: An Efficient and Effective Fully Transformer-based Object Detector,"['Hwanjun Song', 'Deqing Sun', 'Sanghyuk Chun', 'Varun Jampani', 'Dongyoon Han', 'Byeongho Heo', 'Wonjae Kim', 'Ming-Hsuan Yang']","[""object detection"", ""vision transformer"", ""detection transformer""]",We integrate vision and detection transformers to build an efficient  and effective fully transformer-based object detector. ,2110.03921,cs.CV,2021-10-08 06:32:05+00:00,2021-11-29 11:07:13+00:00
w5bNwUzj33,2021,Reject,False,Cross-Domain Few-Shot Learning by Representation Fusion,"[""Thomas Adler"", ""Johannes Brandstetter"", ""Michael Widrich"", ""Andreas Mayr"", ""David Kreil"", ""Michael K Kopp"", ""G\u00fcnter Klambauer"", ""Sepp Hochreiter""]","[""cross-domain learning"", ""few-shot learning"", ""Hebbian learning"", ""ensemble learning"", ""domain shift"", ""domain adaptation"", ""representation fusion""]","We introduce the concept of representation fusion and, based on it, propose CHEF as a new method, which achieves new state-of-the-art results in cross-domain few-shot learning.",,,,
w5uur-ZwCXn,2021,Reject,False,XLA: A Robust Unsupervised Data Augmentation Framework for Cross-Lingual NLP,"[""M Saiful Bari"", ""Tasnim Mohiuddin"", ""Shafiq Joty""]","[""multi-lingual"", ""cross-lingual"", ""data-augmentation"", ""nlp""]",,,,,
w60btE_8T2m,2022,Accept (Spotlight),False,Spanning Tree-based Graph Generation for Molecules,"['Sungsoo Ahn', 'Binghong Chen', 'Tianzhe Wang', 'Le Song']","[""molecule generation"", ""tree generation"", ""graph generation"", ""deep generative model"", ""de novo drug design""]",We propose a new molecular graph generative model based on compact tree constructive operators.,,,,
w6Vm1Vob0-X,2021,Reject,False,Global Node Attentions via Adaptive Spectral Filters,"[""Shouheng Li"", ""Dongwoo Kim"", ""Qing Wang""]","[""Graph Representation learning"", ""Graph Convolutional Network"", ""Graph Fourier transform""]",Adaptive spectral aggregation methods improves GNN performance on disassortative graphs where local node homophily is weak.,,,,
w6p7UMtf-0S,2021,Reject,False,Improving Few-Shot Visual Classification with Unlabelled Examples,"[""Peyman Bateni"", ""Jarred Barber"", ""Jan-Willem van de Meent"", ""Frank Wood""]","[""Meta-learning"", ""Few-shot image classification"", ""Transductive few-shot learning""]","We propose Transductive CNAPS, a neural adaptive Mahalanobis-distance based soft k-means approach for transductive few-shot image classification.",,,,
w7Nb5dSMM-,2022,Reject,False,Evolutionary perspective on model fine-tuning,"['Andrei Kucharavy', 'Ljiljana Dolamic', 'Rachid Guerraoui']","[""Evolutionary algorithms"", ""stochastic gradient descent"", ""fine-tuning""]",We formalize a parallel between biological systems evolution and machine learning models fine-tuning to suggests ways of accelerating fine-tuning,,,,
w8HXzn2FyKm,2022,Reject,False,Finite-Time Error Bounds for Distributed Linear Stochastic Approximation,"['Yixuan Lin', 'Ji Liu', 'Vijay Gupta']","[""Stochastic Approximation"", ""Distributed Stochastic Approximation"", ""Finite-time Analysis""]","This paper develops novel tools for analyzing finite-time performance of distributed linear stochastic approximation (SA) over time-varying directed graphs, including consensus- and push-sum-based SA processes.",,,,
w8iCTOJvyD,2021,Reject,False,Tailoring: encoding inductive biases by optimizing unsupervised objectives at prediction time,"[""Ferran Alet"", ""Kenji Kawaguchi"", ""Maria Bauza Villalonga"", ""Nurullah Giray Kuru"", ""Tomas Perez"", ""Leslie Pack Kaelbling""]","[""inductive biases"", ""meta-learning"", ""semi-supervised learning"", ""adversarial learning"", ""representation learning"", ""transductive learning""]","New framework to encode inductive biases as unsupervised losses optimized at prediction time and show, theoretically and empirically, its usefulness in a wide range of domains(contrastive learning, physics, adversarial robustness, and MBRL).",,,,
wC99I7uIFe,2021,Reject,True,D2p-fed:Differentially Private Federated Learning with Efficient Communication,"[""Lun Wang"", ""Ruoxi Jia"", ""Dawn Song""]","[""Differential Privacy"", ""Federated Learning"", ""Communication Efficiency""]","We propose D2p-fed, a differentially private federated learning protocol with efficient communication.",2006.13039,stat.ML,2020-06-22 06:46:11+00:00,2021-01-02 22:02:32+00:00
wClmeg9u7G,2022,Reject,True,"Distributed Methods with Compressed Communication for Solving Variational Inequalities, with Theoretical Guarantees","['Aleksandr Beznosikov', 'Peter RichtÃ¡rik', 'Michael Diskin', 'Max Ryabinin', 'Alexander Gasnikov']","[""convex optimization"", ""saddle point problem"", ""minmax problem"", ""distributed optimization"", ""quantization"", ""compression""]",,2110.03313,cs.LG,2021-10-07 10:04:32+00:00,2021-10-07 10:04:32+00:00
wE-3ly4eT5G,2021,Reject,False,FactoredRL: Leveraging Factored Graphs for Deep Reinforcement Learning,"[""Bharathan Balaji"", ""Petros Christodoulou"", ""Xiaoyu Lu"", ""Byungsoo Jeon"", ""Jordan Bell-Masterson""]","[""reinforcement learning"", ""factored mdp"", ""factored rl""]","The paper proposes a method to decompose the relationships between states, actions and rewards using known structural information to improve sample efficiency of deep reinforcement learning algorithms.",,,,
wENMvIsxNN,2022,Accept (Spotlight),False,D-CODE: Discovering Closed-form ODEs from Observed Trajectories,"['Zhaozhi Qian', 'Krzysztof Kacprzyk', 'Mihaela van der Schaar']","[""Symbolic Regression"", ""Ordinary Differential Equation""]",,,,,
wG5XIGi6nrt,2021,Reject,False,Learning Private Representations with Focal Entropy,"[""Tassilo Klein"", ""Moin Nabi""]",[],We propose a variant of entropy embedded in an adversarial representation learning setting to leverage privacy sanitization in a semantic-aware fashion.,,,,
wIK1fWFXvU9,2022,Reject,False,Understanding the Interaction of Adversarial Training with Noisy Labels,"['Jianing Zhu', 'Jingfeng Zhang', 'Bo Han', 'Tongliang Liu', 'Gang Niu', 'Hongxia Yang', 'Mohan Kankanhalli', 'Masashi Sugiyama']","[""noisy labels"", ""adversarial training""]","Adversarial training (AT) itself is noisy labels (NL) correction; ""PGD step number"" in AT is a new criterion for sample selection.",,,,
wIzUeM3TAU,2022,Accept (Oral),False,Expressiveness and Approximation Properties of Graph Neural Networks,"['Floris Geerts', 'Juan L Reutter']","[""Graph Neural Networks"", ""Colour Refinement"", ""Weisfeiler-Leman"", ""Separation Power"", ""Universality""]",A general methodology for assessing the expressive and approximation power of GNNs is presented.,,,,
wMIdpzTmnct,2021,Reject,False,Hard-label Manifolds: Unexpected advantages of query efficiency for finding on-manifold adversarial examples,"[""Washington Garcia"", ""Pin-Yu Chen"", ""Somesh Jha"", ""Hamilton Scott Clouse"", ""Kevin Butler""]","[""hard-label attacks"", ""adversarial machine learning"", ""generalization""]",,,,,
wMXYbJB-gX,2022,Reject,True,Towards Understanding Label Smoothing,"['Yi Xu', 'Yuanhong Xu', 'Qi Qian', 'Hao Li', 'Rong Jin']",[],,2006.11653,cs.LG,2020-06-20 20:36:17+00:00,2020-10-03 03:05:47+00:00
wMpS-Z_AI_E,2022,Accept (Poster),False,A Theoretical Analysis on Feature Learning in Neural Networks: Emergence from Inputs and Advantage over Fixed Features,"['Zhenmei Shi', 'Junyi Wei', 'Yingyu Liang']","[""neural networks"", ""feature learning"", ""provable advantage"", ""theoretical analysis""]","Theoretical analysis of feature learning in neural networks on practically motivated learning problems, showing it strongly depends on the structure of the input distribution and leads to the advantage over fixed feature methods like kernels.",,,,
wNsNT56zDkG,2022,Reject,False,Adversarial Rademacher Complexity of Deep Neural Networks,"['Jiancong Xiao', 'Yanbo Fan', 'Ruoyu Sun', 'Zhi-Quan Luo']","[""Adversarial Robustness"", ""Generalization"", ""Rademacher complexity""]",,,,,
wOI9hqkvu_,2021,Reject,False,A Text GAN for Language Generation with Non-Autoregressive Generator,"[""Fei Huang"", ""Jian Guan"", ""Pei Ke"", ""Qihan Guo"", ""Xiaoyan Zhu"", ""Minlie Huang""]","[""language generation"", ""non-autoregressive text generation"", ""generative adversarial networks"", ""GANs"", ""latent variable""]","We propose a text GAN with a non-autoregressive generator, which can be effectively trained with gradient-based method from scratch and applied to text generation applications that require latent variables.",,,,
wQ7RCayXUSl,2022,Reject,False,"Why so pessimistic? Estimating uncertainties for offline RL through ensembles, and why their independence matters.","['Seyed Kamyar Seyed Ghasemipour', 'Shixiang Shane Gu', 'Ofir Nachum']","[""offline reinforcement learning"", ""batch reinforcement learning"", ""ensembles"", ""uncertainty estimation.""]",We demonstrate how significantly beneficial uncertainty estimation through ensembles can be for offline RL and demonstrate much work is still needed for efficient ensembles to be as effective as deep ensembles.,,,,
wQRlSUZ5V7B,2021,Accept (Poster),False,Capturing Label Characteristics in VAEs,"[""Tom Joy"", ""Sebastian Schmon"", ""Philip Torr"", ""Siddharth N"", ""Tom Rainforth""]","[""variational autoencoder"", ""representation learning"", ""deep generative models""]",We present a principled approach to incorporating labels in VAEs that captures the rich characteristic information associated with those labels.,,,,
wQStfB93RZZ,2022,Reject,False,Asynchronous Multi-Agent Actor-Critic with Macro-Actions,"['Yuchen Xiao', 'Weihao Tan', 'Christopher Amato']",[],,,,,
wQfgfb8VKTn,2022,Accept (Spotlight),True,Context-Aware Sparse Deep Coordination Graphs,"['Tonghan Wang', 'Liang Zeng', 'Weijun Dong', 'Qianlan Yang', 'Yang Yu', 'Chongjie Zhang']","[""Multi-agent reinforcement learning"", ""Sparse coordination graphs"", ""Deep coordination graphs""]",We propose a novel method for learning sparse coordination graphs that can be theoretically justified and can significantly reduce communication overhead and improve learning performance of deep coordination graphs.,2106.02886,cs.LG,2021-06-05 12:59:03+00:00,2021-10-15 17:00:37+00:00
wRODLDHaAiW,2022,Accept (Oral),False,iLQR-VAE : control-based learning of input-driven dynamics with applications to neural data,"['Marine Schimel', 'Ta-Chu Kao', 'Kristopher T Jensen', 'Guillaume Hennequin']","[""neuroscience"", ""latent variable models"", ""RNN"", ""VAE"", ""motor control"", ""control theory"", ""dynamical systems""]",We develop a novel autoencoder that uses iLQR as an inference model and apply it to synthetic data as well as neural recordings from primate motor cortex.,,,,
wS0UFjsNYjn,2021,Accept (Spotlight),False,Meta-GMVAE: Mixture of Gaussian VAE for Unsupervised Meta-Learning,"[""Dong Bok Lee"", ""Dongchan Min"", ""Seanie Lee"", ""Sung Ju Hwang""]","[""Unsupervised Learning"", ""Meta-Learning"", ""Unsupervised Meta-learning"", ""Variational Autoencoders""]","we propose a principled unsupervised meta-learning model which meta-learns a set-level variational posterior, by matching it with multi-modal prior distribution obtained by EM.",,,,
wTTjnvGphYj,2022,Accept (Poster),True,Graph Neural Networks with Learnable Structural and Positional Representations,"['Vijay Prakash Dwivedi', 'Anh Tuan Luu', 'Thomas Laurent', 'Yoshua Bengio', 'Xavier Bresson']","[""graph neural networks"", ""graph representation learning"", ""transformers"", ""positional encoding""]",We propose a novel GNN architecture (LSPE) which decouples structural and positional representations to make easy for the network to learn the two essential properties.,2110.07875,cs.LG,2021-10-15 05:59:15+00:00,2022-02-10 07:56:13+00:00
wTWLfuDkvKp,2021,Reject,False,Should Ensemble Members Be Calibrated?,"[""Xixin Wu"", ""Mark Gales""]",[],,2101.05397,cs.LG,2021-01-13 23:59:00+00:00,2021-01-13 23:59:00+00:00
wUUKCAmBx6q,2021,Reject,False,Flow Neural Network for Traffic Flow Modelling in IP Networks,"[""Xiangle Cheng"", ""Yuchen He"", ""Feifei Long"", ""Shihan Xiao"", ""Fenglin Li""]","[""Flow neural network"", ""contrastive induction learning"", ""representation learning"", ""spatio-temporal induction""]",We propose a customised Flow Neural Network for the subsecond traffic flow modelling in IP networks by exploiting the domain-specific data properties according to the IP network structure and working machenism.,,,,
wVYtfckXU0T,2021,Reject,False,PriorityCut: Occlusion-aware Regularization for Image Animation,"[""Wai Ting Cheung"", ""Gyeongsu Chae""]","[""image animation"", ""occlusion"", ""inpainting"", ""gan"", ""augmentation"", ""regularization""]",,2103.11600,cs.CV,2021-03-22 06:05:20+00:00,2021-03-22 06:05:20+00:00
wWK7yXkULyh,2021,Accept (Oral),False,MONGOOSE: A Learnable LSH Framework for Efficient Neural Network Training,"[""Beidi Chen"", ""Zichang Liu"", ""Binghui Peng"", ""Zhaozhuo Xu"", ""Jonathan Lingjie Li"", ""Tri Dao"", ""Zhao Song"", ""Anshumali Shrivastava"", ""Christopher Re""]","[""Large-scale Deep Learning"", ""Large-scale Machine Learning"", ""Efficient Training"", ""Randomized Algorithms""]","We propose MONGOOSE,  a learnable LSH framework for efficient neural network training.",,,,
wXBt-7VM2JE,2021,Reject,False,On Single-environment Extrapolations in Graph Classification and Regression Tasks,"[""Beatrice Bevilacqua"", ""Yangze Zhou"", ""Ryan L Murphy"", ""Bruno Ribeiro""]","[""Extrapolation"", ""Graphs"", ""GNNs"", ""SCM"", ""Causality"", ""Counterfactual Inference""]","To the best of our knowledge, this is the first work to formalize extrapolation in graph classification tasks using counterfactual inference, showing that extrapolation in graph tasks is possible even if given a single environment in training.",,,,
wXgk_iCiYGo,2021,Accept (Poster),True,A Diffusion Theory For Deep Learning Dynamics: Stochastic Gradient Descent Exponentially Favors Flat Minima,"[""Zeke Xie"", ""Issei Sato"", ""Masashi Sugiyama""]","[""deep learning dynamics"", ""SGD"", ""diffusion"", ""flat minima"", ""stochastic optimization""]","We prove that, benefited from the Hessian-dependent covariance of stochastic gradient noise, SGD favors flat minima exponentially more than sharp minima.",2002.03495,cs.LG,2020-02-10 02:04:49+00:00,2021-01-15 14:57:46+00:00
wXoHN-Zoel,2021,Reject,False,There is no trade-off: enforcing fairness can improve accuracy,"[""Subha Maity"", ""Debarghya Mukherjee"", ""Mikhail Yurochkin"", ""Yuekai Sun""]",[],,,,,
wYqLTy4wkor,2022,Reject,False,Grounding Aleatoric Uncertainty in Unsupervised Environment Design,"['Minqi Jiang', 'Michael D Dennis', 'Jack Parker-Holder', 'Andrei Lupu', 'Heinrich Kuttler', 'Edward Grefenstette', 'Tim RocktÃ¤schel', 'Jakob Nicolaus Foerster']","[""reinforcement learning"", ""curriculum learning"", ""generalization"", ""environment design"", ""procedural content generation""]","We characterize how curriculum learning can induce suboptimal reinforcement learning policies with respect to a ground-truth distribution of environments, and propose a method for correcting this effect.",,,,
wZ4yWvQ_g2y,2021,Reject,False,Task-Agnostic and Adaptive-Size BERT Compression,"[""Jin Xu"", ""Xu Tan"", ""Renqian Luo"", ""Kaitao Song"", ""Li Jian"", ""Tao Qin"", ""Tie-Yan Liu""]","[""BERT compression"", ""neural architecture search"", ""adaptive sizes"", ""across tasks"", ""knowledge distillation""]","we propose NAS-BERT, which leverages neural architecture search for BERT compression with adaptive model sizes and across downstream tasks.",,,,
w_7JMpGZRh0,2021,Accept (Spotlight),True,Watch-And-Help: A Challenge for Social Perception and Human-AI Collaboration,"[""Xavier Puig"", ""Tianmin Shu"", ""Shuang Li"", ""Zilin Wang"", ""Yuan-Hong Liao"", ""Joshua B. Tenenbaum"", ""Sanja Fidler"", ""Antonio Torralba""]","[""social perception"", ""human-AI collaboration"", ""theory of mind"", ""multi-agent platform"", ""virtual environment""]","We introduce Watch-And-Help (WAH), a challenge for testing social intelligence in agents.",2010.09890,cs.AI,2020-10-19 21:48:31+00:00,2021-05-03 13:08:55+00:00
w_BtePbtmx4,2021,Reject,False,Accelerating DNN Training through Selective Localized Learning ,"[""Sarada Krithivasan"", ""Sanchari Sen"", ""Swagath Venkataramani"", ""Anand Raghunathan""]","[""Efficient DNN Training""]",,,,,
w_drCosT76,2022,Accept (Poster),True,Differentiable Scaffolding Tree for Molecule Optimization,"['Tianfan Fu', 'Wenhao Gao', 'Cao Xiao', 'Jacob Yasonik', 'Connor W. Coley', 'Jimeng Sun']",[],make the molecular optimization problem differentiable at the structure level,2109.10469,cs.LG,2021-09-22 01:16:22+00:00,2022-01-24 16:59:54+00:00
w_haMPbUgWb,2021,Reject,False,Rewriter-Evaluator Framework for Neural Machine Translation,"[""Yangming Li"", ""Kaisheng Yao""]","[""Neural Machine Translation"", ""Post-editing mechanism"", ""Polish Mechanism"", ""Proper Termination Policy""]","We propose a novel framework, Rewriter-Evaluator, that achieves proper termination policy for multi-pass decoding.",,,,
wabe-NE8-AX,2021,Reject,False,NNGeometry: Easy and Fast Fisher Information Matrices and Neural Tangent Kernels in PyTorch,"[""Thomas George""]",[],A PyTorch library for computing Fisher Information Matrices and Neural Tangent Kernels ,,,,
wb3wxCObbRT,2021,Accept (Oral),False,Growing Efficient Deep Networks by Structured Continuous Sparsification,"[""Xin Yuan"", ""Pedro Henrique Pamplona Savarese"", ""Michael Maire""]","[""deep learning"", ""computer vision"", ""network pruning"", ""neural architecture search""]",We propose an efficient training method that dynamically grows and prunes neural network architectures.,,,,
wbPObLm6ueA,2022,Accept (Poster),False,Fairness Guarantees under Demographic Shift,"['Stephen Giguere', 'Blossom Metevier', 'Yuriy Brun', 'Philip S. Thomas', 'Scott Niekum', 'Bruno Castro da Silva']","[""Fairness and Bias in Artificial Intelligence"", ""Machine Learning""]",We propose a strategy for designing classification algorithms that provide high-confidence fairness guarantees that remain valid if the distribution over observations changes after the trained model is deployed.,,,,
wbQXW1XTq_y,2021,Reject,False,Sim2SG: Sim-to-Real Scene Graph Generation for Transfer Learning,"[""Aayush Prakash"", ""Shoubhik Debnath"", ""Jean Francois Lafleche"", ""Eric Cameracci"", ""Gavriel State"", ""Marc T Law""]","[""computer vision"", ""application"", ""sim2real"", ""scene graph"", ""object detection"", ""simulation in machine learning"", ""transfer learning"", ""synthetic data"", ""driving simulation.""]",We propose sim-to-real scene graph generation using labeled synthetic and unlabeled real data by addressing the domain gap in content and appearance.,,,,
wfRZkDvxOqj,2022,Reject,False,Multi-Task Neural Processes,"['Jiayi Shen', 'Xiantong Zhen', 'Marcel Worring', 'Ling Shao']","[""Multi-task learning"", ""Neural processes"", ""Variational Inference""]","We develop multi-task neural processes, a new variant of neural processes for multi-task learning. ",2111.05820,cs.LG,2021-11-10 17:27:46+00:00,2021-12-02 13:32:57+00:00
wfZGut6e09,2022,Accept (Poster),False,Pareto Policy Adaptation,"['Panagiotis Kyriakis', 'Jyotirmoy Deshmukh', 'Paul Bogdan']","[""multi-objective reinforcement learning"", ""policy gradient"", ""pareto optimality"", ""policy adaptation""]","We propose a policy gradient method for multi-objective reinforcement learning under unknown, linear preferences. ",,,,
wgR0BQfG5vi,2022,Reject,False,Adaptive Label Smoothing with Self-Knowledge,"['Dongkyu Lee', 'Ka Chun Cheung', 'Nevin Zhang']","[""Regularization"", ""Model Calibration"", ""Adaptive Label Smoothing"", ""Self-Knowledge Distillation"", ""Overconfidence"", ""Natural Language Generation""]",We propose adaptive label smoothing with self-knowledge that enhances model performance and calibration.,,,,
whAxkamuuCU,2021,Reject,False,Symbol-Shift Equivariant Neural Networks,"[""David Salinas"", ""Hady Elsahar""]","[""compositionality"", ""Symbolic"", ""Equivariance"", ""question answering"", ""Language Processing""]",We define a class of model whose outputs are equivariant to entity permutations without having to specify or detect such entities in a pre-processing step.,,,,
whE31dn74cL,2021,Accept (Poster),False,A Temporal Kernel Approach for Deep Learning with Continuous-time Information,"[""Da Xu"", ""Chuanwei Ruan"", ""Evren Korpeoglu"", ""Sushant Kumar"", ""Kannan Achan""]","[""Kernel Learning"", ""Continuous-time System"", ""Spectral Distribution"", ""Random Feature"", ""Reparameterization"", ""Learning Theory""]",We propose a temporal kernel learning approach based on random features and reparameterization to characterize the continuous-time information in deep learning models.,2103.15213,cs.LG,2021-03-28 20:13:53+00:00,2021-03-28 20:13:53+00:00
whNntrHtB8D,2021,Reject,False,Gradient Based Memory Editing for Task-Free Continual Learning,"[""Xisen Jin"", ""Junyi Du"", ""Xiang Ren""]","[""Continual learning"", ""task-free continual learning""]",We propose a task-free memory-based continual learning algorithm that edits stored examples over time,,,,
wiSgdeJ29ee,2021,Reject,False,Fine-Tuning Offline Reinforcement Learning with Model-Based Policy Optimization,"[""Adam Villaflor"", ""John Dolan"", ""Jeff Schneider""]","[""Offline Reinforcement Learning"", ""Model-Based Reinforcement Learning"", ""Off-policy Reinforcement Learning"", ""uncertainty estimation""]",We present an offline RL approach that leverages both uncertainty-aware models and behavior-regularized model-free RL to achieve state of the art results on the MuJoCo tasks in the D4RL benchmark.,,,,
wjJ3pR-ZQD,2021,Reject,False,Learning Latent Topology for Graph Matching,"[""Tianshu Yu"", ""Runzhong Wang"", ""Junchi Yan"", ""Baoxin Li""]","[""Graph matching"", ""generative graph model"", ""latent structure learning""]","We proposed a deep graph matching method by learning to generate latent graph topology rather than a fixed initial graph topology, which achieved state-of-the-art performance.",,,,
wk5-XVtitD,2022,Reject,False,Language Model Pre-training Improves Generalization in Policy Learning,"['Shuang Li', 'Xavier Puig', 'Yilun Du', 'Ekin AkyÃ¼rek', 'Antonio Torralba', 'Jacob Andreas', 'Igor Mordatch']","[""Large Language model"", ""Imitation learning"", ""Interactive tasks"", ""policy learning""]",We investigate the effectiveness of LM pretraining to scaffold learning and generalization in autonomous decision-making.,,,,
wkMG8cdvh7-,2022,Accept (Poster),False,Understanding and Improving Graph Injection Attack by Promoting Unnoticeability,"['Yongqiang Chen', 'Han Yang', 'Yonggang Zhang', 'MA KAILI', 'Tongliang Liu', 'Bo Han', 'James Cheng']","[""Graph Neural Networks"", ""Adversarial Attacks"", ""Node Classification""]","We find GIA can be provably more harmful than GMA while at the price of bringing more damage to the homophily distribution, which makes it can easily defendable, hence we propose a novel adversarial objective to mitigate the issue. ",,,,
wl0Kr_jqM2a,2021,Reject,False,Testing Robustness Against Unforeseen Adversaries,"[""Daniel Kang"", ""Yi Sun"", ""Dan Hendrycks"", ""Tom B Brown"", ""Jacob Steinhardt""]","[""adversarial examples"", ""adversarial training"", ""adversarial attacks""]",We propose several new attacks and a framework to measure robustness against unforeseen adversarial attacks.,,,,
wmQCFqV9r8L,2022,Reject,False,SpaceMAP: Visualizing Any Data in 2-dimension by Space Expansion,"['Xinrui Zu', 'Qian Tao']","[""dimensionality reduction"", ""data embedding"", ""manifold learning""]",We propose a novel dimensionality reduction (DR) method using space geometry and hierarchical manifold approximation.,,,,
wogsFPHwftY,2022,Accept (Poster),False,Learning Super-Features for Image Retrieval,"['Philippe Weinzaepfel', 'Thomas Lucas', 'Diane Larlus', 'Yannis Kalantidis']","[""image retrieval"", ""landmark retrieval"", ""mid-level features""]",A novel image retrieval framework that learns mid-level features performing better and more compact that standard local ones,2201.13182,cs.CV,2022-01-31 12:48:42+00:00,2022-01-31 12:48:42+00:00
wpSWuz_hyqA,2021,Accept (Spotlight),True,Grounded Language Learning Fast and Slow,"[""Felix Hill"", ""Olivier Tieleman"", ""Tamara von Glehn"", ""Nathaniel Wong"", ""Hamza Merzic"", ""Stephen Clark""]","[""language"", ""cognition"", ""fast-mapping"", ""grounding"", ""word-learning"", ""memory"", ""meta-learning""]",A language-learning agent with dual-coding external memory meta-learns to combine fast-mapped and semantic lexical knowledge to execute instructions in one-shot.. ,2009.01719,cs.CL,2020-09-03 14:52:03+00:00,2020-10-14 14:38:58+00:00
wqD6TfbYkrn,2022,Accept (Poster),False,A Conditional Point Diffusion-Refinement Paradigm for 3D Point Cloud Completion,"['Zhaoyang Lyu', 'Zhifeng Kong', 'Xudong XU', 'Liang Pan', 'Dahua Lin']","[""Point Cloud Completion"", ""Denoising Diffusion Pobabilistic Model"", ""Conditional Generation""]",,2112.03530,cs.CV,2021-12-07 06:59:06+00:00,2021-12-16 08:26:51+00:00
wqRvVvMbJAT,2021,Reject,False,One Size Doesn't Fit All: Adaptive Label Smoothing,"[""Ujwal Krothapalli"", ""Lynn Abbott""]","[""Uncertainty estimation"", ""Calibration"", ""Label smoothing""]",The main contribution of this work is that we have developed a novel way to train classification CNNs using objectness measure and adaptive label smoothing.,,,,
wronZ3Mx_d,2022,Reject,False,Transfer Learning for Bayesian HPO with End-to-End Meta-Features,"['Hadi Samer Jomaa', 'Sebastian Pineda Arango', 'Lars Schmidt-Thieme', 'Josif Grabocka']","[""meta-learning"", ""hyperparameter optimization"", ""meta-features"", ""deep kernel learning"", ""Bayesian optimization"", ""transfer learning""]",,,,,
wta_8Hx2KD,2021,Accept (Poster),True,Incorporating Symmetry into Deep Dynamics Models for Improved Generalization,"[""Rui Wang"", ""Robin Walters"", ""Rose Yu""]","[""deep sequence model"", ""equivariant neural network"", ""physics-guided deep learning"", ""AI for earth science""]",Integrate various symmetris into deep sequence models for forecasting turbulence and ocean currents with improved accuracy and physical consistency.,2002.03061,cs.LG,2020-02-08 01:28:17+00:00,2021-03-15 23:00:39+00:00
wu5yYUutDGW,2022,Reject,False,Boundary-aware Pre-training for Video Scene Segmentation,"['Jonghwan Mun', 'Minchul Shin', 'Gunsoo Han', 'Sangho Lee', 'Seongsu Ha', 'Joonseok Lee', 'Eun-Sol Kim']","[""Temporal Segmentation"", ""Video Scene segmentation"", ""Self-supervised Learning""]",We propose a novel boundary-aware self-supervised learning framework which conducts pretext tasks carefully designed for the video scene segmentation task.,2201.05277,cs.CV,2022-01-14 02:14:07+00:00,2022-01-14 02:14:07+00:00
wv6g8fWLX2q,2022,Accept (Spotlight),False,TAMP-S2GCNets: Coupling Time-Aware Multipersistence Knowledge Representation with Spatio-Supra Graph Convolutional Networks for Time-Series Forecasting,"['Yuzhou Chen', 'Ignacio Segovia-Dominguez', 'Baris Coskunuzer', 'Yulia Gel']","[""topological data analysis"", ""multipersistence"", ""graph convolutional networks"", ""supragraph diffusion"", ""multivariate time series forecasting""]","We make the first step toward integrating two emerging directions, time-aware deep learning and multi-parameter persistence, allowing us to infer latent time-conditioned relations among entities in multivariate time series forecasting tasks.",,,,
ww-7bdU6GA9,2021,Reject,False,Near-Optimal Linear Regression under Distribution Shift,"[""Qi Lei"", ""Wei Hu"", ""Jason D. Lee""]","[""minimax estimator"", ""covariate shift"", ""model shift""]",We derive near optimal estimators for linear regression under distribution shift.,2106.12108,cs.LG,2021-06-23 00:52:50+00:00,2021-06-23 00:52:50+00:00
wwDg3bbYBIq,2022,Accept (Poster),True,Learning to Remember Patterns: Pattern Matching Memory Networks for Traffic Forecasting,"['Hyunwook Lee', 'Seungmin Jin', 'Hyeshin Chu', 'Hongkyu Lim', 'Sungahn Ko']","[""Traffic Forecasting"", ""Deep Learning""]","We presents a novel graph convolutional memory network, PM-MemNet, for the traffic forecasting.",2110.10380,cs.LG,2021-10-20 05:24:21+00:00,2021-10-20 05:24:21+00:00
wxRwhSdORKG,2021,Accept (Poster),False,Learning Subgoal Representations with Slow Dynamics,"[""Siyuan Li"", ""Lulu Zheng"", ""Jianhao Wang"", ""Chongjie Zhang""]","[""Hierarchical Reinforcement Learning"", ""Representation Learning"", ""Exploration""]",We propose a slowness objective to learn subgoal representations in hierarchical reinforcement learning.,,,,
wxVpa5z4DU1,2022,Reject,True,Accuracy-Privacy Trade-off in Deep Ensemble: A Membership Inference Perspective,"['Shahbaz Rezaei', 'Zubair Shafiq', 'Xin Liu']","[""Ensemble Learning"", ""Deep Ensemble"", ""Membership Inference""]","The paper, through experimental evaluations, shows a trade-off between accuracy and vulnerability of the model to membership inference attacks.",2105.05381,cs.LG,2021-05-12 00:58:04+00:00,2021-10-06 16:46:45+00:00
wzJnpBhRILm,2022,Reject,False,Extreme normalization: approximating full-data batch normalization with single examples,['Sergey Ioffe'],"[""batch normalization"", ""optimization""]","We cast batch normalization as an approximation of full-batch normalization, and propose an alternative with minimal (or no) cross-example interactions",,,,
x1uGDeV6ter,2021,Reject,False,Adaptive Automotive Radar data Acquisition,"[""Madhumitha Sakthi"", ""Ahmed Tewfik""]","[""Compressed Sensing"", ""Adaptive acquisition"", ""object detection""]",Adaptive automotive radar data acquisition using prior image and radar data. ,,,,
x2ywTOFM4xt,2021,Reject,False,Variational saliency maps for explaining model's behavior,"[""Jae Myung Kim"", ""Eunji Kim"", ""Seokhyeon Ha"", ""Sungroh Yoon"", ""Jungwoo Lee""]","[""Interpretability"", ""XAI"", ""Variational Inference""]",Posterior distribution of a saliency map that explains model's behavior and provides uncertainty over the explanation.,,,,
x3F9PuOUKZc,2022,Reject,True,Subpixel object segmentation using wavelets and multiresolution analysis,"['Ray Sheombarsing', 'Nikita Moriakov', 'Jan-jakob Sonke', 'Jonas Teuwen']","[""Segmentation"", ""wavelets"", ""contour prediction"", ""multiresolution analysis""]",In this paper a novel deep learning framework for fast prediction of contours is developed using wavelets and multiresolution analysis.,2110.15233,cs.CV,2021-10-28 15:43:21+00:00,2021-10-28 15:43:21+00:00
x4tkHYGpTdq,2022,Reject,True,DSEE: Dually Sparsity-embedded Efficient Tuning of Pre-trained Language Models,"['Xuxi Chen', 'Tianlong Chen', 'Yu Cheng', 'Weizhu Chen', 'Zhangyang Wang', 'Ahmed Hassan Awadallah']",[],,2111.00160,cs.LG,2021-10-30 03:29:47+00:00,2021-10-30 03:29:47+00:00
x6x7FWFNZpg,2021,Reject,True,"Decentralized SGD with Asynchronous, Local and Quantized Updates","[""Giorgi Nadiradze"", ""Amirmojtaba Sabour"", ""Peter Davies"", ""Ilia Markov"", ""Shigang Li"", ""Dan Alistarh""]","[""distributed machine learning"", ""SGD"", ""decentralized algorithms"", ""quantization""]","We provide a new decentralized, local variant of SGD which allows for asynchronous and quantized communication, while still ensuring convergence under standard assumptions, and good accuracy versus the sequential baseline.",1910.12308,cs.LG,2019-10-27 17:40:26+00:00,2020-12-14 18:32:01+00:00
x9C7Nlwgydy,2021,Reject,True,Consensus Clustering with Unsupervised Representation Learning,"[""Jayanth Reddy Regatti"", ""Aniket Anand Deshmukh"", ""Eren Manavoglu"", ""Urun Dogan""]","[""Clustering"", ""Ensemble Learning"", ""Representation Learning""]",We propose an ensemble learning algorithm for deep clustering which outperforms state-of-the-art clustering algorithms.,2010.01245,cs.CV,2020-10-03 01:16:46+00:00,2021-07-08 17:20:52+00:00
xBoKLdKrZd,2021,Reject,False,A Surgery of the Neural Architecture Evaluators,"[""Xuefei Ning"", ""Wenshuo Li"", ""Zixuan Zhou"", ""Tianchen Zhao"", ""Shuang Liang"", ""Yin Zheng"", ""Huazhong Yang"", ""Yu Wang""]","[""Neural architecture search (NAS)"", ""Parameter Sharing NAS"", ""Predictor-based NAS""]","This paper assesses current fast neural architecture evaluators with multiple direct criteria, under controlled settings.",,,,
xCVJMsPv3RT,2022,Accept (Poster),True,Dropout Q-Functions for Doubly Efficient Reinforcement Learning,"['Takuya Hiraoka', 'Takahisa Imagawa', 'Taisei Hashimoto', 'Takashi Onishi', 'Yoshimasa Tsuruoka']","[""Reinforcement learning""]",We propose a doubly (sample and computationally) efficient RL method (Dr.Q) in which a small ensemble of dropout Q-functions is used. ,2110.02034,cs.LG,2021-10-05 13:28:11+00:00,2021-10-05 13:28:11+00:00
xCcdBRQEDW,2021,Accept (Spotlight),False,PlasticineLab: A Soft-Body Manipulation Benchmark with Differentiable Physics,"[""Zhiao Huang"", ""Yuanming Hu"", ""Tao Du"", ""Siyuan Zhou"", ""Hao Su"", ""Joshua B. Tenenbaum"", ""Chuang Gan""]","[""Soft Body"", ""Differentiable Physics"", ""Benchmark""]",We propose a soft-body manipulation benchmark with differentiable physics support.,2104.03311,cs.LG,2021-04-07 17:59:23+00:00,2021-04-07 17:59:23+00:00
xCm8kiWRiBT,2021,Reject,True,Adversarial Attacks on Binary Image Recognition Systems,"[""Eric Balkanski"", ""Harrison Chase"", ""Kojin Oshiba"", ""Alexander Rilee"", ""Yaron Singer"", ""Richard Wang""]","[""Adversarial attacks"", ""Binary images"", ""Image Recognition"", ""Check processing systems""]",We study adversarial attacks on models designed to classify binary (i.e. black and white) images.,2010.11782,cs.LG,2020-10-22 14:57:42+00:00,2020-10-22 14:57:42+00:00
xCxXwTzx4L1,2021,Accept (Poster),False,ChipNet: Budget-Aware Pruning with Heaviside Continuous Approximations,"[""Rishabh Tiwari"", ""Udbhav Bamba"", ""Arnav Chavan"", ""Deepak Gupta""]","[""Structured Pruning"", ""Budget-Aware Pruning"", ""Budget constraints"", ""Sparsity Learning""]",A budget-aware deterministic strategy for structured pruning based on continuous Heaviside approximations and crispness loss.,,,,
xCy9thPPTb_,2021,Reject,False,The Compact Support Neural Network,"[""Adrian Barbu"", ""Hongyu Mou""]","[""RBF network"", ""OOD detection"", ""overconfident neural networks""]","A neural network that returns all 0 for examples far away from the training data, thus not being overconfident on out of distribution samples.",2104.00269,cs.LG,2021-04-01 06:08:09+00:00,2021-04-01 06:08:09+00:00
xD3RiCCfsY,2022,Reject,False,On Learning to Solve Cardinality Constrained Combinatorial Optimization in One-Shot: A Re-parameterization Approach via Gumbel-Sinkhorn-TopK,"['Runzhong Wang', 'Li Shen', 'Yiting Chen', 'Junchi Yan', 'Xiaokang Yang', 'Dacheng Tao']","[""Combinatorial Problems"", ""Gumbel Re-parameterization"", ""Optimal Transport"", ""Machine Learning""]","We propose Gumbel-Sinkhorn-TopK, a fast and effective one-shot solver for learning cardinality constrained combinatorial optimization problems.",,,,
xDIvIqQ3DXD,2022,Accept (Spotlight),False,On the approximation properties of recurrent encoder-decoder architectures,"['Zhong Li', 'Haotian Jiang', 'Qianxiao Li']","[""encoder-decoder"", ""recurrent neural networks"", ""approximation"", ""temporal product""]","Approximation properties of recurrent encoder-decoder architectures are given, where the formed temporal product structure further characterises temporal relationships able to be efficiently learned.",,,,
xENf4QUL4LW,2022,Accept (Poster),False,Sample Selection with Uncertainty of Losses for Learning with Noisy Labels,"['Xiaobo Xia', 'Tongliang Liu', 'Bo Han', 'Mingming Gong', 'Jun Yu', 'Gang Niu', 'Masashi Sugiyama']","[""Learning with noisy labels"", ""Sample selection"", ""Uncertainty""]",,,,,
xEpUl1um6V,2021,Reject,False,Benchmarking Bias Mitigation Algorithms in Representation Learning through Fairness Metrics,"[""Charan Reddy"", ""Soroush Mehri"", ""Deepak Sharma"", ""Samira Shabanian"", ""Sina Honari""]","[""fairness model evaluation"", ""fair deep learning"", ""adversarial fairness""]",Benchmarking Bias Mitigation Algorithms in Representation Learning through Fairness Metrics,,,,
xF5r3dVeaEl,2021,Reject,False,Local Information Opponent Modelling Using Variational Autoencoders,"[""Georgios Papoudakis"", ""Filippos Christianos"", ""Stefano V Albrecht""]","[""multi-agent systems"", ""opponent modelling"", ""reinforcement learning""]",,,,,
xFOyMwWPkz,2022,Accept (Poster),False,Quantitative Performance Assessment of CNN Units via Topological Entropy Calculation,"['Yang Zhao', 'Hao Zhang']","[""interpretation of neural network units"", ""computational topology"", ""convolutional neural networks"", ""entropy""]",We propose a novel method for quantitatively clarifying the status of individual units in CNNs and show its value in interpreting networks with different generalization ability.,,,,
xFYXLlpIyPQ,2021,Reject,True,Guarantees for Tuning the Step Size using a Learning-to-Learn Approach,"[""Xiang Wang"", ""Shuai Yuan"", ""Chenwei Wu"", ""Rong Ge""]","[""meta-learning"", ""learning-to-learn"", ""step size tuning"", ""optimization"", ""generalization""]",We give theoretical guarantees for the learning-to-learn approach on tuning the step size for quadratic loss and then verify our theory empirically on more complicated learned optimizers.,2006.16495,stat.ML,2020-06-30 02:59:35+00:00,2021-06-11 04:21:42+00:00
xGZG2kS5bFk,2021,Accept (Poster),True, Dance Revolution: Long-Term Dance Generation with Music via Curriculum Learning,"[""Ruozi Huang"", ""Huang Hu"", ""Wei Wu"", ""Kei Sawada"", ""Mi Zhang"", ""Daxin Jiang""]","[""Multimodal Learning"", ""Computer Vision"", ""Sequence Modeling"", ""Generative Models""]",,2006.06119,cs.CV,2020-06-11 00:08:25+00:00,2021-03-14 07:56:13+00:00
xH251EA80go,2021,Reject,False,A Simple Sparse Denoising Layer for Robust Deep Learning,"[""Yueming Lyu"", ""Xingrui Yu"", ""Ivor Tsang""]","[""Sparse Coding"", ""Deep Learning""]",A simple sparse denoising layer as a lightweight plug-in for robust deep learning,,,,
xHKVVHGDOEk,2021,Accept (Poster),False,Influence Functions in Deep Learning Are Fragile,"[""Samyadeep Basu"", ""Phil Pope"", ""Soheil Feizi""]","[""Influence Functions"", ""Interpretability""]",End-to-end investigation of the behaviour of influence functions in deep learning,,,,
xHqKw3xJQhi,2021,Reject,False,VEM-GCN: Topology Optimization with Variational EM for Graph Convolutional Networks,"[""Rui Yang"", ""Wenrui Dai"", ""Chenglin Li"", ""Junni Zou"", ""Hongkai Xiong""]","[""Graph Convolutional Networks"", ""Over-smoothing"", ""Topology Optimization"", ""Stochastic Block Model"", ""Variational EM""]",This paper proposes VEM-GCN for tackling the over-smoothing issue in GCNs with topology optimization that explicitly enhances intra-class connection and suppresses inter-class interaction based on the variational EM algorithm.,,,,
xIAxm1b4pWc,2022,Reject,False,Improving Sentiment Classification Using 0-Shot Generated Labels for Custom Transformer Embeddings,"['Ryan Bluteau', 'Robin Gras']","[""Sentiment Classification"", ""Transformer"", ""Natural Language Processing""]",We generate tabular emotion features using a 0-shot model and input them as embeddings to pretrained transformers such as BERT to improve sentiment classification tasks.,,,,
xJFxgRLx79J,2021,Reject,False,Learning Two-Time-Scale Representations For Large Scale Recommendations,"[""Xinshi Chen"", ""Yan Zhu"", ""Haowen Xu"", ""Muhan Zhang"", ""Liang Xiong"", ""Le Song""]","[""Recommendation System"", ""Large-scale Recommendation"", ""User Behavior Modeling"", ""Long-range sequences""]",,,,,
xKZ4K0lTj_,2022,Accept (Poster),True,Hierarchical Few-Shot Imitation with Skill Transition Models,"['Kourosh Hakhamaneshi', 'Ruihan Zhao', 'Albert Zhan', 'Pieter Abbeel', 'Michael Laskin']","[""behavioral priors"", ""skill extraction"", ""imitation learning"", ""few-shot learning""]",We introduce a new algorithm (FIST) which extracts skills from offline data and adapts them in few-shot to solve unseen complex long-horizon tasks by utilizing an inverse skill dynamics model and semi-parametric imitation. ,2107.08981,cs.LG,2021-07-19 15:56:01+00:00,2021-07-19 15:56:01+00:00
xLfAgCroImw,2022,Accept (Poster),True,"Energy-Based Learning for Cooperative Games, with Applications to Valuation Problems in Machine Learning","['Yatao Bian', 'Yu Rong', 'Tingyang Xu', 'Jiaxiang Wu', 'Andreas Krause', 'Junzhou Huang']","[""Valuation problems"", ""Shapley value"", ""Model interpretation"", ""Data valuation"", ""Enegy-based learning"", ""Attribution-based feature interpretation"", ""Model valuation for ensembles"", ""Feature attributions""]",An energy-based treatment for cooperative games provides a decoupling perspective for Shapley value and others. ,2106.02938,cs.LG,2021-06-05 17:39:04+00:00,2021-10-06 10:42:47+00:00
xMJWUKJnFSw,2022,Accept (Poster),False,NodePiece: Compositional and Parameter-Efficient Representations of Large Knowledge Graphs,"['Mikhail Galkin', 'Etienne Denis', 'Jiapeng Wu', 'William L. Hamilton']","[""knowledge graphs"", ""graph representation learning"", ""tokenization"", ""link prediction"", ""node classification""]",Node hashing in graphs for 10-100x embedding size reduction without significant performance losses on many tasks and inductive out of the box.,,,,
xNO7OEIcJc6,2022,Accept (Poster),False,Evaluating Language-biased image classification based on semantic compositionality,"['Yoann Lemesle', 'Masataka Sawayama', 'Guillermo Valle-Perez', 'Maxime Adolphe', 'HÃ©lÃ¨ne SauzÃ©on', 'Pierre-Yves Oudeyer']","[""interpretation of learned representations"", ""language and visual processing"", ""language-biased image classification"", ""cognitive science""]",We developed a benchmark test based on hierarchical semantic compositionality to evaluate the language-biased image classification of artificial models  and evaluated the CLIP model using it. ,2201.11014,cs.CV,2022-01-26 15:46:36+00:00,2022-01-26 15:46:36+00:00
xNOVfCCvDpM,2022,Accept (Poster),False,Post hoc Explanations may be Ineffective for Detecting Unknown Spurious Correlation,"['Julius Adebayo', 'Michael Muelly', 'Harold Abelson', 'Been Kim']","[""explanations"", ""feature attributions"", ""spurious correlation"", ""interpretability"", ""training point ranking""]",Post hoc explanation methods struggle to detect that deep nets are reliant on spurious training signals.,,,,
xOBMyvoMQw8,2021,Reject,True,Improving Sampling Accuracy of Stochastic Gradient MCMC Methods via Non-uniform Subsampling of Gradients,"[""Ruilin Li"", ""Xin Wang"", ""Hongyuan Zha"", ""Molei Tao""]","[""SG-MCMC"", ""Non-uniform weight""]","A new way for improving the sampling accuracy of SG-MCMC methods is proposed, together with theoretical analysis and empirical evaluations.",2002.08949,cs.LG,2020-02-20 18:56:18+00:00,2021-09-22 22:49:34+00:00
xOHuV8s7Yl,2022,Reject,False,Two Instances of Interpretable Neural Network for Universal Approximations,"['Erico Tjoa', 'Cuntai Guan']","[""Explainable Artificial Intelligence"", ""Neural Network"", ""Universal Approximation"", ""Universal Approximator""]",Two Interpretable Neural Networks for Universal Approximation,,,,
xOeWOPFXrTh,2022,Reject,True,Learning Higher-Order Dynamics in Video-Based Cardiac Measurement,"['Brian L. Hill', 'Xin Liu', 'Daniel McDuff']","[""Computer Vision"", ""Dynamic Systems"", ""Deep Learning""]",Learning Higher-Order Dynamics in Video-Based Cardiac Measurement,2110.03690,eess.IV,2021-10-07 16:29:55+00:00,2021-10-07 16:29:55+00:00
xP37gkVKa_0,2021,Reject,False,Learned Belief Search: Efficiently Improving Policies in Partially Observable Settings,"[""Hengyuan Hu"", ""Adam Lerer"", ""Noam Brown"", ""Jakob Nicolaus Foerster""]","[""Search"", ""partially observable games"", ""multi-agent learning"", ""Hanabi""]",,,,,
xP3cPq2hQC,2022,Accept (Poster),True,Cross-Domain Imitation Learning via Optimal Transport,"['Arnaud Fickinger', 'Samuel Cohen', 'Stuart Russell', 'Brandon Amos']","[""optimal transportation"", ""imitation learning"", ""cross-domain imitation learning"", ""gromov-Wasserstein""]",We study the use of Gromov-Wasserstein for cross-domain imitation learning,2110.03684,cs.LG,2021-10-07 17:59:49+00:00,2021-10-14 20:34:42+00:00
xPw-dr5t1RH,2021,Reject,False,KETG: A Knowledge Enhanced Text Generation Framework,"[""Yan Cui"", ""Xi Chen"", ""Jiang Qian"", ""Bojin Zhuang"", ""Shaojun Wang"", ""Jing Xiao""]","[""text generation"", ""knowledge graph""]",,,,,
xQUe1pOKPam,2022,Accept (Poster),True,Pre-training Molecular Graph Representation with 3D Geometry,"['Shengchao Liu', 'Hanchen Wang', 'Weiyang Liu', 'Joan Lasenby', 'Hongyu Guo', 'Jian Tang']","[""Pre-training"", ""SSL"", ""Molecule"", ""3D Geometry"", ""2D representation""]","We proposed a new SSL framework to make 3D geomety information helpful for 2D representation, in terms of the downstream tasks with 2D info only.",2110.07728,cs.LG,2021-10-07 17:48:57+00:00,2021-10-07 17:48:57+00:00
xQnvyc6r3LL,2021,Reject,False,Finding Patient Zero: Learning Contagion Source with Graph Neural Networks,"[""Chintan Shah"", ""Nima Dehmamy"", ""Nicola Perra"", ""Matteo Chinazzi"", ""Albert-Laszlo Barabasi"", ""Alessandro Vespignani"", ""Rose Yu""]","[""contagion dynamics"", ""theory of graph neural networks"", ""epidemic modeling""]",Investigation and theoretical understanding for the behavior of GNN when using it to find patient zero in epidemic dynamics. ,,,,
xRK8xgFuiu,2022,Reject,False,Causal Discovery via Cholesky Factorization,"['Xu Li', 'YUNFENG CAI', 'Mingming Sun', 'Ping Li']","[""DAG Structure Learning"", ""Causal Discovery""]","This paper proposes an extremely fast, easy to implement, and high-performance DAG structure recovering algorithm via Cholesky factorization.",,,,
xS8AMYiEav3,2022,Accept (Poster),True,Sound and Complete Neural Network Repair with Minimality and Locality Guarantees,"['Feisi Fu', 'Wenchao Li']","[""Neural Network Repair""]",,2110.07682,cs.LG,2021-10-14 19:40:40+00:00,2021-10-14 19:40:40+00:00
xTJEN-ggl1b,2021,Accept (Spotlight),False,LambdaNetworks: Modeling long-range Interactions without Attention,"[""Irwan Bello""]","[""deep learning"", ""neural networks"", ""attention"", ""transformer"", ""vision"", ""image classification""]","Scalable framework for capturing long-range interactions between input and structured contextual information, which leads to strong improvements in vision tasks.",,,,
xTV-wQ-pMrU,2021,Reject,False,Shuffle to Learn: Self-supervised learning from permutations via differentiable ranking,"[""Andrew N Carr"", ""Quentin Berthet"", ""Mathieu Blondel"", ""Olivier Teboul"", ""Neil Zeghidour""]",[],We use recent advances in differentiable ranking to allow for self-supervised pre-training using the full set of permutations.,2103.09879,cs.SD,2021-03-17 19:36:04+00:00,2021-03-17 19:36:04+00:00
xUdEO_yE-GV,2022,Reject,False,Localized Persistent Homologies for more Effective Deep Learning,"['Doruk Oner', 'AdÃ©lie Garin', 'Mateusz Kozinski', 'Kathryn Hess', 'Pascal Fua']","[""Delineation"", ""Persistent Homology"", ""Topology"", ""Aerial Images"", ""Microscopy scans""]",,,,,
xVGrCe5fCXY,2022,Reject,True,Denoising Diffusion Gamma Models,"['Eliya Nachmani', 'Robin San Roman', 'Lior Wolf']",[],A diffusion model with the Gamma distribution,2110.05948,eess.SP,2021-10-10 10:46:31+00:00,2021-10-10 10:46:31+00:00
xVlPHwnNKv,2022,Reject,False,Fast Deterministic Stackelberg Actor-Critic,"['Runsheng Yu', 'Xinrun Wang', 'James Kwok']","[""Deep Reinforcement Learning""]",,,,,
xVzlFUD3uC,2021,Reject,True,Data augmentation as stochastic optimization,"[""Boris Hanin"", ""Yi Sun""]","[""data augmentation"", ""stochastic optimization"", ""scheduling"", ""convex optimization"", ""overparametrization""]",We develop a principled theoretical approach relating data augmentation to stochastic optimization and apply it to obtain provably good augmentation schedules in the overparametrized linear setting.,2010.11171,cs.LG,2020-10-21 17:46:32+00:00,2021-10-27 00:16:34+00:00
xW9zZm9qK0_,2021,Reject,False,Class2Simi: A New Perspective on Learning with Label Noise,"[""Songhua Wu"", ""Xiaobo Xia"", ""Tongliang Liu"", ""Bo Han"", ""Mingming Gong"", ""Nannan Wang"", ""Haifeng Liu"", ""Gang Niu""]",[],,,,,
xWRX16GCugt,2022,Reject,False,Sequoia: A Software Framework to Unify Continual Learning Research,"['Fabrice Normandin', 'Oleksiy Ostapenko', 'Pau Rodriguez', 'Florian Golemo', 'Ryan Lindeborg', 'Matthew D Riemer', 'Lucas Cecchi', 'Timothee LESORT', 'Khimya Khetarpal', 'David Vazquez', 'Laurent Charlin', 'Irina Rish', 'Massimo Caccia']","[""Continual Learning"", ""Reinforcement Learning"", ""Software Engineering"", ""Deep learning""]",Sequoia is a unifying (software) framework featuring nearly all the research settings and methods from the fields of Continual Reinforcement and Continual Supervised Learning.,,,,
xYGNO86OWDH,2021,Accept (Poster),False,Isotropy in the Contextual Embedding Space: Clusters and Manifolds,"[""Xingyu Cai"", ""Jiaji Huang"", ""Yuchen Bian"", ""Kenneth Church""]","[""Contextual embedding space"", ""Isotropy"", ""Clusters"", ""Manifolds""]","This paper reveals isotropy in the clustered contextual embedding space, and found low-dimensional manifolds in there.",,,,
xYJpCgSZff,2021,Reject,False,Counterfactual Thinking for Long-tailed Information Extraction,"[""Guoshun Nan"", ""Jiaqi Zeng"", ""Rui Qiao"", ""Wei Lu""]","[""Information Extraction"", ""Natural Language Processing"", ""Long-tailed Classification"", ""Causal Inference""]",Long-tailed information extraction based on language structure and causal inference,,,,
xZ6H7wydGl,2022,Accept (Poster),False,Robust and Scalable SDE Learning: A Functional Perspective,"['Scott Alexander Cameron', 'Tyron Luke Cameron', 'Arnu Pretorius', 'Stephen J. Roberts']","[""SDE Learning"", ""Parallelization"", ""Importance Sampling""]",We provide an algorithm for estimating the probability of observations of a stochastic process which is significantly faster and more stable than those based on standard integration schemes,,,,
xa6otUDdP2W,2022,Accept (Poster),True,Effective Model Sparsification by Scheduled Grow-and-Prune Methods,"['Xiaolong Ma', 'Minghai Qin', 'Fei Sun', 'Zejiang Hou', 'Kun Yuan', 'Yi Xu', 'Yanzhi Wang', 'Yen-Kuang Chen', 'Rong Jin', 'Yuan Xie']",[],,2106.09857,cs.CV,2021-06-18 01:03:13+00:00,2021-12-11 18:34:49+00:00
xaTensJtCP5,2022,Reject,True,Semi-Empirical Objective Functions for Neural MCMC Proposal Optimization,"['Chris Cannella', 'Vahid Tarokh']","[""Markov Chain Monte Carlo"", ""Neural MCMC"", ""Generative Models"", ""Deep Generative Models"", ""Normalizing Flows""]",We introduce and demonstrate principled objective functions for optimizing MCMC proposal distributions paramterized by deep generative models.,2106.02104,cs.LG,2021-06-03 19:52:56+00:00,2022-01-29 20:10:45+00:00
xboZWqM_ELA,2021,Reject,False,Debiased Graph Neural Networks with Agnostic Label Selection Bias,"[""Shaohua Fan"", ""Xiao Wang"", ""Chuan Shi"", ""Kun Kuang"", ""Nian Liu"", ""Bai Wang""]","[""GRAPH NEURAL NETWORKS"", ""LABEL SELECTION BIAS""]",It is the first work to propose and solve the agnostic label selection bias problem in graph neural networks.,,,,
xbu1tzbjvd,2022,Reject,False,Analyzing Populations of Neural Networks via Dynamical Model Embedding,"['Jordan Cotler', 'Kai Sheng Tai', 'Felipe Hernandez', 'Blake Elias', 'David Sussillo']","[""dynamics"", ""RNNs"", ""model averaging"", ""model clustering"", ""CNNs"", ""semi-supervised learning""]","We have introduced the algorithm DYNAMO, which maps a set of neural network base models to a low dimensional feature space which captures computational features of the networks.",,,,
xbx7Hxjbd79,2022,Reject,False,COLA: Consistent Learning with Opponent-Learning Awareness,"['Timon Willi', 'Johannes Treutlein', 'Alistair Letcher', 'Jakob Nicolaus Foerster']","[""Differentiable games"", ""multi-agent reinforcement learning"", ""general-sum games"", ""lola""]",,,,,
xcd5iTC6J-W,2021,Reject,False,Hidden Markov models are recurrent neural networks: A disease progression modeling application,"[""Matthew Baucum"", ""Anahita Khojandi"", ""Theodore Papamarkou""]","[""hidden markov models"", ""recurrent neural networks"", ""disease progression""]",We develop a neural network implementation of hidden Markov models that can be combined with other predictive networks to improve predictive accuracy and parameter solutions.,,,,
xf0B7-7MRo6,2022,Reject,False,AIR-Net: Adaptive and Implicit Regularization Neural Network for matrix completion,"['Zhemin Li', 'Hongxia Wang']",[],We utilize neural networks to represent Adaptive and Implicit Regularization and named the proposed model \textit{AIR-Net} for Matrix Completion.,,,,
xfNotLXwtQb,2021,Reject,False,Inductive Collaborative Filtering via Relation Graph Learning,"[""Qitian Wu"", ""Hengrui Zhang"", ""Xiaofeng Gao"", ""Hongyuan Zha""]","[""collaborative filtering"", ""matrix completion"", ""inductive learning"", ""relation learning"", ""recommender systems""]",We develop an inductive collaborative filtering model that can inductively compute user representations via message passing over latent relational graphs,,,,
xfOVXyO_cwJ,2021,Reject,True,Empirical Frequentist Coverage of Deep Learning Uncertainty Quantification Procedures,"[""Benjamin Kompa"", ""Jasper Snoek"", ""Andrew Beam""]","[""uncertainty quantification"", ""coverage"", ""dataset shift""]",We have provided the first comprehensive empirical study of the frequentist-style coverage properties of popular uncertainty quantification techniques for deep learning models.,2010.03039,cs.LG,2020-10-06 21:22:46+00:00,2021-02-24 20:54:18+00:00
xfmSoxdxFCG,2021,Accept (Poster),False,Can a Fruit Fly Learn Word Embeddings?,"[""Yuchen Liang"", ""Chaitanya Ryali"", ""Benjamin Hoover"", ""Leopold Grinberg"", ""Saket Navlakha"", ""Mohammed J Zaki"", ""Dmitry Krotov""]","[""neurobiology"", ""neuroscience"", ""fruit fly"", ""locality sensitive hashing"", ""word embedding"", ""sparse representations""]",We show that a network motif from the fruit fly brain can learn word embeddings.,,,,
xgGS6PmzNq6,2021,Accept (Poster),False,On Dyadic Fairness: Exploring and Mitigating Bias in Graph Connections,"[""Peizhao Li"", ""Yifei Wang"", ""Han Zhao"", ""Pengyu Hong"", ""Hongfu Liu""]","[""algorithmic fairness"", ""graph-structured data""]",A new method on the fairness of predictive relationships in graph-structured data,,,,
xiXOrugVHs,2022,Reject,False,Long Document Summarization with Top-Down and Bottom-Up Representation Inference,"['Bo Pang', 'Erik Nijkamp', 'Wojciech Maciej Kryscinski', 'Silvio Savarese', 'Yingbo Zhou', 'Caiming Xiong']","[""top-down inference"", ""bottom-up inference"", ""long document summarization""]",We improve text latent representations by combining top-down and bottom-up inference to effectively and efficiently summarize long documents. ,,,,
xiwHM0l55c3,2021,Reject,False,Monotonic neural network: combining deep learning with domain knowledge for chiller plants energy optimization,"[""Fanhe Ma"", ""Faen Zhang"", ""Shenglan Ben"", ""Shuxin Qin"", ""pengcheng Zhou"", ""Changsheng Zhou"", ""Fengyi Xu""]",[],,2106.06143,eess.SP,2021-06-11 03:01:26+00:00,2021-06-11 03:01:26+00:00
xjXg0bnoDmS,2021,Accept (Poster),True,Entropic gradient descent algorithms and wide flat minima,"[""Fabrizio Pittorino"", ""Carlo Lucibello"", ""Christoph Feinauer"", ""Gabriele Perugini"", ""Carlo Baldassi"", ""Elizaveta Demyanenko"", ""Riccardo Zecchina""]","[""flat minima"", ""entropic algorithms"", ""statistical physics"", ""belief-propagation""]","Relation between local entropy, flat minima, entropic algorithms and good generalization.",2006.07897,cs.LG,2020-06-14 13:22:19+00:00,2021-11-15 22:56:17+00:00
xkjqJYqRJy,2022,Accept (Poster),False,Bayesian Neural Network Priors Revisited,"['Vincent Fortuin', 'AdriÃ  Garriga-Alonso', 'Sebastian W. Ober', 'Florian Wenzel', 'Gunnar Ratsch', 'Richard E Turner', 'Mark van der Wilk', 'Laurence Aitchison']","[""Bayesian deep learning"", ""Bayesian neural networks"", ""Priors""]",Using BNN priors that are not isotropic Gaussians can improve performance and reduce the cold posterior effect.,,,,
xm6YD62D1Ub,2022,Accept (Poster),True,VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning,"['Adrien Bardes', 'Jean Ponce', 'Yann LeCun']","[""self-supervised learning"", ""representation learning"", ""computer vision""]",Variance regularization prevents collapse in self-supervised representation learning,2105.04906,cs.CV,2021-05-11 09:53:21+00:00,2022-01-28 12:23:37+00:00
xnC8YwKUE3k,2021,Accept (Poster),False,Clairvoyance: A Pipeline Toolkit for Medical Time Series,"[""Daniel Jarrett"", ""Jinsung Yoon"", ""Ioana Bica"", ""Zhaozhi Qian"", ""Ari Ercole"", ""Mihaela van der Schaar""]","[""reproducibility"", ""healthcare"", ""medical time series"", ""pipeline toolkit"", ""software""]",We develop and present Clairvoyance: a pipeline toolkit for medical time series.,,,,
xnYACQquaGV,2022,Accept (Poster),True,Neural Contextual Bandits with Deep Representation and Shallow Exploration,"['Pan Xu', 'Zheng Wen', 'Handong Zhao', 'Quanquan Gu']","[""neural network"", ""deep representation learning""]",A new neural network based algorithm for contextual bandit problems with theoretical guarantees and empirical advantages.,2012.01780,cs.LG,2020-12-03 09:17:55+00:00,2020-12-03 09:17:55+00:00
xng0HoPDaFN,2021,Reject,False,An Adversarial Attack via Feature Contributive Regions,"[""Yaguan Qian"", ""Jiamin Wang"", ""Xiang Ling"", ""Zhaoquan Gu"", ""Bin Wang"", ""Chunming Wu""]","[""Adversarial example"", ""Feature contributive regions"", ""Local attack""]",This work explores the method of generating perturbations via the feature contribution regions and provides evidence to prove that the attack on the local semanticsis the most effective.,,,,
xoHdgbQJohv,2021,Accept (Poster),False,Multiscale Score Matching for Out-of-Distribution Detection,"[""Ahsan Mahmood"", ""Junier Oliva"", ""Martin Andreas Styner""]","[""out-of-distribution detection"", ""score matching"", ""deep learning"", ""outlier detection""]",Using score estimates at multiple noise scales outperforms state-of-the-art in out-of-distribution detection.,,,,
xoPj3G-OKNM,2021,Reject,True,Stochastic Normalized Gradient Descent with Momentum for Large Batch Training,"[""Shen-Yi Zhao"", ""Yin-Peng Xie"", ""Wu-Jun Li""]","[""normalized gradient"", ""large batch training size""]",A novel method called stochastic normalized gradient descent with momentum (SNGM) for large batch training.,2007.13985,stat.ML,2020-07-28 04:34:43+00:00,2020-07-28 04:34:43+00:00
xo_5lb5ond,2022,Reject,False,LEAN: graph-based pruning for convolutional neural networks by extracting longest chains,"['Richard Arnoud Schoonhoven', 'Allard Hendriksen', 'Daniel Pelt', 'Joost Batenburg']","[""Pruning"", ""Sparsity"", ""Compression"", ""Graph pruning""]",We propose the LEAN pruning method that prunes CNNs by using graph-based algorithms to select important chains of convolutions.,,,,
xp2D-1PtLc5,2022,Reject,False,ClsVC: Learning Speech Representations with two different classification tasks.,"['Tang huaizhen', 'xulong Zhang', 'Jianzong Wang', 'ning Cheng', 'Jing Xiao']","[""voice conversion"", ""gradient reversal"", ""adversarial learning"", ""speech synthesis""]",a novel framework for voice conversion,,,,
xpFFI_NtgpW,2021,Accept (Poster),False,Rethinking Embedding Coupling in Pre-trained Language Models,"[""Hyung Won Chung"", ""Thibault Fevry"", ""Henry Tsai"", ""Melvin Johnson"", ""Sebastian Ruder""]","[""natural language processing"", ""transfer learning"", ""efficiency"", ""pre-training""]",Decoupling output embedding shapes leads to more transferable Transformer layers and prevents over-specialization of a Transformer's upper layers to the pre-training task.,,,,
xppLmXCbOw1,2021,Accept (Spotlight),False,Self-supervised Visual Reinforcement Learning with Object-centric Representations,"[""Andrii Zadaianchuk"", ""Maximilian Seitzer"", ""Georg Martius""]","[""self-supervision"", ""autonomous learning"", ""object-centric representations"", ""visual reinforcement learning""]",The combination of object-centric representations and goal-conditioned attention policies helps autonomous agents to learn useful multi-task policies in visual multi-object environments,,,,
xpx9zj7CUlY,2021,Accept (Oral),False,Randomized Automatic Differentiation,"[""Deniz Oktay"", ""Nick McGreivy"", ""Joshua Aduol"", ""Alex Beatson"", ""Ryan P Adams""]","[""automatic differentiation"", ""autodiff"", ""backprop"", ""deep learning"", ""pdes"", ""stochastic optimization""]","We develop a general framework and approach for randomized automatic differentiation (RAD), which can allow unbiased gradient estimates to be computed with reduced memory in return for variance.",,,,
xrLrpG3Ep1X,2021,Reject,False,Domain-Free Adversarial Splitting for Domain Generalization,"[""Xiang Gu"", ""Jiasun Feng"", ""Jian Sun"", ""Zongben Xu""]","[""domain generalization"", ""adversarial splitting"", ""meta-learning"", ""image recognition""]","We propose a novel domain generalization method that unifies adversarial splitting of training dataset and meta-learning in a novel Domain-Free Adversarial Splitting framework, achieving state-of-the-art results in domain generalization.",,,,
xrUySgB5ZOK,2021,Reject,False,Learning Visual Representations for Transfer Learning by Suppressing Texture,"[""Shlok Kumar Mishra"", ""Anshul Shah"", ""Ankan Bansal"", ""Jonghyun Choi"", ""Abhinav Shrivastava"", ""Abhishek Sharma"", ""David Jacobs""]","[""Suppressing Texture"", ""Transfer learning"", ""Self-Supervised Learning""]",Suppressing texture leads to better transfer learning performance. ,,,,
xs-tJn58XKv,2022,Reject,True,Learning Stable Classifiers by Transferring Unstable Features,"['Yujia Bao', 'Shiyu Chang', 'Regina Barzilay']","[""transfer learning"", ""spurious correlation"", ""invariant learning""]",,2106.07847,cs.LG,2021-06-15 02:41:12+00:00,2022-01-25 16:15:06+00:00
xspalMXAB0M,2022,Reject,False,A Boosting Approach to Reinforcement Learning,"['Nataly Brukhim', 'Elad Hazan', 'Karan Singh']",[],,,,,
xsx58rmaW2p,2021,Reject,True,Making Coherence Out of Nothing At All: Measuring Evolution of Gradient Alignment,"[""Satrajit Chatterjee"", ""Piotr Zielinski""]","[""generalization"", ""deep learning""]",We present a new metric to study per-example gradient alignment that is mathematically cleaner and more interpretable than previously proposed metrics and use it to empirically study the evolution of gradient alignment in large scale training. ,2008.01217,cs.LG,2020-08-03 21:51:24+00:00,2020-08-03 21:51:24+00:00
xtKFuhfK1tK,2021,Reject,False,Communication-Efficient Sampling for Distributed Training of Graph Convolutional Networks,"[""Peng Jiang"", ""Masuma Akter Rumi""]","[""Graph Convolutional Networks"", ""Sampling"", ""Distributed Training""]",A new neighbor sampling method for reducing the communication overhead in distributed GCN training. ,2101.07706,cs.LG,2021-01-19 16:12:44+00:00,2021-01-19 16:12:44+00:00
xtZXWpXVbiK,2022,Reject,False,Flow-based Recurrent Belief State Learning for POMDPs,"['Xiaoyu Chen', 'Yao Mu', 'Ping Luo', 'Shengbo Eben Li', 'Jianyu Chen']","[""Partially Observable Markov Decision Process"", ""POMDP"", ""Model-based Reinforcement Learning"", ""Visual Control Task""]",,,,,
xvxPuCkCNPO,2021,Accept (Spotlight),True,Correcting experience replay for multi-agent communication,"[""Sanjeevan Ahilan"", ""Peter Dayan""]","[""multi-agent reinforcement learning"", ""experience replay"", ""communication"", ""relabelling""]",We improve multi-agent learning by relabelling past experience to better reflect current communication policies ,2010.01192,cs.LG,2020-10-02 20:49:24+00:00,2021-02-28 22:42:12+00:00
xw04RdwI2kS,2022,Reject,True,Inverse Contextual Bandits: Learning How Behavior Evolves over Time,"['Alihan HÃ¼yÃ¼k', 'Daniel Jarrett', 'Mihaela van der Schaar']","[""inverse contextual bandits"", ""understanding decision-making""]",,2107.06317,cs.LG,2021-07-13 18:24:18+00:00,2021-10-13 16:22:11+00:00
xwAw8QZkpWZ,2022,Reject,False,SAFER: Data-Efficient and Safe Reinforcement Learning Through Skill Acquisition,"['Dylan Z Slack', 'Yinlam Chow', 'Bo Dai', 'Nevan Wichers']","[""safety"", ""reinforcement learning"", ""behavioral priors"", ""skill primitives""]",SAFER accelerates safe learning on downstream tasks by learning both safe and useful behaviors from offline data.,,,,
xxU6qGx-2ew,2022,Reject,False,Gaussian Differential Privacy Transformation: from identification to application,"['Yi Liu', 'Ke Sun', 'Bei Jiang', 'Linglong Kong']","[""differential privacy"", ""gaussian differential privacy"", ""privacy profile""]",,,,,
xxWl2oEvP2h,2021,Reject,False,Rewriting by Generating: Learn Heuristics for Large-scale Vehicle Routing Problems,"[""Hansen Wang"", ""Zefang Zong"", ""Tong Xia"", ""Shuyu Luo"", ""Meng Zheng"", ""Depeng Jin"", ""Yong Li""]","[""vehicle routing problem"", ""reinforcement learning"", ""optimization""]",We propose a novel Rewriting by Generating (RBG) framework based on hierarchical RL agents to solve large-scale vehicle routing problem with usually more than a thousand customers.. ,,,,
xxyTjJFzy3C,2022,Reject,False,Contrastive Learning of 3D Shape Descriptor with Dynamic Adversarial Views,"['Shuaihang Yuan', 'Yi Fang']","[""Dynamic multi-views""]",,,,,
xyEx4_lHqvB,2021,Reject,False,Ensemble-based Adversarial Defense Using Diversified Distance Mapping,"[""Ehsan Kazemi"", ""Mohamed E. Hussein"", ""Wael AbdAlmgaeed""]","[""adversarial machine learning"", ""ensemble"", ""mahalanobis distance""]",,,,,
xyGFYKIPTDJ,2021,Reject,False,Learning Causal Semantic Representation for Out-of-Distribution Prediction,"[""Chang Liu"", ""Xinwei Sun"", ""Jindong Wang"", ""Tao Li"", ""Tao Qin"", ""Wei Chen"", ""Tie-Yan Liu""]","[""out-of-distribution"", ""causality"", ""latent variable model"", ""generative model"", ""variational auto-encoder"", ""domain adaptation""]",We propose a model that identifies the semantic latent factor and invariant latent causal mechanisms for out-of-distribution generalization and domain adaptation.,,,,
xy_2w3J3kH,2022,Accept (Poster),False,Communication-Efficient Actor-Critic Methods for Homogeneous Markov Games,"['Dingyang Chen', 'Yile Li', 'Qi Zhang']","[""multi-agent reinforcement learning"", ""multi-agent communication""]",,,,,
xzqLpqRzxLq,2021,Accept (Poster),False,IEPT: Instance-Level and Episode-Level Pretext Tasks for Few-Shot Learning,"[""Manli Zhang"", ""Jianhong Zhang"", ""Zhiwu Lu"", ""Tao Xiang"", ""Mingyu Ding"", ""Songfang Huang""]","[""few-shot learning"", ""self-supervised learning"", ""episode-level pretext task""]",This paper proposes a novel Instance-level and Episode-level Pretext Task (IEPT) framework that seamlessly integrates SSL into FSL.,,,,
y06VOYLcQXa,2021,Accept (Poster),False,Private Image Reconstruction from System Side Channels Using Generative Models,"[""Yuanyuan Yuan"", ""Shuai Wang"", ""Junping Zhang""]","[""side channel analysis""]",We present the first generative model-based side channel analysis (SCA) to reconstruct private user images.,,,,
y0VvIg25yk,2022,Accept (Poster),False,On the Learning of Quasimetrics,"['Tongzhou Wang', 'Phillip Isola']","[""embedding learning"", ""quasimetric learning"", ""deep learning""]","We theoretically analyze various algorithms on learning quasimetrics (asymmetrical metrics), and propose an embedding-based method with strong guarantees. Experiments on graph learning and Q-learning show its effectiveness over common baselines.",,,,
y13JLBiNMsf,2021,Reject,False,Learning Monotonic Alignments with Source-Aware GMM Attention,"[""Tae Gyoon Kang"", ""Ho-Gyeong Kim"", ""Min-Joong Lee"", ""Jihyun Lee"", ""Seongmin Ok"", ""Hoshik Lee"", ""Young Sang Choi""]","[""Monotonic alignments"", ""sequence-to-sequence model"", ""aligned attention"", ""streaming speech recognition"", ""long-form speech recognition""]",We focus on monotonic sequence-to-sequence tasks and propose source-aware GMM attention which enables online inference and improves long-form sequence generation performance in speech recognition.,,,,
y1PXylgrXZ,2022,Accept (Poster),False,Certified Robustness for Deep Equilibrium Models via Interval Bound Propagation,"['Colin Wei', 'J Zico Kolter']","[""deep equilibrium models"", ""certified robustness"", ""interval bound propagation""]","To develop certifiably robust deep equilibrium (DEQ) models, we propose the IBP-MonDEQ layer, a DEQ layer where interval bounds on the output can be obtained by solving an additional fixed-point equation inspired by interval bound propagation.",,,,
y1faDxZ_-0a,2022,Reject,False,SSFL: Tackling Label Deficiency in Federated Learning via Personalized Self-Supervision,"['Chaoyang He', 'Zhengyu Yang', 'Erum Mushtaq', 'Sunwoo Lee', 'Mahdi Soltanolkotabi', 'Salman Avestimehr']","[""federated learning""]",Tackling Label Deficiency in Federated Learning via Personalized Self-Supervision,,,,
y2I4gyAGlCB,2021,Reject,False,Imagine That! Leveraging Emergent Affordances for 3D Tool Synthesis,"[""Yizhe Wu"", ""Sudhanshu Kasewa"", ""Oliver Groth"", ""Sasha Salter"", ""Kevin Li Sun"", ""Oiwi Parker Jones"", ""Ingmar Posner""]","[""Affordance Learning"", ""Imagination"", ""Generative Models"", ""Activation Maximisation""]",We demonstrate that a task-driven traversal of a learned latent space leads to object affordances emerging naturally as smooth trajectories in this space accessible via the optimisation of high-level performance criteria.,,,,
y4-e1K23GLC,2021,Reject,False,A law of robustness for two-layers neural networks,"[""Sebastien Bubeck"", ""Yuanzhi Li"", ""Dheeraj Mysore Nagaraj""]","[""neural networks"", ""approximation theory"", ""robust machine learning""]","We conjecture a precise tradeoff between the size of a neural network and its robustness, and prove variants of the conjecture.",,,,
y7tKDxxTo8T,2022,Reject,False,Zero-Shot Recommender Systems,"['HAO DING', 'Yifei Ma', 'Anoop Deoras', 'Bernie Wang', 'Hao Wang']","[""Zero Shot Learning"", ""Recommender Systems"", ""Neural Networks"", ""Bayesian""]",A novel hierarchical Bayesian model that performs zero-shot recommendation in a target domain where there are neither overlapping users nor overlapping items with the source domain.,,,,
y8zhHLm7FsP,2022,Reject,False,Ensemble Kalman Filter (EnKF) for Reinforcement Learning (RL),"['Anant A Joshi', 'Amirhossein Taghvaei', 'Prashant G Mehta']","[""decision and control"", ""control theory"", ""reinforcement learning""]",A novel reinforcement learning algorithm based on duality between optimal control and optimal estimation.,,,,
yBJihVXahXc,2021,Reject,False,Generalizing Graph Convolutional Networks via Heat Kernel,"[""Jialin Zhao"", ""Yuxiao Dong"", ""Jie Tang"", ""Ming Ding"", ""Kuansan Wang""]","[""graph networks""]",A continuous propagation model of GCNs with heat kernel.,,,,
yBYVUDj7yF,2022,Reject,True,The Power of Contrast for Feature Learning: A Theoretical Analysis,"['Wenlong Ji', 'Zhun Deng', 'Ryumei Nakada', 'James Zou', 'Linjun Zhang']","[""contrastive learning"", ""self-supervised learning"", ""transfer learning""]","This paper provides a theoretical understanding about the power of contrastive learning on representation learning, downstream task performance, and transferability.",2110.02473,cs.LG,2021-10-06 03:10:28+00:00,2021-12-20 06:17:36+00:00
yCS5dckx_vj,2022,Reject,False,Towards Demystifying Representation Learning with Non-contrastive Self-supervision,"['Xiang Wang', 'Xinlei Chen', 'Simon Shaolei Du', 'Yuandong Tian']","[""self-supervised learning"", ""representation learning"", ""non-contrastive methods"", ""DirectPred"", ""theoretical analysis""]","We analyzed the representation learning process of non-contrastive self-supervised learning in linear networks, and also proposed a new algorithm DirectCopy that achieves good performance in various datasets.",,,,
yEnaS6yOkxy,2021,Reject,False,Class Balancing GAN with a Classifier in the Loop,"[""Harsh Rangwani"", ""Konda Reddy Mopuri"", ""Venkatesh Babu Radhakrishnan""]","[""Long-tailed Learning"", ""GAN"", ""Universal Adversarial Perturbations""]",A regularizer for balancing class distributions of GAN samples with application to long-tailed learning and data-free adversarial attacks.,,,,
yFJ67zTeI2,2021,Accept (Poster),False,Semi-supervised Keypoint Localization,"[""Olga Moskvyak"", ""Frederic Maire"", ""Feras Dayoub"", ""Mahsa Baktashmotlagh""]","[""semi-supervised learning"", ""keypoint localization"", ""limited data"", ""unsupervised loss""]",A novel method for semi-supervised keypoint localization via learning semantic keypoint representations.,2101.07988,cs.CV,2021-01-20 06:23:08+00:00,2021-01-20 06:23:08+00:00
yHeg4PbFHh,2021,Accept (Spotlight),True,BUSTLE: Bottom-Up Program Synthesis Through Learning-Guided Exploration,"[""Augustus Odena"", ""Kensen Shi"", ""David Bieber"", ""Rishabh Singh"", ""Charles Sutton"", ""Hanjun Dai""]","[""Program Synthesis""]",We use a learned model to guide a bottom-up program synthesis search to efficiently synthesize spreadsheet programs.,2007.14381,cs.PL,2020-07-28 17:46:18+00:00,2021-09-30 13:50:43+00:00
yJHpncwG1B,2021,Reject,False,Federated Learning's Blessing: FedAvg has Linear Speedup,"[""Zhaonan Qu"", ""Kaixiang Lin"", ""Zhaojian Li"", ""Jiayu Zhou"", ""Zhengyuan Zhou""]","[""Federated learning""]",The first proof of linear speedup convergence rate for FedAvg.,,,,
yKIAXjkJc2F,2022,Accept (Spotlight),False,Imbedding Deep Neural Networks,"['Andrew Corbett', 'Dmitry Kangin']","[""Neural ODEs"", ""Optimal Control"", ""Deep Neural Networks"", ""Invariant Imbedding""]",Invariant imbedding solution for (Bolza) optimal control problem derived and proved to yield new architectures of imbedded deep neural networks.,2202.00113,cs.LG,2022-01-31 22:00:41+00:00,2022-01-31 22:00:41+00:00
yKYiyoHG4N3,2021,Reject,True,Optimal Neural Program Synthesis from Multimodal Specifications,"[""Xi Ye"", ""Qiaochu Chen"", ""Isil Dillig"", ""Greg Durrett""]","[""program synthesis""]",An optimal neural synthesis approach that finds an I/O-statisfying program while also maximizing the program's score with respect to a neural model. ,2010.01678,cs.CL,2020-10-04 20:51:21+00:00,2021-09-14 18:07:13+00:00
yK_jcv_aLX,2022,Reject,True,Action-Sufficient State Representation Learning for Control with Structural Constraints,"['Biwei Huang', 'Chaochao Lu', 'Liu Leqi', 'JosÃ© Miguel HernÃ¡ndez-Lobato', 'Clark Glymour', 'Bernhard SchÃ¶lkopf', 'Kun Zhang']","[""Representation learning in RL"", ""Minimal sufficient state representations"", ""Graphical model"", ""World model""]",Minimal sufficient state representations for control by leveraging structural constraints,2110.05721,cs.LG,2021-10-12 03:16:26+00:00,2021-10-12 03:16:26+00:00
yN18f9V1Onp,2021,Reject,False,Adaptive Learning Rates for Multi-Agent Reinforcement Learning,"[""Jiechuan Jiang"", ""Zongqing Lu""]",[],,,,,
yN5kwvn4E1R,2021,Reject,False,Dual Graph Complementary Network,"[""Chenhua Liu"", ""Kun Zhan""]",[],,,,,
yOBqNg-CqB0,2022,Reject,True,Re-evaluating Word Mover's Distance,"['Ryoma Sato', 'Makoto Yamada', 'Hisashi Kashima']","[""optimal transport"", ""word mover's distance""]",We re-evaluate the Word Mover's Distance and reveal the true performance of it.,2105.14403,cs.LG,2021-05-30 01:35:03+00:00,2021-05-30 01:35:03+00:00
yOkSW62hqq2,2021,Reject,False,Explicit Connection Distillation,"[""Lujun Li"", ""Yikai Wang"", ""Anbang Yao"", ""Yi Qian"", ""Xiao Zhou"", ""Ke He""]",[],,,,,
yOkmUBv9ed,2021,Reject,False,Block Skim Transformer for Efficient Question Answering,"[""Yue Guan"", ""Jingwen Leng"", ""Yuhao Zhu"", ""Minyi Guo""]","[""Efficient Transformer"", ""Question Answering""]",An efficient plug-to-play method for Transformer-based models by skmming context blocks.,,,,
yRP4_BOxdu,2021,Reject,False,Joint Learning of Full-structure Noise in Hierarchical Bayesian Regression Models,"[""Ali Hashemi"", ""Chang Cai"", ""Klaus Robert Muller"", ""Srikantan Nagarajan"", ""Stefan Haufe""]","[""Full-structure Noise"", ""Hierarchical Bayesian Regression Models"", ""Sparse Bayesian Learning"", ""Unsupervised Learning"", ""Brain Source Imaging"", ""Covariance Estimation.""]",,,,,
yRYtnKAZqxU,2022,Reject,False,Interrogating Paradigms in Self-supervised Graph Representation Learning,"['Puja Trivedi', 'Mark Heimann', 'Danai Koutra', 'Jayaraman J. Thiagarajan']","[""Graph Neural Networks"", ""Contrastive Learning"", ""Self-supervised Learning""]",We investigate conditions for success when using graph contrastive learning or reconstruction based methods for unsupervised graph representation learning.,,,,
ySQH0oDyp7,2022,Accept (Poster),False,QDrop: Randomly Dropping Quantization for Extremely Low-bit Post-Training Quantization,"['Xiuying Wei', 'Ruihao Gong', 'Yuhang Li', 'Xianglong Liu', 'Fengwei Yu']",[],,,,,
yT7-k6Q6gda,2021,Reject,False,Catastrophic Fisher Explosion: Early Phase Fisher Matrix Impacts Generalization,"[""Stanislaw Kamil Jastrzebski"", ""Devansh Arpit"", ""Oliver \u00c5strand"", ""Giancarlo Kerg"", ""Huan Wang"", ""Caiming Xiong"", ""richard socher"", ""Kyunghyun Cho"", ""Krzysztof J. Geras""]","[""early phase of training"", ""implicit regularization"", ""SGD"", ""learning rate"", ""batch size"", ""Hessian"", ""Fisher Information Matrix"", ""curvature"", ""gradient norm""]",Explicit regularization of the trace of the Fisher Information Matrix models implicit regularization in stochastic gradient descent.,,,,
yUxUNaj2Sl,2021,Accept (Poster),False,Does enhanced shape bias improve neural network robustness to common corruptions?,"[""Chaithanya Kumar Mummadi"", ""Ranjitha Subramaniam"", ""Robin Hutmacher"", ""Julien Vitay"", ""Volker Fischer"", ""Jan Hendrik Metzen""]","[""neural network robustness"", ""shape bias"", ""corruptions"", ""distribution shift""]",We show that robustness on common corruptions donot correlate with strong shape bias but with the effective data augmentation strategies like stylization,2104.09789,cs.CV,2021-04-20 07:06:53+00:00,2021-04-20 07:06:53+00:00
yV4_fWe4nM,2022,Reject,True,Deep Fair Discriminative Clustering,"['Hongjing Zhang', 'Ian Davidson']","[""Clustering"", ""Deep learning"", ""Fairness""]",This paper presents a deep learning model for clustering with group-level fairness constraints.,2105.14146,cs.LG,2021-05-28 23:50:48+00:00,2021-05-28 23:50:48+00:00
yWkP7JuHX1,2021,Accept (Oral),True,Image GANs meet Differentiable Rendering for Inverse Graphics and Interpretable 3D Neural Rendering,"[""Yuxuan Zhang"", ""Wenzheng Chen"", ""Huan Ling"", ""Jun Gao"", ""Yinan Zhang"", ""Antonio Torralba"", ""Sanja Fidler""]","[""Differentiable rendering"", ""inverse graphics"", ""GANs""]",We marry generative models with differentiable rendering to extract and disentangle 3D knowledge learned implicitly by generative image synthesis models,2010.09125,cs.CV,2020-10-18 22:29:07+00:00,2021-04-20 18:06:17+00:00
yXBb-0cPSKO,2022,Reject,False,Regularized-OFU: an efficient algorithm for general contextual bandit with optimization oracles,"['Yichi Zhou', 'Shihong Song', 'Huishuai Zhang', 'Jun Zhu', 'Wei Chen', 'Tie-Yan Liu']",[],,,,,
yZBuYjD8Gd,2021,Reject,False,Are all negatives created equal in contrastive instance discrimination?,"[""Tiffany Cai"", ""Jonathan Frankle"", ""David J. Schwab"", ""Ari S. Morcos""]","[""self-supervised learning"", ""contrastive learning"", ""contrastive instance discrimination"", ""negatives"", ""understanding self-supervised learning"", ""ssl""]","We study the relative importance of negatives in contrastive instance discrimination, finding that only the hardest 5% of negatives are necessary and sufficient for good performance, and these negatives are more semantically similar to the query.",,,,
yZkF6xqhfQ,2021,Reject,False,Do Transformers Understand Polynomial Simplification? ,"[""Vishesh Agarwal"", ""Somak Aditya"", ""Navin Goyal""]",[],,,,,
y_op4lLLaWL,2022,Accept (Poster),False,Variational autoencoders in the presence of low-dimensional data: landscape and implicit bias,"['Frederic Koehler', 'Viraj Mehta', 'Chenghui Zhou', 'Andrej Risteski']","[""variational autoencoders"", ""encoder"", ""optima"", ""stability"", ""low-dimensional manifold""]",We analyze the landscape and implicit optimization bias of VAEs in the presence of low-dimensional data and the implications thereof. ,,,,
y_pDlU_FLS,2021,Reject,True,Reverse engineering learned optimizers reveals known and novel mechanisms,"[""Niru Maheswaranathan"", ""David Sussillo"", ""Luke Metz"", ""Ruoxi Sun"", ""Jascha Sohl-Dickstein""]","[""learned optimizers"", ""optimization"", ""recurrent neural networks"", ""RNNs"", ""interpretability""]","We demonstrate that learned optimizers, parameterized by recurrent networks, learn interpretable mechanisms (momentum, gradient clipping, schedules, and learning rate adaptation).",2011.02159,cs.LG,2020-11-04 07:12:43+00:00,2020-11-04 07:12:43+00:00
y_tIL5vki1l,2022,Reject,True,LatentKeypointGAN: Controlling GANs via Latent Keypoints,"['Xingzhe He', 'Bastian Wandt', 'Helge Rhodin']","[""Part Disentanglement"", ""Unsupervised Learning""]","A GAN that controls the image content via latent keypoints that are learned without supervision, thereby internally disentangling the image into parts.",2103.15812,cs.CV,2021-03-29 17:59:10+00:00,2021-12-02 02:18:05+00:00
ybsh6zEzIKA,2022,Reject,True,Intrusion-Free Graph Mixup,"['Hongyu Guo', 'Yongyi Mao']","[""graph augmentation"", ""Mixup"", ""graph classification"", ""graph neural networks""]","We propose the first input mixing schema for Mixup on graph, with theoretical guarantee of manifold intrusion free.",2110.09344,cs.LG,2021-10-18 14:16:00+00:00,2021-12-30 02:11:15+00:00
ydopy-e6Dg,2022,Accept (Poster),False,Image BERT Pre-training with Online Tokenizer,"['Jinghao Zhou', 'Chen Wei', 'Huiyu Wang', 'Wei Shen', 'Cihang Xie', 'Alan Yuille', 'Tao Kong']","[""online tokenizer"", ""masked image modeling"", ""vision transformer""]","We present a self-supervised framework iBOT that can perform masked image modeling with an online tokenizer, achieving the state-of-the-art results in downstream tasks.",2111.07832,cs.CV,2021-11-15 15:18:05+00:00,2022-01-27 09:20:49+00:00
yeP_zx9vqNm,2022,Accept (Spotlight),False,Finding Biological Plausibility for Adversarially Robust Features via Metameric Tasks,"['Anne Harrington', 'Arturo Deza']","[""Peripheral Computation"", ""Adversarial Robustness"", ""Perceptual Invariance"", ""Metamerism"", ""Texture"", ""Psychophysics""]",We suggest that the representations learned by an Adversarially Trained Network are aligned with Human Peripheral Computation,2202.00838,cs.CV,2022-02-02 01:19:40+00:00,2022-02-04 00:24:45+00:00
yeeS_HULL7Z,2021,Reject,False,Attention-Based Clustering: Learning a Kernel from Context,"[""Samuel Coward"", ""Erik Visse-Martindale"", ""Chithrupa Ramesh""]","[""Similarity learning"", ""kernel methods"", ""constrained clustering"", ""transformer analysis"", ""spectral clustering"", ""supervised learning"", ""deep learning""]","We propose an attention-based architecture that utilizes contextual information to learn a kernel, and combine it with an off-the-shelf clustering method to obtain state-of-the-art results on the Omniglot dataset.",,,,
yfKOB5CO5dY,2021,Reject,False,Localized Meta-Learning: A PAC-Bayes Analysis for Meta-Learning Beyond Global Prior,"[""Chenghao Liu"", ""Tao Lu"", ""Doyen Sahoo"", ""Yuan Fang"", ""Kun Zhang"", ""Steven Hoi""]","[""localized meta-learning"", ""PAC-Bayes"", ""meta-learning""]",,,,,
yfe1VMYAXa4,2022,Accept (Poster),False,OntoProtein: Protein Pretraining With Gene Ontology Embedding,"['Ningyu Zhang', 'Zhen Bi', 'Xiaozhuan Liang', 'Siyuan Cheng', 'Haosen Hong', 'Shumin Deng', 'Qiang Zhang', 'Jiazhang Lian', 'Huajun Chen']","[""pre-trained language model"", ""knowledge graph"", ""protein representation""]",A general framework to integrate knowledge graph (gene ontology) into protein pre-training. ,,,,
ygGMP1zkiD1,2022,Reject,False,Debiasing Pretrained Text Encoders by Paying Attention to Paying Attention,"['Yacine GACI', 'Boualem Benatallah', 'Fabio Casati', 'Khalid Benabdeslem']","[""Fairness"", ""Pretrained Text Encoders"", ""Self-Attention"", ""Knowledge Distillation"", ""Social Biases"", ""Debiasing""]","In this work, we reduce social biases encoded in transformer-based text encoders by equalizing their inner attention scores across social groups.",,,,
ygWoT6hOc28,2021,Reject,True,Regression Prior Networks,"[""Andrey Malinin"", ""Sergey Chervontsev"", ""Ivan Provilkov"", ""Mark Gales""]","[""uncertainty"", ""prior networks"", ""regression"", ""ensemble distribution distillation"", ""depth estimation.""]",Development of Prior Networks and Ensemble Distribution Distillation for Regression Tasks,2006.11590,cs.LG,2020-06-20 14:50:14+00:00,2020-12-09 09:34:21+00:00
yhCp5RcZD7,2022,Accept (Poster),True,Geometry-Consistent Neural Shape Representation with Implicit Displacement Fields,"['Wang Yifan', 'Lukas Rahmann', 'Olga Sorkine-hornung']","[""implicit functions"", ""shape reconstruction"", ""shape representation"", ""object reconstruction""]","We extend classic displacement mapping to the neural implicit framework. The resulting novel implicit representation demonstrates superior reconstruction accuracy, parameter efficiency and enable implicit shape editing such as detail transfer.",2106.05187,cs.CV,2021-06-09 16:26:18+00:00,2022-02-02 06:30:24+00:00
yhjfOvBvvmz,2022,Reject,False,Weakly-Supervised Learning of Disentangled and Interpretable Skills for Hierarchical Reinforcement Learning,"['Wonil Song', 'Sangryul Jeon', 'Hyesong Choi', 'Kwanghoon Sohn', 'Dongbo Min']","[""Reinforcement learning"", ""Variational autoencoder"", ""Disentangled representation learning""]",Weakly-supervised learning approach for learning disentangled and interpretable Skills from the continuous latent representations of trajectories.,,,,
yjMQuLLcGWK,2022,Accept (Poster),False,FP-DETR: Detection Transformer Advanced by Fully Pre-training,"['Wen Wang', 'Yang Cao', 'Jing Zhang', 'Dacheng Tao']","[""Object Detection"", ""Detection Transformer"", ""Pre-training"", ""Visual Prompt""]",,,,,
yjsA8Uin-Y,2022,Reject,False,A Good Representation Detects Noisy Labels,"['Zhaowei Zhu', 'Zihao Dong', 'Hao Cheng', 'Yang Liu']","[""noisy labels"", ""sample selection"", ""training-free"", ""representation"", ""noise dection""]",We propose a novel training-free method to detect noisy labels given good representations.,,,,
yjxVspo7gXt,2022,Reject,False,Scaling Fair Learning to Hundreds of Intersectional Groups,"['Eric Zhao', 'De-An Huang', 'Hao Liu', 'Zhiding Yu', 'Anqi Liu', 'Olga Russakovsky', 'Anima Anandkumar']","[""machine fairness"", ""intersectional fairness"", ""bias mitigation"", ""fair learning"", ""knowledge distillation""]",We scale bias mitigations and fair learning techniques to hundreds of intersectional protected groups using knowledge distillation and group-specific predictors.,,,,
yoVo1fThmS1,2021,Reject,True,Novelty Detection via Robust Variational Autoencoding,"[""Chieh-Hsin Lai"", ""Dongmian Zou"", ""Gilad Lerman""]","[""novelty detection"", ""variational autoencoding"", ""robustness"", ""Wasserstein metric"", ""one-class classification"", ""semi-supervised anomaly detection""]",A novel method for novelty detection which allows high corruption of the training set,2006.05534,cs.LG,2020-06-09 22:34:27+00:00,2020-10-07 00:56:34+00:00
yoem5ud2vb,2021,Reject,False,TOMA: Topological Map Abstraction for Reinforcement Learning,"[""Zhao Heng Yin"", ""Wu-Jun Li""]","[""Planning"", ""Reinforcement Learning"", ""Representation Learning""]",,,,,
youe3QQepVB,2022,Reject,False,Generative Modeling for Multitask Visual Learning,"['Zhipeng Bao', 'Yu-Xiong Wang', 'Martial Hebert']",[],We propose a general multi-task oriented generative modeling (MGM) framework that introduces generative models to facilitate multi-task learning and it consistently outperforms state-of-the-art multi-task approaches.,,,,
ypJS_nyu-I,2021,Reject,True,A Deeper Look at Discounting Mismatch in Actor-Critic Algorithms,"[""Shangtong Zhang"", ""Romain Laroche"", ""Harm van Seijen"", ""Shimon Whiteson"", ""Remi Tachet des Combes""]",[],,2010.01069,cs.LG,2020-10-02 15:51:48+00:00,2021-05-25 20:40:55+00:00
yqPnIRhHtZv,2021,Accept (Poster),False,Learning Hyperbolic Representations of Topological Features,"[""Panagiotis Kyriakis"", ""Iordanis Fostiropoulos"", ""Paul Bogdan""]","[""representation learning"", ""hyperbolic deep learning"", ""persistent homology"", ""persistence diagrams""]","We develop a method to learn representations of topological features (i.e., persistence diagrams) on hyperbolic spaces.",2103.09273,cs.LG,2021-03-16 18:34:14+00:00,2021-03-16 18:34:14+00:00
yql6px0bcT,2022,Reject,False,Decentralized Cross-Entropy Method for Model-Based Reinforcement Learning,"['Zichen Zhang', 'Jun Jin', 'Martin Jagersand', 'Jun Luo', 'Dale Schuurmans']","[""Reinforcement Learning"", ""Cross-Entropy Method"", ""Planning"", ""Model-Based RL""]",It proposes a Decentralized Cross-Entropy Method that generalizes the conventional Cross-Entropy Method to work with multiple independent instances for planning,,,,
yr1mzrH3IC,2021,Accept (Spotlight),False,Regularization Matters in Policy Optimization - An Empirical Study on Continuous Control,"[""Zhuang Liu"", ""Xuanlin Li"", ""Bingyi Kang"", ""Trevor Darrell""]","[""Policy Optimization"", ""Regularization"", ""Continuous Control"", ""Deep Reinforcement Learning""]","We show that conventional regularization methods (e.g., $L_2$), which have been largely ignored in RL methods, can be very effective in policy optimization on continuous control tasks; we also analyze why they can help from several perspectives.",,,,
yrD7B9N_54F,2022,Reject,False,Few-shot graph link prediction with domain adaptation,"['Hao Zhu', 'Mahashweta Das', 'Mangesh Bendre', 'Fei Wang', 'Hao Yang', 'Soha Hassoun']","[""link prediction"", ""few-shot learning"", ""domain adaptation""]",Few-shot link prediction with multiple imbalanced domains could be improved by building domain agnostic embedding through adversarial training.,,,,
yrDEUYauOMd,2021,Reject,False,Attainability and Optimality: The Equalized-Odds Fairness Revisited,"[""Zeyu Tang"", ""Kun Zhang""]","[""algorithmic fairness""]",,,,,
ysXk8cCHcQN,2021,Reject,False,Fast 3D Acoustic Scattering via Discrete Laplacian Based Implicit Function Encoders,"[""Hsien-Yu Meng"", ""Zhenyu Tang"", ""Dinesh Manocha""]","[""wave equation"", ""wave acoustics"", ""geometric deep learning"", ""sound simulation"", ""shape laplacian""]",We use a novel neural network to efficiently predict the acoustic scattering effect from 3D objects.,,,,
ysti0DEWTSo,2021,Reject,True,Is deeper better? It depends on locality of relevant features,"[""Takashi Mori"", ""Masahito Ueda""]","[""deep learning"", ""generalization"", ""overparameterization""]",It depends on locality of relevant features whether the depth is beneficial in deep learning for classification tasks.,2005.12488,cs.LG,2020-05-26 02:44:18+00:00,2021-01-27 12:22:50+00:00
yu8JOcFCFrE,2021,Reject,False,Deep Clustering and Representation Learning that Preserves Geometric Structures,"[""Lirong Wu"", ""Zicheng Liu"", ""Zelin Zang"", ""Jun Xia"", ""Siyuan Li"", ""Stan Z. Li""]","[""Deep Clustering"", ""Manifold Representation Learning""]","The proposed framework uses two principles, intra-manifold metric-preserving and inter-manifold metric rank-preserving to solve multi-manifold clustering problem effectively.",,,,
yuXQOhKRjBr,2021,Reject,False,Towards Powerful Graph Neural Networks: Diversity Matters,"[""Xu Bingbing"", ""Huawei Shen"", ""Qi Cao"", ""Yuanhao Liu"", ""Keting Cen"", ""Xueqi Cheng""]","[""GNNs"", ""Expressive power"", ""Diverse sampling"", ""Injective""]","We propose a novel framework to improve the expressive power of GNNs via diverse subgraph sampling, without depending on layer-wise injective aggregation functions.",,,,
yuv0mwPOlz3,2022,Reject,False,Active Learning over Multiple Domains in Natural Language Tasks,"['Shayne Longpre', 'Julia Rachel Reisler', 'Edward Greg Huang', 'Yi Lu', 'Andrew Frank', 'Nikhil Ramesh', 'Chris DuBois']","[""natural language processing"", ""active learning"", ""domain shift detection""]",Active Learning over Multiple Domains in Natural Language Tasks,,,,
yvQKLaqNE6M,2021,Accept (Poster),False,You Only Need Adversarial Supervision for Semantic Image Synthesis,"[""Edgar Sch\u00f6nfeld"", ""Vadim Sushko"", ""Dan Zhang"", ""Juergen Gall"", ""Bernt Schiele"", ""Anna Khoreva""]","[""Semantic Image Synthesis"", ""GANs"", ""Image Generation"", ""Deep Learning""]","We propose OASIS, a novel model for multi-modal semantic image synthesis, improving over previous methods in terms of image quality and diversity while only using adversarial supervision.",,,,
yvuk0RsLoP7,2021,Reject,False,Improving Model Robustness with Latent Distribution Locally and Globally,"[""Zhuang QIAN"", ""Shufei Zhang"", ""Kaizhu Huang"", ""Qiufeng Wang"", ""Rui Zhang"", ""Xinping Yi""]","[""adversarial example"", ""robustness"", ""data manifold"", ""adversarial training""]",We propose a novel adversarial training method which leverages both the local and global information to defend  adversarial attacks.,2107.04401,cs.LG,2021-07-08 07:52:53+00:00,2021-07-08 07:52:53+00:00
yvzMA5im3h,2021,Reject,False,Graph Joint Attention Networks,"[""Tiantian He"", ""Lu Bai"", ""Yew-Soon Ong""]","[""Graph attention networks"", ""Joint attention mechanism"", ""Graph transductive learning""]",,,,,
yx_uIzoHJv,2022,Reject,False,Effect of Pressure for Compositionality on Language Emergence,"['Mihira Kasun Vithanage', 'Rukshan Darshana Wijesinghe', 'Alex Xavier', 'Dumindu Tissera', 'Sanath Jayasena', 'Subha Fernando']","[""Language Emergence"", ""Neural Language Emergence"", ""Compositionality""]","This paper explores the effects of externally introducing a compositionality pressure, on neural agents employed in language emergence,  by considering factors such as the structure of the message space, input space, agent architecture, etc.",,,,
yxafu6ZtUux,2021,Reject,False,AN ONLINE SEQUENTIAL TEST FOR QUALITATIVE TREATMENT EFFECTS,"[""Chengchun Shi"", ""Shikai Luo"", ""Rui Song"", ""Hongtu Zhu""]","[""sequential testing"", ""A/B testing"", ""qualitative treatment effects"", ""bootstrap""]",,,,,
yzDTTtlIlMr,2022,Reject,True,Momentum Doesn't Change The Implicit Bias,"['Bohan Wang', 'Qi Meng', 'Huishuai Zhang', 'Ruoyu Sun', 'Wei Chen', 'Zhi-Ming Ma']","[""Momentum-based Optimizers"", ""Convergence Analysis"", ""Implicit Bias""]",This paper provides the first analysis of implicit bias of momentum-based optimizers on the linear classification model with exponential-tailed loss.,2110.03891,cs.LG,2021-10-08 04:37:18+00:00,2021-10-08 04:37:18+00:00
yztpblfGkZ-,2022,Reject,True,Graph Convolutional Networks via Adaptive Filter Banks,"['Xing Gao', 'Wenrui Dai', 'Chenglin Li', 'Junni Zou', 'Hongkai Xiong', 'Pascal Frossard']",[],,2106.09910,cs.LG,2021-06-18 04:23:34+00:00,2021-06-18 04:23:34+00:00
z-5BjnU3-OQ,2022,Reject,False,HyperCGAN: Text-to-Image Synthesis with HyperNet-Modulated Conditional Generative Adversarial Networks,"['KILICHBEK HAYDAROV', 'Aashiq Muhamed', 'Jovana Lazarevic', 'Ivan Skorokhodov', 'Mohamed Elhoseiny']","[""gan"", ""generative modelling"", ""text-to-image"", ""text2image"", ""hypernetworks""]",A conceptually simple and general approach for text-to-image synthesis that uses hypernetworks ,,,,
z1-I6rOKv1S,2022,Accept (Spotlight),False,Autoregressive Quantile Flows for Predictive Uncertainty Estimation,"['Phillip Si', 'Volodymyr Kuleshov', 'Allan Bishop']",[],Using Quantile Flows for Predictive and Generative Data Modeling and Generation,,,,
z2B0JJeNdvT,2022,Reject,False,Distributed Zeroth-Order Optimization: Convergence Rates That Match Centralized Counterpart,"['Deming Yuan', 'Lei Wang', 'Alexandre Proutiere', 'Guodong Shi']","[""Zeroth-order optimization"", ""distributed optimization""]",Convergence rates that match centralized counterpart for distributed zeroth-order optimization,,,,
z2zmSDKONK,2022,Reject,False,Exploring the Robustness of Distributional Reinforcement Learning against Noisy State Observations,"['Ke Sun', 'Yi Liu', 'Yingnan Zhao', 'Hengshuai Yao', 'SHANGLING JUI', 'Linglong Kong']","[""distributional reinforcement learning"", ""robustness""]",We study the training robsutnesss of distributional reinforcement learning against noisy state observations.,,,,
z3Tf4kdOE5D,2022,Reject,False,FedDiscrete: A Secure Federated Learning Algorithm Against Weight Poisoning,"['Yutong Dai', 'Xingjun Ma', 'Lichao Sun']","[""federated learning"", ""weight poisoning defense""]",,,,,
z5Z023VBmDZ,2021,Accept (Poster),False,More or Less: When and How to Build Convolutional Neural Network Ensembles,"[""Abdul Wasay"", ""Stratos Idreos""]","[""ensemble learning"", ""empirical study"", ""machine learning systems"", ""computer vision""]","We show that when we perform a holistic assessment, we uncover a wide design space, where ensembles not only provide better accuracy but also train and deploy with fewer resources than comparable single convolutional network models.",,,,
z7DAilcTx7,2022,Reject,False,A Distributional Robustness Perspective on Adversarial Training with the $\infty$-Wasserstein Distance,"['Chiara Regniez', 'Gauthier Gidel', 'Hugo berard']",[],Adversarial training studied within distributionally robust optimization framework with $\infty$-$\infty$-Wasserstein Distance and inspiration of optimal transport theory.,,,,
z7p2V6KROOV,2022,Accept (Oral),False,Extending the WILDS Benchmark for Unsupervised Adaptation,"['Shiori Sagawa', 'Pang Wei Koh', 'Tony Lee', 'Irena Gao', 'Sang Michael Xie', 'Kendrick Shen', 'Ananya Kumar', 'Weihua Hu', 'Michihiro Yasunaga', 'Henrik Marklund', 'Sara Beery', 'Etienne David', 'Ian Stavness', 'Wei Guo', 'Jure Leskovec', 'Kate Saenko', 'Tatsunori Hashimoto', 'Sergey Levine', 'Chelsea Finn', 'Percy Liang']","[""distribution shifts"", ""adaptation"", ""unlabeled data""]","We introduce U-WILDS, which augments the WILDS distribution shift benchmark with realistic unlabeled data, and benchmark existing methods for unlabeled data on these in-the-wild distribution shifts.",2112.05090,cs.LG,2021-12-09 18:32:38+00:00,2021-12-09 18:32:38+00:00
z8j0bPU4DIw,2022,Reject,False,Evolution Strategies as an Alternate Learning method for Hierarchical Reinforcement Learning,['Sasha Abramowitz'],"[""Hierarchical reinforcement learning"", ""evolution strategies"", ""reinforcement learning""]",We introduce a novel method that merges evolution strategies and hierarchical reinforcement learning and show that evolution strategies can acheive state-of-the-art performance on challenging problems,,,,
z8xVlqWwRrK,2022,Reject,False,EVaDE : Event-Based Variational Thompson Sampling for Model-Based Reinforcement Learning,"['Siddharth Aravindan', 'Dixant Mittal', 'Wee Sun Lee']","[""Model-based Reinforcement Learning"", ""Thompson sampling"", ""Exploration""]",This paper proposes variational distribution designs to approximate Thompson sampling for model based reinforcement learning in object based domains.,,,,
z9k8BWL-_2u,2021,Accept (Poster),False,Statistical inference for individual fairness,"[""Subha Maity"", ""Songkai Xue"", ""Mikhail Yurochkin"", ""Yuekai Sun""]",[],,2103.16714,stat.ML,2021-03-30 22:49:25+00:00,2021-03-30 22:49:25+00:00
zAyZFRptzvh,2022,Reject,True,Auditing AI models for Verified Deployment under Semantic Specifications,"['Homanga Bharadhwaj', 'De-An Huang', 'Chaowei Xiao', 'Anima Anandkumar', 'Animesh Garg']","[""auditing deep learning"", ""verification"", ""interpretability""]",We enable auditing deep learning models by building a generative bridge that enables verification of semantically aligned specifications,2109.12456,cs.LG,2021-09-25 22:53:24+00:00,2021-11-01 15:33:09+00:00
zBOI9LFpESK,2022,Accept (Poster),False,Learning Generalizable Representations for Reinforcement Learning via Adaptive Meta-learner of Behavioral Similarities,"['Jianda Chen', 'Sinno Pan']","[""deep reinforcement learning"", ""deep learning"", ""representation learning""]",,,,,
zBhwgP7kt4,2022,Reject,False,Dynamic Least-Squares Regression,"['Binghui Peng', 'Shunhua Jiang', 'OMRI WEINSTEIN']","[""Least squares regression"", ""dynamic algorithm""]",Near optimal algorithm and hardness results for dynamic least squares regressions.,,,,
zCu1BZYCueE,2021,Reject,False,Response Modeling of Hyper-Parameters for Deep Convolutional Neural Networks,"[""Mathieu Tuli"", ""Mahdi S. Hosseini"", ""Konstantinos N Plataniotis""]","[""Hyper-Parameter Optimization"", ""Response Surface Modeling"", ""Convolution Neural Network"", ""Low-Rank Factorization""]",A new response surface model is proposed to dynamically track the optimum Hyper-Parameters for training Convolution Neural Network. ,,,,
zDy_nQCXiIj,2021,Accept (Spotlight),False,"GAN ""Steerability"" without optimization ","[""Nurit Spingarn"", ""Ron Banner"", ""Tomer Michaeli""]","[""Generative Adversarial Network"", ""semantic directions in latent space"", ""nonlinear walk""]",Extracting linear & nonlinear semantic directions in GAN latent space without any required optimization,,,,
zElset1Klrp,2021,Accept (Poster),True,Fuzzy Tiling Activations: A Simple Approach to Learning Sparse Representations Online,"[""Yangchen Pan"", ""Kirby Banman"", ""Martha White""]","[""Reinforcement learning"", ""natural sparsity"", ""sparse representation"", ""fuzzy tiling activation function""]",A simple and efficient way to learn sparse feature online in deep learning setting. ,1911.08068,cs.LG,2019-11-19 03:12:06+00:00,2021-03-16 16:32:19+00:00
zFM0Uo_GnYE,2021,Reject,False,On the Importance of Looking at the Manifold,"[""Nil Adell Mill"", ""Jannis Born"", ""Nathaniel Park"", ""James Hedrick"", ""Mar\u00eda Rodr\u00edguez Mart\u00ednez"", ""Matteo Manica""]","[""Topological Learning"", ""GNN"", ""VAE""]",A study on the importance of the topology in representation learning using implicit and explicit graph structure information.,,,,
zFlFjoyOW-z,2022,Reject,False,Interest-based Item Representation Framework for Recommendation with Multi-Interests Capsule Network,"['Yanpeng Xie', 'Tong Zhang', 'Heng Zhang', 'Zhendong Qu']","[""Feature Representation"", ""Recommendation System"", ""Dynamic Routing of Capsule""]","A framework to learn interest-based item representations by user Multi Interests Capsule Network, which is model-agnostic and designed as an auxiliary task to jointly learn item representations.",,,,
zFyCvjXof60,2022,Reject,False, Hypergraph Convolutional Networks via Equivalency  between  Hypergraphs and Undirected Graphs,"['Jiying Zhang', 'Fuyang Li', 'Xi Xiao', 'Tingyang Xu', 'Yu Rong', 'Junzhou Huang', 'Yatao Bian']","[""hypergraph learning"", ""equivalency of hypergraph"", ""graph neural networks""]",,,,,
zHZ1mvMUMW8,2022,Reject,False,Succinct Compression: Near-Optimal and Lossless Compression of Deep Neural Networks during Inference Runtime,"['Yicun Duan', 'Xiangjun Peng']",[],,,,,
zI38PZQHWKj,2021,Reject,False,Feature-Robust Optimal Transport for High-Dimensional Data,"[""Mathis Petrovich"", ""Chao Liang"", ""Ryoma Sato"", ""Yanbin Liu"", ""Yao-Hung Hubert Tsai"", ""Linchao Zhu"", ""Yi Yang"", ""Ruslan Salakhutdinov"", ""Makoto Yamada""]","[""Optimal Transport"", ""feature selection"", ""semantic correspondence""]",We propose an optimal transport method for high-dimensional data and applied it to semantic correspondence problems. ,,,,
zIUyj55nXR,2022,Accept (Oral),False,Frame Averaging for Invariant and Equivariant Network Design,"['Omri Puny', 'Matan Atzmon', 'Edward J. Smith', 'Ishan Misra', 'Aditya Grover', 'Heli Ben-Hamu', 'Yaron Lipman']","[""Invariant and equivariant neural network"", ""expressive power""]",Introducing a general methodology for building expressive and efficient invariant and equivariant networks.,,,,
zKbMQ2NY1y,2022,Reject,False,Aug-ILA: More Transferable Intermediate Level Attacks with Augmented References,"['Chiu Wai Yan', 'Dit-Yan Yeung']","[""adversarial examples"", ""adversarial transferability"", ""intermediate feature"", ""image augmentation""]",We present a fine-tuning method that largely enhances the black-box transferability of adversarial examples.,,,,
zLb9oSWy933,2022,Reject,False,Fast Finite Width Neural Tangent Kernel,"['Roman Novak', 'Jascha Sohl-Dickstein', 'Samuel Stern Schoenholz']","[""Neural Tangent Kernel"", ""NTK"", ""Finite Width"", ""Fast"", ""Algorithm"", ""JAX"", ""Jacobian"", ""Software""]","We develop and open-source a new algorithm for fast computation of the finite width Neural Tangent Kernel, the outer product of Jacobians of a neural network.",,,,
zM6fevLxIhI,2021,Reject,False,Variational Structured Attention Networks for Dense Pixel-Wise Prediction,"[""Guanglei Yang"", ""Paolo Rota"", ""Xavier Alameda-Pineda"", ""Dan Xu"", ""Mingli Ding"", ""Elisa Ricci""]","[""attention network"", ""pixel-wise prediction""]",,,,,
zNHzqZ9wrRB,2022,Accept (Spotlight),False,Equivariant Transformers for Neural Network based Molecular Potentials,"['Philipp ThÃ¶lke', 'Gianni De Fabritiis']","[""Molecular Modeling"", ""Quantum Chemistry"", ""Attention"", ""Transformers""]",We propose a novel equivariant Transformer architecture for the prediction of molecular potentials and provide insights into the molecular representation through extensive analysis of the model's attention weights.,2202.02541,cs.LG,2022-02-05 12:53:40+00:00,2022-02-05 12:53:40+00:00
zNR43c03lRy,2022,Accept (Poster),False,Learning to Annotate Part Segmentation with Gradient Matching,"['Yu Yang', 'Xiaotian Cheng', 'Hakan Bilen', 'Xiangyang Ji']","[""semi-supervised learning"", ""part segmentation"", ""semantic segmentation"", ""generative models"", ""gradient matching""]",We propose a gradient-matching-based method to learn annotator which is able to label generated images with part segmentation by decoding the generator features into segmentation masks.,,,,
zOGdf9K8aC,2021,Reject,False,Self-Supervised Variational Auto-Encoders,"[""Ioannis Gatopoulos"", ""Jakub Mikolaj Tomczak""]","[""generative modeling"", ""deep learning"", ""deep autoencoders""]","We present a novel class of generative models, called self-supervised Variational Auto-Encoder, where we improve VAEs by applying deterministic and discrete transformations of data.",,,,
zPLQSnfd14w,2022,Reject,True,Two Regimes of Generalization for Non-Linear Metric Learning,"['Mark Kozdoba', 'Shie Mannor']","[""metric learning"", ""guarantees"", ""sparsity""]",Different types of guarantees for metric learning with neural networks.,2102.03802,cs.LG,2021-02-07 14:47:00+00:00,2021-02-07 14:47:00+00:00
zQTezqCCtNx,2021,Accept (Spotlight),False,Improving Adversarial Robustness via Channel-wise Activation Suppressing,"[""Yang Bai"", ""Yuyuan Zeng"", ""Yong Jiang"", ""Shu-Tao Xia"", ""Xingjun Ma"", ""Yisen Wang""]","[""Adversarial robustness"", ""channel suppressing"", ""activation strategy.""]",Training with Channel-wise Activation Suppressing (CAS) can help imrove the robustness of adversarial training.,2103.08307,cs.LG,2021-03-11 03:44:16+00:00,2021-03-11 03:44:16+00:00
zRJu6mU2BaE,2022,Accept (Poster),False,ConFeSS: A Framework for Single Source Cross-Domain Few-Shot Learning,"['Debasmit Das', 'Sungrack Yun', 'Fatih Porikli']",[],,,,,
zRb7IWkTZAU,2022,Reject,False,Zero-Shot Reward Specification via Grounded Natural Language,"['Parsa Mahmoudieh', 'Sayna Ebrahimi', 'Deepak Pathak', 'Trevor Darrell']",[],,,,,
zU2v47WF0Ku,2022,Reject,False,Implicit Bias of Linear Equivariant Networks,"['Hannah Lawrence', 'Kristian Georgiev', 'Andrew Dienes', 'Bobak Kiani']","[""Implicit bias"", ""equivariance"", ""deep learning"", ""linear networks"", ""convolution"", ""CNN""]",We characterize the implicit bias of linear Group Equivariant Convolutional Neural Networks (G-CNNs) for all finite groups.,,,,
zUMD--Fb9Bt,2021,Reject,False,A Unified Framework for Convolution-based Graph Neural Networks,"[""Xuran Pan"", ""Shiji Song"", ""Gao Huang""]","[""Graph Representation Learning"", ""Graph Convolution"", ""Graph Signal Processing"", ""Oversmoothing""]",We propose a unified framework for convolution-based graph neural networks and provide a general methodology for evaluating and relating different graph learning modules.,,,,
zWvMjL6o60V,2021,Reject,False,Improving Mutual Information based Feature Selection by Boosting Unique Relevance,"[""Shiyu Liu"", ""Mehul Motani""]","[""Feature Selection"", ""Mutual Information"", ""Unique Relevance""]",A Paper that Highlights the Importance of the Unique Relevance of Features during the Mutual Information based Feature Selection.,,,,
zWy1uxjDdZJ,2021,Accept (Spotlight),False,Fast Geometric Projections for Local Robustness Certification,"[""Aymeric Fromherz"", ""Klas Leino"", ""Matt Fredrikson"", ""Bryan Parno"", ""Corina Pasareanu""]","[""verification"", ""robustness"", ""safety""]","We present a fast, scalable procedure for checking local robustness in neural networks",,,,
zXM0b4hi5_B,2022,Accept (Spotlight),False,On the relation between statistical learning and perceptual distances,"['Alexander Hepburn', 'Valero Laparra', 'Raul Santos-Rodriguez', 'Johannes BallÃ©', 'Jesus Malo']",[],,,,,
zXne1klXIQ,2022,Reject,False,Improving Out-of-Distribution Robustness via Selective Augmentation,"['Huaxiu Yao', 'Yu Wang', 'Sai Li', 'Linjun Zhang', 'Weixin Liang', 'James Zou', 'Chelsea Finn']","[""out-of-distribution robustness"", ""distribution shifts"", ""selective data augmentation""]",Addressing the problem of distribution shift by eliminating the domain-related spurious correlations via data interpolation.,2201.00299,cs.LG,2022-01-02 05:58:33+00:00,2022-01-28 20:13:55+00:00
zYmnBGOZtH,2021,Reject,False,An information-theoretic framework for learning models of instance-independent label noise,"[""Xia Huang"", ""Kai Fong Ernest Chong""]","[""label noise"", ""noise transition matrix"", ""entropy"", ""information theory"", ""local intrinsic dimensionality""]","We introduce a consistent information-theoretic-based estimator for the noise transition matrix of any dataset with instance-independent label noise, without assuming any matrix structure, and without requiring anchor points or clean data.",,,,
zaALYtvbRlH,2022,Reject,False,SpanDrop: Simple and Effective Counterfactual Learning for Long Sequences,"['Peng Qi', 'Guangtao Wang', 'Jing Huang']","[""sequential data"", ""sample efficiency"", ""data augmentation""]",,,,,
zbEupOtJFF,2021,Reject,False,On interaction between augmentations and corruptions in natural corruption robustness,"[""Eric Mintun"", ""Alexander Kirillov"", ""Saining Xie""]","[""corruption robustness"", ""data augmentation"", ""perceptual similarity"", ""deep learning""]",We show that data augmentation improves error on images corrupted by transforms that are visually similar to the augmentations and that this leads to overfitting on a common corruption benchmark.,2102.11273,cs.CV,2021-02-22 18:58:39+00:00,2021-02-22 18:58:39+00:00
zbZL1s-pBF,2022,Reject,False,Training-Free Robust Multimodal Learning via Sample-Wise Jacobian Regularization,"['Zhengqi Gao', 'Sucheng Ren', 'Zihui Xue', 'Siting Li', 'Hang Zhao']","[""Jacobian Regularization"", ""Robust Multimodal Learning""]",We propose a training-free robust multimodal learning method via sample-wise Jacobian regularization.,,,,
zcOJOUjUcyF,2021,Reject,False,Better Optimization can Reduce Sample Complexity: Active Semi-Supervised Learning via Convergence Rate Control,"[""Seo Taek Kong"", ""Soomin Jeon"", ""Jaewon Lee"", ""Hong-Seok Lee"", ""Kyu-Hwan Jung""]","[""Active Learning"", ""Semi-Supervised Learning"", ""Neural Tangent Kernel"", ""Deep Learning""]",We propose a new active learning algorithm inspired by neural tangent kernels and demonstrate its effectiveness when combined with semi-supervised learning.,,,,
zdrls6LIX4W,2021,Reject,False,A Policy Gradient Algorithm for Learning to Learn in Multiagent Reinforcement Learning,"[""Dong-Ki Kim"", ""Miao Liu"", ""Matthew D Riemer"", ""Chuangchuang Sun"", ""Marwa Abdulhai"", ""Golnaz Habibi"", ""Sebastian Lopez-Cot"", ""Gerald Tesauro"", ""JONATHAN P HOW""]","[""Multiagent reinforcement learning"", ""Meta-learning"", ""Non-stationarity""]",We introduce a novel meta-multiagent policy gradient theorem based on meta-learning that can adapt quickly to non-stationarity in the policies of other agents in the environment.,,,,
zeFrfgyZln,2021,Accept (Poster),False,Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval,"[""Lee Xiong"", ""Chenyan Xiong"", ""Ye Li"", ""Kwok-Fung Tang"", ""Jialin Liu"", ""Paul N. Bennett"", ""Junaid Ahmed"", ""Arnold Overwijk""]","[""Dense Retrieval"", ""Text Retrieval"", ""Text Representation"", ""Neural IR""]","This paper improves the learning of dense text retrieval using ANCE, which selects global negatives with bigger gradient norms using an asynchronously updated ANN index. ",,,,
zeGpMIt6Pfq,2022,Reject,True,BioLCNet: Reward-modulated Locally Connected Spiking Neural Networks,"['Hafez Ghaemi', 'Erfan Mirzaei', 'Mahbod Nouri', 'Saeed Reza Kheradpisheh']","[""Spiking Neural Networks"", ""Locally Connected Networks"", ""Spike-timing-dependent plasticity"", ""Reinforcement Learning""]",,2109.05539,cs.NE,2021-09-12 15:28:48+00:00,2021-12-03 00:45:57+00:00
zfO1MwBFu-,2021,Reject,False,Information Theoretic Regularization for Learning Global Features by Sequential VAE,"[""Kei Akuzawa"", ""Yusuke Iwasawa"", ""Yutaka Matsuo""]","[""variational autoencoder"", ""VAE"", ""disentanglement"", ""global features"", ""sequential models"", ""representation learning"", ""mutual information""]","To assist sequential VAEs with global latent variable, we propose a new information theoretic regularization method for disentangling the global factors.",,,,
zf_Ll3HZWgy,2022,Accept (Poster),True,How Much Can CLIP Benefit Vision-and-Language Tasks?,"['Sheng Shen', 'Liunian Harold Li', 'Hao Tan', 'Mohit Bansal', 'Anna Rohrbach', 'Kai-Wei Chang', 'Zhewei Yao', 'Kurt Keutzer']",[],,2107.06383,cs.CV,2021-07-13 20:48:12+00:00,2021-07-13 20:48:12+00:00
zfmB5vgfaCt,2022,Reject,False,TransSlowDown: Efficiency Attacks on Neural Machine Translation Systems,"['Simin Chen', 'Mirazul Haque', 'Zihe Song', 'Cong Liu', 'Wei Yang']",[],,,,,
zg4GtrVQAKo,2021,Reject,False,Generative Adversarial User Privacy in Lossy Single-Server Information Retrieval,"[""Chung-Wei Weng"", ""Yauhen Yakimenka"", ""Hsuan-Yin Lin"", ""Eirik Rosnes"", ""Joerg Kliewer""]","[""Generative adversarial network"", ""generative adversarial privacy"", ""information-theoretic privacy"", ""compression"", ""private information retrieval"", ""data-driven framework""]",We initiate the study of information retrieval from a dataset of files stored on a single server under both a user distortion and a user privacy constraint,2012.03902,cs.LG,2020-12-07 18:31:51+00:00,2021-07-26 21:38:16+00:00
zgGmAx9ZcY,2021,Reject,False,Learning the Connections in Direct Feedback Alignment,"[""Matthew Bailey Webster"", ""Jonghyun Choi"", ""changwook Ahn""]","[""Deep Learning"", ""Feedback Alignment"", ""Backpropagation""]","We improve upon the direct feedback alignment approach, and show that our method can more effectively train convolutional networks on larger datasets such as CIFAR100.",,,,
zgMPc_48Zb,2021,Reject,False,Differentially Private Generative Models Through Optimal Transport,"[""Tianshi Cao"", ""Alex Bie"", ""Karsten Kreis"", ""Sanja Fidler""]","[""Differential Privacy"", ""Generative Learning"", ""GAN"", ""Optimal Transport""]",Learning generative models that satisfy differential privacy guarantees using optimal transport.,,,,
zhynF6JnC4q,2022,Reject,False,Adaptive Q-learning for Interaction-Limited Reinforcement Learning,"['Han Zheng', 'Xufang Luo', 'pengfei wei', 'Xuan Song', 'Dongsheng Li', 'Jing Jiang']","[""reinforcement learning"", ""offline reinforcement learning"", ""online-to-offline"", ""limited interactions""]",A unified framework to mix the offline and online RL and gain the best of both worlds.,,,,
ziRLU3Y2PN_,2022,Accept (Poster),False,Generalized rectifier wavelet covariance models for texture synthesis,"['Antoine Brochard', 'Sixin Zhang']","[""texture synthesis"", ""generative models"", ""wavelets""]","This paper presents a model for texture synthesis, built on a wavelet-based representation of images.",,,,
zleOqnAUZzl,2021,Reject,False,Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs,"[""Ramneet Kaur"", ""Susmit Jha"", ""Anirban Roy""]","[""OOD"", ""out of distribution"", ""trust"", ""model confidence"", ""DNN"", ""deep learning""]",We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.,,,,
zmgJIjyWSOw,2021,Reject,False,UserBERT: Self-supervised User Representation Learning,"[""Tianyu Li"", ""Ali Cevahir"", ""Derek Cho"", ""Hao Gong"", ""DuyKhuong Nguyen"", ""Bjorn Stenger""]","[""user representations"", ""representation learning"", ""self-supervised learning"", ""pretraining"", ""transfer learning""]",On pretraining user representations via self-supervision,,,,
zou-Ry64vqx,2022,Reject,False,FedMorph: Communication Efficient Federated Learning via Morphing Neural Network,"['Guoqing Ma', 'Chuanting Zhang', 'Basem Shihada']","[""Federated Learning"", ""Communication efficient""]",We proposed that sharing a sub-network among the clients and the server can reduce edge devices' communication and computation overloads and increase the generalization accuracy by avoiding over-fitting of FL on local datasets. ,,,,
zq1iJkNk3uN,2022,Accept (Poster),True,Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image  Pre-training Paradigm,"['Yangguang Li', 'Feng Liang', 'Lichen Zhao', 'Yufeng Cui', 'Wanli Ouyang', 'Jing Shao', 'Fengwei Yu', 'Junjie Yan']",[],,2110.05208,cs.CV,2021-10-11 12:17:32+00:00,2021-10-11 12:17:32+00:00
zq4bt_0z-gz,2021,Reject,False,Latent Programmer: Discrete Latent Codes for Program Synthesis,"[""Joey Hong"", ""David Dohan"", ""Rishabh Singh"", ""Charles Sutton"", ""Manzil Zaheer""]",[],,2012.00377,cs.LG,2020-12-01 10:11:35+00:00,2021-08-05 18:49:02+00:00
zrT3HcsWSAt,2021,Accept (Spotlight),False,Behavioral Cloning from Noisy Demonstrations,"[""Fumihiro Sasaki"", ""Ryota Yamashina""]","[""Imitation Learning"", ""Inverse Reinforcement Learning"", ""Noisy Demonstrations""]",We propose an imitation learning algorithm to learn from non-optimal (noisy) demonstrations without any environment interactions and annotations associated with the demonstrations.,,,,
zrW-LVXj2k1,2022,Accept (Poster),True,On the benefits of maximum likelihood estimation for Regression and Forecasting,"['Pranjal Awasthi', 'Abhimanyu Das', 'Rajat Sen', 'Ananda Theertha Suresh']","[""Forecasting"", ""Time-Series"", ""Regression"", ""MLE""]",MLE + Post-Hoc Inference can be competitive with any estimator under some general assumptions ,2106.10370,stat.ML,2021-06-18 22:10:43+00:00,2021-10-09 18:06:56+00:00
zrdUVVAvcP2,2022,Reject,False,GrASP: Gradient-Based Affordance Selection for Planning,"['Vivek Veeriah', 'Zeyu Zheng', 'Richard Lewis', 'Satinder Singh']","[""reinforcement learning"", ""affordances""]",Learning to select affordances in the form of options and primitive actions for lookahead planning,2202.04772,cs.LG,2022-02-08 03:24:36+00:00,2022-02-08 03:24:36+00:00
zsKWh2pRSBK,2021,Reject,False,"Poisoned classifiers are not only backdoored, they are fundamentally broken","[""Mingjie Sun"", ""Siddhant Agarwal"", ""J Zico Kolter""]","[""Backdoor Attacks"", ""Denoised Smoothing"", ""Perceptually-Aligned Gradients""]","We show that backdoored classifiers can be easily attacked without access to the original trigger, by constructing alternative triggers that are just as effective as, or even more so than the original one that are as successful as the original one.",,,,
zspml_qcldq,2021,Reject,False,Cross-Modal Retrieval Augmentation for Multi-Modal Classification,"[""Shir Gur"", ""Natalia Neverova"", ""Chris Stauffer"", ""Ser-Nam Lim"", ""Douwe Kiela"", ""Austin Reiter""]","[""Multi-Modal"", ""VQA"", ""Retrieval""]",,,,,
ztMLindFLWR,2021,Reject,False,Breaking the Expressive Bottlenecks of Graph Neural Networks,"[""Mingqi Yang"", ""Yanming Shen"", ""Heng Qi"", ""Baocai Yin""]","[""graph representation learning"", ""graph neural networks"", ""expressive power""]",We design novel GNNs with provably more expressive power.,2012.07219,cs.LG,2020-12-14 02:36:46+00:00,2020-12-14 02:36:46+00:00
zuDmDfeoB_1,2022,Reject,False,How Does the Task Landscape Affect MAML Performance?,"['Liam Collins', 'Aryan Mokhtari', 'Sanjay Shakkottai']","[""Meta-learning"", ""MAML"", ""multi-task linear regression"", ""two-layer neural networks""]",We investigate the roles of task hardness and geography in the effectiveness of MAML.,,,,
zuqcmNVK4c2,2022,Accept (Poster),False,Self-Joint Supervised Learning,"['Navid Kardan', 'Mubarak Shah', 'Mitch Hill']",[],,,,,
zv-typ1gPxA,2021,Accept (Spotlight),False,Retrieval-Augmented Generation for Code Summarization via Hybrid GNN,"[""Shangqing Liu"", ""Yu Chen"", ""Xiaofei Xie"", ""Jing Kai Siow"", ""Yang Liu""]","[""Code Summarization"", ""Graph Neural Network"", ""Retrieval"", ""Generation""]",This paper proposes a novel retrieval-augmented mechanism to augment the code semantics with hybrid graph neural network for source code summarization.,,,,
zxEfpcmTDnF,2022,Reject,False,Learning and controlling the source-filter representation of speech with a variational autoencoder,"['Samir Alain Sadok', 'Simon Leglaive', 'Laurent Girin', 'Xavier Alameda-Pineda', 'Renaud SÃ©guier']","[""Deep generative models"", ""variational autoencoder (VAE)"", ""speech processing"", ""source-filter model of speech production"", ""representation learning""]",We show that the source-filter model of speech production naturally emerges in the latent space of an unsupervised VAE and we propose a weakly-supervised method to control the pitch and formant frequencies of speech signals in the VAE latent space.,,,,
zx_uX-BO7CH,2021,Accept (Poster),False,Contextual Transformation Networks for Online Continual Learning,"[""Quang Pham"", ""Chenghao Liu"", ""Doyen Sahoo"", ""Steven HOI""]","[""Continual Learning""]",This paper develops a novel method that can model task-specific features with minimal complexity overhead.,,,,
zyrhwrd9EYs,2022,Reject,False,To Impute or Not To Impute? Missing Data in Treatment Effect Estimation,"['Jeroen Berrevoets', 'Fergus Imrie', 'Trent Kyono', 'James Jordon', 'Mihaela van der Schaar']","[""Causality""]",We introduce a realistic missingness mechanism for treatment effects and how to tackle it.,,,,
zz9hXVhf40,2022,Accept (Spotlight),False,Revisiting Design Choices in Offline Model Based Reinforcement Learning,"['Cong Lu', 'Philip Ball', 'Jack Parker-Holder', 'Michael Osborne', 'Stephen J. Roberts']","[""Model-Based Reinforcement Learning"", ""Offline Reinforcement Learning"", ""Uncertainty Quantification""]",,,,,
zzk231Ms1Ih,2022,Accept (Poster),True,A Theory of Tournament Representations,"['Arun Rajkumar', 'Vishnu Veerathu', 'Abdul Bakey Mir']","[""tournament"", ""skew-symmetric"", ""pairwise ranking""]",We develop a theory to understand tournament representations i.e. structurally characterise when a tournament graph can be represented in lower dimensions using a skew symmetric matrix. ,2110.05188,cs.GT,2021-10-06 09:08:00+00:00,2021-10-12 07:34:00+00:00
