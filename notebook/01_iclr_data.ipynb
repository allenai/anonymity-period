{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "outstanding-behavior",
   "metadata": {},
   "source": [
    "# ICLR Data Processing\n",
    "\n",
    "\n",
    "v0.1 Jiayao Zhang\n",
    "June 14, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "certain-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import, division\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import json\n",
    "import uuid\n",
    "import sqlite3\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sns.set()\n",
    "sns.set(font_scale=2.5,)\n",
    "sns.set_style(\"white\")\n",
    "# sns.set_style({'font.family': 'Libertine'})\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.size': 20, 'lines.linewidth':4, 'lines.markersize':12, \n",
    "                         'xtick.labelsize':15, 'ytick.labelsize':15, 'axes.labelsize':20,\n",
    "                         'axes.titlesize': 20, 'legend.fontsize':20,\n",
    "                         'pdf.fonttype': 42, 'ps.fonttype':42, \n",
    "                        'image.interpolation':'nearest', 'figure.figsize': (10,8),\n",
    "                     \"text.usetex\": False,\n",
    "         'text.latex.preamble': r\"\"\"\n",
    "        \\usepackage{libertine}\n",
    "        \\usepackage[libertine]{newtxmath}\n",
    "        \"\"\",\n",
    "                     \n",
    "                    })\n",
    "tqdm.tqdm.pandas()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "valid-fireplace",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "threaded-trouble",
   "metadata": {},
   "source": [
    "### ICLR Database\n",
    "\n",
    "See (ICLR Datbse)[https://cogcomp.github.io/iclr_database/] for details of getting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bound-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.data_utils as data_utils\n",
    "\n",
    "# change the following line accordinlgy\n",
    "DATA_PATH = Path('path/to/iclr/database')\n",
    "DB_NAME = \"cs_conf_release.db\"\n",
    "LOCAL_DATA_PATH = Path('./data')\n",
    "CITATION_DATA_PATH = LOCAL_DATA_PATH / 's2_citation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "studied-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_con = sqlite3.connect(DATA_PATH/DB_NAME)\n",
    "dataloader = data_utils.DataLoader(db_con, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "otherwise-costume",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tables\n",
    "sub_reviews_agg = dataloader.get_table('sub_reviews_agg')\n",
    "sub_derive = dataloader.get_table('sub_derive')\n",
    "sub_arxiv=dataloader.get_table('submission_arxiv')\n",
    "author_grp = dataloader.get_table('author_grp')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "polar-basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader.get_table('venues').to_csv('venues.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "sudden-qatar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2017    [Reject, Accept (Poster), Invite to Workshop T...\n",
       "2018    [Accept (Poster), Reject, Invite to Workshop T...\n",
       "2019             [Reject, Accept (Poster), Accept (Oral)]\n",
       "2020    [Accept (Poster), Accept (Spotlight), Reject, ...\n",
       "2021    [Reject, Accept (Poster), Accept (Oral), Accep...\n",
       "2022    [Reject, Accept (Oral), Accept (Poster), Accep...\n",
       "Name: full_decision, dtype: object"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_reviews_agg.groupby('year').full_decision.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "activated-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the \"design matrix\"\n",
    "design_mat = (sub_reviews_agg # submission-review features\n",
    " .merge(sub_derive, on=['submission_id','year']) # derived features from submissions\n",
    " .merge(author_grp, on=['submission_id','year','arxiv_first']) # arXiv features\n",
    ")\n",
    "\n",
    "# merge with Specter embeddings\n",
    "design_mat = (design_mat\n",
    "    .merge(pd.read_csv(LOCAL_DATA_PATH / 'submission_cluter_20.csv')[['submission_id','cluster']],\n",
    "           on='submission_id', how='left')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a lightweight dataframe for quering S2 data\n",
    "baby_iclr=(design_mat[['submission_id','year','full_decision','arxiv_first',]]\n",
    " .merge(subs[['submission_id','title','authors','keywords','tldr']],\n",
    "       on='submission_id',how='left')\n",
    " .merge(sub_arxiv[['submission_id','arxiv_id','primary_category',\n",
    "                  'published_time','updated_time']], on='submission_id', how='left')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c715189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_iclr.to_csv(LOCAL_DATA_PATH/'baby_iclr.csv', header=True, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "immune-princess",
   "metadata": {},
   "source": [
    "### S2 Citation Data (NCO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "id": "secret-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here the example is 1-year, 3-year, and 5-year (dropping NA rows)\n",
    "# change the path accordingly\n",
    "import functools\n",
    "citation_data_path = [\n",
    "    ('c365', CITATION_DATA_PATH/'c_365.tsv', '\\t'),\n",
    "    ('c730', CITATION_DATA_PATH/'c_730.tsv', '\\t')\n",
    "    ('c1095', CITATION_DATA_PATH/'c_1095.tsv', '\\t'),\n",
    "    ('c1825', CITATION_DATA_PATH/'c_1825.tsv', '\\t')\n",
    "\n",
    "]\n",
    "\n",
    "cites_within_window = functools.reduce(\n",
    "    lambda x,y: x.merge(y,on=['submission_id'], how='outer'),\n",
    "    [(pd.read_csv(p, sep=s)\n",
    "      .rename({'cites_within_year':l,'cites_within_window':l},axis=1,errors='ignore')\n",
    "      [['submission_id',l]]\n",
    "     )\n",
    "     for l, p, s in citation_data_path],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "twelve-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_mat = design_mat.merge(cites_within_window, on='submission_id', how='outer')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "known-skiing",
   "metadata": {},
   "source": [
    "## Prepare Data for Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "antique-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log transform some columns\n",
    "design_mat['log_input_len'] = np.log10(design_mat['input_len'])\n",
    "design_mat['log_ins_rank_min'] = np.log10(design_mat['ins_rank_min'])\n",
    "design_mat['log_ins_rank_avg'] = np.log10(design_mat['ins_rank_avg'])\n",
    "design_mat['log_ins_rank_max'] = np.log10(design_mat['ins_rank_max'])\n",
    "design_mat['log_author_cite_max'] = np.log10(1+design_mat['author_cite_max'])\n",
    "design_mat['log_author_cite_avg'] = np.log10(1+design_mat['author_cite_avg'])\n",
    "design_mat['log_author_cite_min'] = np.log10(1+design_mat['author_cite_min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "rational-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = ['c365', 'c1095', 'c1825']\n",
    "A = 'arxiv_first'\n",
    "Y = 'binary_decision'\n",
    "C_cols = ['year',\n",
    " 'log_input_len',\n",
    " 'log_n_tweets',\n",
    " 'n_fig',\n",
    " 'n_ref',\n",
    " 'n_sec',\n",
    " 'sub_fluency',\n",
    " 'cluster',\n",
    " 'n_author',\n",
    " 'fst_reported_f',\n",
    " 'any_reported_f',\n",
    " 'cnt_reported_f',\n",
    " 'demo_no_us',\n",
    " 'log_ins_rank_min',\n",
    " 'log_ins_rank_avg',\n",
    " 'log_ins_rank_max',\n",
    " 'log_author_cite_min',\n",
    " 'log_author_cite_avg',\n",
    " 'log_author_cite_max'\n",
    "]\n",
    "\n",
    "C_vars = ['C(year)',\n",
    " 'log_input_len',\n",
    " 'log_n_tweets',\n",
    " 'n_fig',\n",
    " 'n_ref',\n",
    " 'n_sec',\n",
    " 'sub_fluency',\n",
    " 'C(cluster)',\n",
    " 'n_author',\n",
    " 'C(fst_reported_f)',\n",
    " 'C(any_reported_f)',\n",
    " 'cnt_reported_f',\n",
    " 'C(demo_no_us)',\n",
    " 'log_ins_rank_min',\n",
    " 'log_ins_rank_avg',\n",
    " 'log_ins_rank_max',\n",
    " 'log_author_cite_min',\n",
    " 'log_author_cite_avg',\n",
    " 'log_author_cite_max'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "regulation-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove NAs in covariates\n",
    "design_mat = design_mat[~design_mat[C_cols].isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "aware-fleet",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_mat.to_csv(LOCAL_DATA_PATH/'design_mat.csv',header=True,index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aging-daily",
   "metadata": {},
   "source": [
    "## Matched Data\n",
    "\n",
    "(run `02_mathcing.ipynb` at this point.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d147761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_matched_df(path, df):\n",
    "    matched_design_mat = pd.read_csv(path).drop('Unnamed: 0',axis=1)\n",
    "    matched_design_mat=matched_design_mat[~matched_design_mat.matched_set.isna()]\n",
    "    return pd.concat([\n",
    "        matched_design_mat.iloc[::2].assign(grp='treated'),\n",
    "        matched_design_mat.iloc[1::2].assign(grp='control'),]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "## with fine-balance\n",
    "fb_matched_dat = load_matched_df(LOCAL_DATA_PATH/'fb_matched_design_mat_ordered.csv', design_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "split-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = design_mat.groupby('cluster').apply(lambda s: \n",
    "    s.groupby('primary_keyword').size().sort_values(ascending=False).iloc[:5],\n",
    "\n",
    "                                   ).to_frame('count').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "prospective-scene",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cluster         primary_keyword  count\n",
      "0        0  reinforcement learning     18\n",
      "1        0           meta-learning     17\n",
      "2        0           deep learning     13\n",
      "3        0   unsupervised learning     11\n",
      "4        0              robustness     10\n",
      "   cluster                     primary_keyword  count\n",
      "5        1              reinforcement learning    116\n",
      "6        1                       deep learning     47\n",
      "7        1             representation learning     11\n",
      "8        1  model-based reinforcement learning     10\n",
      "9        1                     computer vision      9\n",
      "    cluster                primary_keyword  count\n",
      "10        2                  deep learning     31\n",
      "11        2              generative models     13\n",
      "12        2  convolutional neural networks      8\n",
      "13        2         reinforcement learning      8\n",
      "14        2        representation learning      7\n",
      "    cluster            primary_keyword  count\n",
      "15        3              deep learning     57\n",
      "16        3  recurrent neural networks     32\n",
      "17        3      graph neural networks     12\n",
      "18        3      unsupervised learning     11\n",
      "19        3                time series     11\n",
      "    cluster          primary_keyword  count\n",
      "20        4            deep learning    137\n",
      "21        4             optimization     46\n",
      "22        4          neural networks     41\n",
      "23        4  non-convex optimization     26\n",
      "24        4           generalization     24\n",
      "    cluster         primary_keyword  count\n",
      "25        5           deep learning     51\n",
      "26        5              robustness     49\n",
      "27        5    adversarial examples     49\n",
      "28        5  adversarial robustness     34\n",
      "29        5    adversarial training     31\n",
      "    cluster          primary_keyword  count\n",
      "30        6            deep learning     53\n",
      "31        6   reinforcement learning     19\n",
      "32        6  representation learning     19\n",
      "33        6    unsupervised learning     18\n",
      "34        6        generative models     17\n",
      "    cluster                     primary_keyword  count\n",
      "35        7              reinforcement learning    484\n",
      "36        7                       deep learning     55\n",
      "37        7  multi-agent reinforcement learning     39\n",
      "38        7  model-based reinforcement learning     16\n",
      "39        7                  imitation learning     14\n",
      "    cluster       primary_keyword  count\n",
      "40        8    federated learning     71\n",
      "41        8         deep learning     33\n",
      "42        8          optimization     14\n",
      "43        8      machine learning     10\n",
      "44        8  distributed training     10\n",
      "    cluster                  primary_keyword  count\n",
      "45        9                generative models     94\n",
      "46        9                    deep learning     58\n",
      "47        9          variational autoencoder     42\n",
      "48        9  generative adversarial networks     31\n",
      "49        9            unsupervised learning     28\n",
      "    cluster              primary_keyword  count\n",
      "50       10                deep learning     76\n",
      "51       10  natural language processing     66\n",
      "52       10                  transformer     34\n",
      "53       10       reinforcement learning     27\n",
      "54       10            language modeling     24\n",
      "    cluster               primary_keyword  count\n",
      "55       11         graph neural networks    176\n",
      "56       11                 deep learning     45\n",
      "57       11       representation learning     16\n",
      "58       11  graph convolutional networks     15\n",
      "59       11        reinforcement learning     14\n",
      "    cluster           primary_keyword  count\n",
      "60       12             deep learning     76\n",
      "61       12  self-supervised learning     62\n",
      "62       12             meta-learning     44\n",
      "63       12         few-shot learning     23\n",
      "64       12     unsupervised learning     21\n",
      "    cluster         primary_keyword  count\n",
      "65       13  reinforcement learning     36\n",
      "66       13           deep learning     35\n",
      "67       13   graph neural networks     20\n",
      "68       13             transformer     16\n",
      "69       13       generative models     11\n",
      "    cluster             primary_keyword  count\n",
      "70       14               deep learning     74\n",
      "71       14           model compression     24\n",
      "72       14  neural architecture search     14\n",
      "73       14             neural networks     12\n",
      "74       14                quantization     10\n",
      "    cluster           primary_keyword  count\n",
      "75       15             deep learning     37\n",
      "76       15   representation learning     24\n",
      "77       15             meta-learning     16\n",
      "78       15         transfer learning     13\n",
      "79       15  self-supervised learning     10\n",
      "    cluster              primary_keyword  count\n",
      "80       16                deep learning     31\n",
      "81       16      representation learning     16\n",
      "82       16        unsupervised learning     12\n",
      "83       16              word embeddings     11\n",
      "84       16  natural language processing     11\n",
      "    cluster             primary_keyword  count\n",
      "85       17               deep learning     55\n",
      "86       17  neural architecture search     23\n",
      "87       17                optimization     22\n",
      "88       17               meta-learning     19\n",
      "89       17      reinforcement learning     14\n",
      "    cluster          primary_keyword  count\n",
      "90       18            deep learning     60\n",
      "91       18   reinforcement learning     32\n",
      "92       18  representation learning     19\n",
      "93       18           generalization     15\n",
      "94       18          neural networks     13\n",
      "    cluster         primary_keyword  count\n",
      "95       19           deep learning     49\n",
      "96       19        interpretability     19\n",
      "97       19  reinforcement learning     19\n",
      "98       19         neural networks     18\n",
      "99       19  uncertainty estimation     10\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(cluster_df[cluster_df.cluster==i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "intended-softball",
   "metadata": {},
   "source": [
    "### Table One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "conservative-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_mat=pd.read_csv(LOCAL_DATA_PATH/'design_mat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "expanded-answer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tableone\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "artificial-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrcut_tableone(matched, df):\n",
    "    return tableone.TableOne(pd.concat([matched,\n",
    "                                      df[~df.arxiv_first].assign(grp='unmatched')]\n",
    "                            )[C_cols+['grp']].reset_index(), #.assign(grpi=lambda s:s['grp']).set_index(['grpi','submission_id']),\n",
    "                           categorical=['cluster','demo_no_us','fst_reported_f', 'any_reported_f'],\n",
    "                           groupby=['grp'],overall=False, smd=True, missing=False,\n",
    "                           order={'cluster':range(20)},\n",
    "#                              rename={'control':'Matched Comparison Articles', 'treated': 'Early arXiv\\'ed Papers',\n",
    "#                                     'unmatched': 'Non-Early arXiv\\'ed Papers'},\n",
    "                           pval=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "reported-moral",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_fb_matched = constrcut_tableone(fb_matched_dat,design_mat).tableone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "wicked-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_fb_matched.columns=t1_fb_matched.columns.get_level_values(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "worth-homeless",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grp\n",
       "control      1486\n",
       "treated      1486\n",
       "unmatched    7493\n",
       "dtype: int64"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([fb_matched_dat,\n",
    "            design_mat[~design_mat.arxiv_first].assign(grp='unmatched')]\n",
    "    )[C_cols+['grp']].groupby('grp').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "purple-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_matched = constrcut_tableone(matched_dat,design_mat)\n",
    "\n",
    "t1_fb_matched = constrcut_tableone(fb_matched_dat,design_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "italian-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_fb_matched_print=(t1_fb_matched[[t1_fb_matched.columns[i] for i in [1,2,0,3,5]]]\n",
    "  .rename({'control':'Matched Comparison Articles', \n",
    "          'treated': 'Early arXiv\\'ed Papers (Treated Group)',\n",
    "            'unmatched': 'Non-Early arXiv\\'ed Papers (Unmatched)',\n",
    "           'SMD (treated,unmatched)': 'SMD (Before Matching)',\n",
    "           'SMD (control,treated)': 'SMD (After Matching)',\n",
    "          },axis=1\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "micro-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_index(s):\n",
    "    s = list(s)\n",
    "    s[0] = r\"\\texttt{\" + s[0].split(',')[0].replace('_','\\_')+r\"}\"\n",
    "    return tuple(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "after-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_fb_matched_print.index=t1_fb_matched_print.index.map(rename_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "religious-precipitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "                                &      & Early arXiv'ed Papers (Treated Group) & Non-Early arXiv'ed Papers (Unmatched) & Matched Comparison Articles & SMD (Before Matching) & SMD (After Matching) \\\\\n",
      "\\midrule\n",
      "\\texttt{n} & {} &                                  1486 &                                  7493 &                        1486 &                       &                      \\\\\n",
      "\\texttt{index} &      &                        1485.0 (858.2) &                       4447.8 (2585.8) &              1486.0 (858.2) &                 1.538 &               -0.001 \\\\\n",
      "\\texttt{year} &      &                          2020.8 (0.9) &                          2020.3 (1.5) &                2020.8 (0.9) &                -0.447 &               -0.001 \\\\\n",
      "\\texttt{log\\_input\\_len} &      &                             4.0 (0.2) &                             4.0 (0.2) &                   4.0 (0.2) &                -0.355 &               -0.002 \\\\\n",
      "\\texttt{n\\_fig} &      &                            14.3 (7.5) &                            12.6 (7.3) &                  14.0 (8.2) &                -0.221 &                0.035 \\\\\n",
      "\\texttt{n\\_ref} &      &                           44.7 (16.7) &                           40.9 (16.9) &                 44.4 (18.6) &                -0.224 &                0.017 \\\\\n",
      "\\texttt{n\\_sec} &      &                            20.8 (7.8) &                            19.2 (7.1) &                  20.9 (7.9) &                -0.213 &               -0.018 \\\\\n",
      "\\texttt{sub\\_fluency} &      &                             0.8 (0.0) &                             0.8 (0.0) &                   0.8 (0.0) &                 0.172 &               -0.015 \\\\\n",
      "\\texttt{cluster} & 0 &                              77 (5.2) &                             325 (4.3) &                    77 (5.2) &                 0.188 &               <0.001 \\\\\n",
      "                                & 1 &                              66 (4.4) &                             392 (5.2) &                    66 (4.4) &                       &                      \\\\\n",
      "                                & 2 &                              46 (3.1) &                             223 (3.0) &                    46 (3.1) &                       &                      \\\\\n",
      "                                & 3 &                              55 (3.7) &                             340 (4.5) &                    55 (3.7) &                       &                      \\\\\n",
      "                                & 4 &                             140 (9.4) &                             495 (6.6) &                   140 (9.4) &                       &                      \\\\\n",
      "                                & 5 &                             106 (7.1) &                             458 (6.1) &                   106 (7.1) &                       &                      \\\\\n",
      "                                & 6 &                              87 (5.9) &                             363 (4.8) &                    87 (5.9) &                       &                      \\\\\n",
      "                                & 7 &                             129 (8.7) &                            752 (10.0) &                   129 (8.7) &                       &                      \\\\\n",
      "                                & 8 &                              62 (4.2) &                             271 (3.6) &                    62 (4.2) &                       &                      \\\\\n",
      "                                & 9 &                              74 (5.0) &                             465 (6.2) &                    74 (5.0) &                       &                      \\\\\n",
      "                                & 10 &                             108 (7.3) &                             543 (7.2) &                   108 (7.3) &                       &                      \\\\\n",
      "                                & 11 &                              94 (6.3) &                             387 (5.2) &                    94 (6.3) &                       &                      \\\\\n",
      "                                & 12 &                              87 (5.9) &                             455 (6.1) &                    87 (5.9) &                       &                      \\\\\n",
      "                                & 13 &                              49 (3.3) &                             289 (3.9) &                    49 (3.3) &                       &                      \\\\\n",
      "                                & 14 &                              48 (3.2) &                             332 (4.4) &                    48 (3.2) &                       &                      \\\\\n",
      "                                & 15 &                              44 (3.0) &                             274 (3.7) &                    44 (3.0) &                       &                      \\\\\n",
      "                                & 16 &                              41 (2.8) &                             251 (3.3) &                    41 (2.8) &                       &                      \\\\\n",
      "                                & 17 &                              50 (3.4) &                             296 (4.0) &                    50 (3.4) &                       &                      \\\\\n",
      "                                & 18 &                              57 (3.8) &                             299 (4.0) &                    57 (3.8) &                       &                      \\\\\n",
      "                                & 19 &                              66 (4.4) &                             283 (3.8) &                    66 (4.4) &                       &                      \\\\\n",
      "\\texttt{n\\_author} &      &                             4.2 (1.9) &                             4.3 (2.0) &                   4.1 (1.9) &                 0.096 &                0.002 \\\\\n",
      "\\texttt{fst\\_reported\\_f} & False &                           1399 (94.1) &                           6850 (91.4) &                 1397 (94.0) &                 0.106 &                0.006 \\\\\n",
      "                                & True &                              87 (5.9) &                             643 (8.6) &                    89 (6.0) &                       &                      \\\\\n",
      "\\texttt{any\\_reported\\_f} & False &                           1111 (74.8) &                           5320 (71.0) &                 1125 (75.7) &                 0.085 &                0.022 \\\\\n",
      "                                & True &                            375 (25.2) &                           2173 (29.0) &                  361 (24.3) &                       &                      \\\\\n",
      "\\texttt{cnt\\_reported\\_f} &      &                             0.3 (0.6) &                             0.4 (0.6) &                   0.3 (0.6) &                 0.087 &                0.009 \\\\\n",
      "\\texttt{demo\\_no\\_us} & False &                           1022 (68.8) &                           4956 (66.1) &                 1018 (68.5) &                 0.056 &                0.006 \\\\\n",
      "                                & True &                            464 (31.2) &                           2537 (33.9) &                  468 (31.5) &                       &                      \\\\\n",
      "\\texttt{log\\_ins\\_rank\\_min} &      &                             1.1 (0.7) &                             1.1 (0.7) &                   1.1 (0.7) &                 0.042 &               -0.001 \\\\\n",
      "\\texttt{log\\_ins\\_rank\\_avg} &      &                             1.6 (0.6) &                             1.5 (0.6) &                   1.6 (0.6) &                -0.041 &               -0.000 \\\\\n",
      "\\texttt{log\\_ins\\_rank\\_max} &      &                             1.8 (0.6) &                             1.7 (0.6) &                   1.8 (0.6) &                -0.064 &               -0.001 \\\\\n",
      "\\texttt{log\\_author\\_cite\\_min} &      &                             2.3 (0.8) &                             2.3 (0.8) &                   2.4 (0.8) &                 0.008 &               -0.021 \\\\\n",
      "\\texttt{log\\_author\\_cite\\_avg} &      &                             3.6 (0.6) &                             3.6 (0.7) &                   3.6 (0.6) &                -0.067 &               <0.001 \\\\\n",
      "\\texttt{log\\_author\\_cite\\_max} &      &                             4.0 (0.7) &                             3.9 (0.8) &                   3.9 (0.7) &                -0.083 &                0.012 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(t1_fb_matched_print.to_latex(escape=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8-torch",
   "language": "python",
   "name": "py3.8-torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
