{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "advanced-weekend",
   "metadata": {},
   "source": [
    "# Primary and NOC Analysis\n",
    "\n",
    "v.1 Jiayao Zhang\n",
    "June 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "brown-element",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=7\n",
      "env: OMP_NUM_THREADS=15\n",
      "env: OPENBLAS_NUM_THREADS=15\n",
      "env: OPENMP_NUM_THREADS=15\n",
      "env: MKL_NUM_THREADS=15\n",
      "env: HF_HOME=/shared/zjiayao/cache\n",
      "env: ALLENNLP_CACHE_ROOT=/shared/zjiayao/cache/allennlp\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, absolute_import, division\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import json\n",
    "import uuid\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "settled-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sns.set()\n",
    "sns.set(font_scale=2.5,)\n",
    "sns.set_style(\"white\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "tqdm.tqdm.pandas()\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-colon",
   "metadata": {},
   "source": [
    "# Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "romantic-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = ['c365', 'c730', 'c1095']\n",
    "A = 'arxiv_first'\n",
    "Y = 'binary_decision'\n",
    "C_cols = ['year',\n",
    " 'log_input_len',\n",
    " 'n_fig',\n",
    " 'n_ref',\n",
    " 'n_sec',\n",
    " 'sub_fluency',\n",
    " 'cluster',\n",
    " 'n_author',\n",
    " 'fst_reported_f',\n",
    " 'any_reported_f',\n",
    " 'cnt_reported_f',\n",
    " 'demo_no_us',\n",
    " 'log_ins_rank_min',\n",
    " 'log_ins_rank_avg',\n",
    " 'log_ins_rank_max',\n",
    " 'log_author_cite_min',\n",
    " 'log_author_cite_avg',\n",
    " 'log_author_cite_max'\n",
    "]\n",
    "\n",
    "C_vars = ['C(year)',\n",
    " 'log_input_len',\n",
    " 'n_fig',\n",
    " 'n_ref',\n",
    " 'n_sec',\n",
    " 'sub_fluency',\n",
    " 'C(cluster)',\n",
    " 'n_author',\n",
    " 'C(fst_reported_f)',\n",
    " 'C(any_reported_f)',\n",
    " 'cnt_reported_f',\n",
    " 'C(demo_no_us)',\n",
    " 'log_ins_rank_min',\n",
    " 'log_ins_rank_avg',\n",
    " 'log_ins_rank_max',\n",
    " 'log_author_cite_min',\n",
    " 'log_author_cite_avg',\n",
    " 'log_author_cite_max'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "planned-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the path accordingly\n",
    "import functools\n",
    "citation_data_path = [\n",
    "    ('c365', './data/s2_citation/c_365.tsv', '\\t'),\n",
    "    ('c730', './data/s2_citation/c_730.tsv', '\\t'),\n",
    "    ('c1095', './data/s2_citation/c_1095.tsv', '\\t'),\n",
    "    ('c1825', './data/s2_citation/c_1825.tsv', '\\t')\n",
    "\n",
    "]\n",
    "\n",
    "cites_within_window = functools.reduce(\n",
    "    lambda x,y: x.merge(y,on=['submission_id'], how='outer'),\n",
    "    [(pd.read_csv(p, sep=s)\n",
    "      .rename({'cites_within_year':l,'cites_within_window':l},axis=1,errors='ignore')\n",
    "      [['submission_id',l]]\n",
    "     )\n",
    "     for l, p, s in citation_data_path],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-manufacturer",
   "metadata": {},
   "source": [
    "Load processed \"design matrix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beneficial-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_mat=pd.read_csv('./data/design_mat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "touched-indiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratification by subgroups\n",
    "design_mat = (\n",
    "    design_mat.drop(['c365','c1095','c1825'],axis=1)\n",
    "    .merge(cites_within_window, on='submission_id', how='left')\n",
    ")\n",
    "\n",
    "design_mat['inst_level'] =\\\n",
    "    design_mat['log_ins_rank_min'].apply(lambda s : 'L' if s < 1 else ('M' if s < 2 else 'H')\n",
    ")\n",
    "\n",
    "design_mat['author_level'] =\\\n",
    "    design_mat['author_cite_avg'].apply(lambda s : 'L' if s < 500 else ('M' if s < 2000 else 'H')\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "assured-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_matched_df(path, df):\n",
    "    matched_design_mat = pd.read_csv(path).drop('Unnamed: 0',axis=1)\n",
    "    matched_design_mat=matched_design_mat[~matched_design_mat.matched_set.isna()]\n",
    "    return pd.concat([\n",
    "        matched_design_mat.iloc[::2].assign(grp='treated'),\n",
    "        matched_design_mat.iloc[1::2].assign(grp='control'),]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-tablet",
   "metadata": {},
   "source": [
    "Load matched pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "radical-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "## with fine-balance on topic cluster\n",
    "## this will be used in the subsequent analysis\n",
    "fb_matched_dat = load_matched_df('./data/fb_matched_design_mat_ordered.csv', design_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-algorithm",
   "metadata": {},
   "source": [
    "### Inspecting Sample Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "detailed-anaheim",
   "metadata": {},
   "outputs": [],
   "source": [
    "smpsize_df=pd.concat([dat[data_selector(dat,N)]\n",
    " .query(f\"{N}>={t}\")\n",
    " .groupby(\n",
    "    ['arxiv_first','inst_level']).size()\n",
    " .to_frame('smps').assign(N=N,t=t)\n",
    " for N,t  in thres\n",
    "])\n",
    "\n",
    "for i, (N,t) in enumerate(thres):\n",
    "    q = [50, 75, 90]\n",
    "    smpsize_df.loc[(smpsize_df.N==N)&(smpsize_df.t==t),'t'] =\\\n",
    "        rf\"${q[i%3]}\\%$ (${t}$)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "honey-reservoir",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrr}\n",
      "\\toprule\n",
      "            & Author Institution & \\multicolumn{2}{l}{Top-$10$} & \\multicolumn{2}{l}{Top-$10$ to $100$} & \\multicolumn{2}{l}{Others} \\\\\n",
      "            & Early arXiving ($A$) &    $A=0$ & $A=1$ &             $A=0$ & $A=1$ &  $A=0$ & $A=1$ \\\\\n",
      "N & t &          &       &                   &       &        &       \\\\\n",
      "\\midrule\n",
      "$\\cc^{(1)}$ & $50\\%$ ($4$) &       36 &    46 &               320 &   398 &    214 &   322 \\\\\n",
      "            & $75\\%$ ($11$) &       14 &    16 &               171 &   225 &     86 &   139 \\\\\n",
      "            & $90\\%$ ($23$) &        5 &     4 &                77 &   102 &     26 &    42 \\\\\n",
      "$\\cc^{(2)}$ & $50\\%$ ($10$) &       26 &    39 &               247 &   304 &    141 &   232 \\\\\n",
      "            & $75\\%$ ($29$) &       13 &    16 &               133 &   172 &     54 &   108 \\\\\n",
      "            & $90\\%$ ($65$) &        3 &     6 &                52 &    85 &     16 &    34 \\\\\n",
      "$\\cc^{(3)}$ & $50\\%$ ($11$) &       20 &    26 &               168 &   205 &     91 &   157 \\\\\n",
      "            & $75\\%$ ($41$) &        8 &    11 &                95 &   118 &     32 &    75 \\\\\n",
      "            & $90\\%$ ($103$) &        2 &     4 &                34 &    59 &      9 &    28 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "(smpsize_df.reset_index()\n",
    " .replace({'inst_level': {\n",
    "     'H': r'Top-$10$',\n",
    "     'L': r'Top-$10$ to $100$',\n",
    "     'M': r'Others'\n",
    "     },    \n",
    "    'N':{\n",
    "         N:r\"$\\cc^{(\" +f'{i+1}' + r\")}$\"\n",
    "         for i,N in enumerate(Ns)\n",
    "        },\n",
    "    'arxiv_first': {\n",
    "     True: r\"$A=1$\",\n",
    "     False: r\"$A=0$\",\n",
    "         }\n",
    "    })\n",
    " .rename({'inst_level':'Author Institution', 'arxiv_first': r'Early arXiving ($A$)'},axis=1)\n",
    " .pivot(index=['N','t'], columns=['Author Institution', r'Early arXiving ($A$)'], values='smps')\n",
    " .sort_index(axis='columns', level='Author Institution',\n",
    "            key=lambda s:s.map({r'Top-$10$':0,\n",
    "                                r'Top-$10$ to $100$':1,\n",
    "                                r'Others':2})\n",
    "            )\n",
    ").to_latex(escape=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "hawaiian-antarctica",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrr}\n",
      "\\toprule\n",
      "     &       &  acc &  rej &   c365 &    c730 &   c1095 \\\\\n",
      "year & arxiv_first &      &      &        &         &         \\\\\n",
      "\\midrule\n",
      "2018 & $A=0$ &   10 &   10 &   9.85 &   27.45 &   47.40 \\\\\n",
      "     & $A=1$ &   19 &    1 &  30.10 &  112.60 &  249.95 \\\\\n",
      "2019 & $A=0$ &   24 &   24 &  14.52 &   38.70 &   63.52 \\\\\n",
      "     & $A=1$ &   27 &   21 &  14.13 &   39.04 &   69.79 \\\\\n",
      "2020 & $A=0$ &  190 &  312 &   8.32 &   20.53 &   34.03 \\\\\n",
      "     & $A=1$ &  235 &  267 &  11.86 &   34.50 &   58.14 \\\\\n",
      "2021 & $A=0$ &  182 &  320 &   8.99 &   25.15 &   12.71 \\\\\n",
      "     & $A=1$ &  232 &  271 &   8.66 &   24.33 &   35.84 \\\\\n",
      "2022 & $A=0$ &  198 &  216 &   8.76 &   14.24 &    0.29 \\\\\n",
      "     & $A=1$ &  236 &  177 &   7.81 &   20.21 &    0.53 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    dat.sort_values(['binary_decision'])\n",
    "    .replace({'arxiv_first':{\n",
    "        True: r\"$A=1$\",\n",
    "        False: r\"$A=0$\",\n",
    "    }})\n",
    "    .assign(\n",
    "    acc=lambda s:s['binary_decision'],\n",
    "    rej=lambda s:s['binary_decision'],\n",
    ").groupby(['year','arxiv_first']).agg({\n",
    "    'acc': lambda s : sum(s==1),\n",
    "    'rej': lambda s : sum(s==0),\n",
    "        'c365': lambda s: np.round(np.mean(s),2),\n",
    "        'c730': lambda s: np.round(np.mean(s),2),\n",
    "    'c1095': lambda s: np.round(np.mean(s),2),\n",
    "}).to_latex(escape=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-matthew",
   "metadata": {},
   "source": [
    "# Primary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "mathematical-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "collaborative-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_formula = '+'.join(C_vars)\n",
    "formula = f\"{A} + \" + C_formula\n",
    "inst_formula = f\"{A} + \" + '+'.join([var for var in C_vars if 'inst_rank' not in var])\n",
    "author_formula = f\"{A} + \" + '+'.join([var for var in C_vars if 'author_cite' not in var])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cooked-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cond_means_y(predictor, dat, A_col):\n",
    "    Y_1 = np.mean(predictor.predict(dat[dat[A_col]]))\n",
    "    Y_0 = np.mean(predictor.predict(dat[~dat[A_col]]))\n",
    "    return pd.DataFrame([[Y_1,Y_0,Y_1-Y_0]],columns=['Y_1','Y_0','D1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-journey",
   "metadata": {},
   "source": [
    "### (Optional) Unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "deluxe-olive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.606045\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "Y_unadjust = smf.logit(formula=f\"{Y} ~ {formula}\", data=design_mat).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "loving-preserve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_1</th>\n",
       "      <th>Y_0</th>\n",
       "      <th>D1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.504038</td>\n",
       "      <td>0.377019</td>\n",
       "      <td>0.127019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Y_1       Y_0        D1\n",
       "0  0.504038  0.377019  0.127019"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_cond_means_y(Y_unadjust, design_mat, 'arxiv_first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-profit",
   "metadata": {},
   "source": [
    "### Primary Analysis: on the Matched Sample (without NOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-diploma",
   "metadata": {},
   "source": [
    "#### 1. On the full matched sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "developmental-durham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.623841\n",
      "         Iterations 5\n"
     ]
    }
   ],
   "source": [
    "Y_matched = smf.logit(formula=f\"{Y} ~ {formula}\", data=dat).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "stable-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper for bootstraping\n",
    "def bootstrap_ci(dat, A_col, match_col='matched_set', n_rep=2000, est_name='D1'):\n",
    "    idx_set = list(dat[match_col].unique())\n",
    "    \n",
    "    _bootstraps = []\n",
    "    for _ in range(n_rep):\n",
    "        smp_idx = set(np.random.choice(idx_set, len(idx_set), replace=True))\n",
    "        dt = dat.loc[dat[dat[match_col].isin(smp_idx)].index].reset_index(drop=True)\n",
    "        \n",
    "        predictor = smf.logit(formula=f\"{Y} ~ {formula}\", data=dt).fit(disp=0)\n",
    "        _bootstraps.append(\n",
    "            np.mean(predictor.predict(dt[dt[A_col]])) - np.mean(predictor.predict(dt[~dt[A_col]]))\n",
    "        )\n",
    "    res = pd.DataFrame(_bootstraps, columns=[est_name])\n",
    "    res['bidx'] = list(range(n_rep))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "lesser-detroit",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:37<00:00, 12.66it/s]\n"
     ]
    }
   ],
   "source": [
    "Y_matched_boot=bootstrap_ci(dat, 'arxiv_first',\n",
    "                            match_col='matched_set', n_rep=2000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "daily-growth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>ll</th>\n",
       "      <th>hl</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.09762</td>\n",
       "      <td>0.070083</td>\n",
       "      <td>0.126071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           r        ll        hl\n",
       "grp                             \n",
       "0    0.09762  0.070083  0.126071"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ci_table(Y_matched_boot.assign(grp=0),effect_col='D1', groups=['grp'],alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-reservoir",
   "metadata": {},
   "source": [
    "#### 2. On subsets of matched sample determined by availability of citation counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "laden-synthesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [05:00<?, ?it/s]3.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [04:50<02:23, 143.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 3/3 [06:49<00:00, 136.61s/it]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "Y_matched_boot_byN=pd.concat([bootstrap_ci(\n",
    "        dat[data_selector(dat,N)], 'arxiv_first',\n",
    "        match_col='matched_set', n_rep=2000,est_name='DiD'\n",
    "    ).assign(N=N)\n",
    " for N in tqdm.tqdm(Ns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "gothic-switch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>ll</th>\n",
       "      <th>hl</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grp</th>\n",
       "      <th>N</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>c1095</th>\n",
       "      <td>0.100301</td>\n",
       "      <td>0.054199</td>\n",
       "      <td>0.143662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c365</th>\n",
       "      <td>0.097885</td>\n",
       "      <td>0.070897</td>\n",
       "      <td>0.124604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c730</th>\n",
       "      <td>0.098994</td>\n",
       "      <td>0.068010</td>\n",
       "      <td>0.131942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  r        ll        hl\n",
       "grp N                                  \n",
       "0   c1095  0.100301  0.054199  0.143662\n",
       "    c365   0.097885  0.070897  0.124604\n",
       "    c730   0.098994  0.068010  0.131942"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ci_table(Y_matched_boot_byN.assign(grp=0),effect_col='DiD', groups=['grp','N'],alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-shore",
   "metadata": {},
   "source": [
    "# Anlaysis with NOC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-cornell",
   "metadata": {},
   "source": [
    "NOCs are defined by thresholding citation counts using the 0.5, 0.7, and 0.9 -th quantile\n",
    "in the matched sample. Below is the threshold for each citation count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sunset-mortgage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.0, 11.0, 23.0]\n",
      "[10.0, 29.0, 65.0]\n",
      "[11.0, 41.0, 102.70000000000005]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "_=[print([np.quantile(dat[N].dropna(),q) for q in [0.5,0.75,0.9]])\n",
    "  for N in ['c365','c730','c1095']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "impaired-diving",
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = [\n",
    "    ('c365', 4),\n",
    "    ('c365', 11),\n",
    "    ('c365', 23),\n",
    "    ('c730', 10),\n",
    "    ('c730', 29),\n",
    "    ('c730', 65),\n",
    "    ('c1095', 11),\n",
    "    ('c1095', 41),\n",
    "    ('c1095', 103),\n",
    "]\n",
    "def data_selector(df, N):\n",
    "    \"\"\"Select only valid subset of data.\"\"\"\n",
    "    if N not in ['c365','c730','c1095']:\n",
    "        return (df.index >=0) | (df.index<0)\n",
    "    return df.year <= {\n",
    "        'c365': 2022,\n",
    "        'c730': 2021,\n",
    "        'c1095': 2020,\n",
    "    }[N]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-pavilion",
   "metadata": {},
   "source": [
    "### Analysis on all matched samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "alien-egyptian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_full_model(data, N, t):\n",
    "    \"\"\"Model for DiD (additive equi-confounding adjustment for DiD)\"\"\"\n",
    "    sel = data_selector(data, N)\n",
    "    var = f\"N_full_{N}_{t}\"\n",
    "    data[var] = 1. * ( data[N] >= t)\n",
    "    try:\n",
    "        Y_model = smf.logit(f\"{Y}~{formula}\", data=data[sel]).fit(disp=0)\n",
    "    except: \n",
    "        Y_model = smf.logit(f\"{Y}~{formula}\", data=data[sel]).fit(disp=0,method='bfgs')\n",
    "        \n",
    "    try:\n",
    "        N_model = smf.logit(f\"{var}~{formula}\", data=data[sel]).fit(disp=0)\n",
    "    except:\n",
    "        N_model = smf.logit(f\"{var}~{formula}\", data=data[sel]).fit(disp=0,method='bfgs')\n",
    "    return Y_model, N_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "contrary-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cond_means(predictors, dat, A_col):\n",
    "    \"\"\"Helper for collecting the results.\"\"\"\n",
    "    Y_pred, N_pred = predictors\n",
    "    X_tr, X_ct = dat[dat[A_col]], dat[~dat[A_col]]\n",
    "    Y_1 = np.mean(Y_pred.predict(X_tr))\n",
    "    Y_0 = np.mean(Y_pred.predict(X_ct))\n",
    "    N_1 = np.mean(N_pred.predict(X_tr))\n",
    "    N_0 = np.mean(N_pred.predict(X_ct))\n",
    "    return pd.DataFrame([[\n",
    "        Y_1, Y_0, N_1, N_0, N_1-N_0, Y_1-Y_0, (Y_1-N_1)-(Y_0-N_0)\n",
    "    ]], columns=['Y_1','Y_0','N_1','N_0','DN','DY','DiD'])\n",
    "    print(f\"DN: {N_1-N_0:6.4f} vanilla ATET: {Y_1-Y_0:6.4f}\\tNOC ATET: {(Y_1-N_1)-(Y_0-N_0):6.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cardiovascular-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_means_and_ci(dat, A_col, N, t, match_col='matched_set', n_rep=2000,):\n",
    "    \"\"\"Bootstrap CI.\"\"\"\n",
    "    idx_set = list(dat[match_col].unique())\n",
    "    \n",
    "\n",
    "    _bootstraps = []\n",
    "\n",
    "    for bidx in range(n_rep):\n",
    "        smp_idx = set(np.random.choice(idx_set, len(idx_set), replace=True))\n",
    "        dt = dat[dat[match_col].isin(smp_idx)].reset_index(drop=True)\n",
    "        sel = data_selector(dt, N)\n",
    "        predictors = fit_full_model(dt, N, t)\n",
    "                \n",
    "        _bootstraps.append(print_cond_means(predictors, dt[sel], A_col)\n",
    "         .assign(N=N, t=t, n_N1=sum(dt[sel][N] > t))\n",
    "         .assign(boot_idx=bidx)\n",
    "        )\n",
    "    return pd.concat(_bootstraps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-thriller",
   "metadata": {},
   "source": [
    "Sample sizes for each study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "split-clerk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2972, 2145, 1140]"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dat[data_selector(dat, N)].shape[0] for N in Ns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-guess",
   "metadata": {},
   "source": [
    "#### NOC-adjusted Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "fleet-local",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█         | 1/9 [00:00<00:01,  7.25it/s]\u001b[A\n",
      " 22%|██▏       | 2/9 [00:00<00:00,  7.76it/s]\u001b[A\n",
      " 33%|███▎      | 3/9 [00:00<00:00,  7.96it/s]\u001b[A\n",
      " 56%|█████▌    | 5/9 [00:00<00:00,  9.10it/s]\u001b[A\n",
      " 67%|██████▋   | 6/9 [00:00<00:00,  9.22it/s]\u001b[A\n",
      "100%|██████████| 9/9 [00:00<00:00,  9.73it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "fitted_full_models = [\n",
    "    fit_full_model(dat, N, t)\n",
    "    for N, t in tqdm.tqdm(thres)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "peaceful-harris",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 11.41it/s]\u001b[A\n",
      "4it [00:00, 11.84it/s]\u001b[A\n",
      "6it [00:00, 11.84it/s]\u001b[A\n",
      "9it [00:00, 12.06it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "full_model_atet = pd.concat(\n",
    "    [(print_cond_means(predictors, dat[data_selector(dat, N)], 'arxiv_first')\n",
    "     .assign(N=N, t=t, n_N1=sum(dat[data_selector(dat, N)][N] > t))\n",
    "    ) for predictors, (N,t) in tqdm.tqdm(zip(fitted_full_models, thres))\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "statistical-isaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [42:55<00:00, 286.17s/it]\n"
     ]
    }
   ],
   "source": [
    "full_model_ci = pd.concat([\n",
    "    cond_means_and_ci(dat, 'arxiv_first', N=N, t=t, n_rep=2000)\n",
    "    for N, t in tqdm.tqdm(thres)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "creative-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ci_table(boot_df, effect_col='DiD', groups=['N','t'], alpha=0.05):\n",
    "    ll = alpha / 2.\n",
    "    hl = 1. - ll\n",
    "    return pd.concat([\n",
    "      boot_df.groupby(groups)[effect_col].apply(lambda s : np.mean(s)).to_frame('r'),\n",
    "      boot_df.groupby(groups)[effect_col].apply(lambda s : np.quantile(s,ll)).to_frame('ll'),\n",
    "     boot_df.groupby(groups)[effect_col].apply(lambda s : np.quantile(s,hl)).to_frame('hl'),\n",
    "    ],axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_ci.to_csv('./processed_data/nongrp_bootstrap_smps.csv',\n",
    "                    header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "correct-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_ci_table = get_ci_table(full_model_ci,alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "spread-pixel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>ll</th>\n",
       "      <th>hl</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <th>t</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">c1095</th>\n",
       "      <th>11</th>\n",
       "      <td>-0.091711</td>\n",
       "      <td>-0.133880</td>\n",
       "      <td>-0.048697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.026330</td>\n",
       "      <td>-0.068770</td>\n",
       "      <td>0.017409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.021648</td>\n",
       "      <td>-0.027108</td>\n",
       "      <td>0.070624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">c365</th>\n",
       "      <th>4</th>\n",
       "      <td>-0.006561</td>\n",
       "      <td>-0.037596</td>\n",
       "      <td>0.022369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.037272</td>\n",
       "      <td>0.009594</td>\n",
       "      <td>0.065131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.075585</td>\n",
       "      <td>0.047771</td>\n",
       "      <td>0.102834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">c730</th>\n",
       "      <th>10</th>\n",
       "      <td>-0.040641</td>\n",
       "      <td>-0.072574</td>\n",
       "      <td>-0.008928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.007396</td>\n",
       "      <td>-0.025262</td>\n",
       "      <td>0.042002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.051294</td>\n",
       "      <td>0.016825</td>\n",
       "      <td>0.086580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  r        ll        hl\n",
       "N     t                                \n",
       "c1095 11  -0.091711 -0.133880 -0.048697\n",
       "      41  -0.026330 -0.068770  0.017409\n",
       "      103  0.021648 -0.027108  0.070624\n",
       "c365  4   -0.006561 -0.037596  0.022369\n",
       "      11   0.037272  0.009594  0.065131\n",
       "      23   0.075585  0.047771  0.102834\n",
       "c730  10  -0.040641 -0.072574 -0.008928\n",
       "      29   0.007396 -0.025262  0.042002\n",
       "      65   0.051294  0.016825  0.086580"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model_ci_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "floppy-confidence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$-0.0066$ & $0.0373$ & $0.0756$ & $-0.0406$ & $0.0074$ & $0.0513$ & $-0.0917$ & $-0.0263$ & $0.0216$ \\\\\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    r'$'+r'$ & $'.join(\n",
    "     [f\"{r:.4f}\"for r in\n",
    "        [full_model_ci_table.reset_index().query(f\"(N=='{N}') and (t=={t})\").r.iloc[0] \n",
    "         for N,t in thres]\n",
    "     ]\n",
    "    )+r'$ \\\\'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "sophisticated-auction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$-0.0066$ & $0.0377$ & $0.0752$ & $-0.0402$ & $0.0072$ & $0.0508$ & $-0.0912$ & $-0.0264$ & $0.0210$ \\\\\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    r'$'+r'$ & $'.join(\n",
    "     [f\"{r:.4f}\"for r in\n",
    "        [full_model_ci_table.reset_index().query(f\"(N=='{N}') and (t=={t})\").r.iloc[0] \n",
    "         for N,t in thres]\n",
    "     ]\n",
    "    )+r'$ \\\\'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "eight-chemical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$(-0.0376,0.0224)$ & $(0.0096,0.0651)$ & $(0.0478,0.1028)$ & $(-0.0726,-0.0089)$ & $(-0.0253,0.0420)$ & $(0.0168,0.0866)$ & $(-0.1339,-0.0487)$ & $(-0.0688,0.0174)$ & $(-0.0271,0.0706)$ \\\\\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    r'$'+r'$ & $'.join(\n",
    "     [f\"({ll:.4f},{lh:.4f})\"for ll,lh in\n",
    "        [(full_model_ci_table.reset_index().query(f\"(N=='{N}') and (t=={t})\").ll.iloc[0],\n",
    "         full_model_ci_table.reset_index().query(f\"(N=='{N}') and (t=={t})\").hl.iloc[0] )\n",
    "         for N,t in thres]\n",
    "     ]\n",
    "    )+r'$ \\\\'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "historical-respondent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$(-0.0136,0.0002)$ & $(0.0295,0.0457)$ & $(0.0669,0.0836)$ & $(-0.0478,-0.0325)$ & $(-0.0016,0.0162)$ & $(0.0407,0.0611)$ & $(-0.1012,-0.0810)$ & $(-0.0387,-0.0142)$ & $(0.0078,0.0345)$ \\\\\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    r'$'+r'$ & $'.join(\n",
    "     [f\"({ll:.4f},{lh:.4f})\"for ll,lh in\n",
    "        [(full_model_ci_table.reset_index().query(f\"(N=='{N}') and (t=={t})\").ll.iloc[0],\n",
    "         full_model_ci_table.reset_index().query(f\"(N=='{N}') and (t=={t})\").hl.iloc[0] )\n",
    "         for N,t in thres]\n",
    "     ]\n",
    "    )+r'$ \\\\'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-comedy",
   "metadata": {},
   "source": [
    "## Stratified Anlaysis for Author Subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "recreational-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_means_ci_subgrp(dat, N, t, A_col, level_col, level_vars, level_lb,\n",
    "                         all_lb='all',grp_name='level',\n",
    "                         n_rep=2000, match_col='matched_set'):\n",
    "    \"\"\"DiD/NOC for stratified analysis.\"\"\"\n",
    "\n",
    "    estimates = []\n",
    "    for lv, lb in zip([None,]+level_vars, [all_lb,]+level_lb):\n",
    "        df = dat[dat[level_col] == lv] if lv is not None else dat\n",
    "        df = df[data_selector(df, N)].reset_index(drop=True)\n",
    "        idx_set = list(df[match_col].unique())\n",
    "        \n",
    "        _bootstraps = []\n",
    "        for bidx in range(n_rep):\n",
    "            smp_idx = set(np.random.choice(idx_set, len(idx_set), replace=True))\n",
    "            dt = df[df[match_col].isin(smp_idx)].reset_index(drop=True)\n",
    "            try:\n",
    "                Y_pred, N_pred = fit_full_model(dt, N, t)\n",
    "            except:\n",
    "                continue\n",
    "            X_tr, X_ct = dt[dt[A_col]], dt[~dt[A_col]]\n",
    "            Y_1 = Y_pred.predict(X_tr)\n",
    "            Y_0 = Y_pred.predict(X_ct)\n",
    "            N_1 = N_pred.predict(X_tr)\n",
    "            N_0 = N_pred.predict(X_ct)\n",
    "            \n",
    "            # DiD\n",
    "            _bootstraps.append(\n",
    "                (np.mean(Y_1) - np.mean(N_1)) -\\\n",
    "                (np.mean(Y_0) - np.mean(N_0))\n",
    "            )\n",
    "        res = pd.DataFrame(_bootstraps, columns=['DiD'])\n",
    "#         res['bidx'] = list(range(n_rep))\n",
    "        res['grp'] = grp_name\n",
    "        res['n'] = len(idx_set)\n",
    "        res[level_col] = lb\n",
    "        estimates.append(res)\n",
    "    return pd.concat(estimates).assign(N=N, t=t)\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "auburn-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ci_table(boot_df, effect_col='DiD', groups=['N','t'], alpha=0.05):\n",
    "    ll = alpha / 2.\n",
    "    hl = 1. - ll\n",
    "    return pd.concat([\n",
    "      boot_df.groupby(groups)[effect_col].apply(lambda s : np.mean(s)).to_frame('r'),\n",
    "      boot_df.groupby(groups)[effect_col].apply(lambda s : np.quantile(s,ll)).to_frame('ll'),\n",
    "     boot_df.groupby(groups)[effect_col].apply(lambda s : np.quantile(s,hl)).to_frame('hl'),\n",
    "    ],axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_model_ci = pd.concat([\n",
    "        cond_means_ci_subgrp(dat, N=N, t=t,A_col='arxiv_first',\n",
    "            level_col='author_level',level_vars=['L','M','H'],\n",
    "            level_lb=['<500', '500-2000', '>2000'], grp_name='Max Author Citation',\n",
    "            n_rep=1000\n",
    "        )\n",
    "    for N, t in tqdm.tqdm(thres+[(n,0) for n in Ns])\n",
    "])\n",
    "\n",
    "inst_model_ci = pd.concat([\n",
    "        cond_means_ci_subgrp(dat, N=N, t=t,A_col='arxiv_first',\n",
    "            level_col='inst_level',level_vars=['L','M','H'],\n",
    "            level_lb=['top-10', '10-100', 'others'], grp_name='Min Institution Rank',\n",
    "            n_rep=1000\n",
    "        )\n",
    "    for N, t in tqdm.tqdm(thres)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_subgrp_boots = pd.concat([\n",
    "    inst_model_ci.rename({'inst_level':'level'},axis=1).replace({'level':{'all':'All Institutions'}},),\n",
    "    author_model_ci.rename({'author_level':'level'},axis=1).replace({'level':{'all':'All Authors'}},),\n",
    "])\n",
    "\n",
    "\n",
    "full_subgrp_boots['t_lb']=full_subgrp_boots.apply(lambda s :f\"{s['N']}>{s['t']}\",axis=1)\n",
    "full_subgrp_boots['q']=full_subgrp_boots.apply(lambda s :f\"{s['N']}>{s['t']}\",axis=1)\n",
    "\n",
    "for i, (N, t) in enumerate(thres):\n",
    "    q = [r'50\\%', r'75\\%', r'90\\%'][i%3]\n",
    "    full_subgrp_boots.loc[\n",
    "        (full_subgrp_boots.N==N)&(full_subgrp_boots.t==t), 'q'] = q\n",
    "for N in Ns:\n",
    "        full_subgrp_boots.loc[\n",
    "        (full_subgrp_boots.N==N)&(full_subgrp_boots.t==0), 'q'] = r'0\\%'\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "cathedral-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_subgrp_boots.to_csv('./stratified_bootstrap_smps.csv',\n",
    "                         header=True, \n",
    "                         index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8-torch",
   "language": "python",
   "name": "py3.8-torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
